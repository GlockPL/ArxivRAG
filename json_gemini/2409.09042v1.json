{"title": "Semantic Communication for Cooperative Perception using HARQ", "authors": ["Yucheng Sheng", "Le Liang", "Hao Ye", "Shi Jin", "Geoffrey Ye Li"], "abstract": "Cooperative perception, offering a wider field of view than standalone perception, is becoming increasingly crucial in autonomous driving. This perception is enabled through vehicle-to-vehicle (V2V) communication, allowing connected automated vehicles (CAVs) to exchange sensor data, such as light detection and ranging (LiDAR) point clouds, thereby enhancing the collective understanding of the environment. In this paper, we leverage an importance map to distill critical semantic information, introducing a cooperative perception semantic communication framework that employs intermediate fusion. To counter the challenges posed by time-varying multipath fading, our approach incorporates the use of orthogonal frequency-division multiplexing (OFDM) along with channel estimation and equalization strategies. Furthermore, recognizing the necessity for reliable transmission, especially in the low SNR scenarios, we introduce a novel semantic error detection method that is integrated with our semantic communication framework in the spirit of hybrid automatic repeated request (HARQ). Simulation results show that our model surpasses the traditional separate source-channel coding methods in perception performance, both with and without HARQ. Additionally, in terms of throughput, our proposed HARQ schemes demonstrate superior efficiency to the conventional coding approaches.", "sections": [{"title": "I. INTRODUCTION", "content": "Shannon's separation theorem in the 1940s has long been a cornerstone in the field of communication. It suggests that source and channel coding could be optimized separately to approach ideal transmission rates with sufficiently large coding blocks [1]. However, modern wireless communication, driven by the urgency of real-time applications such as the Internet of Things (IoT) and autonomous vehicles, necessitates a departure from this traditional paradigm. The infinite block lengths, idealized in Shannon's theory, clash with the practical demands for low latency and minimal computational complexity in time varying wireless communication scenarios. To address these challenges, semantic communication with joint source-channel coding (JSCC) has been proposed. This method tailors the coding process to specific tasks, optimizing both source and channel coding in unison for improved performance. The initial exploration of JSCC, applied to text transmission, utilized recurrent neural networks (RNNs) to improve semantic fidelity [2], [3]. Concurrently, deep learning-based JSCC systems were designed to directly convert image pixel values into complex channel input symbols, bypassing the traditional separate stages of compression and channel coding [4], [5], [6]. Moreover, in the domain of video transmission, JSCC strategies have been applied to video compression, channel coding, and modulation into a single neural network-based operation, streamlining the transmission process and optimizing bandwidth usage [7], [8].\nEssential for autonomous vehicles, sensor data, particularly light detection and ranging (Li-DAR) point clouds, contains critical semantic content [9]. Autonomous vehicles often face limited perception capabilities due to obstructions, such as buildings and trees. To circumvent these limitations, the concept of cooperative perception has been explored, where connected automated vehicles (CAVs) share their sensor data to achieve a composite view of their surroundings [9], [10], [11], [12], [13], [14]. Vehicle-to-vehicle (V2V) communication is the cornerstone of this system, facilitating the exchange of a wide array of data types, from raw sensory inputs to processed detection outputs, along with crucial metadata, such as timestamps and positional information. Cooperative perception leverages various fusion techniques, which can be categorized into early, intermediate, and late fusion, each with distinct communication demands. Early fusion, which transits raw LiDAR point clouds, demands the highest amount of resources."}, {"title": null, "content": "Intermediate fusion processes and condenses raw data into more manageable features, striking a balance between resource usage and performance efficacy. Late fusion focuses on sharing the final detection results from each CAV, conserving resources but potentially sacrificing accuracy. Typically, intermediate fusion is preferred in cooperative perception due to its efficiency in resource utilization while retaining the potential to achieve the same level of performance as early fusion.\nBuilding on intermediate fusion, various innovative solutions have been investigated to strike a balance between perception performance and communication overhead. For instance, the selective handshake mechanism in [15] identifies and connects the most pertinent CAVs. This mechanism employs a learning-based approach to dynamically form communication groups and determines the optimal timing for data exchange. In addition, the innovative approach to source coding through an end-to-end learning framework [16] employs a spatially aware graph neural network (GNN) to effectively aggregate information collected from CAVs. However, these methods often assumes flawless communication between CAVs, disregarding the potential channel impairments. To address this gap, the novel semantic communication scheme for cooperative perception in [17] showcases the potential of semantic communication in enhancing cooperative perception.\nDue to safety considerations in autonomous driving, data reliability becomes particularly crucial in cooperative perception. Previous approaches cannot guarantee the transmission re-liability under low signal-to-noise ratio (SNR) conditions, posing a significant challenge for the deployment of these technologies in real-world scenarios. Traditionally, hybrid automatic repeat request (HARQ) protocols have been utilized in communication systems to bolster transmission reliability. However, there is limited research on the application of HARQ within semantic communication systems, especially those customized for cooperative perception. Existing studies [8], [18] typically center around the design of error detection methods and aim to ensure the integrity of the reconstructed data rather than the successful completion of task-oriented objectives. These methods, while valuable for reconstruction tasks, may not fully align with the specific requirements of applications, such as cooperative perception, where the ultimate goal extends beyond mere data reconstruction. Designing error detection methods and HARQ protocols for task-oriented semantic communication systems, such as cooperative perception, is challenging. It encompasses not only ensuring the robustness and reliability of data transmission in adverse communication environments but also aligning the error correction mechanisms with the semantic goals of the system."}, {"title": null, "content": "In response, we first propose a novel semantic error detection method to identify semantic mistakes in the task-oriented semantic communication system. Additionally, we present a coop-erative perception semantic communication framework that integrates HARQ, thereby enhancing the reliability of data transmission. Our system is built upon a JSCC architecture and is developed through end-to-end learning, which is optimized to achieve better semantic performance with HARQ. Our main contributions can be summarized as follows:\n\u2022 We introduce a model for cooperative perception based on JSCC that leverages an im-portance map to transmit semantic information effectively, aiming to enhance semantic performance while minimizing communication overhead. By conducting evaluations over a time-varying multipath fading channel, our proposed JSCC communication framework demonstrates superior performance compared to conventional methods that treat source and channel coding separately.\n\u2022 In contrast to traditional bit-error detection methods that rely on cyclic redundancy check (CRC), we develop SimCRC, a semantic error detector designed to assess whether received features necessitate retransmission. This detector employs a Siamese Network architecture and undergoes training via similarity ranking to accurately identify semantic errors.\n\u2022 To ensure the reliability of our model under diverse channel conditions, we have inte-grated our JSCC framework with HARQ techniques. This integration consists of a chase combining strategy, designated as SimHARQ-I, and an approach that incorporates additional redundancy, termed SimHARQ-II. We have conducted extensive simulation on time-varying multipath fading channels to show the proposed SimHARQ-I and SimHARQ-II schemes outpeform conventional separate source and channel coding approaches in both perception performance and throughput.\nThe remainder of this paper is structured as follows: Section II delineates our proposed JSCC model tailored for cooperative perception. Section III elaborates on our novel semantic error detection approach, outlines the HARQ designs, and details the training methodologies employed. Section IV presents empirical evidence showcasing the advantages of our proposed model through simulation results. Finally, Section V concludes the paper."}, {"title": "II. SYSTEM MODEL AND PROBLEM FORMULATION", "content": "Consider a scenario where one CAV shares intermediate features with an ego car. To strike a balance between perception accuracy and communication overhead, we employ an importance"}, {"title": null, "content": "map generator to identify the most crucial elements within the entire feature set. The cooperative perception system with intermediate fusion is structured around four key components: feature extraction, feature sharing, feature fusion, and detection result generation. In this section, we first present the overall procedure of cooperative perception based on the importance map. Subsequently, we extend our cooperative perception model to an OFDM-based framework, aiming to address the challenges posed by time-varying multipath fading channels. Lastly, we will discuss the intricacies and challenges associated with implementing HARQ within the cooperative perception framework."}, {"title": "A. Cooperative Perception Model based on Importance Map", "content": "The framework depicted in Fig. 1 outlines cooperative perception with intermediate fusion at the tth transmission, where the anchor-based PointPillar method [19], [20], [21], [15] is chosen as the backbone to extract the semantic information of the ith sample from the raw LiDAR point clouds X. The extracted feature tensor, Fi, in the CAV can be represented as\n$F_i = \\Phi(X_i),$\nwhere $F_i \\in \\mathbb{R}^{C \\times H \\times W}$, C is the number of channels, H and W represent the height and width of the feature tensor, respectively. The extracted feature tensor $F_i'$ for the ego car can be defined"}, {"title": null, "content": "similarly.\nIn the context of feature sharing, the configurations of the semantic encoder and decoder may vary, depending on the specific HARQ scheme, which will be elaborated in the subsequent section. Here, we introduce a versatile framework for feature sharing, elucidating the process through which feature tensors are sent to the ego vehicle over multiple transmissions. As depicted in Fig. 1, the importance map generator, $P(\\cdot)$, is tasked with pinpointing critical elements within the feature tensor, subsequently generating an importance map $C_i^{(t)}$ for the tth transmission. Following this, the data for the tth transmission, $M_i^{(t)}$, is generated via element-wise multiplication of $F_i$ with the importance map $C_i^{(t)}$, denoted by\n$C_i^{(t)} = P(F_i),$\nand\n$M_i^{(t)} = F_i C_i^{(t)},$\nrespectively, where $C_i^{(t)} \\in [0,1]^{H \\times W}$ and $M_i^{(t)} \\in \\mathbb{R}^{C \\times H \\times W}$. In this study, we define the compres-sion ratio, $CR^{(t)} = \\frac{|M_i^{(t)}|}{|F_i|}$, as the ratio of the data size of the transmitted feature tensor $M_i^{(t)}$ at the tth transmission to the size of the entire feature tensor $F_i$. Through extensive experimentation, we find that setting $CR^{(t)}$ to the order of $10^{-2}$ achieves a desirable balance between conserving transmission resources and maintaining perception accuracy. Given the sparsity of $M_i^{(t)}$, the overall transmission requirement is substantially reduced.\nThen we develop a semantic encoder $\\Psi_s^{(t)}(\\cdot)$ and a semantic decoder $\\Psi_d^{(t)}(\\cdot)$ specifically for the tth transmission. Different from the traditional communication frameworks, our system integrates source coding, channel coding, and modulation within a unified scheme, which will be trained in an end-to-end manner, to enhance semantic-level transmission efficacy. Particularly, the complex symbol stream for the tth transmission is derived from $M_i^{(t)}$ using the semantic encoder, denoted by\n$T_i^{(t)} = \\Psi_s^{(t)}(M_i^{(t)}),$\nwhere $T_i^{(t)} \\in \\mathbb{C}^{H' \\times W'}$, $H'$ and $W'$ represent height and width of the tensor $T_i^{(t)}$. Following the encoding process, the joint source-channel coded sequence, $T_i^{(t)}$, is sent over a time-varying multipath fading channel.\nAt the receiver side (the ego car), the received symbol, denoted as $\\hat{T}_i^{(t)}$, is mapped to semantic information by the semantic decoder $\\Psi_d^{(t)}(\\cdot)$, yielding $\\hat{M}_i^{(t)}$,\n$\\hat{M}_i^{(t)} = \\Psi_d^{(t)}(\\hat{T}_i^{(t)}).$"}, {"title": null, "content": "Considering that prior transmissions may contain correlated information, the candidate feature $\\hat{F}_i^{(t)}$ for the tth transmission is formulated by aggregating all preceding messages up to the tth transmission. This aggregation is achieved through a function $f_c(\\cdot)$, represented as\n$\\hat{F}_i^{(t)} = f_c(\\hat{M}_i^{(1)}, ..., \\hat{M}_i^{(t-1)}, \\hat{M}_i^{(t)}).$\nUpon passing error detection, $\\hat{F}_i^{(t)}$ is updated to $F_i$ and is utilized in the ensuing fusion steps. In scenarios where transmission attempts to reach their maximum, denoted by B, the selection of $F_i$ from the collection $\\hat{F}_i^{(1)}, \\hat{F}_i^{(2)}, ..., \\hat{F}_i^{(B)}$ is determined through a specific selection strategy, details of which will be discussed in the subsequent section.\nUtilizing attention-based mechanisms for feature fusion, we integrate the semantic data, $\\hat{F}_i^{(t)}$, with $F_i'$, deriving a comprehensive fusion tensor that encapsulates semantic insights from both the CAV and the ego car. This fusion output, labeled as $D_i$, is formulated as\n$D_i^{(t)} = \\chi(F_i', \\hat{F}_i^{(t)}),$\nwhere $D_i \\in \\mathbb{R}^{C \\times H \\times W}$ represents the fused tensor and $\\chi(\\cdot)$ symbolizes the attention fusion network. Notably, our method adopts a self-attention fusion approach, which is instrumental in elucidating the spatial interplay between $F_i'$ and $\\hat{F}_i$, enhancing the efficacy of the fusion process. Following the feature fusion, a bounding box method can be generated through the prediction header along with the associated confidence scores. The detection output, $\\hat{Y}_i$, generated by the detection network $\\Gamma(\\cdot)$, can be expressed as\n$\\hat{Y}_i = \\Gamma(D_i),$\nwhere $\\hat{Y}_i$ consists of the regression output and classification output. The regression component includes the 3D position, dimensions, and yaw angle of the predefined anchor boxes. The classi-fication component assigns a confidence score to each bounding box, indicating the probability that it encloses an object."}, {"title": "B. Cooperative Perception Model with OFDM", "content": "For each feature transmission in OFDM systems, a distinct time slot is allocated, comprising Np pilot symbols for channel estimation and Ns data symbols for payload transmission. Channel estimation is facilitated using block-type pilots, where known symbols are transmitted across all subcarriers over a series of OFDM symbols. The complex symbol stream, $T_i$, for the tth"}, {"title": null, "content": "transmission is subject to an initial normalization step, resulting in $T_i^h \\in \\mathbb{C}^{H' \\times W'}$, represented as\n$T_i^h = \\frac{T_i}{\\sqrt{H'W'P_T}},$\nwhere $(\\cdot)^*$ is the conjugate transpose and $P_T$ represents the average transmit power constraint. The normalized symbol stream, $T_i^h$, is reshaped into $T_i^m \\in \\mathbb{C}^{N_s \\times L_{fft}}$, where $L_{fft}$ denotes the number of subcarriers in an OFDM symbol.\nIf the product of H' and W' is less than that of Ns and $L_{fft}$, zero-padding is applied to reshape $T_i^h$ into $T_i^m$. The pilot symbols, denoted as $T_i^p \\in \\mathbb{C}^{N_p \\times L_{fft}}$, are crucial for channel estimation. In our approach, the Np pilot symbols are synthesized using Quadrature Amplitude Modulation (QAM) on randomly generated bits. Once the pilot and data symbols are prepared, we employ the Inverse Fast Fourier Transform (IFFT) to convert from frequency to time domain, resulting in $T_i^p$ and $T_i^m$. This step is followed by appending a cyclic prefix (CP) to enhance the resilience to multipath effects by reducing intersymbol interference. The composite transmit signal, E, encompassing both pilot and data symbols post-CP addition, is then represented as $E \\in \\mathbb{C}^{(N_p + N_s) \\times (L_{fft} + L_{cp})}$, ready for transmission over the channel. At the receiver, upon acquiring the noisy channel output, $\\hat{E}$, the system first discards the CP and then employs the Fast Fourier Transform (FFT) to revert to the frequency domain, yielding the received pilot symbols, $\\hat{T}_i^p$ and data symbols, $\\hat{T}_i^m$.\nIn this paper, we consider wireless communication over a slowly time-varying multipath fading channel through an OFDM system without intercarrier interference. We assume that the Doppler spread is significantly smaller than the subcarrier spacing, allowing the channel to be considered static throughout the duration of an OFDM symbol. Thus, the received frequency domain symbols of the pilots and information can be represented as\n$\\hat{T}_i^m[j, k] = H[j, k]T_i^m[j, k] + Z[j, k],$\nand\n$\\hat{T}_i^p[j, k] = H[j, k]T_i^p[j, k] + Z[j, k],$\nwhere H[j, k] is the channel frequency response at the kth subcarrier of the jth OFDM symbol, and Z[j, k] denotes the AWGN. Meanwhile, H[j, k] can be represented as\n$H[j, k] = \\sum_{m=0}^{M-1} a_m(j)e^{-j2\\pi k \\Delta f \\tau_m}.$"}, {"title": "C. HARQ in Cooperative Perception", "content": "Conventional communication systems utilize three main HARQ mechanisms, namely HARQ-I, HARQ-II, and HARQ-III, based on the types of retransmission content [22].\nHARQ-I: Chase Combining. HARQ-I, also known as the traditional HARQ scheme, trans-mits the same data packet in all retransmissions. It involves adding cyclic redundancy check (CRC) bits to the transmitted data packets and applying forward error-correction (FEC) en-coding. The receiver performs FEC decoding and CRC check on the received data. If errors are detected, the receiver will discard the data associated with the erroneous group and send a negative acknowledgment (NACK) signal, requesting the retransmission of the same data from the previous frame.\nHARQ-II: Incremental Redundancy. HARQ-II selectively transmits parity bits as required, giving it the designation \u201cincremental redundancy\u201d. Hence, in HARQ-II, the transmitted data during the initial transmission and subsequent retransmissions typically differ. Unlike HARQ-I, the receiver does not discard the previously transmitted erroneous groups. Instead, it combines them with the received retransmitted groups for improved decoding.\nHARQ-III. Generally, HARQ-III, closely resembles HARQ-II with the distinction that both information data and parity bits are incorporated in each retransmission. Therefore, each data packet can be independently decoded or synthesized into a codeword with more significant redundancy for combined decoding.\nIntegrating the proposed semantic communication framework with traditional HARQ mecha-nisms faces new challenges. Unlike conventional systems where CRC is used for error detection, our proposed method transmits features directly, bypassing the need for quantization and CRC. This necessitates the development of a semantic-based error detection method to identify semantic errors as traditional CRC cannot be applied to unquantized data. Moreover, to design novel HARQ mechanisms that align with JSCC in our system, similar to traditional HARQ-I and HARQ-II strategies but with semantic considerations. It is an open area for research. We aim"}, {"title": null, "content": "to adapt the principles of chase combining and incremental redundancy to suit our cooperative perception communication framework."}, {"title": "III. COOPERATIVE PERCEPTION WITH HARQ", "content": "In this section, we first introduce a novel semantic error detection method, named SimCRC. Subsequently, the training methodology of SimCRC is outlined. Then, we delineate the architec-ture of our cooperative perception system that integrates HARQ-I, referred to as SimHARQ-I, as well as the architecture employing incremental redundancy, designated as SimHARQ-II. The loss function and corresponding training algorithm of our proposed method are also explicated in detail."}, {"title": "A. Semantic Error Detection Method", "content": "In traditional transmission systems, CRC error detection is typically employed to facilitate automatic retransmission requests, ensuring the correct reception of transmitted data alongside feedback acknowledgments (ACKs). However, the conventional CRC method might flag a trans-mission as erroneous if the bit-error rate (BER) is non-zero, even when the transmitted content is semantically very close to the original. In semantic communication, the focus shifts from bit-level precision to semantic similarity. For instance, in sentence semantic communication systems [18], the BERT model, a pre-trained neural network, is utilized to assess sentence similarities. How-ever, many task-oriented semantic communication systems, including our proposed cooperative perception framework, do not inherently possess a mechanism like BERT for semantic similarity evaluation. Therefore, we propose a semantic-based error detection approach, termed SimCRC, and develop a novel method to measure semantic similarity between the original feature $F_i^{(t)}$ and its reconstructed counterpart $\\hat{F}_i^{(t)}$, in terms of a similarity score S.\nIt is widely known that to some extent, the loss can represent the semantic distance between the predicted result and the ground truth. The perception loss, $L_{per}$, in cooperative perception is composed of localization loss $L_{local}$ and confidence loss $L_{conf}$, represented as\n$L_{per} = L_{local} + L_{conf},$\nwhere $L_{local}$ quantifies the deviation in position, size, and yaw angle between predicted and actual anchor boxes, and $L_{conf}$ assesses the discrepancy between predicted confidence scores and true labels. Semantic errors in $\\hat{F}_i^{(t)}$ will elevate $L_{per}$, indicating degraded perception performance."}, {"title": null, "content": "To compute semantic similarity, we examine the difference between the perception losses of the original and reconstructed features. The similarity score S is inversely related to this difference, modeled as\n$S = min(U, -log_{10} |L_{per}(F_i^{(t)}) - L_{per}(\\hat{F}_i^{(t)})|),$\nwhere U is a predefined upper limit for S. This score helps determine semantic closeness between $F_i^{(t)}$ and $\\hat{F}_i^{(t)}$. However, we need to train a similarity score $\\hat{S}$ to predict the true score S, since $\\hat{F}_i^{(t)}$ is unavailable during operation.\nPrior information, analogous to CRC in the traditional systems, is necessary for semantic error detection. Before sharing features, vehicles broadcast metadata like relative pose and confidence maps [14]. As depicted in Fig. 1, confidence maps $R_i$ and $\\hat{R}_i$, derived from the original and reconstructed features, contain vital semantic information and are smaller in size compared to the full feature, making them suitable as prior information. Note that $R_i$ and $C_i^{(t)}$ are generated from different output layers of the importance map. $C_i^{(t)}$ is a selection matrix composed of 0 and 1, whereas $R_i$ contains certain semantic information. As Fig. 2 illustrates, by employing a siamese neural network [23] to feature dual resnet branches with shared weights, we generate the predicted semantic similarity $\\hat{S}$ using $R_i$ and $\\hat{R}_i$ as\n$\\hat{S} = Sigmoid(MLP([Res(R_i), Res(\\hat{R}_i)])),$\nwhere $\\hat{S}$ is then evaluated against a threshold $\\beta$, a hyperparameter. If $\\hat{S}$ is greater than $\\beta$, ACK should be set as 1, confirming the semantic integrity of the received feature. If $\\hat{S}$ is less than $\\beta$, ACK should be set as 0, indicating significant semantic discrepancies."}, {"title": "B. Training Algorithm of Semantic Error Detection Method", "content": "While the predicted semantic similarity score $\\hat{S}$ is intended to reflect the actual similarity score S, a precise numerical correspondence between the two is unnecessary. Consequently, using a regression loss function for the siamese network might not be the most effective approach. This ineffectiveness is attributed not only to the challenging nature of the training process but also to the susceptibility of the model to changes in the formulation of S. For instance, altering the function f(x) = -log10(x) to f(x) = log2(x) could significantly impact the distribution of S, potentially necessitating a retraining of $\\hat{S}$ without adding meaningful value.\nInspired by RankNet [24], we propose to view it as a similarity ranking problem. Suppose the feature undergoes transmission under varying channel conditions K times, yielding K distinct pairs of $\\hat{S}$ and S. We can easily justify that the feature from the mth transmission is semantically closer to the original than that from the nth if the similarity score $S_m$ from the mth transmission is higher than $S_n$ from the nth transmission. Consequently, we can establish a ranking of the K transmissions based on their respective similarity scores S. The objective in RankNet training is to align the predicted scores, $\\hat{S}$, with the ranking order defined by S. The training process aims to refine $\\hat{S}$ so that it can accurately rank the transmission samples in a manner consistent with the ranking derived from S. This approach circumvents the need for a strict numerical match between $\\hat{S}$ and S, focusing on preserving the relative ordering. It is more pertinent to semantic similarity assessment.\nIn the training phase, the dataset is segmented based on queries. It is important to note that the confidence map, $R_i$, remains unchanged across different samples. Consequently, the predicted score for the mth sample, as shown in (15), is reformulated as\n$\\hat{S}_m = Sigmoid(MLP([Res(R_i), Res(\\hat{R}_i^m)])),$\nwhere $\\hat{R}_i^m$ signifies the confidence map corresponding to the mth sampling.\nFor each query, the model examines every pair of samples, $S_m$ and $S_n$, along with their respective confidence map samplings $\\hat{R}_i^m$ and $\\hat{R}_i^n$. These pairs are processed through 16 to produce two outputs, which are then processed through a sigmoid function to estimate the probability that $\\hat{S}_m$ is greater than $\\hat{S}_n$, represented by\n$P_{mn} = P(\\hat{S}_m > \\hat{S}_n) = \\frac{1}{1 + e^{-\\sigma(\\hat{S}_m - \\hat{S}_n)}},$\nwhere $\\sigma$ is a hyperparameter that influences the curvature of the sigmoid function. The training objective is to minimize the discrepancy between the predicted probabilities and the actual"}, {"title": null, "content": "ranking outcomes. The actual probability, denoted by $\\overline{P}_{mn}$, reflects the ground truth that $\\hat{S}_m$ is greater than $\\hat{S}_n$. We can obtain $\\overline{P}_{mn}$ through $\\overline{P}_{mn} = \\frac{1}{2}(1+S_{mn})$, where $S_{mn}$ can be represented as\n$\\begin{aligned}\nS_{mn} = \\begin{cases}\n1, & \\text{if } S_m > S_n, \\\\\n0, & \\text{if } S_m = S_n \\\\\n-1, & \\text{if } S_m < S_n.\n\\end{cases}\n\\end{aligned}\n$\nThe cross entropy cost function, employed here, penalizes the deviation between the predicted $P_{mn}$ and the actual $\\overline{P}_{mn}$, represented by\n$C_{mn} = -\\overline{P}_{mn} log P_{mn} - (1 - \\overline{P}_{mn})log(1 - P_{mn})\\\\\n= \\frac{1}{2}(1 - S_{mn}) \\sigma(\\hat{S}_m - \\hat{S}_n) + log_e(1 + e^{-\\sigma(\\hat{S}_m - \\hat{S}_n)}).$\nFor a point cloud consisting of K samples over different channels, there are K(K \u2212 1)/2 unique pairs of samples. While (19) addresses the similarity ranking for individual pairs, the aggregate loss for all pairs is computed as\n$C = \\sum_{\\{m,n\\} \\in I} C_{mn},$\nwhere I is the set comprising all unique index pairs {m, n}. To ensure each pair is included only once, we define that I contains pairs of indices {m,n} where $S_m > S_n$, resulting in $S_{mn} = 1$. The gradient of the loss function with respect to a weight parameter $w_k$ is calculated as\n$\\begin{aligned}\n\\frac{\\partial C}{\\partial w_k} &= \\sum_{\\{m,n\\} \\in I} \\frac{\\partial C_{mn}}{\\partial w_k} = \\sum_{\\{m,n\\} \\in I} \\lambda_{mn} (\\frac{\\partial \\hat{S}_m}{\\partial w_k} - \\frac{\\partial \\hat{S}_n}{\\partial w_k}) \\\\\n&= \\sum_{\\{m,n\\} \\in I} (\\lambda_{mn} - \\lambda_{nm}) \\frac{\\partial \\hat{S}_m}{\\partial w_k} = \\sum_{m} A_m \\frac{\\partial \\hat{S}_m}{\\partial w_k},\n\\end{aligned}\n$\nwhere $\\lambda_{mn}$ and $A_m$ are weights that quantify the influence of each pair's gradient difference on the overall gradient. Specifically, $\\lambda_{mn}$ is defined as\n$\\lambda_{mn} = \\frac{\\sigma}{2} (1 - S_{mn}) - \\frac{\\sigma e^{\\sigma (\\hat{S}_m - \\hat{S}_n)}}{1 + e^{\\sigma(\\hat{S}_m - \\hat{S}_n)}},$\nwhich highlights the contribution of each pair to the gradient. The term, $A_m$ is then the net effect of all pair-wise comparisons involving the mth sample, represented by\n$A_m = \\sum_{\\{n | S_m > S_n, n \\in I\\}} \\lambda_{mn} - \\sum_{\\{n | S_m < S_n, m \\in I\\}} \\lambda_{nm}.$\nHence, $A_m$ can be regarded as the cumulative diminutive forces affixed to the mth sampling. As depicted in Fig. 3, the orientation of these vectors indicates the cumulative direction and magnitude of adjustments needed for the predicted score $\\hat{S}_m$ of mth sample. This approach"}, {"title": null, "content": "ensures that the training process accounts for the relative rankings of all sample pairs, guiding the model to refine its predictions in a manner aligning with the overall similarity ranking structure of the dataset."}, {"title": "C. Cooperative Perception System with HARQ", "content": "Initially, we present SimHARQ-I, an end-to-end semantic framework analogous to the HARQ-I framework. As illustrated in Fig. 5(a), SimHARQ-I is engineered to transmit a feature repeatedly until the receiver successfully reconstructs it or the maximum transmission limit, denoted as B, is reached. Meanwhile, the feature can be decoded independently at the tth transmission. Considering that the transmitted information remains constant across various transmission rounds,"}, {"title": null, "content": "it is possible that we use only one importance map, $C_i^{(1)}$, and a unique pair of semantic encoder and decoder, {$\\Psi_s^{(1)}$, $\\Psi_d^{(1)}$}.\nWe depict the architecture of the proposed semantic encoder and decoder in Fig. 4. At the transmitter, the semantic encoder processes feature map $M_i^{(1)}$ from $\\mathbb{R}^{C \\times H \\times W}$ to complex-valued channel input samples $T_i^{(1)} \\in \\mathbb{C}^{H' \\times W'}$. This process involves a deterministic function $\\Psi_s^{(1)}$ and converts $\\mathbb{R}^{C \\times H \\times W}$ to $\\mathbb{C}^{H' \\times W'}$, adhering to an average power constraint. Initially, the feature map M is reshaped to eliminate the zero-component. The feature map is then transformed into Tusing a convolution neural network (CNN) composed of convolutional, normalization, and parametric ReLU activation layers.\nAt the receiver, the semantic decoder converts received complex-valued samples $\\hat{T}_i^{(1)}$ from $\\mathbb{C}^{H' \\times W'}$ back to the reconstructed feature map $\\hat{M}_i^{(1)} \\in \\mathbb{R}^{C \\times H \\times W}$ using a deterministic function $\\Psi_d^{(1)}(\\cdot)$. The decoding process, employing transconvolutional layers, introduces greater complexity than the convolutional layers of the encoder. A reshape layer is then applied to align the reconstructed signal with $M_i^{(1)}$. Then, the tth candidate feature $\\hat{F}_i^{(t)}$ can be obtained through (6), where $f_c(\\hat{M}_i^{(1)}, ..., \\hat{M}_i^{(t-1)}, \\hat{M}_i^{(t)}) = \\hat{M}_i^{(t)}$.\nIf the process reaches the transmission attempt limit, B, the selected feature $F_i$ is determined by\n$F_i = \\hat{F}_i^{(t^*)},$\nwhere $t^* = \\underset{t}{argmax} \\hat{S}_t$ and $\\hat{F}_i^{(t^*)}$ is the feature from the transmission round $t^*$ that maximizes the similarity score $\\hat{S}_t$, indicating that it closely resembles the original feature and is thus ideal for fusion. This approach ensures the selection of the most representative feature for subsequent processing stages.\nSubsequently, we extend our investigation to an end-to-end semantic framework, SimHARQ-II, which is analogous to the HARQ-II framework. SimHARQ-II is devised to transmit incre-mental information until the feature is successfully reconstructed or the maximum number of transmission attempts is reached. Unlike SimHARQ-I, the whole transmitted revisions should be combined for decoding. To facilitate the B transmission rounds, we employ two distinct pairs of semantic encoders and decoders, as depicted in Fig. 5(b). The initial transmission utilizes the first encoder-decoder pair {$\\Psi_s^{(1)}$, $\\Psi_d^{(1)}$} while subsequent transmissions engage the second pair {$\\Psi_s^{(2)}$, $\\Psi_d^{(2)}$}. The configuration of {$\\Psi_s^{(1)}$, $\\Psi_d^{(1)}$} is optimized for high SNR conditions, aiming to maximize efficiency and accuracy in favorable transmission environments. On the other"}, {"title": null, "content": "hand, {$\\Psi_s^{(2)}$, $\\Psi_d^{(2)}$} is designed to be robust in lower SNR scenarios, ensuring reliable feature reconstruction under challenging conditions.\nFor SimHARQ-II, the"}]}