{"title": "VISUALIZING UNCERTAINTY IN TRANSLATION TASKS: AN EVALUATION OF LLM PERFORMANCE AND CONFIDENCE METRICS", "authors": ["Jin Hyun Park", "Utsawb Laminchhane", "Umer Farooq", "Uma Sivakumar", "Arpan Kumar"], "abstract": "Large language models (LLMs) are increasingly utilized for machine translation, yet their predictions often exhibit uncertainties that hinder interpretability and user trust. Effectively visualizing these uncertainties can enhance the usability of LLM outputs, particularly in contexts where translation accuracy is critical. This paper addresses two primary objectives: (1) providing users with token-level insights into model confidence and (2) developing a web-based visualization tool to quantify and represent translation uncertainties. To achieve these goals, we utilized the T5 model with the WMT19 dataset for translation tasks and evaluated translation quality using established metrics such as BLEU, METEOR, and ROUGE. We introduced three novel uncertainty quantification (UQ) metrics: (1) the geometric mean of token probabilities, (2) the arithmetic mean of token probabilities, and (3) the arithmetic mean of the kurtosis of token distributions. These metrics provide a simple yet effective framework for evaluating translation performance. Our analysis revealed a linear relationship between the traditional evaluation metrics and our UQ metrics, demonstrating the validity of our approach. Additionally, we developed an interactive web-based visualization that uses a color gradient to represent token confidence. This tool offers users a clear and intuitive understanding of translation quality while providing valuable insights into model performance. Overall, we show that our UQ metrics and visualization are both robust and interpretable, offering practical tools for evaluating and accessing machine translation systems.", "sections": [{"title": "Introduction", "content": "The rapid advancement of large language models (LLMs) has significantly improved machine translation, providing tools for handling various languages and contexts [1, 2]. Despite these advancements, LLM-generated translations often need more clarity, particularly when translating bigger or more complex sentences [3]. These uncertainties pose challenges for users who rely on translation models for critical tasks, where understanding the model's confidence in its translations is crucial [4]. Without clear indications of uncertainty, users may struggle to gauge the reliability of a translation, potentially leading to misinterpretation or misuse in high-stakes environments.\nIn machine translation, commonly used metrics such as BLEU [5] and ROUGE [6] provide valuable insights into translation quality. These metrics primarily assess n-gram overlap (i.e., precision), making them straightforward to interpret. Additionally, they have been shown to generally correlate with human judgment when averaged across a corpus of sentences [7]. Similarly, METEOR [8], another popular metric, is recognized for its ability to capture semantic and linguistic nuances more effectively than BLEU and ROUGE. By incorporating resources like WordNet [9] and prioritizing recall over precision, METEOR emphasizes semantic meaning. However, like the other metrics, it primarily evaluates overall alignment and does not provide token-level confidence.\nTraditional translation quality metrics overlook the probabilistic uncertainty in LLM outputs. However, the probabilistic uncertainty is crucial for applications requiring explicit communication of accuracy and reliability. Quantifying and visualizing these uncertainties can significantly enhance user interpretability and decision-making, particularly in scenarios that demand precise and confident translations.\nTo address this gap, this study introduces a method for quantifying and visualizing uncertainties in LLM-generated translations. Uncertainty is quantified using token-level probabilities and token-level kurtosis derived from the model's internal outputs. Specifically, we define three measures to assess uncertainty: (1) the geometric mean of token probabilities, (2) the arithmetic mean of token probabilities, and (3) the arithmetic mean of the scaled-kurtosis of top-k tokens' distributions. These metrics collectively provide a comprehensive view of both overall and localized confidence within translations, enabling a deeper understanding of uncertainty. For our experiments, we used the WMT dataset with T5 [10] models of varying sizes - small, base, and large. Similar to the T5 paper, our study focuses on three language translation tasks: English to German, English to French, and English to Romanian, using the WMT dataset only. We used the same dataset and model to develop an uncertainty visualization tool. This tool is implemented as a web-based interface where output tokens are color-coded with varying gradients to represent the confidence level of each token given an input sentence.\nThe following research question is guiding this study:\n\u2022 How can uncertainty in large language model-generated translations be effectively quantified and visualized to enhance user interpretability and decision-making across critical applications?"}, {"title": "Literature Review", "content": "Predictive models, especially those based on deep learning and large language models (LLMs), are widely used across domains, ranging from healthcare [11] to natural language processing [12] and social networks [13]. A key challenge in deploying these models is managing and communicating the uncertainty inherent in their predictions.\nIn neural networks, deep ensembles estimate uncertainty by generating predictions from multiple independently trained models, with variability indicating uncertainty in regions of disagreement. Monte Carlo Dropout (MC-Dropout) estimates uncertainty by running multiple forwards passes with dropout layers enabled during inference, calculating variance in predictions. A study by Dutta et al. [14] compares these methods, finding deep ensembles to be more accurate, while MC-Dropout is competitive with faster inference times. Visualization techniques like Parallel Coordinates Plots (PCP) and heatmaps were used to illustrate uncertainty and model error.\nIn medical applications, where incorrect predictions can have serious consequences, communicating uncertainty is vital [15]. The authors emphasize the importance of quantifying and effectively conveying uncertainty in clinical machine-learning models. Furthermore, explicitly expressing uncertainty through phrases like \"I'm not sure\" can greatly enhance trust between clinicians and machine learning systems.\nThe impact of uncertainty visualization on user reliance has also been explored [16]. The paper found that users tended to trust model outputs more when uncertainty was visualized, particularly in high-stakes or difficult decision-making tasks. Visualization techniques, such as ordinal expressions of uncertainty (e.g., \"low,\" \"medium,\" \"high\"), were shown to help users make more calibrated decisions.\nSimilarly, a tool has been developed to visualize uncertainties and errors in multimodal AI systems [17]. The tool provides an interface for error analysis, enabling users to understand how a model processes and integrates different types of data (e.g., text and images) and where uncertainties arise. This approach is particularly useful in complex AI systems that operate across multiple domains, offering a holistic view of uncertainty across modalities.\nWith the rise of LLMs, there is growing concern about the generation of hallucinations - false or inaccurate information presented as credible [18]. The authors examined how such hallucinations propagate through social networks such as Facebook and how uncertainty in these hallucinations can be measured. They also worked on the methods for quantifying the credibility of hallucinations based on the task type (e.g., question-answering, dialogue). Likewise, a specific type of uncertainty related to knowledge errors exists in LLMs [19]. They propose a method that encourages LLMs to self-reflect and express self-doubt, allowing users to better understand when the model is uncertain about its knowledge."}, {"title": "Methodology", "content": "This study aims to develop a visualization approach to effectively represent uncertainties in using LLMs for translation tasks. To accomplish this, we quantify uncertainties using custom UQ metrics derived from token-level probabilities. We also explore the relationship between these UQ metrics and established translation evaluation metrics, including BLEU, METEOR, and ROUGE. Additionally, we created a web-based application to visualize token-level uncertainties effectively. These visualizations will help users understand where and to what extent the model's outputs may deviate from the ground truth, offering a more interpretable and user-centric interface for translation tasks. We evaluated our approach using various T5 model configurations, including small, base, and large. The sizes of these models are detailed in Table 1."}, {"title": "Dataset", "content": "We use the VMT14, 15, and 16 datasets [20-22], a well-established translation task datasets containing a diverse array of multilingual sentence pairs. These datasets contain sentence pairs in English with translations into German, French, and Romanian, which serve as ground truth for our evaluation. They have been preprocessed to ensure compatibility with our metrics-based analysis."}, {"title": "Traditional Metrics", "content": "To assess the quality of the model's translations, we employ three widely recognized machine translation metrics:\n\u2022 BLEU: BLEU stands for Bilingual Evaluation Understudy Score. It measures the precision of n-grams between the predicted translation and the ground truth, focusing on token choice and order accuracy [8]. The BLEU score formula is defined by the following,\n$BLEU = BP \\cdot exp(\\sum_{n=1}^{N} w_n log p_n)$\nwhere\n1. $p_n$ denotes the precision of n-grams, defined as the ratio of n-grams in the predicted translation that matches the ground truth to the total number of n-grams in the predicted translation.\n2. $w_n$ represents the weights assigned to each n-gram precision score, often set equally (e.g., $w_n = \\frac{1}{N}$ for a uniform weight).\n3. BP is the brevity penalty, calculated to adjust for length mismatches between the predicted and reference translations. It is defined as\n$BP = \\begin{cases} 1, & \\text{if } c > r \\\\ exp(1 - \\frac{r}{c}), & \\text{if } c \\leq r \\end{cases}$\nwhere c is the length of the predicted translation, and r is the length of the reference translation. The brevity penalty discourages excessively short translations, which might otherwise artificially inflate precision. The BLEU metric aggregates these elements to provide a score that balances accuracy across n-grams of varying lengths.\n\u2022 METEOR: METEOR stands for Metric for Evaluation of Translation with Explicit ORdering. It emphasizes recall over precision by incorporating synonyms and stemming, yielding a refined semantic similarity measure. The METEOR score is computed by matching segments (note that segment differs from token) based on exact, stem, synonym, and paraphrase matches [23] and is represented as,\n$METEOR = F_{mean} \\cdot (1 - Penalty)$\nwhere\n1. $F_{mean}$ is the harmonic mean of precision (P) and recall (R), calculated as\n$F_{mean} = \\frac{10PR}{R + 9P}$\nwhere P represents the proportion of matched segments in the predicted translation to the total segments in the prediction, and R represents the proportion of matched segments in the predicted translation to the total segments in the reference.\n2. Penalty discourages fragmented matches (i.e., multiple short matches over longer, more cohesive seg-ments). The penalty is calculated as follows:\n$Penalty = \\gamma \\cdot (\\frac{Chunks}{Matches})^{\\beta}$\nwhere Chunks is the number of contiguous matched segments, Matches is the total number of matched segments, and $\\gamma$ and $\\beta$ are empirically set constants. The penalty reduces the score when the matches are dispersed, reflecting a preference for translations that maintain cohesive segments.\n\u2022 ROUGE: ROUGE is a recall-focused metric commonly used in summarization tasks, which evaluates the overlap of n-grams or longest common subsequences between the predicted and reference translations. We utilize three ROUGE variants in this study:\n1. ROUGE-1: Calculates the overlap of uni-grams (single words) between the predicted and reference translations. It is defined as\n$ROUGE-1 = \\frac{\\sum_{\\text{uni-grams} \\in \\text{Reference}} min(\\text{Count}_{match}(\\text{uni-gram}))}{\\sum_{\\text{uni-grams} \\in \\text{Reference}} \\text{Count}(\\text{uni-gram})}$\n2. ROUGE-2: Measures the overlap of bi-grams (pairs of consecutive words) between the predicted and reference translations. This metric is more sensitive to word order and context. It is given by\n$ROUGE-2 = \\frac{\\sum_{\\text{bi-grams} \\in \\text{Reference}} min(\\text{Count}_{match}(\\text{bi-gram}))}{\\sum_{\\text{bi-grams} \\in \\text{Reference}} \\text{Count}(\\text{bi-gram})}$\n3. ROUGE-L: Based on the Longest Common Subsequence (LCS), ROUGE-L evaluates fluency and sentence structure by assessing the longest sequence of tokens that appear in the same order in both the prediction and reference. ROUGE-L is calculated as\n$ROUGE-L = \\frac{LCS(Reference, Hypothesis)}{Length \\text{ of Reference}}$\nwhere LCS(Reference, Hypothesis) represents the length of the longest common subsequence between the reference and the hypothesis (or predicted translation). This variant captures structural similarity, making it suitable for assessing overall fluency and coherence.\nEach of these metrics provides a distinct perspective on translation quality. BLEU focuses on precision, METEOR emphasizes semantic and recall-focused similarity, and ROUGE is oriented toward structural and contextual overlap, particularly suited for evaluating summarization and coherence. These metrics are applied to translations generated by the LLM to quantify performance relative to the ground truth."}, {"title": "Uncertainty Quantification (UQ) Metrics", "content": "In addition to traditional evaluation metrics, we incorporate Uncertainty Quantification (UQ) metrics to capture the model's confidence at the token level. For each translation generated by the LLMs - T5 small, base, and large - we store token probability matrices representing the model's likelihood for each token within the translated sentence. These enable a probabilistic understanding of each translation output.\nTo quantify uncertainty, we calculate the UQ metrics using three key measures based on probability distributions:\n1. Geometric Mean of Token Probabilities: This measure calculates the geometric mean of the probabilities across tokens in a translation, providing a multiplicative aggregation of token-level confidences. This metric is calculated as:\n$GT = (\\prod_{i=1}^{L} p(token_i))^{\\frac{1}{L}}$\nwhere L is the total number of tokens in the translated sentence, and $p(token_i)$ represents the probability of the i-th token. The geometric mean helps capture an overall confidence score emphasizing lower probabilities. Hence reflecting conservative confidence in the translation.\n2. Arithmetic Mean of Token Probabilities: The arithmetic mean provides an additive aggregation of token probabilities. It offers an average confidence measure across all tokens. This metric is given by:\n$AT = \\frac{1}{L} \\sum_{i=1}^{L} p(token_i)$\nThis equation averages out the probability of each token in the sequence, giving an overall score that treats each token's confidence equally. It offers a balanced view of token-level certainty in the translation.\n3. Arithmetic Mean of scaled kurtosis of token probability: To incorporate higher-order statistical moments, we compute the kurtosis over the top k most probable token probabilities for each token. Specifically, after obtaining the probability distribution for a token, we sort the probabilities in descending order and select the top 1,000 values. We then calculate the kurtosis for each token, resulting in an array of kurtosis values corresponding to the number of tokens in the sentence. To standardize these values, we apply min-max scaling to the kurtosis of each token within the sentence, a step that defines the term scaled kurtosis. Finally, we average the scaled kurtosis values to derive a single representative value for the sentence. Kurtosis in this context captures the peakedness and tail weight of the probability distribution for each token.\n$AK = \\sum_{i \\in \\text{top-k}} [Scaled-kurt(p(token_i))]$\n$\\frac{1}{k} \\sum_{i=1}^{k} \\text{scaled-kurt}(p(token_i))$\nThis measure captures confidence by emphasizing tokens with more extreme probability distributions and provides a refined view of translation certainty. We used this metric because we empirically observed that kurtosis and probability exhibit similar distributions within a sentence.\nA regression analysis between token probabilities and scaled kurtosis yielded a high $R^2$, indicating that kurtosis is a strong statistical measure of uncertainty (see Fig. 1). This trend was consistent across all sentences analyzed. The observed linear relationship between kurtosis and token probabilities supports the use of kurtosis as a central metric for uncertainty quantification.\nThese three measures, taken together, enable a better understanding of uncertainty in model predictions during translation. By visualizing these metrics alongside quality scores, we can contextualize BLEU, METEOR, and ROUGE results and offer users an intuitive representation of translation reliability."}, {"title": "Visualizatation", "content": "To enhance the interpretability of translation tasks and provide insights into model confidence, we developed an interactive live demo application. Built with a web-based front end and a Python-based Flask backend. Users can select from different T5 model variants (small or base) and language pairs (e.g., English to German, French, or Romanian) to observe how the model handles various translation challenges. When a sentence is submitted for translation, the server processes the input, performs the translation using the selected model, and computes token-level uncertainty metrics. These metrics are visualized on the client side using a gradient-based color scheme, where high-confidence tokens are shown in cooler colors and low-confidence tokens in warmer shades. The gradient-based color scheme is determined by token probabilities."}, {"title": "Results", "content": "In this study, we evaluated the performance of T5 small, base, and large on translation tasks from English to three target languages. The evaluation utilized traditional metrics and UQ metrics derived from token probabilities. We also added the BERT F1 score to test semantic similarity. We also provide visualization results for a web-based program. The results are summarized as follows:"}, {"title": "Traditional vs Uncertainty Quantification Metrics", "content": "Fig 2 illustrates each metric's average values and standard deviations across the three translation tasks. These figures demonstrate the superior performance and reduced uncertainty associated with the T5-base, which strikes a balance between size and translation quality. Across all UQ metrics (Confidence-A-K, Confidence-A-T, and Confidence-G-T), the T5 base model either outperforms or performs on par with both T5 small and T5 large. This is a notable finding, as traditional metrics typically show that larger models deliver better performance (e.g., in EN-DE and EN-RO). This suggests that our proposed uncertainty quantification offers unique insights: increasing the number of parameters does not necessarily result in higher confidence when selecting tokens.\nOne limitation of UQ metrics is their tendency to show small standard deviations, with average values typically falling within the 0.7 to 0.9 range. The A-K metric behaves somewhat differently, as its values have been normalized and averaged (See Fig. 2, EN-RO). However, the saturation of UQ metric values at higher levels makes interpreting the results challenging. To address this, a similar normalization and averaging approach, as used in the A-K method, could be applied to A-T and G-T metrics for improved interpretability."}, {"title": "Visualizations", "content": "Fig. 3 and 4 illustrate the translation quality results for uncertainty evaluation using the same sentence. In both samples, The T5 base model demonstrates superior performance compared to the T5 small across both A-T and G-T UQ metrics. Additionally, the gradient-based color scheme visually represents token confidence. The complete code for this work is available at https://github.com/7201krap/CSCE679_Data-Visualization/tree/main/live_demo\nWe observe that T5 small and T5 base produce different outputs or probabilities when given the same input. In Fig. 3, the outputs are identical, but their probabilities differ, which is represented by variations in color. In Fig. 4, the outputs differ, with T5-base producing sentences more likely to be in German and showing higher UQ values (i.e., high confidence).\n\u2022 (T5-small) Translated German: Was ist Ihr Haupt?\n\u2022 (T5-small) Translated English using Google Translate: What is your head?\n\u2022 (T5-base) Translated German: Was ist de in Studien schwer punkt?\n\u2022 (T5-base) Translated English using Google Translate: What is the focus of studies?"}, {"title": "Discussion", "content": "The findings of this study show the complex interplay between model size, translation quality, and uncertainty quantification (UQ) metrics, offering valuable insights into the performance of T5 variants across diverse evaluation criteria. While some may critique our UQ metrics as being overly simplistic and insufficient for capturing semantic meaning compared to traditional metrics, we demonstrate that our proposed UQ metrics align closely with established traditional measures, reinforcing their validity.\nAs illustrated in Fig. 5, a linear relationship is observed between our defined UQ metrics and traditional metrics. While the alignment is not perfect, this relationship supports the validity of our proposed metrics and analysis."}, {"title": "Conclusion", "content": "In this work, we proposed three novel uncertainty metrics based on token probability and kurtosis (leveraging the top-k most probable token candidates). Additionally, we developed an interactive web-based program to visualize token probabilities and confidence levels. Using T5 small, base, and large models, we conducted experiments on translation tasks across three language pairs: English-to-German, English-to-French, and English-to-Romanian.\nOur analysis demonstrated that the proposed UQ metrics offer valuable new insights compared to traditional translation quality evaluation metrics. We also observed a linear relationship between our UQ metrics and their traditional counterparts, further validating their relevance. By visualizing token probabilities interactively, we enhanced user understanding and provided a more accessible and practical interface for analyzing LLM outputs. This approach offers a promising framework for more transparent and interpretable language model applications."}, {"title": "Future Works", "content": "The findings emphasize the importance of balancing model architecture and size to meet specific application needs. Integrating UQ metrics into standard evaluation pipelines can enhance the assessment of translation systems, promoting greater transparency and trust in LLM-generated translations.\nThis study also highlights the value of combining traditional metrics with advanced UQ techniques and visualizations to create translation systems that are both accurate and interpretable. Future research could expand this approach to other language pairs or explore alternative UQ metrics, with a particular focus on low-resource languages. Such efforts could reveal how uncertainty quantification and visualization adapt to diverse linguistic structures and varying data availability."}]}