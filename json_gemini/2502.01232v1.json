{"title": "Efficient Rule Induction by Ignoring Pointless Rules", "authors": ["Andrew Cropper", "David M. Cerna"], "abstract": "The goal of inductive logic programming (ILP) is to find a set of logical rules that generalises training examples and background knowledge. We introduce an ILP approach that identifies pointless rules. A rule is pointless if it contains a redundant literal or cannot discriminate against negative examples. We show that ignoring pointless rules allows an ILP system to soundly prune the hypothesis space. Our experiments on multiple domains, including visual reasoning and game playing, show that our approach can reduce learning times by 99% whilst maintaining predictive accuracies.", "sections": [{"title": "1 Introduction", "content": "The goal of inductive logic programming (ILP) is to induce a hypothesis (a set of logical rules) that generalises training examples and background knowledge (BK) [Muggleton, 1991; Cropper and Duman\u010di\u0107, 2022].\nTo illustrate ILP, suppose we have BK with the relations succ/2, lt/2, gt/1, int/1, even/1, odd/1 and the following positive (E+) and negative (E\u00af) examples:\nE+ = {f(5), f(7)}\nE = {f(2), f(3), f(4), f(6), f(8), f(9)}\nGiven these inputs, we might want to learn a rule such as:\nr1 = f(A) \u2190 odd(A), gt(A,3), lt(A,8)\nThis rule says that f(A) is true if A is odd, greater than 3, and less than 8.\nA learner searches by testing rules on the examples and using the outcome to guide the search. For instance, suppose a learner tests the rule:\nf(A) \u2190 even(A)\nThis rule is too specific because it does not entail any positive example. Therefore, a learner can ignore its specialisations, such as:\nf(A) \u2190 even(A), gt(A,2)\nSimilarly, suppose a learner tests the rule:\nr2 = f(A) \u2190 odd(A), int(A)\nThis rule is too general because it entails two negative ex-amples (f(3) and f(9)). Therefore, a learner can ignore its generalisations. A learner will not necessarily ignore its spe-cialisations because one could still be helpful, such as:\nr3 = f(A) \u2190 odd(A), int(A), gt(A,3), lt(A,8)\nThis rule entails all the positive and none of the negative examples.\nAlthough seemingly useful, we argue that r2 and r3 are pointless because odd(A) implies int(A), so we can remove int(A) whilst preserving semantics. We call such rules re-ducible rules.\nNow consider the rule:\nf(A) \u2190lt(A,B)\nThis rule entails all the positive and all the negative examples. Therefore, a learner can ignore its generalisations. However, although it entails all the negative examples, we cannot ignore its specialisations as one might still be a good rule, such as r\u20811.\nNow consider the specialisation:\nf(A) \u2190lt(A,10)\nThis rule entails all the positive and negative examples, so a learner can ignore its generalisations. However, unlike the pre-vious rule, a learner can ignore its specialisations. The reason is that the literal lt(A,10) implies all the negative examples, i.e. there is no negative example greater than 10. Moreover, this literal cannot be further specialised (except grounding the variable A and thus being pointless). We call such rules indiscriminate rules.\nIn this paper, we show that ignoring pointless (reducible and indiscriminate) rules allows us to efficiently and soundly prune the hypothesis space and thus improve learning performance. Although existing approaches find reasons why a rule fails on examples, such as having erroneous literals [Muggleton et al., 2015; Cropper and Hocquette, 2024] or rules [Shapiro, 1983; Raghothaman et al., 2020], they do not find reducible or indiscriminate rules. We expand on the novelty in Section 2.\nTo explore our idea, we use the learning from failures (LFF) setting [Cropper and Morel, 2021]. LFF frames the ILP prob-lem as an Answer Set Programming problem (ASP) [Gebser et al., 2012], where each (stable) model to the ASP problem represents a hypothesis. The goal of an LFF learner is to accumulate constraints to restrict the hypothesis space. We build on the LFF system POPPER [Cropper and Morel, 2021;"}, {"title": "2 Related Work", "content": "ILP. Many ILP systems, such as ALEPH [Srinivasan, 2001], use bottom clauses [Muggleton, 1995] or variants, such as Kernel sets [Ray, 2009] to restrict the hypothesis space [Mug-gleton, 1995]. The bottom clause of an example is the most specific clause that entails that example. Building a bottom clause can be expensive [Muggleton, 1995] and, in the worst case, a learner needs to build a bottom clause for every positive example. Moreover, approaches that use bottom clauses strug-gle to learn programs with recursion or predicate invention. By contrast, REDUCER does not use bottom clauses and does not have these limitations.\nRedundancy in ILP. Fonseca et al. [2004] define self-redundant clauses, similar to our definition of a reducible rule (Definition 8). Their definition does not guarantee that all the refinements (specialisations) of a redundant clause are redun-dant. By contrast, we prove that specialisations of a reducible rule are reducible (Proposition 1). Moreover, the authors do not propose a way to detect such rules; instead, they expect users to provide information about them. By contrast, we introduce REDUCER, which automatically finds reducible and indiscriminate rules. Raedt and Ramon [2004] check whether a rule has a redundant atom before testing it on examples. If so, it avoids the coverage check. This approach requires anti-monotonic constraints, where if a constraint holds for a rule then it holds for all its generalisations, but not necessarily its specialisations. By contrast, we find properties which allow us to prune specialisations of a rule. Moreover, the approach of Raedt and Ramon [2004] does not explicitly identify implica-tions between literals and thus could keep building rules with the same implied literals. By contrast, REDUCER explicitly finds implications between literals to prune the hypothesis space. Zeng et al. [2014] prune rules with simple forms of syntactic redundancy. For instance, for the rule h(X) \u2190 p(X,Y), p(X,Z), the authors detect that p(X,Z) is duplicate to the literal p(X, Y) under the renaming Z \u2192 Y, where Z and Y are not in other literals. By contrast, we detect semantic redundancy by finding reducible and indiscriminate rules. Srinivasan and Kothari [2005] introduce methods to reduce the dimension-ality of bottom clauses using statistical methods to compress bottom clauses. As the authors state, the resulting lower di-mensional space translates directly to a smaller hypothesis space. We differ by not using bottom clauses.\nRule selection. Many recent systems formulate the ILP problem as a rule selection problem [Corapi et al., 2011; Kaminski et al., 2019; Raghothaman et al., 2020; Bembenek et al., 2023; Law, 2023]. These approaches precompute every possible rule in the hypothesis space and then search for a sub-set that generalises the examples. Because they precompute all possible rules, they cannot learn rules with many literals. Moreover, because they precompute all possible rules, they can build pointless rules. For instance, if allowed to use the relations int/1 and even/l, ILASP4 [Law, 2023] will precom-pute all possible rules with int(A) and even(A) in the body. By contrast, REDUCER does not precompute all rules and instead builds constraints from pointless rules to restrict the genera-tion of rules. For instance, if REDUCER sees a rule with int(A) even(A), it will identify that even(A) implies int(A) and will henceforth never build a rule with both literals.\nConstraints. Many recent ILP systems frame the ILP prob-lem as a constraint satisfaction problem [Corapi et al., 2011; Ahlgren and Yuen, 2013; Sch\u00fcller and Benz, 2018; Kaminski et al., 2019; Bembenek et al., 2023]. MUSPER [Cropper and Hocquette, 2024] finds minimal unsatisfiable sub-hypotheses, i.e. sub-hypotheses that can never be true, and builds con-straints from them to prune the hypothesis space. For instance, given the rule f(A) \u2190 succ(A,B),odd(B),even(B), MUSPER can identify that a number cannot be both odd and even, i.e. that odd(B) and even(B) form an unsatisfiable core, and then prunes the hypothesis space accordingly. By contrast, RE-DUCER finds pointless rules, which are rules with redundancy.\nRule induction. ILP approaches induce rules from data, similar to rule learning methods [F\u00fcrnkranz and Kliegr, 2015]. It is difficult to compare ILP methods with recent rule min-ing techniques, such as AMIE+ [Gal\u00e1rraga et al., 2015] and RDFRules [Zeman et al., 2021]. Most rule-mining methods are limited to unary and binary relations and require facts as input. Additionally, they typically operate under an open-world assumption. By contrast, REDUCER operates under a closed-world assumption, supports relations of any arity, and can learn from definite programs as background knowledge.\nRedundancy in AI. Preprocessing techniques for elimi-nating redundancies have received much attention from the theorem-proving community. Early investigations in this area include [Hoder et al., 2012] and [Khasidashvili and Korovin, 2016], and recent investigations include [Vukmirovic et al., 2023]. In the SAT community, redundancy elimination tech-niques, such as blocked clause elimination [Kullmann, 1999], play an integral role in modern solvers. There is even a"}, {"title": "3 Problem Setting", "content": "We assume familiarity with logic programming [Lloyd, 2012] but have included summaries in the supplementary material. For clarity, we define some key terms. A ruler is a definite clause of the form $h\u2190 P_1,..., P_n$ where $h, P_1,..., P_n$ are literals, $head(r) = h$, and $body(r) = \\{P_1,...,P_n\\}$. We denote the set of variables in a literal l as $vars(l)$. The variables of a ruler, denoted $vars(r)$, is defined as $vars(head(r)) \\cup \\bigcup_{p\\in body(r)} vars(p)$. Given a rule r and a set of positive literals C, by r UC we denote the rule r' such that $head(r) = head(r')$ and $body(r') = body(r) \\cup C$. A specialisation of a rule r is any rule r' that is 0-subsumptively (See [Plotkin, 1971] and the Appendix) more specific than r. In this work, we focus on a restricted form of 0-subsumption, which only considers whether the bodies of two rules with the same head literal are contained in one another. We formally define this restriction through a subrule relation:\nDefinition 1 (Subrule). Let $r_1$ and $r_2$ be rules. Then $r_1$ is a subrule of $r_2$, denoted $r_1 \\subseteq r_2$, if $head(r_1) = head(r_2)$ and $body(r_1) \\subseteq body(r_2)$.\nWe generalise the subrule relation to a sub-hypothesis relation. Unlike the subrule relation, the sub-hypothesis relation is not a restriction of 0-subsumption:\nDefinition 2 (Sub-hypothesis). Let $h_1$ and $h_2$ be hypotheses and for all $r_1 \\in h_1$ there exists $r_2 \\in h_2$ such that $r_1 \\subseteq r_2$. Then $h_1$ is a sub-hypothesis of $h_2$, denoted $h_1 \\sqsubseteq h_2$.\nThe sub-hypothesis relation captures a particular type of hy-pothesis we refer to as basic. These are hypotheses for which specific rules do not occur as part of a recursive predicate definition:\nDefinition 3 (Basic). Let h be a hypothesis, $r_1$ a rule in h, and for all $r_2$ in h, the head symbol of $r_1$ does not occur in a body literal of $r_2$. Then $r_1$ is basic in h.\nAs we show in Section 3.2, certain rules allow us to prune hypotheses basic with respect to these rules."}, {"title": "3.1 Inductive Logic Programming", "content": "We formulate our approach in the ILP learning from entailment setting [De Raedt, 2008]. We define an ILP input:\nDefinition 4 (ILP input). An ILP input is a tuple (E, B,H) where E = (E+, E\u2212) is a pair of sets of ground atoms de-noting positive (E+) and negative (E\u2212) examples, B is back-ground knowledge, and H is a hypothesis space, i.e., a set of possible hypotheses.\nWe restrict hypotheses and background knowledge to definite programs with the least Herbrand model semantics.\nWe define a cost function:"}, {"title": "Definition 5 (Cost function).", "content": "Given an ILP input (E, B,H), a cost function $cost_{E,B} : H \u2192 \\mathbb{N}$ assigns a numerical cost to each hypothesis in H.\nGiven an ILP input and a cost function $cost_{E,B}$, we define an optimal hypothesis:\nDefinition 6 (Optimal hypothesis). Given an ILP input (E, B, H) and a cost function $cost_{E,B}$, a hypothesis $h \\in H$ is optimal with respect to $cost_{E,B}$ when $\\forall h' \\in H$, $cost_{E,B}(h) \u2264 cost_{E,B}(h')$.\nWe use a cost function that first minimises the number of misclassified training examples and then minimises the num-ber of literals in a hypothesis. Given a hypothesis h, a true positive is a positive example entailed by hU B. A true neg-ative is a negative example not entailed by hU B. A false positive is a negative example entailed by hUB. A false negative is a positive example not entailed by hUB. We denote the number of false positives and false negatives of h as $fp_{E,B}(h)$ and $fn_{E,B}(h)$ respectively. We consider a func-tion size: $H \u2192 \\mathbb{N}$, which evaluates the size of a hypothesis $h \\in H$ as the number of literals in it. Formally, we use this cost function:\n$cost_{E,B}(h) = (fp_{E,B}(h) + fn_{E,B}(h), size(h))$"}, {"title": "3.2 Pointless Rules", "content": "We want to find pointless rules, i.e., rules that cannot be in an optimal hypothesis. We focus on reducible and indiscriminate rules.\nA reducible rule contains a body literal that is implied by other body literals. For example, consider the rules:\nr1 = h \u2190 odd(A), int(A)\nr2 = h \u2190 odd(A)\nThe rule r\u2081 is reducible because odd(A) implies int(A). Therefore, r\u2081 is logically equivalent r\u2082.\nAs a second example, consider the rule:\nh\u2190 gt(A,B), gt(B,C), gt(A,C)\nThis rule is reducible because the relation gt/2 is transitive, i.e. gt(A,B) and gt(B,C) imply gt(A,C).\nBecause a reducible rule contains a redundant literal, a reducible rule cannot be in an optimal hypothesis. However, a specialisation of a reducible rule could be in an optimal hypothesis. For instance, consider the rule:\nr1 = h \u2190 member(L,X), member(L,Y)\nIn this rule, member(L,X) implies member(L, Y) and vice-versa, so one of the literals is redundant. However, we could still specialise this rule as:\nr2 = h \u2190 member(L,X), member(L,Y), X>Y\nRules r\u2081 and r2 are not logically equivalent, and r2 could be in an optimal hypothesis.\nA key contribution of this paper is to identify reducible rules where we can prune all their specialisations. The idea is to identify a redundant captured literal. A captured literal is one where all of its variables appear elsewhere in the rule. For instance, consider the rule:\nh\u2190 succ(A,B), succ(B,C), gt(C,A), gt(C,D)"}, {"title": "Definition 7 (Captured literal).", "content": "Let r be a rule, $l \\in body(r)$, and $vars(l) \\subseteq vars(body(r) \\backslash \\{1\\}) \\cup vars(head(r))$. Then l is r-captured.\nIf a literal is captured in a rule, then it is captured in its spe-cialisations:\nLemma 1. Let $r_1$ be a rule, $r_2 \\subseteq r_1$, $l \\in body(r_2)$, and l be $r_2$-captured. Then l is $r_1$-captured.\nProof. Follows from Definition 1 as the subrule relation pre-serves variable occurrence.\nWe define a reducible rule:\nDefinition 8 (Reducible). Let r be a rule, B be BK, l body(r) be r-captured, and $\\mathbb{B} = r \\leftrightarrow r \\backslash \\{1\\}$. Then r is reducible.\nSome specialisations of a reducible rule are reducible:\nProposition 1 (Reducible specialisations). Let B be BK, r1 be a reducible rule, and $r_1 \\sqsubseteq r_2$. Then r2 is reducible.\nProof. Let l be an $r_1$-captured literal and $\\mathbb{B} = r_1 \\leftrightarrow (r_1\\backslash\\{1\\})$. By Lemma 1, l is also $r_2$-captured. Let $C = body(r_2) \\backslash body(r_1)$. Then $\\mathbb{B} = (r_1 \\cup C) \\leftrightarrow ((r_1 \\cup C) \\backslash \\{l\\})$. Finally, since $r_2 = (r_1\\cup C)$, we can deduce $\\mathbb{B} = r_2 \\leftrightarrow (r_2\\backslash\\{1\\})$.\nCertain hypotheses that contain a sub-hypothesis with re-ducible rules are not optimal:\nProposition 2 (Reducible soundness). Let B be BK, h1 be a hypothesis, $h_2 \\subseteq h_1$, $r_1$ be basic rule in $h_1$, $r_2 \\in h_2$, $r_2 \\subseteq r_1$, and $r_2$ be reducible with respect to $\\mathbb{B}$. Then $h_1$ is not optimal.\nProof. By Proposition 1, $r_1$ is also reducible implying that there exists a rule $r_3 \\subset r_1$ such that (i) $\\mathbb{B} = r_1 + r_3$ and (ii) $|r_3|<|r_1|$. Let $h_3 = (h_1\\backslash\\{r_1\\})\\cup\\{r_3\\}$. Then $cost_{E,B}(h_3) < cost_{E,B}(h_1)$, i.e. $h_1$ is not optimal.\nThis proposition implies that if we find a reducible rule, we can ignore hypotheses that include this rule or its specialisations. We now introduce indiscriminate rules. To motivate them, consider the rule:\nf(A) \u2190 odd(A), lt(A,10)\nThis rule is not reducible because odd(A) does not imply lt(A,10), nor does lt(A,10) imply odd(A). However, suppose we have the negative examples $E^\u2212 = \\{f(1), f(2), f(3)\\}$. For these examples, the literal lt(A,10) implies all the negative examples. In other words, there is no negative example greater than 10. Therefore, this literal, and thus this rule, is pointless because it cannot discriminate against the negative examples. We formalise this notion of an indiscriminate rule:\nDefinition 9 (Indiscriminate). Let r be a rule, $\\mathbb{B}$ be BK, E- be negative examples with the same predicate symbol as the head of r, $l \\in body(r)$ be r-captured, and for all e $\\in E^\u2212$, $\\mathbb{B} = (r \u2192 e) \\leftrightarrow (r \\backslash \\{l\\} \u2192 e)$. Then r is indiscriminate."}, {"title": "Proposition 3 (Indiscriminate specialisations).", "content": "Let $\\mathbb{B}$ be BK, r1 be an indiscriminate rule, $r_1 \\subseteq r_2$, and E be negative examples with the same predicate symbol as the head of r1. Then r2 is indiscriminate.\nProof. Let l be an r\u2081-captured literal and for all e \u2208 \u0415\u2212, $\\mathbb{B} = (r_1 \u2192 e) \\leftrightarrow (r_1 \\backslash \\{1\\} \u2192 e)$. By Lemma 1, l is also r2-captured. Let $C = body(r_2) \\backslash body(r_1)$. We can deduce the following for all e \u2208 \u0415\u2212:\n$\\mathbb{B} = eq(r_1, e) \u2192 eq(r_1 \\cup C, e)$\nwhere $eq(r', e) = (r' \u2192 e) \\leftrightarrow (r' \\backslash \\{1\\} \u2192 e)$. Since $r_2 = (r_1 \\cup C)$ then for all e \u2208 E\u2212, $\\mathbb{B} = (r_2 \u2192 e) \\leftrightarrow (r_2 \\backslash \\{1\\} \u2192 e)$.\nAs with reducible rules, some hypotheses with an indiscrimi-nate rule are not optimal:\nProposition 4 (Indiscriminate soundness). Let $\\mathbb{B}$ be BK, E be negative examples, h\u2081 be a hypothesis, r\u2081 be a basic rule in h1, $h_2 \\subseteq h_1$, $r_2 \\in h_2$, $r_2 \\subseteq r_1$, and r2 be indiscrimi-nate with respect to $\\mathbb{B}$ and E\u2212. Then h\u2081 is not optimal.\nProof. By Proposition 3, r\u2081 is also reducible implying that there exists a rule $r_3 \\subset r_1$ such that (i) for all e \u2208 \u0415\u2212, $\\mathbb{B} = (r_1 \u2192 e) \\leftrightarrow (r_3 \u2192 e)$ and (ii) $|r_3| < |r_1|$. Let $h_3 = (h_1 \\backslash \\{r_1\\}) \\cup \\{r_3\\}$. Then $cost_{E,\\mathbb{B}}(h_3) < cost_{E,\\mathbb{B}}(h_1)$, i.e. h\u2081 is not optimal."}, {"title": "Definition 10 (Pointless).", "content": "Let (E, $\\mathbb{B}$, H) be ILP input. A hypothesis h \u2208 H is pointless if there exists r \u2208 h such that r is:\n\u2022 reducible with respect to $\\mathbb{B}$ or\n\u2022 indiscriminate with respect to $\\mathbb{B}$ and E-\nCorollary 1. A pointless hypothesis is not optimal.\nIn Section 4, we introduce REDUCER, which identifies point-less rules and prunes them from the hypothesis space."}, {"title": "4 Algorithm", "content": "We now describe our REDUCER approach. We first describe POPPER, which REDUCER builds on.\nPOPPER. POPPER [Cropper and Morel, 2021; Hocquette et al., 2024] is an ILP system. POPPER takes as input background knowledge (bk), positive (pos) and negative (neg) training ex-amples, and a maximum hypothesis size (max_size). POPPER uses a generate, test, and constrain loop to find an optimal hypothesis (Definition 6). POPPER starts with an ASP pro-gram P. The (stable) models of P correspond to hypotheses (definite programs) and represent the hypothesis space. In the generate stage, POPPER uses an ASP solver to find a model of P. If there is no model, POPPER increments the hypothesis size and loops again. If there is a model, POPPER converts it to a hypothesis h. In the test stage, POPPER uses Prolog to test h on the training examples. If h is better (according to a cost"}, {"title": "Algorithm 2 Finding pointless rules.", "content": "1 def pointless(h, neg, bk):\n2 for rule in h:\n3 if not basic(rule, h):\n4 continue\n5 head, body = rule\n6 for literal in body:\n7 body' = body-literal\n8 if not captured (head, body', literal):\n9 continue\n10 if reducible(bk, body', literal):\n11 return true\n12 if indiscriminate(bk, neg, rule, head, body'):\n13 return true\n14 return false\n15\n16 def reducible(bk, neg, body', literal):\n17 rule' = (1, body' \\cup \\{literal\\})\n18 return unsat (bk, rule')\n19\n20 def indiscriminate (bk, neg, rule, head, body'):\n21 rule' = (head, body')\n22 s1 = neg_covered(bk, neg, rule)\n23 s2 = neg_covered(bk, neg, rule')\n24 return s1 == s2"}, {"title": "Correctness", "content": "We show that REDUCER is correct:\nTheorem 1 (REDUCER correctness). REDUCER returns an optimal hypothesis if one exists.\nProof. Cropper and Morel [2021] show that given optimally sound constraints POPPER returns an optimal hypothesis if one exists (Theorem 1). REDUCER builds on POPPER by pruning pointless (one with a reducible or indiscriminate rule) hypotheses. By Corollary 1, a pointless hypothesis is not opti-mal. Therefore, REDUCER never prunes an optimal hypothesis so returns one if it exists."}, {"title": "5 Experiments", "content": "We claim that identifying pointless rules allows us to soundly and efficiently prune the hypothesis space, which can improve learning performance. To test this claim, our experiments aim to answer the question:\nQ1 Can identifying pointless rules reduce learning times whilst maintaining predictive accuracies?\nTo answer Q1, we compare the performance of REDUCER against POPPER. As REDUCER builds on POPPER, the only experimental difference between the systems is the ability to identify pointless rules and build constraints from them to prune the hypothesis space. Therefore, this comparison directly tests our claim.\nChecking whether a rule is reducible or indiscriminate re-quires testing hypotheses on the BK and examples and thus incurs an overhead cost. To understand the cost of identifying pointless rules, our experiments aim to answer the question:"}, {"title": "Q2 What is the overhead of identifying pointless rules?", "content": "Comparing REDUCER against other systems besides POPPER will not allow us to evaluate the idea of identifying pointless rules because it will not allow us to identify the source of empirical gains. However, many people expect comparisons against other systems. Therefore, our experiments try to an-swer the question:\nQ3 How does REDUCER compare to other approaches?\nTo answer Q3, we compare REDUCER against POPPER, ALEPH [Srinivasan, 2001], and ASPSYNTH [Bembenek et al., 2023]."}, {"title": "5.1 Domains", "content": "We use the following domains.\n1D-ARC. This dataset [Xu et al., 2023] contains visual rea-soning tasks inspired by the abstract reasoning corpus [Chollet, 2019].\nAlzheimer. These real-world tasks involve learning rules describing four properties desirable for drug design against Alzheimer's disease [King et al., 1995].\nIGGP. In inductive general game playing (IGGP) [Cropper et al., 2020], the task is to induce rules from game traces from the general game playing competition [Genesereth and Bj\u00f6rnsson, 2013].\nIMDB. We use a real-world dataset which contains relations between movies, actors, and directors [Mihalkova et al., 2007].\nList functions. The goal of each task in this dataset is to identify a function that maps input lists to output lists, where list elements are natural numbers [Rule et al., 2024].\nTrains. The goal is to find a hypothesis that distinguishes east and west trains [Larson and Michalski, 1977].\nZendo. Zendo is a multiplayer game where players must discover a secret rule by building structures."}, {"title": "5.2 Setup", "content": "In all experiments, we measure the mean predictive accuracy, termination times, and the time taken to discover pointless rules, i.e. the overhead of our approach. We use a 3.8 GHz 8-Core Intel Core i7 and a single CPU to run the experiments. For Q1 and Q2 we use a timeout of 60 minutes per task. We repeat the experiment twice.\nFor Q3, we use a timeout of 10 minutes per task. We repeat the experiment thrice. We set all the systems to use similar biases. However, it is difficult to compare against ASPSYNTH. As with other rule selection approaches (Section 2), ASPSYNTH precomputes all possible rules of a certain size and then uses an ASP solver to find a subset. It is infeasible to precompute all possible rules, so we set the maximum rule size to 4. For ALEPH, we use it with its default settings, but there will likely be different settings that improve the performance of ALEPH."}, {"title": "5.3 Results", "content": "Q1. Can identifying pointless rules reduce learning times whilst maintaining predictive accuracies?\nFigure 2 shows the reduction in learning times of REDUCER vs POPPER. In other words, Figure 2 shows how much learn-ing time ignoring pointless rules saves. Figure 2 shows that REDUCER consistently and drastically reduces learning times. REDUCER reduces learning times on 131/419 tasks by a mean of 24 minutes. These improvements are lower bounds: POP-PER often times out after 60 minutes and likely needs much more time to terminate. REDUCER increases learning times on 13/419 tasks by a mean of 160 seconds."}, {"title": "Figure 2: Learning time improvement of REDUCER compared to", "content": "POPPER. In other words, this plot shows the learning time improve-ment when ignoring pointless rules. The tasks are ordered by the learning time improvement. For legibility, we only show tasks where the learning times differ by more than 1 second."}, {"title": "Figure 3 shows the improvement in predictive accuracy", "content": "of REDUCER vs POPPER. In other words, Figure 3 shows the predictive accuracy improvement when ignoring pointless rules. The results show that REDUCER can drastically improve predictive accuracies. Although both systems are guaranteed to learn optimal hypotheses, they are not guaranteed to find them given the time limit. The reason REDUCER often im-proves accuracy is that it finds a good hypothesis quicker than POPPER.\nREDUCER can drastically improve learning performance. For instance, consider the 1D-ARC task mirror, shown in Figure 1. For this task, REDUCER learns a hypothesis with 100% predictive accuracy and terminates in 101 seconds. By contrast, POPPER learns a hypothesis with only 60% accuracy and timeouts after 60 minutes. In other words, on this task, ignoring pointless rules reduces learning times by at least 97% and improves predictive accuracy by 40%. A reducible rule that REDUCER finds on this task is:\nout(E,A,B) \u2190 succ(A,B), lt(C,A), lt(C,B)\nThis rule is reducible because if B is the successor A and C is smaller than A then C must be smaller than B. When"}, {"title": "REDUCER identifies that this rule is pointless, it builds a con", "content": "straint to prune all specialisations (supersets) from the hypoth-esis space.\nAs a second example, in the IGGP dataset, one of the tasks is to learn a set of rules to describe a legal move in the eight puzzle game. For this task, both REDUCER and POPPER learn hypotheses with 100% accuracy. However, whereas POPPER does not terminate (prove optimality) within 60 minutes, RE-DUCER terminates (proves optimality) after only 10 seconds, a 99% improvement. A reducible rule that REDUCER finds is:\nlegal move(A,B,C,D) \u2190 succ(D,E), pos1(D), pos2(E)\nThis rule is reducible because the posi relations denote posi-tions in the game board, where posi precedes posi+1. There-fore, if pos1(D) is true and E is the successor of D then pos2(E) must be true, and this literal is therefore redundant. Three indiscriminate rules that REDUCER finds are:\nlegal move(A,B,C,D) \u2190 role(B)\nlegal move(A,B,C,D) \u2190 index(C)\nlegal_move(A,B,C,D) \u2190 index(D)\nThese rules are indiscriminate because role(B), index(C), and index(D) are true for every negative example and thus are redundant in the rule.\nThere is one noticeable exception (the rightmost bar) in Figure 2 where REDUCER is substantially worse than POP-PER (2160 seconds vs 86 seconds). This task is pilgrimage-legal_place_pilgrim from the IGGP dataset, where the mean overhead was 185s."}, {"title": "Q2. What is the overhead of finding pointless rules?", "content": "Figure 4 shows the ratio of learning time spent finding point-less rules. The mean overhead is 2%. The maximum is 80%. The overhead is less than 10% on 85% of the tasks. Therefore, the results in this section show that the answer to Q2 is that the overhead of identifying pointless is typically small (<10%).\nQ3. How Does REDUCER compare to other approaches?Table 1 shows the predictive"}]}