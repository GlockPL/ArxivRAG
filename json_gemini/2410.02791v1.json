{"title": "DifFaiRec: Generative Fair Recommender with Conditional Diffusion Model", "authors": ["Zhenhao Jiang", "Jicong Fan"], "abstract": "Although recommenders can ship items to users automatically based on the users' preferences, they often cause unfairness to groups or individuals. For instance, when users can be divided into two groups according to a sensitive social attribute and there is a significant difference in terms of activity between the two groups, the learned recommendation algorithm will result in a recommendation gap between the two groups, which causes group unfairness. In this work, we propose a novel recommendation algorithm named Diffusion-based Fair Recommender (DifFaiRec) to provide fair recommendations. DifFaiRec is built upon the conditional diffusion model and hence has a strong ability to learn the distribution of user preferences from their ratings on items and is able to generate diverse recommendations effectively. To guarantee fairness, we design a counterfactual module to reduce the model sensitivity to protected attributes and provide mathematical explanations. The experiments on benchmark datasets demonstrate the superiority of DifFaiRec over competitive baselines.", "sections": [{"title": "I. INTRODUCTION", "content": "Recommendation algorithms can improve the efficiency of interactions between users and items, have wide applications in e-commerce and social media platforms [11, 12, 34, 55, 56], and have been changing our life and habits explicitly or implicitly. However, recommenders can lead to unfairness about sensitive social attributes such as gender and age, which requires us to face with caution [2, 14]. Recently, research on the fairness of recommendation algorithms has attracted the attention of many scholars [2, 13, 35] and a few fair recommendation algorithms have been proposed.\nUnlike traditional Click-Through Rate (CTR) prediction rec-ommendation algorithms, generative recommendation, often based on deep generative models, directly gives the estimated list of the entire set of candidate products using the learned interaction distribution [26, 33, 44, 51]. This list-wise gener-ation is more likely to give a recommendation list that the user prefers and perceive the interaction information between users and items and that among items in the candidate set, which makes generative recommender achieve a remarkable success [8, 26]. Classical deep generative models include variational autoencoder [24], flow-based generative model [18], and generative adversarial networks [16], etc. Compared to these classical models, recently, diffusion models [39] have shown astonishing generative ability and achieved state-of-the-art results in image generation [6, 41]. This motivated several diffusion model based recommendation algorithms [9, 29, 45].\nIn addition, the existing fair recommenders have at least two optimization objectives [3, 15, 36], namely fairness and accuracy. However, it is difficult to find Pareto optimality [52] for multi-objective optimization problems, and the trade-off between accuracy and fairness is hard to balance. This greatly limits the application of fair recommenders. Fortunately, we find that diffusion models provide a possible solution to this issue. We can employ Bayesian ideology to compress objectives of fairness and accuracy into one. In this way, we can only focus on one optimization goal, reducing the difficulty of optimization.\nIn this work, we propose a diffusion-based fair recom-mender (DifFaiRec) for group-fair recommendations. Dif-FaiRec contains two modules. The first one is a counterfactual module that maps each user to its different group to obtain a counterfactual user, which is to ensure group fairness. The second module is a conditional diffusion model that is conditioned on the counterfactual module, reconstructs the observed interactions, and predicts the unknown interactions in a generative manner. Our contributions are as follows.\nWe propose a novel fair recommendation algorithm Dif-FaiRec. It is the first diffusion model based fair recom-mender.\nWe design a novel fairness strategy. It is built on counter-factual samples and can force the recommender to give fair recommendations.\nWe compress the two objectives (accuracy and fairness) into one and provide a mathematical analysis of why this method works.\nExperiments on two real datasets show that our DifFaiRec is both accurate and fair and outperforms various baselines."}, {"title": "II. RELATED WORKS", "content": "A. Group Fairness in Recommendation\nThe fairness of recommendation systems can be divided into many domains according to different views such as individual vs group, user vs item, and so on [46]. Here, we focus on group fairness, which holds that recommenda-tion performance should be fair among different groups. For fairness in recommendation, the groups of users are often defined according to basic social attributes like gender, age, and career. [10] first evaluated the response of collaborative filtering algorithms to attributes of social concern, namely gender on publicly available book ratings data. [13] formalized the fairness problem as a 0\u20131 integer programming problem and invoked a heuristic solver to compute feasible solutions. [21] proposed a neural fair collaborative filtering method that considers gender bias in recommending career-related items using a pre-training and fine-tuning framework. [27] designed two auto-encoders for users and items working as adversaries to the process of minimizing the rating prediction error. They enforced that the specific unique properties of all users and items are sufficiently well incorporated and preserved in the learned representations to provide fair recommendations.\nThere are a few studies that explore the issue of group fairness from a very different perspective. [28] found that the level of activity of users could also cause unfairness. They provided a re-ranking approach under fairness metric based constraints to address this unfairness problem. [43] studied a special issue on underrepresented market segments. For example, a male user who would potentially like one product may be less likely to interact with them if it is using a 'female' image. [2] designed a novel metric based on pairwise comparisons to maintain fairness in the rankings given by the recommender. [35] formulated their method as a multi-objective optimization problem and considered the trade-offs between equal opportunity and recommendation quality.\nDifferent from the existing research on group fairness in recommendation, our method relaxes the fairness and ac-curacy objectives into one by using the characteristics of the diffusion model and the Bayesian ideology, that is, the fairness recommendation task is transformed from the existing multi-objective optimization problem to the single-objective optimization problem, which reduces the difficulty of solving.\nB. Generative Recommender\nGenerative recommenders are usually based on deep gen-erative models such as variational auto-encoder (VAE) [54], generative adversarial network (GAN) [16], and diffusion models [19, 39].\nVAE consists of two parts: an encoder and a decoder. The encoder outputs the parameters of the latent distribution, such as mean and variance. The decoder takes a sample from the latent distribution and gives a reconstruction of input data [7]. [53] introduced a cross-domain recommendation based on VAE. It extracts information from within-domain and cross-domain and stresses user preference in specific domains. [50] designed a VAE model with adversarial and contrastive learning for sequential recommendations. The model can learn more personalized and significant attributes.\nGAN consists of a generator and a discriminator, and is trained in an adversarial way [22]. [26] presented a fairness-aware GAN for a recommendation system with implicit feed-back. [49] proposed a novel GAN-based recommender to give a set of diverse and relevant items with a designed kernel matrix that considers both co-occurrence of diverse items and personal preference.\nSimilar to VAE and GAN, diffusion models [19, 39], to be detailed in the next section, are also applicable and useful in recommendation systems [9, 29, 45]. For instance, [45] proposed a diffusion recommender model that learns the generative process in a denoising manner and has improved performance on several benchmark datasets. It is worth noting that [9, 29, 45] do not address the fairness problem in recommendation systems.\nLarge language model (LLM)-based recommendation sys-tems have become a hot topic recently. [31] proposed a ChatGPt-based recommendation system that uses ChatGPT to make recommendations based on a user's historical behavior by designing a special prompt. This paper explores the perfor-mance of large language models on recommendation systems. [5] proposed the opportunities and challenges that the LLM-based recommendation system can encounter, and provides a broad idea for researchers. [17] proposed a zero-shot LLM-based conversation recommender, which can improve user retention and extract user interest more accurately.\nDifferent from the existing generative recommenders, our method is based on the conditional diffusion model combining the counterfactual module to achieve a fair and accurate recommendation system. In addition, we give a mathematical explanation for the proposed method, which increases the interpretability of the model."}, {"title": "III. PRELIMINARY", "content": "Diffusion models (DMs) [39] have recently attracted great attention in the fields of image and speech generation. Im-portantly, prompt-guided generation with conditional diffusion has fully demonstrated the controllability and flexibility of DMs. In this section, we briefly introduce the forward process, reverse process, training, and sampling of DMs [19, 25].\nForward process The forward process takes an input sample xo that follows the distribution q(x0) and creates the latent samples x1,...,xT by adding Gaussian noises step by step for T times forming a Markov process [19]:\n$q(x_t|x_{t-1}) := \\mathcal{N}(x_t; \\sqrt{1 - \\beta_t}x_{t-1}, \\beta_tI)$,\nwhere $t \\in \\{1, ..., T\\}$ is the diffusion step, $\\beta_t$ is the variance, and $I$ is an identity matrix.\nReverse process The reverse process is a denoising process starting at $p(x_T) = \\mathcal{N}(x_T;0,I)$ [20]. It aims to recover xo from xT according to\n$p_{\\theta}(x_{t-1}|x_{t}) := \\mathcal{N}(x_{t-1}; \\mu_{\\theta}(x_t, t), \\Sigma_{\\theta}(x_t, t))$,\nwhere $\\mu_{\\theta}(x_t,t)$ and $\\Sigma_{\\theta}(x_t,t)$ are mean and covariance of Gaussian inferred by a network parameterized by $\\theta$.\nTraining The objective of DM is to optimize the variational bound on negative log-likelihood [19]:\n$\\mathbb{E}[-\\log (p_{\\theta}(x_0))] \\le \\mathbb{E}_q \\Big[-\\log \\big(\\frac{p_{\\theta}(x_{0:T})}{q(x_{0:T})}\\big) \\Big] = \\mathbb{E}_q \\Big[-\\log (p(x_T)) - \\sum_{t=1}^T \\log \\big(\\frac{p_{\\theta}(x_{t-1}|x_t)}{q(x_t|x_{t-1})}\\big) \\Big]$"}, {"title": "IV. FAIR DIFFUSION RECOMMENDER", "content": "To take advantage of the generating ability and flexibility of the conditional diffusion model to address group unfairness, we design DifFaiRec that contains three components: 1) group vector builder; 2) counterfactual module; 3) diffusion model.\nA. Problem and Model Formulation\nHere, we state the problem of optimal ranking under group fairness constraint. We use Im and Un to denote the sets of m items and n users respectively. For Im and Un, there is an interaction matrix denoted by $R = [r_1, r_2, . . .,r_n] \\in \\mathbb{R}^{m\\times n}$, where $r_j$ denotes the j-th column of R and $r_{ij}$ is the rating given by user j on item i. $r_{ij} = 0$ means there is no interaction between user j and item i. For convenience, we use a mask matrix $M \\in \\{0,1\\}^{m\\times n}$ to denote whether the ratings in R are missing or not. We would like to construct an algorithm A that learns a prediction model $f_a$ from R that is able to predict the unknown ratings accurately, namely, the following test error is sufficiently small:\n$E_{test} := \\frac{1}{mn} \\sum_{(i,j):M_{ij}=0} M_{ij} \\sum_j [l ([f_a(R)]_{ij}, r_{ij})]$,\nwhere $r^*_{ij}$ denotes the ground-truth rating, $l$ denotes a loss function such as the square loss, and $f_a$ is conducted on R column-wisely, i.e., $f_a(R) = [f_a(r_1),..., f_a(r_n)]$. Note that $E_{test}$ is related to the training error and the complexity of $f_a$ Suppose the users are divided into two groups, denoted as A and B, according to a sensitive attribute $s \\in \\{0,1\\}$ such as gender. We hope the prediction $v$ given by $f_a$ is fair for A and B, i.e., the following prediction bias is sufficiently small:\n$\\delta := |P (f_a(r) = v | s = 0) - P (f_a(r) = v | s = 1)|$.\nSimultaneously obtaining small $E_{test}$ and $\\delta$ is difficult and there usually exists a trade-off between them. Moreover, achieving small $\\delta$ is a challenging task because one has to estimate the probability in a high-dimensional space.\nWe achieve small $E_{test}$ and $\\delta$ using a diffusion model conditioned on group vectors in a counterfactual manner. Let\n$g(z) = f_a(r)$,\nwhere z is some intermediate variable related to r. z can be regarded as a feature representation vector of a user. Thus, the predicted ratings are given by $v = g(z)$. If z is independent from s, then v is independent from s, which means $\\delta = 0$. To approximately achieve such a z, we use a counterfactual method. The idea is as follows:\nWe represent groups A and B as two vectors a and b respectively.\nGiven a user $j \\in A$, we generate $z' = C(z_j, b)$, where C is a counterfactual module. This $z'$ corresponds to a counterfactual user in group B. Similarly, if $j \\in B$, we let $z'_j = C(z_j, a)$.\nThe above construction means for a counterfactual user, s = 0 and s = 1 hold simultaneously. Thus, the value of s has no (ideally) impact on $z'$, which means $z'$ is independent (ideally) from s.\nThe prediction is then based on $g(z')$ rather than $g(z)$:\n$v = f_a(r) = g(z') = g(C(z, y))$,\nwhere $y \\in \\{a, b\\}$. Therefore, the prediction is fair to the two groups A and B.\nFairness requires the model to give a similar prediction for the same user under different conditions. We can turn the require-ment into an equivalent. If condition A becomes condition B for the same user, but nothing else is changed, the user becomes a counterfactual user. At this point, if the model's predicted rating for the counterfactual user remains the same, the requirement is satisfied. Further, if we directly input a counterfactual user to fit the interest of the real user, the model will treat both the counterfactual user and the real user alike. Because we made the model think that these two users have the same interests. In this way, we guarantee the requirement of fairness. (9) describes this idea.\nIn the following two sections, we introduce the design of group vectors a and b and the counterfactual module C.\nB. Constructing Group Vectors\nTo achieve group fairness, the first step is to determine the feature space of two groups that is good for us to distinguish the difference between them.\nOne may classify users into two groups according to a sensi-tive attribute such as gender, where the label is a scalar chosen from {-1,1}. However, a scalar contains limited information about the group. Existing strategies often use embedding methods to represent a group as a low-dimensional dense vector [40]. In fact, before conducting recommendations, the sensitive feature has already caused a gap between the ratings of the two groups. In other words, the training data already contains unfairness. Hence, we try two methods, mean pooling and principal component analysis (PCA) [1, 47], to build feature space based on the given ratings. They are able to quantify the gap or unfairness between two groups.\nMean pooling and PCA are operated along the user axis to obtain group vectors a and b. Mean pooling is formulated as:\n$a = \\frac{\\sum_{j \\in A}r_j}{|A|}$, $b = \\frac{\\sum_{j \\in B}r_j}{|B|}$"}, {"title": "C. Counterfactual Module", "content": "Here, we introduce a counterfactual module to keep fairness recommendations. Intuitively, if group fairness is satisfied, then the recommendation system has the same recommenda-tion performance for the two groups. Further, if the sensitive characteristics of each individual in a group changes while the recommendation performance remains unchanged, it indicates that the algorithm is fair that is [28]:\n$f_a(r; s = 0) = f_a(r; s = 1)$,\nwhich is consistent with (7). However, given a user, the sensitive characteristic is fixed, and there is no real user who changes his/her sensitive characteristic. Therefore, we need to create a user who changes it, which is a counterfactual operation.\nA simple method is to find a user who is similar to the user in another group as the research object but it is very difficult to find a one-to-one mapping for each user. Thus, we design a counterfactual module to map users to another group directly. Firstly, group vectors are transformed by a condition encoder:\n$\\tilde{g} = Enc(g)$, $g \\in \\{a,b\\}$,\nwhere Enc can be a multi-layer perception (MLP).\nThen, an attention mechanism is implemented to run the counterfactual operation. Attention can be formulated as fol-lows [42]:\n$Atten(query, key, value) = Softmax \\big(\\frac{q k^T}{\\sqrt{d}}\\big)v$,\nwhere $q = W_q \\cdot query$, $k = W_k \\cdot key$, $v = W_v \\cdot value$, $W_q$, $W_k$, $W_u$ are parameter matrices and d is the dimension of $q k^T$. Here, the group vector is the query and the user vector is used as both key and value. Counterfactual module maps users in group A to group B with the help of attention:\n$z'_j = Atten(\\tilde{g}, z_j, z_j) = C(z_j, y_j)$,\n$y_j = \\begin{cases}\na & \\text{if } j \\in B, \\\\\nb & \\text{if } j \\in A.\\\\\n\\end{cases}$\nThe attention mechanism is able to adaptively mine the under-lying connection between two vectors and output the correla-tion between them (attention score). But this is equivalent to imposing an equal correlation on each dimension of the vector, which is actually unreasonable. This is the reason for adding a condition encoder D in the counterfactual module. The condition encoder can adaptively perform feature crossover, and then use attention to mine the counterfactual mapping relationship among users' ratings for different items."}, {"title": "D. Model Training", "content": "In our algorithm A, the model can predict the noise-matching term, and then denoise the samples via the following closed-form expression [32]:\n$q(x_{t-1}| x_t, x_0) \\propto N(x_{t-1}; \\mu_{\\theta}(x_t, x_0, t, y), \\sigma^2(t)I)$,\nwhere xo is sampled from R, $\\mu_{\\theta}(x_t, x_0, t)$ and $\\sigma^2(t)$ are mean and covariance of $q(x_{t-1}| x_t, x_0)$. $\\sigma^2(t)$ can be expressed as:\n$\\sigma^2(t) = \\tilde{\\beta}_t = \\frac{(1-\\alpha_{t-1})}{(1-\\bar{\\alpha}_t)}, $\nwhere $\\alpha_t = 1 - \\beta_t$ and $\\bar{\\alpha}_t = \\prod_{i=1}^t \\alpha_{\\tau}$. $\\mu$ can be formulated as follows through parameterization:\n$\\mu_{\\theta}(x_t, t,y) = \\frac{1}{\\sqrt{\\alpha_t}} \\Big(x_t - \\frac{(1-\\alpha_t)}{\\sqrt{1-\\bar{\\alpha}_t}} \\epsilon_{\\theta}(x_t, t,y)\\Big)$,\nwhere $\\epsilon_{\\theta}(x_t,t,y)$ is a noise approximator which can be inferred by diffusion model, and y = a or b based on user's group. In this work, as shown in Figure 1, we let\n$\\epsilon_{\\theta}(x_t,t,y) = MLP3 \\big(Atten\\big(MLP2(y), MLP1 (x_t, t), MLP1(x,t)\\big)\\big) = MLP3(C(MLP1(x_t, t), y))$,\nwhere t denotes the embedding vector (one-hot encoding) of time stept and C denotes the counterfactual module. The pa-rameter set $\\Theta$ contains all parameters of MLP1, MLP2, MLP3, and Atten. For convenience, we let G = [g1, g2,..., gn], where $g_j = a$ if $j \\in B$ and $g_j = b$ if $j \\in A$. G is a matrix of counterfactual group vectors. The training process is summarized in Algorithm 1. Once the training is finished, the unobserved interaction can be predicted by sampling from xT iteratively according to the description in Section III. The detailed procedures are summarized in Algorithm 2. Note that the prediction process has some randomness due to the sampling of z, one may run the algorithm multiple times and use the mean or median as the final prediction for each user, though we find that the standard deviation is often tiny."}, {"title": "E. Essential Mathematical Analysis", "content": "Here, we stand on Bayesian thinking to explain why our model works. For the convenience of analysis, we first in-troduce several events. Denote the counterfactual world as Z, where the users are counterfactual users. I denotes rating event"}, {"title": "V. EXPERIMENTS", "content": "A. Experimental Settings\n1) Datasets: We consider two public datasets, MovieLens-1M\u00b9 and LastFM\u00b2, which are widely used to evaluate recom-mendation algorithms.\nMovieLens-1M contains 1 million ratings on 3,900 movies given by 6,040 users. The ratings are made on a 5-star scale and each user has at least 20 ratings. Since this dataset contains the gender and age attributes of the users, we chose these two attributes as the protected attributes. In terms of age, the users are divided into young people and old people by 50.\nLastFM is a dataset of music recommendations. For each user, there is a list of his or her favorite artists along with the number of plays. Here, we take the number of plays as the rating. Since this dataset lacks user information, we divide the users into two groups according to their activity level and interest diversity. Here, a user-artist interaction is defined as the user has listened to the artist's songs. The play is defined as the number of times a user plays an artist's songs and the given tag represents various music styles. The users are grouped as active or inactive users by an activity level boundary of 15,000 plays and are grouped as users with focused or divergent interests by an interest diversity boundary of 300 tags associated with the artists.\n2) Baselines: We compare DifFaiRec with six baselines including two utility-focused baselines and four fairness-focused baselines. The details are as follows.\nMF [37] is a well-known collaborative filtering technique based on matrix factorization. AutoRec [38] is one of the earliest neural network or deep learning based recommenda-tion models. IFGAN [30] is a GAN4Rec model. Different from traditional GANs, this model employs two generators and uses the gradient information between the generator and discriminator to leverage the sampling strategy combining the two generators. One generator is responsible for generating hard negative samples, the other generator is responsible for generating hard sample pairs, and the discriminator is responsible for distinguishing the sample pairs. DiffRec [45] is the first diffusion-based recommender that takes the diffu-sion model as the backbone to generate the user's feedback. ChatGPT4Rec [31] is based on large language models that can transform the recommendation task into a natural language generation by constructing a specific prompt. FairC [4] is an adversarial framework to train filters to get graph embeddings without information about the users' protected attributes. It can enforce fairness based on different combinations of fairness constraints. FairGO [48] presents a combination structure of sub-filters aiming to remove the information of sensitive attributes. The model is trained via an adversarial technique on a user-centric graph. FairGAN [26] was originally proposed for exposure fairness, which, however, can be regarded as group fairness on the item or user side. Thus we compare FairGAN in our experiments.\n3) Evaluation Metrics: We use three popular metrics in-cluding Recall (R@k), Normalized Discounted Cumulative Gain (N@k), Absolute Equality (A@k), and Equal Opportu-nity (E@k), to evaluate all methods considered in this paper. Particularly, A@k and E@k are defined as\n$A@k := |u_A - u_B|$\nwhere $u_A$ and $u_B$ are mean absolute errors (MAEs) for groups A and B.\n$E@k := \\sqrt{e_A} - \\sqrt{e_B}$"}, {"title": "E. Robustness Study for Group Sparsity", "content": "The performance of our model depends on the quality of the group vector, which is also the limitation of our approach. According to the law of large numbers, the sparsity within a group (the number of users in a group) affects the quality of the group vector. Therefore, we conducted experiments on the effect of group sparsity on the model."}, {"title": "VI. CONCLUSION", "content": "This paper proposes a diffusion model based fair recom-mender, called DifFaiRec addressing the fairness issues in rec-ommendations via an attention-based counterfactual module. To keep fairness, two group vector building methodologies are proposed to find the difference between the two groups. The proposed DifFaiRec generates a fair recommendation list considering group fairness on different sensitive features while maintaining user utility as well as possible. In particular, we give a mathematical analysis for our proposed method. Finally, extensive experiments show the advantages of the proposed recommender over the state-of-the-art baselines. In our future work, we are interested in investigating the issues of fairness across both user and item sides, which are vital for recommendations as well."}]}