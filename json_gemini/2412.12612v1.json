{"title": "SynthCypher: A Fully Synthetic Data Generation Framework for Text-to-Cypher Querying in Knowledge Graphs", "authors": ["Aman Tiwari", "Shiva Krishna Reddy Malay", "Vikas Yadav", "Masoud Hashemi", "Sathwik Tejaswi Madhusudhan"], "abstract": "Cypher, the query language for Neo4j graph databases, plays a critical role in enabling graph-based analytics and data exploration. While substantial research has been dedicated to natural language to SQL query generation (Text2SQL), the analogous problem for graph databases referred to as Text2Cypher remains underexplored. In this work, we introduce SynthCypher, a fully synthetic and automated data generation pipeline designed to address this gap. SynthCypher employs a novel LLM-Supervised Generation-Verification framework, ensuring syntactically and semantically correct Cypher queries across diverse domains and query complexities. Using this pipeline, we create SynthCypher Dataset, a large-scale benchmark containing 29.8k Text2Cypher instances. Fine-tuning open-source large language models (LLMs), including LLaMa-3.1-8B, Mistral-7B, and QWEN-7B, on SynthCypher yields significant performance improvements of up to 40% on the Text2Cypher test set and 30% on the SPIDER benchmark adapted for graph databases. This work demonstrates that high-quality synthetic data can effectively advance the state-of-the-art in Text2Cypher tasks.", "sections": [{"title": "1 Introduction", "content": "As the use of graph databases like Neo4j (neo, 2024) grows, converting natural language into Cypher queries (Text2Cypher) is becoming increasingly important. Cypher (Francis et al., 2018), designed for querying and analyzing graph data, is well-suited for applications such as social networks, recommendation systems, and knowledge graphs (Ji et al., 2021). However, generating"}, {"title": "2 Related Work", "content": "Prior works (Liang et al., 2021; Hains et al., 2023) on natural language querying of knowledge graphs using Cypher has mostly focused on traditional NER based extraction approaches which make them both limited in scope, and cumbersome to write. LLMs have shown promising potential for Text2Cypher task where recently, Neo4j Labs published a gpt-4o generated dataset (tom, 2024), initiating first efforts on Text2Cypher data generation. Importantly, this Text2Cypher data without any validation steps on a limited domain set, with only 6 query types on HuggingFace (Wolf et al., 2019) results only in 50% correctly executable cyphers. Concurrent (peer-reviewed unpublished) Synth2C (Zhong et al., 2024) generates Cyphers using Gpt-40 similar to Neo4j Labs as well as a templatized pipeline with traditional NLP techniques and Illm-as-judge to validate generated cypher descriptions against original questions. However, this technique again does not check for execution correctness and is furthermore limited only to Medical domain (with datasets not publicly available)."}, {"title": "3 Data Generation Pipeline", "content": "Synthetic data generation (Xu et al., 2023; Luo et al., 2023; Ouyang et al., 2022) have proven highly effective.We use LLMs such as Llama 3.1 70B (Van Der Maaten et al., 2024), Mixtral 8x22B (Jiang et al., 2024), and GPT-4 (OpenAI, 2023) to automatically generate diverse domains, schemas, natural language queries, and Cypher queries. Our pipeline covers a broad range of domains and query types, ensuring diversity across topics and difficulty. From data generation to validation, all steps are autonomously managed by models and scripts, allowing the process to run at scale. Generated Cypher queries are executed and validated against expected results to ensure quality.\nStep 1: Schema Generation: We begin by random selection of the seed domains (e.g., e-commerce, inventory management) from Neo4j (neo, 2024) example databases. We then use Mixtral to expand these domains to cover 700 distinct domains. A skeleton schema is generated for each domain, outlining the nodes and relationships (Block 1 in Figure 2). These schemas are validated with GPT-4 for correctness and manually reviewed for coherence and real-world utility in 25% of cases. See Appendix B for more details on schema generation.\nStep 2: Natural Language Question and Ground Truth Generation For each schema, we generate questions based on 109 predefined query types, such as \"Simple Retrieval\" or \"Sub-Graph Queries\" (Block 2 in Figure 2). A dummy ground truth answer for each query is also generated. In the next stage, we fill the database with entries including this dummy answer as the right answer for the question. See Appendix C for further details on question generation and query types.\nStep 3: Neo4j Database Population An empty Neo4j database for each question is created which is populated with synthetic data that fits the schema, question, and ground truth. Python-based code, generated by GPT-4, is used to create and populate the database with nodes, relationships, and data, ensuring consistency between the schema and ground truth (Block 3 in Figure 2). To the best of our knowledge, this strategy of filling the database conditioned on a arbitrarily chosen dummy ground"}, {"title": "4 Experimental Setup", "content": "Data Setup : We used our dataset consisting of 25.8k samples spanning 109 query types and 528 schemas (Table 1) for training. The 109 query types in our SynthCypher represent diverse real-world Cypher use cases. For testing, we employed a separate dataset of 4k samples, covering all 109 query types across 165 schemas not included in train. This split ensures that the model is evaluated on a broad range of query complexities and schema variations. As an additional test dataset, we also adapt the popular SPIDER-SQL (Yu et al., 2018) for Text2Cypher by modeling each table as a node and foreign key relationships.*\nExperiment Setup: We begin our experimentation by analysing the capabilities of the current state of the art 7B/8B models on Text2Cypher. We initially fully finetune three general base models, i.e. Llama 3.1 model(Van Der Maaten et al., 2024), Mistral-v0.2-7B(Jiang et al., 2023) and Qwen-2-7B(Hui et al., 2024), along with two code based models CodeLlama-7B and QwenCoder-2.5-7B. We use UltraChat-200K(Ding et al., 2023) for instruction-finetuning (IFT) the general models and MagiCoder-117K(Luo et al., 2023) for fine-"}, {"title": "5 Results", "content": "As shown in Table-2, our SynthCypher dataset leads to significant improvements on both benchmarks across models. We draw several key observations:\n(1) Need of Text2Cypher datasets - Both off-the-shelf instruct LLMs and our finetuned LLMs on base IFT datasets achieve very low performance. Thus, highlighting lack of Text2Cypher alignment of code LLMs and need of more Text2Cypher IFT datasets.\n(2) Effectiveness of SynthCypher - LLMs finetuned with IFT data mix containing SynthCypher achieve 40% absolute improvement over the base IFT datasets and 30% over off-the-shelf instruct LLMs. These encouraging improvements highlight effectiveness of SynthCypher and directions for future works.\n(3) SynthCypher pipeline - Comparison shown in fig. 3 clearly highlights effectiveness of our pipeline and SynthCypher over other existing dataset generated using GPT-40. This highlights benefits of step-by-step controlled data generation for Text2Cypher."}, {"title": "6 Conclusion", "content": "In this work, we highlight and address the Text2Cypher gap in current open source models, and introduced a novel pipeline to automatically generate and validate high quality Text2Cypher data. Our presented dataset SynthCypher from our pipeline leads to substantial performance improvements across multiple LLMs. We also provide two evaluation benchmarks for future works in this direction."}, {"title": "7 Limitations", "content": "While synthetic data generation strategies have played a crucial role in open source LLM models, these strategies may pose risks in terms of reinforcing model biases, thereby resulting in a data distribution that may not model real world scenarios, or worse yet, cause real world harm (especially when applied to social graph networks). Furthermore, we"}, {"title": "A Appendix-1", "content": null}, {"title": "B Schema Generation Process", "content": "We start with a seed list of 10 domains (e-commerce, IT Management, finance etc) as well as the domains in the Neo4J example databases on their website (neo, 2024). Then we prompt a Mixtral-822B model with higher temperature (0.8) to generate more such domains. Pooled together this yeilds 693 schemas which are split into Train and Test as shown in Table-1."}, {"title": "B.1 Nodes and Relationships", "content": "We start of by contructing a skeleton schema which includes the nodes and relationships that are plausible in the given domain. We elicit responses by conditioning on varying number of nodes and relationships, as well as various query taxonomies to cover a wide range of complexity in the graph as shown in Figure-4"}, {"title": "B.2 Final Schema", "content": "Once we obtain the nodes and relationships sets, we come up with the full schema along with datatypes, properties and directed edges as shown in Figure-5. We elicit the model to reason through matching the nodes with the generated relationships and obtain a final schema. We manually vet 25% of the schemas to ensure diversity, coherence and real world usefulness."}, {"title": "C Question Generation", "content": "For every schema, 20 elicit questions at a time from Mixtral-8*22B by sequentially conditioning it on a randomly selected 7 query types. This ensured a diverse question set covering all domains"}, {"title": "D Synthetic Ground Truth Generation", "content": "For each question, we generate a dummy ground truth, which is of the expected structure, data-type and is plausibly true for that question. The prompt for the same is given in Figure-7 For e.g.\nQuestion: \"What is the total sales in USD for Apples in the California market and who made the most sales?\"\nDummy answer: { \"total_sales_usd\": 10000, \"employee\": \"John Doe\"}"}, {"title": "E Database Infilling", "content": "To fill the database with in such a way that the dummy answer is the right answer for the question, we come up with both positive (relevant to the question, and dummy answer) and negative data points (irrelevant to the question). The prompt is given in Figure-8 and Figure-9. A full example is given as well."}, {"title": "F Cypher Generation", "content": "We do this in four detailed steps so as to give the model ample reasoning and planning tokens. These include\n\u2022 Analysing the user's question - Figure-10\n\u2022 Identifying the pertinent nodes, relationships, and properties for the question. Figure-11\n\u2022 Recalling the best practices and coding guidelines for Cypher, including performance concerns. 12\n\u2022 Generating the final Cypher query. 13"}]}