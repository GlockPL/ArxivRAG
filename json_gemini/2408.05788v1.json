{"title": "Continual Learning of Nonlinear Independent\nRepresentations", "authors": ["Boyang Sun", "Ignaiver Ng", "Guangyi Chen", "Yifan Shen", "Qirong Ho", "Kun Zhang"], "abstract": "Identifying the causal relations between interested variables plays a pivotal role in\nrepresentation learning as it provides deep insights into the dataset. Identifiability, as the central theme of this approach, normally hinges on leveraging data from\nmultiple distributions (intervention, distribution shift, time series, etc). Despite\nthe exciting development in this field, a practical but often overlooked problem\nis, what if those distribution shifts happen sequentially? In contrast, any intelli-\ngence possesses the capacity to abstract and refine learned knowledge sequentially;\nlifelong learning. In this paper, with a particular focus on the nonlinear indepen-\ndent component analysis (ICA) framework, we move one step forward toward the\nquestion of enabling models to learn meaningful (identifiable) representations in a\nsequential manner, termed continual causal representation learning. We theoreti-\ncally demonstrate that model identifiability progresses from a subspace level to a\ncomponent-wise level as the number of distributions increases. Empirically, We\nshow that our method achieves performance comparable to nonlinear ICA methods\ntrained jointly on multiple offline distributions and, surprisingly the incoming new\ndistribution doesn't necessarily benefit the identification of all latent variables.", "sections": [{"title": "1 Introduction", "content": "In many data-driven problems, observations can be considered as the output of mathematical functions\napplied to the underlying representations. The process of learning those meaningful representations\nbased on the measured variables, known as representation learning, is crucial in modern machine\nlearning fields with applications spanning from visions [53, 1, 11, 26] to natural language processing\n[31, 34, 50, 8]. However, traditional approaches to representation learning often fall short by merely\ncapturing statistical correlation without considering the underlying causal structure, which is crucial\nfor achieving robust generalization across different tasks and datasets [40]. Therefore, identifying\ncausal relations between relevant variables is indispensable in representation learning to comprehend\nthe intricate relationships within the datasets.\nDiscovery of causal relations is never an easy problem. In many scenarios, we want to benefit the\nidentifiability of the causal structure by leveraging non-i.i.d data. In traditional causal discovery, it's\nwell known the causal structure can only be identified up to Markov equivalent class without assuming\nfunctional class [45] in the i.i.d case. However, interventions, seen as an \"active distribution shift\",\ncan break the asymmetry and reveal the causal direction. Besides that, a series of studies indicate that\ndistribution shifts and heterogeneous data can improve the identifiability of causal structure [18, 48].\nWhen the interested variables are not directly measured, causal representation learning (CRL)[40]\naims at recovering the latent causal variables and their causal structures from the observations.\nHowever, similar to causal discovery, learning identifiable representations from i.i.d data is highly\nchallenging. In fact, the identifiability of nonlinear independent component analysis (ICA), as\nthe simplest case of CRL where all latents are independent, is proven to be impossible without\nfurther assumptions [9]. To address this problem, existing work often relies on functional constraints\n[60, 28, 3, 61] or distributional assumptions [19, 20, 22, 25].\nRecent advances in this area aim to extend beyond independent latent variables and recover their causal\ngraph. These advancements often rely on parametric or graph assumptions [4, 17, 56, 23] regarding the\nlatent causal structure or, commonly, exploit non-i.i.d data. For instance, [52] explores identifiability\nfrom a counterfactual perspective, while [51] investigates multi-environment data arising from\nunknown interventions. Furthermore, [2] examines data from distinct paired interventions, and [10]\nfocuses on multi-modality data. Additionally, [59] proposes a nonparametric general framework.\nDespite the exciting developments in this field, we should acknowledge that, whether through\nintervention, distribution shift, or counterfactual approaches, mathematically, all these methods\nsimply indicate that there exist multiple distributions for the causal variables of interest, enabling\nthe learning of meaningful (identifiable) representations. However, these approaches implicitly\nassume that we can simultaneously access data from multiple distributions, which is often difficult to\nachieve in real-world scenarios. In contrast, any intelligent agents are able to continually abstract and\nrefine learned knowledge. This raises a direct and fundamental question: how to enable the model to\nlearn identifiable representations with sequential arriving distributions? This challenge leads us to the\nconcept of continual causal representation learning (CCRL).\nIn this paper, with a particular focus on the nonlinear ICA framework, we present a novel approach\nto learning causal representation in continually arriving distributions. Distinct from traditional\ncontinual classification tasks, CCRL requires that the model leverages the changes in distribution\ncontinually to refine the learned representations, ultimately achieving identifiability. This implies\nthat the problem cannot be segregated into discrete local learning tasks, such as learning causal\nrepresentation within individual distributions and subsequently fusing them. In this context, we\nconduct a theoretical examination of the relationships between model identification and the number\nof observed distributions. Our research indicates that the identifiability increases with the inclusion of\nadditional distributions. In particular, subspace identification can be achieved with n + 1 distributions,\nwhile component-wise identification necessitates 2n + 1 distributions or more. This indicates that\nwhen the distribution count is inadequate (n + 1), we can only identify the manifold spanned by a\nsubset of latent variables. However, by utilizing the new side information from arriving distributions,\nwe can further disentangle this subset and improve the identifiability.\nThis discovery motivates us to develop a method that retains prior knowledge and refines it using in-\nformation derived from incoming distributions, a process reminiscent of human learning mechanisms.\nTo realize CCRL, we employ two objectives: (1) the reconstruction of observations within the current\ndistribution, and (2) the preservation of reconstruction capabilities for preceding distributions via\ngradient constraints. To accomplish these goals, we apply Gradient Episodic Memory (GEM) [32] to\nconstrain the model's gradients. GEM aligns the gradients of the new domain with those of prior\ndistributions by eliminating factors within the current distribution that are detrimental to previous\ndistributions. Through empirical evaluations, we demonstrate that our continual approach delivers\nperformance on par with nonlinear ICA techniques trained jointly across multiple offline distributions.\nWe show that the identifiability of the latent causal variables strengthens as the number of observed\ndistributions increases. Interestingly, our theoretical findings indicate that the new distribution does\nnot necessarily benefit the identification of all latent variables, validated by the experiments."}, {"title": "2 Related Work", "content": "Causal representation learning. Beyond conventional representation learning, causal representation\nlearning aims to identify the underlying causal generation process and recover the latent causal\nvariables. There are pieces of work aiming towards this goal. For example, it has been demonstrated\nin previous studies that latent variables can be identified in linear-Gaussian models by utilizing\nthe vanishing Tetrad conditions [43], as well as the more general concept of t-separation [42].\nAdditionally, the Generalized Independent Noise (GIN) condition tried to identify a linear non-\nGaussian causal graph [56]. However, all of these methods are constrained to the linear case while\nnonlinear ICA provides a promising framework that learns identifiable latent causal representations\nbased on their non-linear mixture. However, the identifiability of nonlinear ICA has proven to be\na challenging task [21], which always requires further assumptions as auxiliary information, such\nas temporal structures [44], non-stationarities [19, 20], or a general form as auxiliary variable [22]."}, {"title": "3 Identifiable Nonlinear ICA with Sequentially Arriving Distributions", "content": "In this section, we conduct a theoretical examination of the relationship between model identification\nand the number of distributions. Initially, we introduce the causal generation process of our model (in\nSection 3.1), which considers the dynamics of changing distributions. Subsequently, we demonstrate\nthat model identifiability improves with the inclusion of additional distributions. More specifically,\nwe can achieve component-wise identification with 2n + 1 distributions (in Section 3.2.1), and\nsubspace identification with n + 1 distributions (in Section 3.2.2). Building on these theoretical\ninsights, we introduce our method for learning independent causal representation in the context of\ncontinually emerging distributions (in Section 3.3)."}, {"title": "3.1 Problem Setting", "content": "As shown in Figure 1, we consider the data generation process as follows:\n\n\n\n\nwhere $x \\in \\mathcal{X} \\subseteq \\mathbb{R}^d$ are the observations mixed by latent vari-\nables $z \\in \\mathcal{Z} \\subseteq \\mathbb{R}^n$ through an invertible and smooth nonlinear\nfunction $g : \\mathcal{Z} \\to \\mathcal{X}$ ($d > n$), which is also called a $C^2$ dif-\nfeomorphism. The latent variables $z$ can be partitioned into two\ngroups: changing variables $z_s \\in \\mathcal{Z}_s \\subseteq \\mathbb{R}^{n_s}$ whose distribution\nchanges across the distribution indicator $u$, and invariant variables\n$z_c \\in \\mathcal{Z}_c \\subseteq \\mathbb{R}^{n_c}$ whose distribution remains invariant. In this paper,\nwe refer $u$ as the domain. Given $T$ distributions in total, we have\n$P_{z_s|u_k} \\neq P_{Z_s|u_l}, P_{z_c|u_k} = P_{z_c|u_l}$, for all $k,l \\in \\{1,...,T\\},k \\neq l$.\nWe parameterize the distribution change for changing variables $z_s$\nas the function of $u$ to its parent variables $\\tilde{z}_s$, i.e. $z_s = f_u(\\tilde{z}_s)$.\nOne can understand this setting with the following example: sup-\npose the higher level variables follow Gaussian distribution, i.e.,\n$\\tilde{z}_s \\sim \\mathcal{N}(0, I)$, and $u$ could be a vector denoting the variance of the distribution. The combination of\n$u$ with $\\tilde{z}_s$ will produce a Gaussian variable with different variances at different distributions.\nThe objective of nonlinear ICA is to recover the latent variables $z_s$ and $z_c$ given the observation $x$\nand domain variables $u$ by estimating the unmixing function $g^{-1}$. In this paper, we consider the case"}, {"title": "3.2 Identifiability Theory of Nonlinear ICA", "content": "The identifiability is the key to nonlinear ICA to guarantee meaningful recovery of the latent variables.\nMathematically, the identifiability of a model is defined as\n\n$\\forall (\\theta,\\theta'): p_\\theta(x) = p_{\\theta'}(x) \\implies \\theta = \\theta'$,\n\nwhere $\\theta$ represents the parameter generating the observation $x$. That is, if any two different choices\nof model parameter $\\theta$ and $\\theta'$ lead to the same distribution, then this implies that $\\theta$ and $\\theta'$ are equal\n[25]. For our data generation defined in (1), we have $\\theta = (g, z_c, z_s)$, and $\\theta' = (\\hat{g}, \\hat{z}_c, \\hat{z}_s)$ which\ndenotes the estimated mixing function, estimated invariant variables, and estimated changing variables\nrespectively. Thus, a fully identifiable nonlinear ICA needs to satisfy at least two requirements:\nthe ability to reconstruct the observation and the complete consistency with the true generating\nprocess. Unfortunately, current research cannot achieve this level of identifiability without further\nassumptions that are considerably restrictive. Therefore, existing works typically adopt a weaker\nnotion of identifiability. In the following, we discuss two types of identifiability for the changing\nvariable, and show that the identifiability progressively increases from subspace identifiability to\ncomponent-wise one by incorporating more distributions.\nIn this work, we follow [27] and assume our estimated latent process $(\\hat{g}, \\hat{z}_c, \\hat{z}_s)$ could generate\nobservation $x$ with identical distribution with observation $x$ generated by the true latent process\n$(g, z_c, z_s)$, i.e.,\n\n$p_{x|u}(x'|u') = p_{x|u}(x'|u'), x' \\in \\mathcal{X}, u' \\in \\mathcal{U}$."}, {"title": "3.2.1 Component-wise Identifiability for Changing Variable", "content": "First, we show that the changing variable can be identified up to permutation and component-wise\ninvertible transformation with sufficient changing distributions. Specifically, for the true latent\nchanging variable $z_s$, there exists an invertible function $h = g^{-1} \\circ \\hat{g} : \\mathbb{R}^{n_s} \\to \\mathbb{R}^{n_s}$ such that\n$z_s = h(\\hat{z}_s)$, where $h$ is composed of a permutation transformation $\\pi$ and a component-wise nonlinear\ninvertible transformation $A$, i.e., $\\hat{g} = g \\circ \\pi \\circ A^{-1}$. That is, the estimated variable $\\hat{z}_i$ and the true variable\n$z_i$ have a one-to-one correspondence with an invertible transformation for $\\forall i, j \\in \\{1, ..., n_s\\}$. We\nhave the following lemma from [27].\nLemma 1 Suppose that the data generation process follows (1) and that the following assumptions\nhold:\n1. The set $\\{z \\in \\mathcal{Z} | p(z) = 0\\}$ has measure zero.\n2. The probability density given each domain should be sufficiently smooth. i.e., $p_{z|u}$ is at least\nsecond-order differentiable.\n3. Given domain $u$, every element of latent variable $z$ should be independent with each other.\ni.e., $z_i \\perp z_j|u$ for $i, j \\in \\{1, ..., n\\}$ and $i \\neq j$.\n4. For any $z_s \\in \\mathcal{Z}_s$, there exists $2n_s + 1$ values of $u$, such that for $k = 1,..., 2n_s$, i =\n$1,..., n_s$, the following matrix is invertible:\n\n\\begin{bmatrix}\n    \\varphi_{11}^{(1, 0)} & \\cdots & \\varphi_{1n_s}^{(1, 0)} \\\\\n    \\vdots & \\ddots & \\vdots \\\\\n    \\varphi_{11}^{(k, 0)} & \\cdots & \\varphi_{1n_s}^{(k, 0)} \\\\\n    \\vdots & \\ddots & \\vdots \\\\\n    \\varphi_{11}^{(2n_s, 0)} & \\cdots & \\varphi_{1n_s}^{(2n_s, 0)} \\\\\n\\end{bmatrix},\n\n\nwhere\n\n$\\varphi_{il}^{(k, 0)} := \\frac{\\partial^2\\log(P_{z|u}(z_i|u_k))}{\\partial z_i^2} - \\frac{\\partial^2\\log(p_{z|u}(z_i|u_0))}{\\partial z_i^2}$,\n\n\n\nThen, by learning the estimation $\\hat{g}, \\hat{z}_c, \\hat{z}_s$ to achieve (3), $z_s$ is component-wise identifiable. 1"}, {"title": "3.2.2 Subspace Identifiability for Changing Variable", "content": "Although component-wise identifiability is powerful and attractive, holding $2n_s + 1$ different distri-\nbutions with sufficient changes remains a rather strong condition and may be hard to meet in practice.\nIn this regard, we investigate the problem of what will happen if we have fewer distributions. We first\nintroduce a notion of identifiability that is weaker compared to the component-wise identifiability\ndiscussed in the previous section.\nDefinition 1 (Subspace Identifiability of Changing Variable) We say that the true changing vari-\nables $z_s$ are subspace identifiable if, for the estimated changing variables $\\hat{z}_s$ and each changing\nvariable $z_{s,i}$, there exists a function $h_i : \\mathbb{R}^{n_s} \\to \\mathbb{R}$ such that $z_{s,i} = h_i(\\hat{z}_s)$.\nWe now provide the following identifiability result that uses a noticeably weaker condition (compared\nto Lemma 1) to achieve the subspace identifiability defined above, using only $n_s + 1$ distributions.\nTheorem 1 Suppose that the data generation process follows (1) and that Assumptions 1, 2, and 3\nof Lemma 1 hold. For any $z_s \\in \\mathcal{Z}_s$, we further assume that there exists $n_s + 1$ values of $u$ such that\nfor $i = 1,..., n_s$ and $k = 1, ..., n_s$, the following matrix\n\n\\begin{bmatrix}\n    \\Phi_{1}^{(1, 0)} & \\cdots & \\Phi_{n_s}^{(1, 0)} \\\\\n    \\vdots & \\ddots & \\vdots \\\\\n    \\Phi_{1}^{(k, 0)} & \\cdots & \\Phi_{n_s}^{(k, 0)} \\\\\n    \\vdots & \\ddots & \\vdots \\\\\n    \\Phi_{1}^{(n_s, 0)} & \\cdots & \\Phi_{n_s}^{(n_s, 0)} \\\\\n\\end{bmatrix}\n\nis invertible, where\n\n$\\Phi_{i}^{(k, 0)} := \\frac{\\partial \\log(P_{z|u}(z_i|u_k))}{\\partial z_i} - \\frac{\\partial \\log(P_{z|u}(z_i|u_0))}{\\partial z_i}$\n\nis the difference of first-order derivative of log density of $z_i$ between domain $u_k$ and domain $u_0$\nrespectively. Then, by learning the estimation $\\hat{g}, \\hat{z}_c, \\hat{z}_s$ to achieve (3), $z_s$ is subspace identifiable."}, {"title": "3.3 Method", "content": "In this section, we leverage the insight of the identifiability theory from previous section to develop\nour estimation method.\nGenerative model. As shown in Lemma 1 and Theorem 1, we are aiming at estimating causal\nprocess $\\hat{g}, \\hat{z}_c, \\hat{\\tilde{z}}$, to reconstruct the distribution of observation. As shown in Figure 3, we construct a\nVariational Autoencoder (VAE) with its encoder $q_{\\hat{g}^{-1},q^{-1}_{f_u}}(\\tilde{z}|x)$ to simulate the mixing process and the\ndecoder $\\hat{g}$ to reconstruct a matched distribution $x = \\hat{g}(\\tilde{z})$. Besides, as introduced in data generation\nin Equation 1, the changing latent variable is generated as the function of high-level invariance $\\tilde{z}$\nwith a specific domain influence $u$. Assuming the function is invertible, we employ a flow model to\nobtain the high-level variable $\\tilde{z}$, by inverting the function, i.e., $\\hat{z}_s = f^{-1}_{u}(\\tilde{z}_s)$. To train this model,\nwe apply an ELBO loss as:\n\n$\\mathcal{L}(g, q, f, q_f) = \\mathbb{E}_{x} \\mathbb{E}_{z \\sim q_{g^{-1}, q_f^{-1}}(z|x)} [\\frac{1}{2}||x - \\hat{g}(z)||^2] + \\alpha \\mathbb{K}L(q_{g^{-1}, q_f^{-1}}(z_c|x)||p(Z_c))\n\\hfill + \\beta \\mathbb{K}L(q_{g^{-1}, q_f^{-1},f_u}(z_s|x||p(\\tilde{z}_s))$,\n\n\n\nwhere $\\alpha$ and $\\beta$ are hyperparameters controlling the factor as introduced in [14]. To make the (5)\ntractable, we choose the prior distributions $p(\\tilde{z}_s)$ and $p(z_c)$ as standard Gaussian $\\mathcal{N}(0, I)$.\nContinual causal representation learning. The subspace identifiability theory in Section 3.2.2\nimplies that the ground-truth solution lies on a manifold that can be further constrained with more\nside information, up to the solution with component-wise identifiability. Consequently, it is intuitive\nto expect that when we observe distributions sequentially, the solution space should progressively\nnarrow down in a reasonable manner.\nIt motivates us to first learn a local solution with existing distributions and further improve it to align\nwith the new arriving domain without destroying the original capacity. Specifically, to realize causal"}, {"title": "4 Experiments", "content": "In this section, we present the implementing details of our method, the experimental results, and the\ncorresponding analysis."}, {"title": "4.1 Experiment Setup", "content": "Data. We follow the standard practice from previous work [22, 27] and compare our method to the\nbaselines on synthetic data. We generate the latent variables $z_s$ for non-stationary and mixed Gaussian\ndistributions with domain-influenced variance and mean, while $z_c$ follows standard Gaussian and\nmixed Gaussian with constant mean and variance. The mixing function is a 2-layer MLP with\nLeaky-Relu activation. More details are in Appendix A6.\nEvaluation metrics. We use Mean Correlation Coefficient (MCC) to measure the identifiability of\nthe changing variable $z_s$. However, as the identifiability result can only guarantee component-wise\nidentifiability, it may not be fair to directly use MCC between $\\hat{z}_s$ and $z_s$ (e.g. if $\\hat{z} = z^2$, we will\nget a distorted MCC value). We thus separate the test data into the training part and test part, and\nfurther train separate MLP to learn a simple regression for each $\\hat{z}_s$ to $z_s$ to remove its nonlinearity on\nthe training part and compute the final MCC on the test part. We repeat our experiments over 5 or 3\nrandom seeds for different settings."}, {"title": "4.2 Experimental Results", "content": "Comparison to baseline and joint training. We evaluate the efficacy of our proposed approach\nby comparing it against the same model trained on sequentially arriving distributions and multiple\ndistributions simultaneously, referred to as the baseline and theoretical upper bound by the continual\nlearning community. We employ identical network architectures for all three models and examine\nfour distinct datasets, with respective parameters of $z, being Gaussian and mixed Gaussian with\n$n_s = 4, n = 8$, as well as $n_s = 2, n = 4$. Increasing numbers of distributions are assessed for each\ndataset. Figure 4 shows our method reaches comparable performance with joint training. Further\nvisualization can be found in Appendix A4.\nIncreasing distributions. For dataset $n_s = 4, n = 8$ of Gaussian, we save every trained model after\neach domain and evaluate their MCC. Specifically, we evaluated the models on the original test dataset,\nwhich encompasses data from all 15 distributions. As shown in part (a) of Figure 5, remarkably,\nincreasing distributions lead to greater identifiability results, which align with our expectations that\nsequential learning uncovers the true underlying causal variables as more information is revealed.\nSpecifically, we observe that the MCC reaches a performance plateau at 9 distributions and the extra\ndistributions(from 9 to 15) don't provide further improvement. This appears to be consistent with the\nidentifiability theory that $2n_s + 1 = 9$ distributions are needed for identifiability.\nDiscussion: is joint training always better than learning sequentially? Not necessarily. As dis-\ncussed in Section 3.2.2, the new domain may impair the identifiability of partial variables. While joint\ntraining always shuffles the data and doesn't care about the order information, learning sequentially\nto some extent mitigates the impairment of identifiability.\nTo test our hypothesis, specifically, we conducted an experiment in which both $z_1$ and $z_2$ are Gaussian\nvariables. The variance and mean of $z_1$ change in the second domain, while the other variable\nchanges in the third domain. We then compare our method with joint training only for latent variable\n$z_1$. We repeat our experiments with 3 random seeds and the experiment shows that the MCC of\nour method for $z_1$ reaches up to 0.785 while joint training retains at 0.68 as shown in Figure 5(b).\nIn terms of visual contrast, the scatter plot obtained using our method on the left of Figure 5(b)"}, {"title": "5 Conclusion", "content": "In this paper, we present a novel approach for the fundamental, but overlooked problem: as long as\nthe learning of identifiable representations relies on multiple distributions, how can we facilitate this\nlearning in a continual manner? We believe this approach is unaviodable in practical scenario and just\nakin to human learning. With a particular focus on nonlinear ICA framework, we examined the rela-\ntionship between model identification and the number of observed distributions. Our findings indicate\nthat as additional distributions are incorporated, the identifiability of changing variables escalates,\nwith subspace identification achievable with ns + 1 distributions and component-wise identification\nrequiring 2n + 1 distributions or more. Besides, we briefly show that the introduction of new\ndistributions does not necessarily contribute to all variables. Empirical evaluations have demonstrated\nthat our approach achieves performance on par with nonlinear ICA techniques trained jointly across\nmultiple offline distributions, exhibiting greater identifiability with increasing distributions observed.\nLimitation A obvious limitation of this approach is the requirement for prior knowledge of the\nnumber of changing latent variable. Besides that, the gradient based method pose a challenge to the\nscaling of the algorithm.\nFuture work We believe this paper is only a preliminary exploration of CCRL\u2014there are many\nissues that need to be addressed. Firstly, this paper focuses solely on the nonlinear Independent\nComponent Analysis (ICA) framework, which is the simplest form of CRL. Recovering the latent\nvariables and their causal structure by observing sequentially arriving distributions is a direct challenge.\nSecondly, even in causal discovery, how to leverage sequential distribution shifts to benefit the\nidentification of causal relations is worth investigating. Thirdly, it is important to note that humans\nlearn actively and selectively. Correspondingly, understanding how to \"smartly\" utilize important\ndomains also merits in-depth exploration."}]}