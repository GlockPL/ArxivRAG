{"title": "Exploring the sustainable scaling of Al dilemma: A projective study of corporations' Al environmental impacts", "authors": ["Cl\u00e9ment Desroches", "Martin Chauvin", "Louis Ladan", "Caroline Vateau", "Simon Gosset", "Philippe Cordier"], "abstract": "The rapid growth of artificial intelligence (AI), particularly Large Language Models (LLMs), has raised concerns regarding its global environmental impact that extends beyond greenhouse gas emissions to include consideration of hardware fabrication and end-of-life processes. The opacity from major providers hinders companies' abilities to evaluate their Al-related environmental impacts and achieve net-zero targets.\nIn this paper, we propose a methodology to estimate the environmental impact of a company's Al portfolio, providing actionable insights without necessitating extensive Al and Life-Cycle Assessment (LCA) expertise. Results confirm that large generative Al models consume up to 4600x more energy than traditional models. Our modelling approach, which accounts for increased Al usage, hardware computing efficiency, and changes in electricity mix in line with IPCC scenarios, forecasts Al electricity use up to 2030. Under a high adoption scenario, driven by widespread Generative Al and agents adoption associated to increasingly complex models and frameworks, Al electricity use is projected to rise by a factor of 24.4.\nMitigating the environmental impact of Generative Al by 2030 requires coordinated efforts across the Al value chain. Isolated measures in hardware efficiency, model efficiency, or grid improvements alone are insufficient. We advocate for standardized environmental assessment frameworks, greater transparency from the all actors of the value chain and the introduction of a \"Return on Environment\" metric to align Al development with net-zero goals.", "sections": [{"title": "Introduction", "content": "Artificial Intelligence (AI) is transforming industries worldwide, but its recent rapid developments, particularly in Generative Al and Agentic Al, raises urgent sustainability concerns due to their significant environmental impacts\u00b9. These impacts stem from two primary sources: operational usage, involving electricity and water consumption during training and usage, the manufacturing and the end-of-life processes of hardware equipment. The impacts are linked to the equipment and infrastructures mobilized to deliver Traditional Al and generative Al2,3 (GenAl) services including servers and IT equipment housed in datacenters, as well as telecommunication networks and end-users devices. Collectively, these contribute to global environmental impacts like greenhouse gas emissions, water consumption, resource depletion (minerals and metals), and the escalating issue and impact of electronic waste.\nThe energy demands of Al are particularly concerning, with projections from the International Energy Agency (IEA) indicating that global data center electricity consumption could double by 2026, driven by Al and cryptocurrencies4. Other studies have examined the projected electricity usage of Al data centers5\u20137, all showing potential threefold to eightfold increase. This underscores the urgency of addressing not only energy consumption and associated carbon emissions but also the broader implications of resource usage.\nFor companies committing to carbon neutrality by 2030 or 2040 in alignment with the Paris Agreement, the ability to forecast and address Al's future environmental impacts is critical. In the latest Capgemini Research Institute report study on sustainable GenAI, 64% of companies say Al energy consumption is too complex to measure\u00b9. Assessing Al's environmental footprint is a challenge exacerbated by its complexity. Operational impacts depend on factors such as model efficiency, carbon intensity of electricity grid that powers data centers, number of users and average usage. Embodied impacts are even harder to evaluate, as they involve intricate complex supply chains, with raw material extraction and transformation, manufacturing of semi-conductors, and eventual hardware disposal.\nWe usually categorize Al models into two groups: Traditional Al (or task-specific models) and Generative Al (or general-purpose models)\u00ba. Traditional Al primarily focuses on machine learning (ML) and deep learning models, where users interact with a single model designed for specific predictive tasks (e.g., classification, regression) through input data and output predictions, for computer vision, time series analysis or Natural Language Processing applications. In contrast, a single generative Al model can solve a variety of tasks for users out-of-the-box.2\nSince 2015, interest in the power consumption and energy efficiency of Al models, particularly deep learning models, has been growing10\u201314. Within the Al system hardware life cycle, the primary focus is on the environmental impacts of manufacturing (i.e., the embodied carbon footprint) and Al use (i.e., the operational carbon footprint). The model development phases include data processing, experimentation, training, and inference. Recent research has substantially studied the environmental impacts of training and inference 9,15\u201322.\nRegarding Generative Al specifically, several studies9,19,20 directly try and measure emissions using tools like Code Carbon23 while others, constrained by the lack of transparency from some model providers regarding model architecture, have tried to estimate operational and embodied impacts through simplified models22,24,25. Lately, following the recommendation of Strubell et al20 about the transparency in Al model development phases, the details of training and inference and CO2 emissions of several LLMs are published and closely monitored 18,26,27. Similarly, several initiatives, such as the LLM-Perf Leaderboard, ML.ENERGY Leaderboard, and Cloud Carbon Footprint, have been established to collect data on the energy consumption of Al models28-30."}, {"title": "", "content": "This paper aims to advance the discussion on Al's sustainability by proposing a simplified yet exhaustive methodology to estimate both operational and embodied impacts of Al solutions at a company level. Our methodology comprises four interconnected models:\n1. Life cycle impacts of primary components (compute, storage, network) involved in Al projects.\n2. Life cycle impacts of Al use cases, categorized for simplicity, focusing on various factors such as energy consumption, GHG emissions, water usage, and resource depletion.\n3. Al company portfolio model: we propose a simplified model representing the Al products portfolio of a typical large company portfolio.\n4. 2030 Al Landscape projections, that forecasts adoption, efficiency, and complexity of Al technologies up to 2030.\nBy breaking down these complex assessments into manageable steps, we aim to empower organizations to better understand and project their Al impacts and align their initiatives with global sustainability goals."}, {"title": "Results", "content": "This section presents the results of our modeling and provides an in-depth discussion of the energy consumption of the various Al usage cluster and their multi factor impacts. This includes a comparison of inference and fine-tuning impacts between Generative and Traditional Al use cases, benchmarking against other studies, and an analysis of the relative contributions of embodied versus operational impacts on various factors such as Greenhouse gas (GHG) emissions, water usage or resource depletion. We also share the distribution of impacts of a 2024 fictive company, emphasizing the substantial proportion of generative Al impact within company's operations. Finally, we discuss the 2030 projections of boundaries and intermediate scenarios, illustrating the potential dramatic increase of the impact of Generative Al. We then explore the effectiveness of various mitigation strategies."}, {"title": "2024 portfolio impacts", "content": "To facilitate the modeling of a typical large company's Al portfolio, we have categorized its use cases into distinct clusters based on five dimensions (type of Al, Use case type, model size, usage frequency and number of users). Details are presented in sections Model 3: Company portfolio model and Company Portfolio Model of supplementary information."}, {"title": "Use cases' individual impact", "content": "Our methodology, based on a dual model (Life cycle impacts of Al hardware components and categorized Al use cases consumption of these primary bricks), accounts for both fine-tuning and inference impacts. In the Table below, we share and compare the inference impacts of these clustered use cases calculated with our methodology (see Methods)."}, {"title": "Comparing with other benchmarks and studies", "content": "The energy consumption we report for 1 inference of a \"small\" LLM (0.093 Wh), such as Llama 3.1 8B, aligns closely with empirical energy measurements reported by Luccioni et al.9 on a similar instance (AWS p4de). Indeed, the energy usage for the facebook/OPT6.7B model 30 reported was 0.082 Wh, while Bloomz-7B\u00ba consumed 0.104 Wh per inference. Similarly, the reported energy of Bloom 175B in the same study\u00ba (4 Wh) aligns with the range of medium and large models' energy consumption (Llama 70B: 1.55 Wh and Llama 405B: 17.3 Wh). However, higher energy consumptions are reported by sources like Ecologits25 and the LLM Perf leaderboard30. For instance, the LLM Performance Leaderboard recorded an energy usage of 0.59 Wh for the meta-llama/Meta-Llama-3-8B-Instruct model when generating 208 tokens. This discrepancy could be attributed to differences in generation speed and hardware instances. The LLM Performance Leaderboard reported a generation speed of 23 tok/s on an A10-24GB-150W instance, compared to our study, which achieved 162 tok/s for Azure API. 31"}, {"title": "Key findings", "content": "Generative Al models consume significantly more energy than traditional Al models, with smaller models like Llama 8B using 25 times more energy than traditional NLP models and larger models like Llama 405B consuming up to 4600 times more.\nThe energy demands of larger GenAl models scale substantially. A high-sized model, such as Llama 405B, consumes 186 times more energy than Llama 8B for one chat inference. This disparity is primarily attributed to the significantly lower throughput of Llama 405B (down by 83%) and its reliance on a greater number of vGPUs (35x more) related to a 2:1 scaling ratio of memory needed considering FP16. It results in a significant electricity consumption for these large models, each inference reaching 17Wh (equivalent to toasting bread for 1 minute at 1000 W...).\nEnergy consumption also rises with workflow complexity: chat (1.55 Wh), Retrieval Augmented Generation (2.64 Wh), and agentic workflows (8.54 Wh) due to increased computational steps and token generation, highlighting efficiency challenges with larger models and more complex workflows."}, {"title": "Company Portfolio impact", "content": "Across the modeled portfolio, comprising only 29% generative Al (GenAl) and 71% traditional Al use cases, most inferences are attributed to GenAl. This disproportionate contribution arises from the extensive deployment scale (number of users and usage frequency) associated with GenAl applications. Given that GenAl models are inherently more energy- intensive compared to traditional Al models, this trend is further amplified when analyzing energy consumption per use case which scale to 99.9% attributed to generative Al for our representative portfolio.\nRegardless of the specific impact metric considered, the inference phase constitutes the most significant contributor compared with model fine-tuning. This predominance is primarily due to the substantial energy demands associated with generative Al (GenAl) use cases. Since most companies are using mainstream LLM like gpt-4o, Claude, Mistral, impact of pre-training 32 phase of Large Language Models (LLMs) has been excluded from this analysis, due to limited transparency on the distribution of general public usages versus corporate-specific applications, it still remains challenging to fairly allocate the environmental impact of pre-"}, {"title": "", "content": "training across all users. However, this assumption is not true for LLMs that don't have a substantial usage in production, for which the pre-training phase represent the most important part of its environmental impact. The impact of that kind of models is not discussed here.\nThe balance between embodied and operational impacts varies significantly depending on the environmental criterion assessed. For example, at the scale of our company portfolio, embodied impacts account for as little as 5% of greenhouse gas (GHG) emissions yet represent as much as 89% of resource depletion and nearly 30% of water usage.\nOver a year, the absolute annual impact of the fictive company, considering 100 use cases distributed as explained in the section Company Portfolio Model of supplementary information, stands at an electricity consumption of 3.9GWh for 2,480,000 kgCO2eq. of GHG emissions, 160,000 m\u00b3 of Water used and 0.76 kgSbeq.\nAssuming all companies listed in the Global 2000 Forbes Index follow a similar use case distribution as proposed, we estimate the combined electricity consumption to be approximately 7.8 TWh in 2024. This figure aligns with the International Energy Agency's (IEA) projections for Al data center electricity estimated to grow from 7.3 TWh in 2023 to 70 TWh by 2026, with the remaining consumption largely driven by public Al usage and other companies."}, {"title": "Projected 2030 scenario impacts", "content": "We have envisaged and analyzed four boundary scenarios and another selected intermediate one to project the evolution of Al's footprint at company level:\n1. Scenario Steady ascent: Adoption of generative Al grows gradually with moderate increases in model size and complexity, reflecting conservative market trends. Systemic efficiency remains stable, following historical advancements, leading to a steady rise in energy demand.\n2. Scenario High Adoption without Boundaries: Generative Al adoption accelerates significantly, with widespread use of large, complex models and minimal constraints on usage linked to energy consumption and/or pricing. Systemic efficiency sees limited progress, causing substantial energy consumption and environmental impact.\n3. Scenario Limited Growth with Efficiency Breakthrough: Al adoption remains controlled with modest expansion in use cases and model sizes, emphasizing efficiency over rapid growth. Systemic efficiency improves significantly due to frugal model development, hardware advancements, and adherence to IPCC targets, reducing overall impact.\n4. Scenario Technological Breakthrough: Generative Al adoption expands rapidly but remains focused on high-sized models and complex usage patterns. Systemic efficiency is driven by groundbreaking advancements in hardware performance, minimizing energy consumption despite increased adoption.\n5. Intermediate Scenario: Al adoption grows moderately with balanced use case expansion and model complexity, following average market trends. Systemic efficiency sees gradual improvements in hardware performance and policies-aligned electricity impacts, resulting in environmental rising at a moderate pace.\nOn the usage axis, our findings indicate substantial growth in the number of Al use cases across all scenarios, with increases ranging from a factor of 3.4 to 5.7 (see Table 32 of supplementary information). While generative Al constituted 29%33 of the company's Al portfolio in 2024, projections suggest that this category will represent half of the portfolios by 2030.\nSupported by the significant growth in usage across all scenarios, we find most scenarios display a great increase in environmental footprint, see Error! Reference source not found.."}, {"title": "Sensitivity analysis", "content": "We have performed a sensitivity analysis of main parameters centered around our Intermediate scenario to evaluate impact of our model size hypothesis and agentic use cases deployment as well as reflect on the viability of technological only solutions towards sustainable Al usage in line with a 90% GHG reduction compared with 2024."}, {"title": "Model size", "content": "We have varied the parameter describing generative Al model size evolution in 2030 with +/- 10% uncertainty and find our approach translate this uncertainty linearly with a 1:1 factor indicating high dependency on this parameter (Table 3). We expect this factor to increase linearly with a 1:2 factor due to FP16 parameter encoding that requires 2 bytes per parameter, resulting in a doubling of RAM requirements per new parameter and consequently twice the GPU units needed. We have deferred this model improvement for future work.\nBased on our findings and the significant impact of this factor, we recommend increased attention be given to this parameter, as limited information is currently available or disclosed by main service providers."}, {"title": "Agentic adoption", "content": "The influence of Agentic Al adoption has been analyzed by examining the impact of the estimated Compound Annual Growth Rate (CAGR) associated with the penetration of associated use cases. Our analysis demonstrates that energy consumption is highly sensitive to the adoption rates of agentic use cases, primarily due to the exponential growth assumed in the CAGR projections (Table 4). We identify a second-order polynomial relationship between CAGR and the energy consumption of Al portfolios, as illustrated in Figure 2.\nConsidering the expected development of multi-agents use cases, increase model complexity and reasoning models like OpenAl 03, we have also studied the influence of the number of output tokens in our approach (Table 4). Similar to model size, we find that our approach translates the uncertainty in this factor with a 1:1 factor."}, {"title": "Hardware efficiency", "content": "In this thought experiment, we have explored the feasibility of aligning the High Adoption Without Boundaries and Intermediate scenarios with 90% GHG reduction compared with 2024, defined as achieving at least a 90% reduction in greenhouse gas (GHG) emissions compared to the 2024 portfolio. This alignment has been attempted through adjustments to key exogenous parameters, specifically Power Usage Effectiveness (PUE), energy mix decarbonization, and hardware efficiency.\nImprovement factors for PUE and energy mix were aligned with, respectively, best-in-class current trends in data center efficiency34 and the International Energy Agency's actual country policy pathways35 respectively. However, achieving the required reductions also necessitated hardware efficiency improvements by factors of 565x or 175x, depending on the adoption rates of Generative Al (GenAl) and agentic systems (Table 5). These findings underscore the significant challenges associated with meeting a 90% GHG reduction solely through technological advancements."}, {"title": "Discussion", "content": "The results of our portfolio analysis highlight critical considerations for the sustainable development of Al as a scaling technology."}, {"title": "Transparency vs. Industrial Secrecy", "content": "The tension between transparency in Al's environmental impact and maintaining trade secrets is complex. Leading tech firms, driven by scalability and recovering their huge investments in Generative Al, often rely on proprietary Al training techniques for competitive advantage. Increased transparency could jeopardize this edge, discouraging full disclosure.\nRevealing internal Al methodologies is crucial for environmental transparency but faces significant hurdles. Our approach investigates whether an Al system's environmental footprint can be estimated using a few publicly available parameters. This top-down method suggests reliable results with reduced complexity, encouraging wider corporate adoption.\nAlthough our findings align with open-source models, validating this method for closed-source systems remains challenging. Future efforts should focus on creating a collaborative, open- access database involving tech stakeholders, certification bodies, NGOs, and governments to standardize practices while protecting proprietary information.\nThis is line with the EU AI Act that establishes that providers of general-purpose Al (GPAI) systems, that encompasses Generative Al models, should disclose information on the 'known or estimated energy consumption of the model' and documentation to improve resources consumption of Al systems during their lifecycle36."}, {"title": "Multi-criteria Environmental Footprint", "content": "Conventional life cycle assessments (LCA), using bottom-up methods, require specialized expertise and extensive data, limiting practical application. Our methodology strikes a balance between implementation effort and accuracy, supporting sustainable Al practices.\nMoving beyond a sole focus on carbon emissions, it is crucial to assess potential trade-offs among various environmental impact components. The results reveal significant variation in the source of impact (e.g., operational versus embodied) depending on the factor considered. To capture the full spectrum of environmental consequences and minimize rebound effects on other impact areas, assessments should not be confined to a single factor such as greenhouse gas (GHG) emissions."}, {"title": "Sustainability of Scaling Laws", "content": "Technological advancements and optimized Al usage have the potential to mitigate the escalating computational costs associated with larger models. Scaling laws suggest that performance improves through increasing model parameters and training data volume. However, for this paradigm to be economically viable, it presumes diminishing marginal costs, which depends on continued improvements in data center efficiency (PUE, WUE), decarbonization of electricity, and hardware optimization (CPU, GPU, TPU).\nDespite notable efficiency improvements over the past decade, the long-term sustainability balance between scaling laws and technical progress remains uncertain. Our modeling, based on ceteris paribus ratios, provides partial insight into whether future innovations can maintain a sustainable Al trajectory in line with a 90% GHG reduction compared with 2024.\nBased on our scenario high adoption without boundaries, our model suggests that efficiency improvements of 565x would be required to meet a net-zero target for Al by 2030. Current projections suggest that even the most optimistic efficiency gains described in our"}, {"title": "", "content": "Technological breakthrough scenario fall short, heightening concerns over the long-term sustainability of scaling laws.\nOnly hardware technology major breakthroughs and large scale deployment, such as Neuromorphic computing or Cerebras' Wafer Scale Engines, could sustain scaling trajectories long-term. However, given their current technological readiness level (TRL), such innovations remain speculative for the near future37."}, {"title": "Can Al Models Be Scored Fairly?", "content": "Drawing inspiration from eco-scores in construction and textiles, an environmental scoring label for Al should balance precision and readability to reach a very large audience. A similar initiative has already been ideated by the community. 38,39 The scoring system could either focus on specific metrics such as energy consumption, carbon emissions, and water usage or aggregate these into a single score for simplicity, similar to France's DPE system that scores buildings energy performance. However, aggregation may compromise clarity due to the multidimensional nature of environmental impacts. Beyond usage, which is intuitive for the general public, incorporating factors like model training, semiconductor production, and end- of-life phases might improve accuracy but could also introduce complexity and uncertainty.\nFinally, defining Al environmental class thresholds could be based on either statistical distribution of current Al models (1) like in Energy Star project of Luccioni and al.39 or the French Agency for Ecological Transition (ADEME) car environmental scoring40 or, otherwise, a planetary boundaries approach aligning with global carbon budgets and finite resources (2)41.\nA critical aspect of energy evaluation in Al systems is the precise definition of both the scope and methodology for an energy score. A central question arises: should differentiation occur at the task level or model level?\nOn one hand, since large language models (LLMs) are employed across a wide range of tasks such as conversational agents, RAG, and agents, an energy score based on unitary actions (e.g., energy per token generated) could offer a normalized comparison of models. On the other hand, a broader comparison encompassing the entire spectrum of Al models\u2014including computer vision, image generation, and time series forecasting-necessitates energy scoring based on tasks rather than models. However, defining a theoretical task for fair comparison is challenging. The work of Luccioni et al.9,39 and Tschand and al.42 provide foundational insights in this area defining key categories. However, with the rise of increasingly complex generative Al workflows, such as RAG and multi-agent systems, it is essential to continuously refine and discuss the definition of a \"task\" in energy rating systems. Enhanced granularity, especially for energy-intensive tasks, can improve the precision and fairness of energy impact assessments across diverse Al applications."}, {"title": "Towards an Al Return on Environment (RoE) Metric", "content": "Beyond direct environmental impacts (attributional approach), it is crucial to incorporate indirect effects (scope 4 / consequentialist approach) into Al sustainability assessment. Currently, the lack of a standardized framework and the difficulty of manually constructing"}, {"title": "", "content": "counterfactual scenario for consequentialist methodologies hinder the ability to account for Al's potential positive indirect impacts on the environment. Enhancing existing methodologies is essential to guide the development of Al technologies toward a more responsible use, positioning Al as a positive force in climate change mitigation.\nIn conclusion, the environmental impact of generative Al depends on the responsible collaboration of various stakeholders. Three main factors influence its environmental footprint: widespread adoption across industries, increasing complexity of Al models and frameworks (particularly Agents), and the trend toward larger models. To minimize environmental risks, all actors of the Al value chain, including hardware manufacturers, must actively contribute to responsible deployment and usage. Achieving success requires greater transparency through information sharing among stakeholders, including environmental impact data and optimization methods. Without coordinated effort from model providers to end users, environmental impacts will significantly increase.\nFuture research should address several key areas:\n\u03a0\nIntegrating pre-training impacts, especially of Large Language Models, into value chain analysis to better attribute environmental costs across different enterprise applications.\nContinuously improving modeling methodology, especially in terms of parameter estimation and embodied emissions projections. This includes refining our understanding of hardware lifecycle impacts and improving energy consumption predictions for emerging Al architectures. To improve this framework, a more granular segmentation of typical industry use cases and model sizes could offer deeper insights.\nExpanding research beyond data center energy usage to examine environmental footprint of devices gathering data to be used by Als especially IoT devices that are continuously gathering larger amount of data or end-user devices used to access Al services such as smartphones, watches or glasses.\nInitiating a dialogue with the community (companies, researchers) to further refine benchmarks and define \"conventional\" tasks, building on currently developed use cases within companies.\nWe encourage the broader research community and industry stakeholders to further investigate this topic through developing standardized measurement frameworks, creating open datasets documenting environmental impacts, and establishing collaborative initiatives."}, {"title": "Methods", "content": "Overall methodology\nThis paper aims at estimating the overall environmental impacts of a typical world top 2000 revenue company due to their Al systems. We define an approach (Figure 3) modeling the environmental impact at single use case level that will be aggregated to represent a company portfolio and project towards possible Al and global evolution trends in 2030. The developed approach is easy to maintain and relevant for industry experts without an in-depth expertise in Al or GenAl. It aims to provide insights, identify hotspots, and observe trends to enable effective eco-design actions and levers to limit impact."}, {"title": "Model 1: Life-cycle-assessment methodology of hardware impacts", "content": "This study has relied on the Life Cycle Assessment (LCA) methodology to assess the impact of Al models. The key features of LCA are its multi-criteria, multi-step, and multi-component analysis.\nThe multi-criteria analysis considers five environmental indicators as follows: the global warming potential though the greenhouse gases emissions in kilograms of CO2 equivalent"}, {"title": "Impact evaluation", "content": "The environmental impacts of each use case are assessed using the formula below and its parameters are listed in Table 7 and sources for methodology in Table 8.\n$Impact_{total}(X_p, Sol_i) = \\Sigma_{i=1}^2\\Sigma_{j=1}^2\\Sigma_{k=1}^j Impact(X_p, Sol_i, Step_k, Component_n, Stage_j)$"}, {"title": "LCA Methodology", "content": "Compute model\nFor the embodied impacts assessment, a bill of material methodology has been used considering the following data, hypothesis and sources as the environmental data have not been published.\nFor the operational impact assessment, the electricity consumption of the hardware system has been assessed to 3,110W without additional impact due to the hosting within datacenter and to 4,665W including the PUE. The specification of the hardware and the following calculation rule were used.\n$P_{compute model}(W) = N_{CPU} * (Min(P_{CPU}) + Load rate CPU * (Max(P_{CPU}) - Min(P_{CPU}))) * (1 + \\%_{orchestrator}) + N_{disk} * P_{disk} * Load rate disk * Replication * (1 + \\%_{adddisk}) + N_{GPU} * Load rate GPU * Max(P_{GPU}) * (1 + \\%_{addGPU}) + N_{RAM} * Load rate RAM * P_{RAM} * (1 + \\%_{addRAM})$\nThe same allocation rule used for embodied emission has been used based on vCPU and vGPU embodied emissions."}, {"title": "Storage model", "content": "For the embodied impacts assessment, as the environmental data have not been published, a bill of material methodology has been used considering the following data, hypothesis and sources.\nFor the operational impact, the electricity consumption of the system has been assessed to 1,378W without additional impact due to the hosting within datacenter and to 1,583W including the PUE. The specification of the hardware and the following calculation rule were used.\n$P_{storage model}(W) = N_{CPU} * (Min(P_{CPU}) + Load rate CPU * (Max(P_{CPU}) - Min(P_{CPU}))) * (1 + \\%_{orchestrator}) + N_{disk} * P_{disk} * Load rate disk * Replication *(1+\\%_{adddisk})$"}, {"title": "Electronic card impacts", "content": "The impact of 1 m\u00b2 of electronic card is known using the manufacturing code NEGA-0052 with \"Motherboard; mix of equipment, without processor or RAM\u201d as component name. Therefore, the surfaces of electronic cards hosting GPU & CPU chips are evaluated.\nAt first, 8 GPU chips are hosted on the electronic card PCI-Express 4.0 x1654 as this card is used for a A100 PCIe 80 GB server that could be utilized to run the p4de.24xlarge instance. This card measures 267 mm in length & 111 mm in width which leads to a surface of 2.96E- 02 m\u00b2.\nMoreover, 2 CPU Intel Xeon Platinum 8275CL55 used for p4de.24xlarge has a TDP of 240W56 and 24 cores. Each CPU is considered hosted on the electronic card X12SPA-TF57 supporting TDP up to 270W & up to 40 cores. This card measures 33.02 cm length and 30.48 cm width which leads to a total surface of 2.01E-01 m\u00b2 considering the surfaces of 2 electronic cards."}, {"title": "Chips impacts", "content": "CPU and GPU chips are made from silicium wafers. Wafers undergoes 3 types of significant losses before obtaining CPU & GPU chips (see figure below)."}, {"title": "", "content": "The area of silicium needed to create a chip considering these losses is evaluated to assess its environmental impacts using the manufacturing code of wafers, where $A_{chip}$ is the area of a chip, yield is the yield related to both the edge effect & kerf loss and $Y_{default loss}$ is the yield related to the default losses.\n$A_{silicium needed} = \\frac{A_{chip}}{yield * Y_{default loss}}$"}, {"title": "Yield evaluation", "content": "The edge effect loss occurs when cutting square chips from circular wafers while the kerf loss refers to the material lost during the cutting process of silicon wafers. A first yield is used to consider the edge effect & default losses, where Nchip is the number of chips to be created in a wafer and $A_{wafer}$ is the area of a wafer.\n$yield = \\frac{N_{chip} * A_{chip}}{A_{wafer}}$"}, {"title": "", "content": "The largest wafer used to create chips has a diameter of 300mm58, therefore $A_{wafer}$ is known. $A_{chip}$ of both the CPU & GPU chips are known based on their specifications."}, {"title": "Evaluation of $N_{chip}$", "content": "The evaluation of $N_{chip}$ is known using the following formula59, where $D_{wafer}$ is the diameter of the wafer and $A_{chip with kerf}$ is the area of chip considering its kerf.\n$N_{chip} = \\frac{\\pi*(\\frac{D_{wafer}}{2})^2}{\\frac{A_{chip with kerf}}{\\sqrt{2 + A_{chip with kerf}}}}$"}, {"title": "Evaluation of $A_{chip with kerf}$", "content": "Chips are cut from the wafers with a width called the kerf (see figure below) and are considered a square for simplification purposes."}, {"title": "", "content": "The area $A_{chip with kerf}$ of each chip is determined after considering the kerf, where L is the length of the final square chip & kerf is the width of the cut\n$A_{chip with kerf} = (L+ kerf)\u00b2$\nAs the chip is considered a square, L is easily known where $A_{chip}$ is the area of the final chip.\n$L = \\sqrt{A_{chip}}$\n$A_{chip with kerf}$ is evaluated as $A_{chip}$ was evaluated before and by considering a kerf of 0.2 mm60."}, {"title": "Evaluation of $Y default loss$", "content": "Some defects on wafer lead to the failure of chips. These defects are considered with $Y_{default loss}$ which is given by the formula61 below using the Moore model, where D is the defect density of the wafer.\n$Y_{default loss} = e^{-D*A_{chip}}$"}, {"title": "", "content": "The results below are obtained.\n$A_{silicium needed, CPU chip} = 4.31 * 10^{-3}m\u00b2$\n$A_{silicium needed, GPU chip} = 4.83 * 10^{-2}m\u00b2$\nFinally, the impacts of both chips were evaluated considering their area of silicium needed and their manufacturing code."}, {"title": "Al model Hypothesis", "content": "In this section, we detail all the analysis and hypothesis used in the calculation methodology, from Al training / inference to LCA impact of instances."}, {"title": "Energy breakdown (Compute, storage, network)", "content": "In the following section, we'll detail the energy estimation methodology for a single Al use case. Embodied impacts are estimated similarly using hourly impact factors instead of power consumption."}, {"title": "Energy consumption estimation", "content": "The first step of our impact methodology is to estimate the energetic consumption of an Al solution both for its fine tuning and inference phases.\n$E_{solution:} = E_{sol}{Fine tuning} + E_{sol}{Inference}$\nThroughout these two phases, three types of theoretical energy consumption are involved based on technical specifications of components and usage rates."}, {"title": "Compute", "content": "To model compute usage of Al systems, we used a similar approach as Ecologits25 calculator, dividing GPUs consumption and remaining server's one. We need to 2 items. First, the usage in total Hours of hardware. The total number of hours for training and Fine tuning on one side; and the inference latency on the other depending on the nature of the task (NLP / CV / Tabular / LLM) and the number of GPUs required to run the model (based on model size). Secondly, we need to estimate the power consumption of GPUs and servers used to run the model depending on the server instance considered.\nWith:\n$E_{Compute} = E_{CPU} + E_{GPU} = vCPU_{hours} * P_{vcpu} * +vGPU_{hours} * P_{vgpu}$"}, {"title": "Storage", "content": "To estimate the required energy to store the data", "variables": "the total amount of Data, the number of hours of storage of the data and the power consumption"}]}