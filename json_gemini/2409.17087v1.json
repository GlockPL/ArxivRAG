{"title": "SEN12-WATER: A New Dataset for Hydrological Applications and its Benchmarking", "authors": ["Luigi Russo", "Francesco Mauro", "Alessandro Sebastianelli", "Paolo Gamba", "Silvia L. Ullo"], "abstract": "Climate change and increasing droughts pose significant challenges to water resource management around the world. These problems lead to severe water shortages that threaten ecosystems, agriculture, and human communities. To advance the fight against these challenges, we present a new dataset, SEN12-WATER, along with a benchmark using a novel end-to-end Deep Learning (DL) framework for proactive drought-related analysis. The dataset, identified as a spatiotemporal datacube, integrates SAR polarization, elevation, slope, and multispectral optical bands. Our DL framework enables the analysis and estimation of water losses over time in reservoirs of interest, revealing significant insights into water dynamics for drought analysis by examining temporal changes in physical quantities such as water volume. Our methodology takes advantage of the multitemporal and multimodal characteristics of the proposed dataset, enabling robust generalization and advancing understanding of drought, contributing to climate change resilience and sustainable water resource management. The proposed framework involves, among the several components, speckle noise removal from SAR data, a water body segmentation through a U-Net architecture, the time series analysis, and the predictive capability of a Time-Distributed-Convolutional Neural Network (TD-CNN). Results are validated through ground truth data acquired on-ground via dedicated sensors and (tailored) metrics, such as Precision, Recall, Intersection over Union, Mean Squared Error, Structural Similarity Index Measure and Peak Signal-to-Noise Ratio. Data and code will be opened upon acceptance of the paper. Limited access can be granted during the review process upon request.", "sections": [{"title": "I. INTRODUCTION", "content": "CLIMATE changes are having an impact on the occurrence of extreme events, such as droughts and water scarcity, on one hand, and floods and landslides on the other. It is worth highlighting that drought and floods are two events with different dynamics developing on different timescales. In this work, it has been chosen to focus on drought conditions to provide clear evidence of climate change and its impact on the reduction of water bodies and the water scarcity.\nWater availability is becoming less predictable in many places in the world and, in some of them, droughts are exacerbating water scarcity, thus negatively impacting people's health and productivity and threatening sustainable development and biodiversity. In this context, it is crucial to locate water bodies and reservoirs, to observe their changes over time, to detect hydrological patterns (patterns and behaviors of water resources in a specific area) and their impact on changes in soil and water content, in order to monitor and predict the occurrence of such catastrophic events [1]. The first fundamental step in building a DL framework for accurately identifying water basins and performing detailed analysis, is having a suitable dataset available [2], [3]. To this end, satellite data and their processing can offer support and clear evidence of the changes occurring on Earth, providing the overall picture and gathering long-term data series to comprehend the consequences of these changes [4].\nFor these purposes, this article proposes a new multisource and multitemporal dataset that is unique in several aspects compared to other already available datasets, as discussed ahead. Moreover, in combination with the dataset, a novel end-to-end framework is presented, including as main internal blocks two different neural networks: one U-Net architecture for assessing water segmentation, and a Time Distributed (TD)- Convolutional Neural Network (CNN) fed with the output of the U-Net and able to accomplish the next frame prediction.\nThe objective is to offer a complete tool to policymakers and research community, with a specific dataset and a suitable framework together, able to allow estimation of water losses for reservoirs over a certain period. Thus, this study introduces several key contributions and novel aspects:\n\u2022 SEN12-WATER Dataset: introduction of a novel multisource and multitemporal dataset, SEN12-WATER, which combines SAR polarization, elevation, slope, and mul-tispectral optical bands. This dataset provides a com-prehensive spatiotemporal datacube for analyzing water bodies, which is unique compared to existing datasets.\n\u2022 End-to-End Deep Learning Framework: A new end-to-end Deep Learning (DL) framework is developed for the analysis and estimation of water losses over time. This framework includes advanced models such as a ResNet for speckle noise removal from Sentinel-1 (S1) images, a U-Net for water body segmentation, and a Time Distributed-Convolutional Neural Network (TD-CNN) for predicting future water masks.\n\u2022 Validation with Ground Truth Data: The results of the proposed framework are validated using appropriate Ground Truth data acquired on-ground via dedicated sensors or stations and tailored metrics, demonstrating the"}, {"title": "A. Related works", "content": "As highlighted in the previous section, droughts as a consequence of climate change are exacerbating water scarcity, impacting people's lives and threatening sustainable development. It has become crucial to predict water availability, losses and dynamics of reservoirs, in general. In this Section, SOTA analysis is carried on to verify which specific datasets have been made available, together with related algorithms for processing them. The description of what is proposed comes in the end, highlighting the differences, the novelties and suitability for the aimed objectives with respect to what by now available.\nFrom SOTA analysis, several datasets have been identified. A crucial requirement to assess climate change's impact on water basins is to have available temporal data sequences with suitable characteristics. Therefore, this aspect is carefully researched and verified. Table I shows the main features of these datasets used in related works to map the water presence through the employment of satellite images.\nIn particular Pekel et al. [10] propose a three million Landsat satellite images spanning 32 years, in order to quantify changes in global surface water at 30m resolution. However, this work relies only on optical data, which on the one hand can enhance the evaluation with the detailed information contained within each spectral band but, on the other hand, can be compromised in case of adverse climatic conditions, such as cloud coverage, which can easily occur within dense time series that follow the evolution of a reservoir over multiple years. Zhao et al. [6] introduce the UrbanSARFloods dataset, designed for flood mapping in both urban and open areas using S1 SLC-based SAR data. The dataset includes pre- and post-event SAR intensity and interferometric coherence imagery. It consists of 8879 512 \u00d7 512 pixel chips covering 807500km\u00b2 from 18 flood events across various continents.\nThe creation of the dataset involves both semi-automatic and manual labelling techniques. Semi-automatic labelling employed conventional remote sensing methods, including hierarchical split-based change detection for open flooded areas and thresholding on differential interferometric coherence for urban flood regions. Manual labelling was performed using high-resolution optical data to ensure precise annotation.\nFurthermore, regarding the applications of the dataset, UrbanSARFloods is intended to serve as a benchmark for evaluating state-of-the-art convolutional neural networks in the segmentation of flood areas. The dataset also highlights the challenges associated with urban flood detection, particularly due to data imbalance and the constraints of a relatively small dataset.\nA combination of SAR and optical data is proposed by Wieland et al. [8]. They introduced S1S2-Water, which is a global reference dataset for semantic segmentation of surface water bodies based on S1 and Sentinel-2 (S2) satellite images. The dataset consists of 65 pairs of S1 and S2 images with quality-checked binary water masks. Samples are drawn globally based on the S2 tile-grid (100km \u00d7 100km), considering predominant land cover and the availability of water bodies. Each sample is complemented with metadata and a digital elevation model (DEM) raster from the Copernicus DEM. The images were acquired between May 21, 2018, and November 26, 2020, covering almost all months of the year, with no"}, {"title": "", "content": "samples available for December. In this work, all experiments are carried out using a U-Net architecture, applied separately to Sentinel-1 and Sentinel-2 data without any data fusion. Sentinel-2 images serve as the initial dataset for annotating water masks. The annotation process is semi-automated, where water bodies are first identified using a threshold procedure based on the Normalized Difference Water Index (NDWI).\nThis is another critical aspect, as the use of classical threshold-based indices such as NDWI can help in determining the presence of water but, as outlined in [11], the arbitrariness with which this threshold is set can generate different results, depending on the proportions of subpixel water/non-water components. In a similar way, other works develop a semi-automatic procedures based threshold and classical indices [9] or assisted by visual interpretation [5]. Furthermore, Tottrup et al. discuss the creation and application of a dataset for surface water mapping using satellite observations from Sentinel-1, Sentinel-2, and Landsat-8 [7]. The dataset includes images acquired from July 2018 to June 2020 over diverse test sites with varying topographies and water bodies. The study utilized ancillary datasets such as Digital Elevation Models (DEMs) and pre-existing surface water maps, ensuring they were publicly available. The application involved implementing workflows in Google Earth Engine to facilitate transferabil-ity and reproducibility. One approach combined histogram-thresholding and edge-detection methods to estimate monthly surface water extent from cloud-free satellite scenes, creating binary land and water maps for each scene. This method used classical indices like the Normalized Difference Water Index (NDWI) for optical scenes and specific bands combination for SAR scene.\nIn recent years, advancements in remote sensing technolo-gies have revolutionized waterbody detection and monitoring. Xiang et al. [12] introduce Dense Pyramid Pooling Module (DensePPM) for enhancing water body identification in aerial images through semantic segmentation networks, while Xia et al. [13] propose a dense skip connections network with multi-scale features fusion and attention mechanism to effectively identify water areas amidst complex backgrounds. Hertel et al. [14] compare variational inference-based Bayesian CNN (BCNN) with Monte Carlo dropout network (MCDN) for deriving water extent estimates, emphasizing the importance of reliable uncertainty quantification. Furthermore, Gonz\u00e0lez et al. [15] introduce an innovative approach centered around a Match-up Database (MDB) to simplify validation analysis of satellite-derived water products, enhancing data validation efficiency. Ma et al. [16] develop a local feature search network (DFSNet) with discarding attention module (DAM) for accurate water body segmentation, showcasing significant improve-ments in segmentation accuracy. Hou et al. [17] expand spatio-temporal dynamics measurement of water storage in lakes and reservoirs using high-resolution satellite and altimetry data, enabling global freshwater assessment. Yuan et al. [18] focus on monitoring water levels in the Qingcaosha estuarine reservoir using Landsat-8 and S2 images, demonstrating high accuracy and reliability in satellite-derived results. Li et al. [19] introduce the GLH-water dataset for global surface water detection, showcasing its strong generalization and practical utility. Lastly, Zhong et al. [20] propose NT-Net, an end-to-end semantic segmentation network, for automatic lake water extraction from remote sensing images, addressing challenges and improving extraction coherence and comprehensiveness. These studies collectively contribute to advancing water resource management and monitoring on a global scale."}, {"title": "II. DATA", "content": "Our multimodal and multitemporal dataset, built upon previous work [21], captures all complementary characteristics necessary for mapping water bodies effectively [22], further enhanced by incorporating information on slope and elevation [8]. Our dataset follows the DiRS properties (diversity, richness, and scalability), which are introduced in the recent guideline for building remote sensing benchmark datasets by Long et al. [23]. In Table II, the definition of each property is outlined together with the motivation behind why the aforementioned dataset fulfils these criteria.\nWhat sets this dataset apart is its innovative fusion of S1 (ESA: S1), S2 (ESA: Sentinel-2), slope, and elevation data from Shuttle Radar Topography Mission (SRTM, [24]). These important characteristics and information will represent a valuable step forward in the following training of the introduced models. The presence of S1 and S2 data enables comprehensive analysis in all atmospheric conditions, with S1 SAR data, and detailed insights with S2 high-resolution multispectral data. Furthermore, the additional information on slope and elevation will further improve the ability to identify the water basins for each area of interest [8]."}, {"title": "III. METHODS", "content": "The proposed approach rotates around the analysis of multisource temporal sequences derived from our SEN12-WATER dataset. Our end-to-end model firstly create a segmentation mask, to detect and outline water content from the given image, next it forecast the next frame, and finally it measure the fluctuations in water content, allowing proactive measures against potential drought-related issues.\nTo effectively perform these tasks, the first step is to accurately identify and track water basins over time, utilizing the comprehensive data collection previously discussed. Before segmenting the water bodies, it was necessary to complete several preprocessing steps, particularly focusing on reducing speckle noise in the SAR data. Once the data was preprocessed, segmentation was applied to the entire dataset to identify the water basins. As an improvement to the approach presented in [25], a fully AI-driven method"}, {"title": "A. Pre-processing", "content": "As part of our pre-processing component, despeckling techniques play a crucial role in the accurate identification of water bodies [26]. The use of despeckling methodologies significantly improves the quality and usability of the dataset for mapping and monitoring water basins. The DL methodology for speckle filtering derives from the one presented by Sebastianelli et al. [27], appositely adapted to cope with our dataset. It consists of a ResNet model architecture where speckle is subtracted from the input image through a skip connection and a subtraction layer. This choice was driven mainly because: 1) data and code are open-access and well details (including tutorials and 2) the method is specifically designed to work with the same S1-GRD data used in our study, thus allowing to keep SAR statistical proprieties unchanged [27], achieved because of the residual nature and of the following loss function:\n$L_{SPE} = L_{MSE} + L_{SSIM} + C_{TV}$\n$=\\alpha_1 \\frac{1}{N} \\sum_{i=1}^{N} [y_i - \\hat{y_i}]^2$\n$+ \\beta_1 \\frac{(2\\mu_y\\mu_{\\hat{y}} + C_1)(2\\sigma_{y\\hat{y}} + C_2)}{(\\mu_y^2 + \\mu_{\\hat{y}}^2 + C_1) (\\sigma_y^2 + \\sigma_{\\hat{y}}^2 + C_2)}$\n$+ \\gamma_1 \\sum_{w=1}^{W} \\sum_{h=1}^{H} (y_{w+1,h} - y_{w,h})^2 + (y_{w,h+1} - y_{w,h})^2$\n(1)\nwhere y is the predicted speckle filtered and $\\hat{y}$ is the ground truth image respectively; this loss includes the Euclidean distance, the SSIM\u00b9 and TV (Total Variation) to better preserve the structural similarity, the statistics and the correct amount of smoothing of the result image. Parameters $\\alpha_1$, $\\beta_1$ and $\\gamma_1$ have been fine tuned for our task\u00b2."}, {"title": "B. Segmentation", "content": "The second component, used to compute the water mask, derives from the popular U-Net, commonly used for semantic segmentation tasks in computer vision. U-Net derives its name from its characteristic U-shaped architecture, which consists of a contracting path followed by an expansive path. This architecture enables the network to capture both global context and fine-grained details, making it particularly effective for tasks such as image segmentation [28]. Another notable aspect of this implementation is the inclusion of skip connections, which directly connect corresponding layers in the contracting and expansive paths. These skip connections facilitate the flow of fine-grained details from early layers to later layers, mitigating the issue of information loss commonly encountered in deep neural networks.\nOur Python implementation is based on Keras-TensorFlow library. It has been training via a combination of the binary cross-entropy loss function, suitable for binary segmentation tasks, and the GapLoss function, specifically designed for semantic segmentation tasks, particularly in remote sensing applications. It aims to address the issue of class imbalance by focusing on the gaps between predicted and ground truth segments [29]. The resulting loss is defined by:\n$L_{SEG} = \\alpha_2L_{BCE} + \\beta_2L_{GAP}$\n$= -\\alpha_2\\frac{1}{N} \\sum_{i=1}^{N}[y_i log(\\hat{y_i}) + (1 - y_i) log(1 - \\hat{y_i})]$\n$+ \\beta_2\\sum_{i=1}^{N}(\\frac{(y_i - \\hat{y_i})^2}{(y_i + \\hat{y_i})^2 + \\epsilon})$\n(2)\nwhere $y_i$ is the ground truth label, $\\hat{y_i}$ is the predicted probability, and N is the number of pixels. Values for $\\alpha_2$ and $\\beta_2$ have been fine-tuned\u00b3. The use of both losses allows to benefit from the robust classification capabilities of Cross-Entropy Loss and the precise boundary delineation of GapLoss. This last point is extremely important for out method, since the correct identification, at pixel-level, of water impacts on the water volume computation as detailed in the next sessions."}, {"title": "C. Next-frame prediction task", "content": "The last component of our method, aims at forecasting the water mask in a next-frame prediction setting. Specifically, this module forecast the water mask two months ahead using data gathered from the preceding 14 months. These initial experiments serve as a foundational step in evaluating the introduced dataset and will serve as a basis for further exploration in future research. Three DL frameworks are investigated in our study: 1) ConvLSTM, 2) Bidirectional ConvLSTM, and 3) a Time Distributed CNN.\nBeyond achieving accurate predictions, next-frame prediction holds practical significance. Being able to predict changes in water levels two months in advance is crucial for various applications, particularly in agriculture. For instance, anticipating water scarcity can help farmers plan their irrigation schedules and crop selection, potentially mitigating the adverse impacts of droughts on crop yields. Accurate water level predictions can also aid in water resource management, enabling authorities to make informed decisions about water allocation during critical periods.\nThe loss function that regulates this component is composed of three losses:\n$L_{NEXT} = \\alpha_3L_{MSE} + \\beta_3L_{SSIM} + \\gamma_3L_{TSL}$\n$= \\alpha_3L_{MSE} + \\beta_3L_{SSIM}$\n$+ \\gamma_3\\frac{1}{T-1} \\sum_{t=1}^{T-1} (y_{t+1} - y_t)^2$\n(3)\nwhere $y_i$ is the ground truth label, $\\hat{y_t}$ is the predicted probability, and T is the size of the forecast horizon. Values for $\\alpha_3$, $\\beta_3$ and $\\gamma_3$ have been fine-tuned 4. The combination of the MSE and SSIM helps in not only minimising the pixel-wise differences but also preserving the structural information of the frames. Moreover, to incorporate temporal information into the loss function for next-frame prediction, we included the Temporal Smoothness Loss (TSL) . This loss encourages the predicted frames to be temporally consistent with each other, and we want that miss-prediction of water basins."}, {"title": "D. Time-series analysis", "content": "Time-series analysis plays a pivotal role in understanding temporal patterns within datasets, offering invaluable insights into trends, fluctuations, and underlying dynamics over time. In this context, the utilisation of time-series techniques becomes particularly pertinent in elucidating the evolving nature of environmental phenomena, such as water dynamics.\nWe presented the extraction of water masks from the dataset and the forecast of these, now by analysing these sequences, we aim to discern discernible trends in the fluctuating pixel count of water over time. The ambition is to discern whether variations in the volume of water stem from seasonal trends or potentially signify broader shifts attributable to climate change. This effort not only underscores the importance of robust time-series methodologies in environmental analysis but also underscores the significance of discerning nuanced patterns in water dynamics for informed decision-making and environmental management.\nFocusing on what is proposed here, the water volume variation over time is obtained by properly combining the water masks with a DEM $V_{total} = \\sum(h_{i,j} \\cdot W_{i,j} \\cdot A)$. Where: $h_{i,j}$ is the height of the basin at pixel (i, j) extracted from the DEM, $W_{i,j}$ is the water mask value at pixel (i, j) (0 if no water, 1 if water is present) and A is the total area of a single pixel (100m\u00b2).\nIn support of the proposed methodology, the Appendix provides a separate study that validates the capability to extract water volumes from satellite data. Specifically, this additional study compares measurements obtained through satellite data with ground measurements trough a sensors network."}, {"title": "IV. RESULTS", "content": "This section presents the results of the proposed methodology on the SEN12-WATER dataset, establishing the first benchmark of the dataset.\nDespite the proposed method has an end-to-end structure, it was found beneficial for the matter of scientific discussion to retrieve the performance of the main sub-modules. Regarding speckle filtering, the results are comparable with the one reported in Sebastianelli et Al. [27] and to not overburden the paper, are not reported here, but they can be found on our GitHub page.\na) Results for Segmentation: to evaluate segmentation performances, they were used standard accuracy metrics including Intersection over Union (IoU) score, Precision, and Recall [30]. Performance metrics are computed as weighted average, where the support, which represents the number of true instances for each label, is utilised as weight. By giving greater importance to labels with higher support, this approach addresses the issue of dataset imbalance. Results presented in"}, {"title": "V. DISCUSSION", "content": "The SEN12-WATER dataset stands out for its innovative integration of multisource and multitemporal data, combining Sentinel-1 SAR, Sentinel-2 multispectral optical data, along with slope and elevation information. This combination allows for effective water body monitoring under various environmental conditions, overcoming limitations such as cloud cover that affect optical data. The inclusion of both radar data, unaffected by weather, and high-resolution optical data enhances the dataset's robustness for analyzing seasonal and long-term water dynamics, which is crucial for understanding the impacts of climate change on water resources. Despite its advantages, the SEN12-WATER dataset has some limitations. It is primarily focused on Italy and Spain, which restricts its applicability to regions with different environmental and climatic conditions. Expanding the dataset to include diverse geographical areas, especially those prone to droughts or facing different water management challenges, could address this limitation. Additionally, while the dataset provides bi-monthly samples, critical changes in water dynamics may occur within shorter timescales. Increasing the sampling frequency, particularly during critical periods, would offer a more detailed understanding of these dynamics.\nAlthough the integration of SAR data helps mitigate cloud cover issues, there may still be periods with data gaps due to other operational limitations. To enhance data completeness, integrating additional satellite sources or employing synthetic data generation techniques could be beneficial.\nFurthermore, the proposed methodology, leveraging advanced DL techniques such as U-Net for water body segmentation, enhances the accuracy of water detection and segmentation by using a comprehensive dataset that integrates multiple data sources. Moreover, the use of a ResNet model for speckle noise removal from SAR images improves the quality of the radar data, which is crucial for accurate water body segmentation. Additionally, the combination of segmentation and prediction models (such as the TD-CNN), provides a robust framework for both current analysis and future water dynamics forecasting, making it valuable for proactive drought management and water resource planning. Additionally, the analysis of water volume variations over time represents a truly significant contribution to the scientific community and decision-makers. In fact, it serves as a valuable tool for addressing issues related to water resource management, such as drought. However, the proposed methodology, while robust, has some limitations. The models are specifically trained on the SEN12-WATER dataset, which may limit their generalizability to other datasets or regions. To address this, implementing transfer learning techniques or training on a more different set of datasets could enhance the models' adaptability to various conditions. Additionally, the accuracy of the methodology depends heavily on the quality of the input data. Any noise, errors, or inconsistencies can adversely affect the model outputs. Therefore, improving data preprocessing-through advanced noise reduction techniques or data augmentation-could help mitigate these issues."}, {"title": "VI. CONCLUSION", "content": "This study presents SEN12-WATER, a novel dataset and an end-to-end DL framework for the time series analysis of water bodies. The proposed dataset is a unique spatiotemporal datacube that combines radar polarization, elevation, slope, and multispectral optical bands, providing comprehensive data for the assessment of water dynamics. The methodology integrates advanced models, including a ResNet for speckle noise removal, a U-Net for water body segmentation, and a TD-CNN for future water mask prediction. The findings contribute significantly to climate change resilience and sustainable water resource management by providing actionable insights for policymakers and stakeholders. The detailed analysis of water dynamics and the ability to predict future water conditions support informed decision-making and proactive management of water resources.\nIn conclusion, the results presented in this study not only demonstrate the effectiveness of the proposed framework in water body segmentation and prediction but also underscore its broader applicability in environmental monitoring. The ability to accurately predict water availability two months in advance represents a significant advancement in the field, offering critical support to policymakers and stakeholders in managing water resources more effectively. This underscores the utility of this task, demonstrating its relevance and practical application in areas such as agriculture and resource management, where early awareness of water level changes can significantly influence planning and decision-making."}, {"title": "VII. APPENDIX A", "content": "This appendix presents an additional study that validates the retrieval on water volume presented in the main body of the article. Specifically, this study focuses on the Olivo Dam over the time period that spans from 2016 to 2018. An example of the satellite acquisition on the Olivo dam is reported in Fig. 5. The surface of the water, from S2 data, after segmenting the water mask as described in Section III-B, has been computed via $A_{total} = \\sum(W_{i,j} \\cdot A)$. Where, $w_{ij}$ is the water mask value at pixel (i, j) (0 if no water, 1 if water is present) and A is the total area of a single pixel (100m\u00b2).\nThe theoretical data of reservoir volumes and associated areas were derived from a morphological analysis of the basin. The complete morphometric information of a hydrographic basin requires an analysis of the distribution of elementary areas that make up the basin in relation to the progression of contour lines that delimit these areas. This involves relating area information with the altimetric characteristics of the basin. The altimetric information is essential for determining various parameters that influence the kinematic characteristics of the hydrographic network, contributing to the accuracy of hydrological modeling and water resource management."}]}