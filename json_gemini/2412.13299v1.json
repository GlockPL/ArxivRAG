{"title": "IN-CONTEXT LEARNING FOR MEDICAL IMAGE SEGMENTATION", "authors": ["Eichi Takaya", "Shinnosuke Yamamoto"], "abstract": "Annotation of medical images, such as MRI and CT scans, is crucial for evaluating treatment efficacy and planning radiotherapy. However, the extensive workload of medical professionals limits their ability to annotate large image datasets, posing a bottleneck for AI applications in medical imaging. To address this, we propose In-context Cascade Segmentation (ICS), a novel method that minimizes annotation requirements while achieving high segmentation accuracy for sequential medical images. ICS builds on the UniverSeg framework, which performs few-shot segmentation using support images without additional training. By iteratively adding the inference results of each slice to the support set, ICS propagates information forward and backward through the sequence, ensuring inter-slice consistency. We evaluate the proposed method on the HVSMR dataset, which includes segmentation tasks for eight cardiac regions. Experimental results demonstrate that ICS significantly improves segmentation performance in complex anatomical regions, particularly in maintaining boundary consistency across slices, compared to baseline methods. The study also highlights the impact of the number and position of initial support slices on segmentation accuracy. ICS offers a promising solution for reducing annotation burdens while delivering robust segmentation results, paving the way for its broader adoption in clinical and research applications.", "sections": [{"title": "1 Introduction", "content": "Research on AI applications in healthcare, especially automatic segmentation in medical imaging, has been actively pursued by numerous research institutions alongside advancements in deep learning technology. Segmentation from sequential images, such as CT and MRI scans, is essential for planning surgeries and radiotherapy, as well as assessing the effectiveness of cancer treatments. There is a strong demand for automating this process to reduce the burden of human effort and associated costs.\nFurthermore, in the development of AI for medical image diagnosis assistance, it is often necessary to define regions of interest (ROIs) for lesion areas during the construction of training datasets. For example, ROIs are required for cropping in dimension reduction in classification tasks and for generating radiomics features . Moreover, it has recently been pointed out that performing lesion classification, such as distinguishing between benign and malignant conditions, on a pixel-by-pixel basis through segmentation techniques can enhance classification performance.\nVarious deep neural network architectures have been proposed, starting with U-Net , and in recent years, models based on Vision Transformer have become mainstream . Pretrained models on large-scale datasets such as ImageNet and RadImageNet, as well as foundation models capable of zero-shot inference , have also been introduced. Neural network-based approaches are becoming increasingly large-scale and are advancing in their ability to generalize across various segmentation tasks. However, challenges remain in addressing domain shifts (differences in patient populations or imaging protocols), modality shifts (variations between imaging modalities such as CT and MRI), and site shifts (differences in imaging equipment or procedures across institutions). In addition, there are limitations in the generalizability of these methods when dealing with rare diseases . As a result, when attempting to automate specific segmentation tasks, it often becomes necessary to annotate images from scratch. Therefore, establishing a mechanism to reduce the human cost of annotating entire sequences of images from the ground up is essential.\nThis study aims to establish a system that minimizes the cost of annotating sequential images. To reduce the annotation load per case, we propose a sequential segmentation method based on in-context learning. Specifically, we utilize UniverSeg, a framework for few-shot segmentation proposed by Butoi et al [20]. We repeatedly input a minimal set of initial labels as support images into UniverSeg and add the outputted segmentation masks to the support set. We have named this method In-context cascade segmentation (ICS). We evaluated the proposed method using segmentation tasks for eight cardiac regions included in the HVSMR dataset [21] and discussed its effectiveness and characteristics.\nThe following sections are organized as follows: Section 2 provides an overview of related research on medical image segmentation, as well as discussions on in-context learning and semi-supervised learning. Section 3 clarifies the problem setting and details the proposed method. Section 4 presents the experimental details and results based on HVSMR datasets. Section 5 discusses the findings, and Section 6 concludes with future directions and challenges."}, {"title": "2 Related Works", "content": ""}, {"title": "2.1 Medical Image Segmentation", "content": "Before the widespread adoption of deep learning, medical image segmentation was mainly performed using traditional machine learning techniques, employing both unsupervised and supervised approaches . In unsupervised approaches, clustering and region-based segmentation methods, such as K-means and watershed algorithms, were commonly used. These methods segment regions based on statistical properties of pixels or voxels without requiring prior labeling. Supervised approaches typically involved manually designed hand-crafted features as input, using models such as support vector machines (SVMs) and random forests for pixel-wise classification . Although these methods achieved success in certain tasks, their accuracy and generalizability were limited.\nFollowing the study by Ciresan et al. , deep neural networks enabled automatic feature learning from images, facilitating segmentation. Subsequently, U-Net was introduced and became a standard approach in medical image segmentation. U-Net utilizes an encoder-decoder structure and skip connections to effectively capture both local and global features, achieving high-precision segmentation. In recent years, methods based on Transformers and 3D segmentation techniques have been proposed, enabling high-accuracy segmentation for more complex structures and different modalities. Additionally, large-scale medical image segmentation models, such as MedSAM based on Segment anything model (SAM), have emerged, allowing for high-accuracy results from minimal annotations. The UniverSeg model used in our study is also a type of large-scale medical image segmentation model."}, {"title": "2.2 In-context Learning", "content": "In-context learning is a concept originally introduced in large language models (LLMs), where a pre-trained model can immediately make predictions for new tasks based on examples provided within the context, without requiring additional training. In GPT-3 , where the term in-context learning was first used, it was shown that merely a few examples are sufficient for the model to perform tasks based on the new context. Furthermore, Oswald et al. theoretically demonstrated that the mechanism enabling Transformers to perform in-context learning is similar to gradient descent.\nThe concept of in-context learning is also being applied to image recognition . In UniverSeg , labeled images (support set) are provided as examples to perform segmentation on a new query image. In this study, we further develop this approach of in-context learning and apply it as \"In-context Self-learning,\" where inference results are sequentially utilized."}, {"title": "2.3 Semi-supervised Learning", "content": "Semi-supervised learning is a methodology for leveraging unlabeled data when only a limited amount of labeled data is available. In medical image segmentation, where labeling costs are particularly high, semi-supervised learning is frequently employed. Major approaches include self-training , co-training , and graph-based methods , each of which has been applied to medical image segmentation. In self-training, the model re-trains itself using labels predicted from unlabeled data. Co-training involves two different classifiers complementing each other as they learn from unlabeled data. Graph-based methods represent data as a graph structure and estimate labels through label propagation."}, {"title": "3 Methods", "content": ""}, {"title": "3.1 Problem Definition", "content": "Given a volume dataset V = {slice1, slice2,..., slicen} consisting of n slices, we assume that m of these slices are available as a labeled support set. The support set is defined as follows:\nS = {(slicei\u2081, labeli\u2081), (slice\u017c2, labeli\u2082), . . ., (sliceim, labelim)},\nwhere labeli, represents the segmentation mask for slicei.\nThe objective of this study is to perform segmentation on the remaining n m unlabeled slices using the support set S, and to estimate the segmentation mask Mk for each unlabeled slice slicek. Formally, this can be expressed as follows:\nSpecifically, using a segmentation model f (e.g., UniverSeg), the mask Mk for any query slice slicek is estimated as:\nMk = f(slicek, S), for k \u2208 {1,2,..., n} \\ {11, 12, ..., im}."}, {"title": "3.2 UniverSeg", "content": "UniverSeg is a general-purpose model designed to achieve few-shot segmentation in medical imaging. It has been trained on 53 datasets, comprising more than 22,000 examinations that include CT and MR images. Without any additional retraining, this model can quickly adapt to new segmentation tasks given only a few support sets. Structurally, UniverSeg is based on an encoder-decoder architecture and incorporates a \"CrossBlock\" mechanism for bidirectional feature transmission between query images and support set images. Similar to U-Net [citation], the encoder extracts features at multiple resolutions, and the decoder generates segmentation masks from these features. Pre-trained on a large-scale medical image dataset called MegaMedical, UniverSeg demonstrates the ability to adapt to various tasks and different modalities. In this study, we provide a continuous set of labeled slices as the support set and perform inference on the remaining slices . However, in the original UniverSeg approach, each slice is processed independently, making it difficult to ensure consistency across adjacent slices. To address this issue, we introduce a new method described next."}, {"title": "3.3 In-context Cascade Segmentation (ICS)", "content": "This study proposes In-context Cascade Segmentation (ICS), a method based on UniverSeg that performs sequential segmentation across an entire set of consecutive slices . ICS achieves consistent segmentation by using the inference results of each slice as part of the support set for the next slice, thereby propagating inference results both forward and backward through the sequence.\nAlthough the details are described in Algorithm 1, the general flow of ICS is as follows:\n1. Initialization of the Support Set\nTo initiate segmentation, we first set a small number of labeled slices near the center or anatomically important slices as the initial support set.\n2. Bidirectional Sequential Inference\nStarting from the initial support set, we apply the pre-trained UniverSeg model (trained on large-scale datasets) to perform inference in both the forward (rightward) and backward (leftward) directions across all slices. After completing the inference for each slice, we add the resulting prediction to the support set of the next slice, thereby sequentially propagating the inference results. Note that the support set is always maintained at the most recent m slices.\nDuring this process, data augmentation is applied to the support images.\nBy adopting this approach, ICS improves segmentation accuracy across a continuous sequence of slices, ensuring consistency particularly at boundaries and in fine structures. Moreover, since inference is performed sequentially, the results obtained for each slice can be leveraged for subsequent slices, enabling continuous segmentation throughout the entire volume. As a result, ICS is expected to improve inter-slice consistency and accuracy compared to a direct application of UniverSeg."}, {"title": "4 Experiments", "content": "In this section, we conduct experiments using the HVSMR dataset to verify the effectiveness and characteristics of the proposed method. We describe the dataset and experimental settings, the evaluation metrics, and the implementation details."}, {"title": "4.1 Dataset", "content": "HVSMR [citation] consists of 60 cardiovascular MRI (CMR) scans obtained at Boston Children's Hospital, accompanied by segmentation masks for four cardiac chambers and four great vessels. The ground truth masks were created by combining manual annotations with automated segmentation by a 3D-UNet, followed by human revisions. Each case includes various heart diseases and surgical histories, reflecting diverse cardiac anatomical structures across patients.\nSince this study does not involve parameter tuning through training, all cases were used to evaluate the proposed method. In addition, each of the eight anatomical regions was treated as a separate dataset. As a preprocessing step, any slices that did not contain the region of interest (i.e., no annotated labels) were removed."}, {"title": "4.2 Experimental Settings", "content": "To examine the effectiveness and characteristics of the proposed method, we conducted the following three evaluations:\nComparison with Baseline Methods\nAs a baseline, we used the conventional UniverSeg. Adopting the same initial labels and augmentation settings as the proposed method, we performed inference on all slices without in-context learning.\nEffect of the Number of Initial Labels\nThe number m of initial labeled slices in the proposed method can be chosen arbitrarily, so we investigated how this choice affects the performance. We varied m from 1 to 5."}, {"title": "4.3 Evaluation Metrics", "content": "We used the Dice similarity coefficient (DSC), defined by the following equation, as the performance metric for segmentation:\nDSC = \\frac{2 \\cdot TP}{2TP + FP + FN}\nHere, TP (True Positive), FP (False Positive), TN (True Negative), and FN (False Negative) were calculated based on the predicted results and the ground truth labels at each pixel."}, {"title": "4.4 Implementation", "content": "All implementations of the proposed method were carried out using Python 3.10.8. For the UniverSeg model, we employed the publicly available pre-trained model from the repository provided by Butoi et al. [20]. Computations were performed on a machine equipped with an Intel(R) Core(TM) i9-10940X CPU (3.30GHz) and a Quadro RTX 8000 GPU (48GB memory)."}, {"title": "5 Results", "content": "First, the comparison results with the baseline method are shown in Figure 3 and Table 1. From the table, ICS demonstrated significantly higher DSC (p<0.05) than the baseline method in the LA, RA, AO, PA, and SVC regions. On the other hand, no significant differences were observed for the LV, RV, and IVC regions.\nFigure 4 shows an example in which ICS significantly outperformed the baseline method for the PA region of Patient 32. With the baseline method, the target region was not captured adequately in response to fine structures and positional changes, resulting in discontinuous predictions and large missing areas. In contrast, ICS consistently captured the target region across the entire sequence of slices and produced stable masks in each slice. On the other hand, Figure 5 shows a case where the baseline method outperformed ICS for the LV region of the same patient. As we move toward the right side, the anatomical features change, and while the baseline method sometimes exhibited noisy predictions, there were certain slices where it delineated the region more accurately than ICS. Meanwhile, although ICS produced relatively stable masks, it tended to over-segment the target region, resulting in a higher number of false positives overall."}, {"title": "6 Discussion", "content": "In this study, we conducted three comparative experiments to evaluate the effectiveness of the proposed method, In-context Cascade Segmentation (ICS). Based on the results, we provide the following discussion and subsequently address the limitations of the study.\nComparison with the Baseline Method\nICS demonstrated significantly higher DSC values compared to the baseline method (UniverSeg) in the regions of LA, RA, AO, PA, and SVC (Table 1). Particularly in PA, ICS ensured consistency across consecutive slices and accurately captured anatomically complex structures, as confirmed in Figure 4. On the other hand, no significant differences were observed in LV and IVC, with ICS exhibiting a tendency toward over-segmentation in LV, resulting in an increase in false positives (Figure 5). Overall, ICS tended to overestimate the region of interest, whereas the baseline method underestimated it. Such tendencies have also been reported in self-training-based methods , and this study suggests that similar behavior is present in the proposed method that replaces self-training with in-context learning. To address this tendency and facilitate more precise segmentation, it is necessary to introduce constraints during the support set updates, such as considering the confidence of inference results.\nEffect of the Number of Initial Support Slices\nIn the experiment varying the number of initial support slices m, most regions showed an improvement in DSC as m increased (Figure 7). Particularly when a sufficient number of support slices were provided, ICS achieved stable segmentation results. This trend is consistent with observations from the original UniverSeg article [20]. However, in terms of computational cost, the increase in inference time and, specifically, GPU memory consumption with a higher number of support slices raises concerns. These results suggest that selecting an appropriate number of initial support slices is crucial in situations with limited computational resources. Alternatively, model distillation could be employed to optimize the efficiency of the UniverSeg model itself, alongside other strategies for improving computational efficiency.\nEffect of the Position of Initial Support Slices\nThe experiment varying the position of the initial support slices revealed that the position has a significant impact on segmentation accuracy. The DSC plot for each slice in Figure 6 shows a trend where the deviation from the ground truth increases as the distance from the initial position grows. While this suggests that the initial position should ideally be set at the center of the region of interest, it is noteworthy that this is not necessarily the case for all anatomical regions, which is an intriguing finding.\nFuture developments should focus on establishing methods to determine appropriate initial slices before annotation. This challenge aligns with the cold start problem in active learning , and various approaches, such as clustering-based methods, could potentially be leveraged to address it.\nLimitation\nThe limitations of this study are outlined in two points. The first limitation is the assumption that all volumes, including the boundary slices, are labeled. In real-world data, slices that do not contain the region of interest may be present, necessitating a mechanism to appropriately stop label propagation at such slices. The second limitation is the lack of validation datasets. UniverSeg utilizes a large portion of publicly available datasets. To prevent data leakage, it was necessary to rely on the limited number of open datasets that were not used for pretraining. Consequently, this study was effectively restricted to using only the HVSMR dataset. Future work should include in-house datasets and extend the evaluation to various modalities, such as CT and ultrasound, to further validate the method."}, {"title": "7 Conclusion", "content": "This study proposed the In-context Cascade Segmentation (ICS) method to improve segmentation performance in sequential medical images with minimal annotations. By leveraging the UniverSeg framework, ICS sequentially updates its support set using inference results, propagating segmentation information across slices in both forward and backward directions. Through experiments on the HVSMR dataset, ICS demonstrated significant improvements over the baseline method in several anatomical regions, particularly in ensuring inter-slice consistency and accurately capturing complex structures.\nThe results highlighted that ICS performs well when a sufficient number of initial support slices are provided and that the position of these slices significantly impacts the segmentation accuracy. However, challenges such as over-segmentation in certain regions, the computational cost associated with a large number of support slices, and the need for effective initial slice selection were also identified. These findings suggest several avenues for future work, including the optimization of support set updates, model efficiency improvements, and the development of automated strategies for selecting optimal initial slices.\nIn conclusion, ICS represents a promising step toward reducing annotation burdens in medical image segmentation while maintaining high accuracy and consistency. Further validation using diverse datasets and imaging modalities will help establish its robustness and broaden its applicability in clinical and research settings."}]}