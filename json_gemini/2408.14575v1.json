{"title": "EVINCE: Optimizing Adversarial LLM Dialogues via Conditional Statistics and Information Theory", "authors": ["Edward Y. Chang"], "abstract": "This paper introduces EVINCE (Entropy and Variation IN Conditional Exchanges), a dialogue framework advancing Artificial General Intelligence (AGI) by enhancing versatility, adaptivity, and reasoning in large language models (LLMs). Leveraging adversarial debate and a novel dual entropy theory, EVINCE improves prediction accuracy, robustness, and stability in LLMs by integrating statistical modeling, information theory, and machine learning to balance diverse perspective exploration with strong prior exploitation. The framework's effectiveness is demonstrated through consistent convergence of information-theoretic metrics, particularly improved mutual information, fostering productive LLM collaboration. We apply EVINCE to healthcare, showing improved disease diagnosis, and discuss its broader implications for decision-making across domains. This work provides theoretical foundations and empirical validation for EVINCE, paving the way for advancements in LLM collaboration and AGI development.", "sections": [{"title": "1 Introduction", "content": "The pursuit of Artificial General Intelligence (AGI) remains a central goal of AI research. We propose a paradigm shift in this quest: utilizing multiple Large Language Models (LLMs) engaged in synergistic dialogues as a crucial step towards AGI. This approach, we contend, addresses key limitations of current AI systems and provides a novel pathway to more robust, versatile, and capable artificial intelligence. Specifically, our work targets three core AGI characteristics: versatility, adaptivity, and reasoning capability.\nCurrent LLMs, despite their remarkable capabilities, face significant challenges, including hallucination (generating false or nonsensical information), bias (reflecting and potentially amplifying societal prejudices), and limited reasoning (difficulties in complex problem-solving and logical inference).\nWe posit that multi-agent dialogue systems offer a promising avenue to address these challenges. By fostering diversity and debate among LLMs, these systems can mitigate biases and promote enhanced reasoning capabilities. Furthermore, the iterative nature of multi-round dialogues allows for continuous context enrichment, enabling LLMs to access more precise information and formulate more accurate responses, thus reducing the occurrence of hallucinations.\nOur previous work, SocraSynth (Chang, 2023a), addresses LLM limitations through structured multi-agent dialogues. By leveraging both adversarial and collaborative interactions between LLMs, SocraSynth demonstrates quantifiable improvements across various domains. In healthcare, it achieves a 5% improvement in diagnostic accuracy (Chang and et al., 2023), while in news analysis, it identifies and explains biases in articles (Chang, 2024c). These advancements showcase enhanced versatility, adaptivity, and reasoning capability-key AGI characteristics.\nSocraSynth's adversarial component promotes the exploration of diverse perspectives, while its collaborative component fosters rigorous reasoning to reach well-reasoned conclusions. This synergy has yielded measurable gains beyond healthcare and bias mitigation, extending to geopolitical analysis (Chang, 2023b), corporate planning (Tsao, 2023), investment banking (Chang, 2024b), and emotional behavior modeling (Chang, 2024a). These results demonstrate SocraSynth's effectiveness in mitigating LLM limitations and achieving substantial performance improvements across various applications, highlighting its potential for advancing towards AGI's generalized problem-solving capabilities.\nAlthough SocraSynth has demonstrated effectiveness, it relies on \u201ccontentiousness\u201d as a qualitative measure to moderate the linguistic behaviors of participating LLMs. For instance, a high"}, {"title": "2 Related Work", "content": "The core objective of adversarial debate, as embodied in SocraSynth with EVINCE, is to foster diverse opinions and challenge assumptions, ultimately leading to more comprehensive and informed decision-making. This contrasts with traditional ensemble learning methods, which prioritize error diversity for improved accuracy. This section surveys ensemble learning and adversarial learning, highlighting the unique aspects of EVINCE and its theoretical underpinnings."}, {"title": "2.1 Ensemble Learning", "content": "Ensemble methods, such as Bagging (Breiman, 1996), Boosting (Freund and Schapire, 1997), and Mixtures of Experts (Jacobs et al., 1991), traditionally aim to enhance machine learning performance by combining predictions from multiple models to achieve error diversity. Similarly, early LLM debate frameworks, e.g., (Michael et al., 2023; Chan et al., 2023; Liang et al., 2023; Du et al., 2023) have focused primarily on improving answer accuracy rather than fostering a comprehensive exploration of information for critical decision-making.\nSocraSynth distinguishes itself from traditional ensemble methods by prioritizing the generation of diverse predictions over the mere avoidance of errors. This is achieved through a dynamic protocol that adaptively adjusts the \u201ccontentiousness\" level of the debate, encouraging models to initially explore a wide range of perspectives and rigorously assess the quality of arguments. Through constructive exchange of ideas in subsequent iterations, SocraSynth converges on a more informed and robust decision. Its approach, grounded in EVINCE's dual entropy theory, allows for the exploration of various ideas by one LLM while maintaining stability through the other, effectively preventing premature convergence on a narrow set of perspectives."}, {"title": "2.2 Addressing Common Misconceptions about Adversarial LLM Dialogue", "content": "The rapid growth in academic conference submissions has led to an expanded reviewer pool, potentially impacting review quality. In this context, some misconceptions about our work have arisen, which we address here:\n1. Misconception: Multiple LLMs cannot mitigate hallucination.\nSome reviewers have expressed skepticism about the ability of multiple LLMs to reduce hallucination. However, our approach does not simply aggregate potentially flawed outputs. Instead, SocraSynth leverages the strengths of multiple models to cross-check, challenge, and refine information. This process is analogous to peer review in scientific discourse, where collective scrutiny enhances the reliability of conclusions.\n2. Misconception: Multiple LLM dialogues cannot lead to knowledge discovery.\nDespite evidence provided in (Chang, 2023a) and (Chang and Chang, 2023), some reviewers remain skeptical about the potential for knowledge discovery through LLM dialogues. Our work demonstrates that carefully structured interactions between LLMs can indeed lead to novel insights and knowledge synthesis by leveraging the polydisciplinary knowledge representation inherent in LLMs.\n3. Misconception: The approach lacks theoretical foundation.\nOur approach is grounded in conditional statistics and information theory, which we use to optimize LLM interactions. This theoretical foundation ensures that the dialogue converges towards more accurate and less biased outcomes, addressing concerns about the rigor of our methodology.\nBy addressing these misconceptions, we aim to clarify the scientific basis and potential of our approach. The synergistic interaction between LLMs in SocraSynth, coupled with EVINCE's theoretical pillars, represents a novel method for enhancing the capabilities of language models. This approach has applications in reducing bias, mitigating hallucination, and potentially advancing the field towards more robust AI systems."}, {"title": "3 Algorithm, Maxims, and Theories", "content": "Problem Statement: Organize a structured debate between two equally competent large language models (LLMs), LLM\u0104 and LLMB, to conduct t rounds. At each round t, each model produces a probability distribution, denoted as \\(P^{(t)}_A\\) and \\(P^{(t)}_B\\), over C possible outcomes, accompanied by sup-"}, {"title": "3.1 Preliminaries in Information Theory", "content": "This section presents the key metrics used to measure information diversity, similarity, divergence, and other relevant factors within EVINCE. These metrics serve three primary objectives:\n\u2022 Wasserstein Distance (WD): Measures distribution difference between predictions to identify exploration opportunities (Kantorovich, 1942; Rubner et al., 2000; Villani, 2008).\n\u2022 Shannon Entropy or Relative Entropy: Measures diversity of perspectives (Cover and Thomas, 2006; Shannon, 1948).\n\u2022 Reasoning Quality: The CRIT algorithm evaluates the logical soundness and persuasiveness of supporting arguments (Chang, 2023c), helping to identify and mitigate hallucinations and poorly-reasoned arguments."}, {"title": "3.1.2 Exploring new possibilities while adhering to the dialogue subject", "content": "\u2022 Correlation Coefficients: Tracks the evolution of opinions and assesses debate stability (Brown et al., 2005) toward the goal of the dialogue.\n\u2022 Mutual Information (MI): Quantifies information overlap to ensure focused and productive debates (Cover and Thomas, 2006) and measures the degree of agreement/disagreement."}, {"title": "3.1.3 Examining information convergence and establishing termination criteria", "content": "\u2022 Jensen-Shannon (JS) Divergence: Assesses similarity between probability distributions (Lin, 1991) (symmetric).\n\u2022 Cross Entropy (CE): Measures the asymmetric difference between prediction distributions (Shore and Johnson, 1980).\n\u2022 Kullback-Leibler (KL) Divergence: Reveals asymmetric differences between probability distributions (Kullback, 1951)."}, {"title": "3.2 EVINCE Algorithm Specifications", "content": "Figure 1 formally specifies the detailed operations of EVINCE.\nSetup and Initialization: EVINCE employs two equally competent LLM instances, LLMA and LLMB, which can be different models (e.g., GPT and Claude) or independent instances of the same model. Given an information set S and a class-label set C, EVINCE outputs a probability distribution over C with justifications. For example, S could represent a patient's symptoms and C a set of diseases, with EVINCE moderating a dialogue to predict the patient's disease(s).\nThe debate \"contentiousness\u201d is initially set to 90% to encourage disagreement and explore diverse perspectives. This high level is maintained for the first two iterations, then gradually reduced by x% in each subsequent iteration to shift from exploration to exploitation\u00b9. demonstrates\n\u00b9The setting of x at the beginning of a dialogue iteration can depend on the values of all moderation subroutines. Our empirical experience suggests x = 25% because a typical"}, {"title": "3.3 Maxims with Theoretical Foundations", "content": "Progress towards the optimality goal is guided and measured by metrics introduced in Section 3.1. This section explains how these metrics can be used in complementary ways to facilitate proper trade-offs between diversity and convergence, exploration and exploitation, and several other factors. In the EVINCE algorithm presented in Figure 1, we have annotated the steps to which these four maxims are applied."}, {"title": "Maxim #1: Orchestrate Two Equally Competent LLMs in Structured Debate:", "content": "Integrating two equally competent LLMs ensures a balanced exchange of insights and avoids bias. This adversarial setup fosters diversity in predictions, each supported by justifications, promoting critical evaluation and uncovering potential blind spots.\nHow? Choosing LLMs with comparable performance on a shared validation set, a balanced debate can be ensured. Suitable models include GPT-4, Claude, and Gemini. Conditioning different instances of the same LLM to support opposing stances on a subject matter can also be effective due to the theoretical justification of in-context learning with conditional Bayesian statistics (Xie et al., 2021)."}, {"title": "Maxim #2: Encourage the Accurate Rather Than the \"Popular\" Prediction:", "content": "Typically, LLMs, with their maximum likelihood next-token prediction objective, tend to favor the most popular predictions. By conditioning LLMs within specific contexts, we can prioritize specific stance over popularity, mitigating confirmation biases.\nHow? Using the proxy metrics in Table 1, EVINCE dynamically adjusts the \u201ccontentiousness\" level in debates. These metrics quantify agreement, diversity, and mutual information, promoting productive information exchange and enhancing prediction quality."}, {"title": "Maxim #3. Evaluating the Convergence Rate of the Predictions Across the Iterations:", "content": "This aspect focuses on measuring how quickly and effectively the predictions from the LLMs converge"}, {"title": "4 Empirical Study", "content": "This empirical study investigates the application of EVINCE to disease diagnosis, leveraging large language models (LLMs) as diagnostic tools. We aim to validate the following three hypotheses:\n1. Contentiousness & Prediction Quality: Initial LLM disagreement (measured by Wasserstein distance) increases with higher initial contentiousness but decreases as debate progresses."}, {"title": "4.1 Study #1: Post vs. Pre-Debate Accuracy", "content": "We employed GPT-4, Gemini, and Claude3 to perform independent disease predictions on 304 patient instances, then used EVINCE to pair them and evaluate performance gain.\nExperimental Setup: We set k = 5 for both LLM agents, with one agent at high temperature and the other at low temperature. The contentiousness level was set very high (\u2206 = 0.9 out of 1) to encourage significant cross entropy. Setting k = 5 ensures some minimal common ground, fostering meaningful interaction. High contentiousness promotes counterarguments and information exchange.\nPre- and Post-Debate Evaluation: We conducted two sets of experiments:\n1. Constrained Prediction (Baseline): We limited disease predictions to the 40 labels in the dataset, mimicking common supervised learning assumptions. This yielded high accuracy (95-97%) but is unrealistic for real-world diagnosis where general practitioners consider all possibilities. This constraint highlights LLMs' flexibility, as they're less prone to overfitting erroneous labels (further discussed in subsequent studies).\n2. Unconstrained Prediction: We removed the label constraint to better simulate real-world conditions. All 304 patient cases yielded stable results across GPT-4, Gemini-3, and Claude-3, with a standard deviation of just 1.5%. Prior to debate (light blue bars in Figure 2), GPT-4 led in accuracy (82.8%), followed by Gemini (80.3%) and Claude (79.5%).\nEVINCE Performance: Implementing EVINCE with GPT-4 and Claude-3 pairing and GPT-4 and Gemini-3 pairing consistently improved accuracy by 4-5 percentage points (green bars in Figure 2). The GPT-4 and Claude-3 pairing achieved 87.5% accuracy (Figure 2a), rivaling state-of-the-art clinical performance like the REFUEL algorithm (Peng et al., 2018).\nDiscussion: The remaining 12.5% inaccuracy for the GPT-Claude pairing might not be solely attributable to EVINCE. Considering the potential 11% US misdiagnosis rate reported by Johns Hopkins (Newman-Toker et al., 2023b), this discrepancy could indicate mislabeled data in the original dataset. This presents a groundbreaking opportunity: EVINCE could potentially identify and correct errors in existing datasets, a concept we explore further in Section 4.3."}, {"title": "4.2 Study #2: Confusion vs. Opportunities", "content": "Two primary factors contribute to EVINCE's improved diagnostic accuracy: (1) structured debates with reasoning encourage LLMs to explore alternative diagnoses in both breadth and depth, leading to more comprehensive analysis and decision-making (see Appendices B and C); and (2) pairing high- and low-entropy LLMs balances exploratory diversity with exploitative stability, resulting in more robust and high-quality decisions, as demonstrated in this second study."}, {"title": "4.3 Study #3: Ground-Truth Remediation", "content": "This study illustrates how EVINCE can identify potential misdiagnoses, explain the reasoning behind them, and recommend corrective actions. Traditionally, machine learning scientists rely on labeled data as \"ground truth.\u201d However, as evidenced by"}, {"title": "4.4 Experiment Remarks", "content": "EVINCE initiates debates with high contentiousness, encouraging dual prediction entropy between LLMs, as supported by the EDT theorem. It utilizes normalized mutual information (MI) to track shared knowledge accumulation throughout the debate, while Wasserstein distance (WD) and Jensen-Shannon divergence (JSD) quantify dissimilarity between LLM predictions.\nThese metrics (EDT, WD, JSD, MI) provide a comprehensive view of debate progress. WD and JSD assess the potential for further communication and refinement, while MI monitors shared understanding, aiding in determining the optimal stopping point.\nThe asymmetric nature of KL divergence and cross entropy warrants further investigation. Despite eventual convergence in our case studies, discrepancies observed in the second round (one direction increasing while the other decreases) suggest potential value in exploring asymmetric information. Future work will re-evaluate the use of these metrics if asymmetry proves beneficial.\nBesides generating final joint disease predictions, EVINCE provides:\n\u2022 Recommendations for additional symptom inquiries and lab tests to improve accuracy.\n\u2022 Suggestions to query symptom onset, duration, severity, trends, and associated symptoms (documented in Appendices B.8 and C.9).\nThese recommendations have been verified by general practitioners to be valuable."}, {"title": "5 Concluding Remarks", "content": "This paper introduces EVINCE, a framework designed to facilitate collaborative dynamics among Large Language Models (LLMs) through structured, adversarial debates. Our research demonstrates that EVINCE significantly advances the pursuit of Artificial General Intelligence (AGI) by enhancing three core characteristics: versatility, adaptivity, and reasoning capability. By addressing key limitations of current AI systems, including hallucination, bias, and limited reasoning, EVINCE provides a novel pathway towards more robust and capable artificial intelligence.\nThe core strength of EVINCE lies in its three theoretical pillars: Inclusiveness Exploration, Information Flow Dynamics, and Reasoning Quality and Coherence. These pillars, grounded in conditional statistics and information theory, enable LLMs to transcend their typical \u201cmaximal likelihood\" behaviors, mirroring human adaptability in linguistic tasks. The integration of the CRIT system, which combines Socratic methods with formal reasoning techniques, further enhances critical thinking and ensures logically sound and objective-aligned collective reasoning.\nOur empirical validation demonstrates EVINCE's effectiveness in improving prediction accuracy across various domains, notably achieving a 5% improvement in medical diagnosis tasks. The framework has also shown promise in identifying biases in news articles (Chang, 2024c), showcasing its potential for broader applications in fields such as geopolitical analysis (Chang, 2023b)"}, {"title": "Appendix A: Evaluative Phase of EVINCE", "content": "EVINCE uses the Socratic method to evaluate the \"reasonableness\" of a set of arguments that support a subject matter. The Socratic method is a questioning technique used in teaching and philosophy to encourage critical thinking and self-discovery (Wikipedia, 2023). The method involves asking a series of questions to explore complex ideas and help individuals arrive at their own understanding of a concept. It is based on the belief that knowledge cannot be simply imparted, but must be discovered through a process of questioning and dialogue.\nTo illustrate how these methods can practically be applied, let's use the example of critical reading. Critical reading is a crucial component of critical thinking, which involves evaluating the quality and credibility of written materials, from research papers to blog posts (Lai et al., 2017; Paul and Binker, 1990). It requires a systematic and analytical approach, asking relevant questions, and using effective prompts to gain deeper understanding of the text (Elder and Paul, 2010).\nTo aid in critical reading, we introduce a prompt template called CRIT (Chang, 2023c), which stands for Critical Reading Inquisitive Template. Given a document d, CRIT evaluates it and produces a validation score \u0393. Let \u03a9 denote the conclusion or claim of d, and let R be the set of reasons supporting the claim. We define (Yr, \u03b8r) = V(r \u21d2 \u03a9) as the causal validation function, where Yr denotes the validation score, \u03b8r the source credibility score, for each reason-to-conclusion argument r \u21d2 \u03a9."}, {"title": "Appendix B: EVINCE Debate - Dengue Fever vs. Chikungunya", "content": "This experiment addresses a diagnostic challenge involving multiple potential diseases. A patient presents with the following 12 symptoms: [skin rash, joint pain, vomiting, fatigue, high fever, headache, nausea, loss of appetite, pain behind the eyes, back pain, malaise, muscle pain, red spots over the body]. In this case, GPT-4 provides the initial diagnosis, with Gemini following suit. The confirmed diagnosis for this experiment is Dengue Fever. Given the satisfactory diversity in predictions from the two LLMs, the debate progresses and converges smoothly."}, {"title": "Appendix C: EVINCE Debate - Jaundice vs. Hepatitis", "content": "In this experiment, GPT-4 and Claude receive an identical list of symptoms from the moderator, aimed at guiding disease diagnosis, facilitating debate, and shaping subsequent recommendations. The \"ground-truth\" disease is Jaundice. (We do not shorten the debate content for review.)"}, {"title": "Appendix D: Formulas of Metrics", "content": "This appendix outlines the mathematical formulas for various data analysis metrics used in probabilistic and statistical modeling.\nKullback-Leibler Divergence\nThe Kullback-Leibler Divergence measures the difference between two probability distributions:\n\\(D_{KL}(P||Q) = \\sum_{x \\in X} P(x) log \\frac{P(x)}{Q(x)}\\)\nJensen-Shannon Divergence\nThe Jensen-Shannon Divergence is a symmetrized and smoothed version of the KL Divergence:\n\\(JSD(P||Q) = \\frac{1}{2}D_{KL}(P||M) + \\frac{1}{2}D_{KL}(Q||M)\\)\nwhere M = (P + Q).\nWasserstein Distance\nThe Wasserstein Distance, also known as the Earth Mover's Distance (EMD), measures the distance between two probability distributions:\n\\(W(P,Q) = inf_{\\gamma \\in \\Gamma(P,Q)} \\int_{x \\times y} d(x, y) d\\gamma(x, y).\\)\nCross Entropy\nCross Entropy measures the average number of bits required to identify an event from a set of possibilities, under a specific model:\n\\(H(P,Q) = - \\sum_{x \\in X} P(x) log(Q(x)).\\)\nMutual Information\nMutual Information measures the amount of information that one random variable contains about another random variable:\n\\(I(X; Y) = \\sum_{y \\in Y} \\sum_{x \\in X} p(x, y) log \\frac{p(x, y)}{p(x)p(y)}\\)\nNormalized Mutual Information\nNormalized Mutual Information is calculated as the mutual information divided by the maximum of the entropies of the variables:\n\\(NMI(X; Y) = \\frac{I(X; Y)}{max(H(X), H(Y))}.\\)"}, {"title": "Appendix E: Symptom Checking", "content": "This is the typical procedure of a GP to perform patient symptom checking.\n1. Patient History: The GP begins by reviewing the patient's medical history, including previous illnesses, chronic conditions, medications, allergies, and family medical history."}, {"title": "Appendix F: The EnToPPS Framework", "content": "EnToPPS integrates predictions from two LLMs, denoted as A and B, each providing probability distributions over C classes. The following steps outline the EnToPPS process:\n1. Obtain Top-C Predictions: For each LLM (A and B), obtain the predicted probabilities for all C classes, denoted as PA and PB:\n\\(P_A = [p_{A1}, p_{A2},...,p_{AC}], P_B = [p_{B1}, p_{B2},...,p_{BC}],\\)\nwhere PAi and PBi represent the predicted probability of class i by LLM A and B, respectively.\n2. Select Top-k Predictions: For each LLM (A and B), select the top-k predicted classes based on their probabilities:\n\\(T_A = [t_{A1}, t_{A2},..., t_{Ak}], T_B = [t_{B1}, t_{B2},...,t_{Bk}],\\)\nwhere tAi and tBi represent the class index of the ith top prediction by A and B, respectively.\n3. Combine Top-k Predictions: Combine the top-k predictions from both LLMs to create a set of unique predicted classes:\n\\(T_C = T_A \\cup T_B = [t_{c1},t_{c2},..., t_{cm}], k \\le m \\le 2k.\\)\n4. Backfill Missing Probabilities: For each class in the combined set TC, backfill its probability from the original probability distributions PA and PB:\n\u2022 If a class tci is present in TA, assign its probability from PA: pci = PAi\u00b7\n\u2022 If a class tci is present in TB, assign its probability from PB: pci = PBi.\n\u2022 If a class tci is present in both TA and TB, assign the average probability: \\(p_{ci} = \\frac{p_{Ai} + p_{Bi}}{2}\\).\n5. Normalize Probabilities: Normalize the probabilities of the classes in the combined set TC to ensure they sum up to 1:\n\\(P_c = [p_{C1}, p_{C2},...,p_{Cm}], where p_{Ci} = \\frac{p_{ci}}{\\sum_{j=1}^m p_{cj}}\\)"}]}