{"title": "EVINCE: Optimizing Adversarial LLM Dialogues via Conditional Statistics and Information Theory", "authors": ["Edward Y. Chang"], "abstract": "This paper introduces EVINCE (Entropy and Variation IN Conditional Exchanges), a dialogue framework advancing Artificial General Intelligence (AGI) by enhancing versatility, adaptivity, and reasoning in large language models (LLMs). Leveraging adversarial debate and a novel dual entropy theory, EVINCE improves prediction accuracy, robustness, and stability in LLMs by integrating statistical modeling, information theory, and machine learning to balance diverse perspective exploration with strong prior exploitation. The framework's effectiveness is demonstrated through consistent convergence of information-theoretic metrics, particularly improved mutual information, fostering productive LLM collaboration. We apply EVINCE to healthcare, showing improved disease diagnosis, and discuss its broader implications for decision-making across domains. This work provides theoretical foundations and empirical validation for EVINCE, paving the way for advancements in LLM collaboration and AGI development.", "sections": [{"title": "Introduction", "content": "The pursuit of Artificial General Intelligence (AGI) remains a central goal of AI research. We propose a paradigm shift in this quest: utilizing multiple Large Language Models (LLMs) engaged in synergistic dialogues as a crucial step towards AGI. This approach, we contend, addresses key limitations of current AI systems and provides a novel pathway to more robust, versatile, and capable artificial intelligence. Specifically, our work targets three core AGI characteristics: versatility, adaptivity, and reasoning capability.\nCurrent LLMs, despite their remarkable capabilities, face significant challenges, including hallucination (generating false or nonsensical information), bias (reflecting and potentially amplifying societal prejudices), and limited reasoning (difficulties in complex problem-solving and logical inference).\nWe posit that multi-agent dialogue systems offer a promising avenue to address these challenges. By fostering diversity and debate among LLMs, these systems can mitigate biases and promote enhanced reasoning capabilities. Furthermore, the iterative nature of multi-round dialogues allows for continuous context enrichment, enabling LLMs to access more precise information and formulate more accurate responses, thus reducing the occurrence of hallucinations.\nOur previous work, SocraSynth (Chang, 2023a), addresses LLM limitations through structured multi-agent dialogues. By leveraging both adversarial and collaborative interactions between LLMs, SocraSynth demonstrates quantifiable improvements across various domains. In healthcare, it achieves a 5% improvement in diagnostic accuracy (Chang and et al., 2023), while in news analysis, it identifies and explains biases in articles (Chang, 2024c). These advancements showcase enhanced versatility, adaptivity, and reasoning capability-key AGI characteristics.\nSocraSynth's adversarial component promotes the exploration of diverse perspectives, while its collaborative component fosters rigorous reasoning to reach well-reasoned conclusions. This synergy has yielded measurable gains beyond healthcare and bias mitigation, extending to geopolitical analysis (Chang, 2023b), corporate planning (Tsao, 2023), investment banking (Chang, 2024b), and emotional behavior modeling (Chang, 2024a). These results demonstrate SocraSynth's effectiveness in mitigating LLM limitations and achieving substantial performance improvements across various applications, highlighting its potential for advancing towards AGI's generalized problem-solving capabilities.\nAlthough SocraSynth has demonstrated effectiveness, it relies on \u201ccontentiousness\u201d as a qualitative measure to moderate the linguistic behaviors of participating LLMs. For instance, a high"}, {"title": "Related Work", "content": "The core objective of adversarial debate, as embodied in SocraSynth with EVINCE, is to foster diverse opinions and challenge assumptions, ultimately leading to more comprehensive and informed decision-making. This contrasts with traditional ensemble learning methods, which prioritize error diversity for improved accuracy. This section surveys ensemble learning and adversarial learning, highlighting the unique aspects of EVINCE and its theoretical underpinnings."}, {"title": "Ensemble Learning", "content": "Ensemble methods, such as Bagging (Breiman, 1996), Boosting (Freund and Schapire, 1997), and Mixtures of Experts (Jacobs et al., 1991), traditionally aim to enhance machine learning performance by combining predictions from multiple models to achieve error diversity. Similarly, early LLM debate frameworks, e.g., (Michael et al., 2023; Chan et al., 2023; Liang et al., 2023; Du et al., 2023) have focused primarily on improving answer accuracy rather than fostering a comprehensive exploration of information for critical decision-making.\nSocraSynth distinguishes itself from traditional ensemble methods by prioritizing the generation of diverse predictions over the mere avoidance of errors. This is achieved through a dynamic protocol that adaptively adjusts the \u201ccontentiousness\" level of the debate, encouraging models to initially explore a wide range of perspectives and rigorously assess the quality of arguments. Through constructive exchange of ideas in subsequent iterations, SocraSynth converges on a more informed and robust decision. Its approach, grounded in EVINCE's dual entropy theory, allows for the exploration of various ideas by one LLM while maintaining stability through the other, effectively preventing premature convergence on a narrow set of perspectives."}, {"title": "Addressing Common Misconceptions about Adversarial LLM Dialogue", "content": "The rapid growth in academic conference submissions has led to an expanded reviewer pool, potentially impacting review quality. In this context, some misconceptions about our work have arisen, which we address here:\nSome reviewers have expressed skepticism about the ability of multiple LLMs to reduce hallucination. However, our approach does not simply aggregate potentially flawed outputs. Instead, SocraSynth leverages the strengths of multiple models to cross-check, challenge, and refine information. This process is analogous to peer review in scientific discourse, where collective scrutiny enhances the reliability of conclusions.\nDespite evidence provided in (Chang, 2023a) and (Chang and Chang, 2023), some reviewers remain skeptical about the potential for knowledge discovery through LLM dialogues. Our work demonstrates that carefully structured interactions between LLMs can indeed lead to novel insights and knowledge synthesis by leveraging the polydisciplinary knowledge representation inherent in LLMs.\nOur approach is grounded in conditional statistics and information theory, which we use to optimize LLM interactions. This theoretical foundation ensures that the dialogue converges towards more accurate and less biased outcomes, addressing concerns about the rigor of our methodology.\nBy addressing these misconceptions, we aim to clarify the scientific basis and potential of our approach. The synergistic interaction between LLMs in SocraSynth, coupled with EVINCE's theoretical pillars, represents a novel method for enhancing the capabilities of language models. This approach has applications in reducing bias, mitigating hallucination, and potentially advancing the field towards more robust AI systems."}, {"title": "Algorithm, Maxims, and Theories", "content": "Problem Statement: Organize a structured debate between two equally competent large language models (LLMs), $LLM_A$ and $LLM_B$, to conduct $t$ rounds. At each round $t$, each model produces a probability distribution, denoted as $P_A^{(t)}$ and $P_B^{(t)}$, over $C$ possible outcomes, accompanied by sup-"}, {"title": "Preliminaries in Information Theory", "content": "This section presents the key metrics used to measure information diversity, similarity, divergence, and other relevant factors within EVINCE. These metrics serve three primary objectives:"}, {"title": "Fostering diversity of perspectives while ensuring reasoning quality", "content": "\u2022 Wasserstein Distance (WD): Measures distribution difference between predictions to identify exploration opportunities (Kantorovich, 1942;\n\u2022 Shannon Entropy or Relative Entropy: Measures diversity of perspectives (Cover and Thomas, 2006; Shannon, 1948).\n\u2022 Reasoning Quality: The CRIT algorithm evaluates the logical soundness and persuasiveness of supporting arguments (Chang, 2023c), helping to identify and mitigate hallucinations and poorly-reasoned arguments."}, {"title": "Exploring new possibilities while adhering to the dialogue subject", "content": "\u2022 Correlation Coefficients: Tracks the evolution of opinions and assesses debate stability (Brown et al., 2005) toward the goal of the dialogue.\n\u2022 Mutual Information (MI): Quantifies information overlap to ensure focused and productive debates (Cover and Thomas, 2006) and measures the degree of agreement/disagreement."}, {"title": "Examining information convergence and establishing termination criteria", "content": "\u2022 Jensen-Shannon (JS) Divergence: Assesses similarity between probability distributions (Lin, 1991) (symmetric).\n\u2022 Cross Entropy (CE): Measures the asymmetric difference between prediction distributions (Shore and Johnson, 1980).\n\u2022 Kullback-Leibler (KL) Divergence: Reveals asymmetric differences between probability distributions (Kullback, 1951)."}, {"title": "Exploring new possibilities while adhering to the dialogue subject", "content": "\u2022 Correlation Coefficients: Tracks the evolution of opinions and assesses debate stability (Brown et al., 2005) toward the goal of the dialogue.\n\u2022 Mutual Information (MI): Quantifies information overlap to ensure focused and productive debates (Cover and Thomas, 2006) and measures the degree of agreement/disagreement."}, {"title": "Examining information convergence and establishing termination criteria", "content": "\u2022 Jensen-Shannon (JS) Divergence: Assesses similarity between probability distributions (Lin, 1991) (symmetric).\n\u2022 Cross Entropy (CE): Measures the asymmetric difference between prediction distributions (Shore and Johnson, 1980).\n\u2022 Kullback-Leibler (KL) Divergence: Reveals asymmetric differences between probability distributions (Kullback, 1951)."}, {"title": "EVINCE Algorithm Specifications", "content": "Figure 1 formally specifies the detailed operations of EVINCE.\nSetup and Initialization: EVINCE employs two equally competent LLM instances, $LLM_A$ and $LLM_B$, which can be different models (e.g., GPT and Claude) or independent instances of the same model. Given an information set $S$ and a class-label set $C$, EVINCE outputs a probability distribution over $C$ with justifications. For example, $S$ could represent a patient's symptoms and $C$ a set of diseases, with EVINCE moderating a dialogue to predict the patient's disease(s).\nThe debate \"contentiousness\u201d is initially set to 90% to encourage disagreement and explore diverse perspectives. This high level is maintained for the first two iterations, then gradually reduced by $x\\%$ in each subsequent iteration to shift from exploration to exploitation\u00b9."}]}