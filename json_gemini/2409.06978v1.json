{"title": "Large Language Models and the Extended Church-Turing Thesis", "authors": ["Ji\u0159\u00ed Wiedermann", "Jan van Leeuwen"], "abstract": "The Extended Church-Turing Thesis (ECTT) posits that all effective information processing, including unbounded and non-uniform interactive computations, can be described in terms of interactive Turing machines with advice. Does this assertion also apply to the abilities of contemporary large language models (LLMs)? From a broader perspective, this question calls for an investigation of the computational power of LLMs by the classical means of computability and computational complexity theory, especially the theory of automata. Along these lines, we establish a number of fundamental results. Firstly, we argue that any fixed (non-adaptive) LLM is computationally equivalent to a, possibly very large, deterministic finite-state transducer. This characterizes the base level of LLMs. We extend this to a key result concerning the simulation of space-bounded Turing machines by LLMs. Secondly, we show that lineages of evolving LLMs are computationally equivalent to interactive Turing machines with advice. The latter finding confirms the validity of the ECTT for lineages of LLMs. From a computability viewpoint, it also suggests that lineages of LLMs possess super-Turing computational power. Consequently, in our computational model knowledge generation is in general a non-algorithmic process realized by lineages of LLMs. Finally, we discuss the merits of our findings in the broader context of several related disciplines and philosophies.", "sections": [{"title": "1 Introduction", "content": "Historical context Back in 2001, at the occasion of entering a new millennium, a notable book entitled \u201cMathematics Unlimited 2001 and Beyond\u201d appeared, giving a unique overview of the state of mathematics at the end of the twentieth century and offering remarkable insights into its future development and that of its related fields. In one of the book chapters, we investigated the role of the classical Turing machine paradigm in contemporary computing [15]. Especially, we were interested in whether the Church-Turing Thesis (CTT), claiming that every algorithm can be described in terms of a Turing machine, has withstood the \u2018test of time'. Did this thesis still apply to all modern computations as we witness them today? We characterized the latter as computations that fulfill three conditions that appeared with the advent of modern computing technologies: non-uniformity of programs, interactivity (or reactivity), and infinity of operation. Based on this observation, we brought evidence and argumentation in favor of what we called the Extended Church-Turing Thesis (ECTT), which can be seen as a strengthening of the classical Church-Turing Thesis from this newer perspective:\nExtended Church-Turing Thesis: All effective information processing, including unbounded\nand non-uniform interactive computations, can be modeled in terms of interactive Turing\nmachines with advice."}, {"title": "2 Simulations between LLMs and finite-state transducers", "content": "When it comes to characterizing the computational power of LLMs, note that a single LLM cannot in principle simulate an arbitrary Turing machine, simply because LLMs are finite-state devices and no such device can simulate an infinite-state machine. Thus, to characterize the computational power of LLMs, we must look for weaker models than Turing machines. Finite-state transducers (FSTs) offer themselves as a natural choice. We will argue first that deterministic FSTs and fixed (non-adaptive) LLMs are computationally equivalent, within the input limits of the latter.\nAs far as the computational model of an LLM is concerned, we will consider a standard, or nowadays one might even say, 'classical' elementary ChatGPT model as described, e.g., in [24]. These models are able to learn probability distributions of words (tokens) during a training phase, and make use of it during their inference phase. Probabilistic mechanisms are not included in the LLM architecture. During inference, their behavior is influenced by their initial setting and a learned probabilistic distribution captured from the training data.\nFrom a computability viewpoint, trained LLMs can be viewed as deterministic interactive finite-state systems producing knowledge in response to the initial prompts. They work with finite precision weights and learned fixed statistical behavior, devoid of any memory or functional augmentations. They read their inputs in a sequential manner. LLMs require substantial computational resources for their deployment, although the development of their transformer decoder-based technology leads to ever more efficient implementations [14].\nA finite-state transducer is a finite-state machine with two tapes, following the terminology for Turing machines: a two-way read-only input tape and a write-only output tape. An FST reads strings of a given set on the input tape and generates strings of a related set on the output tape. An FST is allowed to make steps that do not consume an input symbol (e-moves), to reflect \u2018internal processing' of state information. A general FST can be thought of as a generator of strings, a deterministic FST as a mapping from input to output strings.\nThe input-to-output properties of FSTs relate their abilities to those of LLMs. However, the models are still very different. For example, LLMs have an intrinsic ability to learn and adapt based on vast"}, {"title": "Theorem 1.", "content": "Let L be a fixed LLM. Then, there is a deterministic FST T simulating L."}, {"title": "Proof.", "content": "(Outline.) Let L be a fixed LLM. We argued that I is deterministic and of bounded size.\nThe Church-Turing thesis guarantees that the deterministic system I can, in principle, be simulated\nby a Turing machine with the same input convention. Since I is of bounded size and hence a finite-\nstate system, the simulating Turing machine is of constant space complexity for all inputs and thus,\ncomputationally equivalent to some deterministic FST I. This proves that theoretically, a sufficiently\nlarge and complex FST could simulate the behavior of L."}, {"title": "Theorem 2.", "content": "Let I be a deterministic FST. Then, for any n > 1, there is a fixed LLM L simulating T\non all words of length at most n."}, {"title": "Proof.", "content": "(Outline.) Given n, we indicate how to construct an LLM L as required. Note that the given\nFST I is a deterministic two-way transducer with a finite number of states, a finite number of in-\nput and output symbols or phrases, and a finite number of transition rules. For an LLM, this makes\nit a relatively simple system to learn: it can just represent the single-valued transition function of\nI with rules (current_state,symbol_read) \u2192 (head_move,new_state,output_symbol), for every pair\n(current_state, symbol_read).\nThe transition rules of I can be directly embedded into the vector representations used by an LLM.\nThe rules can be seen as the 'words' of the language that is to be processed by L, the sentences are\nthe sequences of 'words' as they are applied in deterministic order when I is processing an input"}, {"title": "Theorem 3.", "content": "The computational power of fixed LLMs equals that of deterministic FSTs."}, {"title": "Theorem 3", "content": "is the ground level result for our purposes. More powerful simulations can be proved for LLMs that allow for enhanced capabilities of the transformer decoders. For an overview of this recent research area, see e.g. [5, 13]."}, {"title": "3 Simulations between LLMs and interactive Turing machines with ad-vice", "content": "We now turn to our main question: the position of LLMs with respect to the ECTT. How to deal with the development towards more and more powerful LLMs in this respect? In answering it, an important role will be played by the simulation of (deterministic) Turing machines by LLMs."}, {"title": "3.1 Simulating Turing machines \u2018inside' of LLMs", "content": "When contemplating the simulation of Turing machines (TMs) by LLMs, a first solution that comes to mind is the one that led A.M. Turing to the design of his \u2018Turing machine'. In this solution, the LLM at hand is augmented with an external, potentially unbounded memory that will take the role of the tape of the simulated TM, and the LLM itself will merely serve as the finite-state control of that machine.\nEssentially, this is the solution presented by Schuurmans [11], who showed how to operate an external read-write memory using specific prompts to simulate computations of a universal TM. In doing so, it was not necessary to modify the LLM's weights, which the author sees as a key aspect of his proposal.\nIn our present approach, we strive for a different exploitation of the computational potential of LLMs, without augmenting them with any external memories \u2013 by scrutinizing the resource limits of their computational mechanisms. This is achieved by specializing an LLM to the desired 'degree' in its only task,"}, {"title": "Theorem 4.", "content": "Let M be a deterministic multi-tape TM of space complexity S(n). Then, for any n and k\nsuch that S(n) < k, there is an LLM L using word-to-vector embeddings of size O(k) simulating M on\nany input of length n."}, {"title": "Proof.", "content": "Given n and k such that S(n) \u2264 k, we construct an LLM L that simulates M on inputs of size\nn. Without loss of generality, M may be assumed to be always halting. (Note that halting computations\ncannot be longer than the number of different configurations of M, which is bounded by clogn+S(n) for\nsome constant c. This can be checked by keeping a count of the number of steps. If S(n) > logn, this\ncan be done within the space bound by M itself, otherwise it can be done by L itself.) L will be a\n\u2018standard' LLM with word-to-vector embeddings of size O(k) with a special attentional mechanism to\nbe described later in this proof.\nIn the training phase, our initially \u201cempty\u201d LLM must be trained on various valid fragments of the\nTM computation for inputs of size n, i.e. with configurations of size at most S(n), where S(n) \u2264 k. Doing\nso, the set of all work tape configurations up to size k will become the basic \u2018vocabulary' (set of words) of\nthe language of our LLM. Each configuration will serve as the word-to-vector embedding of some word\nfrom the underlying 'Turing machine language'. The result of the training phase is the representation of"}, {"title": "Corollary 1.", "content": "Let M be a TM/A of space complexity S(n). Then, for any n and k with S(n) \u2264 k, there is\nan LLM L using word-to-vector embeddings of size O(k) simulating M on any input of length n."}, {"title": "Proof.", "content": "(Outline.) Referring to the proof of Theorem 4, one can clearly add M's advice as an extra input"}, {"title": "3.2 Non-uniform computation and lineages of LLMs", "content": "By their very definition, the LLMs are interactive computational devices. During their operation, future prompts can react to the answers to the previous prompts. Also, by the results from the previous section, it is conceivable that LLMs are adjusted or modified over time, or even do so themselves when needed or desired. What could, ultimately, be the computational 'reach' of this conception of LLMs?\nLineages We model this very general notion of an evolving LLM by a sequence L = L1,L2,\u2026 of consecutive LLMs called a lineage (after [17]). Each member of such a sequence is specialized in performing computations that require specific 'technical' parameters, such as a specific size of word embeddings, a specific input sizes and so on (like the values of n and k in Theorem 4). So far, this is the standard approach as known in non-uniform complexity theory, e.g. in the study of Boolean circuits or neural networks."}, {"title": "3.3 Simulation of ITM/As by lineages of LLMs and Vice Versa", "content": "Will simulations as in Theorem 4 and Corollary 1 work also in the extended setting of lineages and ITMs? Of course, as long as the input streams are confined to single members of a lineage and satisfy the fixed assumptions of the theorem and the corollary, the simulations will work. But what happens when the streams fail to satisfy these assumptions, e.g. when streams are not bounded ahead of time? We first focus on the simulation of ITM/As.\nTo simulate an ITM/A by a lineage of LLMs, we must solve two problems. First, the simulation must consider the fact that the space complexity of the simulated machine may grow with the size of the input, and second, the use of advice (which depends only on the input size) must be taken into account as well. (We consider the simulation on finite but unbounded inputs only, as infinite inputs are not realistic as prompts for LLMs.)\nThe general idea of the simulation is to simulate computations of the given ITM/A M per partes by members of a lineage of LLMs, as the individual sequences of configurations of M unfold, having increasing requirements on the computational resources of the simulating LLMs. Each sequence of configurations is simulated following Corollary 1 by a dedicated member of L \u2208 L as long as the configurations \u201cfit\u201d into the word embeddings of I and the advice of M remains unchanged."}, {"title": "Theorem 5.", "content": "Let M be an ITM/A. Then, there exists an lineage of evolving LLMs L simulating M on all\ninput streams."}, {"title": "Proof.", "content": "(Outline) Our starting point is Corollary 1. Initially, assume that M has space complexity S(n)\nand that we have chosen a \u2018trigger' k\u2081 such that S(n) \u2264 k\u2081 holds for some initial values of n, the number\nof symbols in the input stream so far. Then, by Corollary 1, there exists an LLM L\u2081 using word-to-vector\nembeddings of size O(k\u2081) simulating M on the input stream for n inputs with n = 1, 2, . . . . However, this\nsimulation may have to come to a halt from two reasons.\nFirst, for some value of n, it may appear for the first time that S(n) exceeds k\u2081. This means that a\nconfiguration p of M has been reached that no longer fits into the word-to-vector embeddings of size\nO(k1). To remedy this situation, we construct a new member L2 \u2208 L with embeddings of size k2 > k1.\nThe respective embeddings will contain all configurations of M of size k2 which are descendants of\nconfiguration p, augmented, of course, with all possible inputs and advice symbols as required in the\nproof of Corollary 1.\nSecond, it might happen that for some value of n, it still holds that S(n) \u2264 k\u2081, but that M gets\na new advice as it reaches configuration p. As before, this calls for a model reconstruction, this time\nconstructing L2 \u2208 L, with word embeddings of a size k2 with k2 > k\u2081 for all descendants of p of size\nO(k2) and a new advice string. This also handles the case when both reasons occur simultaneously.\nProceeding inductively in the same way as indicated above, an evolving lineage L = L1, L2,\u2026 is\nobtained that simulates the ITM/A on all finite but unbounded streams."}, {"title": "Theorem 6.", "content": "Let L = L1,L2,\u2026\u2026 be a lineage of evolving LLMs. Then, there exists an ITM/AM simu-\nlating L on all input streams."}, {"title": "Proof.", "content": "(Outline.) The result follows from the description of how lineages work, provided an ITM/A M\ncan be designed that, for every i \u2265 1, will simulate the i-th LLM of the lineage whenever this LLM's turn\nhas come, i.e. when the i-th switching point is passed in the processing of the input stream.\nFor i \u2265 1, let the i-th advice of M be defined to be D(Li), a full description of Li (including any\nprovision from its environment that applies). On any input stream, if i inputs have been processed, M\ncalls its advice function to get access to D(Li) on its advice tape, enabling it to simulate L; when its\ntime in the simulation of the lineage has come. Thanks to the classical Church-Turing thesis this is\npossible, as D(Li) is an algorithmic description of a real digital 'machine'. Hence, M computes the\nsame transduction as Li on its part of the input stream."}, {"title": "Theorem 7.", "content": "For each lineage L of evolving LLMs there is an ITM/A M such that M simulates L on all\ninput streams, and vice versa."}, {"title": "4 Discussion of the amazing knowledge generation ability of very large finite-state transducers", "content": "We now review the results we obtained from a more detached viewpoint, in the broader perspective of related fields like computability, computational complexity theory, AI theory, robotics, and cognitive sciences. The common denominator in our discussion will be to point to the potential of our findings for a better understanding of the essential qualities and limitations of the new emerging information processing technology represented by evolving LLMs. The discussion aims to bring thought-provoking insights, provide novel perspectives to the ongoing debates of LLMs, and challenge future AI research.\nComputability and complexity aspects In these domains, the main message has been the confirmation that the Extended Church-Turing Thesis is valid also for the latest achievement in the field of IT technology, the development of evolving LLMs. This result could be obtained, thanks to the design of a novel simulation of \u201csmall\u201d (resource-bounded) Turing machines entirely within LLMs as in Theorem 4 or Corollary 1. Subsequently, in the end, this has led to the proof of the super-Turing computational power of these AI systems, as a consequence of Theorem 7. Related results comprised a complete characterization of the computational power of single LLMs in Theorem 3, and that of lineages of LLMs in Theorem 7. These results seem to be the first results dealing with the complexity of LLMs from an automata theoretic point of view.\nThe results are a bit paradoxical \u2013 mankind's most complex computational devices turn out to be computationally equivalent to one of the simplest fundamental models of computation, finite-state transducers. LLMs are, in fact, instances of highly resourceful large scalable finite-state transducers.\nThe illusory language-processing power of LLMs In Theorem 3 we saw that the computational power of LLMs is on par with that of FSTs. This raises questions concerning the natural language-processing power of LLMs.\nNamely, the languages generated or accepted by FSTs are regular. How it is then possible that, in the practice of LLMs, these devices seem to correctly recognize long sequences of natural languages which in general are known to be more complex than words in a regular language (cf. [10])? This conundrum could be explained by the fact that a finite swath of a language of whatever complexity, captured in the training set, can always be seen as part of a regular language. Beyond this swath, for sufficiently long inputs, the language behaves as a regular language. On the one hand, this explains the apparent inherent efficiency of giant LLMs in processing natural language texts of a reasonable length we see in practice. On the other hand, it also explains the limited abilities of LLMs to deal with tasks not sufficiently represented in the training set, such as simple arithmetic, logical operations like abduction, planning, etcetera.\nNevertheless, prolonging the context window (hence the input length) indefinitely will reveal the true recognition power\u2014that of FSTs\u2014of LLMs, which from a certain internal configuration will start"}, {"title": "The problem of understanding", "content": "In the domain of AI, the amazingly versatile abilities of LLMs put these systems into the position of the harbingers that announce a paradigm shift afflicting the entire A\u0399 ecosystem. Our results contribute to a better apprehension of the nature of the information processing in LLMs. The key observation in this respect is the analogy between natural language processing in LLMs and general computation realization by Turing machines. While natural language processing in LLMs works with finitely many words of a natural language, within a general TM computation each configuration is seen as a word of the \u201cTuring machine language\". Such a language has potentially an infinite number of words. Syntax and semantics of this language are described by the underlying TM \"program\". It describes the relationship between the words generated by the program and, in the end, between the input and the output of the program. In this way, it explains how the program's execution transforms the input to the output. This can be seen as a correctness proof of the program, or as a formal proof of (the machine's) understanding (of what it had done). Of course, this form of understanding is different from what we, humans, understand as understanding.\nIt is here where the study of programming language theory can inspire, e.g., the ongoing debates on understanding by LLMs (cf. [6]). The analogy between natural language processing by LLMs and the processing of the TM language by a TM may shift the debate to a firm mathematical ground."}, {"title": "Understanding understanding", "content": "To illustrate the difference in understanding in LLMs and TMs, let us compare the \"mechanism of understanding\u201d in an LLM processing a natural language, and in an LLM simulating a TM according to Theorem 4. In the former case, the decision to generate the next word of the underlying natural language is based on the limited semantic context based on the vector embeddings of several meticulously chosen words, and the gigantic linguistic background knowledge stored in the form of neural nets. In the latter case, the decision to generate the next word of the Turing machine language (i.e., the next TM configuration) is based on the entire history of computation represented by the sequence of configurations entered by the machine until that time. Moreover, any TM computation makes implicit use of the designer's background knowledge that is already embedded in the design of the underlying TM program. This kind of knowledge is tailored to the intended purpose of the computation.\nWhich of the two decisions concerning the prolongation of both computations being compared, is based on a more profound knowledge of the situation? The winner is the TM, because its decision is based on the maximal available information it could have directly and indirectly at its disposal."}, {"title": "Competence without linguistic understanding?", "content": "From an evolutionary point of view, it seems that the key to the notion of understanding is understanding in non-linguistic systems. \u201cHuman-like understand-"}, {"title": "The inner life of LLMs", "content": "There is more to the previous comparison between LLMs and TMs. At each computational step, an embodied TM governing a cognitive cyber-physical system has complete information available not only about its own \u201ccurrent state\u201d, from all its external and internal sensors, motors, and the respective feedback from those devices that the system possesses, but also about all its past states. Note that each configuration of such a TM contains a complete representation of the machine's \u201cphenomenal experience\u201d at that time (cf. [22]). This gives the LLM simulating a TM as in Theorem 4 (that by its very definition remembers all possible \u201cstates of mind\" of such a machine, one is tempted to say) an opportunity to \u201ctime travel\u201d backward and forwards over these states, and thus explore its past decisions or consider its possible \u201cfutures\u201d and adjust its behavior accordingly. What never-thought-of possibilities for classical LLMs! This observation is of interest, especially in the context of the recent announcement on a new consensus: there is \u201ca realistic possibility\" for elements of consciousness in reptiles, insects, and mollusks [4]. If so, why can't it occur in the AI systems whose complexity competes with such simple creatures? Is the feeling \u201chow it is like to understand?\u201d the missing element in our understanding of understanding? In this context, considerations about minimal machine consciousness are the first signs of similar general trends in AI (cf. [21, 22]).\nIn general, it might be possible to consider various high-level non-linguistic cognitive abilities of LLMs via formal counterparts in the TM environment. For, how else could these abilities be ascribed to LLMs without having their mirror in the language of TMs? In this way, variants of representations of a Turing machine's computations could serve as drosophila for ideas about LLMs.\""}, {"title": "Building a bridge between rule-based and biological computation", "content": "The paradigm shift in our apprehension of computations mentioned above is pregnantly expressed precisely by Theorem 7, which builds a bridge between biologically-inspired and logico-mathematical ways of information processing. Although equipollent from a computability point of view, i.e. expressing the same computational power by different means, the two ways do not have equivalent significance and reach. ITM/As epitomize the"}, {"title": "5 Conclusion", "content": "The era of interactive non-uniform information processing at scale is here. The Extended Church-Turing Thesis formulated as a vision more than 20 years ago, has appeared to hold for LLMs, too. The information processing by evolving LLMs heralds the advent of the new understanding of computation, and especially of AI. Despite their known deficiencies, the LLMs are wonderful, exciting, and so far quite mysterious information processing devices possessing a maximal computational power like we can expect from massive classical computations. It remains to be seen where and what the new development of LLMs-like devices will bring us in the future. Undoubtedly, the Extended Church-Turing Thesis will cover our steps in this endeavor."}]}