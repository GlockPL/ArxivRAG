{"title": "Sensing technologies and machine learning methods for emotion recognition in autism: Systematic review", "authors": ["Oresti Banos", "Zhoe Comas-Gonz\u00e1lez", "Javier Medina", "Aurora Polo-Rodr\u00edguez", "David Gil", "Jes\u00fas Peral", "Sandra Amador", "Claudia Villalonga"], "abstract": "Background: Human Emotion Recognition (HER) has been a popular field of study in the past years. Despite the great progresses made so far, relatively little attention has been paid to the use of HER in autism. People with autism are known to face problems with daily social communication and the prototypical interpretation of emotional responses, which are most frequently exerted via facial expressions. This poses significant practical challenges to the application of regular HER systems, which are normally developed for and by neurotypical people.\nObjective: This study reviews the literature on the use of HER systems in autism, particularly with respect to sensing technologies and machine learning methods, as to identify existing barriers and possible future directions.\nMethods: We conducted a systematic review of articles published between January 2011 and June 2023 according to the 2020 PRISMA guidelines. Manuscripts were identified through searching Web of Science and Scopus databases. Manuscripts were included when related to emotion recognition, used sensors and machine learning techniques, and involved children with autism, young, or adults.\nResults: The search yielded 346 articles. A total of 65 publications met the eligibility criteria and were included in the review.\nConclusions: Studies predominantly used facial expression techniques as the emotion recognition method. Consequently, video cameras were the most widely used devices across studies, although a growing trend in the use of physiological sensors was observed lately. Happiness, sadness, anger, fear, disgust, and surprise were most frequently addressed. Classical supervised machine learning techniques were primarily used at the expense of unsupervised approaches or more recent deep learning models. Studies focused on autism in a broad sense but limited efforts have been directed towards more specific disorders of the spectrum. Privacy or security issues were seldom addressed, and if so, at a rather insufficient level of detail.", "sections": [{"title": "1. Introduction", "content": "Autism spectrum disorder (ASD) is a neurodevelopmental condition\ncharacterized by a deficit in communication, social interaction, and lack\nof understanding of emotions. It affects circa 1% of the population and\ncan be detected in the first years of life [1]. One of the key reasons for\nthe emotional misunderstanding is the inability of people with autism\nto comprehend prototypical feelings and emotions, which directly af-\nfects social interaction. In view of this challenge, some research has\nbeen lately devoted to the automatic recognition of human emotions\nin autism. This research area is largely based on the well-established\nfield of Human Emotion Recognition (HER), which exploits sophisti-\ncated sensing technologies and advanced machine learning techniques\nto detect and understand the feelings and emotions of people. Even\nwhen HER systems have been used to detect, intervene, and accom-\npany the adaptation process of people with autism into society, it is\ngenerally accepted that existing approaches are not definitive. Many of\nthese studies deal with biased data and recognition of emotions such\nas happiness or fear was only marginally impaired in autism as well\nas the generalizability of the findings from the currently available data\nremains unclear [2,3]. Furthermore, HER algorithms primarily rely on\nfacial cues, overlooking other important aspects such as body language,\nvocal tone, and contextual and situational factors that would improve\nthe accuracy of the algorithms [4]. [5] and [6] describe new tools as\nwell as computational model to assist people with autism in under-\nstanding and operating in the socioemotional world around them. Some\nfindings reveal that children with autism spectrum condition have resid-\nual difficulties in this aspect of empathy. In the work of [7] authors\nconcluded that relations between particular emotions and human body\nreactions have long been known, but there remain many uncertainties\nin selecting measurement and data analysis methods Moreover, it is\nalso observed that a great number of the HER models used in autism\nare based on data collected from neurotypical people [8]. Be that as\nit may, the use of general HER models in autism-related applications\nposes a number of challenges yet to be addressed and which demand\nspecial attention from the scientific community. While there exists a\ngreat bulk of systematic reviews addressing the technologies and meth-\nods used for emotion recognition in general [7,9\u201311], very few focus\nspecifically on its use in autism. In fact, existing systematic reviews\nin this direction are either centred on a specific technology such as\neye-tracking [12], robots [13], and wearables [14], or particular meth-\nods like deep learning [15]. Hence, a comprehensive systematic review\nfocusing on the state of the art on emotion recognition sensing tech-\nnologies and machine learning methods for autism emotion recognition\nis presented here. The results of this review will contribute to improve\nthe current techniques for emotion recognition used in autism stud-\nies, encourage new research focusing on other conditions of the autism\nspectrum disorder that have been marginally investigated to date, and\npromote the use of physiological methods in addition to other tradi-\ntional behavioural methods as potential emotion recognition modalities\nto be used in autism. The primary objective of this review was to de-\ntermine the trends, advances, and challenges on sensing technologies\nand machine learning methods for emotion recognition in autism. To\nthat end, this review aimed to answer the following research questions:\n(1) What type of sensor technology has been used for emotion recogni-\ntion in autism?; (2) What type of machine learning techniques are most\ncommonly used for emotion recognition in people with autism?; and (3)\nWhat are the main challenges in the use of emotion recognition tech-\nnologies in people with autism? To the best of our knowledge, there\nare many reviews on autism, on HER, on machine learning methods but\nvery little written about the whole of them and their complementation\nof these different areas. This is the main novelty of this review. Our\nstudy covers all age groups unlike most studies that focus on children.\nWe raised a specific question to identify the main challenges in the use\nof emotion recognition technologies in autism. We also provide privacy\nand security aspects including the use of inform consents or approval\nby ethics committees. Furthermore, we offer a more recent view on the\nart as its search reaches up to June 2023."}, {"title": "2. Methods", "content": "The PRISMA 2020 (Preferred Reporting Items for Systematic Re-\nviews and Meta-Analyses) guidelines [16] were followed to perform\na systematic review of the literature on sensing technologies and ma-\nchine learning methods for emotion recognition in autism. The specific\nmethodology followed is described in the following sections."}, {"title": "2.1. Eligibility criteria", "content": "This review focused on studies that dealt with sensor technology\nand machine learning techniques for emotion recognition in children,\nyoung, and adults with autism. We did not restrict study location, sam-\nple size, gender, age, autism type, type of emotion, emotion recognition\nmodality, devices and sensors, nor algorithms. Studies were eligible to\nbe included in this review if they had three characteristics: 1) they were\nrelated to emotion recognition; 2) used sensors and machine learning\ntechniques; and 3) involved children with autism, young or adults.\nOther eligibility criteria included: 1) published between January\n2011 and June 2023; 2) written in English; 3) scientific article pub-\nlished in a journal or in conference proceedings; and 4) research domain\nrelated to computer science or engineering.\nStudies were ineligible if affective technology was used in therapy\nand treatment of patients with autism or in an educational environ-\nment. Therefore, we excluded studies related to: 1) robotic treatments\nor therapies; and 2) social interaction and education."}, {"title": "2.2. Information sources", "content": "We conducted electronic searches for eligible studies within the\nreference databases of Scopus and Web of Science. The search was con-\nducted from 1st January 2011 to 30th June 2023."}, {"title": "2.3. Search strategy", "content": "\u201cAutism\u201d and \u201cemotion recognition\u201d/\u201crecognition of emotion\u201d were\nselected as primal concepts to be searched. In addition to them, syn-\nonyms of the \u201cautism\u201d term, namely \u201cautistic\u201d, and the \u201cemotion\u201d term,\nnamely \u201cmood\u201d and \u201caffect\u201d, were also considered as they are quite\noften used interchangeably in this research area. Limits were also ap-\nplied to the search strategy based on the eligibility criteria. We selected\npapers published between 2011-2023, published in English computer\nscience or engineering journals or proceedings. The resulting queries\neventually run on Scopus and Web of Science are shown below.\nScopus:\nTITLE-ABS-KEY(((autism OR autistic) AND (\"emotion recognition\" OR\n\"mood recognition\" OR \"affect recognition\" OR \"recognition of mood\"\nOR \"affect recognition\" OR \"recognition of affect\")) AND (LIMIT-TO\n(PUBYEAR, 2023) OR LIMIT-TO (PUBYEAR, 2022) OR LIMIT-TO (PUB-\nYEAR,2021) OR LIMIT-TO (PUBYEAR,2020) OR LIMIT-TO (PUB-\nYEAR,2019) OR LIMIT-TO (PUBYEAR, 2018) OR LIMIT-TO (PUB-\nYEAR, 2017) OR LIMIT-TO (PUBYEAR, 2016) OR LIMIT-TO (PUB-\nYEAR,2015) OR LIMIT-TO (PUBYEAR,2014) OR LIMIT-TO (PUB-\nYEAR,2013) OR LIMIT-TO (PUBYEAR, 2012) OR LIMIT-TO (PUB-\nYEAR, 2011)) AND (LIMIT-TO (LANGUAGE, \"English\")) AND (LIMIT-TO\n(DOCTYPE, \"ar\") OR LIMIT-TO (DOCTYPE,\"cp\")) AND (LIMIT-TO (SUB-\nJAREA, \"COMP\") OR LIMIT-TO (SUBJAREA, \"ENGI\")) AND (LIMIT-TO\n(SRCTYPE, \"p\") OR LIMIT-TO (SRCTYPE, \"j\")))\nWeb of Science:\n(TS=((((autism OR autistic) AND (\"emotion recognition\" OR \"mood\nrecognition\" OR \"affect recognition\" OR \"recognition of mood\" OR \"af-\nfect recognition\" OR \"recognition of affect\"))))) AND (PY==(\"2023\" OR\n\"2022\" OR \"2021\" OR \"2020\" OR \"2019\" OR \"2018\" OR \"2017\" OR\n\"2016\" OR \"2015\" OR \"2014\" OR \"2013\" OR \"2012\" OR \"2011\") AND\nDT==(\"ARTICLE\") AND SJ==(\"ENGINEERING\" OR \"COMPUTER\nSCIENCE\") AND LA==(\"ENGLISH\"))"}, {"title": "2.4. Selection process", "content": "The records retrieved from the databases and hand search were im-\nported to the Mendeley Web Library, which was used as a primary tool\nto navigate through both records and reports. Duplicate records were\nmanually identified by cross-checking title and abstract and then re-\nmoved by three reviewers (ZC, OB, CV). These reviewers also screened\neach record and each report retrieved, assessed their eligibility, and\neventually selected the final set of studies to be included in the review\nafter reaching a majority consensus."}, {"title": "2.5. Data collection process", "content": "All reviewers (ZC, OB, JM, AP, DG, JP, SA, CV) participated in the\nreview and assessment of the included studies. The studies were evenly\ndistributed among three groups of reviewers according to their affilia-\ntion.\nWe used a cloud-based collaborative spreadsheet (Google Spread-\nsheet) to collect data from the included studies. The document consisted\nof a state-of-the-art matrix where each row represented a study and the\ncolumns indicated the data items to be analyzed. Each group of re-\nviewers had to full screen and analyze the papers that were assigned\nto them and fill the information in the corresponding columns of the\nmatrix. Periodic meetings were held in order to harmonise terminol-\nogy and overcome potential discrepancies in the assessment process.\nReviewers worked independently to extract the information."}, {"title": "2.6. Data items", "content": "The columns defined in the collaborative spreadsheet corresponded\nto the outcomes for which data were sought. The specific columns de-\nfined were: study name, year of publication, type of article, research\ngoals, subject condition (autism type), emotion recognition modality,\ndataset (collection or use of), description of the dataset (if applicable),\nemotions sensed, devices used for the data collection, machine learning\ntechniques, validation methods, study sample (size, type), study length,\nperformance results, study outcomes, privacy and security, and chal-\nlenges and future work."}, {"title": "3. Results", "content": ""}, {"title": "3.1. Study selection", "content": "A sample of 371 records were identified from the literature search.\nNamely, the search in Scopus yielded 206 records, while 165 records\nwere obtained for Web of Science. 71 duplicate records were removed\nbefore screening. After deduplication, 300 records remained and were\nscreened based on title and abstract. 112 records were excluded and\n188 reports were sought for retrieval. 13 reports could not be retrieved\nand the remaining 175 reports were assessed for eligibility. 110 reports\nwere excluded according to the eligibility criteria and the remaining 65\nreports were included for the analysis. The workflow with the detailed\nprocess is shown in Fig. 1."}, {"title": "3.2. Research goal", "content": "The objectives for investigating emotion recognition in autism vary\nacross studies. However, certain common goals are shared among some\nof these studies. Thus, for example, 29% (19/65) of the studies propose\nand analyze algorithms and machine learning techniques to automati-\ncally recognize emotions in people with autism [17\u201334]. Around 18%\n(12/65) of the studies propose the development and application of\nvideo games and apps to help children with autism understand and ex-\npress emotions [8,35\u201345]. Fewer than 5% (3/65) of the studies explore\nthe use of physiological signals for the automated identification of emo-\ntions [19,46,47]. The remainder of the studies have disparate goals. All\nresearch goals are detailed in Table A.1."}, {"title": "3.3. Autism type", "content": "The type of autism varies across studies (Fig. 2). For example, 70%\n(46/65) of the studies address \"autism\" in general [8,17\u201323,28\u201335,38\u2013\n40,42,44,46,48\u201371], while 12% (8/65) refer to the full spectrum as \"all\nkind of autism\" [24\u201327,37,72\u201374]. Studies referring to \"autism\" tend\nto address broad aspects that apply to the overarching spectrum of\nASD. In contrast, when some studies specifically mention \"all kind of\nautism\", they appear to suggest a deliberate effort to encompass the\ndiverse manifestations and subtypes within the autism spectrum, recog-\nnizing and considering the heterogeneity of the condition. Nonetheless,\nmost often both terms are used interchangeably. In some studies spe-\ncific subtypes of the disorder are addressed. For example, 8% (5/65)\ncorrespond to high-functioning autism [45,61,75\u201377]. Less than 2%\n(1/65) to mild autism [78] and 2% (1/65) to attention-deficit hyper-\nactivity disorder [79]. 6% (4/65) address combinations of parts of\nthe spectrum, namely middle and moderate autism [47], all kinds of\nautism and Asperger [36], and high-functioning autism and Asperger\n[41,80]. While there exist a varied distribution of research focus across\nsubtypes, the contributions in this regard are comparatively low. The\nlimited focus on these subtypes may suggest that the majority of re-\nsearch in ASD aims to address broader aspects of the spectrum rather\nthan delving into detailed examinations of specific subtypes. In Ta-\nble A.2, the subtype of autism addressed in each selected paper is\nlisted."}, {"title": "3.4. Emotional expressions", "content": "The selected studies focus on diverse emotional responses, expres-\nsions and sensed body regions or signals (Fig. 3). The most common\nemotion recognition modality is based on facial expressions, account-\ning for 63% (41/65) of the studies [8,20,22,23,26,28\u201332,34\u201338,40\u2013\n46,49,51\u201356,58\u201361,64,67,68,72,75,76,79,80]. 15% (10/65) are based\non speech aspects [25,27,63,65,66,69,71,73,74,77], followed by 5%\n(3/65) exploiting body movement [21,39,48], 2% (1/65) based on daily\nactivities [17], 2% (1/65) measuring brain activity [19], and 2% (1/65)\nfocusing on eye activity [78]. 12% (8/65) of the studies consist of a mul-\ntimodal approach which combine some of the above [18,24,33,47,50,\n57,62,70]. This distribution underscores the prevalent reliance on facial\nexpressions while recognizing the significance of speech-related aspects\nin understanding and studying emotions within ASD.\nIn relation to the sensed body regions or signals, the majority of\nstudies 71% (46/65) use physical data, i.e. sensed from the external\nparts of the body, mostly the face. 20% (13/65) of the studies exploit the\ninner body, including physiological signals such as electroencephalog-\nraphy (EEG) and electromyography (EMG), or psychoacoustic signals\n[19,24,25,27,47,63,65,66,69,71,73,74,77]. The neurophysiological ap-\nproaches provide valuable insights into the neural and muscular cor-\nrelates of emotional states. As for the rationale behind considering\npsychoacoustics lies in the fundamental role of voice in the recognition\nof emotions within human interactions. By delving into the nuances\nof voice expression, researchers aim to deepen their understanding of\nhow emotions are conveyed and perceived through auditory cues, con-"}, {"title": "3.5. Study characteristics", "content": "The average number of participants was 49, calculated from the\n48 studies indicating the number of participants (74% of the stud-\nies) [8,18,19,21\u201327,29,30,32,33,36\u201341,44\u201348,50\u201355,57,58,60\u201362,65,\n67,70,72\u201380]. The minimum sample size was four subjects [67] and\nthe maximum 500 [22]. This diversity in sample sizes underscores\nthe variability in research approaches within the field, with some\nstudies opting for smaller, more focused samples, while others in-\nvolve larger cohorts. Seventeen papers did not specify this number\n[17,20,28,31,34,35,42,43,49,56,59,63,64,66,68,69,71]. The absence of\nparticipant count details in a significant number of papers highlights the\nneed for increased transparency and reporting consistency in research\nmethodologies. The distribution of the studies based on the sample size\nis shown in Fig. 4.\nOne day was the minimum study duration [19] and 140 days the\nmaximum duration [48]. Yet, it must be noted that no additional infor-\nmation is provided in the rest of studies to this respect. The absence of\nduration details in the rest of the studies emphasizes the need for im-\nproved reporting standards to ensure a comprehensive understanding\nof the temporal aspects of HER research in autism.\nAs for the neurodevelopmental disorder distribution, 51% (33/65)\nof the studies involved people with autism [8,18,21,22,25,27,29,32,33,\n37\u201341,44\u201347,51,54,57,58,61,62,65,67,70,72,75\u201378,80]. Almost 28%\n(18/65) included both people with and without autism [8,18,25,27,29,\n38,41,44,45,47,54,57,58,74\u201379]. This approach allows researchers to\nexplore and understand the unique features associated with ASD by con-\ntrasting them with individuals without the disorder. Around 9% (6/65)\nof the studies considered only people without autism [30,50,52,53,55,\n81]. Although it is not always clearly stated, the reasons for only consid-\nering neurotypical individuals are either the desire to establish baseline\ncharacteristics or more often the lack of access to people with autism.\nIn 32% (21/65) of the studies, the disorder is not precisely described\n[17,19,20,23,24,26,28,31,35,36,42,43,48,52,56,60,63,64,66,68,73]. In\n23% (15/65) an existing dataset was used to test the proposed solution\n[19,28,30\u201332,34,40,42,43,49,63,66,68,69,71].\nLess than 28% (18/65) of the studies involved subjects of both\ngenders [18,23,24,27,29,30,36,37,39,50,54,57,65,70,72\u201374,76]. 5%"}, {"title": "3.6. Types of emotions", "content": "The set of emotions analyzed in the selected studies are broadly\nbased on the six universal emotional expressions, i.e. \"anger\", \"sad-\nness\", \"happiness\", \"disgust\", \"surprise\", and \"fear\" [82]. 43% (28/65)\nof the studies focused on these six basic emotions [18,22,23,26,27,\n30,32,35,37,38,47\u201350,56\u201361,73\u201380]. Two studies [20,68] used these\nvery six emotions but replacing \"disgust\" with the \"neutral\" emotional\nstate. Another study only uses four basic emotions adding \"delight\" and\n\"joy\" emotions [34]. The remaining 33 studies (51%) [8,17,19,21,24,\n25,29,31,33,36,39\u201346,50\u201355,62\u201367,69,71,72] used a number of emo-\ntions ranging from two to nine primitives. The emotions considered\nin addition to the six basic ones were \"neutral\", \"calm\", \"nervous\",\n\"scared\", \"curious\u201d, \u201cexcited\u201d, \"sleepy\", \"contempt\", \"joy\", \"interested\",\n\"positive\", \"positive and talking\", \"odd positive\", \"negative\", \"bore-\ndom\", and \"contentment\".\nThe exceptions to this are [25\u201327,43,47,58\u201360,73,74,76,77,80], which used\ndifferent sets of emotions for training and validation than for test, rep-\nresenting 20% (13/65) of the studies. Employing a different set of\nemotions for test introduces valuable diversity, reflecting the model's\nadaptability to recognize a broader spectrum of emotional expressions\nbeyond its training data. This approach enhances the robustness and\nreal-world applicability of HER models by challenging them with un-\nseen emotion data instances during evaluation."}, {"title": "3.7. Devices and sensors", "content": "Two generations of devices and sensors are identified for the time\nframe considered for this review, which is related to the periods 2011-\n2014 and 2015-2023, respectively.\nAround 11% (7/65) of the studies correspond to the period 2011-\n2014, which is characterized by using images and audio as the primary\ndata source. 57% (4/7) of these studies use a so-called first genera-\ntion of devices consisting of webcams, headphones, and microphones\n[36,73,74,77]. To facilitate the labelling of the user's data, some con-\ntrols were incorporated into the systems in 43% (3/7) of the afore-\nmentioned studies, including control knobs [74,77] or numeric keypads\n[79], which were easily handled by users with autism. This period\nmarked the initial steps in using technology for autism research, es-\ntablishing a foundation for future studies.\nCirca 89% (58/65) of the studies represent the period 2015-2023,\nwhich is distinguished by a second generation of more advanced and\nubiquitous devices and sensors. The technological advancement in-\ntroduced a wide range of versatile devices, including mobile phones,\ntablets, 3D cameras, infrared cameras, and more, expanding the capa-\nbilities for data collection. Thus, for example, handheld devices are\nincluded in 16% (9/58) of these studies, including mobile phones\n[30,40,50], tablets [37,78], and other handheld devices [58]. Some of\nthese devices were used to support gamification apps [8] or to exploit\nthe mobile camera sensor for recognition purposes [30,35]."}, {"title": "3.8. Models and performance", "content": "This subsection summarises the findings concerning machine learn-\ning techniques, performance and metrics, validation methods, and the\nnumber of data samples.\nThe reviewed studies make primary use of supervised learning tech-\nniques. Support vector machines (SVM) stand out as the most widely\nused technique, namely in 29% (19/65) of the studies [8,19,21,23,24,\n27,29,31,39,41,46\u201350,60,69,73,74]. SVM, together with other classical\nmachine learning techniques such as decision trees (DT), random for-\nest (RF), logistic regression (LR) and nearest neighbours k (KNN), are\npresent in roughly 54% (35/65) of the studies reviewed. The remain-\ning 17% (11/65) of the studies do not provide any information on the\ntechniques used [36,37,56\u201359,61,75,78\u201380].\nThe use of Deep Learning is currently confined to recent works, con-\nstituting a 31% (20/65) of the studies [20,25,28\u201334,40\u201343,63\u201366,68,\n69,71]. This limitation suggests an untapped opportunity, as earlier\nresearch may not have fully harnessed the capabilities of deep learn-\ning for complex pattern recognition tasks in emotion recognition in\nautism. Notably, some of the most recent works leverage Deep Learn-\ning techniques, including convolutional neural networks, highlighting\nthe emerging potential for improved performance in emotion recogni-\ntion. However, it is crucial to acknowledge a potential bias towards\nsupervised learning, indicating a potential gap in exploring unsuper-\nvised or semi-supervised methods. These alternative approaches could\noffer valuable insights, especially in scenarios where labelled data is\nscarce or challenging to acquire. Exploring a broader spectrum of deep\nlearning methodologies could enhance the versatility and effectiveness\nof emotion recognition models.\nThe performance of emotion recognition models varies significantly\namong the studies, attributed to differences in target emotions, sensor\ndata types, machine learning techniques, and dataset instances. This\nvariation suggests challenges in directly comparing study outcomes and\nestablishing standardized benchmarks. Studies can be categorized into\nthree groups according to performance levels. First, 28% (18/65) of the\nstudies are ranked as of high performance (i.e. accuracies greater than\n90%), most usually developing an offline evaluation based on datasets\ncollected under controlled conditions [8,21,23,24,26,28,32,40,41,43,\n49,55,59,67,70,72,76,80]. The second group characterizes by perfor-\nmances within the range 80-90%, representing 23% (15/65) of the stud-\nies [17,18,22,29,38,42,48,53,58,60,63,66,73,74,78]. The third and last\ngroup encompass 26% (17/65) of the studies [19,20,25,31,33,39,40,\n50\u201352,54,62,64,65,68,69,77], with more ambitious and challenging so-\nlutions based on emerging sensor technologies, leading to performances\nbelow 80%. The remaining studies have not sufficiently described their\nperformance results and could not be classified into any group.\nThe studies make use of a variety of metrics to evaluate model per-\nformance, including accuracy, sensitivity, and specificity. This range of\nmetrics provides a fair understanding of model performance, especially\nthose handling dataset imbalances. Concerning the metrics used to es-\ntimate model performance, around 57% (37/65) of the studies have\nchosen the use of accuracy [8,17\u201324,28\u201330,32,33,35,38\u201343,46,48\u201350,\n52\u201355,62\u201364,66\u201370]. Other studies have used unweighted average re-\ncall to deal with data set imbalance more effectively [27,30,65,74].\nSensitivity has also been used in some studies [51,59,72], although they\nstill need to evaluate the prominence of true negatives by avoiding the\nuse of specificity. Few studies [18,22,41] rely on the use of accuracy,"}, {"title": "3.9. Information privacy and security", "content": "Despite the relevance of ensuring privacy and security policies in\nthis field, only 22% (14/65) of the studies acknowledge these suf-\nficiently [18,23,24,29,36,39,41,47,54,58,61,67,72,79]. Three of these\nstudies [23,72,79] followed the 1964 Declaration of Helsinki, a formal\nstatement of ethical principles published by the World Medical Associ-\nation (WMA) to guide the protection of human participants in medical\nresearch [83]. The other 11 studies mentioned that they either had the\nconsent of the relatives of the people with autism or their work was\napproved by the ethics committee of the given universities or other in-\nstitutions. All details are provided in Table A.8.\nUpon analyzing the obtained results, the majority of studies that\nindicated privacy and security aspects had obtained consent from fam-\nily members, or the research was approved by ethical committees of\nuniversities/institutions; very few studies adhered to the Declaration\nof Helsinki. However, it is evident that there is insufficient considera-\ntion of privacy and security aspects in the majority of studies. Studies\nlacking pertinent details may not adhere to ethical protocols, thereby\ngenerating concerns about the protection of participants."}, {"title": "4. Discussion", "content": ""}, {"title": "4.1. Findings", "content": "The great majority of the studies analyzed referred to the autism\nspectrum disorder in different ways. Namely, it was noticed the use of\ntwo terminologies \"autism\" and \"all kinds of autism\" to refer to this\ncondition interchangeably. This shows a lack of unification on the use\nof this terminology by the scientific community of the HER field. More\nimportantly, more research needs to be placed towards mild and high-\nfunctioning autism, as well as other conditions of the autism spectrum\nlike Asperger, which according to the results are just marginally consid-\nered.\nWhile a majority of studies indicate the type of autism considered in\ntheir research, a significant number did not. Omitting information on\nthe type of autism considered in studies can hinder accurate interpreta-\ntion and reduce the applicability of findings, leading to potential mis-\ninterpretations and limiting the generalizability of research outcomes.\nAdditionally, the absence of this specification may impede meaning-\nful comparisons across studies, hindering the overall advancement of\nknowledge in the field of emotion recognition in autism.\nThe lack of proper specification of gender aspects in over half of the\nreviewed studies can have several consequences. It may lead to an in-\ncomplete understanding of how gender influences the outcomes of the\nresearch, potentially masking gender-related patterns or differences in\nemotional recognition within the context of ASD. Additionally, it hin-\nders the generalizability of"}]}