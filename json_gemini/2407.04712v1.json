{"title": "Sensing technologies and machine learning methods for emotion recognition in autism: Systematic review", "authors": ["Oresti Banos", "Zhoe Comas-Gonz\u00e1lez", "Javier Medina", "Aurora Polo-Rodr\u00edguez", "David Gil", "Jes\u00fas Peral", "Sandra Amador", "Claudia Villalonga"], "abstract": "Background: Human Emotion Recognition (HER) has been a popular field of study in the past years. Despite the great progresses made so far, relatively little attention has been paid to the use of HER in autism. People with autism are known to face problems with daily social communication and the prototypical interpretation of emotional responses, which are most frequently exerted via facial expressions. This poses significant practical challenges to the application of regular HER systems, which are normally developed for and by neurotypical people. Objective: This study reviews the literature on the use of HER systems in autism, particularly with respect to sensing technologies and machine learning methods, as to identify existing barriers and possible future directions. Methods: We conducted a systematic review of articles published between January 2011 and June 2023 according to the 2020 PRISMA guidelines. Manuscripts were identified through searching Web of Science and Scopus databases. Manuscripts were included when related to emotion recognition, used sensors and machine learning techniques, and involved children with autism, young, or adults. Results: The search yielded 346 articles. A total of 65 publications met the eligibility criteria and were included in the review. Conclusions: Studies predominantly used facial expression techniques as the emotion recognition method. Consequently, video cameras were the most widely used devices across studies, although a growing trend in the use of physiological sensors was observed lately. Happiness, sadness, anger, fear, disgust, and surprise were most frequently addressed. Classical supervised machine learning techniques were primarily used at the expense of unsupervised approaches or more recent deep learning models. Studies focused on autism in a broad sense but limited efforts have been directed towards more specific disorders of the spectrum. Privacy or security issues were seldom addressed, and if so, at a rather insufficient level of detail.", "sections": [{"title": "1. Introduction", "content": "Autism spectrum disorder (ASD) is a neurodevelopmental condition characterized by a deficit in communication, social interaction, and lack of understanding of emotions. It affects circa 1% of the population and can be detected in the first years of life [1]. One of the key reasons for the emotional misunderstanding is the inability of people with autism to comprehend prototypical feelings and emotions, which directly affects social interaction. In view of this challenge, some research has been lately devoted to the automatic recognition of human emotions in autism. This research area is largely based on the well-established field of Human Emotion Recognition (HER), which exploits sophisticated sensing technologies and advanced machine learning techniques to detect and understand the feelings and emotions of people. Even when HER systems have been used to detect, intervene, and accompany the adaptation process of people with autism into society, it is generally accepted that existing approaches are not definitive. Many of these studies deal with biased data and recognition of emotions such as happiness or fear was only marginally impaired in autism as well as the generalizability of the findings from the currently available data remains unclear [2,3]. Furthermore, HER algorithms primarily rely on facial cues, overlooking other important aspects such as body language, vocal tone, and contextual and situational factors that would improve the accuracy of the algorithms [4]. [5] and [6] describe new tools as well as computational model to assist people with autism in understanding and operating in the socioemotional world around them. Some findings reveal that children with autism spectrum condition have residual difficulties in this aspect of empathy. In the work of [7] authors concluded that relations between particular emotions and human body reactions have long been known, but there remain many uncertainties in selecting measurement and data analysis methods Moreover, it is also observed that a great number of the HER models used in autism are based on data collected from neurotypical people [8]. Be that as it may, the use of general HER models in autism-related applications poses a number of challenges yet to be addressed and which demand special attention from the scientific community. While there exists a great bulk of systematic reviews addressing the technologies and methods used for emotion recognition in general [7,9\u201311], very few focus specifically on its use in autism. In fact, existing systematic reviews in this direction are either centred on a specific technology such as eye-tracking [12], robots [13], and wearables [14], or particular methods like deep learning [15]. Hence, a comprehensive systematic review focusing on the state of the art on emotion recognition sensing technologies and machine learning methods for autism emotion recognition is presented here. The results of this review will contribute to improve the current techniques for emotion recognition used in autism studies, encourage new research focusing on other conditions of the autism spectrum disorder that have been marginally investigated to date, and promote the use of physiological methods in addition to other traditional behavioural methods as potential emotion recognition modalities to be used in autism. The primary objective of this review was to determine the trends, advances, and challenges on sensing technologies and machine learning methods for emotion recognition in autism. To that end, this review aimed to answer the following research questions: (1) What type of sensor technology has been used for emotion recognition in autism?; (2) What type of machine learning techniques are most commonly used for emotion recognition in people with autism?; and (3) What are the main challenges in the use of emotion recognition technologies in people with autism? To the best of our knowledge, there are many reviews on autism, on HER, on machine learning methods but very little written about the whole of them and their complementation of these different areas. This is the main novelty of this review. Our study covers all age groups unlike most studies that focus on children. We raised a specific question to identify the main challenges in the use of emotion recognition technologies in autism. We also provide privacy and security aspects including the use of inform consents or approval by ethics committees. Furthermore, we offer a more recent view on the art as its search reaches up to June 2023."}, {"title": "2. Methods", "content": "The PRISMA 2020 (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines [16] were followed to perform a systematic review of the literature on sensing technologies and machine learning methods for emotion recognition in autism. The specific methodology followed is described in the following sections."}, {"title": "2.1. Eligibility criteria", "content": "This review focused on studies that dealt with sensor technology and machine learning techniques for emotion recognition in children, young, and adults with autism. We did not restrict study location, sample size, gender, age, autism type, type of emotion, emotion recognition modality, devices and sensors, nor algorithms. Studies were eligible to be included in this review if they had three characteristics: 1) they were related to emotion recognition; 2) used sensors and machine learning techniques; and 3) involved children with autism, young or adults. Other eligibility criteria included: 1) published between January 2011 and June 2023; 2) written in English; 3) scientific article published in a journal or in conference proceedings; and 4) research domain related to computer science or engineering. Studies were ineligible if affective technology was used in therapy and treatment of patients with autism or in an educational environment. Therefore, we excluded studies related to: 1) robotic treatments or therapies; and 2) social interaction and education."}, {"title": "2.2. Information sources", "content": "We conducted electronic searches for eligible studies within the reference databases of Scopus and Web of Science. The search was conducted from 1st January 2011 to 30th June 2023."}, {"title": "2.3. Search strategy", "content": "\"Autism\" and \"emotion recognition\"/\"recognition of emotion\" were selected as primal concepts to be searched. In addition to them, synonyms of the \"autism\" term, namely \"autistic\", and the \"emotion\" term, namely \"mood\" and \"affect\", were also considered as they are quite often used interchangeably in this research area. Limits were also applied to the search strategy based on the eligibility criteria. We selected papers published between 2011-2023, published in English computer science or engineering journals or proceedings. The resulting queries eventually run on Scopus and Web of Science are shown below. Scopus: TITLE-ABS-KEY(((autism OR autistic) AND (\"emotion recognition\" OR \"mood recognition\" OR \"affect recognition\" OR \"recognition of mood\" OR \"affect recognition\" OR \"recognition of affect\")) AND (LIMIT-TO (PUBYEAR, 2023) OR LIMIT-TO (PUBYEAR, 2022) OR LIMIT-TO (PUBYEAR,2021) OR LIMIT-TO (PUBYEAR,2020) OR LIMIT-TO (PUBYEAR,2019) OR LIMIT-TO (PUBYEAR, 2018) OR LIMIT-TO (PUBYEAR, 2017) OR LIMIT-TO (PUBYEAR, 2016) OR LIMIT-TO (PUBYEAR,2015) OR LIMIT-TO (PUBYEAR,2014) OR LIMIT-TO (PUBYEAR,2013) OR LIMIT-TO (PUBYEAR, 2012) OR LIMIT-TO (PUBYEAR, 2011)) AND (LIMIT-TO (LANGUAGE, \"English\")) AND (LIMIT-TO (DOCTYPE, \"ar\") OR LIMIT-TO (DOCTYPE,\"cp\")) AND (LIMIT-TO (SUBJAREA, \"COMP\") OR LIMIT-TO (SUBJAREA, \"ENGI\")) AND (LIMIT-TO (SRCTYPE, \"p\") OR LIMIT-TO (SRCTYPE, \"j\"))) Web of Science: (TS=(((((autism OR autistic) AND (\"emotion recognition\" OR \"mood recognition\" OR \"affect recognition\" OR \"recognition of mood\" OR \"affect recognition\" OR \"recognition of affect\"))))) AND (PY==(\"2023\" OR \"2022\" OR \"2021\" OR \"2020\" OR \"2019\" OR \"2018\" OR \"2017\" OR \"2016\" OR \"2015\" OR \"2014\" OR \"2013\" OR \"2012\" OR \"2011"}, {"title": "2.4. Selection process", "content": "The records retrieved from the databases and hand search were imported to the Mendeley Web Library, which was used as a primary tool to navigate through both records and reports. Duplicate records were manually identified by cross-checking title and abstract and then removed by three reviewers (ZC, OB, CV). These reviewers also screened each record and each report retrieved, assessed their eligibility, and eventually selected the final set of studies to be included in the review after reaching a majority consensus."}, {"title": "2.5. Data collection process", "content": "All reviewers (ZC, OB, JM, AP, DG, JP, SA, CV) participated in the review and assessment of the included studies. The studies were evenly distributed among three groups of reviewers according to their affiliation. We used a cloud-based collaborative spreadsheet (Google Spreadsheet) to collect data from the included studies. The document consisted of a state-of-the-art matrix where each row represented a study and the columns indicated the data items to be analyzed. Each group of reviewers had to full screen and analyze the papers that were assigned to them and fill the information in the corresponding columns of the matrix. Periodic meetings were held in order to harmonise terminology and overcome potential discrepancies in the assessment process. Reviewers worked independently to extract the information."}, {"title": "2.6. Data items", "content": "The columns defined in the collaborative spreadsheet corresponded to the outcomes for which data were sought. The specific columns defined were: study name, year of publication, type of article, research goals, subject condition (autism type), emotion recognition modality, dataset (collection or use of), description of the dataset (if applicable), emotions sensed, devices used for the data collection, machine learning techniques, validation methods, study sample (size, type), study length, performance results, study outcomes, privacy and security, and challenges and future work."}, {"title": "3. Results", "content": "A sample of 371 records were identified from the literature search. Namely, the search in Scopus yielded 206 records, while 165 records were obtained for Web of Science. 71 duplicate records were removed before screening. After deduplication, 300 records remained and were screened based on title and abstract. 112 records were excluded and 188 reports were sought for retrieval. 13 reports could not be retrieved and the remaining 175 reports were assessed for eligibility. 110 reports were excluded according to the eligibility criteria and the remaining 65 reports were included for the analysis. The workflow with the detailed process is shown in Fig. 1."}, {"title": "3.2. Research goal", "content": "The objectives for investigating emotion recognition in autism vary across studies. However, certain common goals are shared among some of these studies. Thus, for example, 29% (19/65) of the studies propose and analyze algorithms and machine learning techniques to automatically recognize emotions in people with autism [17\u201334]. Around 18% (12/65) of the studies propose the development and application of video games and apps to help children with autism understand and express emotions [8,35\u201345]. Fewer than 5% (3/65) of the studies explore the use of physiological signals for the automated identification of emotions [19,46,47]. The remainder of the studies have disparate goals. All research goals are detailed in Table A.1."}, {"title": "3.3. Autism type", "content": "The type of autism varies across studies (Fig. 2). For example, 70% (46/65) of the studies address \"autism\" in general [8,17\u201323,28\u201335,38\u201340,42,44,46,48\u201371], while 12% (8/65) refer to the full spectrum as \"all kind of autism\" [24\u201327,37,72\u201374]. Studies referring to \"autism\" tend to address broad aspects that apply to the overarching spectrum of ASD. In contrast, when some studies specifically mention \"all kind of autism\", they appear to suggest a deliberate effort to encompass the diverse manifestations and subtypes within the autism spectrum, recognizing and considering the heterogeneity of the condition. Nonetheless, most often both terms are used interchangeably. In some studies specific subtypes of the disorder are addressed. For example, 8% (5/65) correspond to high-functioning autism [45,61,75\u201377]. Less than 2% (1/65) to mild autism [78] and 2% (1/65) to attention-deficit hyperactivity disorder [79]. 6% (4/65) address combinations of parts of the spectrum, namely middle and moderate autism [47], all kinds of autism and Asperger [36], and high-functioning autism and Asperger [41,80]. While there exist a varied distribution of research focus across subtypes, the contributions in this regard are comparatively low. The limited focus on these subtypes may suggest that the majority of research in ASD aims to address broader aspects of the spectrum rather than delving into detailed examinations of specific subtypes. In Table A.2, the subtype of autism addressed in each selected paper is listed."}, {"title": "3.4. Emotional expressions", "content": "The selected studies focus on diverse emotional responses, expressions and sensed body regions or signals (Fig. 3). The most common emotion recognition modality is based on facial expressions, accounting for 63% (41/65) of the studies [8,20,22,23,26,28\u201332,34\u201338,40\u201346,49,51\u201356,58\u201361,64,67,68,72,75,76,79,80]. 15% (10/65) are based on speech aspects [25,27,63,65,66,69,71,73,74,77], followed by 5% (3/65) exploiting body movement [21,39,48], 2% (1/65) based on daily activities [17], 2% (1/65) measuring brain activity [19], and 2% (1/65) focusing on eye activity [78]. 12% (8/65) of the studies consist of a multimodal approach which combine some of the above [18,24,33,47,50, 57,62,70]. This distribution underscores the prevalent reliance on facial expressions while recognizing the significance of speech-related aspects in understanding and studying emotions within ASD. In relation to the sensed body regions or signals, the majority of studies 71% (46/65) use physical data, i.e. sensed from the external parts of the body, mostly the face. 20% (13/65) of the studies exploit the inner body, including physiological signals such as electroencephalography (EEG) and electromyography (EMG), or psychoacoustic signals [19,24,25,27,47,63,65,66,69,71,73,74,77]. The neurophysiological approaches provide valuable insights into the neural and muscular correlates of emotional states. As for the rationale behind considering psychoacoustics lies in the fundamental role of voice in the recognition of emotions within human interactions. By delving into the nuances of voice expression, researchers aim to deepen their understanding of how emotions are conveyed and perceived through auditory cues, con-"}, {"title": "3.5. Study characteristics", "content": "The average number of participants was 49, calculated from the 48 studies indicating the number of participants (74% of the studies) [8,18,19,21\u201327,29,30,32,33,36\u201341,44\u201348,50\u201355,57,58,60\u201362,65, 67,70,72\u201380]. The minimum sample size was four subjects [67] and the maximum 500 [22]. This diversity in sample sizes underscores the variability in research approaches within the field, with some studies opting for smaller, more focused samples, while others involve larger cohorts. Seventeen papers did not specify this number [17,20,28,31,34,35,42,43,49,56,59,63,64,66,68,69,71]. The absence of participant count details in a significant number of papers highlights the need for increased transparency and reporting consistency in research methodologies. The distribution of the studies based on the sample size is shown in Fig. 4. One day was the minimum study duration [19] and 140 days the maximum duration [48]. Yet, it must be noted that no additional information is provided in the rest of studies to this respect. The absence of duration details in the rest of the studies emphasizes the need for improved reporting standards to ensure a comprehensive understanding of the temporal aspects of HER research in autism. As for the neurodevelopmental disorder distribution, 51% (33/65) of the studies involved people with autism [8,18,21,22,25,27,29,32,33, 37\u201341,44\u201347,51,54,57,58,61,62,65,67,70,72,75\u201378,80]. Almost 28% (18/65) included both people with and without autism [8,18,25,27,29, 38,41,44,45,47,54,57,58,74\u201379]. This approach allows researchers to explore and understand the unique features associated with ASD by contrasting them with individuals without the disorder. Around 9% (6/65) of the studies considered only people without autism [30,50,52,53,55, 81]. Although it is not always clearly stated, the reasons for only considering neurotypical individuals are either the desire to establish baseline characteristics or more often the lack of access to people with autism. In 32% (21/65) of the studies, the disorder is not precisely described [17,19,20,23,24,26,28,31,35,36,42,43,48,52,56,60,63,64,66,68,73]. In 23% (15/65) an existing dataset was used to test the proposed solution [19,28,30\u201332,34,40,42,43,49,63,66,68,69,71]. Less than 28% (18/65) of the studies involved subjects of both genders [18,23,24,27,29,30,36,37,39,50,54,57,65,70,72\u201374,76]. 5%"}, {"title": "3.6. Types of emotions", "content": "The set of emotions analyzed in the selected studies are broadly based on the six universal emotional expressions, i.e. \"anger\", \"sadness\", \"happiness\", \"disgust\", \"surprise\", and \"fear\" [82]. 43% (28/65) of the studies focused on these six basic emotions [18,22,23,26,27, 30,32,35,37,38,47\u201350,56\u201361,73\u201380]. Two studies [20,68] used these very six emotions but replacing \"disgust\" with the \"neutral\" emotional state. Another study only uses four basic emotions adding \"delight\" and \"joy\" emotions [34]. The remaining 33 studies (51%) [8,17,19,21,24, 25,29,31,33,36,39\u201346,50\u201355,62\u201367,69,71,72] used a number of emotions ranging from two to nine primitives. The emotions considered in addition to the six basic ones were \"neutral\", \"calm\", \"nervous\", \"scared\", \"curious\u201d, \u201cexcited\u201d, \"sleepy\", \"contempt\", \"joy\", \"interested\", \"positive\", \"positive and talking\", \"odd positive\", \"negative\", \"boredom\", and \"contentment\"."}, {"title": "3.7. Devices and sensors", "content": "Two generations of devices and sensors are identified for the time frame considered for this review, which is related to the periods 2011-2014 and 2015-2023, respectively. Around 11% (7/65) of the studies correspond to the period 2011-2014, which is characterized by using images and audio as the primary data source. 57% (4/7) of these studies use a so-called first generation of devices consisting of webcams, headphones, and microphones [36,73,74,77]. To facilitate the labelling of the user's data, some controls were incorporated into the systems in 43% (3/7) of the aforementioned studies, including control knobs [74,77] or numeric keypads [79], which were easily handled by users with autism. This period marked the initial steps in using technology for autism research, establishing a foundation for future studies. Circa 89% (58/65) of the studies represent the period 2015-2023, which is distinguished by a second generation of more advanced and ubiquitous devices and sensors. The technological advancement introduced a wide range of versatile devices, including mobile phones, tablets, 3D cameras, infrared cameras, and more, expanding the capabilities for data collection. Thus, for example, handheld devices are included in 16% (9/58) of these studies, including mobile phones [30,40,50], tablets [37,78], and other handheld devices [58]. Some of these devices were used to support gamification apps [8] or to exploit the mobile camera sensor for recognition purposes [30,35]."}, {"title": "3.8. Models and performance", "content": "This subsection summarises the findings concerning machine learning techniques, performance and metrics, validation methods, and the number of data samples. The reviewed studies make primary use of supervised learning techniques. Support vector machines (SVM) stand out as the most widely used technique, namely in 29% (19/65) of the studies [8,19,21,23,24, 27,29,31,39,41,46\u201350,60,69,73,74]. SVM, together with other classical machine learning techniques such as decision trees (DT), random forest (RF), logistic regression (LR) and nearest neighbours k (KNN), are present in roughly 54% (35/65) of the studies reviewed. The remaining 17% (11/65) of the studies do not provide any information on the techniques used [36,37,56\u201359,61,75,78\u201380]. The use of Deep Learning is currently confined to recent works, constituting a 31% (20/65) of the studies [20,25,28\u201334,40\u201343,63\u201366,68, 69,71]. This limitation suggests an untapped opportunity, as earlier research may not have fully harnessed the capabilities of deep learning for complex pattern recognition tasks in emotion recognition in autism. Notably, some of the most recent works leverage Deep Learning techniques, including convolutional neural networks, highlighting the emerging potential for improved performance in emotion recognition. However, it is crucial to acknowledge a potential bias towards supervised learning, indicating a potential gap in exploring unsupervised or semi-supervised methods. These alternative approaches could offer valuable insights, especially in scenarios where labelled data is scarce or challenging to acquire. Exploring a broader spectrum of deep learning methodologies could enhance the versatility and effectiveness of emotion recognition models. The performance of emotion recognition models varies significantly among the studies, attributed to differences in target emotions, sensor data types, machine learning techniques, and dataset instances. This variation suggests challenges in directly comparing study outcomes and establishing standardized benchmarks. Studies can be categorized into three groups according to performance levels. First, 28% (18/65) of the studies are ranked as of high performance (i.e. accuracies greater than 90%), most usually developing an offline evaluation based on datasets collected under controlled conditions [8,21,23,24,26,28,32,40,41,43, 49,55,59,67,70,72,76,80]. The second group characterizes by performances within the range 80-90%, representing 23% (15/65) of the studies [17,18,22,29,38,42,48,53,58,60,63,66,73,74,78]. The third and last group encompass 26% (17/65) of the studies [19,20,25,31,33,39,40, 50\u201352,54,62,64,65,68,69,77], with more ambitious and challenging solutions based on emerging sensor technologies, leading to performances below 80%. The remaining studies have not sufficiently described their performance results and could not be classified into any group. The studies make use of a variety of metrics to evaluate model performance, including accuracy, sensitivity, and specificity. This range of metrics provides a fair understanding of model performance, especially those handling dataset imbalances. Concerning the metrics used to estimate model performance, around 57% (37/65) of the studies have chosen the use of accuracy [8,17\u201324,28\u201330,32,33,35,38\u201343,46,48\u201350, 52\u201355,62\u201364,66\u201370]. Other studies have used unweighted average recall to deal with data set imbalance more effectively [27,30,65,74]. Sensitivity has also been used in some studies [51,59,72], although they still need to evaluate the prominence of true negatives by avoiding the use of specificity. Few studies [18,22,41] rely on the use of accuracy,"}, {"title": "3.9. Information privacy and security", "content": "Despite the relevance of ensuring privacy and security policies in this field, only 22% (14/65) of the studies acknowledge these sufficiently [18,23,24,29,36,39,41,47,54,58,61,67,72,79]. Three of these studies [23,72,79] followed the 1964 Declaration of Helsinki, a formal statement of ethical principles published by the World Medical Association (WMA) to guide the protection of human participants in medical research [83]. The other 11 studies mentioned that they either had the consent of the relatives of the people with autism or their work was approved by the ethics committee of the given universities or other institutions. All details are provided in Table A.8. Upon analyzing the obtained results, the majority of studies that indicated privacy and security aspects had obtained consent from family members, or the research was approved by ethical committees of universities/institutions; very few studies adhered to the Declaration of Helsinki. However, it is evident that there is insufficient consideration of privacy and security aspects in the majority of studies. Studies lacking pertinent details may not adhere to ethical protocols, thereby generating concerns about the protection of participants."}, {"title": "4. Discussion", "content": "The great majority of the studies analyzed referred to the autism spectrum disorder in different ways. Namely, it was noticed the use of two terminologies \"autism\" and \"all kinds of autism\" to refer to this condition interchangeably. This shows a lack of unification on the use of this terminology by the scientific community of the HER field. More importantly, more research needs to be placed towards mild and high-functioning autism, as well as other conditions of the autism spectrum like Asperger, which according to the results are just marginally considered. While a majority of studies indicate the type of autism considered in their research, a significant number did not. Omitting information on the type of autism considered in studies can hinder accurate interpretation and reduce the applicability of findings, leading to potential misinterpretations and limiting the generalizability of research outcomes. Additionally, the absence of this specification may impede meaningful comparisons across studies, hindering the overall advancement of knowledge in the field of emotion recognition in autism. The lack of proper specification of gender aspects in over half of the reviewed studies can have several consequences. It may lead to an incomplete understanding of how gender influences the outcomes of the research, potentially masking gender-related patterns or differences in emotional recognition within the context of ASD. Additionally, it hinders the generalizability of findings, as the impact of gender on emotion recognition might be relevant. The number of participants involved in the studies varies remarkably, thus limiting the comparability of the results. While it is generally encouraged in the area to include as many participants as possible, the number of involved individuals should be fairly supported via an appropriate statistical power analysis. At least, it should be attempted to guarantee a sufficient number of participants matching the average number of the art. The emotion recognition modality most predominantly used is the one based on facial expressions, followed by speech. The reason for favouring the measurement of physical variables over physiological might be related to the fact that emotions are socially expressed and perceived via physical cues, such as facial and visual expressions and"}, {"title": "4.1. Findings", "content": "the voice tone. ASD is however sometimes characterized by a lack of expressiveness. Hence", "neutral\" stands out as the most frequent one, possibly due to its prevalence in the daily life. The majority of devices and sensors employed in the period 2015-2023 are seen to be particularly advances with respect to the ones used in the period 2011-2014. IP and infrared cameras, face or body tracking sensors, and partially wearable sensors or robots are used in the second half of the decade while more traditional systems such as webcams and microphones were used during the first half. From our analysis we can conclude that most works use a single technology to assess emotions in autism. The main reason for considering a sole device could be to simplify the sensor setup and lessen the intrusiveness sometimes felt by users when using these technologies. Combining multiple technologies to assess emotions may potentially lead to more accurate and robust decisions, as shown in the literature for neurotypical populations [84]. However, as we found out in a former study of ours [85], people with autism (adolescents) show reluctance to using multiple devices, and in particular to some specific ones such as infrared cameras. All the algorithms used are of the supervised kind, which was expected since most of the reviewed studies are aimed at diagnosing autism. A limitation observed for such approaches is that they tend to be learned on general-purpose emotion recognition datasets, most likely due to a clear lack of existing autism-specific datasets. General-purpose datasets could serve well for boosting some machine learning models, however they are of limited use when it comes to recognising the emotions expressed by people with autism. One goal for the community could then be the creation of new relevant datasets particularly devised for autism applications. Moreover, we did not find any study exploring the use of unsupervised methods. The use of these methods allows for the creation of clusters, which could help identify people with similar patterns within a similar spectrum. This is found of much interest specially when it comes to a disorder like autism, which is quite diverse per se. The performance results have been shown to vary among studies. High performances are obtained for a number of studies, however, it is observed that most of such studies do not describe in sufficient detail the evaluation method, thus hindering the validity of the reported results. Cross-validation and accuracy metrics are most widely used for evaluating the emotion recognition models performance [86]. A minority of the studies characterize the performance of their system more comprehensively using other metrics such as sensitivity and specificity. In order to avoid the effects of data bias, future research in this area is encouraged to consider using more robust metrics such as the F-score [87]. The number of data samples is also found key to determine the relevance of the reported results, and according to this review, only a minority of the studies appear to use a relevant sample set. This limits somewhat the validity of some of the results reported in the reviewed studies. Privacy and security aspects have been partially addressed and only by a minority of the studies. It should be noted```json\n{\n ": "itle", "Sensing technologies and machine learning methods for emotion recognition in autism: Systematic review": "authors", "Oresti Banos": "Zhoe Comas-Gonz\u00e1lez", "Javier Medina": "Aurora Polo-Rodr\u00edguez", "David Gil": "Jes\u00fas Peral", "Sandra Amador": "Claudia Villalonga", "abstract": "Background: Human Emotion Recognition (HER) has been a popular field of study in the past years. Despite the great progresses made so far, relatively little attention has been paid to the use of HER in autism. People with autism are known to face problems with daily social communication and the prototypical interpretation of emotional responses, which are most frequently exerted via facial expressions. This poses significant practical challenges to the application of regular HER systems, which are normally developed for and by neurotypical people.\nObjective: This study reviews the literature on the use of HER systems in autism, particularly with respect to sensing technologies and machine learning methods, as to identify existing barriers and possible future directions.\nMethods: We conducted a systematic review of articles published between January 2011 and June 2023 according to the 2020 PRISMA guidelines. Manuscripts were identified through searching Web of Science and Scopus databases. Manuscripts were included when related to emotion recognition, used sensors and machine learning techniques, and involved children with autism, young, or adults.\nResults: The search yielded 346 articles. A total of 65 publications met the eligibility criteria and were included in the review.\nConclusions: Studies predominantly used facial expression techniques as the emotion recognition method. Consequently, video cameras were the most widely used devices across studies, although a growing trend in the use of physiological sensors was observed lately. Happiness, sadness, anger, fear, disgust, and surprise were most frequently addressed. Classical supervised machine learning techniques were primarily used at the expense of unsupervised approaches or more recent deep learning models. Studies focused on autism in a broad sense but limited efforts have been directed towards more specific disorders of the spectrum. Privacy or security issues were seldom addressed, and if so, at a rather insufficient level of detail.", "sections": [{"title": "1. Introduction", "content": "Autism spectrum disorder (ASD) is a neurodevelopmental condition characterized by a deficit in communication, social interaction, and lack of understanding of emotions. It affects circa 1% of the population and can be detected in the first years of life [1]. One of the key reasons for the emotional misunderstanding is the inability of people with autism to comprehend prototypical feelings and emotions, which directly affects social interaction. In view of this challenge, some research has been lately devoted to the automatic recognition of human emotions in autism. This research area is largely based on the well-established field of Human Emotion Recognition (HER), which exploits sophisticated sensing technologies and advanced machine learning techniques to detect and understand the feelings and emotions of people. Even when HER systems have been used to detect, intervene, and accompany the adaptation process of people with autism into society, it is generally accepted that existing approaches are not definitive. Many of these studies deal with biased data and recognition of emotions such as happiness or fear was only marginally impaired in autism as well as the generalizability of the findings from the currently available data remains unclear [2,3]. Furthermore, HER algorithms primarily rely on facial cues, overlooking other important aspects such as body language, vocal tone, and contextual and situational factors that would improve the accuracy of the algorithms [4]. [5] and [6] describe new tools as well as computational model to assist people with autism in understanding and operating in the socioemotional world around them. Some findings reveal that children with autism spectrum condition have residual difficulties in this aspect of empathy. In the work of [7] authors concluded that relations between particular emotions and human body reactions have long been known, but there remain many uncertainties in selecting measurement and data analysis methods Moreover, it is also observed that a great number of the HER models used in autism are based on data collected from neurotypical people [8]. Be that as it may, the use of general HER models in autism-related applications poses a number of challenges yet to be addressed and which demand special attention from the scientific community. While there exists a great bulk of systematic reviews addressing the technologies and methods used for emotion recognition in general [7,9\u201311], very few focus specifically on its use in autism. In fact, existing systematic reviews in this direction are either centred on a specific technology such as eye-tracking [12], robots [13], and wearables [14], or particular methods like deep learning [15]. Hence, a comprehensive systematic review focusing on the state of the art on emotion recognition sensing technologies and machine learning methods for autism emotion recognition is presented here. The results of this review will contribute to improve the current techniques for emotion recognition used in autism studies, encourage new research focusing on other conditions of the autism spectrum disorder that have been marginally investigated to date, and promote the use of physiological methods in addition to other traditional behavioural methods as potential emotion recognition modalities to be used in autism. The primary objective of this review was to determine the trends, advances, and challenges on sensing technologies and machine learning methods for emotion recognition in autism. To that end, this review aimed to answer the following research questions: (1) What type of sensor technology has been used for emotion recognition in autism?; (2) What type of machine learning techniques are most commonly used for emotion recognition in people with autism?; and (3) What are the main challenges in the use of emotion recognition technologies in people with autism? To the best of our knowledge, there are many reviews on autism, on HER, on machine learning methods but very little written about the whole of them and their complementation of these different areas. This is the main novelty of this review. Our study covers all age groups unlike most studies that focus on children. We raised a specific question to identify the main challenges in the use of emotion recognition technologies in autism. We also provide privacy and security aspects including the use of inform consents or approval by ethics committees. Furthermore, we offer a more recent view on the art as its search reaches up to June 2023."}, {"title": "2. Methods", "content": "The PRISMA 2020 (Preferred Reporting Items for Systematic Reviews and Meta-Analyses) guidelines [16] were followed to perform a systematic review of the literature on sensing technologies and machine learning methods for emotion recognition in autism. The specific methodology followed is described in the following sections."}, {"title": "2.1. Eligibility criteria", "content": "This review focused on studies that dealt with sensor technology and machine learning techniques for emotion recognition in children, young, and adults with autism. We did not restrict study location, sample size, gender, age, autism type, type of emotion, emotion recognition modality, devices and sensors, nor algorithms. Studies were eligible to be included in this review if they had three characteristics: 1) they were related to emotion recognition; 2) used sensors and machine learning techniques; and 3) involved children with autism, young or adults.\nOther eligibility criteria included: 1) published between January 2011 and June 2023; 2) written in English; 3) scientific article published in a journal or in conference proceedings; and 4) research domain related to computer science or engineering. Studies were ineligible if affective technology was used in therapy and treatment of patients with autism or in an educational environment. Therefore, we excluded studies related to: 1) robotic treatments or therapies; and 2) social interaction and education."}, {"title": "2.2. Information sources", "content": "We conducted electronic searches for eligible studies within the reference databases of Scopus and Web of Science. The search was conducted from 1st January 2011 to 30th June 2023."}, {"title": "2.3. Search strategy", "content": "\"Autism\" and \"emotion recognition\"/\"recognition of emotion\" were selected as primal concepts to be searched. In addition to them, synonyms of the \"autism\" term, namely \"autistic\", and the \"emotion\" term, namely \"mood\" and \"affect\", were also considered as they are quite often used interchangeably in this research area. Limits were also applied to the search strategy based on the eligibility criteria. We selected papers published between 2011-2023, published in English computer science or engineering journals or proceedings. The resulting queries eventually run on Scopus and Web of Science are shown below. Scopus: TITLE-ABS-KEY(((autism OR autistic) AND (\\\"emotion recognition\\\" OR \\\"mood recognition\\\" OR \\\"affect recognition\\\" OR \\\"recognition of mood\\\" OR \\\"affect recognition\\\" OR \\\"recognition of affect\\\")) AND (LIMIT-TO (PUBYEAR, 2023) OR LIMIT-TO (PUBYEAR, 2022) OR LIMIT-TO (PUBYEAR,2021) OR LIMIT-TO (PUBYEAR,2020) OR LIMIT-TO (PUBYEAR,2019) OR LIMIT-TO (PUBYEAR, 2018) OR LIMIT-TO (PUBYEAR, 2017) OR LIMIT-TO (PUBYEAR, 2016) OR LIMIT-TO (PUBYEAR,2015) OR LIMIT-TO (PUBYEAR,2014) OR LIMIT-TO (PUBYEAR,2013) OR LIMIT-TO (PUBYEAR, 2012) OR LIMIT-TO (PUBYEAR, 2011)) AND (LIMIT-TO (LANGUAGE, \\\"English\\\")) AND (LIMIT-TO (DOCTYPE, \\\"ar\\\") OR LIMIT-TO (DOCTYPE,\\\"cp\\\")) AND (LIMIT-TO (SUBJAREA, \\\"COMP\\\") OR LIMIT-TO (SUBJAREA, \\\"ENGI\\\")) AND (LIMIT-TO (SRCTYPE, \\\"p\\\") OR LIMIT-TO (SRCTYPE, \\\"j\\\"))) Web of Science: (TS=(((((autism OR autistic) AND (\\\"emotion recognition\\\" OR \\\"mood recognition\\\" OR \\\"affect recognition\\\" OR \\\"recognition of mood\\\" OR \\\"affect recognition\\\" OR \\\"recognition of affect\\\"))))) AND (PY==(\\\"2023\\\" OR \\\"2022\\\" OR \\\"2021\\\" OR \\\"2020\\\" OR \\\"2019\\\" OR \\\"2018\\\" OR \\\"2017\\\" OR \\\"2016\\\" OR \\\"2015\\\" OR \\\"2014\\\" OR \\\"2013\\\" OR \\\"2012\\\" OR \\\"2011\\\")) AND DT== (\\\"ARTICLE\\\") AND SJ==(\\\"ENGINEERING\\\" OR \\\"COMPUTER SCIENCE\\\") AND LA== (\\\"ENGLISH\\\"))"}, {"title": "2.4. Selection process", "content": "The records retrieved from the databases and hand search were imported to the Mendeley Web Library, which was used as a primary tool to navigate through both records and reports. Duplicate records were manually identified by cross-checking title and abstract and then removed by three reviewers (ZC, OB, CV). These reviewers also screened each record and each report retrieved, assessed their eligibility, and eventually selected the final set of studies to be included in the review after reaching a majority consensus."}, {"title": "2.5. Data collection process", "content": "All reviewers (ZC, OB, JM, AP, DG, JP, SA, CV) participated in the review and assessment of the included studies. The studies were evenly distributed among three groups of reviewers according to their affiliation.\nWe used a cloud-based collaborative spreadsheet (Google Spreadsheet) to collect data from the included studies. The document consisted of a state-of-the-art matrix where each row represented a study and the columns indicated the data items to be analyzed. Each group of reviewers had to full screen and analyze the papers that were assigned to them and fill the information in the corresponding columns of the matrix. Periodic meetings were held in order to harmonise terminology and overcome potential discrepancies in the assessment process. Reviewers worked independently to extract the information."}, {"title": "2.6. Data items", "content": "The columns defined in the collaborative spreadsheet corresponded to the outcomes for which data were sought. The specific columns defined were: study name, year of publication, type of article, research goals, subject condition (autism type), emotion recognition modality, dataset (collection or use of), description of the dataset (if applicable), emotions sensed, devices used for the data collection, machine learning techniques, validation methods, study sample (size, type), study length, performance results, study outcomes, privacy and security, and challenges and future work."}, {"title": "3. Results", "content": "A sample of 371 records were identified from the literature search. Namely, the search in Scopus yielded 206 records, while 165 records were obtained for Web of Science. 71 duplicate records were removed before screening. After deduplication, 300 records remained and were screened based on title and abstract. 112 records were excluded and 188 reports were sought for retrieval. 13 reports could not be retrieved and the remaining 175 reports were assessed for eligibility. 110 reports were excluded according to the eligibility criteria and the remaining 65 reports were included for the analysis. The workflow with the detailed process is shown in Fig. 1."}, {"title": "3.2. Research goal", "content": "The objectives for investigating emotion recognition in autism vary across studies. However, certain common goals are shared among some of these studies. Thus, for example, 29% (19/65) of the studies propose and analyze algorithms and machine learning techniques to automatically recognize emotions in people with autism [17\u201334]. Around 18% (12/65) of the studies propose the development and application of video games and apps to help children with autism understand and express emotions [8,35\u201345]. Fewer than 5% (3/65) of the studies explore the use of physiological signals for the automated identification of emotions [19,46,47]. The remainder of the studies have disparate goals. All research goals are detailed in Table A.1."}, {"title": "3.3. Autism type", "content": "The type of autism varies across studies (Fig. 2). For example, 70% (46/65) of the studies address \"autism\" in general [8,17\u201323,28\u201335,38\u201340,42,44,46,48\u201371], while 12% (8/65) refer to the full spectrum as \"all kind of autism\" [24\u201327,37,72\u201374]. Studies referring to \"autism\" tend to address broad aspects that apply to the overarching spectrum of ASD. In contrast, when some studies specifically mention \"all kind of autism\", they appear to suggest a deliberate effort to encompass the diverse manifestations and subtypes within the autism spectrum, recognizing and considering the heterogeneity of the condition. Nonetheless, most often both terms are used interchangeably. In some studies specific subtypes of the disorder are addressed. For example, 8% (5/65) correspond to high-functioning autism [45,61,75\u201377]. Less than 2% (1/65) to mild autism [78] and 2% (1/65) to attention-deficit hyperactivity disorder [79]. 6% (4/65) address combinations of parts of the spectrum, namely middle and moderate autism [47], all kinds of autism and Asperger [36], and high-functioning autism and Asperger [41,80]. While there exist a varied distribution of research focus across subtypes, the contributions in this regard are comparatively low. The limited focus on these subtypes may suggest that the majority of research in ASD aims to address broader aspects of the spectrum rather than delving into detailed examinations of specific subtypes. In Table A.2, the subtype of autism addressed in each selected paper is listed."}, {"title": "3.4. Emotional expressions", "content": "The selected studies focus on diverse emotional responses, expressions and sensed body regions or signals (Fig. 3). The most common emotion recognition modality is based on facial expressions, accounting for 63% (41/65) of the studies [8,20,22,23,26,28\u201332,34\u201338,40\u201346,49,51\u201356,58\u201361,64,67,68,72,75,76,79,80]. 15% (10/65) are based on speech aspects [25,27,63,65,66,69,71,73,74,77], followed by 5% (3/65) exploiting body movement [21,39,48], 2% (1/65) based on daily activities [17], 2% (1/65) measuring brain activity [19], and 2% (1/65) focusing on eye activity [78]. 12% (8/65) of the studies consist of a multimodal approach which combine some of the above [18,24,33,47,50, 57,62,70]. This distribution underscores the prevalent reliance on facial expressions while recognizing the significance of speech-related aspects in understanding and studying emotions within ASD. In relation to the sensed body regions or signals, the majority of studies 71% (46/65) use physical data, i.e. sensed from the external parts of the body, mostly the face. 20% (13/65) of the studies exploit the inner body, including physiological signals such as electroencephalography (EEG) and electromyography (EMG), or psychoacoustic signals [19,24,25,27,47,63,65,66,69,71,73,74,77]. The neurophysiological approaches provide valuable insights into the neural and muscular correlates of emotional states. As for the rationale behind considering psychoacoustics lies in the fundamental role of voice in the recognition of emotions within human interactions. By delving into the nuances of voice expression, researchers aim to deepen their understanding of how emotions are conveyed and perceived through auditory cues, con-"}, {"title": "3.5. Study characteristics", "content": "The average number of participants was 49, calculated from the 48 studies indicating the number of participants (74% of the studies) [8,18,19,21\u201327,29,30,32,33,36\u201341,44\u201348,50\u201355,57,58,60\u201362,65, 67,70,72\u201380]. The minimum sample size was four subjects [67] and the maximum 500 [22]. This diversity in sample sizes underscores the variability in research approaches within the field, with some studies opting for smaller, more focused samples, while others involve larger cohorts. Seventeen papers did not specify this number [17,20,28,31,34,35,42,43,49,56,59,63,64,66,68,69,71]. The absence of participant count details in a significant number of papers highlights the need for increased transparency and reporting consistency in research methodologies. The distribution of the studies based on the sample size is shown in Fig. 4.\nOne day was the minimum study duration [19] and 140 days the maximum duration [48]. Yet, it must be noted that no additional information is provided in the rest of studies to this respect. The absence of duration details in the rest of the studies emphasizes the need for improved reporting standards to ensure a comprehensive understanding of the temporal aspects of HER research in autism.\nAs for the neurodevelopmental disorder distribution, 51% (33/65) of the studies involved people with autism [8,18,21,22,25,27,29,32,33, 37\u201341,44\u201347,51,54,57,58,61,62,65,67,70,72,75\u201378,80]. Almost 28% (18/65) included both people with and without autism [8,18,25,27,29, 38,41,44,45,47,54,57,58,74\u201379]. This approach allows researchers to explore and understand the unique features associated with ASD by contrasting them with individuals without the disorder. Around 9% (6/65) of the studies considered only people without autism [30,50,52,53,55, 81]. Although it is not always clearly stated, the reasons for only considering neurotypical individuals are either the desire to establish baseline characteristics or more often the lack of access to people with autism. In 32% (21/65) of the studies, the disorder is not precisely described [17,19,20,23,24,26,28,31,35,36,42,43,48,52,56,60,63,64,66,68,73]. In 23% (15/65) an existing dataset was used to test the proposed solution [19,28,30\u201332,34,40,42,43,49,63,66,68,69,71]. Less than 28% (18/65) of the studies involved subjects of both genders [18,23,24,27,29,30,36,37,39,50,54,57,65,70,72\u201374,76]. 5%"}, {"title": "3.6. Types of emotions", "content": "The set of emotions analyzed in the selected studies are broadly based on the six universal emotional expressions, i.e. \"anger\", \"sadness\", \"happiness\", \"disgust\", \"surprise\", and \"fear\" [82]. 43% (28/65) of the studies focused on these six basic emotions [18,22,23,26,27, 30,32,35,37,38,47\u201350,56\u201361,73\u201380]. Two studies [20,68] used these very six emotions but replacing \"disgust\" with the \"neutral\" emotional state. Another study only uses four basic emotions adding \"delight\" and \"joy\" emotions [34]. The remaining 33 studies (51%) [8,17,19,21,24, 25,29,31,33,36,39\u201346,50\u201355,62\u201367,69,71,72] used a number of emotions ranging from two to nine primitives. The emotions considered in addition to the six basic ones were \"neutral\", \"calm\", \"nervous\", \"scared\", \"curious\u201d, \u201cexcited\u201d, \"sleepy\", \"contempt\", \"joy\", \"interested\", \"positive\", \"positive and talking\", \"odd positive\", \"negative\", \"boredom\", and \"contentment\"."}, {"title": "3.7. Devices and sensors", "content": "Two generations of devices and sensors are identified for the time frame considered for this review, which is related to the periods 2011-2014 and 2015-2023, respectively. Around 11% (7/65) of the studies correspond to the period 2011-2014, which is characterized by using images and audio as the primary data source. 57% (4/7) of these studies use a so-called first generation of devices consisting of webcams, headphones, and microphones [36,73,74,77]. To facilitate the labelling of the user's data, some controls were incorporated into the systems in 43% (3/7) of the aforementioned studies, including control knobs [74,77] or numeric keypads [79], which were easily handled by users with autism. This period marked the initial steps in using technology for autism research, establishing a foundation for future studies. Circa 89% (58/65) of the studies represent the period 2015-2023, which is distinguished by a second generation of more advanced and ubiquitous devices and sensors. The technological advancement introduced a wide range of versatile devices, including mobile phones, tablets, 3D cameras, infrared cameras, and more, expanding the capabilities for data collection. Thus, for example, handheld devices are included in 16% (9/58) of these studies, including mobile phones [30,40,50], tablets [37,78], and other handheld devices [58]. Some of these devices were used to support gamification apps [8] or to exploit the mobile camera sensor for recognition purposes [30,35]."}, {"title": "3.8. Models and performance", "content": "This subsection summarises the findings concerning machine learning techniques, performance and metrics, validation methods, and the number of data samples. The reviewed studies make primary use of supervised learning techniques. Support vector machines (SVM) stand out as the most widely used technique, namely in 29% (19/65) of the studies [8,19,21,23,24, 27,29,31,39,41,46\u201350,60,69,73,74]. SVM, together with other classical machine learning techniques such as decision trees (DT), random forest (RF), logistic regression (LR) and nearest neighbours k (KNN), are present in roughly 54% (35/65) of the studies reviewed. The remaining 17% (11/65) of the studies do not provide any information on the techniques used [36,37,56\u201359,61,75,78\u201380]. The use of Deep Learning is currently confined to recent works, constituting a 31% (20/65) of the studies [20,25,28\u201334,40\u201343,63\u201366,68, 69,71]. This limitation suggests an untapped opportunity, as earlier research may not have fully harnessed the capabilities of deep learning for complex pattern recognition tasks in emotion recognition in autism. Notably, some of the most recent works leverage Deep Learning techniques, including convolutional neural networks, highlighting the emerging potential for improved performance in emotion recognition. However, it is crucial to acknowledge a potential bias towards supervised learning, indicating a potential gap in exploring unsupervised or semi-supervised methods. These alternative approaches could offer valuable insights, especially in scenarios where labelled data is scarce or challenging to acquire. Exploring a broader spectrum of deep learning methodologies could enhance the versatility and effectiveness of emotion recognition models. The performance of emotion recognition models varies significantly among the studies, attributed to differences in target emotions, sensor data types, machine learning techniques, and dataset instances. This variation suggests challenges in directly comparing study outcomes and establishing standardized benchmarks. Studies can be categorized into three groups according to performance levels. First, 28% (18/65) of the studies are ranked as of high performance (i.e. accuracies greater than 90%), most usually developing an offline evaluation based on datasets collected under controlled conditions [8,21,23,24,26,28,32,40,41,43, 49,55,59,67,70,72,76,80]. The second group characterizes by performances within the range 80-90%, representing 23% (15/65) of the studies [17,18,22,29,38,42,48,53,58,60,63,66,73,74,78]. The third and last group encompass 26% (17/65) of the studies [19,20,25,31,33,39,40, 50\u201352,54,62,64,65,68,69,77], with more ambitious and challenging solutions based on emerging sensor technologies, leading to performances below 80%. The remaining studies have not sufficiently described their performance results and could not be classified into any group. The studies make use of a variety of metrics to evaluate model performance, including accuracy, sensitivity, and specificity. This range of metrics provides a fair understanding of model performance, especially those handling dataset imbalances. Concerning the metrics used to estimate model performance, around 57% (37/65) of the studies have chosen the use of accuracy [8,17\u201324,28\u201330,32,33,35,38\u201343,46,48\u201350, 52\u201355,62\u201364,66\u201370]. Other studies have used unweighted average recall to deal with data set imbalance more effectively [27,30,65,74]. Sensitivity has also been used in some studies [51,59,72], although they still need to evaluate the prominence of true negatives by avoiding the use of specificity. Few studies [18,22,41] rely on the use of accuracy,"}, {"title": "3.9. Information privacy and security", "content": "Despite the relevance of ensuring privacy and security policies in this field, only 22% (14/65) of the studies acknowledge these sufficiently [18,23,24,29,36,39,41,47,54,58,61,67,72,79]. Three of these studies [23,72,79] followed the 1964 Declaration of Helsinki, a formal statement of ethical principles published by the World Medical Association (WMA) to guide the protection of human participants in medical research [83]. The other 11 studies mentioned that they either had the consent of the relatives of the people with autism or their work was approved by the ethics committee of the given universities or other institutions. All details are provided in Table A.8.\nUpon analyzing the obtained results, the majority of studies that indicated privacy and security aspects had obtained consent from family members, or the research was approved by ethical committees of universities/institutions; very few studies adhered to the Declaration of Helsinki. However, it is evident that there is insufficient consideration of privacy and security aspects in the majority of studies. Studies lacking pertinent details may not adhere to ethical protocols, thereby generating concerns about the protection of participants."}, {"title": "4. Discussion", "content": "The great majority of the studies analyzed referred to the autism spectrum disorder in different ways. Namely, it was noticed the use of two terminologies \"autism\" and \"all kinds of autism\" to refer to this condition interchangeably. This shows a lack of unification on the use of this terminology by the scientific community of the HER field. More importantly, more research needs to be placed towards mild and high-functioning autism, as well as other conditions of the autism spectrum like Asperger, which according to the results are just marginally considered. While a majority of studies indicate the type of autism considered in their research, a significant number did not. Omitting information on the type of autism considered in studies can hinder accurate interpretation and reduce the applicability of findings, leading to potential misinterpretations and limiting the generalizability of research outcomes. Additionally, the absence of this specification may impede meaningful comparisons across studies, hindering the overall advancement of knowledge in the field of emotion recognition in autism. The lack of proper specification of gender aspects in over half of the reviewed studies can have several consequences. It may lead to an incomplete understanding of how gender influences the outcomes of the research, potentially masking gender-related patterns or differences in emotional recognition within the context of ASD. Additionally, it hinders the generalizability of findings, as the impact of gender on emotion recognition might be relevant. The number of participants involved in the studies varies remarkably, thus limiting the comparability of the results. While it is generally encouraged in the area to include as many participants as possible, the number of involved individuals should be fairly supported via an appropriate statistical power analysis. At least, it should be attempted to guarantee a sufficient number of participants matching the average number of the art. The emotion recognition modality most predominantly used is the one based on facial expressions, followed by speech. The reason for favouring the measurement of physical variables over physiological might be related to the fact that emotions are socially expressed and perceived via physical cues, such as facial and visual expressions and"}, {"title": "4.1. Findings", "content": "the voice tone. ASD is however sometimes characterized by a lack of expressiveness. Hence, it might be a good choice to observe and to analyze physiological behaviour in this population in addition to the physical one. A major part of the studies used the six basic universal emotions (anger, sadness, happiness, disgust, surprise, and fear) considered as a standard for HER systems. The reasons may have to do with the fact that such emotions represent the most common set expressed by people in their daily life [82", "neutral\" stands out as the most frequent one, possibly due to its prevalence in the daily life. The majority of devices and sensors employed in the period 2015-2023 are seen to be particularly advances with respect to the ones used in the period 2011-2014. IP and infrared cameras, face or body tracking sensors, and partially wearable sensors or robots are used in the second half of the decade while more traditional systems such as webcams and microphones were used during the first half. From our analysis we can conclude that most works use a single technology to assess emotions in autism. The main reason for considering a sole device could be to simplify the sensor setup and lessen the intrusiveness sometimes felt by users when using these technologies. Combining multiple technologies to assess emotions may potentially lead to more accurate and robust decisions, as shown in the literature for neurotypical populations [84": ".", "85": "people with autism (adolescents) show reluctance to using multiple devices, and in particular to some specific ones such as infrared cameras. All the algorithms used are of the supervised kind, which was expected since most of the reviewed studies are aimed at diagnosing autism. A limitation observed for such approaches is that they tend to be learned on general-purpose emotion recognition datasets, most likely due to a clear lack of existing autism-specific datasets. General-purpose datasets could serve well for boosting some machine learning models, however they are of limited use when it comes to recognising the emotions expressed by people with autism. One goal for the community could then be the creation of new relevant datasets particularly devised for autism applications. Moreover, we did not find any study exploring the use of unsupervised methods. The use of these methods allows for the creation of clusters, which could help identify people with similar patterns within a similar spectrum. This is found of much interest specially when it comes to a disorder like autism, which is quite diverse per se. The performance results have been shown to vary among studies. High performances are obtained for a number of studies, however, it is observed that most of such studies do not describe in sufficient detail the evaluation method, thus hindering the validity of the reported results. Cross-validation and accuracy metrics are most widely used for evaluating the emotion recognition models performance [86", "87": "."}]}]}