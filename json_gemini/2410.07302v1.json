{"title": "Examining the Prevalence and Dynamics of AI-Generated Media in Art Subreddits", "authors": ["Hana Matatov", "Marianne Aubin Le Qu\u00e9r\u00e9", "Ofra Amir", "Mor Naaman"], "abstract": "Broadly accessible generative AI models like Dall-E have made it possible for anyone to create compelling visual art. In online communities, the introduction of AI-generated content (AIGC) may impact community dynamics by shifting the kinds of content being posted or the responses to content suspected of being generated by AI. We take steps towards examining the potential impact of AIGC on art-related communities on Reddit. We distinguish between communities that disallow AI content and those without a direct policy. We look at image-based posts made to these communities that are transparently created by AI, or comments in these communities that suspect authors of using generative AI. We find that AI posts (and accusations) have played a very small part in these communities through the end of 2023, accounting for fewer than 0.2% of the image-based posts. Even as the absolute number of author-labelled AI posts dwindles over time, accusations of AI use remain more persistent. We show that Al content is more readily used by newcomers and may help increase participation if it aligns with community rules. However, the tone of comments suspecting AI use by others have become more negative over time, especially in communities that do not have explicit rules about AI. Overall, the results show the changing norms and interactions around AIGC in online communities designated for creativity.", "sections": [{"title": "Introduction", "content": "Online communities are grappling with how to respond to the availability of AI-generated content (AIGC) online. In this paper, we seek to characterize how online visual art communities may diverge based on whether they expressly forbid AI or choose to remain neutral towards the use of AI. On the one hand, communities that forbid the use of AI often cite that content quality may be lower, creative perspectives will be homogenized, and community values could be compromised (Lloyd, Reagle, and Naaman 2023; Frosio 2023; Radivojevic et al. 2024). Conversely, communities that choose not to forbid AI may be calling upon arguments that AI can be used in ways that help democratize certain hobbies, spark creativity, and may increase participation (Gero, Long, and Chilton 2023; Lloyd, Reagle, and Naaman 2023; Panchanadikar et al. 2024). Online communities are wrestling with these choices and strategies. Characterizing the dynamics and behaviors of community members, especially in communities that differ in their rules toward AI, can inform future community actions. We explore how this tension in explicitly restricting AI is playing out within art subreddit communities, which are highly creative, have specific community values, and where members may have broad access to AI for image generation.\nMore broadly, we also provide an initial understanding of behaviors around AIGC that have developed in art-based online communities. AIGC has been described as a \"paradigm shift in content creation and knowledge representation\" (Wang et al. 2023). Across different fields, emergent work has attempted to quantify the prevalence and responses to AIGC online, from impact to academic peer review and synthetic news articles, to online crowdwork (Liang et al. 2024; Latona et al. 2024; Veselovsky, Ribeiro, and West 2023; Christoforou, Demartini, and Otterbacher 2024; Hanley and Durumeric 2024). However, there is a need to understand how AIGC may impact online social ecosystems, since these are often based on community values and authenticity in ways that may be called into question by the widespread adoption of AIGC (Lloyd, Reagle, and Naaman 2023). In this study, we tackle this question as it related to online art communities.\nTo this end, we collect a list of 57 art-related subreddit communities, which we label as AI-neutral or Al-disallowed based on their stance towards AI posts. From these subreddits, we retrieve and classify 28,405 image-based posts where the poster has either admitted to generating the image with AI (Transparent Al post), or a commenter has accused the image of being AI-generated (Suspected Al post). We then analyze the number of AI-generated posts made to these communities over time, the trajectories of newcomers to these communities who post AI-generated images, and the speed and impact of AI-suspecting comments on posts. From our analysis of this data, we make the following contributions:\n\u2022 Overall, we find that the prevalence of posts made to these art-based communities where the authors transparently self-report AI-generated use, or where commenters raise suspicion about the use of AI is surprisingly low, affecting less than 0.2% of image-based posts in our dataset.\n\u2022 We find that the production of AI-based image posts"}, {"title": "Background", "content": "Our research focuses on online art communities, where we investigate the discussions about AI-generated images, specifically AI-generated art. The work therefore relates to extensive prior work in online communities, and emerging work on AI-generated content, particularly images."}, {"title": "Online Communities", "content": "Online communities have been a popular topic of study for internet researchers. One relevant theory to online communities is the concept of communities of practice (CoP) (Wenger 1999, 1996; Lave 1991; McDonald and Cater-Steel 2016; Wenger, McDermott, and Snyder 2002), where groups of people who share a common interest come together to explore these ideas, share, and improve their practice. CoP theory emphasizes that members engage in collective learning through shared practices, discussions, and activities, as is the case in Reddit art-based communities. Broadly speaking, online communities often wrestle with tradeoffs between different priorities, such as growth and attracting newcomers, sustainability, content quality, and fostering a sense of virtual belonging (Kairam, Mercado, and Sumner 2022; Lin et al. 2017; Hwang and Foote 2021; Kraut et al. 2012). Recent work on Reddit mapped subreddits into five archetype, which relate to different ways they produce a sense of community (Prinster et al. 2024) In this work, we are interested in art communities, which are probably most aligned with the Content Generation archetype from that work, and aim to understand how such a community of practice might be impacted by AIGC.\nIndeed, the recent emergence of AIGC may present a boon for online communities, but could also put community values under threat. The Diffusion of Innovations theory, formulated by Rogers (Rogers, Singhal, and Quinlan 2014; Rogers and Adhikarya 1979), focuses on the process by which individuals adopt new innovations and ideas, suggesting that different communities may also adapt innovations in diverse ways. Weld, Zhang, and Althoff (2024) identify that Reddit communities put emphasis on diverse values, and often prioritizing one comes at the cost of another \u2013 for example, the quality of content can be in direct conflict with the need to grow communities and be self-sustaining. Prior work has identified that the choice for whether to allow or disallow AI can force subreddit moderators to contend with which of these values to codify as rules (Lloyd, Reagle, and Naaman 2023). These decisions can have consequences beyond individual subreddits; recent work has demonstrated that simple changes like exposing moderation decisions significantly impacts the behaviors of users on the Reddit platform (Jhaver, Rathi, and Saha 2024). As communities content with the decision of how to moderate AI-generated content, this study provides initial evidence for how these decision may shape participation in online communities."}, {"title": "AI-Generated Images", "content": "Text-to-image models, such as DALL-E\u00b9, Stable Diffusion\u00b2, and Midjourney\u00b3, have exhibited exceptional performance in generating both abstract and photorealistic images. Prior to the advent of these models, Generative Adversarial Networks (GAN)-based models were employed to generate images (Brock, Donahue, and Simonyan 2018; Goodfellow et al. 2014; Zhang et al. 2021). With such popular image-generation tools available since 2022, the concept of AI-generated content have been increasingly impacting online communities.\nSince these tools are so advanced, one key challenge is the automatic detection or manual identification of AI-generated images. Efforts to determine whether an image was generated by generative models reveal the challenges humans face in accurately identifying AI-generated images (Lu et al. 2024; Nightingale and Farid 2022), with a misclassification rate of 38.7% (Lu et al. 2024). Furthermore, even the top-performing AI-generated image detection model achieves a misclassification rate of 13% (Lu et al. 2024).\nA few papers have specifically examined the detection of AI-generated art (Ha et al. 2024; Wang, Huang, and Hong 2023). Ha et al. (2024) showed that an approach combining human experts and automatic detectors was most effective, while non-artist crowdworkers generally were unable to discern between human-created art and AI-generated images. Given this technological ability to produce images, including art, and the inability of humans or machines to discern generated images, it is natural to expect that online communities might be impacted by AIGC."}, {"title": "AI-generated Art and Online Communities", "content": "AI-generated art is not just as an attempt for fabrication or low-effort creation. Several papers make the case for AI-generated art creations as authentic and creative (Mazzone and Elgammal 2019; Garcia 2024). Garcia (2024) specifically investigates AI-generated art produced by advanced technologies like DALL-E4. The paper provides a compre-"}, {"title": "Dataset", "content": "To investigate online discussions within art communities regarding AI-generated images, we undertook a careful process to select data from Reddit communities (subreddits) dedicated to art. Then we used an initial keyword-based filtering using a list of generative AI keywords, presented in this section, and LLM-based labeling, detailed in the next section."}, {"title": "Classification of the Dataset Using LLMS", "content": "Having gathered a dataset of potentially AI-relevant image-based posts based on keyword match, we further classified the posts using large language models (LLMs) (Abburi et al. 2023; Zhang et al. 2024; Pangakis and Wolken 2024) First, since keyword matching can be imprecise, we use classifiers to filter the dataset to only retain posts and comments genuinely pertaining to AI-generated images. Second, we differentiate between text that identifies the image in the post as being AI-generated, versus those that broadly mention AI-generated images.\nTo this end, we developed textual prompts and utilized the ChatGPT API9. Three distinct prompts were developed to correspond with each of the three type of text in our dataset: post's title or body, comments made by the author of the post, and comments by other users (see Appendix C). These prompts were designed following the principles of chain-of-thought prompting (Wei et al. 2022). Each prompt required the language model to provide reasoning before giving a classification decision. Additionally, each prompt included nine examples from the dataset, implementing an in-context few-shot learning approach (Wei et al. 2022).\nWe evaluated the accuracy of each of the three prompts using three validation sets. We randomly sampled 100 texts"}, {"title": "Categorization of the Communities", "content": "We categorized the 57 subreddits into two types of communities: those with rules that explicitly ban Al images, and those whose rules do not mention AI. Previous papers have explored the reactions of community moderators to AI-generated content, including focusing on the decisions of Reddit moderators to enact rules restricting the use of AI, as well as the responses of their communities (Lloyd, Reagle, and Naaman 2023; Shankar and Sim 2024). We set out to distinguish the different communities based on their expressed approach to AI content. Using the data provided via the PRAW API11, we examined each subreddit's API description, public description, and rules. If any of these fields indicated that AI-generated content (or particularly AI-generated images or art) is not permitted, we categorized the subreddit as \u201cAI-disallowed community\". Otherwise, if the publication of AI-generated content was not mentioned in the subreddit's description or rules, it was categorized as \u201cAI-neutral community\" 12. Among the 57 subreddits, 24 explicitly forbid AI, while the remaining 33 subreddits do not reference AI in their descriptions and rules.\nTo obtain a more comprehensive understanding and baseline for the subreddits in each category, we utilized torrents (Watchful1 2024) to count the total number of posts that included a media item in these communities, regardless of whether they contained the AI-related keywords. We refer to these posts that included a media item, such as an image or video, as \u201call image-based posts\u201d."}, {"title": "Analyses and Findings", "content": "In this section, we use the dataset we collected and refined in previous sections to examine variations in volume, participation, and feedback patterns across AI-disallowed communities and AI-neutral communities. This analysis highlights the distinctions between these two types of communities, as well as the differences in trends for the different types of posts Transparent AI posts and Suspected AI posts."}, {"title": "Rise of AI Posts and Comments", "content": "We conducted an analysis of post volume over time across different communities to understand how posting patterns shifted in response to the introduction and increasingly mainstream adoption of generative AI throughout 2022. Specifically, we examined temporal patterns of posts containing AI-generated images according to our classification, and compared these trends to the overall volume of image-based posts within the subreddits we examined. We explore how these trends vary over time between the AI-disallowed communities and the Al-neutral communities."}, {"title": "Participation and Newcomers", "content": "The previous sections focused on volume of posts and discussions over time and in relation to other image posts in the same communities. In this section, we examine the pattern of participation in creating AI-related posts across the different art communities. In particular, we focus on newcomers (first-time image posters). Is there evidence that AI-generated images make it easier for newcomers to contribute content \u2013 and if so, do these newcomers stay and contribute over time? Does this pattern diverge for those who are making Transparent Al posts to AI-disallowed versus AI-neutral communities?\nOverall, the participation of newcomers was significantly more emphasized in making Transparent Al posts than the overall presence of newcomers in posting images to these communities. In AI-disallowed communities, newcomers usually publish 6.71% of all image-based posts. This ratio is similar in AI-neutral communities, with 6.51% of newcomers publishing image-based posts. However, newcomers made as much as 25.15% of Transparent Al posts in Al-disallowed communities during our period of analysis. In Al-neutral communities, newcomers made a similar 22.99% of the Transparent Al posts. The differences between newcomer production of identified AI content versus regular content was significant for both types of communities (Chi-square, p < 0.00001).This over-representation in newcomers posting AI-generated content suggests that this kind of content may encourage and broaden community participation."}, {"title": "Feedback, Interactions and Sentiment", "content": "We investigate the interactions \u2013 responses and comments on identified or suspected AI-generated content, and how they are different, in tone or dynamics, from other content or across community types.\nFirst, we look at engagement levels with Transparent AI posts across different communities. We examined the engagement with image-based posts using the upvote ratio as a metric, which represents the proportion of upvotes relative to the total number of votes (both upvotes and downvotes) received by a post. For this analysis, we compared the distributions of upvote ratios in two distinct periods: (1) January-March 2022 and (2) January-March 2023. These periods were selected to capture the differences across an entire year, particularly given the release of significant text-to-image generation tools and the peak in activity observed towards the end of 2022, as discussed in previous sections.\nFigure 2 illustrates the cumulative distribution of posts across different upvote ratio ranges (X-axes), and the corresponding cumulative number of posts (Y-axes). The left panel displays the distributions for all image-based posts in the analyzed subreddits, while the right panel focuses on Transparent Al posts. Additionally, the upper panel shows posts within AI-disallowed communities, whereas the lower panel presents posts from Al-neutral communities. The figure shows that the upvote ratio distribution for all image-based posts across both community types was similar (top left and bottom panels), and that there were only minor differences (dotted vs. solid line) between 2022 and 2023 upvote ratios in both.\nWhile the responses to all image posts remained stable, the responses to Al posts (panels on the right side of the figure) had shifted between 2022 and 2023 in both types of communities, but in different directions. In AI-disallowed communities, responses to Transparent AI Posts were more positive in terms of upvote ratio in 2023 than in 2022. However, it is possible that this higher positivity is a result of these posts getting less total engagement in these communities overall. On the other hand, in AI-neutral communities, responses to Transparent AI Posts in 2023 had lower upvote ratio than in 2022.\nWe conducted a similar analysis for Suspected AI posts, which refer to posts where non-author commenters claimed or implied that the image was generated using AI tools. The engagement with Suspected AI Posts is entirely different than all image-based posts or Transparent AI posts, and cannot be directly compared to either. These posts generally have more engagement (comments and upvotes) than the other categories. This difference has a couple of explanations. First, Suspected AI Posts by definition have at least one comment, which already suggests different distributions. Second, the higher comparable engagement could"}, {"title": "Discussion", "content": "Our study provides insights about how AI-generated content is impacting online communities, specifically those that deal with creative visual content-in this case, art-related subreddits.\nPerhaps surprisingly, we observed low volumes of (admitted, transparent) AI-generated content in these communities compared to other media-based posts. Across 2022 and 2023, years with popular discussion of AI and growing availability of image-generating tools, posts that either transparently used AI or were accused of doing so together amounted to less than 0.2% of media posts. Of course, it is possible that AI-generated image posts are more prevalent, but neither the authors nor the commenters are identifying them. Studies on the prevalence of AIGC online are sparse, but those that exist in other domains for now also indicate low numbers \u2013 for example, estimating 1.39% of machine-generated news articles for mainstream news websites (Hanley and Durumeric 2024) or up to 0.05% of AI-generated profiles on Twitter (Ricker et al. 2024). Of course, since this technology is still new, any presence of AIGC on public platforms points towards propagation in the future, and a fundamental shift to how people communicate digitally.\nInterestingly, though, our data shows that the volume of Transparent Al posts diminished over time after a first (expected rise), perhaps as novelty declined. On the other hand, responses to posts that are suspected of using AI rose later, and remained somewhat higher through the end of our data collection. These dynamics suggest that we have entered a new era in online communities, where the public is suspicious about the AI provenance of information. Unfortunately, we know that suspicion of AI content is likely to lower trust online more broadly (Jakesch, Hancock, and Naaman 2023). We also find that people may be becoming more negative about AIGC over time, as negative sentiments in comments for Suspected Al posts increased between early and late 2023. Additionally, our analysis highlights how this broad suspicion may interact with online community rules and moderation: Al-disallowed communities receive more suspicion comments, and these appear more quickly.\nIn general, these findings raise the question of the role of rules and norms in online communities. There is clearly a difference in how communities decided to tackle the challenge of AI-generated content, and these norms and rules have both changed over time. It is important to continue to understand what brings about change of rules, how they are implemented, and how norms might shift as a result. Prior work identified that rules forbidding certain actions may appear later in a subreddit's lifecycle and are often associated with larger subreddits (Reddy and Chandrasekharan 2023; Fiesler et al. 2018). It is likely that this trend will be the same for rules about AI-generated content. While we used a binary classification system to differentiate between AI-disallowed and Al-neutral communities, it is possible and even likely that our AI-disallowed communities implemented rules forbidding AI at some point in the middle of our dataset timespan. While this possibility makes the temporal trends more salient, it may underrepresent the strength of some of our comparative findings where, for example Al-disallowed communities have not actually disallowed AI for the full period. We see a rich space for future work here. For example, scholars could study communities immediately before and after a rule change forbidding AI is implemented. Future work may also look to evaluate the effects of AI how subreddit bans are implemented and enforced. For example, prior work in other setting has found that exposing rulesets more readily can decrease harmful content while increasing newcomer participation (Matias 2019).\nOur findings carry implications for how AI may enable newcomers to participate in online communities, but also how AI-interested newcomers may change existing communities. First, newcomers to communities create proportionally more Transparent AI posts than general image-based posts. This newcomer over-representation confirms prior work that suggests that the introduction of generative AI leads to more participation and posting (Guo et al. 2024; Wei and Tyson 2024; Zhou and Lee 2024). We show that users whose first image-based post to a subreddit is a self-labelled AI-generated image continue to post such AIGC at high rates within the subreddit. This behavior suggests that creators who initially joined these subreddits to transparently share AI-generated art, and have returned to post again, are truly interested in AI-generated images or find it as their only possible avenue to contribute. Kraut et al. (2012) identify five basic challenges that online communities face when dealing with newcomers, and our findings suggest that while the ready availability of AIGC may help with the recruitment and retention of new members, these new members do not become socialized in the exact same way as members that do not post AIGC. Instead, new members that post AIGC appear to wish to continue posting AIGC and may become turned off from online communities once AI content is banned. Indeed, we find evidence that when such newcomers post to subreddits where AI-generated content is prohibited, they are less likely to remain engaged within the community. Possible explanations for this lower retention include criticism or bans from the moderators of the subreddits, negative feedback from other participants, low interaction or engagement with their posts, or the possibility that these users are low-value contributors that are less invested in the community itself and thus contribute less frequently. Of course, lower retention of newcomers may not be a universal negative if new contributions are low-effort, and prior work has found moderators are sometimes willing to make these sacrifices to uphold community values (Lloyd, Reagle, and Naaman 2023).\nOur work also contributes an analysis of comments that suspect the author used AI to generate posts. The data suggests that high levels of community engagement on the post (e.g. comments) is associated with AI suspicion by commenters. In other words, AI suspicion may be more readily attached to successful posts. Our findings also suggest that AI accusations arrive rapidly, especially in Al-disallowed communities, reflecting the heightened awareness among participants regarding the possibility of generative art. This rapid response could indicate the role of moderators or community members working to uphold the standards and environment of their respective communities by quickly identifying and challenging suspected AI-generated works."}]}