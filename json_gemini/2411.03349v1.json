{"title": "RuAG: LEARNED-RULE-AUGMENTED GENERATION FOR LARGE LANGUAGE MODELS", "authors": ["Yudi Zhang", "Pei Xiao", "Lu Wang", "Chaoyun Zhang", "Meng Fang", "Yali Du", "Yevgeniy Puzyrev", "Randolph Yao", "Si Qin", "Qingwei Lin", "Mykola Pechenizkiy", "Dongmei Zhang", "Saravan Rajmohan", "Qi Zhang"], "abstract": "In-context learning (ICL) and Retrieval-Augmented Generation (RAG) have gained attention for their ability to enhance LLMs' reasoning by incorporating external knowledge but suffer from limited contextual window size, leading to insufficient information injection. To this end, we propose a novel framework RuAG to automatically distill large volumes of offline data into interpretable first-order logic rules, which are injected into LLMs to boost their reasoning capabilities. Our method begins by formulating the search process relying on LLMs' commonsense, where LLMs automatically define head and body predicates. Then, RuAG applies Monte Carlo Tree Search (MCTS) to address the combinational searching space and efficiently discover logic rules from data. The resulting logic rules are translated into natural language, allowing targeted knowledge injection and seamless integration into LLM prompts for LLM's downstream task reasoning. We evaluate our framework on public and private industrial tasks, including natural language processing, time-series, decision-making, and industrial tasks, demonstrating its effectiveness in enhancing LLM's capability over diverse tasks.", "sections": [{"title": "INTRODUCTION", "content": "Leveraging external datasets to enhance the performance of pretrained Large Language Models (LLMs) on downstream tasks has become a significant focus in recent research (Brown et al., 2020a; Hu et al.; Fan et al., 2024; Dong et al., 2022). Methods such as supervised fine-tuning (SFT) (Hu"}, {"title": "RELATED WORK", "content": "In this section, we review the most relevant topics related to our work, including the techniques to exploit external data in LLMs and logic rule learning.\nExternal data usage in LLMs. There are several ways to inject external knowledge into large language models. The most common way is supervised fine-tuning, but it suffers from high com-putational costs. In-context learning (Brown et al., 2020a) prompts LLMs with a few handcrafted demonstrations which are understandable for the LLMs. More fancy, Retrieval-Augmented Gener-ation (RAG)(Chen et al., 2024a) complements LLMs by retrieved relevant knowledge from external databases (Li et al., 2023; Shen et al., 2023) or constructing demonstrations for in-context learning (ICL) (Poesia et al., 2022; Agrawal et al., 2023), showing promise in tasks like OpenQA (Borgeaud et al., 2022; Guu et al., 2020) and games (Zhu et al., 2023a; Hu et al., 2024). Knowledge graphs are welcome in external knowledge formats as well, especially in structured tasks like relation extrac-tion and entity recognition (Shu et al., 2024; Wang et al., 2024), improving task-specific decisions. Recent research also investigates how LLMs can summarize logic rules from large datasets to serve as a knowledge storage (Zhu et al., 2023b; Luo et al., 2023), but shows high computational costs due to frequent calls to commercial LLMs (Brown et al., 2020b; OpenAI, 2023).\nLogic rule learning. Logic rules are increasingly employed to enhance the interpretability and ac-curacy of decision-making in AI systems (Chiu et al., 2023; An et al., 2024). Manually defined logic rules have been used to describe how certain events or outcomes are triggered by predefined condi-tions. However, this process is labor-intensive and highly domain-dependent (Evans & Grefenstette, 2018; Li et al., 2020). Researchers have explored automatic methods for extracting logic rules, such as statistical approaches and likelihood estimation (Cheng et al., 2022; Qu et al.; Ru et al., 2021). Despite these advances, the process still involves extensive domain knowledge and commonsense reasoning, requiring expert intervention to identify the candidate target and body predicates."}, {"title": "ENHANCE LLMS' REASONING THROUGH APPLYING LOGIC RULES", "content": "In this section, we introduce RuAG, our novel approach to augment Large Language Models (LLMs) with logic rules learned from pre-collected training data. Instead of directly fine-tuning the LLM-which can be costly and prone to overfitting-or using retrieval-augmented generation limited by input length, we transform the data into concise logic rules. These rules encapsulate essential pat-terns and guide the LLM during generation, enhancing performance and interpretability.\nAs shown in Figure 3, RuAG comprises three key steps: 1) LLM-Based Logic Rule Search For-mulation: leverage the LLM to automatically formulate the logic rule learning problem, defining predicates, actions, states, and rewards. (Section 3.1) 2) Logic Rule Search with Monte Carlo"}, {"title": "FROM DATA TO RULE SEARCH: LLM-BASED LOGIC RULE SEARCH FORMULATION", "content": "Search for logical rules traditionally requires significant human effort, particularly in defining domain-specific head predicates and selecting relevant features that characterize data samples. This process demands domain knowledge and impacts both the quality of the derived logic rules and the computational cost of search. To address this challenge, our method begin with LLM-based Logic Rule Search Formulation, where we leverage the capabilities of LLMs to automatically formulate the logic rule learning problem through defining the predicates.\nInitial Predicates. Given a dataset D = {(x, y)}, where each data sample x = [x1,x2,...,XN] \u2208 X is N-dimensional and y \u2208 {0,1} is the label, we initial the label as the target predicate and the features as the body predicates. We can directly translate discrete variables into Boolean val-ues through one-hot vectors. For continuous variables, we can translate them into Boolean-valued attributes through Gini-index (Strobl et al., 2007). Therefore, each predicate is a Boolean-valued function representing a basic condition derived from the data. Discrete variables can be directly translated into Boolean-valued through one-hot vectors. Continuous variables are translated into Boolean-valued attributes through Gini-index. Therefore, each predicate is a Boolean-valued func-tion representing a basic condition derived from the data. Furthermore, we suggest prompting LLMs to remove impossible body predicates to reduce logic rules search space or suggest new target pred-icates to search more logic rules for a better understanding of the task.\nRemoving Impossible Body Predicates. Given a target predicate, the LLM aids in filtering out impossible or irrelevant body predicates, reducing the computational burden. By utilizing common-sense reasoning, the LLM can identify predicates that are unlikely to contribute to effective logic rules. For instance, in a system log analysis, the LLM might determine that certain attributes like user IDs are less relevant for anomaly detection compared to error codes or access patterns.\nSuggesting New Target Predicates. In addition to the primary target predicate (e.g., achieving a specific classification label), the LLM can suggest additional head predicates to explore. This is particularly useful in tasks requiring long-horizon planning, where intermediate goals can guide the"}, {"title": "LOGIC RULE SEARCH WITH MCTS", "content": "Following the definition of predicates in logic rule searching, we apply Monte Carlo Tree Searching (MCTS) to perform logic rule learning, inspired by its effectiveness in searching optimal policy in large state spaces.\nStates, Actions, and Rewards in MCTS. With the predicates defined, the state, action, and reward in MCTS for logic rule searching can be defined as:\n\u2022 States (S): Each state represents a partial logic rule, consisting of a set of predicates. The initial state is the empty set, S0 = \u00d8. Subsequent states are defined as: Sn = Sn-1 \u222a {ai}, where ai is the predicate added by an action.\n\u2022 Actions (A): Actions involve adding a new predicate to the current state. The action space is defined as: A = {Add ai | a\u017c is a candidate predicate generated by the LLM}.\n\u2022 Rewards (R): The reward function evaluates the quality of a logic rule. For example, the reward for state Sn can be defined as the precision of the rule evaluating on the dataset D.\nTypically, MCTS involves building a search tree and simulating outcomes to estimate the value of actions. It consists of four key phases: selection, expansion, simulation, and backpropagation. Selection and expansion: The process begins at the root node, where the algorithm selects the most promising child nodes based on the Upper Confidence Bound applied to Trees (UCT). This continues until a leaf node is reached. If the leaf node is not terminal, new child nodes are created to explore potential moves. As an example, we expand a new node at the state of [(age \u2265 30),] \u21d2 (income \u2265 $50,000), if we select a new candidate predicate (income > $50,000) according to its UCT value, then we add it into the rule: [(age \u2265 30),] \u2190 (income > $50,000) and enter the new state of [(age \u2265 30), (education = bachelor's)] \u21d2 income > $50,000. Simulation: For the newly expanded nodes, random simulations (also known as rollouts) are performed to calculate the reward of the state. Backpropagation: The calculated reward is then propagated back up the tree, updating the nodes' statistical information. The UCT algorithm plays a crucial role in MCTS, balancing exploration and exploitation by selecting actions that maximize: UCTj = Xj + C\\sqrt{2\\frac{\\ln N_c}{N_j}}, where Xj is the average reward of action j, Nc is the total number of visits to the parent node, is the number of visits to node j, C is a constant that adjusts the exploration-exploitation trade-off.\nFinally, we collect all the rules constructed at the terminal nodes when 1) the constructed rule reaches a predefined maximum length (i.e., the number of body predicates exceeds a threshold).2) If the reward of the final node (i.e., the precision of the rule) exceeds a predefined threshold, indicating that the rule is sufficiently accurate."}, {"title": "LEARNED-RULE-AUGMENTED GENERATION", "content": "After the logic rule search, we gather a set of logic rules and follow the following steps to perform learned-rule-augmented generation. 1) Clean Searched Rules: The collected rules may contain duplicates, exhibit low quality, or cover only a limited subset of the data. We first eliminate those with low rewards or minimal data coverage. Then, we compare each pair of rules and retain the one with the higher reward if its body predicates are a subset of the other's. 2) Translate Rules into Natural Language: To enhance the LLMs' comprehension, we translate these symbolic rules into natural language, resulting in a group of sentences. These sentences can then be injected into the LLM prompts to guide generation more effectively. 3) Retrieve Relevant Rules: It is optional to"}, {"title": "EXPERIMENTS", "content": "Most decision-making and prediction tasks can be abstracted into state chains to achieve their ulti-mate goals, which allows our method to adapt to a wide variety of tasks. In this section, we evaluate our method over diverse domains, including NLP (relationship extraction in Section 4.1), time-series predication (log-based anomaly detection in Section 4.2), decision-making task (cooperative game (Chen et al., 2024b) in Section 4.3) and a private industrial task (unauthorized party abuse detection in Appendix A). We compare our method with the domain-specific baselines for each task and HtT (Zhu et al., 2023b), which applies LLMs to generate rules. The specific implementation details of the experimental setup can be found in Appendix C."}, {"title": "RELATION EXTRACTION", "content": "Document-level relation extraction is a critical task in natural language processing (NLP), where the goal is to identify and classify relationships between entities across entire documents rather than isolated sentences. This task becomes more complex at the document level due to the larger con-text and the need to resolve long-range dependencies and co-references between entities scattered throughout the document. However, using only LLMs for this task is often limited by their inabil-ity to consistently capture complex document-wide relationships, especially when reasoning across multiple entities and contexts.\nSetup. We conduct experiments on the DWIE dataset (Zaporojets et al., 2021), which contains 802 documents and 23,130 entities. After excluding irrelevant articles, 700 documents are used for train-ing and 97 for testing. During the rule extraction process, we leveraged the LLM to filter out 15% of the relationships that were unlikely to serve as valid predicates. We evaluate the performance of our method using standard relation extraction metrics, including Precision, Recall, and F1-score. For comparison, we evaluate our method against several state-of-the-art models for document-level rela-tion extraction, including CNN, BILSTM (Yao et al., 2019), Context-Aware (Sorokin & Gurevych, 2017), and BERT-based models(Shi & Lin, 2019), which are widely used in document-level rela-tion extraction tasks. Additionally, we compare with the LLM-based HtT(Zhu et al., 2023b) model, which employs predefined logical rules to extract relations. These comparison methods provide a comprehensive benchmark for assessing the effectiveness of our approach in extracting relations at the document level.\nMain Results. As shown in Fig-ure 1, our method outperforms both deep learning-based and LLM-based baselines in document-level relation extraction. DL-based methods that leverage richer con-textual information tend to achieve bet-ter performance. For instance, BERT and BILSTM outperform CNN, demonstrating the importance of modeling long-range semantic dependencies in document-level relation extraction. Additionally, the re-sults highlight the potential of LLM-based methods in this task. When using GPT-4 as the base model, LLM-based approaches surpass DL-based methods, showcasing the effectiveness of large language models in capturing complex document-level relationships. Moreover, our method outperforms HtT in both GPT-3.5 and GPT-4 settings. This is because HtT extracts rules from a single document, which limits its global perspec-tive, while the predefined rules may not fully represent the broader context. In contrast, our method utilizes MCTS to search for rules from a global viewpoint, effectively mining potential rules from the training data. This approach ensures efficiency while maintaining the reliability of the rules dur-ing the search process. By combining the learned logic rules with the reasoning power of LLMs,"}, {"title": "LOG-BASED ANOMALY DETECTION", "content": "Log-based anomaly detection is fundamentally a time-series prediction task, where the goal is to predict whether a sequence of log events indicates abnormal system behavior. This task is crucial for maintaining system reliability and security by identifying patterns that signal potential failures or attacks. Given the temporal nature of log data, both sequential patterns and the semantic content of the logs must be analyzed to accurately detect anomalies. Effective anomaly detection in time-series log data is essential for preventing system downtime and ensuring the smooth functioning of distributed infrastructures.\nSetup. We evaluate our method on the HDFS dataset (Xu et al., 2009) for the log-based anomaly detection task. This dataset consists of over 11 million log entries generated from Hadoop-based map-reduce jobs on more than 200 Amazon EC2 nodes. In practice, we sampled 20,000 blocks of log sequences from the HDFS dataset, consisting of approximately 486,060 log entries. The dataset was split chronologically into training, validation, and test sets with a ratio of 8:1:1. We evaluate our method using F1 score (F1), Precision, and Recall to compare it against several baselines. The base-lines include traditional methods like LogCluster (Lin et al., 2016), DeepLog (Du et al., 2017), and LogRobust (Zhang et al., 2019), as well as LLM-based models like Vanilla, HtT, and LogGPT (Qi et al., 2023), providing a comprehensive assessment of performance across various approaches.\nMain Results. Table 2 compares our method with traditional baselines and LLM-based models on the log-based anomaly de-tection task. Traditional deep learning meth-ods heavily rely on the training dataset, generally suffering from limited generaliza-tion ability and difficulty in discovering new anomalies. As a result, they perform poorly here. The LLM-based models, all based on GPT-4, demonstrate their potential even with a prompt-based approach. LogGPT achieves an F1 score of 72.56% and a perfect recall of 100%, highlighting the LLM's ability to infer system anomalies from semantic information like abnormal keywords. However, LogGPT's precision is less ideal (56.82%), due to the lack of domain-specific knowledge, leading it to misclas-sify minor issues as anomalies. HtT, which learns anomaly patterns from training data and provides them to the LLM for detection, performs worse than LogGPT with an F1 score of 58.73%, due to inefficiencies in handling large-scale data and difficulties in identifying global patterns. In contrast, our method leverages MCTS to efficiently extract the most reliable rules from the entire dataset, pro-viding clear guidance to the LLM. This approach results in 100% recall and significantly improves precision by addressing the LLM's tendency to misclassify normal log sequences. As a result, our method achieves an F1 score of 92.59%, outperforming all baselines."}, {"title": "MULTI-AGENT GAME: ALICE&BOB", "content": "In the real world, plenty of scenarios involve decision-making, planning, and collaborating, espe-cially in partially observable environments. Moreover, often the optimal strategy often contradicts human intuition. You can not walk towards the treasure directly as there may be walls blocking the path. In such tasks, it is crucial to inject domain knowledge to make informed decisions, as only by integrating specific domain expertise can the model accurately identify the optimal strategy and make sound judgments.\nSetup. We choose the cooperative multi-agent game Alice&Bob, which requires both planning and collaboration. In the game, Alice and Bob work together to find the treasure (Chen et al., 2024b), and the optimal paths for both agents often go against intuition. They are required to sequentially experience key blocks, with one agent needing to remain on a block to enable the other to obtain the"}, {"title": "ABLATION STUDY", "content": "In this section, we present an ablation study to evaluate the robustness and effectiveness of our method across several dimensions. First, we analyze the performance of our method when using different LLM backbones, examining whether the choice of LLM impacts overall task performance. Second, we explore the contribution of different components in our method, including the use of chain-of-thought (CoT) reasoning and rule-based guidance, to assess how each component improves the task. Lastly, we investigate the effectiveness of the MCTS rule extraction process by varying the number of search episodes.\nAblation on different LLM backbones. Table 5 presents the results of our ablation study on different LLM backbones across relation extraction, log anomaly detection and cooperative games. It compares baseline models (Vanilla), chain-of-thought (CoT), and our RuAG for GPT-3.5 and GPT-4. While CoT improves performance by promoting step-by-step reasoning, it falls short in tasks requiring domain knowledge. In contrast, RuAG learned rules from external data, provides the required context, and consistently enhances performance across different backbones.\nAblation on searching episodes in MCTS. Table 6 shows the impact of MCTS search episodes for three tasks. In relation extraction and cooperative games, we report the number and accuracy of extracted rules are evaluated, while log anomaly detection is assessed based on the final task per-"}, {"title": "CASE STUDY", "content": "In this section, we present a case study to demonstrate how the ex-tracted rules help LLMs perform tasks more effectively across different domains. The extracted rules serve as a guiding mechanism, assist-ing the LLM in making more accurate predictions and improving task performance by providing structured logic and patterns that the LLM can follow. Figure 4 illustrates the most representative cases where ex-"}, {"title": "CONCLUSION", "content": "In this paper, we introduce a novel framework RuAG that automatically distills large volumes of of-fline data into understandable first-order logic rules, which are then injected into LLMs to enhance"}, {"title": "ETHICS STATEMENT", "content": "In this paper, we strictly obey the principles outlined in the ICLR Code of Ethics, including careful consideration of potential ethical concerns, including the impact on human subjects, data privacy, and fairness in algorithmic decisions. Specially, the three public datasets do not have potential risk. As for the private industrial dataset, we promise that any data used in this study were released in compliance with legal and ethical standards, and proper security measures were implemented to safeguard personal information."}, {"title": "REPRODUCIBILITY STATEMENT", "content": "We provide the all the details of our method in the paper and appendix, including evaluation prompts, detailed experimental setup and implementation, hyperparameters for both LLM reasoning and MCTS. The code will be available upon the paper publication. These above ensure that others can reproduce our method."}, {"title": "EXPERIMENTAL RESULTS ON PRIVATE INDUSTRAIL DATASET: UNAUTHORIZED PARTY ABUSE DETECTION", "content": "The Unauthorized Party Abuse (UPA) detection task is a binary classification problem, where the goal is to predict whether an incident is a case of UPA (IsUPA) based on a series of features. These features include both time-dependent data, such as resource acquisition velocities and user activity history, as well as static features, like resource descriptions and types of compromised subscriptions. The task is to accurately classify each event as either UPA or not, while maintaining high precision and recall to avoid misclassifying legitimate customer activities.\nSetup The dataset used for this task comes from a private industrial source, consisting of histor-ical incidents of Unauthorized Party Abuse (UPA). It includes both time-dependent features, such as resource acquisition velocities and user activity history, as well as static features, like resource descriptions and types of compromised subscriptions. The dataset is imbalanced, with significantly fewer UPA cases compared to legitimate ones, and the overall data volume is large. To address this, we sampled a balanced dataset and tested the algorithm on smaller batches. For evaluation, we used common fraud detection metrics, including F1-score, Recall, Precision, and Accuracy. We compared our method against several baselines, including XGBoost, Decision Tree, and Rule Grounding. In Rule Grounding, the extracted rules were directly used for prediction to evaluate the effectiveness of rule extraction.\nImplement Details In our task, most features in the dataset are continuous. To adapt to the re-quirement of Monte Carlo Tree Search (MCTS) for discrete state mining, we used the Gini index to discretize these continuous features. Specifically, for each continuous feature, we divided it into 10 discrete states. The discretization process involved calculating the Gini index to determine the opti-mal split points, ensuring that each resulting interval maintains a high degree of data purity. Thus, each data sample was converted into a sequence of discrete states.\nWe used Monte Carlo Tree Search (MCTS) to extract rules from the training set. MCTS was initial-ized with a root node representing the initial state. Child nodes were created and expanded using the Upper Confidence Bound (UCB) formula. Simulations were performed to explore different paths, and optimal rules were generated for both IsUPA=1 and IsUPA=0 targets. The rollout was set to 500, and the reward was based on the precision derived from the rule. The maximum rule length was set to 5. Additionally, if a node's precision exceeded 0.85, we considered it a terminal node, as further expansion was deemed unnecessary. This allowed us to collect all reasonable rules with lengths ranging from 1 to 5.\nMain result Table 8 shows the results of different methods on the small batch dataset for abuse detection. We observe that the rules extracted using MCTS achieve high precision, similar to tradi-tional machine learning methods, but also exhibit a higher recall. This is because MCTS explores a broader search space, allowing it to capture a more comprehensive set of abuse patterns. On the other hand, directly using the LLM for this task yields poor performance, with an F1 score of only 22.64%. The lack of domain-specific knowledge and the difficulty in processing purely numerical features hinder the LLM's effectiveness in this scenario.\nHowever, our method, which provides the MCTS-extracted rules as historical guidance to the LLM, enables the LLM to make better decisions by combining the extracted rules with feature information from specific scenarios. The results indicate that our approach significantly improves the LLM's performance on this type of numerical task. With the help of rules, the LLM's F1 score increases to 96%, demonstrating the effectiveness of our method in guiding the LLM to handle such tasks better. The table shows several representative rules extracted using MCTS, along with their pre-cision, recall, and F1-score if used directly for detection. As can be seen, just using the first rule alone yields an F1 score of 0.6623. Additionally, precision is crucial for rules in this task, as high precision means that the rule for predicting IsUPA=1 is highly reliable and unlikely to make false positive errors."}]}