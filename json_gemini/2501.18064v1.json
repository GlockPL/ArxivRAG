{"title": "Learning Metal Microstructural Heterogeneity through Spatial Mapping of Diffraction Latent Space Features", "authors": ["Mathieu Calvat", "Chris Bean", "Dhruv Anjaria", "Hyoungryul Park", "Haoren Wang", "Kenneth Vecchio", "J.C. Stinville"], "abstract": "To leverage advancements in machine learning for metallic materials design and property prediction, it is crucial to develop a data-reduced representation of metal microstructures that surpasses the limitations of current physics-based discrete microstructure descriptors. This need is particularly relevant for metallic materials processed through additive manufacturing, which exhibit complex hierarchical microstructures that cannot be adequately described using the conventional metrics typically applied to wrought materials. Furthermore, capturing the spatial heterogeneity of microstructures at the different scales is necessary within such framework to accurately predict their properties. To address these challenges, we propose the physical spatial mapping of metal diffraction latent space features. This approach integrates (i) point diffraction data encoding via variational autoencoders or contrastive learning and (ii) the physical mapping of the encoded values. Together these steps offer a method offers a novel means to comprehensively describe metal microstructures. We demonstrate this approach on a wrought and additively manufactured alloy, showing that it effectively encodes microstructural information and enables direct identification of microstructural heterogeneity not directly possible by physics-based models. This data-reduced microstructure representation opens the application of machine learning models in accelerating metallic material design and accurately predicting their properties.", "sections": [{"title": "INTRODUCTION", "content": "The mechanical properties of metallic materials are fundamentally governed by plasticity and its localization at the microstructural scale. Plastic localization originates from the collective behavior of deformation events that are directly controlled by the structure and heterogeneity of the metal's microstructure. In wrought materials, microstructural features such as annealing twins,\ntriple junctions, quadrupole points, large grains, twist boundaries, and macrozones play a significant role in triggering localized\nplasticity1-8. Moreover, additively manufactured (AM) materials present increased microstructure complexity, characterized\nby highly heterogeneous microstructure spanning multiple scales. These AM materials may exhibit distinctive features such\nas cellular structures, low-angle grain boundaries, and regions of intense dislocation density, which significantly influence\nplasticity9, 10.\nTo accurately predict mechanical properties and accelerate materials design11\u201316, it is therefore crucial to capture the full\nrange of heterogeneous microstructural features and understand their collective influence on plasticity and deformation\nmechanisms17,18. Electron Backscatter Diffraction (EBSD), a technique that spatially maps point (local) diffraction data,\nremains the predominant tool for assessing microstructural heterogeneity across various scales. Through physics-based analysis\nof diffraction patterns (for instance extraction of Kikuchi bands), crystallographic orientation can be determined, enabling the\ngeneration of detailed microstructure maps. Beyond crystallographic orientation, researchers are advancing physics-based\nmethods to further characterize microstructural heterogeneity. For example, sharpness analysis of Kikuchi patterns (diffraction\npatterns) provides a qualitative assessment of dislocation density and its distribution19. Similarly, cross-correlation techniques\napplied to Kikuchi patterns allow for the evaluation of lattice expansion and its spatial heterogeneity20. Additionally, refined\nspatial analysis of Kikuchi patterns can inform on geometrically necessary dislocation density21. These approaches focus on\nextracting specific physical information, such as crystallographic orientation, while discarding other potentially valuable data\nembedded in the diffraction patterns. An example of this conventional approach is shown in Fig. 1(A), where crystallographic\norientation is determined by analyzing the location of Kikuchi bands within the diffraction pattern22. In contrast, when\nsharpness analysis is used to assess dislocation density, the focus shifts to evaluating the diffuseness of the Kikuchi bands\nrather than their precise location. For each of these analyses, some information from the raw collected data is lost during the"}, {"title": "RESULTS", "content": "Diffraction data\nThe dataset utilized in this study consists of conventional EBSD measurements taken over a large area (1 mm\u00b2), following the\nprocedure outlined in the methods section. The materials investigated include nickel-based superalloys processed via forging\nand additive manufacturing, specifically a wrought, fully recrystallized Inconel 718 and an additively manufactured (AM)\nInconel 718 in its as-built condition. Detailed descriptions of the investigated materials can be found in the methods section.\nThe inverse pole figure (IPF) maps along the horizontal direction for the examined alloys are shown in Fig. 2. Significant\ndiscrepancies in microstructure morphology and heterogeneities between the wrought and AM materials are observed. The\nwrought material exhibits equiaxed crystallographic grains with uniform crystallographic orientation within each grain. In\ncontrast, due to the unique thermal history and rapid solidification associated to the AM process, the AM Inconel 718 displays\nelongated grains, large lattice rotation gradients, and a high fraction of low angle grain boundaries. Additionally, a high density\nof dislocations28, residual stresses29 and potential chemical fluctuations are expected to be present30\u201332. During the EBSD\nmeasurements, diffraction patterns, known as Kikuchi patterns, and the position at which the patterns are taken, are recorded\nand stored as TIFF images with a resolution of 480 by 480 pixels. All patterns of a single EBSD maps are stored as a UP2 file.\nDetails on the acquisition and patterns themselves are provided in the methods section.\nAs schematically illustrated in Fig. 1(B), the proposed method begins by encoding the Kikuchi patterns, which requires the\ndevelopment and training of a specific machine learning approach. This process is detailed in the following section. Once the"}, {"title": "Encoding of diffraction data", "content": "A machine learning architecture has been developed and trained to encode experimental Kikuchi patterns into a low-dimensional\nlatent space representation. For that purpose, we followed and tested two distinct approaches: (a) a variational autoencoder\n(VAE)35 and (b) a modified VAE including a contrastive learning approach (SimCLR) initially developed for classification\npurposes34; the complete structure of the architecture designed for this application is given in Fig. 3. Two different convolutional\nneural networks (CNN) are used: an Encoder used to convert the Kikuchi patterns to their latent space representations and a\nDecoder to restore the Kikuchi patterns from the low-dimensional representations. Different numbers of latent space dimensions\nhave been investigated, ranging from 16 to 256 dimensions and the associated numbers of kernels are detailed in Table 2 in the\nmethods section.\nFigure 3(A) illustrates the training principles of the VAE. The loss function consists in a pixel-to-pixel L2 loss calculated\nbetween the original pattern and its reconstructed counterpart (once encoded and decoded). The region surrounding the patterns\n(artificially black region with no signal) has been masked out and therefore does not contribute to the evaluation of the loss.\nA Kullback-Leibler divergence term is also added to ensure that the learned distributions converge toward a standard normal\ndistribution36. The dataset used for training consists of 96,000 randomly selected Kikuchi patterns from all investigated\nmaterials. No augmentation has been applied to the Kikuchi patterns used for training.\nConcurrently and to evaluate a different training procedure and with the goal of being more robust against acquisition noise,\nwe integrate an additional contrastive loss33,34 within the VAE approach, as shown in Figure 3(B). In the original SimCLR\napproach34, developed for classification purposes, features are extracted by a ResNet architecture37 from two augmented\nversions of the same image and projected using a multilayer perceptron (MLP). For this training, we used a pixel-to-pixel\nL2 loss calculated between the original pattern (before augmentations) and the reconstructed versions. A Kullback-Leibler\ndivergence is also evaluated for each encoded set of augmented Kikuchi patterns. Finally, a contrastive loss term is added based\non these projected representations33. In our approach, the low-dimensional representations are not used for classification but\nneed to be suitable for pattern reconstruction. This additional loss term helps the architecture to produce a robust representation\nwithin the latent space despite the various noise that may be added through the augmentations to the initial image. Some\naugmentations used in the SimCLR study are not suitable for Kikuchi patterns augmentation including crop, resize, cutout,"}, {"title": "Latent space features mapping", "content": "After training the Encoder using either the conventional VAE or our SimCLR approach, we utilize it to encode all collected\nKikuchi patterns from both investigated materials. This process provides an efficient solution to build a low-dimensional\nrepresentation (a vector of 16, 32, 64, 128, or 256 latent space features) while mitigating the loss of information. These features\nare then spatially mapped according to the physical grid used during the collection of the Kikuchi patterns. As a result, for both\nmaterials, we generate 16, 32, 64, 128, or 256 maps that can be represented and visualized."}, {"title": "Latent space microstructure design: latent space and physical features disentanglement", "content": "The latent space associated to the low-dimensional representations depends on both the Encoder and Decoder architectures\nbut also the loss functions used during training. First, we trained conventional VAEs35 with two loss terms (pixel-to-pixel L2\nloss and KL divergence) and various number of latent space dimensions ranging from 16 to 256. With limited numbers of\nlatent space dimensions, the architecture first focuses on the reconstruction of main features such as the background and the\nbands as illustrated in Fig. 8(B.1). With more dimensions, the latent space is able to store more information and provides better\nreconstructions as shown in Fig. 8(B.2, B.3, B.4 and B.5) for the same diffraction patterns. In the first row of Fig. 8(A.1 to\nA.5) is given the difference with the preprocessed pattern. With sufficient dimensions, the only difference that remains is not\nassociated to the bands but to the random noise of the experimental pattern. Additionally, Fig. 8(C) illustrates the difference\nbetween reconstruction while adding more dimensions to the latent space representation. Going from 16 to 32 dimensions\nimproves band reconstruction in the center of the pattern. Then, going from 32 to 64 dimensions improves the bands near the\noutside of the pattern. Advancing to 128 and 256 dimensions consists of smaller improvements about three times less intense\ncompared to the 16-32 change and localized on bands but also in between bands.\nTo disentangle the various physical features within the dimensions of the latent space, one approach is to encode the data into a\nlatent space with more dimensions. The feature maps most visually sensitive to the cell structure were extracted using a VAE"}, {"title": "Latent space microstructure design: latent space and physical features disentanglement", "content": "The latent space associated to the low-dimensional representations depends on both the Encoder and Decoder architectures\nbut also the loss functions used during training. First, we trained conventional VAEs35 with two loss terms (pixel-to-pixel L2\nloss and KL divergence) and various number of latent space dimensions ranging from 16 to 256. With limited numbers of\nlatent space dimensions, the architecture first focuses on the reconstruction of main features such as the background and the\nbands as illustrated in Fig. 8(B.1). With more dimensions, the latent space is able to store more information and provides better\nreconstructions as shown in Fig. 8(B.2, B.3, B.4 and B.5) for the same diffraction patterns. In the first row of Fig. 8(A.1 to\nA.5) is given the difference with the preprocessed pattern. With sufficient dimensions, the only difference that remains is not\nassociated to the bands but to the random noise of the experimental pattern. Additionally, Fig. 8(C) illustrates the difference\nbetween reconstruction while adding more dimensions to the latent space representation. Going from 16 to 32 dimensions\nimproves band reconstruction in the center of the pattern. Then, going from 32 to 64 dimensions improves the bands near the\noutside of the pattern. Advancing to 128 and 256 dimensions consists of smaller improvements about three times less intense\ncompared to the 16-32 change and localized on bands but also in between bands.\nTo disentangle the various physical features within the dimensions of the latent space, one approach is to encode the data into a\nlatent space with more dimensions. The feature maps most visually sensitive to the cell structure were extracted using a VAE"}, {"title": "Structure of latent space", "content": "The framework proposed in this study demonstrated its ability to produce a low-dimensional representation of Kikuchi patterns\nand to capture key features contained in the diffraction patterns. However, the structure of the latent space depends strongly\non several hyperparameters considered in this study, such as the number of dimensions of the latent space, the structure of\nboth the Encoder and the Decoder, but also the loss function used during training. All these parameters significantly affect\nthe reconstruction quality of Kikuchi patterns as demonstrated in Table 1. Increasing the number of dimensions improves the\nquality of the reconstruction, but also favors the identification of microstructural features such as the cellular structure shown\nin Fig. 9. 256 dimensions, the largest number of latent space dimensions considered in this study produces a reconstruction\nsimilar to the original patterns. Ultimately, using a much larger number of latent space dimensions will improve reconstruction,\nbut may also find structure in the noise of the Kikuchi patterns and produce feature maps that are no longer representative of the\nmicrostructure under consideration. Different loss functions were employed in addition to conventional VAEs. Despite the\nuse of an additional contrastive loss, performances are found to be similar to the conventional 128-dimension VAE (Table 1).\nOn the other hand, increasing the weight of the Kullback-Leibler divergence by using \u1e9e-VAE greatly affects the quality of\nthe reconstructions. While some reconstructed patterns are of excellent quality, others do not show any bands (Fig. 10(B.2))\nor are erroneously reconstructed (Fig. 10(C.2)). In Higgins et al.41, the \u1e9e-VAE learned a more efficient low-dimensional\nrepresentation on datasets such as faces64 and chairs65. More generally, increasing \u1e9e should help the model to align the\nlatent dimensions with the various factors found in the image6 but has also been reported to globally affect the quality of\nthe reconstruction67. For Kikuchi patterns, most of the underlying factors of variation are not independent and depend on the\ncrystal reciprocal space. Some other factors of variation, such as the pattern distortion68 or dislocation density19, could be\ndecoupled but represent smaller variations in a pattern compared to the crystallographic orientation. Beyond affecting the\nquality of reconstruction, increasing \u1e9e leads to erroneous reconstructions, as shown in Fig. 10, analogous to the 'mode collapse'\nobserved for Generative Adversarial Networks (GAN)69. The proposed approaches reveal a trade-off between accurately\nreconstructing Kikuchi patterns, crucial for identifying microstructure heterogeneity, and achieving a continuous latent space\ncapable of predicting realistic Kikuchi patterns to guide the design of new microstructures. One solution involves leveraging\na conditional VAE-GAN architecture trained on synthetic data generated through forward modeling70. This combination of\nVAE and GAN networks allows for the modification of the latent space structure, as the discriminator network evaluates both\ntraining diffraction patterns and patterns randomly sampled from the latent space during training. This way, Training can be\nperformed to target physical features.\nPerspectives: The proposed encoding methods have the potential to efficiently reveal heterogeneities and could be extended to\nother material characterization techniques such as EDS. Multi-modal latent feature maps (combining encoded EBSD and EDS\nfor instance) can provide a solution to increase sensitivity to different types of heterogeneities (chemical, dislocation, orientation,\nphase) and/or at different scales71. The content of the latent space could be enhanced towards certain heterogeneities by means\nof semi-supervised or supervised learning (conditional statements and/or classifiers)70. Moreover, the mapped low-dimensional\nrepresentation can be further used for heterogeneity identification and microstructure segmentation without physics-based\nanalysis72. It creates opportunities for autonomous identification of microstructural features and their heterogeneity, paving the\nway for uncovering the microstructure genome. Furthermore, by developing approaches to enhance continuity within the latent\nspace, the design of novel microstructures will become feasible directly within the latent space."}, {"title": "Identification of microstructure heterogeneity", "content": "It is evident from Fig. 4, 5, 6, and 7 that the proposed approach, which encodes and maps data within the latent space, enables\nthe identification of microstructural heterogeneities at various scales beyond conventional EBSD analysis. When applied to a\nwrought alloy with fully recrystallized grains, the grain structure is revealed, and the contrast observed is mostly related to the\ncrystallographic orientation, specifically the position of the bands within the Kikuchi pattern. Results compare to conventional\nmethods, such as the Hough transform56 or dictionary-based approaches57,58 that rely on the band positions and comparing them\nwith theoretical patterns. Nevertheless, as shown in Fig. 4(B), the proposed encoding and mapping approach reveals a small\ntwin (black arrow in Fig. 4(B)) that is not visible in the IPF maps presented in Fig. 2(A). Despite using the same experimental\nmeasurements, the encoding and mapping approach highlights smaller-scale features, thereby providing enhanced sensitivity in\nidentifying microstructural heterogeneities. This enhancement can be explained by the nature of EBSD measurements, where\nthe measurement is not discrete but relies on averaging the diffraction information over the interaction volume59. When the\nmeasurement is performed near grain boundaries, the interaction volume often encompasses two distinct crystallographic\norientations, leading to the overlapping of Kikuchi patterns. Conventional EBSD analysis assumes the presence of only a single\npattern, ignoring such overlaps. However, in the case of encoding Kikuchi patterns, the latent space features derived from\noverlapping patterns differ significantly from those obtained for a single diffraction pattern. As a result, the proposed approach\nachieves better spatial sensitivity in detecting microstructural heterogeneities with sub-interaction volume resolution."}, {"title": "Encoding and mapping for data-based prediction", "content": "Another advantage of the proposed approach, beyond identifying microstructural heterogeneities, is its potential to reduce\ncomplex microstructures into a latent space representation suitable for use in data-driven prediction models. Considering the\n256- or 128-dimensional latent space, the proposed approach reduces the data volume by a factor of 900 and 1800, respectively.\nIn addition, this method simplifies microstructure representation by directly encoding diffraction data without any prior\nknowledge or annotations needed. Traditional approaches to simplify microstructure representations often rely on graph neural\nnetworks 23, 24, 60-63, which require an initial physical preprocessing step, such as grain segmentation. These methods typically\nutilize simple physical descriptors of microstructure, such as the average grain orientation, grain size, and geometry. However,\nfor complex microstructures, such as those produced by AM, these traditional methods are unable to account for features like\ncellular structures, lattice expansion, and chemical fluctuations. In contrast, the present method theoretically preserves all the\ninformation contained in the diffraction patterns by encoding the raw data directly. The sensitivity is significantly enhanced\ncompared to conventional or advanced physical EBSD processing, as demonstrated in Fig. 5, 6, and 7. These figures reveal\nfluctuations related to lattice expansion, dislocation density, and crystallographic orientation and structure that are not detectable\nusing conventional or advanced EBSD physics-based processing methods. This demonstrates that by encoding metal diffraction\ndata and mapping the associated latent space features, we can extract all microstructure features without relying on physical\nassumptions or prior knowledge of the existing features.\nWhen using this method as input for any data-driven model, the disentanglement of physical features is not so critical. Instead,\nthe focus shifts to designing the latent space to provide a better and more continuous representation of all possible Kikuchi\npatterns to further increase sensitivity. If the latent space is overly clustered, the model may struggle to differentiate between\nclosely related diffraction states. Therefore, optimizing the latent space for smooth, comprehensive coverage of diffraction\npatterns is essential for achieving accurate and robust predictions in data-based models.\nAnother key aspect of achieving smooth and comprehensive coverage in the latent space (a continuous latent space) is ensuring\nthat all feature values within the latent space correspond to realistic Kikuchi patterns. This is essential for effective design\nand functionality within the latent space. With a continuous latent space, microstructures can be generated directly, allowing\nmaterial optimization to occur within the latent space itself."}, {"title": "METHODS", "content": "Materials\nThree different nickel-based superalloys were used in this study: a wrought recrystallized Inconel 718 (30 minutes at 1050\u00b0C\nfollowed by 8 hours at 720\u00b0C) with chemical composition of (wt.%) Ni \u2013 0.56% Al \u2013 17.31% Fe \u2013 0.14% Co \u2013 17.97% Cr \u2013\n5.4% Nb \u2013 Ta \u2013 1.00% Ti \u2013 0.023% C \u2013 0.0062% N; a 3D-printed Inconel 718 by DED (as-built) ; a partially recrystallized\nWaspalloy (heat-treated) characterized by a necklace microstructure (for a training purpose but not detailed in the present study).\nThe 3D-printed material was produced using a Formalloy L2 Directed Energy Deposition (DED) unit utilizing a 650 W Nuburu\n450 nm blue laser capable of achieving a 400 \u00b5m laser spot size. Argon was used as the shielding and carrier gas, and the\nspecimen remained in its as-built condition. The chemical composition is in wt.%: Ni \u2013 0.45% Al \u2013 18.77% Fe \u2013 0.07% Co\n18.88% Cr-5.08% Nb \u2013 0.96% Ti \u2013 0.036% C \u2013 0.02% Cu - 0.04% Mn - 0.08% Si - 3.04% Mo. All samples were machined\nby EDM as flat dogbone samples of gauge section 1 \u00d7 3 mm\u00b2. All samples were mechanically polished using abrasive papers\nfollowed by diamond suspension down to 3 \u00b5m and were finished using a 50 nm colloidal silica suspension.\nElectron BackScatter Diffraction\nEBSD measurements were performed on a ThermoFischer Scios 2 Dual Beam SEM/FIB with an EDAX OIM-Hikari detector\nwith a 1 and 0.1 \u00b5m step size, at an accelerating voltage 20kV, current of 6.4nA, an exposure time of 8.5 ms, 12mm of working"}, {"title": "VAE architecture", "content": "The complete VAE architecture is detailed in Fig. 3(C), composed of two CNNs, Encoder and Decoder portions, to project\nKikuchi patterns to a low-dimensional representation space and to restore the original pattern from this low-dimensional\nrepresentation. The Encoder and Decoder consist of large convolution kernels to limit the depth of the network and are detailed\nin Table 2 for the different latent space dimensions. Leaky ReLU with a scale factor of 0.2 were used as activation functions\nafter each convolution layer (and transposed convolution), except for the output layer of the decoder network, for which a\nhyperbolic tangent was used. The Encoder terminates by a fully connected layer followed by a sampling layer35. \"Shortcut\nconnections\" - popularized by ResNets37 were used to accelerate the training on layers marked as * in Table 2."}, {"title": "Data preprocessing and VAE training", "content": "Before VAE training, Kikuchi pattern backgrounds were calculated over each EBSD map to be individually subtracted from\neach pattern. To reduce the number of CNN parameters, a binning of 4 was applied. The patterns were also rescaled to the\n[-1,1] range to match the scale of hyperbolic tangent output function. To encode the Kikuchi patterns, various dimensions of\nlatent spaces were considered ranging from 16 to 256 values. All VAEs have been trained with a total of 96k patterns, 16k\npatterns randomly selected within each EBSD map (before and after mechanical testing). All the CNN architectures have been\ntrained with the Adam updater73 and using the same parameters: a batch size of 256 for 250 epochs, learning rate of 0.001,\ngradient decay of 0.9 and squared gradient decay of 0.999. The trainings took about 6 hours regardless of the latent space\ndimensions and about 40 hours with the augmentations for the adapted methodology for contrastive learning34. All trainings\nhave been performed using the same CPU and GPU configuration: Intel i7-14700F and Nvidia Geforce RTX 4090."}]}