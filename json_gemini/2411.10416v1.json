{"title": "Towards Automatic Evaluation of Task-Oriented Dialogue Flows", "authors": ["Mehrnoosh Mirtaheri", "Nikhil Varghese", "Chandra Khatri", "Amol Kelkar"], "abstract": "Task-oriented dialogue systems rely on predefined conversation schemes (dialogue flows) often represented as directed acyclic graphs. These flows can be manually designed or automatically generated from previously recorded conversations. Due to variations in domain expertise or reliance on different sets of prior conversations, these dialogue flows can manifest in significantly different graph structures. Despite their importance, there is no standard method for evaluating the quality of dialogue flows. We introduce FuDGE (Fuzzy Dialogue-Graph Edit Distance), a novel metric that evaluates dialogue flows by assessing their structural complexity and representational coverage of the conversation data. FuDGE measures how well individual conversations align with a flow and, consequently, how well a set of conversations is represented by the flow overall. Through extensive experiments on manually configured flows and flows generated by automated techniques, we demonstrate the effectiveness of FuDGE and its evaluation framework. By standardizing and optimizing dialogue flows, FuDGE enables conversational designers and automated techniques to achieve higher levels of efficiency and automation.", "sections": [{"title": "Introduction", "content": "One of the most promising applications of Conversational AI lies in Customer Service Automation, where task-oriented dialogue systems aim to address customer concerns effectively without human intervention. These systems often rely on dialogue flows-structured conversation schemes to retrieve appropriate information from knowledge bases or back-end systems. Over the years, frameworks like Dialogflow CX\u00b9, Rasa\u00b2, and Amazon Lex\u00b3 have facilitated the creation of task-oriented dialogue systems by leveraging flows comprising user intents, agent actions, and other metadata. As shown in Figure 1, dialogue flows define possible paths a customer and agent can take during a conversation, enabling structured automation.\nDialogue flows are typically handcrafted by domain experts through an iterative process involving historical data analysis. This iterative process depends on the designer's expertise, the quality of the data, and the time invested, resulting in dialogue flows or directed acyclic graph (DAG) that vary significantly in flow attributes such as the number of user intents, intent sequences, and graph paths.\nAlternatively dialogue flows can be can be generated using automated flow discovery algorithms, which leverage historical dialogue data. These algorithms rely on hyperparameters that significantly influence the resulting flow structure. However, evaluation of flows with respect to historical dialogues has been a relatively unexplored area of NLP. Previous work has predominantly focused on improving the quality of task-oriented dialog agents through better intent discovery (Zhang et al. 2022; Shi et al. 2018; Perkins and Yang 2019) which is often categorized as a sub-problem in the dialogue flow discovery process. The domain of flow discovery from historical human-human dialogues has had relatively sparse research despite being crucial for building task-oriented dialogue agents. There is a need to automatically evaluate the quality of the dialogue flows with respect to the historical dialogue transcripts used to generate them to deliver a consistent baseline, better versioning and tracking progress of flows, and corresponding automation with time.\nTo that end, we introduce a novel evaluation framework to assess the flow discovery algorithm or to guide the human"}, {"title": "Preliminaries", "content": "In this section, we begin by defining the important terms frequently used throughout the paper involving the dialogue flows and describe the core idea behind the automatic dialogue flow discovery methods. Then, we explain the Levenshtein distance (Levenshtein et al. 1966) and the algorithm to compute it as a foundation for the FuDGE algorithm."}, {"title": "Automatic Flow Discovery", "content": "Automatic flow discovery aims to obtain a dialogue flow from a dialogue corpus. A dialogue corpus consists of a set of N dialogues. Each dialogue includes a sequence of agent and user utterances that occur turn by turn. A dialogue flow is a DAG representing the corpus in the form of nodes, where each node is a user intention/request or an agent response.\nA naive way of obtaining a graph from a dialogue corpus is assigning a node to every utterance and connecting the consecutive utterance nodes. This results in a massive graph with the same number of nodes as the number of utterances. This is impractical for initializing a dialogue agent or giving to a human for manual configuration because it would capture all the noise inherent in human-human conversations. Also, the graph would be extremely large for practical, real-world dialogue datasets, making it very hard for manual configuration or automation. To achieve more condensed representations, automatic flow discovery methods broadly follow two steps:\n1.  Identify the type of agent responses and user requests and assign an intent label to each user/agent utterance. An intent label \"book hotel\" might include user utterances like \"I want to book a hotel\", \"Need a room in the Marriott for next month\", and \"Need accommodation this weekend\". This could be achieved by training a classifier on manually annotated user and agent utterances or by performing density-based clustering like DBSCAN (Ester et al. 1996) using pre-trained encoders like BERT (Devlin et al. 2018). Various semi-supervised methods (Forman, Nachlieli, and Keshet 2015; Lin, Xu, and Zhang 2020; Zhang et al. 2021) also focus on the intent discovery task, which is to find an utterance intent in the presence of some existing intents.\n2.  Once the dialogue utterances are replaced by intent labels, automatic flow discovery methods employ various AI techniques to convert the conversation paths into a more condensed graph. Some methods may facilitate flow ranking strategies that discover the most important paths and pruning strategies that remove the less important nodes or edges from the graph.\nIn this work, we use two proprietary automatic flow discovery methods, each employing different strategies to build the dialogue flows. The final expected outcome is a dialogue flow similar to what is depicted in Figure 1. For both algorithms, we can use annotated data (agent and user utterance intent labels) or a clustering method to assign labels to the utterances. In our experiments, we generate flows with and without intent labels to demonstrate the efficacy of our work."}, {"title": "Levenshtein Distance", "content": "The Levenshtein distance (aka edit distance) is the backbone of numerous search algorithms. It is defined as the minimum number of deletion, insertion or substitution operations needed to convert a string a to string b, where \\( \u03b1 = a_1a_2a_3...a_n \\) and \\( b = b_1b_2b_3... b_m \\) are sequences of single characters. Given the sequence a and b, we define \\( d_{r,s} \\) to be the minimum number of operations used to convert sub-strings \\( a_{1:r} = a_1a_2 ... a_r \\) to \\( b_{1:s} = b_1b_2...b_s \\). \\( d_{r,s} \\) can be recursively computed by considering three following possibilities:\n1.  delete \\( a_r \\), then match \\( a_{1:r-1} \\) with \\( b_{1:s} \\).\n2.  insert \\( b_s \\) at the end of \\( a_{1:r} \\), then match \\( a_1a_2...a_rb_s \\) with \\( b_1b_2...b_{s-1}b_s \\) or equivalently \\( a_{1:r} \\) and \\( b_{1:s-1} \\).\n3.  substitute \\( a_r \\) with \\( b_s \\), then match \\( a_{1:r-1} \\) and \\( b_{1:s-1} \\)."}, {"title": "Problem Definition", "content": "We represent a dialogue flow with a DAG \\( G = (V, E) \\), and its root node \\( G_r \\). Each path in G starting from the root corresponds to a possible user-agent interaction scenario in a dialogue system. Each node in G is associated with an intent bucket \\( B_i \\in \\mathbb{B} = \\{B_1,B_2,..., B_M\\} \\). A bucket \\( B^i = \\langle actor, utterances \\rangle \\) consists of a collection of utterances, grouped together if they all convey the same semantic corresponding to a user intent (\\( actor = user \\)) or an agent action (\\( actor = agent \\)). Throughout the paper, we use the term intent for both users and agents. For simplicity, we also assume that the root node \\( G_r \\) is the start of all the conversations and is associated with a dummy bucket. A flow path \\( P = G_rP_1P_2...P_n \\) is a path in graph G, where \\( P_i \\in V \\) and \\( (P_i, P_{i+1}) \\) is an edge in E.\nTo generate a dialogue flow, human experts or dialogue flow discovery methods leverage a dialogue corpus \\( \\mathbb{C} = \\{C^1, C^2,..., C^N\\} \\) consisting of N recorded conversations between users and agents in a service center. The dialogue flows obtained from a dialogue corpus can vary significantly, depending on the biases of human experts and machine algorithms. Therefore it is essential to devise an automatic way of comparing various dialogue flows obtained from a corpus."}, {"title": "Methodology", "content": "Given a dialogue flow graph \\( G = (V, E) \\) obtained from a dialogue corpus \\( \\mathbb{C} = \\{C^1,C^2,...,C^N\\} \\), we evaluate the flow from two perspectives: (i) how well does the flow represent the dialogue corpus (information loss) (ii) how well is the representation compressed/denoised (complexity)."}, {"title": "Information Loss", "content": "We define information loss as the distance between a dialogue corpus and the discovered flow from the corpus, which is the average distance between each dialogue in the corpus and the flow. Intuitively, the more similar the conversations in the corpus are to the paths in the flow, the less the amount of information loss is. More formally, assume that \\( C^i \\in \\mathbb{C} \\) is a dialogue, and \\( \\mathbb{F}_G = \\{P_k = G_rP_k^1P_k^2...P_k^n\\}_K \\) is the set of all flow paths in G starting at the root node \\( G_r \\) and ending at a leaf node. The fuzzy dialogue-graph distance between \\( C^i \\) and G can be defined as:\n\\[ FuDGE(C^i, G) = \\min_{P_k \\in \\mathbb{F}_G} dist(C^i, P_k) \\]\n The distance between the dialogue flow G and corpus \\( \\mathbb{C} \\) is then defined as:\n\\[ f(\\mathbb{C}, G) = \\frac{1}{N} \\sum_{i=1}^{N} FuDGE(C^i, G) \\]"}, {"title": "Complexity", "content": "The complexity of the representation can be defined as the complexity of the graph representing the dialogue flow. Depending on the application, there are various ways to calculate the complexity of a graph. Here we define complexity as the number of nodes of a graph."}, {"title": "Flow-F1 Score (FF1)", "content": "There is a trade-off between the amount of information being represented with the flow and the complexity of the generation. To capture this trade-off, we propose to take the harmonic mean between the normalized complexity and the FUDGE score. To normalize the complexity, we divide it by the total number of utterances, as it is the upper bound for the graph size if we include every single utterance from the dialogue corpus as a node. The maximum FUDGE score is bounded by the average conversation length since the highest score one can get is from an empty graph by inserting every single utterance. Therefore, we normalize the FUDGE score by the average conversation length in the dialogue corpus. The Flow-F1 (FF1) is:\n\\[ FF1 = \\frac{2(1 - n_c) \\times (1 - n_f)}{(1 - n_c) + (1 - n_f)} \\]\nwhere \\( n_c \\) and \\( n_f \\) are normalized complexity and normalized average FuDGE score (Equation 4)."}, {"title": "Fuzzy Dialogue-Graph Edit Distance", "content": "Motivated from the Levenshtein distance, we focus on aligning a flow path with a dialogue. This is particularly challenging as we need to match a given utterance in the dialogue with an intent in the flow path. Intuitively, an utterance is a good match with an intent if it is semantically close to the majority of the utterances associated with the intent.\nMore precisely, given a dialogue flow \\( G = (V, E) \\), its set of flow paths \\( \\mathbb{F}_G = \\{P_k = G_rP_k^1P_k^2...P_k^n\\}_K \\), and a conversation \\( C^i = u_1u_2...u_m \\), we start with finding the edit distance between \\( C^i = u_1u_2...u_m \\) and a specific flow path \\( P^i = G_rP_1^iP_2^i...P_n^i \\). Conversation \\( C^i \\) is a sequence of utterances \\( u_1u_2...u_m \\) produced by a set of actors \\( a_1a_2...a_m \\), and flow path \\( P^i = G_rP_1^iP_2^i...P_n^i \\) is a sequence of nodes, where each node \\( P_r^i \\) is associated with an intent bucket \\( B^r = \\langle actor, utterances \\rangle \\). The dialogue flow path edit distance follows the logic described in the preliminaries section. It is similar to Equation 1, except that we need to define the substitution cost between an utterance and an intent. Once the distance between a single flow path and a dialogue is determined, the FuDGE distance can be computed using the formula in Equation 3."}, {"title": "Fuzzy Substitution Cost", "content": "We want to match an intent with an utterance if the utterance is semantically similar to the utterances in the intent bucket.\n\\[ C_{sub}(B^r, u) \\sim d_1(B^r, u) \\]\nIf the utterance and the intent are semantically close to each other, they get matched, but on the other hand, if they are not similar, the intent should be replaced. It is worth noting that we cannot simply replace an intent with an utterance. Therefore, we propose to replace the intent with the nearest intent to the u in the set of universal intent buckets \\( \\mathbb{B} \\). Intuitively, if the current node intent is dissimilar to u, it should be replaced with the most similar intent to u. Define \\( B^* \\) as the most similar intent to the u, therefore:\n\\[ cost_{sub}(B^r, u) \\sim d_2(B^r, B^*) \\]\nWe define the final substitution cost as:\n\\[ cost_{sub}(B^r, u) = \u03b1(d_1(B^r, u) + d_2(B^r, B^*)) \\]\nWhere \\( d_1 \\) and \\( d_2 \\) are the intent-utterance and intent-intent distance, respectively, and \\( \u03b1 \\) is a coefficient set to 0.5 here to keep the substitution cost between 0 and 1.\nWe define the intent-utterance and intent-intent distance as a function of their distance in a semantic space. Namely we encode an utterance u and the intent utterances \\( B^r.utterances = \\{u_1, . . . u_l\\} \\) into distributional representations \\( e_u \\), and \\( \\{e_1, e_2, . . ., e_l \\} \\) using Sentence Bert Encoder (Reimers and Gurevych 2019). We use the intent centroid as a representation for the intent, obtained by taking the average of the embeddings of all the utterances in the intent, i.e. \\( e_{B^r} = \\frac{1}{l} \\sum_{j=1}^{l} e_l \\).\nIntent-utterance distance is defined in two ways: (i) The cosine distance between an utterance embedding and an intent centroid, and (ii) The cosine distance between the utterance embedding and the nearest utterance in the intent."}, {"title": "Complexity Analysis & Efficient Implementation", "content": "The original edit distance algorithm uses dynamic programming to compute the Levenstein distance. In dynamic programming, the computed solutions to subproblems (e.g., \\( d_{i,j} \\) in Equation 1) are stored in a memoization table so that these don't have to be recomputed. Even with a memoization table, computing the formula in Equation 3 results in a \\( O(TKM) \\) running time if we separately compute the distance between every single path in the flow \\( \\mathbb{F}_G = \\{P_k = G_rP_1^kP_2^k...P_n^k\\}_K \\), \\( n_k < T \\) and a conversation of length m. Calculating the distance between a dialogue corpus of size N with a flow graph (Equation 4) results in running time complexity of \\( O(TKNM) \\). This makes it impractical to calculate the distance between complex dialogue flows with many paths and large dialogue corpora.\nWe leverage the structure of a flow DAG to develop a more efficient memoization approach. The core idea behind our approach is that flow paths in a dialogue graph can share overlapping sub-paths. For example in Figure 2, node \\( P_3 \\) has two children \\( P_4 \\), and \\( P_6 \\). The two paths \\( root->...->P_3->P_4 \\) and \\( root->...->P_3->P_6 \\) share the same prefix \\( root->... ->P_3 \\), up to the node \\( P_3 \\), and as a result, both paths require the same memoization information for calculating case 2 and 3 in Equation 1. Instead of a regular memoization table, where row i corresponds to a subsequence ending at index i, for each node, we keep an array containing the edit distance between a conversation and a path that starts from the root and ends at the node. Our approach then combines dfs-traversal with memoization, where at each node, it uses the parent edit distance array for the calculation in the current node. It is also worth noting that a node might have more than one distance array since multiple paths might end at a certain node (Node P5 in Figure 2). Our approach computes the distance between a dialogue and all the paths in the dialogue flow by taking the entire DAG instead of looking at each path separately. The complexity of computing the FuDGE distance between all flow paths and a conversation with length n is \\( O((|V| + |E|)n) \\). Algorithm 1 and Algorithm 2 provide the implementation detail of naive and efficient algorithms."}, {"title": "Experiments", "content": "We describe the automatic flow discovery methods, dialogue corpora, and the evaluation datasets for assessing our study's performance of FuDGE and FF1."}, {"title": "Flow Discovery Methods", "content": "Although automatic flow discovery is highly desired, there are only a few discovery algorithms, most unpublished. Graph2Bot (Bouraoui et al. 2019) is an algorithm that discovers big convoluted graphs that, although they can be filtered, the over-generation of paths results in loops, which prevent the dialogue flows from being used for a dialogue system. We use two unpublished algorithms (but currently under review) to discover dialogue flows in a dialogue corpus which we call ALG1 and ALG2. Both algorithms start with a set of user and agent intents. An intent is a collection of semantically similar utterances representing a user or agent's intention. Both algorithms can use the fully annotated intents when the dialogue corpus is fully annotated. In the absence of human-annotated intents, an intent discovery method is being used to find the intent clusters. AGL1 only needs agent intents at the beginning, and the user utterances get grouped as a by-product of graph minimization. For this work, we generate dialogue flows with and without human annotated intents and compare the flows, which we refer to as supervised and unsupervised flows."}, {"title": "Datasets", "content": "In this work, we use two datasets, each consisting of a set of dialogues, where each dialogue is a conversation between two actors (i.e., user and agent) that consists of a sequence of turns. A turn is an utterance produced by one of the actors. Ideally, the best way to evaluate our framework is to compare a set of manually crafted gold flows, perfect in both coverage and compression, with automatically discovered flows from the dialogue corpus. To our knowledge, there is no public dataset with gold standard flows. Therefore, we propose to impose a level of supervision with human-annotated utterances. Many dialogue state tracking datasets (Williams et al. 2014; Bouraoui et al. 2019; Tian et al. 2021; Qi et al. 2022) have human annotated dialogue act utterances, none of which have fully annotated user intents. A dialog act is an utterance that serves as a function in the dialog, such as a question, a statement, or a request. In contrast, intents are more fine-grained and categorize a user intention. For example, \"I want to book a hotel room\" and \"I would like to order pizza\" have the same dia-logue act request while their intents are different. Our first dataset, Finance, is a dataset with fully annotated agents and user intents. It constitutes the conversations between a user and the customer service of a financial agency. Our second dataset is created from STAR(Mosig, Mehri, and Kober 2020), which is the only publicly available dialogue state tracking dataset partially annotated with agent intents. STAR is a schema-guided task-oriented dialog dataset consisting of 127,833 utterances across 5,820 task-oriented dialogs in 13 domains, from which we pick two domains, Hotel and Bank since they contain the most number of dialogues. We processed the dialogues in the STAR dataset and removed those with unlabeled agent utterances. is providing an appendix."}, {"title": "FUDGE Evaluation", "content": "This experiment aims to evaluate the effectiveness of FuDGE as a distance metric. More specifically, given a dialogue flow created for a specific task, a good distance metric should provide lower scores for conversations that belong to the task than the out-of-task conversations. We picked Make Payment task from the Finance dataset with 150 conversations and Bank Fraud Report and Hotel Book from the STAR dataset, with 180 and 145 conversations. We generated separate dialogue flows for each of these tasks using ALG1 and ALG2. For each task, we also randomly sampled 50% of the in-task conversations and added the same number of out-of-task conversations. We evaluated each task-flow with the corresponding dialogue corpus and obtained the average FuDGE score for each dialogue corpus. These results are summarized in The average score for within-task dialogues (positives) is significantly smaller than the out-of-task (negatives) dialogues. It can segregate within-task conversations from out-of-task conversations. These results suggest that FuDGE is an effective distance metric that can be used independently in any application involving the distance between a dialogue and any predefined DAG structured dialogue scheme."}, {"title": "Parameter Optimization With FF1", "content": "Automatic flow discovery usually involves multiple steps, including clustering the utterances, creating the graph, ranking important paths, and pruning the graph accordingly. Each of these steps may add different hyperparameters to the entire discovery pipeline. The simplest clustering algorithms, such as K-means, require k as the number of clusters. While hyperparameter selection can drastically impact the quality of the final discovered flows, it has been done mainly by manual trial and error. In this experiment, we show that the FF1 score is a practical framework for choosing the optimal set of hyperparameters. For this experiment, we use ALG2 as the flow discovery algorithm. This algorithm consists of a ranking strategy that ranks the paths based on their importance and later keeps the k top-ranked paths as the discovered flow. In both supervised and unsupervised setup, we run ALG2 task over the Make Payment task from the Finance dataset. We generate multiple flows for different values of k ranging from 1 to the maximum number of paths in the complete graph. The top row shows the normalized FuDGE score obtained for each flow versus k. First, we can see the clear segregation between the within-task and out-of-task dialogues. Moreover, as more paths get added, the FuDGE score asymptotically decreases to a minima. The middle row depicts the normalized complexity score for different k values, which indicates a monotonic increase in the complexity, which is expected as we add more paths, and, thus, more nodes to the graph. The bottom row is the final FF1 score. We see that the scores go up to an optimal point as we add more paths, but it starts declining. The peak in the graph is almost aligned with the point where the FuDGE score starts to stay constant."}, {"title": "FF1 Evaluation", "content": "In this section, we compare dialogue flows with and without annotated intents. The discovery algorithms need to use a clustering method to generate the intents without the labeled data. This process imposes some noise on the flow discovery, leading to lower quality dialogue flows. This experiment aims to show that our evaluation approach can capture this phenomenon. We generated complete flows by running ALG1 and ALG2 over the entire dialogue corpus for both datasets. Then, we calculated the average FuDGE score and the complexity of each discovered flow and computed the FF1 score. summarizes the results of this experiment. As shown, for the Finance dataset, the score for the supervised discovered flows is higher than the unsupervised discovered flows, with only one exception. However, the FF1 score for the unsupervised flows discovered by ALG1 is significantly higher than the supervised flows. Manual investigation of the flows showed that the annotated labels were too fine-grained. Clustering led to more high-level intents, which eventually processed better quality dialogue flows. We provide more discussion about this case in the Appendix."}, {"title": "Related Work", "content": "Related work for our work is relatively sparse. Although automatic evaluation of dialogue systems is an active field of research (Yeh, Eskenazi, and Mehri 2021; Khalid and Lee 2022), most of the metrics and approaches focus on evaluating a dialogue in utterance level (Sun et al. 2021; Ghazarian et al. 2020). However, our work focuses on the evaluation of the dialogues in conversation level, mostly produced by an AI algorithms, such as Graph2Bot introduced by Bouraoui et al. (2019) and is a tool for assisting conversational agent designers. It could extract a graph representation from human-human conversations using unsupervised learning. More recently, (Qiu et al. 2020) used a Variational Recurrent Neural Network model with discrete latent states to learn dialogue structure in an unsupervised fashion. They evaluate their method by using Structure Euclidean Distance (SED) and Structure Cross-Entropy (SCE) based on the transition probabilities between nodes but found them to be unstable. SED and SCE also do not consider the semantic similarity between the node and the original conversation.\nWord Confusion Networks (WCNs) (Mangu, Brill, and Stolcke 2000) has been used extensively to model the hypothesis of automatic speech recognition (ASR). Just like the dialogue flows, WCNs can also be represented as DAGs. A popular metric for identifying the quality of ASR has been word error rate which incorporates ideas of edit distance that can be derived through each path in the WCN that represents an ASR hypothesis. Lavi et al. (2021) introduced the notion of using edit distance (Wagner and Fischer 1974) for dialog-dialog similarity. In their work, they used sentence-level embeddings (Cer et al. 2018; Reimers and Gurevych 2019) to determine the similarity between two utterances within a dialogue and defining the edit distance substitution cost."}, {"title": "Conclusion", "content": "This paper presents a novel evaluation framework for a crucial task necessary for building task-oriented dialogue agents. This framework can be used with any flow discovery method and dialogue corpora as long as the generated dialogue flows can be represented as a DAG. We introduced the FF1 metric, a harmonic mean of flow complexity and FuDGE distance, and demonstrated its efficacy as a tool to select hyperparameters of a flow discovery algorithm or process. We envisage it to be a useful guide for human conversational designers or as a measure to optimize an automatic flow discovery process. We also propose an efficient implementation of FuDGE distance with \\( O((|V|+|E|)n) \\), allowing it to scale to large datasets. This approach delivers a consistent baseline, thereby better versioning and tracking the progress of flows and corresponding automation with time. In the future, we hope to incorporate utterance characteristics for the insertion and deletion cost to account for the actual semantic cost of the operation."}, {"title": "Mathematical Formulations", "content": "This section provides the exact mathematical formulation to calculate the fuzzy substitution cost. For the representation of an intent bucket, we average the embedding of the utterances in the bucket.\n\\[ e_{B^r} = \\frac{1}{|B^r.utterances |}  \\sum_{i \\in B^r.utterances} e_u \\]\nThe distance between an intent \\( B^r \\) and utterance u is \\( d_1 \\) and is defined as:\n\\[ d_1(B^r, u) = \\begin{cases}  \\phi(B^r, u) & B^r.actor = u.actor \\\\ 100, & otherwise  \\end{cases} \\]\nWhere \\( \\phi \\) is the function of intent and utterance semantic embeddings and is defined in two following ways:\n1.  Min. The minimum distance between u and the nearest utterance in \\( B^r.utterances \\).\n\\[ \\phi(\u0392^r, u) = min_{u_i \\in B^r.utterances} cosine(e_{u_i}, e_u) \\]\n2.  Centroid. The cosine distance between \\( e_{B^r} \\) and \\( e_u \\)\n\\[ \\phi(\u0392^r, u) = cosine(e_u, e_{B^r}) \\]\nFor the intent-intent distance \\( d_2 \\) we use the formula in Equation 10 to obtain two intent representation, \\( d_2 \\) then is:\n\\[ d_2(B^r, B^s) = \\begin{cases}   cosine(e_{B^r}, e_{B^s}) & B^r.actor = B^s.actor \\\\ 100, & otherwise  \\end{cases} \\]\nWhile the \\textbf{Min} approach often produces smaller FUDGE score, and therefor larger FF1 , the \\textbf{Centroid} method is more robust to the effect of outliers in the intent clusters."}, {"title": "Dataset Detail", "content": "contains the dataset tasks and the number of conversations per task. The tasks with the most number of conversations are selected for the second and third sections in the experiments section.\nWe are publishing the STAR dataset, including the dialogue corpora used for flow discovery and evaluation, and the discovered flows from the STAR dialogue corpus using ALG1 and ALG2."}, {"title": "Flow Investigation", "content": "In this section, we provide a more detailed discussion of the results in and the reason why for the STAR dataset, the ff1 score is higher for the unsupervised flows compared to the supervised flows. After manual investigation, we concluded that the agent labels were too fine-grained. is providing an example of this scenario. The three intents in the supervised setup are clustered together by the clustering algorithm in the unsupervised setup. This is often the case that these three intents occur in a different order within a conversation; therefore, having one intent instead of three results in a more compact denoised flow."}]}