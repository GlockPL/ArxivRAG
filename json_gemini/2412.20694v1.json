{"title": "UBER: Uncertainty-Based Evolution with Large Language Models for Automatic Heuristic Design", "authors": ["Zijie Chen", "Zhanchao Zhou", "Yu Lu", "Renjun Xu", "Lili Pan", "Zhenzhong Lan"], "abstract": "NP-hard problem-solving traditionally relies on heuristics, but manually crafting effective heuristics for complex problems remains challenging. While recent work like FunSearch has demonstrated that large language models (LLMs) can be leveraged for heuristic design in evolutionary algorithm (EA) frameworks, their potential is not fully realized due to its deficiency in exploitation and exploration. We present UBER (Uncertainty-Based Evolution for Refinement), a method that enhances LLM+EA methods for automatic heuristic design by integrating uncertainty on top of the FunSearch framework. UBER introduces two key innovations: an Uncertainty-Inclusive Evolution Process (UIEP) for adaptive exploration-exploitation balance, and a principled Uncertainty-Inclusive Island Reset (UIIS) strategy for maintaining population diversity. Through extensive experiments on challenging NP-complete problems, UBER demonstrates significant improvements over FunSearch. Our work provides a new direction for the synergy of LLMs and EA, advancing the field of automatic heuristic design.", "sections": [{"title": "1 Introduction", "content": "A wide range of mathematical science problems are NP-complete which are extremely hard to solve but easy to evaluate (Romera-Paredes et al., 2024). Generally, heuristics are designed to search the solutions (Jia et al., 2023). Evolutionary Algorithms (EAs) are widely used to automatically optimize these heuristics (Liu et al., 2023; Mei et al., 2023). Recently, large language models (LLMs) have shown remarkable capability in code generation (Austin et al., 2021; Chen et al., 2021; Li et al., 2023), opening up new avenues for hyper-heuristic algorithms. These \u201cLLM+EA\" methods utilize LLMs as variation operators in EAs, demonstrating promising results across diverse problem domains (Chen et al., 2024; Zheng et al., 2023; Nasir et al., 2024; Wang et al., 2024).\nA notable instance of the LLM+EA method is FunSearch (Romera-Paredes et al., 2024), which attains heuristics leading to significant mathematical discoveries through approximately 2.5 million evolutionary steps within a multi-population EA. Theoretically, to search for optimal heuristics in a \"function space\", FunSearch should do well in two aspects: carrying out a deeper search in the most promising areas of the whole function space, and exploring the wide unknown regions. We term these two aspects as exploitation and exploration.\nHowever, how to do better exploration and exploitation remains a largely unresolved area of research (Weng, 2020). We notice a pronounced deceleration in performance enhancement during the later stages, suggesting that FunSearch fails to come up with heuristics with higher quality\u00b9. Additionally, we observe the code samples Fun-Search generates are similar to its parents from time to time, suggesting a consistently low diversity of newly generated samples as depicted in Figure 1. Such phenomenons indicate that FunSearch is not exploiting and exploring the \"function space\" well. This limitation impedes FunSearch to discover heuristics with higher quality.\nTo address the issues, we propose Uncertainty-Based Evolution with laRge language models (UBER). UBER introduces two innovations upon FunSearch's framework: uncertainty-inclusive evolution process (UIEP) and uncertainty-inclusive island reset (UIIS). We measure the quality of a sample by the expected score of new samples generated using the original sample as a parent. Drawing inspiration from the Upper Confidence Bound (UCB), a concept widely adopted in reinforcement learning, we further propose Uncertainty-Inclusive Quality (UIQ) with uncertainty estimated by the number of times a sample is selected as parents. UIEP selects suitable parents for evolution based on UIQ. Besides, UIIS periodically reinitializes islands that have a low probability of evolving high-quality samples with promising samples from other islands. UBER is rigorously tested on both standard combinatorial optimization problems and complex problems such as the cap set problem. The results indicate that our method outperforms Fun-Search in terms of designing superior heuristics. Our code will be made public soon.\nWe summarize our contributions as:\n1. We present an uncertainty-aware parent selection mechanism that quantitatively evaluates and incorporates uncertainty in LLM-generated code samples. The mechanism establishes a probabilistic scoring system that enables systematic prioritization of candidates during evolutionary search.\n2. We introduce an uncertainty-guided island reset protocol that adaptively restructures populations based on quantified uncertainty measures. The protocol provides a principled approach to balance population diversity with solution quality by strategically reinitializing underperforming islands.\n3. Experimental results across multiple NP-complete problems demonstrate quantitative"}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Heuristics for Math Problems", "content": "Heuristics are typically used to search solutions for NP-hard problems such as the Traveling Salesman Problem (TSP) (Liu et al., 2023), online bin packing (Coffman Jr et al., 1984), cap set problem (Grochow, 2019; Tao and Vu, 2006) etc. Heuristics guide the search direction to find relatively good solutions within a reasonable time. While it's hard to hand craft a good heuristic, hyper-heuristics algorithms (Burke et al., 2003) like evolutionary algorithm can automatically optimize heuristics from a trivial on (Jia et al., 2023; Mei et al., 2023). Since the boost of deep learning, various relevant methods have been used to assist EA (Bengio et al., 2021; Hudson et al., 2022; Hottung et al., 2020)."}, {"title": "2.2 LLM+EA", "content": "The effectiveness of EA is largely dependent on variation operators' ability to produce diverse, promising new candidates, which requires substantial domain knowledge for specific problems (O'Neill et al., 2010). While Large Language Models have made significant strides in general coding and math capabilities (Guo et al., 2024; Li et al., 2023; Chen et al., 2021), they still struggle with open math problems. Recent research has focused on combining EAs and LLMs to unleash the LLMs' potential (Lehman et al., 2024), so-called LLM+EA methods. LLM+EA methods blurred the distinction between utilizes LLM's few-shot generation capability as variation operators. The application of LLM+EA methods have been extended to broad domains, including neural architecture search (Chen et al., 2024), text-based tasks (Meyerson et al., 2023), optimization (Brahmachary et al., 2024), and even molecular design (Wang et al., 2024)."}, {"title": "2.3 FunSearch and Beyond", "content": "FunSearch (Romera-Paredes et al., 2024) has pushed the scale \u201cLLM+EA\" methods to an unprecedented level, generating approximately 2.5 million samples throughout the whole process. This was achieved through the implementation of an asynchronous system composed of 15 LLM samplers and several hundreds of code evaluators operating in parallel. It extends beyond theoretical and mathematical results for important mathematic problems like the cap set and admissible set problems. Later works concentrate on enhancing FunSearch-like methodologies through improved prompting strategies for generating new programs. EoH (Liu et al., 2024) designs 5 prompts for exploration or modification rather than the single fixed prompt used previously and also suggests that LLM should generate a text description prior to guide the generation of new code. ReEvo (Ye et al., 2024), on the other hand, incorporated LLM reflection into the process, allowing the LLM to generate good samples based on reflections of history samples. In contrast, we argue the essence of FunSearch lies in the repeated few-shot sampling, with a careful selection of samples serving as examples."}, {"title": "3 Preliminary: FunSearch", "content": "In this section, we introduce FunSearch, the specific LLM+EA method that forms the central focus of our study. Definitions of FunSearch's core components are provided first. Subsequently, we will introduce the evolution process and the island reset technique employed within FunSearch. Finally, we will discuss the drawbacks of FunSearch we observed in our experiments."}, {"title": "3.1 Overview of FunSearch", "content": "FunSearch is designed to evolve a Python function within certain program specifications. The score of each function sample \\(c\\) can be acquired by running the program specification on some predefined test instances, which we denote as \\(s(c)\\). A Database \\(D\\) encapsulates all the samples. \\(D\\) comprises \\(n \\ge 1\\) islands: \\(D = \\{I_1,...I_n\\}\\). Each island maintains an independent population for evolution and operates in isolation, devoid of communication with other islands. Moreover, an island \\(I\\) consists of multiple clusters (denote as \\(C\\)). Within each cluster \\(C\\), program samples with the same result on each test instance are stored. Thus, all samples in a cluster share the same score, which we denote as the score of the cluster \\(s(C)\\), with some repurposing of function notation."}, {"title": "3.2 Evolution Process", "content": "At each timestep \\(t\\), FunSearch randomly decides an island \\(I\\) to generate some new samples. Two program samples are chosen from \\(I\\) to serve as parents. Subsequently, the LLM is prompted with these parent samples as few-shot examples to generate new samples. Following their evaluation, these newly generated samples are stored back into the island \\(I\\).\nTo select parents at each timestep \\(t\\), FunSearch first selects two clusters \\(C_i\\) and \\(C_j\\) in \\(I\\), which is followed by choosing one sample from each selected cluster as parents, namely \\(p_1^{(t)}, p_2^{(t)}\\). The probability for each cluster \\(C\\) to be chosen is proportionate to \\(\\exp(s(C))\\). Samples are chosen within a cluster favoring the shorter ones. Specifically, let \\(l_c\\) be the length of sample \\(c\\) measured by the number of characters, and\n\\[\\bar l_c = \\frac{\\max_{c \\in C}\\{l_a\\} - l_c}{\\max_{c \\in C}\\{l_a\\} - \\min_{c \\in C}\\{l_a\\} + 1e-6}.\\]\nThe probability of chosen \\(c\\) as parent is proportionate to \\(\\exp(\\frac{\\bar l_c}{T_{prog}})\\), where \\(T_{prog} > 0\\) is a a hyperparameter indicating the temperature.\nAfter selecting parents, LLM sampler generates \\(n_s\\) new samples given the \\(p_1^{(t)}, p_2^{(t)}\\) as few-shot example: \\(C_{new}^{(t)} = f(p_1^{(t)}, p_2^{(t)}; \\Theta)\\), where \\(\\Theta\\) is LLM's parameters and \\(n_s\\) is a hyperparameter. The generated samples at timestep \\(t\\) are sent back to \\(I\\) after being evaluated on pre-defined test instances. Each sample is stored within a cluster where all program instances yield identical results on each test instance. If no existing cluster satisfies the requirement for a sample, a new cluster will be created and the sample is subsequently saved in it. Program samples that result in an exception or timeout during evaluation are consequently discarded."}, {"title": "3.3 Island Reset", "content": "Periodically, after the generation of every \\(T_{reset}\\) number of samples, FunSearch resets half of the islands that are characterized as underperforming. FunSearch identifies underperforming islands as ones whose highest-scoring cluster has a lower score than that of at least \\(n/2\\) islands. For each island that necessitates a reset, all samples within it are removed, and the island is subsequently reinitialized with the highest-scoring program sample selected from a random remaining island."}, {"title": "3.4 Analysis", "content": "We run 10 experiments on online bin packing OR1 using FunSearch as implemented in Section 6.1. We assess the diversity of generated samples by the proportion of changed tokens in generated samples compared to their parents, which is defined as the token level edit distance of generated samples with its parents normalized with the length of samples. We visualize the performance progress of FunSearch as well as our method's \"Proportion of Change\" in Figure 1. We use lines to represent the average across 10 runs, and a light shadow to depict the range of variation.\nFunSearch exhibits a noticeable performance plateau in the later stages, suggesting its exploitation within the searched regions is suboptimal. Yet, since FunSearch mainly considers \\(s(C)\\), which is indirect to indicate the expected score of samples to be generated, we state that FunSearch's insufficiency in exploitation should be as expected.\nMoreover, samples generated by FunSearch have constantly low \u201cProportion of Change\", meaning they are closer to their parents. This suggests that despite many tricks such as multi-population, and parent selection based on softmax probability, we observe a significant low diversity in samples generated by FunSearch. This indicates that FunSearch is not doing exploration well.\nTo address the issues for FunSearch, we introduce UBER. UBER consists of uncertainty-inclusive evolution process (UIEP) and uncertainty-inclusive island reset (UIIS), which we will introduce in Section 4 and 5 respectively.\""}, {"title": "4 Uncertainty-Inclusive Evolution Process", "content": "The evolution process of our method (Figure 2) bears similarity with FunSearch, except for parent selection, which we believe is the core of the evolution process. We propose Uncertainty-Inclusive Quality (UIQ), a measure used to evaluate the sample's quality with uncertainty based on the number of times they are chosen as parents. Then we introduce the uncertainty-inclusive evolution process (UIEP) of our method, which utilizes UIQ to select appropriate parents at each evolution timestep.\nIn practice, we observed a very high degree of similarity among samples within each cluster C. Hence our method focuses on selecting appropriate clusters at each timestep. Once a cluster is chosen at a given time step, we employ the same method as FunSearch to choose a sample within it as parents."}, {"title": "4.1 Uncertainty-Inclusive Quality", "content": "For the pursuit of exploitation, parents that always lead to high scores in generated samples should be prioritized. Hence, we define the quality of samples in a cluster C at each timestep t as the mean score of all samples generated having samples in C serving as a parent.\n\\[Q_t(C) = \\frac{\\sum_{c \\in C} \\sum_{a \\in P_{c,t}} s(a)}{|P_{c,t}|}\\]\nwhere \\(P_{c,t}\\) is a collection of all samples generated with \\(c\\) as an example before timestep \\(t\\).\nInspired by UCB, we introduce uncertainty into the quality of samples. Let \\(N_t(C)\\) be the number of times samples in cluster C are used as parent before timestep \\(t\\). We define UIQ as:\n\\[Q_p(C,t) = Q_t(C) + k_p \\sqrt{\\frac{\\ln t}{N_t(C)} }\\]\nwhere the footnote \"p\" is short for \u201cparent\", and \\(k_p > 0\\) is a hyperparameter."}, {"title": "4.2 Parent Selection", "content": "At each timestep \\(t\\), after an island I is selected to generate a new sample, our method selects the top-2 clusters with the highest \\(Q_p(C, t)\\) within I. Subsequently, we choose one sample from each chosen clusters as parents using the method mentioned before. Our method automatically balances exploration and exploitation, since it is either choosing parents that leads to high score in generated samples or exploring uncertain parents."}, {"title": "5 Uncertainty-Inclusive Island Reset", "content": "At regular intervals, our method resets half of the underperforming islands. Similar to FunSearch, this involves clearing all samples within these islands and reinitializing them with high-quality samples sourced from the remaining islands.\nSpecifically, after sampling for every \\(T_{reset}\\) steps, we calculate for each island I:\n\\[Q_r(I, t) = \\max_{C \\in I} \\{Q_t(C) + k_r \\sqrt{\\frac{\\ln t}{N(C)} }\\}\\]\nwhere the footnote \u201cr\" is short for \"reset\" and \\(k_r > 0\\) is a hyperparameter. Let \\(C_I\\) be the cluster that satisfies the maximum. We reset half of the islands with the lowest \\(Q_r(I, t)\\). All samples are removed from the identified islands. For reset islands, we randomly choose a remaining island \\(I_{rem}\\) and use a sample from \\(C_{rem}\\) to re-initialize it.\nUIIS replaces islands that have a low likelihood of evolving high-score samples with more promising ones from other islands. This strategy aids in maintaining the evolution within beneficial regions, thus fostering improved performance in future."}, {"title": "6 Experiments", "content": ""}, {"title": "6.1 Implementation Details", "content": "We implement an asynchronous system on a single server with 8 NVIDIA A100 GPUs and 2 Intel(R) Xeon(R) Platinum 8358 CPUs. On each GPU, an LLM inference service is set up locally using the SGLang (Zheng et al., 2024) framework. This segregates LLM inference from the entire system, maximizing the advantages of asynchronous concurrency. We use OpenCoder-8B-Instruct (Huang et al., 2024) throughout our experiment, while also experiment with Deepseek-coder (Guo et al., 2024) to ablate the influence of LLM. We use nucleus sampling with \\(p = 0.95\\) and \\(t = 1.0\\). The maximum length of each sample is 2048 tokens. We provide our prompt for LLM in Appendix E.\nThe remaining components of our implementation operate in parallel, leveraging the Python multiprocessing library. The database is shared and accessible to all processes. Our samplers, functioning as parallel processes, iteratively retrieve parent samples (examples) from the database and submit requests to the backend LLM services. Upon the generation of new samples, evaluators are called by the samplers to assess these samples before their storage in the database. Any samples that result in an Exception or Timeout are systematically discarded. Other hyperparameter settings are shown in Table 1. Note for TSP, a very small amount of sample is required to get relatively good result. Thus we use only 1 island and removed island reset technique for TSP experiments. We also provide our hyperparameter search results in Appendix B to show how the hyperparameters are set."}, {"title": "6.2 Experiment problems", "content": "We assessed the performance of our method on three NP-complete problems:\n\u2022 Online Bin Packing: The bin packing problem aims to accommodate a set of items, each with distinct sizes, into the least number of fixed-sized bins. We focus on its online scenario, where each item is packed as it arrives, differing from an offline setting where all items are available from the outset. We conduct experiments using our method on a widely recognized bin packing benchmark, the OR-Library (Beasley, 1990), which comprises four datasets (OR1 to OR4). Identical to FunSearch (Romera-Paredes et al., 2024), our method evolves the heuristics within a local-search algorithm. The heuristic is a priority function that determines the ranking of bins where the incoming item should be positioned. We evaluate the methods using the fraction of excess bins used over the L2 lower bound of the optimal offline bin packing solution, a metric we refer to as the \"excess rate\".\n\u2022 Cap Set: The cap set problem (Grochow, 2019) is an important problem in extremal combinatorics. The cap set problem finds the largest \u201ccap set\", which is a set of vectors in Z3 such that the sum of any three vectors is not zero. As with FunSearch (Romera-Paredes et al., 2024), our method evolves a priority function that assigns a rank to each vector in Z3, which guides a greedy construction of cap sets. For n \u2264 6, the cap set problem is already solved. We carry out experiments for n = 8, and use the size of the largest cap sets found as performance."}, {"title": "6.3 Baselines", "content": "We compared our method with extensive baselines. This includes:\n\u2022 FunSearch: We use directly the performance on online bin packing and cap set reported in FunSearch (Romera-Paredes et al., 2024).\n\u2022 FunSearch*: Since we are not using the same LLM and hardware compared with Fun-Search (Romera-Paredes et al., 2024), Fun-Search's results are not always comparable with ours. Hence, we reproduced the FunSearch method on our GPU server according to our"}, {"title": "6.4 Main Results", "content": "In Table 2, we report the performance of the best heuristics acquired by each method. Our method significantly outperforms all baseline methods in all datasets of online bin packing. The fraction of excess bins costed by our methods is 9.36% ~41.73% lower than \"FunSearch*\" and 10.98% ~ 42.44% lower compared with results reported in FunSearch. For TSP, even though all methods are very close to the optimal solution, our method still performs better than other baseline methods, with the gap with the optimal route 20.69% smaller than \"FunSearch*\" and 8.00% than EoH. Both result demonstrates the quality of heuristics acquired using our method, with non-trivial performance improvement in these tasks.\nOur method outperforms \"FunSearch*\" in the cap sets problem, where we find a cap set that is greater than \"FunSearch*\" by 16 for n=8. Although we are not able to surpass the performance reported in FunSearch (Romera-Paredes et al., 2024), we argue it's hard to reproduce their results due to the following reason: The time and computational cost to run a complete cap set experiment (generating and evaluating 2.5 million programs) is extremely"}, {"title": "6.5 Discussion", "content": "Since the performance of the best run might be influenced by randomness, we carry out some experiments to prove the performance gain is due to our method efficacy in both exploitation and exploration. We use online bin packing (OR1 ~ OR4), as the target problem in this section.\nIn Figure 3, we show the performance progress of our method compared with and \u201cFunSearch*", "FunSearch*\" our method leads to non-marginal performance improvements even at later stage, indicating our method does better in exploitation. Moreover, there's only slight performance difference between our method and \"FunSearch*\" in early stage. We believe the clue behind the \u201csudden\" performance improvement in later stage is that our method does better at exploration.\nIn Figure 4, we plot the \"Proportion of Change\" of online bin packing experiments for both \u201cFunSearch*": "nd our method during evolution. Since the result is very stochastic, we visualize using a running average with window size=1000. The new samples generated by our method always holds less similarity to their parents compared with \u201cFunSearch*"}, {"title": "6.6 Ablation Study", "content": "We carried out an ablation study to provide a deeper understanding of our method. Experiments are carried on the OR3 of online bin packing. Unless otherwise specified, all methods (variants) share the same implementation as Section 6.1. Several variants of our method experimented with are:\n\u2022 Ours: Our method as describe before.\n\u2022 UIQ-only: UIQ-only adopts the same evolution process as our method, with clusters with top-2 \\(Q_p(C, t)\\) are chosen for parents at each timestep. However, UIQ-only does not use UIIS, but shares the same island reset with FunSearch as described in Section 3.3.\n\u2022 Q-only: Q-only selects clusters with top-2 \\(Q_t(C)\\) for parents at each timestep. Its measure is identical to our method except no uncertainty is involved. Its island reset uses the same method as FunSearch.\n\u2022 FunSearch*: Our baseline, \u201cFunSearch*\" as described in Section 6.3.\nWe report the best as well as average excess rate (along with standard deviation) among 10 runs for each variant in Table 3.\nThe performance gap between \u201cFunSearch*"}, {"title": "6.7 Choice of LLM", "content": "To check if the performance gain from our method is invariant to unrelated conditions like LLM, we carry out experiment on online bin packing OR3 dataset. Apart from OpenCoder-8b-Instruct used in experiments before, we select another LLM with a smaller size and possibly lower code generation performance namely Deepseek-coder-6.7b (Guo et al., 2024). We show results in Table 4.\nThe result shows that our method always leads to better performance than FunSearch, even when a LLM with poor performance is used. which justifies it as model agnostic. Moreover, the result acquired from OpenCoder is always better than Deepseek-coder, which is a weaker LLM in comparison. Such results suggest that utilizing larger or better LLMs, even better results on hard problems like cap set may be possible."}, {"title": "7 Conclusion", "content": "In this paper, we studied FunSearch, a type of LLM+EA method that optimizes heuristics through evolution. We discovered that it has significant drawbacks: not doing well in either exploitation or exploration. Inspired by UCB, we propose our method, consisting of UIEP and UIIS that can address this issue. Experiment results demonstrate that our method steadily outperforms baseline methods, regardless of the task or unrelated conditions like specific LLM. We are optimistic that, boosted by our method, FunSearch can fully utilize LLM's potential and further be able to solve more problems in an even wider range of fields."}, {"title": "8 Limitations", "content": "Despite making non-trivial improvements on combinatorial optimization problems like online bin packing and TSP, our method fails to outperform heuristics searched by FunSearch (Romera-Paredes et al., 2024) on the cap set problems. Although this may potentially diminish the superiority of our method on large-scale complex problems, we have made every effort to demonstrate the advantage of our method over \u201cFunSearch*\" on the cap set problem under comparable settings. The performance of the best heuristics discovered is related to the choice of LLM, the number of samples generated and some random factors. Besides, to the best of our knowledge, no research work has ever surpassed the result of FunSearch (Romera-Paredes et al., 2024) in the cap set problem. We see this as an opportunity to further extend the capability of LLM+EA methods.\nMoreover, our method as well as FunSearch, requires generating codes using LLMs and running these codes on some devices. This might be dangerous, since the code generated by LLM may be unpredictable and hard to explain. In our experiment, we observed codes generated by LLM trying to modify (write and read) local files. We tried our best to overcome this risk in our experiments by restricting permission to access local disk, running codes in safe namespaces, etc."}]}