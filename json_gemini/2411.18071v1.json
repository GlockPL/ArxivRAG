{"title": "Simulating Tabular Datasets through LLMs to Rapidly Explore Hypotheses about Real-World Entities", "authors": ["Miguel Zabaleta", "Joel Lehman"], "abstract": "Do horror writers have worse childhoods than other writers? Though biographical details are known about many writers, quantitatively exploring such a qualitative hypothesis requires significant human effort, e.g. to sift through many biographies and interviews of writers and to iteratively search for quantitative features that reflect what is qualitatively of interest. This paper explores the potential to quickly prototype these kinds of hypotheses through (1) applying LLMs to estimate properties of concrete entities like specific people, companies, books, kinds of animals, and countries; (2) performing off-the-shelf analysis methods to reveal possible relationships among such properties (e.g. linear regression); and towards further automation, (3) applying LLMs to suggest the quantitative properties themselves that could help ground a particular qualitative hypothesis (e.g. number of adverse childhood events, in the context of the running example). The hope is to allow sifting through hypotheses more quickly through collaboration between human and machine. Our experiments highlight that indeed, LLMs can serve as useful estimators of tabular data about specific entities across a range of domains, and that such estimations improve with model scale. Further, initial experiments demonstrate the potential of LLMs to map a qualitative hypothesis of interest to relevant concrete variables that the LLM can then estimate. The conclusion is that LLMs offer intriguing potential to help illuminate scientifically interesting patterns latent within the internet-scale data they are trained upon.", "sections": [{"title": "Introduction", "content": "While science often involves generating new data to explore hypotheses, we likely underappreciate what possible insights hide in plain sight within the vast expanse of already-existing data. One reason we might expect this is that it takes significant human effort to unearth and clarify hypotheses from diverse data sources. For example, there exist many written biographies, which in aggregate may speak to important patterns of the human condition, e.g. how and if aspects of childhood experience relate to adult life choices or relationship, or how personality and mental health interact. However, such information is unstructured and potentially spread across many different texts; for many questions of interest no one has yet made the effort to curate a from such diverse sources a specific dataset.\nTo explore these kinds of questions quantitatively within existing data requires: (1) seeking quantitative variables that are indicative of more qualitative properties of interest (e.g. how many adverse childhood experiences, or ACEs (Boullier and Blair 2018) a specific person experienced, or estimating their OCEAN personality traits (Roccas et al. 2002)); and (2) sifting through diverse unstructured collections of text to ground or estimate those quantities (e.g. reading several biographies of a figure to count their ACEs). To approach both steps manually often requires significant labor, domain expertise, and trial and error. As a result of these costs, we do not thoroughly mine what lies latent within existing data.\nInterestingly, large language models (LLMs) are trained over an enormous corpus of human cultural output, and continue to advance in their capabilities to inexpensively answer arbitrary queries about specific entities. Thus, the main idea in this paper is to leverage LLMs for quick-and-dirty explorations of hypotheses about real-world entities (like people, countries, books, and activities). In particular, given a high-level hypothesis (such as \u201cDo horror writers have worse childhoods than other authors?\"), an LLM can (1) suggest quantitative variables to ground such a hypothesis that are plausibly within its training corpus (e.g. \"Did this person's parents get a divorce\u201d), (2) generate a list of concrete entities (e.g. 100 well-known horror writers and 100 well-known writers of other genres), and (3) estimate the concrete variables for each entity (e.g. \"Did Steven King's parents get a divorce?\").\nIn this way, from an initial rough idea, an LLM can generate an approximate artisanal dataset, providing a preliminary way of exploring the hypothesis. The hope is that this estimation, while not perfect, could serve as an accelerant for active brainstorming, and could fit into a larger pipeline of science. For example, correlations between variables could also be automatically calculated in the simulated dataset, and if a strong and interesting correlation is found, it could motivate the effort to curate by hand a validated dataset, or to gather new data in service of the hypothesis (e.g. a more controlled survey of aspiring writers and their ACE scores). Because this kind of LLM generation (for a moderate-sized dataset) is inexpensive and fast, it can enable faster iteration\""}, {"title": "Background", "content": "LLMs as simulators. Several previous studies have demonstrated the potential for LLMs to act as simulators, often focusing on human behaviors or responses. For instance, (Argyle et al. 2023) demonstrate that LLMs can represent diverse human subpopulations and simulate survey result probabilities based on demographic information, such as predicting voting behavior given race, gender, and political affiliation. Similarly, other works leverage LLMs to replicate human behavior experiments, showing that LLMs can reproduce well-established findings from prior human subject studies (Aher, Arriaga, and Kalai 2023); and others simulate user satisfaction scores to optimize a dialogue system (Hu et al. 2023).\nOur work aims to generalize beyond human-centered applications by focusing on simulating the properties of any class of specific entities, such as animals and countries (although we also include an experiment about athletes). Our focus is different as well: most previous studies explore simulations of human behavior for experimental replication, while we aim to use LLMs as a tool for quickly simulating datasets that can inform the exploration of broader scientific hypotheses in an efficient, exploratory manner.\nSimilarly, (Cohen et al. 2023) demonstrate the potential for extracting structured knowledge from LLMs to build knowledge graphs, which supports the idea that LLMs will be useful tools for simulating datasets on the fly. We build upon this idea to generate synthetic data for exploring novel relationships and hypotheses.\nMore broadly, synthetic data generation has been widely studied for its ability to improve machine learning models, address privacy concerns, and augment datasets (Lu et al. 2024b). However, most applications focus on tasks like model enhancement or privacy-preserving data generation, rather than on hypothesis-driven exploration. Recent work has begun to explore the use of LLMs to generate synthetic datasets, but most often with the aim to increase the performance of LLMs rather than to enable rapid hypothesis testing.\nHypothesis Generation. LLMs are increasingly being applied for hypothesis generation, with approaches generally falling into three categories: text-based, data-driven, and hybrid methods.\nText-based approaches leverage LLMs to synthesize hypotheses directly from given textual data. For example, (Tong et al. 2024) explore generating psychological hypotheses from academic articles. Their method relies on extracting a causal graph from the corpus of literature for hypothesis generation. Data-driven approaches focus on uncovering patterns in structured datasets. For instance, (Zhou et al. 2024) extracts hypotheses from labeled data, enabling automated discovery of insights. However, this reliance on existing datasets poses challenges when suitable labeled data is unavailable, restricting its scope in exploratory or novel domains. Hybrid approaches combine insights from both literature and data. (Xiong et al. 2024) demonstrates how LLMs can integrate knowledge from text and structured data to propose hypotheses.\nIn contrast to these approaches, our work focuses not on generating hypotheses directly, but on simulating datasets from which hypotheses can be explored. By leveraging LLMs as simulators of the properties of concrete entities, we enable a structured and data-driven pathway to hypothesis prototyping, mitigating the pitfalls of forgetting and compounding errors observed in direct hypothesis generation (Liu et al. 2024). Furthermore, in domains where hallucination poses a significant challenge, we apply a self-correction mechanism (Madaan et al. 2023) to improve simulation quality, which in future work could be further addressed with retrieval-augmented generation."}, {"title": "Approach", "content": "The overarching ambition in this paper is to move towards automating more of the process of exploring interesting and important patterns latent within existing internet-scale data, to advance our scientific understanding of the world and make the most of the data we have already generated as a society. One significant obstacle to prototyping a hypothesis within society-scale data is to curate a dataset by hand that can reveal evidence about the hypothesis, which requires sifting through many data sources and carefully translating unstructured data into structured, quantitative tables.\nThe general approach in this paper to avoid that cost, is to generate approximate tabular datasets by querying LLMs. Such tabular data is a powerful way of exploring patterns, where we can consider each row as entity, and each column as a property of that entity. The idea is that training data for LLMs implicitly includes many properties of real-world entities of scientific interest, like people, animals, activities, and countries. Information about a particular entity may be spread across many different documents and contexts, and usefully centralized into the weights of the LLM through the training process (Cohen et al. 2023).\nThis naturally leads to a simple approach to simulate an artisanal tabular dataset fit to explore a particular hypothesis. First, we consider the case where an experimenter provides a list of entities (e.g. like particular animals) and properties"}, {"title": "LLM-driven Dataset Simulation Experiments", "content": "The first set of experiments explore LLMs' ability to simulate useful tabular datasets, given a list of entities and properties. We begin with a simple dataset of binary characteristics of animals as a didactic toy example that we expect to be well-within the capabilities of LLMs; we also explore a more difficult domain that involves specific demographic properties of countries, and complicated constructed indicators (e.g. of how egalitarian a country is), where it is less clear that LLMs would be adept, as a way of probing the limits of this technique. Note that in these experiments we use existing ground-truth datasets as a grounded proxy for the situation of real interest, e.g. to simulate novel datasets; while there is some risk of LLMs memorizing these datasets (as LLMs are at least aware of the Zoo dataset), we find in later experiments that the method does indeed generalize to novel datasets.\n4.1 Zoo Domain\nDescription. In this experiment, we assess the ability of LLMs to simulate the well-known \"Zoo Dataset\" from the UCI Machine Learning Repository (Forsyth 1990). This dataset consists of 101 animal instances (e.g. vampire bat, aardvark), each characterized by 16 binary features (e.g., hair, feathers, teeth) and a categorical target variable representing the animal's type (e.g., mammal, insect). Our aim is to determine whether LLMs can replicate this dataset accurately. Note that the LLM is conditioned on the plain-text names of the animals and features.\nMotivation. We choose this dataset as a first exploration because of its intuitive simplicity. It is clear that LLM training should include simple biological features of animals within it, and thus this provides a toy environment in which to sanity check the approach. The Zoo domain also illustrates how LLMs can be applied to biological or ecological datasets, offering potential for hypothesis generation in specialized fields.\nExperiment setting. To assess the accuracy of individual simulated binary properties, we compared the outputs of the LLMs to the ground-truth dataset. The quality of properties was evaluated using accuracy as the primary metric for both animal features (independent variables) and animal type (dependent variable). We used GPT-40-mini and the prompting strategy of directly querying property values in a Pythonic dictionary format."}, {"title": "Towards Hypothesis-Driven Dataset Simulation", "content": "The previous experiments explored the ability of LLMs to simulate datasets in a controlled setting where ground-truth data was available (e.g. by having the LLM simulate existing datasets). In this section, we move more towards the setting of direct interest, where we want to explore a hypothesis but do not have a pre-existing dataset. We also experiment here with greater LLM autonomy: In addition to having the LLM simulate the data, we also have it map from a high-level hypothesis to the properties worth simulating to explore it. Further experiments explore having the LLM also generate the list of entities of interest (e.g. particular sports figures in this case). In this way, we move more towards having an LLM assistant that can help an experimenter quickly brainstorm and explore potential hypotheses.\nDescription. In this section, we evaluate the ability of LLMs to generate datasets based on qualitative hypotheses. Specifically, we explore the relationship between an athlete's sport type (team vs. individual), the number of major injuries (lasting over two months), and peak performance age. The system receives a prompt outlining the hypothesis along with a list of 40 athletes (20 soccer players and 20 tennis players). The simulator was provided only with the hypothesis and a list of entities, from which it generated data corresponding to the key properties mentioned. Real values for the number of injuries were collected from Tennis Explorer for tennis players and Transfermarkt for soccer players, while the peak performance age was sourced using Perplexity (Perplexity 2024) (as a proxy for exhaustive Google searches).\nTo justify our use of Perplexity for sourcing the peak performance age, we conducted spot checks comparing it to direct LLM queries (e.g., asking ChatGPT). Specifically, we asked both systems for the place of birth of 20 lesser-known soccer players from the Spanish soccer league. While ChatGPT accurately identified only 10 out of 20, Perplexity correctly retrieved all 20 places of birth. This significant difference (Fischer's exact test; $p < 0.001$)) is likely due to Perplexity's use of Retrieval-Augmented Generation (RAG), which enhances factual accuracy by grounding the inferences of the LLM in externally retrieved data (Shuster et al. 2022; Ren et al. 2023).\nMotivation. This task tests whether LLMs can simulate data for hypotheses that would be time-consuming to collect in the real world. Information such as the number of injuries or peak performance age is often scarce, so gener-"}, {"title": "Discussion and Conclusion", "content": "The experiments in this paper highlight the potential for LLMs to translate high-level descriptions of hypotheses into approximate datasets, ones that can be used to quickly iterate towards interesting latent patterns in existing data. The hope is to empower experimenters to more easily sift through the space of hypotheses by lowering the cost of gathering a dataset by hand. In practice, after discovering an interesting hypothesis, the experimenter will still likely need to either curate a grounded dataset, or perform a real-world experiment, to generate a scientifically validated result.\nThis kind of method of course has its limitations, as it depends on the estimation abilities of LLMs, which will vary with how well the LLMs' dataset covers the entities as properties of interest, as well as the overall capabilities of the LLM itself. One interesting phenomenon to note is that in the Countries domain, simulating data and then analyzing the relationships among that data performed better than asking the LLM directly to estimate relationships among variables (without simulating the data). In other words, while the information about the variables was latent within the LLM (as it could be simulated), externalizing that information to run outside analysis upon it, yielded further insights. Such improvement relates to the general idea of LLMs iterating upon their own outputs as a way of generating further useful synthetic data.\nWhile the approach here directly queries an LLM, another interesting direction is to employ a more agentic pipeline to actively construct a grounded dataset. That is, LLMs that can browse the web and write code could do things like piece together existing datasets, or attempt to actively ground each data point in reliable sources (e.g. similar to how Perplexity was used to approximate ground truth in the final domain). Such an approach, if it worked well, might present another point in the trade-off between (1) cost and speed, and (2) dataset fidelity: e.g. it would gain fidelity but require more complex chaining of LLM calls.\nMore broadly, a grander ambition is to create an open-ended system (Stanley, Lehman, and Soros 2017) that could continually discover new, interesting patterns in data. The second set of experiments represents a step in this direction, where the experimenter supplies the high-level hypothesis, which is then translated into the rows and columns of a dataset, which is then simulated. But this could be taken further, where a user instead supplies a more broad question of interest, e.g. \"What are interesting patterns of human behavior that can be discerned from biographies of historical figures,\" and the system itself continually searches for unexpected and interesting patterns by simulating and analyzing datasets. This is related to other directions that attempt to apply LLMs towards open-ended creativity (Lu et al. 2024a; Lehman et al. 2023).\nWhile the approach here works with simulating specific real-world entities (like countries, athletes, and animals), it is also interesting to consider automated creation of datasets that relate to simulations of people through LLMs (Argyle et al. 2023; Aher, Arriaga, and Kalai 2023). Indeed, the work here started with that direction (to explore hypotheses related to whether people with different e.g. OCEAN personality scores would benefit from different leisure activities). There are interesting technical challenges to consider, such as modeling distributions of people and their responses (e.g. the distribution of people with a high openness score, and the distribution of their favorite activities), rather than discrete properties of singular entities as in this paper. Such research is an interesting direction of future work that can build off the foundation established in this paper.\nFinally, it is interesting to consider the possibilities for novel kinds of ML algorithms opened up by the ability to simulate new features and datasets on the fly. That is, classic tabular learning algorithms (like decision trees) are typically applied to fixed datasets; yet, LLMs open up the possibility of dynamically expanding the feature set as learning progresses. Future work will explore extensions of decision trees that start from a minimal dataset (perhaps only consisting of entities and the dependent variable), and through human-computer interaction, gradually build the dataset as the learning algorithm proceeds; the decision tree algorithm itself becomes more open-ended in its unfolding.\nIn conclusion, this paper described the potential of using LLMs to simulate datasets about real-world entities, in service of accelerating the exploration of hypotheses about them. Overall, this research points towards the possibility of fully automated systems for automated discovery of knowledge aggregated from the vast cultural output of humans: What exciting patterns (about us, and about the world) lie waiting for us to distill from the ever-growing ocean of civilization-scale data?"}, {"title": "A Countries Domain", "content": "A.1 Pre-processing steps\n1. Filtering feature database for year 2022\n2. Remove features that contain 'Standard Error'. For example, 'Rule of Law: Standard Error' seems a bit too unclear what it means\n3. Filter for common countries (egalitarian index and demographic features come from different data sources)\n4. Remove demographic features that are not present in all countries\n5. Randomly sample N countries and K features from that (N=50, K=10)\nA.2 List of countries\n1 Eswatini\n2 Mongolia\n3 Trinidad and Tobago\n4 Madagascar\n5 Estonia\n6 Mauritania\n7 Germany\n8 Guinea-Bissau\n9 Ethiopia\n10 Canada\n11 Kazakhstan\n12 Colombia\n13 Eritrea\n14 Somalia\n15 Haiti\n16 Brazil\n17 Paraguay\n18 Mali\n19 Georgia\n20 Sweden\n21 Czechia\n22 Myanmar\n23 Guyana\n24 Cyprus\n25 El Salvador\n26 Indonesia\n27 Montenegro\n28 Bolivia\n29 Kenya\n30 New Zealand\n31 Dominican Republic\n32 Sudan\n33 Tanzania\n34 Bahrain\n35 Solomon Islands\n36 Thailand\n37 Romania\n38 Mauritius\n39 Peru\n40 Morocco\n41 India\n42 Zambia\n43 Philippines\n44 Togo\n45 Djibouti\n46 Barbados\n47 Zimbabwe\n48 Central African Republic\n49 Portugal\n50 Malawi\n51 Chile\n52 Sao Tome and Principe\n53 Gabon\n54 Switzerland\n55 Jamaica\n56 Sierra Leone\n57 Lesotho\n58 Nicaragua\n59 Malta\n60 Honduras\n61 Norway\n62 Senegal\n63 Afghanistan\n64 Lebanon\n65 Mexico\n66 Singapore\n67 Niger\n68 Iraq\n69 United Kingdom\n70 Papua New Guinea\n71 Saudi Arabia\n72 Belarus\n73 Seychelles\n74 Ireland\n75 Fiji\n76 Pakistan\n77 Uganda\n78 France\n79 Burundi\n80 Bosnia and Herzegovina\n81 Maldives\n82 Benin\n83 Vanuatu\n84 Liberia\n85 Qatar\n86 Uzbekistan\n87 Kuwait\n88 South Africa\n89 Finland\n90 Libya\n91 Austria\n92 Chad\n93 Oman\n94 United Arab Emirates\n95 Namibia\n96 Belgium\n97 Guatemala\n98 Kosovo\n99 Ecuador\n100 Slovenia\n101 Poland\n102 Bhutan\n103 Turkmenistan\n104 Burkina Faso\n105 Cuba\n106 Cambodia\n107 Moldova\n108 Spain\n109 United States\n110 Cote d'Ivoire\n111 Serbia\n112 Croatia\n113 South Sudan\n114 Netherlands\n115 Guinea\n116 Latvia\n117 Japan\n118 Algeria\n119 Albania\n120 Hungary\n121 Luxembourg\n122 Uruguay\n123 Armenia\n124 Greece\n125 Bulgaria\n126 Suriname\n127 Nigeria\n128 Angola\n129 Jordan\n130 Azerbaijan\n131 China\n132 Ghana\n133 Denmark\n134 Comoros\n135 Malaysia\n136 Italy\n137 Lithuania\n138 North Macedonia\n139 Tajikistan\n140 Mozambique\n141 Panama\n142 Ukraine\n143 Israel\n144 Sri Lanka\n145 Australia\n146 Equatorial Guinea\n147 Bangladesh\n148 Tunisia\n149 Cameroon\n150 Iceland\n151 Argentina\n152 Rwanda\n153 Nepal\n154 Costa Rica\n155 Botswana\nA.3 List of features\n1 Population ages 00-04, male (% of male population)\n2 Population, male (% of total population)\n3 Population ages 65 and above, female (% of female population)\n4 Regulatory Quality: Percentile Rank\n5 Population ages 40-44, male (% of male population)\n6 Regulatory Quality: Estimate\n7 Population ages 0-14, female\n8 Population ages 60-64, female (% of female population)\n9 Survival to age 65, female (% of cohort)\n10 Population ages 15-64, total\n11 Government Effectiveness: Percentile Rank\n12 Rule of Law: Estimate\n13 Population ages 15-64, male (% of male population)\n14 Population ages 65-69, male (% of male population)\n15 Population ages 05-09, female (% of female population)\n16 Birth rate, crude (per 1,000 people)\n17 Mortality rate, under-5 (per 1,000 live births)\n18 Population ages 20-24, male (% of male population)\n19 Population ages 65 and above, total\n20 Adolescent fertility rate (births per 1,000 women ages 15-19)\n21 Population ages 10-14, female (% of female population)\n22 Sex ratio at birth (male births per female births)\n23 Life expectancy at birth, male (years)\n24 Regulatory Quality: Number of Sources\n25 Number of deaths ages 20-24 years\n26 Number of deaths ages 10-14 years\n27 Population ages 70-74, male (% of male population)\n28 Population ages 40-44, female (% of female population)\n29 Probability of dying among adolescents ages 15-19 years (per 1,000)\n30 Population ages 0-14, female (% of female population)\n31 Voice and Accountability: Percentile Rank\n32 Mortality rate, neonatal (per 1,000 live births)\n33 Population ages 50-54, male (% of male population)\n34 Population ages 75-79, male (% of male population)\n35 Population ages 55-59, female (% of female population)\n36 Population ages 0-14, total\n37 Population ages 45-49, male (% of male population)\n38 Population ages 50-54, female (% of female population)\n39 Population ages 55-59, male (% of male population)\n40 Voice and Accountability: Percentile Rank, Upper Bound of 90% Confidence Interval\n41 Mortality rate, under-5, female (per 1,000 live births)\n42 Population ages 0-14, male (% of male population)\n43 Population ages 65 and above, male (% of male population)\n44 Mortality rate, infant (per 1,000 live births)\n45 Population ages 45-49, female (% of female population)\n46 Population ages 30-34, male (% of male population)\n47 Population ages 70-74, female (% of female population)\n48 Regulatory Quality: Percentile Rank, Upper Bound of 90% Confidence Interval\n49 Rule of Law: Number of Sources\n50 Population ages 15-19, female (% of female population)\n51 Control of Corruption: Estimate\n52 Population ages 80 and above, male (% of male population)\n53 Control of Corruption: Percentile Rank, Upper Bound of 90% Confidence Interval\n54 Statistical performance indicators (SPI) : Pillar 1 data use score (scale 0-100)\n55 Political Stability and Absence of Violence/Terrorism: Estimate\n56 Political Stability and Absence of Violence/Terrorism: Percentile Rank, Upper Bound of 90% Confidence Interval\n57 Government Effectiveness: Number of Sources\n58 Probability of dying among youth ages 20-24 years (per 1,000)\n59 Government Effectiveness: Percentile Rank, Upper Bound of 90% Confidence Interval\n60 Population, male\n61 Voice and Accountability: Percentile Rank, Lower Bound of 90% Confidence Interval\n62 Population ages 65 and above, female\n63 Mortality rate, under-5, male (per 1,000 live births)\n64 Population ages 15-64, male\n65 Population ages 15-19, male (% of male population)\n66 Population ages 35-39, male (% of male population)\n67 Population ages 75-79, female (% of female population)\n68 Rule of Law: Percentile Rank\n69 Population ages 80 and above, female (% of female population)\n70 Population ages 15-64, female (% of female population)\n71 Political Stability and Absence of Violence/Terrorism: Number of Sources\n72 Net migration\n73 Population ages 35-39, female (% of female population)\n74 Number of infant deaths\n75 Number of deaths ages 15-19 years\n76 Probability of dying among adolescents ages 10-14 years (per 1,000)\n77 Fertility rate, total (births per woman)\n78 Life expectancy at birth, female (years)\n79 Population ages 05-09, male (% of male population)\n80 Voice and Accountability: Number of Sources\n81 Age dependency ratio, young (% of working-age population)\n82 Rule of Law: Percentile Rank, Lower Bound of 90% Confidence Interval\n83 Age dependency ratio (% of working-age population)\n84 Population, female (% of total"}, {"title": "Prompt Examples", "content": "\u2022 Direct style, Structured format\n1 sys_prompt = You will be asked to make your best guess about the value a country had for a particular feature in 2022. Respond in the following json format: {feature: value}. Where feature is the characteristic about the country, and value is your numeric guess. If you don't know, make your best guess\n2 user_prompt = Country: Namibia, Population ages 45-49, male (% of male population):\n\u2022 Direct style, Descriptive format\n1 sys_prompt = You will be asked to make your best guess about the value a country had for a particular feature in 2022. Respond in the following json format: {feature: value}. Where feature is the characteristic about the country, and value is your numeric guess. If you don't know, make your best guess\n2 user_prompt = What was the value of the 'Population ages 45-49, male (% of male population)' in Namibia for 2022?\n\u2022 Report style, Structured format\n1 sys_prompt = You are an expert historian. Please complete the following document.\n2 user_prompt = This document contains demographics and other variables of countries in 2022. It is documented by an expert historian and socio-political expert. \nCountry: Namibia, Population ages 45-49, male (% of male population) :\n\u2022 Report style, Descriptive format\n1 sys_prompt = You are an expert historian. Please complete the following document.\n2 user_prompt = This document contains demographics and other variables of countries in 2022. It is documented by an expert historian and socio-political expert. \nI conclude that the Population ages 45-49, male (% of male population) in Namibia for 2022 was"}, {"title": "Extra Figures", "content": ""}]}