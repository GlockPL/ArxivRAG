{"title": "Counterfactual Token Generation in Large Language Models", "authors": ["Ivi Chatzi", "Nina Corvelo Benz", "Eleni Straitouri", "Stratis Tsirtsis", "Manuel Gomez-Rodriguez"], "abstract": "\"Sure, I am happy to generate a story for you: Captain Lyra stood at the helm of her trusty ship, the Maelstrom's Fury, gazing out at the endless sea. [...] Lyra's eyes welled up with tears as she realized the bitter truth - she had sacrificed everything for fleeting riches, and lost the love of her crew, her family, and herself.\" Although this story, generated by a large language model, is captivating, one may wonder-how would the story have unfolded if the model had chosen \"Captain Maeve\" as the protagonist instead? We cannot know. State-of-the-art large language models are stateless they maintain no internal memory or state. Given a prompt, they generate a sequence of tokens as an output using an autoregressive process. As a consequence, they cannot reason about counterfactual alternatives to tokens they have generated in the past. In this work, our goal is to enhance them with this functionality. To this end, we develop a causal model of token generation that builds upon the Gumbel-Max structural causal model. Our model allows any large language model to perform counterfactual token generation at almost no cost in comparison with vanilla token generation, it is embarrassingly simple to implement, and it does not require any fine-tuning nor prompt engineering. We implement our model on Llama 3 8B-instruct and conduct both qualitative and quantitative analyses of counterfactually generated text. We conclude with a demonstrative application of counterfactual token generation for bias detection, unveiling interesting insights about the model of the world constructed by large language models.", "sections": [{"title": "1 Introduction", "content": "Reasoning about \"what might have been\", about alternatives to our own past actions, is a landmark of human intelligence [1-3]. This type of reasoning, known as counterfactual reasoning, has been shown to play a significant role in the ability that humans have to learn from limited past experience and improve their decision making skills over time [4-6], it provides the basis for creativity and insight [7], and it is tightly connected to the way we attribute causality and responsibility [8-11]. Can currently available large language models (LLMs) conduct counterfactual reasoning about alternatives to their own outputs? In this work, we argue that they cannot, by design.\nCurrently available LLMs are stateless they maintain no internal memory or state. Given an input prompt, they generate a sequence of tokens\u00b9 as output using an autoregressive process [12, 13]. At each time step, they first use a neural network to map the prompt and the (partial) sequence of tokens generated so far to a token distribution. Then, they use a sampler to draw the next token at random from the token distribution. Finally, they append the next token to the (partial) sequence of tokens, and continue until"}, {"title": "2 A Causal Model of Token Generation", "content": "To formally express autoregressive token generation, we adopt (part of) the notation introduced by Duetting et al. [47] in a different (non-causal) context. Let V denote the vocabulary (set) of tokens available to the LLM, which includes an end-of-sequence token \u22a5. Then, we denote by V* = V \u222a V2 \u222a \u2022 \u2022 \u222a VK the set of sequences of tokens up to maximum length K, and by \u2205 the empty token. An LLM takes as input a prompt sequence sq \u2208 V* and responds with an output sequence s \u2208 V*. The output sequence is generated using an autoregressive process. At each time step i \u2208 [K], the LLM first takes as input the concatenation of the prompt sequence sq and the (partial) output sequence si-1 and generates a distribution over tokens di \u2208 \u2206(V). Then, it samples the next token ti ~ di from the distribution di and creates the output sequence si = si\u22121 \u25e6 ti, where \u25e6 denotes the concatenation of a token or sequence with another sequence. Further, if ti = \u22a5, it terminates and returns s = si and, otherwise, it continues to the next step i + 1 in the generation.\nGiven any prompt sequence, the above autoregressive process determines what (factual) output sequence the LLM generates as a response. However, given a generated output sequence, the above process does not determine what counterfactual output sequence the LLM would have generated if the prompt sequence, or some of the tokens in the output sequence, had been different. To address this limitation, we augment the autoregressive process using a structural causal model (SCM) [15, 16], which we denote as M. Our SCM M is defined by the following assignments\u2074:\n$S_0 = S_q, D_i =\\begin{cases} f_D(S_{i-1}) & \\text{if last}(S_{i-1}) \\neq \\perp, \\\\ P_{\\emptyset} & \\text{otherwise} \\end{cases},$\n$T_i = \\begin{cases} f_T(D_i, U_i) & \\text{if } D_i \\neq P_{\\emptyset}, \\\\ \\emptyset & \\text{otherwise} \\end{cases},$\n$S_i = S_{i-1} \\circ T_i \\text{ and } S = S_K,$ (1)\nwhere Sq and U = (Ui)i\u2208{1,...,K} are independent exogenous random variables, with Sq ~ PQ and Ui ~ PU, respectively, fD and fT are given functions, P\u2205 is the point mass distribution on \u2205, and last(Si-1) denotes the last token of the sequence Si-1. Here, the function fD is defined by the transformer architecture of the LLM and the choice of function fT and distribution PU determines the exact mechanism that the LLM's sampler uses to (stochastically) select the next token Ti. Note that, there always exists a pair of fT and PU such that the distribution over tokens Di matches the distribution PM (Ti) entailed by M (see Buesing et al. [48], Lemma 2 for a technical argument). Moreover, note that, in the SCM M, the output sequence S contains the prompt sequence to lighten the notation regarding interventions.\nUnder this augmented autoregressive process, given an output sequence S = s and noise values U = u, we can generate the counterfactual output sequence the LLM would have generated if the prompt sequence,"}, {"title": "3 Counterfactual Token Generation Using Gumbel-Max SCMS", "content": "Under the class of Gumbel-Max SCMs, the function fT that implements the sampling of the next token in the SCM M adopts the following functional form [17]:\n$f_T(D_i, U_i) = \\text{argmax}_{t \\in V}{\\log D_{i,t} + U_{i,t}},$ (3)\nwhere Ui,v ~ Gumbel (0, 1) are independently distributed Gumbel variables. Importantly, this class of SCMS has been shown to satisfy a desirable counterfactual stability property that can be intuitively expressed as follows. Assume that, at time step i, the augmented autoregressive process sampled token ti given di = fD(Si-1). Then, in a counterfactual scenario where Di = d', it is unlikely that, at time step i, the augmented autoregressive process would have sampled a token t' other than ti the factual one unless, under the token distribution d', the relative chance of generating token ti decreased compared to other tokens. More formally, for any token distribution d' \u2208 \u2206(V) with d' \u2260 di such that\n$\\frac{P_M(T_i = t_i | D_i = d')}{P_M(T_i = t_i | D_i = d_i)} > \\frac{P_M(T_i = t' | D_i = d')}{P_M(T_i = t' | D_i = d_i)},$\nit holds that, in the counterfactual scenario where Di = d', the counterfactual token Ti \u2260 t'.\nIn practice, in addition to solving the non-identifiability issues discussed previously, the use of Gumbel-Max SCMs allows for an efficient procedure to sample a sequence of counterfactual tokens with minimal additional memory requirements compared to vanilla token generation. We summarize the procedure in Algorithm 1. Recall that, to generate the counterfactual output sequence, one needs to use the same values uj for the noise variables that were used during the factual generation and then perform an autoregressive computation based on Equation 2. Instead of storing the values uj for all time steps j \u2208 [K], whose dimensionality matches the size of the vocabulary V, Algorithm 1 employs a simple idea: it stores the state of the random number generator rj used at each time step j \u2208 [K] of the factual generation. Then, during the counterfactual generation, it regenerates the values uj = GenGumbel(rj) on the fly."}, {"title": "4 Experiments", "content": "In this section, we experiment with an implementation of our model on Llama 3 8B-instruct [50], a popular open-weights large language model. We start by qualitatively analyzing an example of counterfactual story generation. Next, we quantitatively analyze the similarity between factual and counterfactual text. We conclude with an application of counterfactual token generation in detecting model biases towards demographic groups.\n4.1 How would the story have unfolded for \u201cCaptain Maeve\u201d?\nAs discussed in Section 3, by using the Gumbel-Max SCM, our approach to counterfactual token generation is guaranteed to satisfy the property of counterfactual stability-counterfactual token generation \"prioritizes\" selecting the same tokens Ti that were selected during the factual generation. As a consequence, we expect the counterfactual text generated using counterfactual token generation to be similar to the factual text. Here, we investigate this qualitatively through an anecdotal example of story generation.\n4.2 How similar is counterfactually generated text to the factual one?\nIn the previous section, we demonstrated through an example that counterfactual token generation results in text that is (partially) similar to the factual text, as expected due to the property of counterfactual stability. Here, we empirically verify this expectation using a quantitative analysis and explore how it is affected by the model parameters.\n4.3 Does counterfactual token generation reveal model biases?\nCommon approaches to addressing questions of bias and fairness rely on making counterfactual comparisons based on sensitive attributes [53]. For example, would a person's income have been the same if their race or sex were different? In this section, we focus on a census data generation task, and demonstrate the use of counterfactual token generation to investigate potential biases of the LLM towards demographic groups."}, {"title": "5 Conclusions", "content": "In this work, we have proposed a causal model of token generation. Using the Gumbel-Max SCM, we have introduced a methodology that enhances state-of-the-art LLMs with the ability to perform counterfactual token generation, allowing them to reason about past alternatives to their own outputs. We have experimentally analyzed the similarity between an LLM's original output and the one generated by counterfactual token generation, and we have demonstrated the use of our methodology in bias detection.\nOur work opens many interesting avenues for future work. Our causal model of the autoregressive process underpinning large language models crucially relies on the Gumbel-Max SCM. However, it would be interesting to understand the sensitivity of counterfactual token generation to the specific choice of SCM, and to consider alternative SCMs, especially those that do not satisfy the property of counterfactual stability. Furthermore, we have showcased our model on a single LLM, namely Llama 3 8B-instruct. It would be useful to implement our model on other LLMs and use counterfactual token generation to reveal similarities and differences between the underlying models of the world constructed by different LLMs. Specifically, it would be insightful to see whether the sensitivity of an LLM's counterfactual output changes as its number of parameters increases. Lastly, an interesting future direction would be to explore the use of our methodology in conjunction with human feedback to train (or fine-tune) LLMs that better understand causal relationships."}]}