{"title": "Multi-Agent Trajectory Prediction with Difficulty-Guided Feature Enhancement Network", "authors": ["Guipeng Xin", "Duanfeng Chu", "Liping Lu", "Zejian Deng", "Yuang Lu", "Xigang Wu"], "abstract": "Trajectory prediction is crucial for autonomous driving as it aims to forecast the future movements of traffic participants. Traditional methods usually perform holistic infer-ence on the trajectories of agents, neglecting the differences in prediction difficulty among agents. This paper proposes a novel Difficulty-Guided Feature Enhancement Network (DGFNet), which leverages the prediction difficulty differences among agents for multi-agent trajectory prediction. Firstly, we employ spatio-temporal feature encoding and interaction to capture rich spatio-temporal features. Secondly, a difficulty-guided decoder is used to control the flow of future trajectories into subsequent modules, obtaining reliable future trajectories. Then, feature interaction and fusion are performed through the future feature interaction module. Finally, the fused agent features are fed into the final predictor to generate the predicted trajectory distributions for multiple participants. Experimental results demonstrate that our DGFNet achieves state-of-the-art performance on the Argoverse 1&2 motion forecasting benchmarks. Ablation studies further validate the effectiveness of each module. Moreover, compared with SOTA methods, our method balances trajectory prediction accuracy and real-time inference speed. The code is available at https://github.com/XinGP/DGFNet.", "sections": [{"title": "I. INTRODUCTION", "content": "TRAJECTORY prediction is a crucial component of cur-rent autonomous driving systems. Its goal is to infer the future trajectory distribution of agents based on historical information within the scene. In addition to the historical motion information of the agents, various complex factors must be considered, such as lane markings and traffic light constraints in the map, as well as social interactions between agents. These considerations ensure that the future trajectory distribution can accurately reflect the agents' movement trends, thereby ensuring the proper functioning of the autonomous driving system.\nCurrently, mainstream prediction model architectures can be roughly divided into three steps: feature encoding, feature interaction, and feature decoding. Additionally, some methods improve the accuracy and robustness of prediction models through feature enhancement. These methods involve interme-diate modeling of future intentions or trajectories and interact and fuse these with the original encoded features. Although these methods significantly improve model performance com-pared to mainstream model architectures, they fail to con-sider the inherent heterogeneity in prediction difficulty among agents, i.e., the natural differences in prediction difficulty for different agents within the scene.\nTo address potential hazards in driving scenarios, during the decision-making and planning stages of autonomous driving, it is common to consider the heterogeneity of traffic participants' behaviors [1]\u2013[4]. This is primarily manifested in driver social"}, {"title": null, "content": "behaviors, intent uncertainty, and scenarios characterized by long-tail distributions [1], [5], [6]. They categorize surrounding agents from different measurement perspectives to enhance the safety and comfort of decision-making and planning tasks. Recently, some studies have incorporated long-tail detection into trajectory prediction tasks [4], [7]. Specifically, they use methods such as contrastive learning or clustering to measure similarity, aiming to reduce the distance in feature space between samples that share similar scene characteristics. Compared to the difficulty of driving scenarios, our method explores the influence of prediction difficulty of different agents within a single scene on the network.\nIn real driving scenarios, human drivers often predict the future behaviors of most agents subconsciously, relying on intuition. However, when faced with agents that may pose risks and exhibit high prediction difficulty, human drivers tend to carefully consider their behavior and motivations [8]. Inspired by human drivers, we aim to investigate the effectiveness of prediction methods that follow the principle of easy-to-hard in multi-agent trajectory prediction tasks. To mimic the prediction approach of human drivers, our first step is to initially predict the potential intentions and future trajectories of all agents in the scene based on historical trajectories and map information. This step resembles the rough sub-conscious prediction of human drivers. Then, the prediction difficulty differentiation of agents is performed based on the difficulty coefficient modeling. Additionally, based on difficulty differentiation, we use reliable future trajectories as prior information and utilize feature interaction and fusion for feature enhancement. The significance of this step is that the future behaviors of easily predictable agents impose motion constraints on those agents with higher difficulty. Finally, to better capture local motion features and global relationships, we combine two approaches for scene representation.\nAs illustrated in the Fig. 1, traditional trajectory prediction methods can be broadly summarized into two stages: En-coding&Interaction and Final Prediction. Initially, contextual encoding is employed to extract scene features from various input information. These features are processed through an interaction module, which aids the model in understanding and capturing the interactions and relationships between different entities (such as vehicles, lane markings, traffic lights, etc.). Finally, these features are passed to a decoding module to obtain the final predicted trajectories and their correspond-ing probability distributions. The primary difference in our pipeline is the addition of an intermediate module that gener-ates reliable future trajectories, thereby better prediction results can be achieved for agents with higher prediction difficulty. The main contributions of this paper can be summarised as follows:\n\u2022 We introduce a novel network architecture that combines the strengths of two scene representations and leverages the differences in prediction difficulty among agents for multi-agent trajectory prediction, thereby improving overall prediction accuracy.\n\u2022 We propose a difficulty-guided decoder that adjusts the flow of future trajectories based on prediction difficulty,"}, {"title": null, "content": "ensuring that reliable trajectories are utilized in subse-quent prediction steps.\n\u2022 Inspired by human drivers, our method follows the prin-ciple of easy-to-hard. By initially predicting the easier-to-predict agents and using their reliable future trajectories for feature interaction and fusion, we enhance the predic-tion results for agents with higher prediction difficulty.\nThe rest of this paper is organized as follows: We briefly review the related work in Section II. We present the technical details of our proposed method in Section III. Then, extensive experiments and analysis are presented in Section IV. Finally, we conclude the paper in Section V."}, {"title": "II. RELATED WORK", "content": "Heterogeneity in Trajectory Prediction. The inherent heterogeneity in driving trajectories can provide rich ad-ditional information for decision making tasks, leading to safer and more flexible decision outcomes. Recent research in trajectory prediction tasks has taken such heterogeneity into account to provide personalised predictions. For example, Chen et al. [9] proposed a distribution discrimination method to predict personalised motion patterns by distinguishing latent distributions. Xing et al. [10] introduced a joint time-series modelling approach that considers different driving styles to predict the trajectory of lead vehicles. In contrast to the emphasis on heterogeneity in the aforementioned works, our research focuses primarily on the prediction difficulty of the agents. For example, Makansi et al. [4] addressed the problem of long-tailed data distribution by exploiting the effects of feature embeddings. The use of contrastive learning in feature embeddings aggregates rare and difficult samples, contributing to improved final prediction performance. Qian et al. [11] introduced a teacher learning strategy based on the difficulty of scene prediction. They predefined the prediction difficulty of the scene and trained the proposed model by first training on easier samples and then on more difficult samples. How-ever, both methods did not consider potential differences in difficulty between agents in multi-agent prediction scenarios. In this work, we designed a difficulty estimation module to estimate potential prediction difficulties in multi-agent predic-tion scenarios. The future trajectories of agents with lower prediction difficulties are integrated into the scene to enhance information.\nFuture Feature Enhancement. Compared to conventional pipelines, methods that enhance features using future infor-mation allow networks to incorporate future constraints and interactions. These methods can be broadly categorized into two approaches: intention and future trajectories. TNT [12] and PECNet [13] model vehicle intention as latent variables and generate different prediction trajectories conditioned on vehicle intentions, forming predicted trajectories under certain constraint conditions. GANet [14] and ADAPT [15] inte-grate and fuse vehicle intentions for future feature enhance-ment through feature interaction. Similarly, Prophnet [16] and FFINet [17] model intermediate latent variables in the form of trajectories, where the output of intermediate decoders is one"}, {"title": null, "content": "or multiple trajectories. Additionally, there is a method that models future trajectories through planner sampling, followed by feature enhancement [18], [19].\nMost relevant to our work is M2I [20], which exploits po-tential game relationships between vehicles. It uses a Relation Predictor and a Marginal Trajectory Predictor to input the future trajectories of the leader in the game relationship as prior information into the Conditional Trajectory Predictor. However, we find that this method is highly dependent on the accuracy of the inferred game relationships and future trajectories. Accurately identifying game relationships be-tween two vehicles in long-term predictions proves to be very challenging. Therefore, we use the more easily extractable prediction difficulty as a basis for personalized classification. Our approach is an end-to-end inference model, abandoning the multi-model inference method used by M2I.\nScene Representation. Inspired by the application of con-volutional neural networks in image processing, early trajec-tory prediction methods used rasterized images as the main form of scene representation and then extracted 2D image features through convolution [21]. However, this approach required extensive image rendering processing and suffered from occlusion issues between trajectories and map scenes. To address this, Vectornet [22] introduced a unified scene representation by vectorizing trajectories and map scenes, and utilized MLP to extract scene information.\nBroadly, vectorization can be categorized into two types: scene-centric and agent-centric. Since the pioneer of vector-ization, Vectornet, was designed for single-agent trajectory prediction tasks, it naturally took the last frame coordinates of the vehicle to be predicted as the scene center, and expressed the trajectories and map vector coordinates of all other agents around the scene center. The benefit of this approach is that it enables the preservation of global relative pose features of various objects in the scene during feature extraction, and facilitates the embedding of some prior information or trajectory anchors [12], [16].\nHowever, due to the demands of multi-agent trajectory prediction tasks, there has been a shift towards agent-centric scene representation methods. Building upon agent-centric approaches, some methods aim to preserve as much infor-mation as possible about the mutual spatial relationships of various objects in the scene [23]\u2013[26]. To achieve this, they incorporate local pairwise-relative pose features and extract and fuse the relative pose information through networks such as GNNs [27] and Transformers [28]. However, such methods suffer from the limitation that historical and predicted trajecto-ries only retain local motion characteristics, making it incon-venient to embed anchor and prior information. Therefore, we aim to preserve the advantages of each method by integrating the two approaches."}, {"title": "III. METHOD", "content": "Recent works [10], [11] have been dedicated to associ-ating similar scenes through contrastive learning or cluster-ing, linking scenes based on their similarity, and enhancing features during inference according to the degree of scene similarity. We propose DGFNet, a network designed for multi-agent trajectory prediction using a Difficulty-Guided Feature Enhancement module for asynchronous interaction between historical trajectories and reliable future trajectories. As shown in Fig. 3, the architecture of DGFNet can be divided into three components: spatio-temporal feature encoding, feature interaction, and trajectory decoding.\n(1)Spatio-temporal Feature Extraction. This component extracts spatio-temporal features separately from agent-centric historical trajectory information and scene-centric informa-tion using both agent-centric and scene-centric approaches. (2) Feature Interaction. The difference with spatio-temporal feature extraction is that the feature extraction component is compatible for both scenarios. However, feature interaction is not. The feature interaction component is categorized into two types: multi-head attention module and multi-head attention module with edge features. The two interaction methods are respectively applicable to scene-centric and agent-centric sce-nario representations. (3)Trajectory Decoder. This component is divided into a difficulty-guided decoder and a final decoder. The difficulty-guided decoder operates during the intermediate process, while the final decoder outputs the final prediction results."}, {"title": "B. Problem formulation", "content": "Building on the majority of previous work, such as [1], [12], [22], [25], [29], we assume that upstream perceptual tasks can provide high-quality 2D trajectory tracking data for agents in a coordinate system. At the same time, localisation and mapping tasks can provide accurate self-vehicle positioning data and comprehensive HD map data for the urban environment. In other words, for j agents within a given scene, we obtain x and y positions, denoted as $X^{-th:0}_{i:j}$, corresponding to the time stamp horizon $\\{-th, ..., 0, 1, ..., t_f\\}$. The trajectory prediction task consists of predicting the future trajectories $Y^{1:t_f}_i$ of the agents by using the HD map information $M$ (including road coordinates, topological links, traffic lights and other relevant information) within the given scene and the historical trajectories output by the tracking task.\nIn accordance with the encoding methodology employed by VectorNet and LaneGCN, we represent the trajectory informa-"}, {"title": null, "content": "tion of agents and lane details in vectorized form. To elaborate further, for a given agent i within the scenario, its trajectory information, denoted as $X^i$, is represented as a matrix $X^{-th:0}_{th:0}$ comprising a spatio-temporal sequence\\{$s_{-th}$, $s_{-th+1}$,..., $s_{0}$\\} over the past th time step. Similarly, map information is also segmented into predefined sequence vectors to capture various scene details. Analogous to trajectory vectors, map information is represented as $M^{1:N} = \\{s_1, s_2, ..., s_N\\}$, where N denotes the total vector length. Within each lane vector $s_i$, there is an inclusion of lane slice coordinates, lane type (e.g., straight or left-turn lane), and map lane details such as traffic signals. This encapsulates diverse map information pertaining to each lane.\nIt should be noted that this method involves two types of scenario representations. As shown in Fig. 2, the scene-centric representation involves only one coordinate system, where all agents and lane markings are expressed within this coordinate system. For simplicity, we only use uppercase notation to denote the trajectory and map tensor as $X$ and $M$, respectively. In the agent-centric representation, multiple coordinate systems exist. Initially, all agents and lane markings are rotated using matrix rotation so that their orientations align with the x-axis. Subsequently, we use the original coordinates p and velocity orientation v to calculate the relative position distance $d_{ij}$ and the angular difference $\\alpha_{i j}$, $\\beta_{ij}$. We denote the agent-centric trajectory and map tensor as $A$ and $L$, respectively. Pairwise-relative pose is represented as $RPE$ = {$\\parallel d_{i\\rightarrow j}\\parallel$, $sin(\\alpha_{i\\rightarrow j})$, $cos(\\alpha_{i\\rightarrow j})$, $sin(\\beta_{i\\rightarrow j})$, $cos(\\beta_{i\\rightarrow j})\\$}.\nC. Spatio-temporal feature extraction\nIn the problem formulation, we explain the process of representing agent and high-definition (HD) map data as vectors, establishing a corresponding mapping between con-tinuous trajectories, map annotations, and sets of vectors. This vectorization method allows us to encode trajectory and map information as vectors. Following the trajectory feature ex-traction method of LaneGCN, our trajectory feature extraction module mainly uses 1D CNN and downsampling techniques to encode the historical trajectories of all vehicles in the scene, thus obtaining encoded historical trajectory features. For map tensor, we use the PointNet [30] to encode lane nodes and structural information to obtain map features. It is worth mentioning that when processing scene-centric vector information, we do not mix vehicle historical trajectories and lane line information. Our view is that vehicle trajectories, as dynamic vectors, need to be distinguished from static maps to better capture the local motion characteristics of the vehicles. For the extraction of historical trajectory features are described by this:\n$Z_i$ = Convld(Resld($X_i$)) for i = 0,1,..., $N_{fpn}$ -1 (1)\n$X_i$ = Inter($Z_{i+1}$, scale_factor = 2) + $Z_i$ (2)\nafter Resld and Convld encoding, feature alignment is per-formed by scaling and interpolation operations. For the agent-"}, {"title": null, "content": "centric trajectory tensor, the same feature extraction is used to obtain $A$.\nFor map feature extraction is described by this:\n$H_1$ = PAB1 (ReLU(LayerNorm($MW_p$ + $b_p$))) (3)\n$M$ = PAB2($H_1$) (4)\nwhere $M\\in ]RN_{lane}\\times10\\times C_{in}$ are the input lane features, $W_p \\in R^{C_{in}\\times h}$ and $b_p \\in Rh$ are the weights and biases for the projection layer, and PAB represents the PointAggregateBlock. Similarly, we can obtain the agent-centric map feature $L$.\nFor RPE we use MLP for feature extraction to get RPE.\nD. Feature interaction\nOur intention was to utilize the global representation of scence-centric scenes to embed future trajectory features. Interestingly we found that even without any future enhance-ment, just concatenating the Actor features after the two interactions gives a better boost. Specific results can be seen later in the ablation experiments. Here we will present the two interaction methods: multi-head attention module and multi-head attention module with edge features, respectively.\nWe first introduce a generic feature interaction block. In contrast to the general method, which uses simple attention operations for feature interaction, we believe that multi-head attention mechanisms are often better suited to handle complex input sequences and capture a wider range of hierarchical and diverse information. We opt for Multi-Head Attention Blocks (MHAB) instead of the previously used simple attention oper-ations, as used for the features [31]. Specifically, we use self-attention encoders and feedforward networks (FFN) for self-interaction and cross-attention encoders and FFN for cross-interaction:\nMHA(Q, K, V) = softmax ($\\frac{Q K^T}{\\sqrt{dimk}}$) V (5)\nQ, V 2, K,V = $W^Q$, $W^k$,$W^V$ (6)\nwhere MHA denotes the Multi-Head Attention operation. Q, K, V are computed by linear projections $W_q$, $W_k$, $W_v$ applied to input vectors. The attention mechanism computes scaled dot-product attention using Q and K, and applies it to V after softmax normalization.\nThe feature interaction module for carrying edge features is described as follows:\nMHA(Q', K', V') = softmax ($\\frac{Q'K'^T}{\\sqrt{dimk}}$) V' (7)\nQ', K',V' = Q+$W^{Q_{edge'}}$, K+$W^{k_{edge'}}$, V+$W^{V_{edge'}}$ (8)\nhere, Q', K', V' are the query, key, and value tensors after linear transformations that incorporate edge features, and edge' is the edge feature after linear transformation.\nFinally, the normalized output after attention and dropout application is:\nx' = LayerNorm(x + Drop(MHA(Q', K', V'))) (9)"}, {"title": null, "content": "For ease of expression, we denote regular multi-head at-tention as MHA and multi-head attention with edge features as MHAedge. Our Scene-centric Feature Interaction can be denoted as follows:\n$\\widehat{X}^{(1)}$ = MHAM(M$^{(1-1)}$, $X^{(1-1)}$) (10)\nM$^{(1)}$ = MHAMM(M$^{(1-1)}$) (11)\nM$^{(1)}$ = MHAM(X$^{(1)}$, M$^{(1-1)}$) (12)\nX$^{(1)}$ = MHAAA($X^{(1-1)}$) (13)\nHere, I denotes the current layer index, and X$^{(0)}$ = X and M$^{(0)}$ = M are the initial inputs.\nOur Agent-centric Feature Interaction can be denoted as follows:\n$\\widehat{A}^{(k)}$ = MHAedge($\\widehat{A}^{(k-1)}$, $\\widehat{L}^{(k-1)}$, RPE$^{(k-1)}$) (14)\nSimilarly we complete multiple rounds of interactions by looping through multiple levels of updates.\nE. Difficulty-guided decoder\nTo take advantage of the different prediction difficulties of different agents in the scenario, we developed the Difficulty Guided Feature Enhancement Module, which consists of a Difficulty Guided Trajectory Decoder and a Future Feature Interaction Module.\nTo capture features of plausible future trajectories in the scene, we introduce a Difficulty-Guided Decoder to obtain the future trajectories of agents that are relatively easier to predict. Firstly, we decode the actor features $\\widehat{A}^{(k)}$ in Agent-centric, which have undergone multiple layers of feature interactions. Each agent receives six predicted trajectories. Following the ADAPT [15] trajectory decoder to get higher quality decoded trajectories by predicting endpoints for refinement. The decod-ing process can be expressed as follows:\n$\\widehat{E}$ = MLPend($\\widehat{A}^{(1)}$) + MLPrefine(Cat[$\\widehat{Y}^{(1)}$, $\\widehat{E}$]) (15)\nP = Cat[MLPtraj (Cat[$\\widehat{X}^{(1)}$, $\\widehat{E}$]), $\\widehat{E}$] (16)\nWhere endpoints $\\widehat{E}$ are predicted and refined by concatenating with the agent features $\\widehat{A}^{(1)}$, then the trajectories P are predicted and merged with the refined endpoints.\nThe Argoverse 1 validation and train sets show that the predicted trajectories of most of the vehicles in the scenarios exhibit a high degree of concentration, with more than 90% of the samples of straight ahead trajectories in each case [32]. This suggests that the motion patterns of most agents can be easily captured, reflecting real-world traffic scenarios. In order to prevent higher difficulty prediction trajectories from entering the subsequent modules and generating cumulative errors, we introduced a difficulty masker to filter the initial prediction results. ScenceTransformer [33], inspired by recent approaches to language modeling, has pioneered the idea of using a masking strategy as a query to the model, enabling it to invoke a single model to predict agent behavior in multiple ways (marginal or joint prediction). This mechanism in this"}, {"title": null, "content": "paper is intended to mask out the initial prediction trajectories of the more difficult agents, thus providing better control over the prediction accuracy. This process can be formalized as Algo. 1.\nF. Future feature enhancement\nFor the reliable future trajectories we first flatten them by performing the flatten operation on multiple future trajectories for feature dimension alignment. Then future trajectory feature extraction is performed by a simple MLP layer. These two operations can be formulated as:\nF = MLP(flatten($P_{masked}$)) (17)\nSubsequently, we interact the future trajectory feature F with the agent-centric interactive actor feature $\\widehat{A}^{(k)}$ via multi-head attention. This operation aims to impose certain con-straints on the prediction of other agents through the reliable future trajectory features. Finally, we need to perform one last interaction using the original map features M. This step is crucial as it aims to refocus on the reachable lane lines of the map after imposing social constraints through the future trajectory features [34]. These two operations can be formulated as:\nH = MHAAF($\\widehat{A}^{(k)}$, F) (18)\n$\\widehat{O}$ = MHAMM (H, M) (19)\nG. Final prediction\nWe perform feature fusion operations on the final features $\\widehat{O}$ and the scence-centric feature X$^{(1)}$, expanding the decoding dimension to 256. Our final predictor can generate multimodal trajectories for all agents in the scene and their correspond-ing probabilities in a single inference. This process can be described as follows:\nAfusion = Cat($\\widehat{O}$, X$^{(1)}$) (20)\nE = MLPend(Afusion) + MLPrefine(Cat[Afusion, $\\widehat{E}$]) (21)\nK = softmax(MLPcls(Cat[Afusion, $\\widehat{E}$])) (22)\nP = Cat[MLP traj (cat[Afusion, $\\widehat{E}$]), $\\widehat{E}$] (23)"}, {"title": "IV. EXPERIMENTS", "content": "A. Experimental setup\nDatasets. Our model DGFNet is tested and evaluated on a very challenging and widely used self-driving motion pre-diction dataset: the Argoverse 1&2 [47], [48]. Both motion prediction datasets provide agent tracking trajectories and semantically rich map information at a frequency of 10Hz over a specified time interval. The prediction task in Argoverse 1 is to predict trajectories for the next 3 seconds based on the previous 2 seconds of historical data. The dataset contains a total of 324,557 vehicle trajectories of interest extracted from over 1000 hours of driving. In contrast, Argoverse 2 requires a higher level of robustness and generalization of the predic-tive model, with 250,000 of the most challenging scenarios officially filtered from the self-driving test fleet. Argoverse 2 predicts the next 6 seconds from the first 5 seconds of historical trajectory data, and Argoverse 2 provides heading data for traffic targets as well as traffic target categories, in order to ensure fair comparisons between models, the dataset has official data partitioning and the test set is evaluated using the Eval online test server.\nEvaluation Metrics. We have adopted the standard testing and evaluation methodology used in motion prediction compe-titions to assess prediction performance. Key metrics for indi-vidual agents include Probabilistic minimum Final Displace-ment Error (p-minFDE), Minimum Final Displacement Error (minFDE), Minimum Average Displacement Error (minADE), Miss Rate (MR) and Drivable Area Compliance (DAC). Where p-minFDE, MR, and minFDE reflect the accuracy of the predicted endpoints, and minADE indicates the overall bias in the predicted trajectories. DAC, reflects the compliance of the predicted outcomes, which is incorporated into the bias when the predicted outcomes are outside of the drivable region.\nImplementation Details. We generate lane vectors for lanes that are more than 50 meters away from any available agent. The number of layers land k of interaction features are set to 3. All layers except the final decoder have 128 output feature channels. In addition, the weight parameters in the loss function are set to a=0.7, \u03b2=0.1 and \u5165=0.2. The hyperparameter 7 in the difficulty masker was set to 5. The"}, {"title": "V. CONCLUSION", "content": "In this paper, we propose a novel Difficulty-Guided Feature Enhancement Network (DGFNet) for muti-agent trajectory prediction. Distinguishing from general future enhancement networks, our model emphasizes filtering future trajectories by masking out and retaining only reliable future trajectories for feature enhancement, which greatly improves the prediction performance. Extensive experiments on the Argoverse 1&2 benchmarks show that our method outperforms most state-of-the-art methods in terms of prediction accuracy and real-time processing. In addition, we integrate agent-centric and scence-centric scene features in a concise and effective way, and demonstrate that the fusion of the two features is effective in improving the model prediction accuracy.\nEmulating the predictive habits of human drivers is an intriguing direction for future research. This involves emu-lating human strategies when encountering different vehicles and making effective assumptions in the presence of incom-plete perceptual information. Furthermore, we will integrate Difficulty-Guided feature enhancement into other prediction frameworks to further validate the efficacy of this module in optimizing multi-agent trajectory prediction problems."}]}