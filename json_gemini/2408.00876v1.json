{"title": "On the Relationship Between Monotone and Squared Probabilistic Circuits", "authors": ["Benjie Wang", "Guy Van den Broeck"], "abstract": "Probabilistic circuits are a unifying representation of functions as computation graphs of weighted sums and products. Their primary application is in probabilistic modeling, where circuits with non-negative weights (monotone circuits) can be used to represent and learn density/mass functions, with tractable marginal inference. Recently, it was proposed to instead represent densities as the square of the circuit function (squared circuits); this allows the use of negative weights while retaining tractability, and can be exponentially more compact than monotone circuits. Unfortunately, we show the reverse also holds, meaning that monotone circuits and squared circuits are incomparable in general. This raises the question of whether we can reconcile, and indeed improve upon the two modeling approaches. We answer in the positive by proposing InceptionPCs, a novel type of circuit that naturally encompasses both monotone circuits and squared circuits as special cases, and employs complex parameters. Empirically, we validate that InceptionPCs can outperform both monotone and squared circuits on image datasets.", "sections": [{"title": "1 INTRODUCTION", "content": "Probabilistic circuits (PC) [Choi et al., 2020] are a unifying class of tractable probabilistic models. By imposing simple structural properties on the circuit, one can answer many inference queries such as marginalization and maximization, efficiently and exactly. The typical way to learn PCs is to enforce non-negativity throughout the circuit, by restricting to non-negative parameters; these are known as monotone PCs [Darwiche, 2003, Poon and Domingos, 2011]. However, recent works have also shown that there exist many tractable models that provably cannot be expressed in this way [Zhang"}, {"title": "2 PRELIMINARIES", "content": "Notation We use capital letters to denote variables and lowercase to denote their assignments/values (e.g. X, x). We use boldface (e.g. X,x) to denote sets of vari- ables/assignments.\nDefinition 1 (Probabilistic Circuit). A probabilistic circuit C over a set of variables V is a rooted DAG consisting of three types of nodes n: input, product and sum nodes. Each input node n is a leaf encoding a function fn: W \u2192 R for some W\u2286 V, and for each internal (product or sum) node n, denoting the set of inputs (i.e. nodes n' for which n \u2192 n') by in(n), we define:\nfn = {\\begin{array}{ll} \\prod_{n_i \\in in(n)} f_{n_i} & \\text{if n is product}; \\\\ \\sum_{n_i \\in in(n)} \\Theta_{n,n_i} f_{n_i} & \\text{if n is sum}. \\end{array}   (1)"}, {"title": "3 EXPRESSIVE EFFICIENCY OF MONOTONE AND SQUARED STRUCTURED-DECOMPOSABLE CIRCUITS", "content": "One of the primary applications of probabilistic circuits is as a tractable representation of probability distributions. As such, we typically require the function output of the circuit to be a non-negative real. The usual way to achieve this is to enforce non-negativity of the weights and input functions:\nDefinition 4 (Monotone PC). A probabilistic circuit is monotone if all weights are non-negative reals, and all input functions map to the non-negative reals.\nGiven a monotone PC C, one can define a probability distri- bution p1(V) = \\frac{f_C(V)}{Z_C} where Zc is the partition function of the PC. However, this is not the only way to construct a non-negative function. In Loconte et al. [2024], it was proposed to instead use fc to represent a real (i.e. possi- bly negative) function, by allowing for real weights/input functions; this can then be squared to obtain a non-negative function. That is, we define p2(V) := \\frac{f_C(V)^2}{\\sum_v f_C(v)^2}.\nIn order for \\sum_v f_C(v)^2 to be tractable to compute, a sufficient condition is for the circuit C to be structured- decomposable; one can then explicitly construct a"}, {"title": "4 TOWARDS A UNIFIED MODEL FOR DEEP SUMS-OF-SQUARES-OF-SUMS", "content": "We begin by noting that, beyond simply negative parameters, one can also allow for weights and input functions that are complex, i.e. take values in the field C. Then, to ensure the non-negativity of the squared circuit, we multiply a circuit with its complex conjugate. That is:\nP_2(V) = \\frac{|f_C(V)|^2}{\\sum_v |f_C(v)|^2} = \\frac{f_C(V) \\overline{f_C(V)}}{\\sum_v f_C(v) \\overline{f_C(v)}}\nAs complex conjugation is a field isomorphism of C, taking a complex conjugate of a circuit is as straightforward as taking the complex conjugate of each weight and input function, retaining the same DAG as the original circuit."}, {"title": "4.1 DEEP SUMS-OF-SQUARES-OF-SUMS: A LATENT VARIABLE INTERPRETATION", "content": "In the latent variable interpretation of probabilistic circuits [Peharz et al., 2016], for every sum node, one assigns a cate- gorical latent variable, where each state of the latent variable is associated with one of the inputs to the sum node; we show an example in Figure 1a. In this interpretation, when performing inference in the probabilistic circuit, we explic- itly marginalize over all of the latent variables beforehand.\nHowever, interpreting these latent variables when we con- sider probability distributions defined by squaring circuits. The key question is, does one marginalize out the latent variables before or after squaring? We show both options in Figures 1b and 1c. In Figure 1b, we square before marginal- izing Z. In this case, and we are left with a sum node with non-negative real parameters. On the other hand, if we marginalize before squaring, we have a sum node with four children and complex parameters. Interestingly, the for- mer case is very similar to directly constructing a monotone PC, while the latter is more like an explicit squaring without latent variables. This suggests that we can switch between monotone and squared PCs simply by deciding whether to sum the latent variables inside or outside the square.\nUsing this perspective, we propose the following model, which makes explicit use of both types of latent variable. For simplicity, we assume that each sum node has the same num- ber of children Ku \u00d7 Kw. For each scope sc(n) of sum node in the circuit, we assign two latent variables Usc(n), Wsc(n), which are categoricals with cardinality Ku, Kw respec- tively. Writing U, W for the sets of all such latents, we can then construct an augmented PC where each child of a sum node corresponds to a value of both latents Usc(n), Wsc(n).\nDefinition 5 (Augmented PC). Given a smooth and decom- posable probabilistic circuit C over variables V where each sum node has Ku \u00d7 Kw children, we define the augmented PC Caug over variables VUU UW as follows. In reverse topological order (i.e. from leaves to root), for each sum node n with inputs n1, \u2026, NK\u028a\u00d7Kw, we replace the inputs with new product nodes n'\u2081, \u2026\u2026\u2026, n'\u039a\u03c5\u00d7Kw, where for each 1 \u2264 i \u2264 Ku, 1 \u2264 j \u2264 Kw:\n n_{iK_W+j} = n_{iK_W+j} \\times [U_{sc(n)} = i] \\times [W_{sc(n)} = j]\nwhere [Usc(n) = i], [Wsc(n) = j] are input nodes with input functions that output 1 if the condition inside the bracket is satisfied and 0 otherwise."}, {"title": "4.2 TENSORIZED IMPLEMENTATION", "content": "To implement InceptionPCs at scale and with GPU accelera- tion, we follow recent trends in probabilistic circuit learning [Peharz et al., 2020, Mari et al., 2023] and consider ten- sorized architectures, where sum and product nodes are"}, {"title": "5 EXPERIMENTS", "content": "We run preliminary experiments with InceptionPCs on vari- ants of the MNIST image dataset [LeCun and Cortes, 2010, Cohen et al., 2017, Xiao et al., 2017]. Our primary re- search question is to examine the relative expressivity and"}, {"title": "6 DISCUSSION", "content": "To conclude, we have shown that two important classes of tractable probabilistic models, namely monotone and squared real structured-decomposable PCs are incompara- ble in terms of expressive efficiency in general. Thus, we propose a new class of probabilistic circuits based on deep sums-of-squares-of-sums that generalizes these approaches. As noted by [Loconte et al., 2024], these PCs can be viewed as a generalization of tensor networks for specifying quan- tum states [Glasser et al., 2019, Novikov et al., 2021]; indeed InceptionPCs can be interpreted as a mixed state, i.e. a sta- tistical ensemble of pure quantum states. Our InceptionPCs are also related to the PSD circuits of [Sladek et al., 2023], which can be interpreted as a sum of squared circuits, with the difference being that we allow for latents to be summed out both inside and outside the square throughout the circuit while achieving quadratic complexity. Promising avenues to investigate in future work would be improving the optimiza- tion of InceptionPCs, for example, by deriving an EM-style algorithm using the latent variable interpretation outlined here; as well as reducing the computational cost of training by designing more efficient architectures."}, {"title": "A PROOFS", "content": "Proposition 1 (Tractability of Complex Conjugation). Given a smooth and decomposable circuit C, it is possible to compute a smooth and decomposable circuit C such that f(V) = fc(V) of size and in time O(|C|). Further, if C is structured decomposable, then it is possible to compute a smooth and structured decomposable C2 s.t. fc2(V) = fc(V)fc(V) of size and in time O(|C|2).\nProof. We show the first part inductively from leaves to the root. By assumption, we can compute the complex conjugate of the input functions. Thus we need to show that we can compute the conjugate of the sums and products efficiently, assuming that we can compute the conjugates of their inputs.\nSuppose that we have a sum n; then we have that: fn = \u2211n; Ein(n) On,nifni = n; Ein(n) On,n; fni. Thus we can simply conjugate the weights and take the conjugated input nodes.\nSuppose that we are given a product n; then we have that: fn = In\u2081\u2208in(n) fni = In\u2081\u2208in(n) fni. Thus we can take the conjugated input nodes.\nThis procedure is clearly linear time and keeps exactly the same structure as the original circuit (thus smoothness and decomposability). If the input circuit is structured decomposable, then we can multiply fe and fe as they are compatible [Vergari et al., 2021], producing a smooth and structured decomposable circuit as output.\nTheorem 2. There exists a class of non-negative functions p(V), such that there exist monotone structured-decomposable PCs C with p(V) = fc(V) of size polynomial in |V|, but the smallest structured-decomposable PC C' such that p(V) = fc'(V)^2 has size 2\u00ba(|V|).\nProof. Given a set of d variables V, we consider the function:\np(V) = n(V) + 1  (3)\nwhere we write n(V) for the non-negative integers given by the binary representation.\nExistence of Compact Str.Dec.Monotone Circuit This function can be easily represented as a linear-size monotone structured-decomposable PC as follows:\np(V) = fc(V) = \\sum_{i=0}^{d-1} 2^iV_i + 1\nwhich can also be easily smoothed if desired."}, {"title": "B LOWER BOUND STRATEGY", "content": "Lower Bound Strategy It remains to show the lower bound on the size of the negative structured-decomposable PC C'. Firstly, we have the following Lemma:\nLemma 1. [Martens and Medabalimi, 2014] Let F be a function over variables V computed by a structured-decomposable and smooth circuit C. Then there exists a partition of the variables (X, Y) with |V| \u2264 |X|, |Y| < |V| and N < |C| such that:\nF(X,Y) = \u2211G(X) \u00d7 H(Y)  (4)\nfor some functions Gi, Hi.\nTo show a lower bound on |C'|, we can thus show a lower bound on N. To do this, we use another Lemma:\nDefinition 6. Given a function F over variables X, Y, we define the value matrix MF(X,Y) \u2208 R2|x|x2|Y| by:\nM_{n(X),n(Y)} := F(X,Y)  (5)\nLemma 2. [de Colnet and Mengel, 2021] Suppose Equation 4 holds. Then rank(MF(X,Y)) \u2264 N.\nThus, it suffices to lower bound rank(MF(X,Y)) over all partitions X, Y such that |V| < |X|, |Y| \u2264 |V|.\nLower Bound Given such a partition X, Y, assume w.l.o.g. |X| \u2264 |Y|. Consider any function F(V) such that F(V) = \u00b1\u221an(V) + 1.\nEach variable X \u2208 X corresponds to some variable in V. We write idx(X) to denote the index of the variable X corresponds to; for example, if X is V4, then idx(X) = 4. Then we have the following:\nF(X,Y) = \u00b1\\sqrt{\\sum_{i=0}^{|X|-1} 2^{idx(X_i)} X_i + \\sum_{i=0}^{d-|X|-1} 2^{idx(Y_i)} Y_i + 1}  (6)\nWe write (X) := \u2211i=|x|-1 2idx(i) Xi and (Y) := \u2211i=d-x-1 2idx(i); such that F(X,Y) = \u00b1\u221a(X) + \u03b9(Y) + 1. Note that is injective as the idx(Xi) are distinct for each i (sim. for idx(Y\u2081)).\nNow we need the following Lemma:\nLemma 3. For any \u0454 > 0, and for sufficiently large d, there exists at least M = 2(1\u2212\u20ac)d distinct instantiations of {x}_0^{M-1} and M distinct instantiations of {y}_0^{M-1} of Y such that p_i := \\iota(x_i) + \\iota(y_i) + 1 are distinct primes, and  \\iota(x_j) + \\iota(y_k) + 1 \\ne p_i for any 0 \\leq i, j, k \\leq M - 1 except i = j = k.\nProof. We begin by lower bounding the number of prime pairs; that is, the number of instantiations (x, y) of X, Y such that (F(x, y))\u00b2 = \u03b9(x) + \u03b9(y) + 1 is prime. Each prime p less than or equal to 2d will have exactly 1 prime pair. The number of primes \u03c0(m) less than or equal to any given integer m \u2265 17 is lower bounded by \\frac{m}{\\ln{m}}  Rosser and Schoenfeld [1962]. Thus, we have that the number of prime pairs is at least:\n\\frac{2^d}{d\\ln{2}} (7)\nGiven any instantiation \u00e6 of X, we call y a prime completion of x if (x, y) is a prime pair. We now claim that there are at least M instantiations of X such that each has at least 2M\u00b2 + 1 prime completions. Suppose for contradiction this was not the case. Then the total number of prime pairs is upper bounded by:\n (M - 1) \\times 2^{d-|X|} + (2^{|X|} - M + 1) \\times 2M^2\n< 2^{(1-\\epsilon)d}2^{d-|X|} + 2^{|X|} \\times 2^{2(1-\\epsilon)d+1}\n= 2^{(1-\\epsilon)d-|X|} + 2^{2(1-\\epsilon)d+|X|+1} 2^{(1-\\epsilon)d}+2^{(1-2\\epsilon)d+1} (8)"}, {"title": "BLOG-SUM-EXP TRICK FOR COMPLEX NUMBERS", "content": "To avoid numerical under/overflow, we perform computations in log-space when computing a forward pass of a PC. For complex numbers, this means keeping the modulus of the number in log-space and the argument in linear-space."}, {"title": "C EXPERIMENTAL DETAILS", "content": "For each dataset, we split the training set into a train/valid split with a 95%/5% ratio. We train for 250 epochs, employing early stopping if there is no improvement on the validation set after 10 epochs. We use the Adam optimizer [Kingma and Ba, 2015] with learning rate 0.005 and batch size 256. Model training was performed on RTX A6000 GPUs.\nFor the input functions, we use categorical inputs for each pixel V, i.e. for 8-bit data we have 256 parameters f(V = i) for each i \u2208 0, 255. For monotone PCs, this takes values in R\u22650, for squared negative PCs, this takes values in R, and for squared complex PCs or InceptionPCs this takes values in C.\nIn Figure 3, we show learning curves for the MNIST and FashionMNIST datasets (y-axis shows training log-likelihood). It can be seen that for monotone, squared complex, and InceptionPCs, the curve is fairly smooth and optimizes quickly, while the curve is more noisy for squared real PCs. We hypothesize that this is due to the fact that gradients for the squared real PC have a discontinuity in the complex plane when the parameter is 0; meanwhile PCs with non-negative real or complex parameters can smoothly optimize over the complex plane."}]}