{"title": "You Have Thirteen Hours in Which to Solve the Labyrinth: Enhancing AI Game Masters with Function Calling", "authors": ["Jaewoo Song", "Andrew Zhu", "Chris Callison-Burch"], "abstract": "Developing a consistent and reliable AI game master for text-based games is a challenging task due to the limitations of large language models (LLMs) and the complexity of the game master's role. This paper presents a novel approach to enhance AI game masters by leveraging function calling in the context of the table-top role-playing game \"Jim Henson's Labyrinth: The Adventure Game.\" Our methodology involves integrating game-specific controls through functions, which we show improves the narrative quality and state update consistency of the AI game master. The experimental results, based on human evaluations and unit tests, demonstrate the effectiveness of our approach in enhancing gameplay experience and maintaining coherence with the game state. This work contributes to the advancement of game AI and interactive storytelling, offering insights into the design of more engaging and consistent AI-driven game masters.", "sections": [{"title": "1 Introduction", "content": "Imagine a world where the power of storytelling meets the ingenuity of artificial intelligence, giving rise to game masters that can weave captivating narratives and adapt to the players' choices in real-time. This is the vision that drives our research into enhancing AI game masters for table-top role-playing games (TTRPGs). However, the realization of this vision is hindered by the limitations of current large language models (LLMs) and the inherent complexity of the game master's role (Liapis et al., 2014). The popularity of LLMs sparked a wave of research on AI game masters (Hua and Raley, 2020; Callison-Burch et al., 2022; Zhou et al., 2022; Zhu et al., 2023a; Ang et al., 2023; Triyason, 2023), but the challenge of maintaining consistency and coherence with the game state across multiple turns remains largely unaddressed. Indeed, using an LLM for a game master allows a variety of inputs and diverse narratives, unlike the traditional keyword-matching approach that requires rigid input commands and fixed outputs. However, an LLM-based game master is prone to going off the rails with respect to game rules and flow due to its unpredictability and limitation in performing game-specific functionalities. This is where our work comes in, proposing a novel approach that leverages function calling (Schick et al., 2024; Li et al., 2024) to provide fine-grained controls to the AI game master, enabling it to generate narratives that are not only engaging but also consistent with the game rules and state. The main contributions of this paper are as follows:\n\u2022 We present a methodology for enhancing AI game masters by integrating function calling, which allows for game-specific controls and state management.\n\u2022 We implement a simulation of the TTRPG \"Jim Henson's Labyrinth: The Adventure Game\" to evaluate the effectiveness of our approach in a realistic game setting.\n\u2022 We conduct human evaluations and unit tests to assess the impact of function calling on the narrative quality, state update consistency, and overall gameplay experience.\n\u2022 We provide insights and guidelines for designing more engaging and consistent AI-driven game masters, contributing to the advancement of game AI and interactive storytelling."}, {"title": "2 Related Work", "content": "The integration of AI in game design and development has been a topic of growing interest in recent years. In this section, we review the relevant literature on AI game masters, with a focus on the use of LLMs and function calling."}, {"title": "2.1 AI Game Masters in TTRPGs", "content": "One of the most actively researched TTRPGs in the domain of LLMs would be Dungeons & Dragons (D&D) (Gygax and Arneson, 1974). Callison-Burch et al. (2022) model D&D as a dialogue challenge and experiment on the LLM's performance on the next utterance prediction and game state tracking, using the model to generate the next state. Zhu et al. (2023a) present a dataset based on the ground-truth game states collected from real gameplay and test their effects on narration generation. Zhu et al. (2023c) show that GPT-3 (Brown et al., 2020) can be used as a game master's assistant to help brainstorm and create random encounters in D&D. Santiago et al. (2023) use an LLM as a story-telling assistant in D&D including a few generated story examples. Both these projects focus on using an LLM as an assistant, not a fully functional GM."}, {"title": "2.2 LLMs with Function Calling", "content": "The integration of function calling with LLMs has shown promising results in various domains. Schick et al. (2024) propose a method for fine-tuning LLMs with API call annotations, enabling them to perform tasks such as question answering, calculation, and translation. Li et al. (2024) apply function calling to dialogue state tracking by mapping domains to functions and slot-value pairs to argument-value pairs. In the context of games, Volum et al. (2022) and Wang et al. (2023) leverage LLM-generated functions to perform actions in Minecraft. However, these projects focus on open-ended gaming agents rather than game masters, which arguably have more complex requirements and responsibilities. Our work builds upon these previous studies by integrating function calling with LLMs to enhance AI game masters in the context of TTRPGs. We propose a methodology that allows for game-specific controls and state management, enabling more consistent and engaging gameplay experiences."}, {"title": "3 Overview of Labyrinth", "content": "To evaluate the effectiveness of our approach, we implement a simulation of the TTRPG \u201cJim Henson's Labyrinth: The Adventure Game\" (Milton, 2020) using the chat-based framework Kani (Zhu et al., 2023b). Labyrinth is a TTRPG inspired by the 1986 fantasy film \u201cLabyrinth,\" directed by Jim Henson. In Labyrinth, players take on the roles of adventurers navigating a magical and treacherous maze filled with challenges and obstacles. The game master is responsible for describing the game world, controlling non-player characters (NPCs), and enforcing the game rules. Here are some key features of the game:\n\u2022 System and Rules: The game is designed with newcomers in mind, and has a simpler rule set than D&D. In the character creation process, players pick a class, with one character trait and one flaw (which affect their skill checks).\n\u2022 Dice-Based \u201cTests\u201d: The game primarily uses six-sided dice (d6) to determine the outcome whenever a character tries something that has a chance of failure. If the result is higher or equal to the difficulty number set by the GM, the character succeeds, otherwise they fail. Relevant character traits cause dice to be rolled with advantage (rolling 2d6 and keeping the highest), and flaws cause dice to be rolled with disadvantage (2d6, keeping the lower).\n\u2022 Locations: The game includes pre-written adventures through a variety of locations in the Labyrinth. Each location describes criteria that players must achieve in order to move on to the next location. Most locations contain objects, NPCs and random tables which are used for initializing the scene or defining random encounters.\n\u2022 Time tracking: The players are given 13 hours to reach the center of the Labyrinth and defeat the Goblin King. Any failure to pass the exit criteria or succeed in a certain task increments the clock."}, {"title": "4 Labyrinth Game Simulation", "content": "In our simulation of Labyrinth, the players create characters to explore the Labyrinth, and our AI agent takes on all of the responsibilities of the game master. More details in the implementation are in Appendix A."}, {"title": "4.1 Game State", "content": "There are two types of game states in this system.\n\u2022 The scene state, which represents the current state of the game world, including the scene description, NPCs, objects, and success/failure conditions. The details of the scene state are elaborated in Appendix B.\n\u2022 The player state encompasses the specifications of each player character, such as their name, kin, persona, traits, flaws, and inventory. The details of the player state are written in Appendix C. These game states are initialized before each scene starts and can be updated during the game by the AI game master using the provided functions, discussed below. The scene state and player states are represented as Python objects or variables and are included in the input prompt for every generation by default."}, {"title": "4.2 Rule Retrieval", "content": "To maintain consistency with the game rules, we manually summarized the game rules by extracting the essential parts from the book. This rule summary, which consists of about 50 sentences, is injected into the prompt as a whole or a few sentences are retrieved according to the importance. More details are in Appendix A.4."}, {"title": "4.3 Dialogue history", "content": "The dialogue history represents all of the turns in the chat, including player input, GM descriptions (output to the player), and function calls made by the GM. A sample dialogue is given in Figure 2. The chat messages in the history form the prompt to the game master depending on the pre-defined prompt design configurations, which are elaborated in Appendix A.5."}, {"title": "4.4 Function Types", "content": "We define two types of functions in our game system:\n1. Dice roll function: This function simulates the rolling of dice when a player attempts an action with a certain difficulty. For example, the activate_test function generates random numbers to mimic dice rolls and determines the success or failure of the action based on the outcome and the game rules. A dice roll function affects the game flow but does not directly modify the game state.\n2. State functions: These functions directly modify the game state variables. For instance, the create_npc function adds a new NPC to the current scene, while the add_item function updates a player's inventory by adding a new item. State functions are essential for maintaining consistency between the game narrative and the underlying game state."}, {"title": "4.5 Function Calling Process", "content": "During gameplay, the AI game master determines when to call a function based on the current game context and the predefined function definitions. The function definitions, along with the chat history and game state, are passed to the language model as part of the input prompt. The model then selects the appropriate function to call and parses the necessary arguments from the dialogue context. Figure 2 shows an example of multi-turn interaction between a player and the game master with functions. Normally, the game master generates a natural language response, but a function can be called anytime when it is necessary. Note that function calls can be sequential, where another function might be called after the previous one depending on the context or the result. Until the game master determines that no more functions or responses are needed (i.e. generates a stop token without a function call), the game master's turn continues. Figure 3 illustrates the steps involved in a single function call. The AI game master first generates a response based on the current game state and chat history. If a function call is required, the model selects the appropriate function and provides the necessary arguments. The function is then executed, updating the game state if necessary, and the result is appended to the chat history. This process continues until the game master determines that no further functions or responses are needed."}, {"title": "5 Experimental Design", "content": "In this section, we discuss the data collection and unit test procedures used to evaluate the performance of the AI game master."}, {"title": "5.1 Data Collection", "content": "To collect gameplay data, we simulate 24 game scenes from the Labyrinth game book using GPT-4(Achiam et al., 2023) to play the roles of both the players and the game master. We create four player characters with diverse kins, traits, and flaws, and use the SentenceBERT (Reimers and Gurevych, 2019) model for retrieving relevant rule sentences based on the current input messages. We test six different game master settings, varying the use of functions and game state management:\n\u2022 FG-all: Using all states and functions.\n\u2022 FG-dice: Using all states and only dice roll function.\n\u2022 FG-states: Using all states and only state functions.\n\u2022 FG-default: Using all states, but no functions. All states stay the same after initialization.\n\u2022 FG-gen: Using all states and the states are updated by GPT-4, not by functions.\n\u2022 DG: Using no states and no functions. It sees the game states at the beginning, but they can be excluded due to the context size limit later."}, {"title": "5.2 Human Evaluation", "content": "We recruit seven evaluators to assess the generated responses. Each evaluator is assigned 12 game scripts (two scenes with six different settings) and asked to rate the responses on a Likert scale along three dimensions: consistency, which is how well the model remains grounded in previous turns the game states, reliability, which is how well the model follows the Labyrinth rules and role as GM, and interest, which is how interesting the model's generation is. Full details of the human evaluation can be found in Appendix F."}, {"title": "5.3 Unit Tests", "content": "In addition to the gameplay data, we design 30 unit tests to compare the state update correctness between the different game master settings. Each test case consists of input states, input dialogue, and expected output states. The objective is to predict the output states correctly given the input states and dialogue. The unit test cases are generated by augmenting the collected gameplay data, focusing on instances where state variables are changed after the game master generates a response. We use GPT-4 to paraphrase the dialogues while preserving the overall content and manually inspect the correctness of the state updates and the validity of the generated dialogues."}, {"title": "6 Experimental Results", "content": ""}, {"title": "6.1 Human Evaluation Results", "content": "Table 2 presents the human evaluation scores for each setting, averaged over three different samplings."}, {"title": "6.1.1 Consistency", "content": "For consistency, the FG-all setting, which uses both dice roll and state functions, outperforms the other settings. This demonstrates the effectiveness of integrating function calling in enhancing the consistency with the game progress. Appendix G shows the statistical significance of FG-all calculated against other settings. We found that the game easily fell into an undesired loop, where both players and game master infinitely wait for the dice roll without proceeding with anything. This \"dice roll deadlock\" hugely hurts the overall game experience and prevents the game master from following the game flow correctly. This is why FG-dice gets the second-best scores, showing the importance of the dice roll function to avoid this deadlock. Appendix H.1 presents two different gameplay logs with and without the dice roll function. FG-default and FG-states particularly fall behind in consistency. Especially, FG-states calls state functions too frequently, introducing new game states before resolving the previous challenges. This degrades the performance of the agent even worse. Appendix H.3.1. shows one of the examples. Interestingly, DG shows the decent scores in consistency. We believe that DG is good at making up the dice result without the function since it does not leverage any states, allowing the game master to focus on the game rules better. We infer that the reason why FG-gen is also good at avoiding the deadlock is thanks to updating action_scene=True variable. The action scene is activated when each player should take one dice roll action at a time to overcome an urgent circumstance. So it produces a signal like: \"This is an action scene and you need to determine the result of each action!\"."}, {"title": "6.1.2 Reliability", "content": "For reliability, the FG-all also got the best scores in almost every sampling. This shows that using both function types helps the game master control and manage the game robustly. DG hits the nearly highest scores in reliability. By qualitative analysis, we found that DG tends to state the game rules explicitly and correct the player's trial more often. Again, this is an advantage of using only game rules without the extensive game states or function descriptions. This renders the game master seem more strict, whether its intervention is valid or not. Appendix H.2 shows a few cases of how the game master corrected the user's requests. Unlike in consistency, FG-dice performs moderately in terms of reliability. While having the dice roll function mitigates the dice roll deadlock, that does not necessarily mean it is always beneficial. One of the feedbacks says that FG-dice often allows the player's unrealistic moves too easily without determining whether they are valid or reasonable. Appendix H3.2 includes a more detailed example. We conclude that the dice roll function and state functions intervene with each other, preventing excessive calls of certain functions and setting a proper balance during the game. According to the appendix G, FG-all shows a meaningful improvement compared to FG-states and FG-default. However, its performance is not statistically significant enough against FG-gen and DG. We believe the reliability metric has a lack of clarity and produces an unexpected bias even if the response is not good enough. This shows designing a more straightforward metric is essential for future works."}, {"title": "6.1.3 Interest", "content": "Overall, the settings with function calling (FG-all, FG-dice, FG-states) generate more specific and interesting responses. We see that functions are beneficial for improving the details and engagement of the output since the function message is integrated into the chat history and introduces additional context. Appendix G presents that FG-all shows a worthwhile improvement in interest compared to FG-default, FG-gen and DG. Interestingly, DG performs as great as FG-dice in interest among the settings that do not use function calling. While DG might introduce unrelated content during the game, this hallucination is actually considered interesting, regardless of its correctness."}, {"title": "6.2 Unit Tests Results", "content": "We conduct unit tests to evaluate the correctness of state updates for the FG-all, FG-states, and FG-gen settings. Table 3 presents the unit test results, showing the proportion of correctly predicted output states for each setting. The FG-states setting consistently outperforms FG-all and FG-gen in the unit tests. This is because state functions can update the game state before the game master's turn is completed, whereas dice roll functions may cause the game master to consider the current challenge resolved without calling additional state functions. However, it is important to note that the unit tests assume short-term interactions, and the superior performance of FG-states in this context does not necessarily translate to better performance in actual gameplay, where the lack of dice roll functions can lead to excessive function calls and disrupt the game flow. Appendix I presents an example of a dialogue in one test case, and how the existence of a dice roll function causes the difference between the results of FG-all and FG-states."}, {"title": "7 Conclusions", "content": "In this research, we have demonstrated the effectiveness of integrating function calling with large language models (LLMs) to enhance the capabilities of AI game masters in the context of \"Jim Henson's Labyrinth: The Adventure Game.\" Our experiments show that a combination of dice roll and state functions leads to the highest quality narratives and most engaging gameplay experiences, as evaluated by human raters. However, we also discovered that the optimal balance between these two types of functions is not always straightforward, with dice roll functions being crucial for smooth game flow and state functions being essential for maintaining consistency with the underlying game state. Our work contributes to the growing body of research on the application of LLMs and function calling to game AI and interactive storytelling. By demonstrating the benefits and trade-offs of different function configurations in the context of a specific TTRPG, we provide valuable insights and guidelines for designing more engaging and consistent AI-driven game masters."}, {"title": "8 Limitations and Future Work", "content": "While our approach has shown promising results in the context of \"Jim Henson's Labyrinth: The Adventure Game,\" there are several limitations to consider. First, the functions used in our study were specifically designed for this particular game, which may limit the generalizability of our findings to other TTRPGs or game genres. Future research could explore methods for automatically generating or adapting game-specific functions based on game manuals and rules, potentially enabling the application of our approach to a wider range of games. Another limitation is the subjectivity inherent in human evaluations of the AI game master's performance. While we aimed to mitigate this by providing clear evaluation criteria and using multiple raters, the complexity and length of the game transcripts may have introduced some variability and bias in the ratings. Future work could investigate the use of more objective evaluation metrics and the potential for AI-assisted evaluation tools to handle longer and more complex interaction sequences. Finally, while our work has implications for the broader field of game AI and interactive storytelling, these connections could be explored in more depth. Future research could investigate how the insights gained from our study of AI game masters in TTRPGs could be applied to other domains, such as video game NPCs, interactive fiction, or educational simulations. By continuing to bridge the gap between LLMs, function calling, and game AI, we can unlock new possibilities for creating engaging, adaptive, and immersive interactive experiences."}, {"title": "A Implementation details of Labyrinth", "content": ""}, {"title": "A.1 Overview", "content": ""}, {"title": "A.2 Scene initialization", "content": "We manually parsed all scene text from the game book into a large JSON file. The data file has a list of JSON objects and each object represents the specifications of one scene, including the description, locations, notes, random tables, etc. However, these raw scene data are not formalized and have a low readability. Since most of the components are pure natural language texts, it is hard to parse a certain keyword or object from the scene. Also, the raw scene lacks details and the game master should improvise most of them in real-time during the game. To increase the consistency, we need more specific and informative initialization of scene components before the game, so that the model can keep track of the game states more easily. In the scene initialization step, we convert a raw scene JSON object into a formalized scene state using GPT-4. Given a JSON input of the scene and the game rule summary, the model extracts, paraphrases, or creates the required scene state components. In more detail, the model generates the overall summary of the scene, the specifications of existing NPCs, the success condition of the scene, the failure condition of the scene, the intended game flow, and the environmental objects with their descriptions. All scene state components are organized in Appendix B. One of the most interesting components in Labyrinth is the random tables. The game master can use the randomly sampled entries from a table in various ways. For instance, the random samples can be new information or hints which might be useful for the players. Or they can be new challenges the players should overcome. The game master is also able to make random encounters such as new NPCs, objects or urgent circumstances. For scene initialization, we assume that a random table can be used for 1) nothing (only used during the game), 2) initializing NPCs, 3) initializing objects, or 4) initializing both NPCs and objects. We instructed GPT-4 to use the random tables for initializing a scene in the Chain-of-Thought approach, following these steps: First, GPT-4 determines which usage each random table falls into. If a table should be used for 2, 3, or 4, we ask GPT-4 how many samples should be retrieved from this table."}, {"title": "A.3 Player character generation", "content": "Unlike the scene initialization, the player character is made by each human player. We parsed the \"Creating character\" section from the book and organized the available options a player can choose. Each player chooses one kin and each kin has the persona, default traits, flaws, or items accordingly. Then the player can set the name and goal freely. Finally, the player chooses one trait and flaw from the given list to complete the character creation. The created player information is converted into a player state in JSON format. All player state components are elaborated in Appendix C."}, {"title": "A.4 Rule injection", "content": "There are two ways of injecting the rules into the prompt. First, full injection simply attaches the full rule summary. On the other hand, retrieval injection parses the top 5 relevant rule sentences given the current input messages and adds them to the prompt. In more detail, assume that there are R rule sentences and Q input messages. All of them are encoded into the vectors in size of E. With the rule matrix $G \\in \\mathbb{R}^{E \\times R}$ and query matrix $M \\in \\mathbb{R}^{E \\times Q}$, the cosine similarity matrix C is calculated as follows:\n$C \\in \\mathbb{R}^{R \\times Q}, C_{ij} = \\frac{g \\cdot m}{\\|g\\| \\|m\\|}, g = \\begin{bmatrix} G_{l_i} \\\\ G_{2_i} \\\\ : \\\\ G_{E_i} \\end{bmatrix}, m = \\begin{bmatrix} M_{l_j} \\\\ M_{2_j} \\\\ : \\\\ M_{E_j} \\end{bmatrix}$ (1)\nThen, we take the max-pooled vector $C' \\in \\mathbb{R}^{R \\times 1}$ to get the maximum score of each rule sentence. Finally, we pick the top 5 sentences with the highest scores and put them into the prompt."}, {"title": "A.5 Prompt designs", "content": "In this work, the user is able to set various combinations of prompt design approaches. By default, Kani provides a prompt construction algorithm to set the given messages to fit into the limited context window size. It excludes the least recent messages first until the total number of tokens in the messages is less than or equal to the context size, including the system instruction, function descriptions, and any other messages that are set to be always included. Besides that, we implemented the following variants in prompt design methodologies:\n\u2022 Concatenation\nSimple concatenation is just concatenating the messages in order, which is mostly used in a wide range of interactive AI systems. Retrieval concatenation, on the other hand, fetches the most relevant chat messages from the history given the current queries to process. This is actually the same mechanism as the retrieval rule injection, but the only difference is that the system attends to the utterances in the past chat history, not the rule sentences.\n\u2022 Maximum number of messages\nThe user can specify the maximum number of messages in the prompt. If it is not set, the system takes as many messages as possible within the context size. If a certain number is set, the system only takes a limited number of messages as specified.\n\u2022 Summarization\nSummarization can be used in various ways. By default, summarization requires the summarization period, which indicates how frequently the chat history should be summarized. For example, if the period is 2, when every 2 interactions between the player party and the game master are finished, the game master summarizes the history so far and adds the result to the chat history. This summary can be used when the system concatenates the messages either with simple concatenation or retrieval concatenation. If the summarization period doesn't exist, the system summarizes the whole chat history every time it creates an input prompt. In this case, none of the other variants for prompt design matter.\n\u2022 Raw chat message handling\nWhen the system leverages summarization, it can also either remove the original chat messages or keep them. In other words, the summary replaces the original chat messages that are used for summarization. In this way, the number of chat messages remaining in the history can be efficiently maintained."}, {"title": "B Scene state details", "content": ""}, {"title": "C Player state details", "content": ""}, {"title": "D List of all functions", "content": ""}, {"title": "E Function definition examples", "content": ""}, {"title": "E.1 activate_test (Dice roll)", "content": ""}, {"title": "E.2 create_npc (State)", "content": ""}, {"title": "F Survey questions", "content": ""}, {"title": "F.1 Consistency", "content": "How consistent is the target response to the current game progress, including the chat history and the game states?\n1. The target response is consistent with the chat history between the players and the master so far.\n\u2022 The model remembers the past interactions.\n\u2022 The response is relevant to the player party's queries or requests.\n2. The target response is consistent with the updates in the scene and players so far.\n\u2022 The model acknowledges the existing components in the current scene, such as NPCs, objects, and random table entries.\n\u2022 The model acknowledges the existing properties of the players, such as traits, flaws, and inventories.\n*If the model output assumes or fakes up any non-existing components, ignore it for this question. This will be penalized in the reliability check question.\n(1=The model does not follow the progress at all, 3=The model makes a narration that is plausible but misses some components in the scene or players, 5=The model's response correctly follows the chat history while acknowledging the existing components in the states well too)"}, {"title": "F.2 Reliability", "content": "How well does the model control and manage the game reliably?\n1. The game master fully understands the game and performs its task as a master correctly.\n\u2022 The model keeps the general game rules in Labyrinth.\n\u2022 The model understands the scene-specific rules, instructions, and specifications of the current scene and guides the players to proceed with the game as intended.\n2. When a player tries to do something invalid, the game master rejects it robustly.\n\u2022 The model rejects it when the player attempts to do something which cannot be performed by a player character or which is not the player's task.\n\u2022 The model rejects it when the player tries to use a trait, flaw, or item which does not exist in the player.\n\u2022 The model rejects it when the player tries to leverage or get access to non-existing objects, NPCs, or random tables.\n3. Any unexpected behavior which might hurt the players' gameplay experience or make the game flow far from intended should be penalized.\n*Note that this metric does not evaluate the quality of the response. Even if the response looks perfect, it can contain an invalid content or the model might just let the player do an unallowed trial.\n(1=The model blatantly ignores the rules or is completely generous with the players' invalid moves, which makes the game go into a bad state, 3=The model gets some rules incorrect or accepts the players' some violations, but the game generally progresses as it should, 5=The model keeps the rules correctly and corrects the players' invalid or unacceptable behaviors)"}, {"title": "F.3 Interest", "content": "How interesting is the generated response?\n1. The response describes the scene funny, entertaining and specific.\n2. The response makes the user engaged and immersed in the game.\n(1=The response is too bland, simple, or half-hearted, 3=The response is not highly entertaining, but at least it is not boring, 5=The response is so engaging and immersive that I wouldn't want to stop the game if I were a player)"}, {"title": "G Statistical significance", "content": ""}, {"title": "H Examples of the model's responses", "content": ""}, {"title": "H.1 Dice roll behaviors", "content": ""}, {"title": "H.1.1 With a dice roll function", "content": ""}, {"title": "H.1.2 Without a dice roll function", "content": ""}, {"title": "H.2 Controlling the behavior from the player", "content": ""}, {"title": "H.3 Limitation of using one function type", "content": ""}, {"title": "H.3.1 Excessive calls of functions only with state functions", "content": ""}, {"title": "H.3.2 Accepting the requests too generously only with a dice roll function", "content": ""}, {"title": "I Unit test example", "content": ""}]}