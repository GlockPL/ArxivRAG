{"title": "A comprehensive survey of contemporary Arabic sentiment analysis: Methods, Challenges, and Future Directions", "authors": ["Zhiqiang Shi", "Ruchit Agrawal"], "abstract": "Sentiment Analysis, a popular subtask of Natural Language Processing, employs computational methods to extract sentiment, opinions, and other subjective aspects from linguistic data. Given its crucial role in understanding human sentiment, research in sentiment analysis has witnessed significant growth in the recent years. However, the majority of approaches are aimed at the English language, and research towards Arabic sentiment analysis remains relatively unexplored. This paper presents a comprehensive and contemporary survey of Arabic Sentiment Analysis, identifies the challenges and limitations of existing literature in this field and presents avenues for future research. We present a systematic review of Arabic sentiment analysis methods, focusing specifically on research utilizing deep learning. We then situate Arabic Sentiment Analysis within the broader context, highlighting research gaps in Arabic sentiment analysis as compared to general sentiment analysis. Finally, we outline the main challenges in developing robust sentiment analysis models for the Arabic language, and present promising directions to guide future research in this field.", "sections": [{"title": "1 Introduction", "content": "Sentiment Analysis (SA), also referred to as opinion mining, leverages computational models to extract individuals' sentiments and opinions from data (Liu, 2015). This field has garnered significant attention from both academic and industrial sectors, as evidenced by the multitude of studies conducted to comprehend human sentiment (Liu, 2015), (Zeng and Li, 2022), (Varathan et al., 2017). However, although Arabic is a widely popular language spoken by over 372 million people across the globe, the volume of research dedicated to Arabic Sentiment Analysis (ASA) remains considerably lower compared to high-resourced languages such as English and French. This study presents a systematic review of existing literature on Arabic sentiment analysis, with a particular focus on approaches that employ deep learning methodologies.\nSeveral prior surveys on Arabic sentiment analysis (ASA) exist (Almurqren et al., 2024), (Al-Ayyoub et al., 2019), (Al-Twairesh et al., 2014), (Biltawi et al., 2016), (Abdelhameed and Mu\u00f1oz-Hern'andez, 2017), (Abo et al., 2019), (Rahma et al., 2023). However, the majority of these do not cover contemporary deep learning based methods. Additionally, these do not present a detailed analysis of the gaps, challenges and future directions for ASA. This paper fills this gap and presents a comprehensive survey of contemporary methods for Arabic sentiment analysis, systematically organizing recent literature in the field and highlighting the key contributions and limitations of current SA methods. We also situate these approaches within the broader framework of general sentiment analysis and approaches for high-resource languages, facilitating an understanding of the developments as well as the gaps in ASA. The major contributions of this study are summarised below:\n\u2022 We present a systematic survey of contemporary research conducted in Arabic sentiment analysis, with a focus on deep learning methodologies. We present an analysis of the key contributions and limitations of state-of-the-art ASA methods across various dimensions such as modality (unimodal, multi-modal), granularity (coarse-grained, fine-grained) and context (sentence-level, document-level, aspect-level).\n\u2022 We situate Arabic sentiment analysis within the broader framework of general sentiment analysis, identifying research gaps in Arabic sentiment analysis, and highlighting areas where advancements are needed to bridge the gap with high-resource languages.\n\u2022 We outline the key challenges in developing robust sentiment analysis models for the Arabic language, and present promising directions to guide future research in this field."}, {"title": "2 The Evolution of Arabic Sentiment Analysis", "content": "In this section, we describe the evolution of Arabic sentiment analysis, from lexicon based methods to deep learning based methods. To highlight the importance of these traditional methods, we conduct a case study using Arabic lexicons, in which we highlight how lexicons can be utilised to improve deep learning based methods."}, {"title": "2.1 Lexicon Based Methods", "content": "Lexicon based methods utilise a pre-defined lexicon to determine the sentiment of the given text. The words in the lexicon are annotated with polarity or sentiment scores. The overall sentiment of the text are calculated by summing up all the words' sentiment score. Given their crucial role in lexicon based methods, we briefly mention some widely used Arabic lexicons.\nArabic Senti-Lexicon (Abdullah;, 2018): Arabic Senti-Lexcion contains 3880 synsets that are annotated with part of speech, polarity scores and inflected forms.\nArsenL (Arabic Sentiment Lexicon) (Badaro et al., 2014): ArsenL are constructed from multiple resources, including English WordNet (EWN), Arabic WordNet (AWN), English SentiWordNet (ESWN), and SAMA (Standard Arabic Morphological Analyzer). It contains 157969 synsets and has positve, negative and neutral sentiment scores."}, {"title": "2.2 Machine learning based methods", "content": "Lexicon based methods are simple and fast, but they heavily rely on the lexicons and the sentiment scores of the lexicons lack context. Machine learning based methods can help to overcome these limitations by learning the sentiment features from data rather than pre-defining them by humans. However, for traditional machine learning methods, feature engineering is required as a precursor to the ML algorithms.\nSome widely used feature engineering methods include bag-of-words (Qader et al., 2019), TF-IDF (Sammut and Webb, 2010) and word embedding (Almeida and Xex\u00e9o, 2019). After the features have been extracted, machine learning methods such as naive Bayes (Al-Horaibi and Khan, 2016), support vector machines (Duwairi et al., 2016) and random forests based methods (Altawaier and Tiun, 2016) can be used for sentiment analysis. In the following sections, we will systematically review deep learning based approaches."}, {"title": "2.3 The importance of traditional methods: a case study on sentiment lexicons", "content": "It is important to note that even with the rise of deep learning based methods for sentiment analysis, sentiment lexicons like ArSenL(Badaro et al., 2014) can still be valuable as they provide a foundational understanding of sentiment that can enhance model performance, especially in low-resource scenarios or when dealing with domain-specific language that may not be well-represented in training data. Some use cases of these lexicons include data preprocessing where the irrelevant terms are filtered out based on the sentiment lexicon, sentiment weighting (Zhang et al., 2011) where the lexicon is employed to help the model weight sentiment-relevant features more effectively. In the following paragraphs, we will use some examples to illustrate how sentiment lexicons can be utilised to improve the sentiment analysis performance.\nFeature Augmentation: Lexicons can be utilised to augment the features. In (Heikal et al., 2018), a sentiment lexicon is integrated to augment the features for deep learning based modes. (Xiang et al., 2021) explores part-of-speech-focused lexical substitution for data augmentation to enhance sentiment analysis performance. (Li and Zou, 2024) discusses how lexicon-based approaches assign sentiment polarities and scores to keywords, which can be used for feature augmentation in hybrid models.\nInterpretability: Arabic sentiment lexicons enhance interpretability in sentiment analysis by providing a clear framework for understanding how specific words and phrases contribute to sentiment assessments. By combining lexicons with advanced methods like attention-based LSTM and explainable AI techniques, such as LIME (Ribeiro et al., 2016), researchers can further clarify which features are most significant in determining sentiment, thereby enhancing the transparency of their findings (Abdelwahab et al., 2022). These lexicons facilitate the identification of the sentiment polarity of individual terms, making it easier to trace the reasoning behind a sentiment classification (van der Veen and Bleich, 2025). Moreover, the integration of lexicon-based approaches with machine learning techniques can improve the interpretability of complex models, as researchers can analyze how lexicon entries influence the overall sentiment predictions (Ambreen et al., 2024)."}, {"title": "3 Situating ASA methods vis-\u00e0-vis general SA approaches", "content": "We situate the research in Arabic Sentiment Analysis (ASA) and juxtapose it with general trends in sentiment analysis (SA) in this section. We present an overview of several sentiment analysis tasks, and for each task we highlight the advancements in general sentiment analysis research, followed by a focus on Arabic-specific sentiment analysis. While not exhaustive, the selected approaches illustrate key differences and current trends between general and Arabic sentiment analysis. Table 1 provides an overview of datasets for ASA organised according to the modality, granularity and context involved. We refer to these datasets in the subsequent subsections."}, {"title": "3.1 Sentiment Classification", "content": "Sentiment classification involves assigning a sentiment label (positive, neutral, negative) or a sentiment rating (e.g., one to five) to a given input, which can be text or data from other modalities. As one of the earliest sentiment analysis tasks (Liu, 2015), sentiment classification has attracted significant research interest."}, {"title": "3.1.1 General Sentiment Classification", "content": "The development of general sentiment classification reflects the ongoing paradigm shifts within the field of natural language processing (Liu et al., 2021). Early works in sentiment classification primarily relied on task-specific models, employing either traditional machine learning methods like Support Vector Machines (SVMs) or deep learning-based approaches. These models were trained on labeled data and limited to solving specific tasks.\nHowever, the emergence of pre-trained language models such as BERT (Devlin et al., 2019) has revolutionized the field. These models, typically based on components of the Transformer architecture, are pre-trained on massive amounts of unlabeled data and subsequently fine-tuned for specific tasks, including sentiment classification. Large language models like GPT-3 (Brown et al., 2020) further push the boundaries of model size, demonstrating the ability to acquire various emergent capabilities such as in-context learning when scaled sufficiently large (Wei et al., 2022). A systematic analysis of large language models' effectiveness in tackling various sentiment analysis tasks, including sentiment classification, is provided by (Zhang et al., 2023)."}, {"title": "3.1.2 Arabic Sentiment Classification", "content": "The development of Arabic sentiment classification follows a similar trajectory to that of general sentiment classification. Early research predominantly focused on task-specific models trained on sentiment classification datasets for Arabic text. (Dahou et al., 2016) constructed Arabic word embeddings and subsequently employed a Convolutional Neural Network (CNN) as a classifier. (Attia et al., 2018) proposed a language-independent framework for text classification, evaluating its performance on Arabic sentiment classification tasks as well. Table 2 provides detailed descriptions of various task-specific methods for Arabic sentiment classification, along with their contributions and limitations. As highlighted in the table, the biggest limitation of such methods is that they are task-specific and do not generalise well to other tasks or dialects.\nWith the remarkable success of pre-trained language models based on bidirectional transformers, such as BERT (Devlin et al., 2019), on diverse natural language understanding tasks, numerous studies have explored their utilization for Arabic sentiment classification. (ElJundi et al., 2019) developed hULMonA, a pre-trained language model specifically for Arabic, and fine-tuned it for Arabic sentiment analysis. AraBERT (Antoun et al., 2020) builds upon this work by pre-training the model entirely on an Arabic corpus and evaluating its performance on various tasks. (Abdul-Mageed et al., 2021) introduced ARBERT and MARBERT, language models pre-trained on dialectal Arabic. Table 3 offers detailed descriptions of different pre-trained language model-based methods for Arabic sentiment classification."}, {"title": "3.2 Multifaceted Analysis of Subjective Text (MAST)", "content": "Multifaceted analysis of subjective text (MAST) represents an extension of sentiment classification that delves deeper into task granularity. It shifts the focus towards more specialized tasks, such as irony detection (Zeng and Li, 2022) and comparative opinion mining (Varathan et al., 2017)."}, {"title": "3.2.1 General MAST", "content": "The development trajectory of general MAST mirrors that of general sentiment classification, as discussed in Section 3.1.1. Due to the focus on specialized tasks within MAST, it encompasses a multitude of sub-tasks. While these sub-tasks have been extensively explored in the field, a detailed de-"}, {"title": "3.2.2 Arabic MAST", "content": "Compared to general MAST, research on Arabic MAST remains less developed. This section will solely introduce research on Arabic sarcasm detection, as it has garnered a relatively larger body of work following the release of the ArSarcasm (Abu Farha and Magdy, 2020) and ArSarcasm-v2 (Abu Farha et al., 2021) datasets, alongside a shared task organized by WANLP (Abu Farha et al., 2021).\nWhile various methods have been employed, including traditional machine learning approaches, task-specific deep learning methods, and pre-trained language model-based methods, the latter category combined with various optimizations has emerged as the most effective approach. (Hengle et al., 2021) propose a hybrid model that leverages contextual representations from AraBERT (Antoun et al., 2020) alongside static word vectors.\nAdditionally, recent research explores various machine learning techniques such as down-sampling and augmentation (Israeli et al., 2021) for this task. (Faraj et al., 2021) employ an ensemble approach, combining different pre-trained language models with a hard voting technique. (Talafha et al., 2021) propose framing the problem as a regression task, predicting the level of sarcasm. Table 4 provides detailed descriptions of methods for Arabic sarcasm detection, along with their contributions and limitations."}, {"title": "3.3 Aspect-Based Sentiment Analysis (ABSA)", "content": "Aspect-based sentiment analysis (ABSA) extends sentiment analysis by introducing a finer-grained level of task granularity. Unlike sentiment classification, where the output is typically a binary or multi-class label, ABSA delves deeper, focusing on aspects within the sentiment analysis process."}, {"title": "3.3.1 General ABSA", "content": "Similar to MAST, general ABSA encompasses various sub-tasks, ranging from simpler single ABSA tasks like aspect term extraction to more complex compound ABSA tasks such as aspect sentiment triplet extraction (Zhang et al., 2022). (Zhang et al., 2022) provide a comprehensive survey on general ABSA, we recommend referring to their work for further details on general trends in this direction."}, {"title": "3.3.2 Arabic ABSA", "content": "Research on Arabic ABSA lags behind that of general ABSA. The majority of existing works in Arabic ABSA primarily address aspect sentiment classification, which essentially translates to sentiment classification applied at the aspect level. Additionally, many studies rely solely on feature-based approaches and traditional machine learning methods. This section will focus exclusively on deep learning-based methods for Arabic ABSA.\nThe development of Arabic ABSA parallels that of Arabic sentiment classification, as discussed in Section 3.1.2. A growing number of studies are employing deep learning and pre-trained language model-based methods. (Al-Smadi et al., 2017) and (Alshammari and Almansour, 2020) compare traditional machine learning and deep learning methods for Arabic ABSA. (Al-Dabet et al., 2021) propose different network architectures tailored to specific Arabic ABSA tasks. (Abdelgwad et al., 2021) develops a BERT-based model for Arabic ABSA. Table 5 provides detailed descriptions of methods for Arabic ABSA."}, {"title": "3.4 Comparison within Arabic Sentiment Analysis Methods", "content": "Although task-specific methods are dedicated to ASA tasks, the most effective methods are those that combine pre-trained language models and various optimisation techniques. hULMonA (ElJundi et al., 2019) first demonstrate the effectiveness of pre-trained language models by developing a pre-trained LM for Arabic and fine-tuning it for ASA, which significantly improves the performance. Latter pre-trained Arabic LMs such as AraBERT (Antoun et al., 2020) and ARBERT (Abdul-Mageed et al., 2021) further push the boundary of ASA by using Arabic specific tokenisation and pre-training models on dialectal Arabic.\nAnother research direction extends the existing methods using various approaches such as domain adaptation (El Mekki et al., 2021) and data augmentation (Refai et al., 2022). However, the models based on pre-trained LMs are not computationally efficient, and involve a significant computational overhead, whereas approaches such as (Alyafeai and Ahmad, 2021) maintain the balance between performance and efficiency by distillation and quantisation."}, {"title": "3.5 Gaps and challenges in Arabic Sentiment Analysis", "content": "This section outlines key research gaps between Arabic sentiment analysis and general sentiment analysis across three dimensions:"}, {"title": "3.5.1 Gaps", "content": "This section outlines key research gaps between Arabic sentiment analysis and general sentiment analysis across three dimensions:\n\u2022 Modality: Multimodality has recently garnered significant interest within general sentiment analysis, with a surge in research activity (Lai et al., 2023). However, investigations into multi-modal Arabic sentiment analysis remain limited. Most datasets for Arabic sentiment analysis are restricted to the text modality.\n\u2022 Granularity: The majority of research in Arabic sentiment analysis focuses solely on Arabic sentiment classification. As evidenced in the previous sections, even studies exploring Arabic MAST and Arabic ABSA often target simpler tasks. Consequently, Arabic sentiment analysis lags behind general sentiment analysis in terms of MAST and ABSA tasks.\n\u2022 Context: While datasets for general sentiment analysis encompass various levels ranging from document level to aspect level, most datasets for Arabic sentiment analysis remain at the document level. Even some recently released datasets lack annotations at sentence level and aspect level."}, {"title": "3.5.2 Challenges", "content": "The Arabic language is characterized by its high morphological complexity, which entails intricate word formation processes that may obscure meaning (Habash, 2010). Additionally, the high degree of ambiguity and polysemy inherent in Arabic lexicon complicates semantic interpretation. The presence of negation and the extensive range of dialects further exacerbate these challenges, as they introduce variations that must be meticulously accounted for in linguistic models (El-Beltagy and Ali, 2013).\nData scarcity and cultural contextualization present additional challenges for Arabic. There is a scarcity of large, labeled datasets for many dialects, making it difficult to train robust models. Moreover, sentiment expression can vary significantly based on cultural nuances, requiring models to understand context beyond mere text."}, {"title": "4 Recent trends in Arabic Sentiment Analysis", "content": "Several research efforts are ongoing to develop robust Arabic-specific methods and overcome the challenges presented in Section 3.5. We organise and present these efforts below."}, {"title": "4.1 Addressing Dialectal Variations", "content": "The issue of dialectal variation has received significant attention in both task-specific and pre-trained language model-based approaches. (Baly et al., 2017) conducted a characterization study analyzing tweets from different Arab regions, highlighting the importance of addressing the dialectal problems in Arabic SA. The efforts that tackle this challenge are presented below, grouped into the broad approach employed:"}, {"title": "4.1.1 Dataset Creation, Domain Adaptation and Data Augmentation", "content": "(Medhaffar et al., 2017) addressed this challenge by annotating a corpus specifically for the Tunisian dialect and evaluating their models on data from various dialects. A similar approach to this method was the one proposed by (Guellil et al., 2018). They presented a method for automatically constructing an Algerian dialect corpus. (El Mekki et al., 2021) introduced an unsupervised domain adaptation method for cross-domain and cross-dialect sentiment analysis in Arabic. (Refai et al., 2022) proposed a data augmentation method specifically designed for Arabic classification tasks using transformer-based models."}, {"title": "4.1.2 Increasing use of Deep learning", "content": "Researchers are increasingly using deep learning models, particularly transformer based models, to effectively capture the nuances of different Arabic dialects. For example, ARBERT and MARBERT (Abdul-Mageed et al., 2021) were specifically pre-trained on dialectal Arabic to address these dialectal variations."}, {"title": "4.1.3 Transfer Learning and Multilingual Models", "content": "Transfer learning approaches are being used to leverage knowledge from models trained on larger datasets in other languages or MSA, facilitating better performance on dialect data with limited resources. Multilingual transformer models like mBERT are also applied for handling multiple Arabic dialects (Devlin et al., 2019)."}, {"title": "4.2 Arabic-specific Tokenization", "content": "Recent research has also explored the importance of developing tokenization methods specifically for the Arabic language. (Alyafeai et al., 2021) compared the performance of different tokenizers for various Arabic classification tasks. (Alkaoud and Syed, 2020) proposed tokenization strategies specifically tailored for both static and contextual Arabic word embeddings, demonstrating significant performance improvements.The efforts in this direction can be grouped into the following trends:\nMorphological Analysis Implementation of advanced morphological analysis tools to accurately identify roots, prefixes, and suffixes, ensuring proper tokenization of complex words. Noteworthy contributions in this area include the MADAMIRA tool, which provides robust morphological analysis and disambiguation for modern written Arabic, showcasing significant improvement in processing complex Arabic morphological structures (Pasha et al., 2014).\nDialect-Specific Tokenizers: Development of tokenization models tailored to specific Arabic dialects to handle regional vocabulary and expressions effectively. The CALIMA-Star project exemplifies efforts to create comprehensive morphological lexicons specific to different Arabic dialects, allowing more precise tokenization and analysis for dialectal data (Taji et al., 2018).\nContextual Tokenization: Use of context-aware tokenization methods to understand the meaning of words in context, assisting in disambiguating similar words. Contextual models like AraBERT and its advancements in tokenization strategies demonstrate the power of context-aware embeddings to capture nuanced language variations in sentiment analysis (Antoun et al., 2020).\nIncorporating Diacritics: Desining tokenizers that handle diacritics appropriately, either by retaining them for analysis or by normalizing words without diacritics while preserving meaning. Research by (Alqahtani et al., 2020) highlights the role of diacritics in enhancing sentiment analysis, emphasizing the necessity for tokenizers that efficiently process diacritized text data without losing critical semantic information.\nWhile these trends have demonstrated improved performance for ASA, significant research efforts need to be directed in order to bridge the gap between ASA and general SA for high-resource languages."}, {"title": "5 Future Directions", "content": "To conclude, we present promising research directions to foster the development of robust models for Arabic sentiment analysis.\nCreation of richer datasets: Future efforts should prioritize the development of datasets that encompass richer annotations across the following dimensions:\n\u2022 Multimodality: Datasets that integrate various modalities (text, audio, video) to capture richer sentiment information.\n\u2022 Fine-grained tasks: Datasets designed for exploring more intricate sentiment analysis tasks beyond sentiment classification.\n\u2022 Multi-context annotations: Datasets with annotations at finer levels (sentence level, aspect level) to facilitate in-depth analysis.\nMultimodal Sentiment Analysis: While limited research has been conducted in multimodal ASA, leveraging information from multiple modalities holds significant potential for accurate sentiment analysis. Future research should explore effective techniques for incorporating multimodal data and develop robust models for this task.\nLarge Language Models (LLMs) for ASA: Recent advancements in LLMs have yielded remarkable performance on various tasks. Arabic LLMs like AceGPT-LL (Huang et al., 2023) have also emerged. However, a systematic analysis of LLMs for sentiment analysis, particularly in the context of Arabic, is lacking. Future research should investigate how to best utilize LLMs for Arabic sentiment analysis.\nInterpretable Sentiment Analysis: Existing Arabic sentiment analysis methods primarily provide final sentiment labels without explanations for their outputs. Recent work on improving the interpretability of question answering by examining model reasoning (Huang and Chang, 2023) suggests a promising approach that can be adapted to sentiment analysis. For example, models could be designed to output reasoning steps leading to their final sentiment polarity predictions.\nExploration of Fine-Grained Tasks: General sentiment analysis research has shifted towards increasingly fine-grained tasks. However, most Arabic sentiment analysis studies remain focused on sentiment classification at the document level. A systematic exploration of other fine-grained tasks, particularly those within MAST and ABSA, would be beneficial for advancing the field."}, {"title": "6 Limitations", "content": "This survey acknowledges some limitations. Firstly, it primarily focuses on works utilizing deep learning methods. As highlighted in (Abu Kwaik et al., 2022), feature-based methods can outperform pre-trained language model-based methods in some instances. Future surveys may benefit from including an exploration of feature-based approaches. Additionally, while this work compares Arabic sentiment analysis with general sentiment analysis, it would also be valuable to situate Arabic sentiment analysis within the broader context of Arabic classification tasks and Arabic natural language processing tasks in general."}]}