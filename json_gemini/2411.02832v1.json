{"title": "PersianRAG: A Retrieval-Augmented Generation System for Persian Language", "authors": ["Hossein Hosseini", "Mohammad Sobhan Zare", "Zahra Zojaji", "Amir Hossein Mohammadi", "Arefeh Kazemi", "Mohammad Ali Nematbakhsh"], "abstract": "Abstract- Retrieval augmented generation (RAG) models, which integrate large-scale pre-trained generative models with external retrieval mechanisms, have shown significant success in various natural language processing (NLP) tasks. However, applying RAG models in Persian language as a low-resource language, poses distinct challenges. These challenges primarily involve the preprocessing, embedding, retrieval, prompt construction, language modeling, and response evaluation of the system. In this paper, we address the challenges towards implementing a real-world RAG system for Persian language called PersianRAG. We propose novel solutions to overcome these obstacles and evaluate our approach using several Persian benchmark datasets. Our experimental results demonstrate the capability of the PersianRAG framework to enhance question answering task in Persian.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, the field of NLP has witnessed significant advancements, especially in the development of LLMs capable of generating coherent and contextually relevant text. Despite their impressive capabilities, generative language models often tend to provide outdated information or fabricate facts a phenomenon commonly referred to as \"Hallucination\". This limitation persists even when models are aligned with human preferences through reinforcement learning [1] or style alignment techniques [1-4]. RAG systems have emerged as a promising solution to these challenges. By integrating the strengths of pre-trained models and retrieval mechanisms, RAG provides a powerful framework that enhances model performance and reduces errors in generated content [5]. Additionally, RAG enables the rapid deployment of applications tailored to specific organizations and domains without needing to update the underlying model's parameters, provided that relevant documents are available for retrieval. Several methods have been proposed to enhance LLMs through query-dependent retrieval [5-7]. A typical RAG process includes critical components such as embedding (semantic representation of documents and queries), retrieval (efficient access to relevant documents), and generation (producing responses based on retrieved information)."}, {"title": "II. RETRIEVAL AUGMENTED GENERATION", "content": "RAG helps produce more accurate and comprehensive responses by combining two approaches retrieval and generation. Unlike purely generative models that respond solely based on their training data, RAG can refer to external knowledge bases and retrieve real-time, accurate information to enhance its responses.\nInformation retrieval is a process that extracts relevant external knowledge related to the user's query, rather than focusing on information that the language model can easily understand. It aims to find the most relevant pieces of knowledge to support the model's response generation.\nThe RAG approach, which combines retrieved information with the language model's ability to understand and generate human-like text, leads to more accurate and relevant results. This method is particularly useful in domains requiring deep and up-to-date knowledge, such as medicine, law, and science, where it can improve response quality and reduce errors in language models.\nThis reception from RAG systems was primarily due to two factors: first, the impressive capabilities offered by LLMs, and second, because it combines the strengths of retrieval-based and generation-based models to improve text generation tasks. Essentially, the advantage of using RAG lies in leveraging the power of LLMs to generate responses based on documents that these LLMs may not have previously seen or been trained on. In specific domains, this means obtaining high-quality and precise answers to questions for which an LLM might not have an inherent response."}, {"title": "III. PERSIANRAG ARCHITECTURE", "content": "Despite major advancements in the capabilities of language models, RAG remains a highly relevant and efficient option for generating accurate and enriched responses by incorporating information from external sources. Despite the proven effectiveness of RAG in question-answering systems, multilingual RAG and specifically RAG in Persian, a language with unique characteristics and resource limitations, has received less emphasis in research, despite its importance and widespread application. Nevertheless, recent studies have begun to address this gap. Therefore, the current study presents the first successful implementation of Persian RAG system called PersianRAG. The architecture of the PersianRAG system is depicted in Fig. 1.\nThe components of this architecture are described as follows.\nThe knowledge base serves as a repository of structured information, consisting of processed data that has been organized into meaningful content. This content may include a collection of various texts, scientific articles, wikis, organizational documents, and other curated information sources. The knowledge base is continuously updated and serves as the primary input for information retrieval in the RAG system.\nThe text extractor is responsible for processing and extracting raw textual content from the knowledge base. These contents may include structured or unstructured documents that need to be transformed into suitable formats for preprocessing.\nAfter extracting information from the knowledge base, this component cleans and optimizes the texts. Preprocessing includes activities such as removing noise, additional markings, and certain specific characters in various languages. For Persian, for example, this might involve removing half-spaces. This stage is crucial, as the quality of input data has a direct impact on final results.\nThe embedder plays a key role in converting texts into vector representations. This process involves using deep learning models to compress textual information into numerical vectors. These vectors, although more compact and with fewer dimensions, preserve the semantic information of the texts and convert them into an efficient vector representation for further processing."}, {"title": "V. CHALLENGES", "content": "Reading Persian PDFs presents a major challenge for RAG systems. This challenge arises particularly due to the presence of half-space characters and the Persian '', as well as specific encodings used in certain organizations. As a result, when extracting text from Persian PDFs, the text might become completely scrambled, or characters might incorrectly stick together or be separated. For example, the character \"\u0647\" might be written separately, or \"\u06cc\" may display incorrectly. These problems significantly hinder the comprehension of text by large language models, and the more non-standard or problematic data there is, the lower the accuracy of the entire pipeline.\nAdditionally, some organizations or companies maintain their PDFs as scanned copies with no access to the original Text version. For these types of files, advanced image-to-text conversion models and various (Optical Character Recognition) OCR tools were tested.\nInitial experiments indicated that the best method for extracting text from these files is through OCR. In this regard, open-source multilingual OCR tools with Persian recognition capabilities that operate offline were evaluated. The tools tested included Tesseract OCR, ABBYY FineReader, py2pdf, and Easy OCR. The results showed that the best tool for offline OCR is Google's Tesseract OCR. Although Tesseract performs better in recognizing Persian text compared to similar tools, it still faces challenges, particularly in correctly reading numbers in the text.\nFinding the best embedding model or approach for the target language in RAG systems is of great importance. These models convert text into numerical vectors, which are semantic representations of the text used for information search and retrieval. The quality and accuracy of information retrieval heavily depend on the performance of the embedding model.\nTo address this challenge, the following methods can be utilized:"}, {"title": "Separation of Prompt Components", "content": "The investigation focused on using specific markers to clearly separate different components of the prompt, such as the instructions, retrieved results, and user query. Generally, common separators that language models have been trained on were used, following templates like:\nCan be significantly helpful and assist the language model in better understanding. Additionally, utilizing Markdown symbols to separate different parts of the text, rows and columns in tables, and optimizing table styles, according to our team's investigations, results in receiving more accurate and better responses from LLMs."}, {"title": "Adding Metadata", "content": "An effective strategy to improve the performance of RAG systems is to include brief contextual information before each retrieved result. This approach helps LLMs better comprehend the relationship between the retrieved results and the user's query, leading to more accurate responses. In real operational environments, which encompass a vast array of diverse documents such as sales reports and meeting minutes, adding metadata can significantly prevent semantic errors. For instance, in response to a query like \"Sales report of the section under discussion following the June meeting\", without metadata, the retrieval module might return all results related to June without considering the relevant year. This could result in the LLM generating irrelevant and misleading answers. To resolve this issue, appropriate metadata, such as precise temporal information (e.g., datetime), can be added to the user's query, substantially increasing the accuracy and correctness of the responses. This approach assists both the LLM and the retrieval module in understanding the user's exact intent when referencing a specific time frame. It is important to note that the type and number of required metadata should be adjusted according to the application domain and the general pattern of expected queries in the RAG system. In some cases, merely adding temporal information may not suffice, and it may be necessary to incorporate additional contextual information. To optimize this process, another LLM chain can be employed at the beginning of the pipeline to intelligently identify and add the necessary types and amounts of metadata. In conclusion, by implementing the aforementioned set of strategies and conducting continuous optimizations, we were able to significantly enhance the performance of the implemented RAG system in terms of information retrieval and generating relevant responses. These advancements are particularly important for low-resource languages like Persian, which face specific challenges in natural language processing."}]}