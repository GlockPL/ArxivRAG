{"title": "Rethinking Functional Brain Connectome Analysis: Do Graph Deep Learning Models Help?", "authors": ["Keqi Han", "Yao Su", "Lifang He", "Liang Zhan", "Sergey Plis", "Vince Calhoun", "Carl Yang"], "abstract": "Functional brain connectome is crucial for deciphering the neural mechanisms underlying cognitive functions and neurological disorders. Graph deep learning models have recently gained tremendous popularity in this field. However, their actual effectiveness in modeling the brain connectome remains unclear. In this study, we re-examine graph deep learning models based on four large-scale neuroimaging studies encompassing diverse cognitive and clinical outcomes. Surprisingly, we find that the message aggregation mechanism, a hallmark of graph deep learning models, does not help with predictive performance as typically assumed, but rather consistently degrades it. To address this issue, we propose a hybrid model combining a linear model with a graph attention network through dual pathways, achieving robust predictions and enhanced interpretability by revealing both localized and global neural connectivity patterns. Our findings urge caution in adopting complex deep learning models for functional brain connectome analysis, emphasizing the need for rigorous experimental designs to establish tangible performance gains and perhaps more importantly, to pursue improvements in model interpretability.", "sections": [{"title": "1 Introduction", "content": "Brain connectome analysis has captivated researchers for its potential to decode the intricate organizations of the human brain and predict clinical outcomes [1-4]. Functional magnetic resonance imaging (fMRI) plays a crucial role in this field by capturing brain activity through blood-oxygen-level-dependent (BOLD) signals. These signals facilitate the construction of functional brain networks, where nodes correspond to specific brain regions of interest (ROIs) and edges represent pair-wise statistical relationships, typically correlations, between the BOLD signals"}, {"title": "2 Results", "content": "Simple models can match or even exceed the predictive performance of more complex GDL models\nTo address the ambiguity regarding the effectiveness of complex GDL models, we conduct extensive experiments across four fMRI-based brain network datasets with various clinical pre- diction tasks, ranging from demographics to cognitive ability and neural disorders: ABIDE [31] for autism disease classification, PNC [32] for gender"}, {"title": "Message aggregation in GDL models has a detrimental effect on prediction performance within the context of functional brain connectome analysis", "content": "In GDL models, the message aggregation is crucial for combining node features from neighboring nodes to form new node representations. This process is widely adopted in many fields, such as social network analysis [36], chemistry for molecular graph predictions [37], and recommendation systems [38], due to its ability to capture complex relational information. However, as shown in Fig. 1, most aggregation-based GDL models tend to underperform classical ML models like Logistic Regression, SVM/SVR [39] and Kernel Ridge Regression, and simpler MLP-based models. This raises the question about the genuine effectiveness of the aggregation operations in brain connectome analysis.\nTo further investigate the impact of aggregation, we vary the graph density by retaining different percentages of the top K% edges in the graphs, so as to explicitly control the extent of aggregation. Notably, with K = 0, the graphs have no edges between ROIs, so node features are transformed independently, eliminating any aggregation effects. To align with existing stud- ies, the original settings of each GDL model are followed for extracting the top K% edges. Specifically, for models like GCN [40], GAT [35], GIN [41], GraphSage [42], NeuroGraph [26], and BrainGNN [3], only positive correlations between ROIs are considered as potential edges. This approach adheres to the common assumption that positive correlations are typically more informative in the context of functional brain networks [3, 26]. Conversely, for BrainGB [23] and Brain- NetTF [4], both positive and negative correlations are incorporated, following the methodologies described in the original papers."}, {"title": "The proposed dual-pathway model achieves robust prediction performance across various datasets", "content": "Previous experiments have shown that simple linear models like Logistic Regression and Elastic-Net, often outperform other baselines. However,"}, {"title": "Two pathways of the proposed model reveal different and complementary neural circuitry patterns", "content": "The proposed dual-pathway model integrates a non-aggregation linear model (LM) and a graph attention network (GAT) as the aggregation- based graph model. Each pathway uncovers unique neural circuitry patterns linked to neu- rological diseases and cognitive functions. The LM pathway offers interpretability through the weights assigned to the input features-vectorized upper triangular portion of the brain network matrix, while the GAT pathway provides inter- pretability via attention maps averaged across test samples.\nTo help understand the circuitry patterns cap- tured by two pathways, we map ROIs into six commonly recognized neural systems based on structural and functional roles [44]: the Somato- motor Network (SM), Default Mode Network (DMN), Ventral Salience Network (VS), Central Executive Network (CE), Dorsal Salience Network (DS), and Visual Network (Vis). For this analysis, we focus on the ABCD dataset due to its exten- sive coverage of cognitive and behavioral measures across a large population, making it particularly suitable for a detailed interpretability study.\nWe systematically examine the revealed neural circuitry from three aspects: Important Connections (Edge-level), Salient ROIs (Node-level), and Graph Properties of the Highlighted Brain Connectivity (Subgraph-level). Detailed discussions on these discoveries are deferred to Section 3."}, {"title": "3 Discussion", "content": "Performance of Compared Baselines\nDespite advancements in GDL and the growing interest in aggregation-based models for functional brain connectome analysis [3, 4, 23-28, 46], our findings suggest that sophisticated GDL models do not necessarily outperform simpler models, such as classical ML models and MLPs. This challenges the prevailing assumption that increased model complexity leads to better predictive performance.\nMany existing works implicitly assume that GDL's complexity guarantees superior results. In practice, these studies often omit direct comparisons with simpler models [4, 23, 25, 28], thereby leaving the true effectiveness of these complex models inadequately assessed. Even when simpler baselines are included, as in BrainGNN [3] and NeuroGraph [26], benchmarking is incomplete, and their experimental conclusions are inconsistent."}, {"title": "Ineffectiveness of Message Aggregation", "content": "Message aggregation techniques are widely adopted across domains to capture complex relational information [36-38], but in functional brain networks, our results show that these operations degrade rather than improve prediction accuracy. GDL-based brain connectome analysis models typically use the connection profile as the node features, which has become a standard practice [3, 4, 23-28, 30]. Specifically, the connection pro- file, representing a row of the functional brain connectome matrix, inherently captures the global relationships between a given node and all other nodes in the network. Since these node features already contain the full spectrum of inter-node connections, the aggregation employed in GDL models [29], which pools information from neigh- boring nodes, introduces redundancy and even destroy originally obvious features. This is related to over-smoothing, a phenomenon where repeated aggregation causes node features to become indis- tinguishable from one another [47], ultimately diluting the discriminative power of the original features. Moreover, connection profiles are derived from BOLD time series correlations, reflecting strong linear relationships between ROIs, which also leads to redundancy. Consequently, complex models are more prone to over-smoothing during aggregation, making it difficult to extract mean- ingful high-order features. In contrast, simpler models like logistic regression better utilize these linear relationships and avoid the potential noise from aggregation."}, {"title": "Performance of the Dual-pathway Model", "content": "The proposed hybrid model, which integrates both linear and graph-based components, achieves robust prediction performance across datasets. The LM pathway leverages the strong predic- tive power inherent in the original functional brain connectivity, preserving the direct input- output relationship and avoiding feature distor- tions. Meanwhile, the GAT pathway improves upon previous models by using BOLD time series embeddings as node features, instead of con- nection profiles. BOLD time series embeddings retain the raw temporal dynamics and variabil- ity of ROIs' signals, which captures richer tem- poral information and mitigates over-smoothing issues linked to the strong linear dependencies and redundancy in connection profiles."}, {"title": "Interpretability of the Dual-pathway Model", "content": "Important Connections (Edge-level): The dual-pathway model provides complementary insights into brain network organization, highlighting both localized and global patterns of connectivity for understanding the neural basis of brain function. The GAT pathway's focus on within-system connections, particularly within DMN, SM and CE, resonates with well- established findings in neuroscience about cognitive ability. The DMN is tied to internally directed cognitive processes such as self-referential thinking, memory retrieval, and future planning [51- 53]. Similarly, the SM network, crucial for motor control and sensory processing, has shown within- network coherence related to fine motor skills and their correlation with cognitive abilities [13, 54]. The CE network's within-system emphasis rein- forces its critical role in executive functions like working memory, decision-making, and cognitive control, which is correlated with fluid intelli- gence [55, 56]. This within-system focus reflects the specialized, localized processing within func- tional networks. Moreover, the observed bilateral symmetry suggests that the GAT pathway effec- tively captures the functional coherence between homologous regions across hemispheres, which is known to be important for cognitive stability and performance [14, 57]. On the other hand, the identification of cross-system connections between DMN-CE [9, 58], as well as between the Vis-SM"}, {"title": "4 Methods", "content": "Dataset acquisition and processing\n\u2022 Autism Brain Imaging Data Exchange (ABIDE) [31]: a publicly available dataset [31] consists of anonymized resting-state functional magnetic resonance imaging (rs-fMRI) data collected from 17 international sites, providing a diverse and comprehensive collection for studying Autism Spectrum Disorder (ASD).\nThe data is preprocessed using the C-PAC pipeline [75], which includes several stages: slice time correction using AFNI's 3dTshift, motion correction with AFNI's 3dvolreg, skull- stripping with AFNI's 3dAutomask, global mean intensity normalization and band-pass filtering (0.01-0.1 Hz). After quality control, 1009 subjects are left, with 516 individuals (51.14%) diagnosed with ASD. The prediction task focuses on binary classification for ASD diagnosis. The brain regions are defined using the Craddock 200 atlas [76], with each subject represented by a 200 \u00d7 200 functional connec- tivity matrix. The BOLD time-series for each ROI are truncated to a length of 100.\nClassical Machine Learning Baselines: Connectome-based Predictive Modeling (CPM) [19], a widely recognized model in network neu- roscience for predicting behavioral or clinical out- comes based on brain connectivity data. CPM is typically split into two variations: CPM-NEG and CPM-POS, where predictive features are selected based on negative and positive correlations with the target variable, respectively. Covariance Max- imizing Eigenvector-based Predictive Modeling (CMEP) [22], a more recent model that first gen- erates candidate features based on eigenvectors with strong linear covariance with the target vari- able. These features are then used in ElasticNet regression to assess their predictive power, stream- lining the process by avoiding arbitrary feature selection thresholds. Additionally, we employed classical models including Logistic Regression for classification, Linear Regression for regression, ElasticNet for both classification and regression, Support Vector Machine (SVM) for classification, Support Vector Regression (SVR) for regression, Random Forest for both classification and regres- sion, as well as Naive Bayes for classification and Kernel Ridge Regression for regression. An overview of these models can be found in [39].\nNon-graph Deep Learning Baselines: Brain- NetCNN [81], a convolutional neural network (CNN) framework specifically designed for pre- dicting clinical neurodevelopmental outcomes from brain networks. Unlike classical image-based CNNs that use spatially local convolutions, Brain- NetCNN incorporates novel convolutional filters that operate on the topological locality of struc- tural brain networks. These filters include edge-to-edge, edge-to-node, and node-to-graph con- volutions, making the model particularly well- suited for leveraging the unique structure of brain connectivity data. Additionally, we also use two multi-layer perceptron (MLP)-based models: MLP-Flatten and MLP-Node. MLP-Flatten takes the upper triangular part of the brain connectome matrix as input, flattens it into a feature vec- tor, and processes it through two fully connected layers. In contrast, MLP-Node transforms each node's feature individually using shared weights across nodes, then concatenates these transformed node features into a graph-level embedding for the final prediction.\nAggregation-based Graph Deep Learning Baselines: Message aggregation in GDL refers to combining information from neighboring nodes to update the representation of a central node, which is crucial in learning the structural and relational patterns within graph data. Below, we describe the GDL models employed in our study, focusing on general-purpose GDL techniques and those specifically tailored for brain connectome analysis.\nThe dual-pathway model comprises two complementary pathways. The first pathway (orange arrow) retains the simplicity and effectiveness of linear models (LM), using the flattened upper triangular part of the functional brain network matrix as its feature. Formally, for a given sample, let $B\\in R^{n\\times t}$ represent the BOLD time series data, where n is the number of ROIs, and t is the number of time points. The functional brain network is then represented by the Pearson correlation matrix $A \\in R^{n\\times n}$, where each element $A_{ij}$ is the Pearson correlation coefficient between the time series of ROI i and ROI j. The feature vector $u \\in R^{\\frac{n(n-1)}{2}}$ is obtained by flattening the upper triangular part of A, which serves as the feature to the LM pathway. This feature construction approach is consistent with"}, {"title": "\u2022", "content": "\u2022 Following previous works [3, 26], the negative connections are excluded for graph model. This step emphasizes the functional connectiv- ity between ROIs that exhibit co-activation or co-deactivation, reflecting homophily, where the behavior patterns of connected ROIs are similar. This homophily aligns with the core assumptions of commonly used GDLs [83]. In contrast, neg- ative correlations between ROIs, which indicate heterophily or dissimilar behavior patterns, do not fit these assumptions.\nThe GAT model takes the graph $\\hat{A}$ and node features X as inputs to compute the node embeddings $H\\in R^{n\\times d'}$, where d' is the dimension of the learned node embedding. A graph-level embedding $h_{graph} \\in R^{d''},d'' = n \\times d'$ is then obtained via concatenation pooling: $h_{graph} = Concat Pooling(H)$. Finally, the graph-level embedding $h_{graph}$ from the GAT pathway is concatenated with the vec- torized feature vector u from the LM pathway: $z = [h_{graph}; u]$, which is then passed through a fully connected layer to make the final prediction. Specifically, for classification tasks, the prediction is given by $\\hat{y} = \\sigma(Wz + b)$, where $\\sigma(\\cdot)$ is softmax function. For regression tasks, the prediction is given by $\\hat{y} = Wz+b, where W and b represent the weights and bias of the fully connected layer. Given the dominance of the LM pathway for prediction, there is a tendency for the GAT path- way to be undertrained during joint optimization. To mitigate this imbalance, we adopt a phased training strategy. Initially, the LM pathway is frozen, allowing the GAT pathway to train inde- pendently for a tunable number of epochs. Then, both pathways are jointly optimized, ensuring the GAT pathway is well-trained and contributes effectively to the overall prediction."}]}