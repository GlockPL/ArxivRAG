{"title": "Effective and Efficient Representation Learning for Flight Trajectories", "authors": ["Shuo Liu", "Wenbin Li", "Di Yao", "Jingping Bi"], "abstract": "Flight trajectory data plays a vital role in the traffic management community, especially for downstream tasks such as trajectory prediction, flight recognition, and anomaly detection. Existing works often utilize handcrafted features and design models for different tasks individually, which heavily rely on domain expertise and are hard to extend. We argue that different flight analysis tasks share the same useful features of the trajectory. Jointly learning a unified representation for flight trajectories could be beneficial for improving the performance of various tasks. However, flight trajectory representation learning (TRL) faces two primary challenges, i.e. unbalanced behavior density and 3D spatial continuity, which disable recent general TRL methods. In this paper, we propose FLIGHT2VEC, a flight-specific representation learning method to address these challenges. Specifically, a behavior-adaptive patching mechanism is used to inspire the learned representation to pay more attention to behavior-dense segments. Moreover, we introduce a motion trend learning technique that guides the model to memorize not only the precise locations, but also the motion trend to generate better representations. Extensive experimental results demonstrate that FLIGHT2VEC significantly improves performance in downstream tasks such as flight trajectory prediction, flight recognition, and anomaly detection.", "sections": [{"title": "Introduction", "content": "With the continual development of air transportation, flights tend to broadcast their current locations for safe and efficient air traffic control (Zhang et al. 2023). The collected flight trajectories are one of the most critical data sources for air traffic management, attracting increasing attention from both academic and industrial fields. Recent works show that deep representation learning has become the dominant technique and achieved significant performance for various flight trajectory-related tasks, such as trajectory prediction (Liu and Hansen 2018; Wu et al. 2022; Zhang et al. 2023; Guo et al. 2024), flight monitoring (Zhang et al. 2016; Fern\u00e1ndez et al. 2019), and anomaly detection (Olive and Basora 2020; Memarzadeh, Matthews, and Templin 2022; Memarzadeh, Matthews, and Weckler 2023). However, these works either utilize handcrafted features or design representation models for one specified task. We argue that different flight tasks may share the same useful features of trajectory. Jointly learning a unified representation for flight trajectories could be beneficial for boosting the performance of various tasks, which motivates this work.\nLearning unified trajectory representation for different tasks has been well-studied on vehicle and human mobility trajectories (Yao et al. 2017; Li et al. 2018; Chen et al. 2021; Jiang et al. 2023). Deep sequential models, such as Recurrent Neural Networks (Yao et al. 2017; Li et al. 2018) and Transformer (Chen et al. 2021; Yao et al. 2022; Jiang et al. 2023) are employed to encode the spatial-temporal correlations and transform raw trajectories into generic representation vectors. Nevertheless, existing solutions are hard to extend to represent flight trajectories due to the two challenges, i.e. unbalanced behavior density and 3D spatial continuity.\nUnbalanced behavior density. Flight trajectories are characterized by high point density but sparse behavior information. As shown in Figure 1(a), the aircraft usually fly in a straight line with a fixed attitude. The representative activities, such as turns, holding patterns, and takeoff/landing phases, only account for a relatively small part, e.g. 5%, of the whole trajectory. Existing TRL methods usually treat every point equally without considering the density of behaviors, leading to inconsequential representations.\n3D spatial continuity. Flights move in a three-dimensional space, exhibiting more complex spatial patterns compared to ground trajectories."}, {"title": "Related Work", "content": "Flight Trajectory Analysis Framework. Existing research on flight trajectory data analysis always requires manual feature engineering and specialized models for each task, heavily relying on domain expertise and being difficult to extend. For instance, (Guo et al. 2022a, 2024) proposed a feature representation method based on binary encoding (BE) for trajectory prediction, utilizing Conv1D and Transformer modules to capture spatiotemporal features of trajectory points. (Fang et al. 2021) selected 10 correlation coefficient features, such as Oil Temperature (OilT) and Oil Pressure, for trajectory recognition. (Qin et al. 2022) introduced unsupervised feature engineering methods to map input data into latent feature spaces for anomaly detection. The limitation of these methods is that they require expert knowledge and complex feature engineering to extract useful information. There are also some learning-based methods, but they do not solve the problem of uneven behavior density. They either model the entire trajectory indiscriminately (Guo et al. 2024) or only focus on specific segments such as takeoff and landing phases (Fern\u00e1ndez et al. 2019; Memarzadeh, Matthews, and Templin 2022), unable to adaptively identify and model informative segments of the trajectory. In conclusion, although existing methods have achieved success in specific tasks, they rely on complex feature engineering highlights the need for a unified approach.\nTrajectory Representation Learning. Trajectory Representation Learning (TRL) has gained significant attention in the data engineering community due to its effectiveness in enhancing various downstream tasks. Existing methods can be broadly divided into two categories: road network-based methods and grid-based methods. Road network-based methods (Fu and Lee 2020; Chen et al. 2021; Jiang et al. 2023; Qian et al. 2024) map trajectories to nodes of the road network and learn representations of nodes to generate trajectory representations. However, flight trajectories can move in three-dimensional space without the constraints of road networks, making road network-based methods inapplicable. Grid-based methods (Yao et al. 2018, 2019; Li et al. 2018; Yang et al. 2021; Jing et al. 2022) divide the geographical space into a grid of cells and map trajectories to these grids to learn representations. These methods are also difficult to apply to flight trajectories since dividing 3D space into grids will result in an exponential increase in the number of grids. This will make the trajectory data on many grids too sparse, thus the model cannot effectively learn trajectory representations. Overall, there is no existing work specifically focused on representation learning for flight trajectories and existing TRL methods are not applicable to flight trajectories.\nPatch-based Transformer. In recent years, patch-based approaches for time series analysis have emerged as mainstream. Compared to point-wise processing methods, these models not only improve efficiency but also exhibit notable performance improvements, revealing the importance of enhancing modeling of local semantics through patching. For instance, PatchTST (Nie et al. 2022) segments each time series into patches and employs an Multi-layer Perceptron (MLP) to feed patch embeddings into a Transformer. This method also utilizes mask-based unsupervised pre-training to learn representations that can generalize to various downstream tasks. Following PatchTST, a series of patch-based Transformer models for time series have continually set new benchmarks in various downstream tasks, such as prediction (Wang et al. 2024; Chen et al. 2024), classification (Li, Li, and Yan 2024) and anomaly detection (Yang et al. 2023). Notably, HDMixer (Huang et al. 2024) has revealing the importance of patch division. This research shows that incorrect patch boundaries can obscure local patterns and disrupt the semantic continuity of the sequence. However, these methods do not address the issue of unbalanced behavior density, i.e., they fail to effectively capture sparse but critical behaviors in flight trajectories."}, {"title": "Preliminary", "content": "In this section, we first define the problem and then describe the proposed method FLIGHT2VEC, respectively.\nProblem Definition. Given a flight trajectory denoted by $T = {x_1,x_2,..., x_n}$, where each $x_i$ represents a recorded point at timestamp $i$, the objective of Trajectory Representation Learning (TRL) is to generate a general low-dimensional representation, $v \\in R^D$, that can be utilized in various downstream tasks.\nIn this study, each trajectory point $x_i$ is described by six key attributes related to the aircraft's status:\n$x_t = [lon_i, lat_i, alt_i, Vlon_i, Vlat_i, Valt_i]$,\nwhere $lon_i, lat_i,$ and $alt_i$ represent the longitude, latitude, and altitude of the aircraft, respectively. The attributes $Vlon_i, Vlat_i$, and $Valt_i$, denote the velocity components in the longitudinal, latitudinal, and altitude dimensions, respectively.\nOverview of FLIGHT2VEC. As shown in Figure 2, FLIGHT2VEC consists of two key components, i.e. behavior-adaptive patching Transformer and model optimization. In the first component, we segment the flight trajectory into a sequence of patches according to the density of behaviors. For non-behavior segments, we down-sample the orginal records and compress the long segments into patches with equal size. The generated patches are feed to a patch Transformer encoder to obtain the flight representation. To optimize the parameters in FLIGHT2VEC, a motion trend learning approach is proposed along with the traditional MSE loss to reconstruct the masked patches. It encourages the learned representations memorize not only the location coordinates but also the moving directions of each records in the masked patches."}, {"title": "Methodology", "content": "We specify the two key components of FLIGHT2VEC, i.e., the behavior-adaptive patching Transformer, and the optimization of the model, respectively.\nBehavior-Adaptive Patching Transformer\nBehaviors such as takeoff and turning only account for a very small part of flight trajectories, but they are informative and crucial for modeling trajectory patterns. Therefore, we propose an behavior-based patching mechanism that extracts more informative features by amplifying behavior-dense segments.\nBehavior-Based Patching We observe that: (i) behavior segments reflect significant trajectory changes, such as turns and holding patterns; (ii) non-behavioral segments show stable movement with dense point distributions, which are less informative. Inspired by the observation, we first identify behavior segments $A$ in a flight trajectory $T$ and then adaptively patch the trajectory based on $A$.\nSpecifically, considering a flight trajectory indicated by $T = {X_1,X_2,...,X_n}$, we first apply a threshold filter to remove noisy points with excessive oscillations. Next, we calculate the angle change for each point as: $angle_i = {a_1,a_2,...,a_n}$.\nThen, points with angle changes exceeding a threshold $s$ are identified as active points, denoted by $A'$:\n$A' = {a_i | angle_i > s}$\nAfter that, we use a behavior-based patching algorithm to create patches as the inputs of Transformer. Since each behavior is composed of multiple consecutive points, for each active point, we compute its index distance to neighboring active points and cluster those with index distance less than a threshold. Then, we select a central active point $c$ from each cluster as a patch center and we can get a patch with a predefined patch size $S$. As illustrated in Figure 3, $a_j, a_{j+1}$, and $a_{j+2}$ are all active points. Since they are adjacent, we consider them to be in the same cluster and select point $a_{j+1}$ as the center point $c$. After that, we obtain a behavioral patch set $P_b$ consists of $g$ patches, where $g$ is the number of active point clusters. Each patch in $P_b$ preserves the information of a behavioral segment, improving the model's ability to learn from local patterns.\nFor non-behavioral segments, we perform uniform sampling with a step size of $\\frac{N-g}{n}S$ to generate additional patches from these segments, where the $N$ denotes the number of patches and $S$ is the patch size. Overall, we get a sequence of patches $P = [P_1,...,P_N]$ which consists of $g$ behavioral patches and $N - g$ non-behavioral patches."}, {"title": "Optimization of FLIGHT2VEC", "content": "To model the complex moving patterns and the spatial continuity in flight trajectories, we optimize FLIGHT2VEC with a mask-based self-supervised learning strategy and a novel motion trend learning.\nMask-based self-supervised learning. Previous methods often adopt random masking to optimize patch Transformer, which is not suitable for flight trajectories where most points are moving uniformly in a straight line. For these points, the model can easily infer the masked values through simple interpolation between adjacent time points, without capturing the complex trajectory patterns. To address this problem, we introduce a motion-based randomization strategy to effectively mask the behavior patches $P_b$ and their surrounding areas. Specifically, we mask the patches in $P_b$ and their neighboring patches with the probability $p_b$, and we mask other patches with the probability $p_n$, where $p_n < p_b$. Then, we use a $D \\times P$ linear layer to reconstruct the masked patches $x_{mask}$. The Mean Squared Error (MSE) loss to minimize reconstruction errors:\n$L_{MSE} = E_x \\frac{1}{M}\\sum_{i=1}^{M} ||x_{masked} - x_{mask}||^2$\nwhere $M$ is the number of points in the masked patches.\nMotion Trend Learning. However, MSE loss is not enough to model flight trajectories for two main reasons. First, MSE loss treats all errors equally, regardless of their spatial context, which means it does not effectively capture the spatial continuity and dependencies inherent in flight trajectories. Second, MSE loss does not adequately model the uncertainty and sparsity of significant behavioral points within dense trajectory data. Critical behavioral segments, such as turns and altitude changes, are sparse but vital for accurate representation. Optimizing the model with only MSE loss may result in suboptimal learning, as it might not adequately focus on these sparse yet crucial points.\nFor example, as illustrated in Figure 4, consider a point $X_1$ that needs to be reconstructed or predicted, with two candidate points $x_a$ and $x_b$. Both $x_a$ and $x_b$ are equidistant from $X_1$, resulting in the same MSE loss. But $x_a$ is better than $x_b$ because it is located on the line where the trajectory is moving forward. To model this preference and inherent uncertainty, we introduce the moving direction loss function.\nSpecifically, we categorize each point in the trajectory based on its movement direction. For point $X_i = (lon_i, lat_i, alt_i)$ and $X_{i+1} = (lon_{i+1}, lat_{i+1}, alt_{i+1})$, we calculate the direction vector d'from $x_i$ to $x_{i+1}$:\n$d = (lon_{i+1} - lon_i, lat_{i+1} \u2013 lat_i, alt_{i+1} \u2013 alt_i)$.\nEach component of $d$ can be positive, negative, or zero, corresponding to the direction along each axis. The direction is represented as a triplet $(d_{lon}, d_{lat}, d_{alt})$ based on the direction vector, where $d_{lon} = sign(lon_{i+1} \u2013 lon_i), d_{lat} = sign(lat_{i+1} \u2013 lat_i)$, and $d_{alt} = sign(alt_{i+1} \u2013 alt_i)$. The sign function is defined as:\n$sign(u)=\\begin{cases} 1 & \\text{if } u > 0 \\\\ 0 & \\text{if } u = 0 \\\\ -1 & \\text{if } u <0 \\end{cases}$\nWe divided the 3D moving space into 26 categories based on directional movement. Each dimension (longitude, latitude, and altitude) has three possible states: positive, negative, or unchanged. Combining these states yields 3\u00d73\u00d73-1=26 unique directions, excluding the case where all dimensions remain unchanged. Each point is then assigned a category corresponding to its movement direction.\nWe adopt following moving direction loss to optimize the model and to learn these directional preferences:\n$L_{MD} = -E_x log P(y_{masked} | y_{mask}, x)$\nwhere $y_{masked}$ represents the label of one of the 26 moving directions.\nThe final loss is a combination of Mean Squared Error (MSE) loss and the moving direction loss, enabling the model to capture both spatial relationships and precise values. Thus, the final combined loss function is:\n$L_m = L_{MD} + \\lambda \\cdot L_{MSE}$\nwhere $\\lambda$ is a weighting factor that balances the contributions of the two parts.\nBy incorporating the spatial proximity-aware loss function and the moving direction loss, FLIGHT2VEC can effectively encode the complex three-dimensional movement patterns in flight trajectories into the learned representations."}, {"title": "Complexity Analysis", "content": "The complexity of the behavior-based patching is $O(n)$, where $n$ represents the length of the flight trajectory. Then, the complexity of patch projection and position embedding is $O(N \\cdot S \\cdot d_m)$, where $N, S, d_m$ denote the number of patches, the size of each patch and the embedding dimension, respectively. Then, the backbone, i.e., the Transformer encoder, involves self-attention computation, resulting in a complexity of $O(N^2 \\cdot d_m)$. Finally, the complexity of the Linear Layer is $O(N d_m)$. In general, the time complexity of our framework is $O(N^2 \\cdot d_m)$, with the Transformer Encoder being the most computationally intensive component. In practice, the number of patches is much less the length of trajectory which makes FLIGHT2VEC efficient."}, {"title": "Experiment", "content": "Experimental Settings\nIn this section, we briefly introduce the datasets, experiment protocols, baselines and hyperparameter settings. The code and data are public available at https://github.com/liushuoer/FLIGHT2VEC. More details of the experimental settings are described in the Appendix.\nData Descriptions We conduct extensive experiments on two real-world datasets, the Swedish Civil Air Traffic Control (SCAT) (Nilsson and Unger 2023) and Aircraft Trajectory Classification Data for Air Traffic Management(ATFMTraj) (Phisannupawong, Damanik, and Choi 2024b).\nExperimental Protocol We employ three representative tasks, i.e. flight trajectory prediction (FTP), flight recognition (FR), and anomaly detection (AD), to evaluate the representations learned from FLIGHT2VEC. For FTP, we predict the future trajectory in (1, 3, 15, 30, 60) different horizons and utilize Mean Absolute Error (MAE), Mean Absolute Percentage Error (MAPE), Root Mean Squared Error (RMSE) and Mean Distance Error (MDE) as the evaluation metrics. For FR, we directly use the category of flight as ground truth and evaluate the performance with accuracy (ACC), precision (PRE), and recall (REC). For AD, we generate the synthetic anomalies according to the previous work (Guo et al. 2022b) and evaluate the performance of FLIGHT2VEC with AUC and AUPR. Following the settings of the previous work, we use the Mean Time Cost(MTC) metric to evaluate the computational performance.\nBaselines As described in the experimental protocol, we employ three tasks to verify the performance of FLIGHT2VEC. For flight trajectory prediction, three representative methods, i.e. FlightBERT++ (Guo et al. 2024), LSTM+Attention (Guo et al. 2022a), and PatchTST (Nie et al. 2022) are compared. For anomaly detection methods, we use DMDN (Lijing, Weili, and Zhao 2021), and DDM (Guo et al. 2022b) for performance comparison. For flight trajectory recognition, we select SPIRAL (Lei et al. 2019) and ATSCC (Phisannupawong, Damanik, and Choi 2024a) as our baselines. Moreover, we also compare the ablations of FLIGHT2VEC to verify the superiority of the proposed techniques and study the parameter sensitivity to provide some insight in the use of FLIGHT2VEC.\nHyperparameters setting Our model utilizes the Transformer configuration from (Nie et al. 2022), which includes 3 layers with a model dimension of 256, and 16 attention heads with a dropout rate of 0.2. The binomial masking probability is set at 0.4. The dimension of the representation pi is set to 256. For training, the batch size is set to 256, and the AdamW optimizer is used with a learning rate of 1 \u00d7 10-5 The model is pre-trained for 100 epochs with a patch length of 32. All the experiments are conducted on the 2\u00d7 NVIDIA 3090Ti."}, {"title": "Effectiveness of FLIGHT2VEC", "content": "To evaluate the effectiveness of FLIGHT2VEC, we conduct experiments on the aforementioned three tasks and analyze the results of each task respectively.\nResults of Flight Trajectory Prediction. We conduct FTP experiment on SCAT dataset and report the quantitative results in Table 1. According to the results, we have four observations. Firstly, the Transformer-based methods, such as PatchTST, FlightBERT++ and FLIGHT2VEC, achieve superior performance compared with the LSTM+Attention. Owing to the large parameter size and self-attention mechanism, Transformer-based methods have higher model capacity to model the long-term dependence for flight prediction. Secondly, FlightBERT++ is the most competitive baseline, which can predict the flight trajectory in a non-autoregressive manner, but it is also inferior to FLIGHT2VEC. This proves the effectiveness of activity density and moving trends modeled in FLIGHT2VEC. Thirdly, with the prediction horizon increasing, the performances of all methods are dropped. For example, the MDE of Flight-BERT++ increases by approximately 237% when the horizon increases from 3 to 15. FLIGHT2VEC still beats all compared baselines on all prediction horizons. We attribute this to the effectiveness of moving direction loss which captures the 3D spatial motion trend of flight trajectory. Lastly, due to the fusion of some attributes of the trajectory points, Flight-BERT++ achieves better performance than FLIGHT2VEC for short-term horizon predictions (in horizons 1 and 3). We use the same method in FlightBERT++ to integrate the attributes in FLIGHT2VEC and form FLIGHT2VEC +BE. As shown, FLIGHT2VEC +BE achieves the best performance across all prediction horizons, which also proves the scalability of our method.\nResults of Anomaly Detection. The flight trajectory anomaly detection experiments are also conducted on SCAT dataset. The results are presented in Table 2. Due to the absence of real ground truth anomalies. We construct four types of anomalies, i.e., Successive Multipoint Anomaly (SMA), Horizontal Deviation (HD), Vertical Deviation (VD) and Go-Around following the existing work (Guo et al. 2022b). We train another MLP layer along with the learned representations of FLIGHT2VEC to achieve anomaly detection. All the methods are trained with the same training dataset. For evaluation metrics, we utilize AUPR in addition to AUC to handle the unbalanced anomaly classes. As shown, the performance of DMDN is inferior to DDM, which proves the density estimation method of DMDN can not learn representative features for detecting anomalies. FLIGHT2VEC achieves significant improvements in all metrics, proving that the learned representations can capture the local movement patterns of the flight trajectory. For Go-Around anomaly, FLIGHT2VEC achieves 10.4% and 14.1% improvements of AUC and AUPR, compared with the most competitive baseline DDM. Moreover, the results of FLIGHT2VEC consistently outperform the baselines on four anomaly types, indicating that the proposed behavior-adaptive patching and moving direction loss can encourage the representation model to learn useful features.\nResults of Flight Recognition. We conduct the flight recognition experiment on ATFMTraj dataset and present the results in Table 3. In ATFMTraj, the flight trajectories are categorized into four classes, i.e., RKSla, RKSId, ESSA and LSZH, by the airports of take-off and landing. As illustrated, the performances of all methods are relatively high. The best accuracy of the four classes are over 99%. For the compared baselines, the performance of ATSCC significantly outperforms SPIRAL. The precision increased from 0.8301 to 0.9946 on RKSla. This phenomenon indicates the segment-patch framework in ATSCC can better represent the flight trajectory compared with using original data directly. FLIGHT2VEC utilizes the behavior-adaptive patching Transformer and achieves comparable results with the performance of ATSCC."}, {"title": "Efficiency of FLIGHT2VEC", "content": "To verify the efficiency of FLIGHT2VEC, we report the Mean Time Cost (MTC) of representation generation along with the model size in Table 4. As shown, the computational time of FLIGHT2VEC is better than, at least comparable with, all the compared baselines. For the FTP task, FLIGHT2VEC is the fast method expect for PatchTST. However, PatchTST is a light model that is not specifically designed for flight trajectories and performs poorer than FLIGHT2VEC. FlightBERT++ is inferior to FLIGHT2VEC, because FlightBERT++ is a encoder-decoder framework while FLIGHT2VEC is a decoder-only architecture. The parameters in FLIGHT2VEC are much less than Flight-BERT++, leading to better computational efficiency. For FR, SPIRAL has minimal computational time. This is because SPIRAL is not a deep learning method. Compared with the SOTA method, FLIGHT2VEC is 10 times faster than ATSCC, i.e., from 43.89 ms (ATSCC) to 3.11 ms (FLIGHT2VEC). For AD task, FLIGHT2VEC demonstrate substantial improvements in computational performance compared to the baselines."}, {"title": "Ablation Study", "content": "We compare FLIGHT2VEC with two ablations to analyze the effectiveness of the proposed components. We remove the proposed behavior-based patching, randomly sample points at fixed intervals and divide the patch to obtain w/o PD. We obtain w/o MD by removing moving direction loss.\nDue to the space limit, we only report the experiment on FTP task and the results are shown in Table 5. We observe: (1) Comparing the results of FLIGHT2VEC with w/o MD, we observe the moving direction loss can model the spatial continuity flight trajectories. For example, the RMSE improves from 18.24 to 23.11 on altitude. (2) From the results of w/o PD and FLIGHT2VEC, we can conclude that the activity patching mechanism capacity to represent flight trajectory is more effective than a fixed patch. (3) FLIGHT2VEC achieves the best performance compared to all ablations, which proves the effectiveness of the proposed techniques."}, {"title": "Sensitivity Analysis", "content": "We analyze the impact of selecting different patch sizes and representation dimensions on different tasks. We ranged the patch size from 8 to 48 and the representation dimension from 64 to 512, and then show the average performance of these configurations on different tasks in Figure 5.\nWith the increase of patch size, the performance of FLIGHT2VEC first increases and then drops. FLIGHT2VEC achieves the best performance with the patch size of 32 on both FTP and AD tasks. For FR task, the optimal performance is achieved with the largest patch size of 48. This is because the FR task pays more attention to the global movement patterns of the flight trajectory.\nFor the change of embedding dimension, the performances of the three tasks have similar patterns. FLIGHT2VEC achieves the best performance on the dimension size of 256. This phenomenon indicates FLIGHT2VEC is robust to different embedding dimension sizes."}, {"title": "Conclusion", "content": "In this paper, we present FLIGHT2VEC which is the first unified framework specifically designed for flight trajectory representation learning. By addressing the challenges of unbalanced behavior density and 3D spatial continuity, FLIGHT2VEC enhances the representation of flight trajectories. Our approach introduces an adaptive behavior-based patching mechanism and a direction loss, significantly improving performance across tasks like trajectory prediction, anomaly detection, and flight monitoring. Extensive experiments across multiple task demonstrate that FLIGHT2VEC not only significantly outperforms existing methods but also sets a new benchmark in the field."}, {"title": "Appendix", "content": "Details of datasets.\n\u2022 SCAT: The SCAT dataset contains detailed data of almost 170,000 flights from October 2016 to September 2017, as well as weather forecasts and airspace data collected from the air traffic control system in the Swedish flight information region. The dataset is limited to scheduled flights, excluding military and private aircraft. After removing trajectories that only flew at a single altitude, we obtained a final dataset of 100, 383 trajectories.\n\u2022 ATFMTraj: The dataset has classification labels based on aeronautical publications. The dataset is divided into four sub-datasets based on the airport and flight plan (departing or arriving). The arrival and departure datasets of Incheon International Airport (ICAO code: RKSI) are denoted as RKSIa and RKSId, respectively. The arrival datasets of Stockholm Arlanda Airport (ICAO code: ESSA) and Zurich Airport (ICAO code: LSZH) are denoted as ESSA and LSZH, respectively.\nDetails of Compared Baselines.\nWe compare FLIGHT2VEC with seven baselines, which are divided into three groups based on downstream tasks: flight trajectory prediction (FTP) methods, flight trajectory recognition methods, and anomaly detection methods. For the first group, we employ three baselines. We compare the State-of-the-Art (SOTA) model FlightBert++(Guo et al. 2024) in the field of flight trajectory prediction and the model LSTM+Attention(Guo et al. 2022a) based on the Seq2Seq architecture according to its experimental settings. We also compare the patch-based Transformer model PatchTST(Nie et al. 2022) and the model FLIGHT2VEC +BE that introduces the additional features proposed by FlightBert++. For flight trajectory recognition methods, we select SPIRAL(Lei et al. 2019) and ATSCC(Phisannupawong, Damanik, and Choi 2024a), as our baselines. For anomaly detection methods, we use DMDN (Lijing, Weili, and Zhao 2021), and DDM (Guo et al. 2022b) for performance comparison.\nExperimental Protocol.\nIn our experiments, each dataset is divided into two subsets: the first 50% of timestamps is denoted as the training set, while the latter 50% is denoted as the test set. We utilize three downstream tasks to evaluate the performance of FLIGHT2VEC. For trajectory prediction task, we predicts the results in a single inference process for multiple time steps on the SCAT data set. The experimental results are divided into five (1, 3, 15, 30, 60) different horizons, corresponding to 20 seconds, 1, 5, 10 and 20 minutes trajectories in the future. For flight trajectory recognition task, we directly used the real label to conduct the experiments. Due to privacy concerns, Existing flight trajectory dataset either have no labeled anomaly edges or only have one anomaly type. To verify the ability of FLIGHT2VEC on various anomaly types, we follow the experiments of (Guo et al. 2022b) and generate three kinds of systematic anomaly types, i.e., Successive Multipoint Anomaly (SMA), Horizontal Deviation (HD), Vertical Deviation (VD) and Go-Around for SCAT datasets. SMA refers to multiple consecutive trajectory points in a flight that deviate from the planned flight path. This anomaly may indicate a problem with the aircraft's control or navigation. HD refers to the aircraft's deviation from the planned horizontal path during flight. Especially during the approach phase, HD anomalies may affect flight safety. VD refers to the aircraft's deviation from the expected vertical flight trajectory. The aircraft fails to accurately follow the glide path, which may cause the aircraft to be in a dangerous state of being too high or too low during approach or landing. Go-Around refers to aborting the landing and re-entering the route when the aircraft cannot land safely. In the anomaly detection task, in order to simulate the situation with few anomaly in real-world scenarios, we only add 5% anomaly lable data to the test set."}]}