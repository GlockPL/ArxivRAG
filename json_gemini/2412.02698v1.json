{"title": "Scaling BERT Models for Turkish Automatic Punctuation and Capitalization Correction", "authors": ["Abdulkader Saoud", "Mahmut Alomeyr", "Mehmet Fatih Amasyali", "Himmet Toprak Kesgin"], "abstract": "This paper investigates the effectiveness of BERT- based models for automated punctuation and capitalization corrections in Turkish texts across five distinct model sizes. The models are designated as Tiny, Mini, Small, Medium, and Base. The design and capabilities of each model are tailored to address the specific challenges of the Turkish language, with a focus on optimizing performance while minimizing computational overhead. The study presents a systematic comparison of the performance metrics-precision, recall, and F1 score of each model, offering insights into their applicability in diverse operational contexts. The results demonstrate a significant improvement in text readability and accuracy as model size increases, with the Base model achieving the highest correction precision. This research provides a comprehensive guide for selecting the appropriate model size based on specific user needs and computational resources, establishing a framework for deploying these models in real-world applications to enhance the quality of written Turkish.", "sections": [{"title": "I. INTRODUCTION", "content": "Clear communication is critical to successful interactions, and poor communication can lead to misunderstandings. There are two main ways to communicate: verbally and in writing. Written communication requires punctuation. These punctuation marks significantly affect how sentences are interpreted. This is especially important in Turkish, which is characterized by its detailed structure, where proper punctuation is necessary to avoid confusion and clearly convey the intended message. Despite the critical role of punctuation and capitalization in maintaining textual integrity, current natural language processing (NLP) tools often fall short, especially for languages like Turkish that have unique linguistic features. Existing models are predominantly trained on English language datasets, which do not sufficiently capture the syntactic and grammatical nuances of Turkish. This discrepancy often results in suboptimal performance when these models are applied to Turkish texts, potentially distorting the intended meaning of the communication. Moreover, there is a notable lack of resources that specifically address the automatic correction of punctuation and capitalization in Turkish, creating a significant gap in NLP applications for Turkish speakers.\nThis paper presents a model that not only corrects punctuation and capitalization errors more effectively, but also makes clear, error-free written communication available to more people. By improving the accuracy of punctuation and capitalization, the model also improves the performance of text-to-speech (TTS) systems, making the spoken version of written texts sound more natural and easier to understand.In addition, this improved model can be a crucial tool for proofreading and editing, significantly improving the quality of Turkish writing on various platforms, from academic articles to social media content. Ultimately, this innovation aims to improve overall written communication in Turkish, ensuring clear and accurate information exchange in both informal and formal settings.\nIn this research, we used the \"batubayk/TR-News\" [1] dataset, accessible through the Hugging Face [2] platform, which contains a wide range of Turkish news articles. The dataset was carefully segmented into sub-paragraphs, each limited to 512 tokens, in order to optimize the training process of the BERT models. Each token was then classified into different classes, paving the way for the fine-tuning phase. We used several variants of the \"ytu-ce-cosmos\u201d pre-trained BERT models [3]-from tiny to base-to explore the effect of model size on performance. Parameters were carefully adjusted to optimize accuracy, and performance comparisons were made between the different model sizes to determine the most effective configuration for punctuation and capitalization tasks in Turkish texts.\nFollowing the fine-tuning phase, we conducted a series of experiments to evaluate the performance of our models. This included rigorous testing under various conditions to"}, {"title": "II. LITERATURE REVIEW", "content": "The proposed method is based on the classification of individual tokens within a sentence, rather than the entire sentence or document, as is the case with sentiment analysis or topic classification. This system, referred to as Token Classification, is frequently employed for Named Entity Recognition (NER) task [12]. However, it can be utilized in a self-supervised manner by labeling each token with the punctuation mark that follows it or whether the word begins with a capital letter.\nVarious methods have been explored to correct punctuation errors and predict the use of capital letters. Token Classification is the most commonly used method in this domain. CRFs (Conditional Random Fields) are generally used algorithms for Token Classification [4].\nTraditional methods often combine prosodic and lexical features using recurrent neural networks, while more recent approaches leverage Transformer-based models. The state-of-the-art method proposed by Courtland et al. [14] employs a BERT-based model that achieves high accuracy. This study contributes to the existing literature by developing BERT-based punctuation restoration models for English and Hungarian. The results demonstrate significant advancements in this field.\nIn recent research, Ling et al. have introduced a fast and compact BERT model specifically designed for punctuation correction in Chinese texts [13]. This model retains 95% of the performance capabilities of models ten times its size, although its application has been limited solely to the medical field.\"\nIn their research, Hieu and Dinh [5] demonstrated the superiority of monolingual models over multilingual counterparts in accurately predicting punctuation in Vietnamese texts. Their findings underscore the efficacy of tailored, language-specific models in handling the nuanced aspects of punctuation. Furthermore, they highlighted the potential of transfer learning in enhancing model performance. Building on these insights, they proposed an augmented approach that incorporates both Bidirectional Long Short-Term Memory (Bi-LSTM) layers and CRF to further refine the accuracy of punctuation prediction. This method leverages the strengths of deep learning and sequence modeling to optimize text processing tasks.\nOne effective method in NLP is using transformers. A study [11] tested this approach on English and Bengali, achieving excellent results for English and providing initial insights for Bengali. Another study [7] focused on Turkish, creating a specific dataset for this language. They applied models such as BERT [8], ELECTRA [9], and ConvBERT [10] to see how well they could handle Turkish text. It should be noted, however, that this study is trained on a very small number of punctuation marks (only three in total) and is limited to the prediction of punctuation marks. These studies show the adaptability of transformer models to different languages.\nIn contrast to the models presented in the literature, our model is specifically designed to predict and correct eight different punctuation marks, rather than the three punctuation marks typically addressed in previous models. Additionally, it is capable of not only predicting punctuation but also determining whether a word is written entirely in lowercase, uppercase, or first letter uppercase. Furthermore, it offers five distinct models for speed and performance, including models that are both highly efficient and compact, as well as larger and more successful models."}, {"title": "III. METHOD", "content": "This section details the methodologies employed in this project to develop and evaluate Turkish BERT models for NER and punctuation prediction tasks. It covers the models and architectures used, data preprocessing and training procedures, and the evaluation metrics applied to assess the models' performance. The following subsections provide an in-depth overview of these components."}, {"title": "A. Models and Architectures", "content": "In this paper, BERT models trained by YTU-CE-COSMOS have been utilized. These models are Tiny, Mini, Small, Medium, and Base, and the differences, advantages, and disadvantages of each have been discussed in detail. BERT is a deep learning model based on transformer architecture and works with bidirectional logic on texts. The BERT model is used for various NLP tasks such as Question Answering, Mask Filling, Text Classification, and more. The BERT model consists of two main parts:\n\u2022 Encoder: The set of layers where the text is taken as input and the tokens are represented.\n\u2022 Output Layer: The layer where outputs for customized tasks are produced. This layer has been adjusted specifically for the NER task of the project.\nThe characteristics of the Turkish BERT models (tiny, mini, small, medium, and base) have been examined in detail. Architectural details such as hidden dimensions, number of attention heads, hidden layers, and total parameters are presented in the Table I."}, {"title": "B. Data Preprocessing and Training", "content": "For this project, the 'batubayk/TR-News' [1] dataset, which is 760 MB in size, was used. The selected dataset contains clean news sentences and the news texts usually use correct punctuation, making it ideal for our study. The dataset consists of 9 columns, but only the 'content' column, which consists solely of paragraphs, was used, and the other columns were deleted. The distribution of the dataset into train, test, and validation sections was done as 70%, 20%, and 10% respectively. The distribution of punctuation marks can be seen in Table II."}, {"title": "C. Evaluation", "content": "The metrics used to determine the accuracy of the model's outputs are described below:\n\u2022 Precision: Precision denotes the ratio of true positive predictions to the total number of instances predicted as positive by the model.\nPrecision = $\\frac{\\text{True Positive}}{\\text{True Positive + False Positive}}$ (1)\n\u2022 Recall: This metric indicates the percentage of all actual positive instances that the model correctly predicts as positive.\nRecall = $\\frac{\\text{True Positive}}{\\text{True Positive + False Negative}}$ (2)\n\u2022 F1 Score: The F1 score is the harmonic mean of Precision and Recall, balancing both metrics.\nF1 = 2 \u00d7 $\\frac{\\text{Precision \u00d7 Recall}}{\\text{Precision + Recall}}$ (3)\n\u2022 Confusion Matrix: The Confusion Matrix is a table that shows the model's true positive, false positive, false negative, and true negative predictions for each class. This matrix is used to visually assess the model's performance in detail."}, {"title": "IV. PERFORMANCE ANALYSIS", "content": "1) Preprocessing: The model was initially trained by tokenizing sentences using the NLTK library. This method yielded good results during the testing phase. However, in real-world tests, since the accuracy of the punctuation marks entered by the user is unknown, paragraphs could not be split into sentences. When the model was tested without splitting paragraphs, it did not yield satisfactory results. Therefore, the method described in the system design section, which involves using the paragraph without splitting, was employed.\n2) the affect of learning rate: Models were trained and tested using different learning rate values. The results of the tests are shown in Tables V and VI. Changing the learning rate value yielded different results for each model. For example, a value of 4e-4 performed better than 5e-5 in all models except for Base. Finally, the modules with the highest F1 scores in the experiments were used.\n3) Model Testing: To evaluate the models' performance in a real-world scenario, they were tested on a dataset of 1000 examples. This testing phase aimed to assess the models' efficiency and reliability when applied to a substantial amount of data. The time taken to test each model on these examples is summarized in Figure 1.The tests were conducted using a GPU (NVIDIA GeForce GTX 1060)."}, {"title": "V. EXPERIMENTAL RESULTS", "content": "The F1 scores of the trained models are presented in Table VII.\nWe can infer from the confusion matrices of the Tiny models in Figures 2 and 3 that, while the capitalization model's performance is acceptable, the punctuation model's performance is less reliable. Specifically, the model performs well with periods and apostrophes but struggles with more complex punctuation marks.\nThe Mini models demonstrated the most significant improvement over the Tiny models, achieving a 0.04 increase in F1 score for capitalization and an 0.08 increase for punctuation, which now accurately predicts most punctuation marks, except for semicolons and exclamation marks.\nIn Small models considerable improvement over Mini models has been seen, both models are performing effectively in most of the cases, except for semicolons and exclamation marks.\nMoving from Small to Medium and Base models, minor improvements have been observed, with a 0.926 F1 score for capitalization and 0.785 F1 score for punctuation. The Base model demonstrated the highest performance. The confusion matrices for punctuation and capitalization performance of the"}, {"title": "VI. CONCLUSION AND FUTURE STUDIES", "content": "This study has successfully demonstrated the potential of BERT-based models to effectively correct punctuation and capitalization errors in Turkish text, a language with unique syntactic and grammatical complexities. Through the deployment of five distinct model sizes-Tiny, Mini, Small, Medium, and Base-we have provided a comprehensive analysis that illustrates the relationship between model size, performance, and resource utilization.\nThe experimental results demonstrate that while larger models, such as the Base model, achieve the highest levels of accuracy, with an F1 score of 0.785 in punctuation and 0.926 in capitalization tasks, smaller models, such as Tiny and Mini, still perform commendably. This balance offers flexibility for applications with limited computational resources or those requiring faster processing times without a substantial sacrifice in performance.\nA key finding of this research is the importance of model tuning, particularly the optimization of learning rates and batch sizes, which played a significant role in achieving the best results from each model size. Furthermore, our approach in adapting the BERT architecture for the specific needs of punctuation and capitalization correction has not only improved the readability and quality of Turkish texts but also enhanced the efficiency of text-to-speech systems and automated content editing tools.\nAs future work, we intend to investigate the integration of these models into real-world applications such as live text editors and automated content generation systems. Additionally, we aim to examine the transferability of our approach to other agglutinative languages, which could expand the impact of our work and provide a foundation for multilingual NLP tools that can adapt to the nuances of various languages.\nAdditionally, we plan to conduct experiments with significantly larger datasets, examining the impact of corpus size on model performance. This includes a focus on improving the prediction accuracy of less frequently used punctuation marks by strategically increasing their representation in the training data. By adjusting the proportion of paragraphs containing these rarer punctuation marks, we can assess their impact on overall model performance and refine our approach to better handle diverse linguistic scenarios. This effort will enable us to further enhance the robustness and accuracy of our models across a wider range of text types and applications.\nIn conclusion, the outcomes of this study contribute valuable insights into the development of NLP tools for Turkish and potentially other similar languages. They reaffirm the efficacy of BERT-based models in dealing with complex linguistic tasks, such as punctuation and capitalization correction. The scalability of model sizes provides developers and researchers with a versatile toolkit that can be employed in a range of scenarios, from mobile devices with limited capabilities to powerful cloud-based applications."}]}