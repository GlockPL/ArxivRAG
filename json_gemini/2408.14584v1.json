{"title": "DIAGen: Semantically Diverse Image Augmentation with Generative Models for Few-Shot Learning", "authors": ["Tobias Lingenberg", "Markus Reuter", "Gopika Sudhakaran", "Dominik Gojny", "Stefan Roth", "Simone Schaub-Meyer"], "abstract": "Simple data augmentation techniques, such as rotations and flips, are widely used to enhance the generalization power of computer vision models. However, these techniques often fail to modify high-level semantic attributes of a class. To address this limitation, researchers have explored generative augmentation methods like the recently proposed DA-Fusion. Despite some progress, the variations are still largely limited to textural changes, thus falling short on aspects like varied viewpoints, environment, weather conditions, or even class-level semantic attributes (e.g., variations in a dog's breed). To overcome this challenge, we propose DIAGen, building upon DA-Fusion. First, we apply Gaussian noise to the embeddings of an object learned with Textual Inversion to diversify generations using a pre-trained diffusion model's knowledge. Second, we exploit the general knowledge of a text-to-text generative model to guide the image generation of the diffusion model with varied class-specific prompts. Finally, We introduce a weighting mechanism to mitigate the impact of poorly generated samples. Experimental results across various datasets show that DIAGen not only enhances semantic diversity but also improves the performance of subsequent classifiers. The advantages of DIAGen over standard augmentations and the DA-Fusion baseline are particularly pronounced with out-of-distribution samples.", "sections": [{"title": "1 Introduction", "content": "A common problem in the field of computer vision is the insufficient amount of real-world training data [23]. Collecting and annotating data at scale can be difficult, expensive, and time-consuming [21]. To address this issue, data augmentation techniques are crucial in scenarios with very few labelled samples (few-shot) [29,37], as they support generalization and robustness by introducing data variation. While offering valuable benefits, standard augmentation methods like rotations, flips, and scaling often fall short in providing semantic diversity beyond that of the original data [46]. This lack of diversity in training data negatively influences downstream applications, e.g., for objects that typically occur in certain environments, such as a cow being correctly classified on a grassy background but not on a beach [4]. In response to the bottleneck of real data and its lack of diversity, researchers have turned to synthetic data generation as a promising alternative [21]. Recent advancements, such as DA-Fusion by Trabucco et al. [46], demonstrate the potential of synthetic data augmentation by using an off-the-shelf diffusion model.\nHowever, the lack of diversity in synthetic data generation is still a known issue [21,38]. Upon inspecting the images generated by DA-Fusion (see Figs. 1 and 6), it is evident that they appear to be very similar, primarily altering textural details and minor structural elements with no noticeable change in viewpoint, limiting its effect as an augmentation technique. We observe that DA-Fusion is constrained in achieving sufficient diversity due to a lack of control over how an image is augmented. To address this issue, we propose DIAGen (Diverse Image Augmentation with Generative Models), which builds on DA-Fusion and adds three components to it. Thereby, DIAGen enhances the semantic diversity of synthetic images while maintaining high quality, making it an effective augmentation technique to generate diverse training data that simulates a wide range of environments for applications such as autonomous vehicles and robotics. Thus, improving model robustness by enabling safer, more reliable behavior in real-world scenarios. Additionally, DIAGen can be applied to downstream tasks like relation detection [40,43] to enhance the augmentation diversity of rare relations to mitigate biased prediction."}, {"title": "2 Related Work", "content": "Synthetic Data for Few-Shot Learning. Numerous works have explored synthetic image generation using GANs [5,15,41,52] and diffusion models [13, 14,28,34]. In few-shot learning, the small number of labelled images presents a challenge due to the inherently scarce class sampling. Collecting more real-world data is resource intensive [21], but synthetic data can utilize the knowledge of pre-trained generative model. While GANs have already been used for few-shot learning [3], diffusion models offer better results [10] due to their stability, high image quality, and flexibility during image generation [6].\nRecently, Trabucco et al. [46] attempted to generalize their pipeline based on a diffusion model, DA-Fusion, to unseen concepts by integrating Textual Inversion [8]. This method uses three to five real images to learn new visual concepts, creating pseudo word vectors for a text-to-image model. Textual Inversion is ideal for few-shot learning, enhancing the text encoder's vocabulary with new concepts. DA-Fusion then uses these embeddings to generate synthetic images with Stable Diffusion [33]. The denoising process of the diffusion model is conditioned on the text prompt and guided by a real training image [22]. DIAGen builds upon the work of Trabucco et al. [46] to increase the semantic diversity of the synthetic images further.\nDiversity in Datasets. The quality of machine learning models heavily relies on the diversity of their training data. A lack of diversity can lead to biases and poor performance [17], particularly in few-shot scenarios [16]. Creating synthetic data comes with a challenging trade-off: balancing fidelity for accurate representation and diversity for increased coverage [26]. While previous methods have improved synthetic data quality, they only address coverage implicitly. That said, there have been attempts to explicitly focus on the aspect of diversity. Wang et al. [48] demonstrated promising results by using a diversity measurement-based meta-learner. He et al. [10] utilized a text-to-image diffusion model and inserted different descriptive image prompts to achieve a higher coverage for zero- and few-shot learning. Although we use a similar idea, our method can generalize to unseen concepts and provide explicit control over how image prompts are generated, by instructing our LLM with a meta prompt.\nDue to the importance of a high visual quality and coverage of synthetic datasets, many metrics have been proposed to assess these properties [39]. The most common metrics are the Fr\u00e9chet Inception Distance (FID) [12] and the Inception Score (IS) [36], which rely on a pre-existing classifier (InceptionNet [42]). However, both summarise the comparison of the two distributions (real and synthetic) into a single number, overlooking the distinction between fidelity and diversity [35]. To address this, more refined metrics like precision and recall [2,35], density and coverage [26], and the Vendi score [7] have been developed. In our work, we use an improved version of precision and recall [18] due to its wide acceptance in the text-to-image community and its high agreement with human perception [39].\nOut-of-Distribution Generalization. Conventional machine learning algo- rithms often assume that training and test data come from the same distribution. However, in real-world applications, this assumption often fails to hold due to unforeseen distributional shifts. This can lead to a drastic decline in real-world performance [11, 20, 25, 27]. Especially in safety-critical applications, these out- of-distribution (OOD) scenarios need to be handled with the same quality and confidence as identically distributed data. While there have been advancements in OOD detection to reject these samples or hand them over to human users (e.g., in the case of autonomous driving) [50], our goal is to investigate whether an increased dataset diversity allows for the implicit handling of these cases.\nRecent advancements in large-scale models designed to encapsulate extensive world knowledge have enabled a broader coverage of OOD examples. Tong and Dai [44] demonstrate the promising performance of pre-trained text-to-image diffusion models for OOD generalization. However, despite advancements, stud- ies indicate that large-scale text-generation models are still not as effective at handling OOD cases compared to identically distributed data [32,47,51]. Build- ing on these developments, we leverage two distinct large-scale models trained on text and image modalities, harnessing their comprehensive world knowledge."}, {"title": "3 Methodology", "content": "The input to our model DIAGen is a small dataset, R = {Rn | 1,..., N} of N real images, containing only a few images per class. The output of the pipeline (see Fig. 2) is an expanded labelled dataset that includes both the real images as well as M corresponding synthetic images Sn,m for each real image Rn. The goal is to augment the small given dataset in a semantically diverse way to enable the training of a downstream application with better generalization.\nBefore detailing our method to increase semantic diversity, we first lay out, how we define diversity. We focus on improving the intra-class diversity that represents the variance within the data points of a class. We aim to improve two different aspects of diversity: First, we address the different semantically meaningful contexts in which the class can occur. Here we use the three categories of diverse settings as proposed by Kattakinda and Feizi [17], namely weather conditions, time of day, and environment. Second, we enhance the diversity of object appearance itself, e.g., by changing the type of a motorcycle (cf. Fig. 1).\n3.1 Embedding Noise\nThe diffusion model that DIAGen builds upon is conditioned on a text prompt [33] containing the learned pseudo word vector for a specific class. The word vector of a class, e.g., car to give a concrete example, is learned with Textual Inversion [8] and the resulting embedding vector S is inserted into the prompt \u201ca photo of a S\u2217\u201d. Following Mikolov et al. [24], who observed that directions in embedding spaces represent semantic meaning, e.g., $king - man + woman = queen$, and that vectors that are very close to each other also have very similar meaning, we propose adding noise on top of the learned class concept vectors (see Fig. 2, contribution a). We hypothesize that varying S\u2217 of an object yields images of similar object types, since their representations are likely to be close together in the embedding space. This may result in scenarios where the representation of oldtimer is next to the embedding vector of our learned representation of car."}, {"title": "3.2 LLM Prompting", "content": "To achieve more explicit control over image generation beyond simply adding noise to the class embedding, we utilise a large language model (LLM) to provide textual guidance for the diffusion model (see Fig. 2, contribution b). Specifically, we employ GPT-4 [1], known for its robustness and extensive knowledge acquired from internet-scale data. We also tried the smaller model Llama2 (7B) [45] and observed a similar performance.\nDue to the different functioning and training data of language and image models, the covered knowledge also differs. This is beneficial in scenarios where the diffusion model has rarely seen a concept and hence has no contextual knowl- edge of the concept. An LLM such as GPT-4 can provide additional meaningful context so that the resulting synthetic images exhibit high semantic diversity. We instructed GPT-4 to dynamically generate a certain number of prompts in the following style:\na photo of a (adjective) Su (location and/or weather preposition) (weather) (location) (time of day with preposition)\nAs mentioned earlier, Su denotes the learned embedding vector of a class after adding noise, which can be treated as a new pseudo-word. Every place- holder enclosed in brackets is optional and may be completed by GPT-4 to generate prompts of varying lengths and complexity. For instance, the final prompt of class: dog could be \"a photo of a (fluffy) Su\", for class: plane \u201ca photo of a Su (flying above a city at night)\u201d, and for class: spoon \"a photo of an (antique) Su (on a wooden table)\". For more details see Appendix E."}, {"title": "3.3 Weighting Mechanism", "content": "Similar to DA-Fusion [46], the extent to which the generated images can devi- ate from the guiding image is controlled by a strength hyperparameter to. This parameter, ranging from 0 to 1, relates to the time step of inserting the guiding image during the diffusion model's denoising process. When to \u2192 0, the gener- ated images closely resemble the guiding image. While increasing to enhances the image diversity, this increased freedom also leads to a higher probability of generating synthetic images that do not match the intended class label, which can result in either distorted class representations or entirely unrelated concepts."}, {"title": "4 Experiments", "content": "4.1 Datasets\nTo evaluate the effectiveness of our method, four datasets were utilized. A consis- tent set of hyperparameters was used across all datasets to maintain the model's off-the-shelf property and to allow for direct comparison.\nFirst, the FOCUS dataset [17] was chosen, which contains 21K images of 10 different classes in common and uncommon settings, altering the time of day, weather condition, and location. This broad distribution makes FOCUS a well- suited dataset for our experiments, enabling the evaluation of DIAGen's ability to reproduce the distribution of the data only knowing very few images per class.\nSecond, we test our model on the MS COCO dataset [19]. This dataset com- prises common objects in context, which implies that objects occur in different settings and have a variety of appearances. This dataset allows for a direct com- parison to the baseline DA-Fusion, as it was also used in Trabucco et al. [46]."}, {"title": "4.2 Experimental Setup", "content": "We compare DIAGen's results against two baselines: DA-Fusion was chosen as the first baseline since DIAGen is built upon this model. We use the origi- nal experimental setup of Trabucco et al. [46]. Secondly, we compare DIAGen to standard augmentations, given their widespread use for data augmentation tasks. For this, we used a combination of rotations, flips, scale adjustments, and crops. More details on the experimental setup including all values for the hyperparameters can be found in the supplemental material.\nThe model's effectiveness was evaluated on a downstream classifier, com- paring its behaviour on four datasets: FOCUS [17], MS COCO [19], Custom COCO, and Uncommon Settings. The downstream classifier accuracy serves as the primary metric for our studies, following the work of Ravuri and Oriol [30].\nTo ensure relevance for few-shot learning, we trained on small, varying dataset sizes containing 2, 4, and 8 examples per class. Furthermore, to increase the re- producibility and reliability of our findings, we used 3 different seeds to alter the selection of the images in the training split and calculated the mean."}, {"title": "4.3 Classification Accuracy", "content": "shows the downstream classifier accuracy for DIAGen, the baseline DA- Fusion, and standard augmentations. We plot the accuracy over different few- shot dataset sizes, limiting the size to 2, 4, and 8 examples for each class.\nWe observe a consistent improvement in validation and test accuracy, by as much as +5% points across the four datasets when compared to DA-Fusion. The gain of DIAGen against standard augmentations is even more evident, reaching up to +10.5% points. These results highlight the effectiveness of DIAGen, espe- cially in limited data scenarios. In few-shot learning situations where training examples are scarce, DIAGen introduces additional semantic diversity as we fur- ther analyse below, thereby strengthening the model's generalization ability.\nBy using Uncommon Settings, which targets edge cases of real-world object occurrences, we measure how effectively each method can cover a broad range of real-world scenarios. An analysis of the results on the Uncommon Setting test set (see Fig. 3, bottom-right) reveals a significantly higher accuracy of our DIAGen, with gains of approximately +2% points compared to DA-Fusion and +3% points compared to standard augmentations, across all dataset sizes. While the training dataset remains identical to Custom COCO, the test set now in- cludes samples from a distribution entirely different from the training data. This supports the hypothesis that our augmentation technique improves semantic diversity, particularly in generalizing to edge cases and uncommon scenarios."}, {"title": "4.4 Ablation Study", "content": "We now analyze the contributions of the three components in our DIAGen pipeline: embedding noise, LLM prompts, and weighting mechanism. We conduct an ablation study by running each module independently to assess their individ- ual impact. Fig. 4 illustrates the accuracy gains attributed to each component relative to the DA-Fusion baseline.\nEmbedding noise leads to major improvements when only 2 examples per class are used for training. Although the positive effect of adding noise on its own decreases with more examples per class, its combination with the other components yields significant benefits. We attribute the synergy of the combined method to the ability of the embedding noise and LLM to increase diversity at the expense of class fidelity, a trade-off that the weighting mechanism mitigates by assigning a lower weight to low-quality images. Weighting is effective in refining the augmentation process, as visualized by comparing its results with the runs only utilizing noise and LLM prompts in Fig. 4.\nIn contrast to embedding noise, using LLM prompts alone yields promis- ing results, significantly improving the accuracy in case of 2 and 4 examples per class. Interestingly, although DIAGen proves effective across all tasks and dataset sizes, the use of LLM prompts alone outperformed the combined ap- plication in specific scenarios (4 examples per class with Custom COCO). This observation suggests that DIAGen holds the potential to achieve even better results through task-specific fine-tuning by activating different components of its pipeline. Our findings show that while each component can independently improve the accuracy, their true strength emerges in combination.\nTo further verify that the observed improvements in DIAGen are not merely due to hyperparameter adjustments (see Appendix C), we conducted an exper- iment directly comparing DIAGen with DA-Fusion using an identical set of hy- perparameters (see Fig. 5). The results clearly show that DIAGen's performance gains stem from our contributions, rather than from changes in hyperparameters alone. In fact, relaxing the hyperparameters within the DA-Fusion model proves counterproductive, often resulting in reduced performance."}, {"title": "4.5 Diversity Analysis", "content": "While it is important to evaluate the results of the downstream application, we also consider the overall quality and especially the semantic diversity of the synthetic dataset by exploring alternative metrics. If we visually compare the two datasets generated by DA-Fusion and DIAGen, we clearly observe a higher level of diversity with our method (see Fig. 6). At first glance, the DA-Fusion images all look very similar. Small changes can only be observed in fine textural details, such as the imprint on the bottle in Fig. 6 (left). DIAGen, on the other hand, achieves a higher degree of diversity in its images. As shown in Fig. 6(right), it generates varied cars, like an oldtimer and a silver car, in different styles and settings, whereas DA-Fusion produces nearly identical cars. DIAGen's images are both accurately labeled and semantically diverse.\nTo objectively quantify the diversity enhancement, we use the precision and recall metrics for the real and synthetic dataset distributions as defined by Kynk\u00e4\u00e4nniemi et al. [18] (see Appendix F). When interpreting the results, it is important to consider the dataset sizes. Our Custom COCO dataset is rela- tively small, with less than 50 images per class collected by us, leading to a high data bias. In contrast, the MS COCO and FOCUS datasets contain significantly more images per class. Notably, the FOCUS dataset was collected with an em- phasis on including uncommon settings. As a result, the real image distributions are likely to differ significantly among these three datasets.\nThe results in Tab. 1 show a significant recall improvement, with up to a 37.3% increase across all datasets and training samples, reflecting greater im- age diversity. These results align with observed increases in image diversity. For precision, the FOCUS dataset shows only minor differences, indicating that DI- AGen generates diverse yet class-consistent images. However, Custom COCO exhibits a notable precision drop. This can be attributed to the small size of the Custom COCO dataset, which does not adequately represent the real-world data distribution of its classes, as stated above. For instance, DIAGen produces an oldtimer as a car, which is a valid real-world representation of cars, but Custom COCO does not contain any oldtimer images. While Custom COCO addresses data leakage, its distribution is not fully representative of each class and this \"good\" sample is considered to be outside the real distribution, which lowers the precision score. For this reason, the precision score for Custom COCO has lim- ited significance. This argumentation is backed by the precision results for MS COCO, where we observe a smaller drop in precision compared to DA-Fusion. This difference is attributed to the fidelity-diversity trade-off.\nOverall, these results underline that DIAGen notably enhances diversity in synthetic images."}, {"title": "5 Conclusion", "content": "We introduced DIAGen, an off-the-shelf image augmentation technique designed to increase semantic diversity in datasets with few labeled examples per class. DIAGen expands the DA-Fusion framework [46] by incorporating three key com- ponents: The first two modules of DIAGen focus on increasing diversity in the augmentation process by (i) introducing noise to the class representations in the embedding space, and (ii) enriching text prompts with semantically meaningful content, leveraging the capabilities of an LLM. The last module is designed to complement these strategies to keep a high class fidelity by (iii) using a weighting mechanism to reduce the influence of suboptimal generated images using a classi- fier. These components help balance fidelity and diversity in synthesized images.\nThe resulting model improves classification accuracy across various datasets and enhances recall as a diversity metric. It is particularly effective in enabling down- stream models to generalize to uncommon scenarios and edge cases, making it valuable for augmenting data in few-shot settings."}]}