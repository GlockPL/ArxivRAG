{"title": "The use of GPT-4o and Other Large Language Models for the Improvement and Design of Self-Assessment Scales for Measurement of Interpersonal Communication Skills", "authors": ["Goran Buba\u0161"], "abstract": "OpenAI's ChatGPT (GPT-4 and GPT-4o) and other Large Language Models (LLMs) like Microsoft's Copilot, Google's Gemini 1.5 Pro, and Antrophic's Claude 3.5 Sonnet can be effectively used in various phases of scientific research. Their performance in diverse verbal tasks and reasoning is close to or above the average human level and rapidly increasing, providing those models with a capacity that resembles a relatively high level of theory of mind. The current ability of LLMs to process information about human psychology and communication creates an opportunity for their scientific use in the fields of personality psychology and interpersonal communication skills. This article illustrates the possible uses of GPT-4o and other advanced LLMs for typical tasks in designing self-assessment scales for interpersonal communication skills measurement like the selection and improvement of scale items and evaluation of content validity of scales. The potential for automated item generation and application is illustrated as well. The case study examples are accompanied by prompts for LLMs that can be useful for these purposes. Finally, a summary is provided of the potential benefits of using LLMs in the process of evaluation, design, and improvement of interpersonal communication skills self-assessment scales.", "sections": [{"title": "1 Introduction", "content": "After it was introduced in November 2022 by the OpenAI research organization (OpenAI, 2022), ChatGPT (GPT-3.5) and its successors like GPT-4, GPT-4 Turbo, and GPT-4o, as well as other Large Language Models (LLMs), including Microsoft's Copilot (formerly Bing Chat) and Google's Gemini (formerly Bard), rapidly attracted much interest by the"}, {"title": "2 Performance of LLMs in verbal and reasoning tasks", "content": "In March 2023 OpenAI provided a detailed overview of the advancement concerning the performance of ChatGPT in various university-level exams and aptitude tests, with a noticeable improvement that had been achieved from GPT-3.5 to GPT-4 (OpenAI, 2024). Most of the offered data indicated that, when academic and professional exams are concerned, GPT-4 predominantly scores in the range from the 80th to 100th percentile when compared to human test-takers. However, despite the rapid and continuous evolution of LLMs, it must also be observed that such favorable results were not reported for ChatGPT/GPT-4 in one review study published in 2024 (Newton and Xiromeriti, 2024).\nThe technical evolution of ChatGPT from GPT-1 to GPT-4 in the 2018 to 2023 period (a comprehensive overview is obtainable in Wu et al., 2023) has been paralleled by a remarkable increase in its emergent abilities in human-like reasoning (see: Hagendorff et al., 2023). In that respect, evidence from peer-reviewed and published research includes one study that compared ChatGPT (version: January 9, 2023) to human subjects in diverse problem-solving tasks to find no substantial advantage for either (Orr\u00f9 et al., 2023), and another study that found that GPT-3 can be similar or even above the level of human participants in analogical reasoning tasks (Webb et al., 2023). However, it is noticeable that, during the evolution of LLMs, in the tasks associated with intelligence testing with the use of verbal/textual items most new generations of LLMs have progressed in quantum leaps (for example, regarding the advancement from GPT-3.5 to GPT-4; see: McIntosh et al., 2024). Several articles without scholarly peer review have indicated that LLMs have the potential to surpass most human subjects in specific intelligence tests: King (2023), Klein & Kovacs (2023), Roivainen (2023), de Souza et al. (2023), Wasilewski & Jablonski (2024). Furthermore, according to published scholarly papers with peer review, recent research has demonstrated the potential of LLMs like GPT-4 to exceed human subjects in specific divergent thinking tasks that are commonly associated with creativity, for instance, in the studies by Guzik et al. (2023) and Hubert et al. (2024). Despite potential controversies, outside the scholarly community there has been a considerable focus on the issue of humans versus LLMs regarding"}, {"title": "3 LLMs and personality research", "content": "Even though the use of LLMs like ChatGPT (and other more advanced models) in various areas of personality research is only in the initial phases, besides the efforts to decipher the personality of popular LLMs (for a brief review of this topic see: Wen et al., 2024), several important areas of interest have also emerged that will be elaborated in the continuation of this section."}, {"title": "3.1 Assessment of personality traits", "content": "A considerable number of studies have addressed the ability of LLMs to assess human personality. For instance, Rhao et al. (2023) explored this issue with imaginary personalities and tried to propose a general framework for personality assessment by LLMs. A study performed by Cao and Kosinski (2024) with GPT-3, an earlier version of ChatGPT, revealed that the way human raters perceive public figures regarding likability and Big Five personality traits can be predicted by \"their names' location in GPT-3's semantic space\". Guinn (2023) discovered that in classifying human author's writings using the Myers-Briggs Personality Type (MBPT) dimensions (i.e. Introversion-Extroversion, Intuition-Sensing, Thinking-Feeling, Judging-Perceiving) the classifications of ChatGPT (GPT-3.5) were comparable to other state-of-the-art models that used machine learning for personality type classification.\nThe same ability of GPT-3.5 and GPT-4 to predict MBPT personality dimensions was confirmed by Murphy (2024) concerning the classification of personality type that was based on the 50 most recent tweets by an individual. Also, in the latter study, GPT-3.5 and GPT-4 substantially outperformed three machine learning models at the same task. Similarly, the research conducted by Peters and Matz (2024) also suggests that GPT-3.5 Turbo and GPT-4 display a modest ability to infer Big Five personality traits from social media posts of Facebook users without being previously trained for that purpose (in contrast to machine learning models), even though the accuracy of the LLMs in that study was slightly lower than that of models that were specifically trained for that purpose. Ji et al. (2024) revealed a rather high ability of GPT-3.5 Turbo to predict HEXACO personality dimensions (i.e. Honesty-Humility, Emotionality, Extraversion, Agreeableness, Conscientiousness, and Openness to Experience) from basic persona descriptions. In addition, Ji et al. (2023) explored the ability of ChatGPT for personality recognition from human text (essays and tweets) and found that it was capable of providing predictions of Big Five personality traits (i.e. Openness, Conscientiousness, Extraversion, Agreeableness, and Neuroticism) that are comparable to other automated models, while also supplementing these predictions with natural language explanations and logical reasoning. However, the study performed by Derner et al. (2023) uncovered only rather low correlations between the self-assessment of subjects on the one side, and Big Five personality predictions made by GPT 3.5 from their short texts, on the other."}, {"title": "3.2 Desirability rating of personality items", "content": "Phillips and Robie (2024) investigated the efficacy of utilizing LLMs to identify ideal responses in personality assessments with the use of integrity and conscientiousness measures and revealed that GPT-3.5 and GPT-4 performed better than other LLMs in that respect, as well as that they outperformed human participants (university business students) in the ability to fake responses to score highly on favorable personality traits in a job application and selection situation. It must be noted that the LLMs specially trained for sentiment analysis (other than those of the ChatGPT type) have proven comparable to human judges in desirability rating of items of self-report measures (Hommel, 2023), but are far more complicated for such use by researchers than the currently available advanced models like GPT-4o, Gemini 1.5 Pro, and Claude 3.5 Sonnet."}, {"title": "3.3 Emotion classification and understanding", "content": "Belkhir and Sadat (2023) revealed a rather high accuracy of ChatGPT in emotion classification, as well as the possibility to pre-train ChatGPT for the production of more human-like responses in empathetic conversations. The research performed by"}, {"title": "3.4 Psychiatric disorders", "content": "Finally, in the field of psychiatry (Abbas et al., 2023) there are indications that ChatGPT and Google Bard can identify various disorders (e.g. major depressive disorder, schizophrenia, obsessive-compulsive disorder, etc.) from case descriptions made by a physician based on the Diagnostic and Statistical Manual of Mental Disorders (DSM). Also, in a study by Hadar-Shoval et al. (2024), ChatGPT demonstrated mentalizing-like abilities regarding the feelings of imaginary individuals who had been attributed to possessing borderline personality disorder or/and schizoid personality disorder in various simulated situations that were designed according to the Levels of Emotional Awareness Scale."}, {"title": "3.5 Item generation for measurement of personality traits", "content": "The previous outline of selected topics related to the use of ChatGPT and other LLMs in personality research provides evidence for their capacity to (a) 'reason' about human personality traits with a considerable level of 'comprehension'; (b) based on textual input, 'detect' or 'identify' specific personality"}, {"title": "4 Goals and research questions", "content": "The main goal of the study that is presented in this paper was to explore and provide examples of several"}, {"title": "4.1 Research goal", "content": "The main goal of the study that is presented in this paper was to explore and provide examples of several means by which LLMs like GPT-4o, GPT-4, Copilot, Gemini 1.5 Pro, and Claude 3.5 Sonnet can be used for the improvement, evaluation, and design/construction of self-assessment scales in the scientific field of interpersonal communication skills. Because of the limited length of this article, only brief demonstrations and examples of potential uses of such tools will be provided. At the time this article was being completed no scholarly articles were found that extensively addressed the issue of the improvement and design of self-assessment scales for the measurement of interpersonal communication skills."}, {"title": "4.2 Research questions", "content": "The following research questions were formulated based on the previous research goal and potential benefits for scholars and educators who are involved in the process of design and evaluation of self-assessment scales in the specific field of interpersonal communication skills:\nRQ1: Can Microsoft Copilot and other LLMs be effectively used for the translation and simplification of the items of self-assessment scales?\nRQ2: Can prompts be used with GPT-4o and other advanced LLMs to categorize the items of questionnaires with multiple self-assessment scales in a form that complements their empirical evaluation using confirmatory factor analysis?\nRQ3: Can GPT-4o and other advanced LLMs be effectively utilized in activities like evaluation, improvement, and redesign of interpersonal communication skills self-assessment scales and questionnaires?\nRQ4: Can GPT-4o and other advanced LLMs generate/design new interpersonal communication skills self-assessment scales and questionnaires?\nRQ5: \"Can GPT-4o, Gemini 1.5 Pro, and Claude 3.5 Sonnet generate new scales and respective items for the measurement of interpersonal communication skills, and subsequently apply them to users in an interactive multiturn form?\""}, {"title": "5 Method", "content": "As was previously outlined, LLMs of the ChatGPT family have considerably improved in their capacity for semantic processing of textual/verbal information and also demonstrate considerable explicit and implicit knowledge in the field of human personality. Various providers of AI-based tools and services, like OpenAI, Microsoft, Google, Antrophic, and others, are competing in creating newer, increasingly more sophisticated, technically proficient, and advanced releases of their products, currently at a rate of at least once or twice a year. In conducting a research study involving LLMs, it is opportune to consider (a) currently up-to-date LLMs, as well as (b) those that are"}, {"title": "5.1 Instruments", "content": "As was previously outlined, LLMs of the ChatGPT family have considerably improved in their capacity for semantic processing of textual/verbal information and also demonstrate considerable explicit and implicit knowledge in the field of human personality. Various providers of AI-based tools and services, like OpenAI, Microsoft, Google, Antrophic, and others, are competing in creating newer, increasingly more sophisticated, technically proficient, and advanced releases of their products, currently at a rate of at least once or twice a year. In conducting a research study involving LLMs, it is opportune to consider (a) currently up-to-date LLMs, as well as (b) those that are available to other researchers. In addition, the training data (i.e. digitalized human knowledge in textual form) for LLMs like GPT-4/GPT-4o, Copilot, Gemini 1.5 Pro, and Claude 3.5 Sonnet is constantly expanding and includes a vast amount of content that is available on the internet. That means that at least some responses to the prompts delivered to LLMs trained on internet data and with real-time access to internet content may not only be the result of their capacity for semantic analysis and 'transformation' of text, but also of some form of ability to retrieve content from their \u2018memory', or as a result of concurrent internet search (as in the case of Microsoft's Copilot, for example). Furthermore, to select the currently best-performing LLMs it is recommended to consult LLM benchmarks and leaderboards (Caballar and Stryker, 2024). However, the problem remains regarding the potential LLMs' responses that are generated from \u2018memory' or internet search which may represent a 'copy' or highly resemble a solution that can be found elsewhere in an (almost) identical form, as illustrated by the following example.\nTo test the ability of Microsoft's Copilot to sort usability and user experience-related items from an assessment instrument published in an open-access online scholarly journal research paper (see: Buba\u0161 et al., 2024) in December 2023, the following prompt was given to Copilot in June 2024: \"Categorize the following items/sentences to the usability categories/variables 'Perceived Usefulness', 'General Usability', 'Learnability' and 'System Reliability' <followed by a list of 19 items:>\". Surprisingly or not, Copilot performed this categorization perfectly, with an identical order of items as in the original instrument that had been published online, also returning a link to this research paper. This indicates that in testing various \u2018abilities' of LLMs regarding the design and evaluation of items and scales for self-assessment, it may sometimes be opportune to use unpublished assessment instruments that could not have been a part of an LLMs 'training' or easily available to them by internet search.\""}, {"title": "5.1.1 Large Language Models (LLMs)", "content": "Having in mind the results of the LLM benchmarking in June 2024, as well as their other characteristics like availability, popularity, and potential for parallel use on equal tasks, the following LLMs were selected for use in case studies that are presented in this paper: GPT-4o and GPT-4 (OpenAI), Copilot (GPT-4 Turbo, Microsoft), Gemini 1.5 Pro (Google) and Claude 3.5 Sonnet (Antrophic).\nThe preferred LLM for the translation of questionnaire items from Croatian to English and their simplification (in section 6.1) was Copilot (powered by GPT-4 Turbo).\nInitial categorizations of scale items were performed with GPT-4o and sometimes replicated with the use of other LLMs.\nPrompts about different interpretations, aspects of use, and analyses of assessment scales and items were"}, {"title": "5.1.2 Self-assessment scales and questionnaires", "content": "For case studies presented in this paper, several unpublished questionnaires and self-assessment scales for the measurement of interpersonal communication skills were used which are described below.\nThe Interpersonal Communication Competence Inventory (ICCI) (Buba\u0161, 2003) is a multifaceted questionnaire designed only for research purposes with acceptable internal consistency of all self-assessment scales and concurrent validity regarding other interpersonal skills measures and the Big Five (NEO-PI) personality traits. The ICCI consists of 374 items distributed in 23 scales that are designed to measure the constructs: following Knowledge of the Communication Process, Motivation for Interpersonal Communication, Social Relaxation, Composure, Initiation of Interaction, Communication Effectiveness, Assertiveness, Interpersonal Control, Interaction Management, Adaptability, Interaction Involvement, Self-Monitoring, Decoding Skills, Nonverbal Sensitivity, Encoding Skills, Nonverbal Expressivity, Verbal Expressivity, Altercentrism / Other-orientedness, Self-Disclosure, Empathy, Support, Collaboration, and Conversational Skill. The English versions of the selected sample items for all the scales mentioned above are provided in Appendix I. The ICCI self-assessment scales were designed in 1999 (in Croatian language) based on the literature on related constructs. Since the items of the ICCI scales were never published in their Croatian or English version they can be used for zero-shot and one-shot prompting of LLMs that were not previously trained with the specific input regarding the content of the ICCI. It must be noted that almost all of the ICCI scales comprise exactly 8 positively worded and 8 negatively worded (reverse-scored) items each (except for the Motivation for Interpersonal Communication scale, which has 15 positively and 15 negatively worded items, and the Verbal Expressivity scale, which has only 8 positively worded items).\nThe four shortened versions of ICCI scales (with 4 positively worded items each) that measure the following constructs (abbreviation and respective Cronbach alpha coefficients are in brackets) comprise Verbal Expressivity (VE; \u03b1=.77), Self-Disclosure (SD; \u03b1=.70), Composure (CO; \u03b1=.75), and Conversational Skill (CS; \u03b1=.81). These short forms of selected interpersonal communication skills scales"}, {"title": "5.2 Subjects", "content": "For the empirical evaluation in form of confirmatory factor analysis (see Table 2) of four shortened versions of interpersonal communication skills scales (labeled Verbal Expressivity, Self-Disclosure, Composure, and Conversational Skill) the data was collected in the year 2022 and the subjects were first-year undergraduate students of information systems at a Croatian university (N=170; 17 to 23 years of age; 77.7% male, 19.4% female and 2.9% that did not disclose gender).\nThe data presented in Appendix II was collected using the ICCI questionnaire in 1999 (N=403). The subjects were first-year Information Systems students from the University of Zagreb in Croatia, of whom 72% were male and 28% were female."}, {"title": "5.3 Procedure", "content": "For each case study a different procedure was used to respond to the main goal of this study and research questions."}, {"title": "6 Case studies", "content": "Each of the following case studies was designed to answer one of the research questions. Using the same or similar prompts for GPT-4o and other LLMs as in the case studies researchers can replicate most of the processes in those case studies as long as the examined LLMs are available. With the ongoing advancement of LLMs novel Al products and services may considerably outperform the ones used in this research. However, most of the principles and techniques for the evaluation, improvement, and design of self- assessment scales and their items with the use of examined LLMs GPT-4/GPT-4o, Copilot, Gemini 1.5 Pro, and Claude 3.5 Sonnet, will probably also continue to be applicable with the appearance of newer and better versions of such tools/services or new LLMs like Llama (Meta AI) or Grok (xAI). Part of the focus in the presentation of the following case studies will be on the formulation and testing of useful prompts that can be utilized in the creation and evaluation of items of self-assessment scales and questionnaires in the field of interpersonal communication skills."}, {"title": "6.1 Use of LLMs for the translation and simplification of self-assessment scale items", "content": "One of the important aspects of the design and use of novel self-assessment scales is the possibility of translating them to another language to present them to an international scholarly audience and/or apply them (online) to subjects of different native language(s) and geographical location(s). Also, the authors of self- assessment scales may wish to phrase the wording of items in initial versions of their scales in a way that is simpler and easier to understand by the subjects in their research. Table 1 shows the translation by Microsoft's Copilot (in the middle column) into English of items from two previously unpublished interpersonal communication competence scales in the Croatian language (in the left-hand column) entitled (a) Verbal Expressivity and (b) Self-Disclosure. The translated English versions of the items were also used to demonstrate the simplification of those items (in the right-hand column). It has to be noted that the two scales represent a shortened (i.e. four-item) version of the original scales developed by the author of this paper, as explained earlier in subsection 5.1.2. The initial prompt for the translation task was: \"Translate the following sentences from Croatian to English. These sentences are from a self-assessment scale related to self-disclosure [verbal expressivity] in interpersonal communication: <a list of items>\". After the translation is completed, the prompt for the simplification task can, for instance, be worded in the following form: \"Now try to rephrase the following sentences to make them as easy to read and understand"}, {"title": "6.2 Use of LLMs for the categorization of items of self-assessment scales", "content": "In scale development, the confirmatory factor analysis is often used in the construct validation process to investigate the latent structure of an assessment instrument (questionnaire), i.e. to verify that the number of its hypothetical underlying dimensions and loadings of items on specific factors are in accordance with the theoretical assumptions that guided its construction (see: Brown, 2015, pp. 1-2). The items from a newly constructed and unpublished instrument (Buba\u0161, 2023) for the self-assessment of four communication skills (Verbal Expressivity, Self-Disclosure, Composure, and Conversational Skill) will be used in this section to illustrate the use of LLMs for categorization of items in parallel to conducting confirmatory factor analysis. In Table 2 the items and results of the confirmatory factor analysis are presented for the aforementioned four scales. Similar to the previous section of this paper, each of the scales represents a shortened (i.e. four-item) version of the original ICCI scales. The data were collected in the year 2022 with the Croatian versions of the scales from subjects (N=170) who were first-year university students of information systems aged 17 to 23 (average age was 19 years), 77.7% of whom were male and 19.4% of female gender (2.9% did not specify their gender).\nIt must be noted that even though this was a forced factor analysis with Varimax rotation, a four-factor latent structure was also indicated by the Kaiser-Guttman rule of preserving factors with an eigenvalue greater than one in the initial unrotated solution (having in mind the potential problems with such a criterion, as discussed in: Zwick & Velicer, 1986)."}, {"title": "6.3 Use of LLMs for the improvement of self-assessment scales", "content": "To further test GPT-4o at a much larger scale, eight positively worded items from the selected 17 self-assessment scales of the ICCI were scrambled in a circular sequence (A1, B1, C1, D1, [...], A2, B2, C2, D2, [...], A3, B3, C3, D3, ...) and placed in the following prompt (with slightly adapted labels of some scales to improve the definitions of the constructs) for GPT-40: \"Categorize the 136 items related to the following 17 categories of interpersonal communication skills: (1) Initiation of Interaction, (2) Verbal Decoding of Messages, (3) Nonverbal Sensitivity, (4) Adaptability in Communication, (5) Composure in Interaction, (6) Self-Disclosure, (7) Empathy, (8) Comforting and Support, (9) Verbal Messages Encoding Skill, (10) Nonverbal Expressivity, (11) Verbal Expressivity, (12) Interaction Involvement, (13) Self-Monitoring, (14) Conversational Skill, (15) Assertiveness, (16) Interpersonal Control, (17) Interaction Management. Place exactly 8 items in each category by choosing the semantically most similar items that best describe the skill that labels the category. Use each item only once. Here are the items: <a sequence of 136 items completes this prompt>\". This was a somewhat ambiguous task due to certain overlap between the following sets of skills in actual communication behaviors that contribute to those skills: (a) Empathy & Comforting and Support; (b) Assertiveness & Interpersonal Control & Interaction Management; (c) Verbal Messages"}, {"title": "6.4 Design of new self-assessment scales using LLMs", "content": "As was mentioned earlier, in the field of personality psychology the possibility to generate Big Five personality items for self-assessment scales was demonstrated using GPT-3 (Lee et al., 2023) with a selection of final items by human evaluators, as well as with the use of more advanced ChatGPT to create a 'ready to use' short version of the Big Five measure with a single prompt (Walton and Anguiano-Carrasco, 2024) without human expert intervention in the measure generated by ChatGPT. It must be noted that Franco-Mart\u00ednez et al. (2023) illustrated how prompts for LLMs can be used for generating items for the measurement of non-cognitive constructs. Correspondingly, it can be assumed that advanced LLMs like GPT-4/GPT-4o, Copilot (GPT-4 Turbo), Gemini 1.5 Pro, and Claude 3.5 Sonnet can also be utilized for generating items for interpersonal communication skills self-assessment scales.\nFor instance, testing of the capacity of LLMs to generate a new short-form personality self-assessment measure that is related to interpersonal communication, without any preparation of the LLM (e.g. with a zero-shot prompt), but with the use of the International Personality Item Pool (IPIP) for model items (IPIP, 2023) and with a specific choice of"}, {"title": "6.5 Automated application and scoring of self-assessment scales with LLMs", "content": "LLMs like GPT-4o, GPT-4, Copilot, Claude 3.5 Sonnet, and Gemini 1.5 Pro are essentially very advanced forms of chatbots or multi-turn dialogue systems (see: Yi et al., 2024). Some benchmarking studies have found GPT-3.5 and GPT-4 to outperform other LLMs in multiturn tasks (see: Kwan et al., 2024; Chen et al., 2023), but they did not include evaluations of Gemini 1.5 Pro and Claude 3.5 Sonnet. In this section, the potential to use a single prompt to instruct LLMs to perform the design and application of new interpersonal skills scales (or questionnaires) will be briefly demonstrated. It must be emphasized that, for this purpose, it is opportune to use at least one-shot or, preferably, multiple-shot prompting to ensure a better-quality new self-assessment instrument. Also, at the current level of LLM development and without proper ethical guidance it is recommended to employ an LLM for the automated application of interpersonal skills scales only for exploring the capacities of a particular LLM while avoiding any diagnostic use or interpretations except for research purposes.\nHere is a general form of a potential zero-shot prompt that worked well with almost all the LLMs that were examined (i.e. GPT-4o, GPT-4, Gemini 1.5 Pro, Claude 3.5 Sonnet): \"Using the best possible items for self-assessment of the communication skill 'Active Listening' create a brief new scale with 10 items regarding the use of active listening in everyday communication. Use a 1 to 5 Likert scale ranging from '1 = Not at all true of me' to '5 = Very true of me' for collecting responses. After you have created this new scale, ask me one by one questions and wait for my answers from 1 to 5. When you receive my responses"}, {"title": "6.6 Practical advice regarding the use of LLMs for translation, evaluation, improvement, and design of new self-assessment scales", "content": "Effective use of LLMs commonly requires some practice and experience. Expert advice is also beneficial, as well as learning from exemplary prompts that can be found in the instructions of the providers of LLMs for their use, on the web, and in other resources (e.g. templates, guides, and tutorials for prompt engineering). In various sections of this paper, a collection of useful prompts is provided for specific objectives which, however, only represent a sample of a wide variety of potential prompts that can also serve a similar purpose.\nVarious LLMs may demonstrate an advantage in different particular tasks. For instance, with its responses to the prompts Copilot often provided potentially useful links to related web pages. Also, GPT-4o, Gemini 1.5 Pro, and Claude 3.5 Sonnet could perform more sophisticated dialogues about interpersonal communication skills and constructs compared to less advanced LLMs. Easy access to archives of previous dialogues with an LLM can also be beneficial for different purposes, as well as the"}, {"title": "7 Summary and discussion", "content": "The main goal of the study that is presented in this paper was to explore and provide examples of several procedures by which LLMs like GPT-4o, GPT-4, Copilot, Gemini 1.5 Pro, and Claude 3.5 Sonnet can be used for the improvement, evaluation, and design/construction of self-assessment scales in the scientific field of interpersonal communication skills.\nIn section 1 of this paper named \u201cIntroduction\" a brief overview of the literature is provided regarding the potential of using ChatGPT and other more advanced LLMs in various phases and fields of academic research (Chukwuere, 2024), including specific areas like STEM motivation (Donmez et al., 2023), adoption of AI in higher education (Rahman et al., 2023), and teacher technostress (Khlaif et al., 2023). Also, there has been a rapid increase in the use of LLMs for psychology applications (Ke et al., 2024). In this paper the LLMs have proved to be beneficial in the specific scientific field of design and improvement of self-assessment scales for the measurement of interpersonal communication skills.\nA very high capacity to process textual verbal content is necessary if LLMs are utilized to design and improve self-assessment scales. This 'cognitive' ability of LLMs was previously illustrated in section 2"}, {"title": "8 Conclusion", "content": "Even though some reflection upon ethical concerns regarding LLMs have been listed in subsection 6.6 entitled \"Practical advice regarding the use of LLMs for translation, evaluation, improvement, and design of new self-assessment scales\", the topic of ethics and LLM (mis)use is so broad and well elaborated in literature (for instance, see: Strasser, 2024; Pournaras,"}, {"title": "9 Limitations of research", "content": "The most important limitation of the research presented in this paper, as well as of other cited research that is published in preprint archives (arXive, SSRN, etc.), is that it has not been peer-reviewed. Only for some of the cited research papers published on preprint servers the information about the conference at which they were listed in the program has been obtained and provided in the list of references, while for other cited preprint papers there is no evidence of peer review.\nAs was the case with several studies that addressed the early versions of LLMs like GPT-2, GPT-3, ChatGPT, and Bard, novel LLM technologies (GPT- 4o, Gemini 1.5 Pro, Claude 3.5 Sonnet) tend to appear in a year or two or less, outperforming the existing ones. Therefore, with the introduction of more advanced LLMs some of the case studies, examples, observations and conclusions that are presented in this research paper may cease to be up-to-date. Also, new research papers are being rapidly produced with findings that may also outdate some of the LLM- related papers that were cited here, even though most of these were published from 2023 until the end of July 2024. However, the potential of using LLMs in evaluating and improving existing interpersonal communication skills questionnaires will probably continue to be a valuable research and applied topic for some time in the future.\nMost of the case studies presented in this paper were conducted using multiple LLMs. Therefore, if"}, {"title": "10 Declaration of conflict of interest and use of Al in research", "content": "The author declares that there is no conflict of interest and that (a) this research was not funded by any AI-related project, public or private enterprise, and (b) the research was conducted as part of the authors' scientific research obligation associated with employment at a higher education institution.\nEach instance of Al usage in the case studies is denoted in the text of this paper (with a clear indication of the LLM employed for a particular case study). Also, Al was not used for literature search, writing of any part of the text of this paper, or for its translation, except for the translation from Croatian to English of the items displayed in Table 1 and Table 2, where using LLMs for translation was associated with the corresponding research question."}]}