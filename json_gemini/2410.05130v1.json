{"title": "SCALABLE AND ACCURATE GRAPH REASONING WITH LLM-BASED MULTI-AGENTS", "authors": ["Yuwei Hu", "Runlin Lei", "Xinyi Huang", "Zhewei Wei", "Yongchao Liu"], "abstract": "Recent research has explored the use of Large Language Models (LLMs) for tackling complex graph reasoning tasks. However, due to the intricacies of graph structures and the inherent limitations of LLMs in handling long text, current approaches often fail to deliver satisfactory accuracy, even on small-scale graphs and simple tasks. To address these challenges, we introduce GraphAgent-Reasoner, a fine-tuning-free framework that utilizes a multi-agent collaboration strategy for explicit and precise graph reasoning. Inspired by distributed graph computation theory, our framework decomposes graph problems into smaller, node-centric tasks that are distributed among multiple agents. The agents collaborate to solve the overall problem, significantly reducing the amount of information and complexity handled by a single LLM, thus enhancing the accuracy of graph reasoning. By simply increasing the number of agents, GraphAgent-Reasoner can efficiently scale to accommodate larger graphs with over 1,000 nodes. Evaluated on the GraphInstruct dataset, our framework demonstrates near-perfect accuracy on polynomial-time graph reasoning tasks, significantly outperforming the best available models, both closed-source and fine-tuned open-source variants. Our framework also demonstrates the capability to handle real-world graph reasoning applications such as webpage importance analysis.", "sections": [{"title": "1 INTRODUCTION", "content": "Graphs, as a crucial data structure for modeling complex real-world relationships, are ubiquitous across various scenarios, e.g. citation networks, recommendation networks. Many important applications like drug discovery (Stokes et al., 2020), traffic forecasting (Jiang & Luo, 2022), and financial detection (Motie & Raahemi, 2024), require reasoning over graphs to be realized. Noticing the powerful general knowledge and language processing capabilities of Large Language Models (LLMs) (Brown et al., 2020), a significant amount of works have focused on using LLMs to perform various reasoning tasks, such as mathematical formula derivation (Meadows et al., 2023), commonsense reasoning (Madaan et al., 2022), and multi-hop question answering (Creswell et al., 2023). However, most of them primarily involve shallow or sequential reasoning. To bring the LLM reasoning closer to human thinking, it is necessary for LLMs to master deeper and more complex reasoning, such as graph reasoning.\nDespite significant efforts by researchers to enable LLMs to memorize, comprehend, and perform basic reasoning on graph structures, several issues still persist: 1) The scale of graphs that can be handled is limited. Describing graph structures in natural language inevitably leads to excessively long inputs. Due to context length limitations and the shortcomings of LLMs in handling lengthy text (Liu et al., 2023), previous works (Chai et al., 2023; Fatemi et al., 2024; Perozzi et al., 2024) could only handle graphs of very limited size (e.g. fewer than 20 nodes and 100 edges). 2) The performance on graph reasoning tasks is relatively poor. Unlike text, which can tolerate some degree of semantic deviation, reasoning and computation on graphs must be highly precise. However, current works demonstrate poor accuracy (average 20~60%) in various graph reasoning tasks like"}, {"title": "2 PRELIMINARIES AND RELATED WORKS", "content": "Preliminaries. In general scenarios, when discussing LLMs solving graph reasoning problems, the input is a $(G,Q)$ pair. G is a graph represented as $G = (V,E, \\{s_i\\}, \\{t_i\\})$, where V is the node set and E, the edge set. For each node $v_i \\in V$, a sequential text node feature $s_i$ is associated; similarly, for each edge $e_i \\in E$, a sequential text edge feature $t_i$ is assigned. The graph G is described in natural language, typically using edge or adjacency list representation. Q is a task-specific instruction or problem description. LLMs will process the (G,Q) pair and return an answer string A.\nLarge Language Models for Graph Reasoning. To further enhance the reasoning capabilities of LLMs, many works have attempted to improve the performance of LLMs in graph reasoning. Wang et al. (2023) first introduces the NLGraph Benchmark to evaluate the performance of LLMs on various graph reasoning tasks. Fatemi et al. (2024) explores the impact of different graph encoding methods and graph structure types on the performance of LLMs in graph reasoning tasks. Additionally, it introduces another benchmark called GraphQA. Considering the lengthy nature of describing graph structures in text, Chai et al. (2023) and Perozzi et al. (2024) respectively use Transformers and GNNs to encode graph structures and attempt to align them with LLMs. Inspired by how humans understand structural information through the visual modality, Wei et al. (2024) generates corresponding visual images based on graph structures and provides them to visual LLMs for graph reasoning. Chen et al. (2024a) conducted Supervised Fine-Tuning and Directly Prefered Optimization on LLMs, enhancing the performance of LLMs and encouraging them to output explicit reasoning paths.\nLarge Language Model based Multi-Agents. Recent advancements in LLMs have spurred interest in their application within multi-agent systems. LLM-based multi-agent frameworks leverage the natural language understanding and reasoning capabilities of LLMs to enable agents to collaborate, communicate, and solve complex tasks in a distributed manner. Existing multi-agents works for problem solving primarily focuses on applications such as Software Development (Dong et al., 2023; Hong et al., 2024; Qian et al., 2024), Embodied Agents (Zhang et al., 2024; Mandi et al., 2024; Chen et al., 2024b) and Science Debate (Xiong et al., 2023; Chan et al., 2024). However, using LLM-based multi-agents to handle graph data has been less explored, especially in the areas of graph reasoning and graph computation tasks. This may be due to the hallucination issue inherent in LLMs (Huang et al., 2023), where their responses are factually incorrect. This problem becomes more complex in a multi-agent setting, as the hallucinations of a single agent may propagate to other nodes by communication (Guo et al., 2024). This requires the performance of individual agents be sufficiently stable to ensure the correct operation of the entire multi-agent system."}, {"title": "3 LIMITATIONS OF SINGLE LLM IN GRAPH REASONING", "content": "Although LLMs exhibit strong language processing and logical reasoning capabilities, problems with the Transformer architecture and Attention mechanism (Vaswani et al., 2017) still limit the scale and accuracy when they process graph problems. There are two primary limitations:\nThe graph structure is too complex to memorize and understand for a single LLM. Using adjacency or edge lists to describe graph structures in natural language is the most intuitive and direct method, facilitating the processing of graph data by LLMs through text. However, this approach inevitably leads to a lengthy context, as the number of edges can grow quadratically with the number of nodes. As the graph scales up and becomes denser, the graph structure becomes highly complex, requiring a large amount of tokens to describe the edge relationships. When the text becomes too lengthy, it becomes difficult for LLMs to properly allocate attention, and they may even struggle with simple tasks such as key-value pair matching Liu et al. (2023). This presents significant challenges for LLMs in identifying key information for graph reasoning tasks from the lengthy context.\nFurthermore, the graph structure is described in a sequential manner. LLMs have to identify implicit graph structures from sequential text. Since the processing of LLMs is a black-box operation, it is difficult to assert that they truly construct graph structures implicitly and thereby understand them. Huang et al. (2024) conducted extensive experiments to explore whether LLMs treat the input prompts as graphs or merely as paragraphs with keywords on TAGs. The results show that the performance of LLMs in handling TAGs primarily stems from the context rather than the graph structure. LLMs tend to process the graph description as linearized paragraphs rather than graphs.\nA single LLM struggles to solve reasoning problems in real-world scenarios. Researchers train LLMs on graph reasoning tasks to empower them to utilize learned graph-related knowledge or algorithms to tackle real-world graph problems. However, in practical scenarios, the amount of information associated with each node can be enormous. Take citation networks as an example: a single node represents a paper, and its node information includes the title, abstract, and references, which could amount to several thousand tokens. In addition to the complexity of graph structures, the need to handle a large amount of node information further exacerbates the burden on a single LLM and highlights its shortcomings in processing long contexts. Moreover, using a single LLM to handle the entire network is inefficient, as it cannot coherently process the entire network's problems. Typically, it is necessary to manually compress or summarize the information for each node and then feed local subgraphs to the LLM for processing (Guo et al., 2023; Chen et al., 2023).\nFurthermore, many current works (Chen et al., 2024a; Perozzi et al., 2024) require training GNNs or fine-tuning LLMs on individual or multiple graph reasoning tasks. However, when transferring to other graph tasks, a certain degree of performance degradation occurs, and retraining or fine-tuning for new graph tasks consumes a significant amount of time and resources. Whether LLMs can apply the graph knowledge and algorithms learned during the training process to actual graph reasoning also remains an open question. We explored this question in 5.3 and observed significant overfitting in LLMs fine-tuned on specific graph reasoning tasks. Therefore, the ideal solution would be to leverage the powerful general knowledge acquired during the pre-training phase of LLMs through an appropriate approach, enabling them to handle graph reasoning tasks as naturally as they do with natural language problems."}, {"title": "4 GRAPHAGENT-REASONER", "content": "To solve the limitations above, we propose a novel framework based on multi-agent collaboration called GraphAgent-Reasoner as shown in Figure 3, aiming to solve graph reasoning problems explicitly and correctly. The interface of the framework is a Master LLM, which is responsible for processing the textual input of graph problems, constructing the agent network, directing them to collaboratively solve the problem, and finally aggregating the states of all agents to derive the solution. Its implementation is based on the React Agent proposed by Yao et al. (2023), which is capable of reasoning based on the environment and executing corresponding actions, as detailed later. The pipeline of GAR consists of four steps: Graph Construction, Algorithm Establishing, Distributed Execution and Master Summarization.\nGraph Construction. Given an input pair (G, Q), the Master LLM first extracts the node and edge information from the textual description of graph G. It then constructs an agent for each node and initializes the node's state and neighbor information, forming an interconnected network of agents."}, {"title": "Algorithm Establishing", "content": "Each agent independently maintains its state and neighbor data, communicates with adjacent agents based on instructions from the Master LLM, and updates its state in each round.\nAlgorithm Establishing. To accommodate diverse graph tasks and fully exploit the knowledge embedded in LLMs during pre-training, we propose a unified solution approach framed within a distributed paradigm as shown in Algorithm 1. This approach requires the Master LLM to specify six core components for each problem: State, Message, Initialization, Send, Update, and Termination.\n\u2022 State: The local information maintained by each node, representing its current state. This can include attributes like node features, labels, or any other task-specific data. The states evolve as nodes receive messages and update their information.\n\u2022 Message: The data transmitted between nodes during the communication phase. Messages typically contain information that neighboring nodes need to perform updates, such as feature values, distances, or other task-relevant information.\n\u2022 Initialization: At the start of the execution, each node initializes its state with predefined values, which may be based on node IDs, input features or task-specific requirements. This step ensures that the graph is ready to begin the communication process.\n\u2022 Send: After initialization, each node generates messages based on its current state and sends them to its neighboring nodes. This step is repeated in each iteration, allowing nodes to continuously exchange information with their neighbors.\n\u2022 Update: Upon receiving messages from its neighbors, each node updates its state by aggregating the incoming messages and combining them with its current state. This iterative process enables nodes to refine their information over time.\n\u2022 Termination: The algorithm halts when a predefined stopping condition is met, such as reaching a fixed number of iterations, achieving convergence, or satisfying a task-specific criterion. Once the termination condition is reached, each node will send its final state to the Master LLM, and the execution terminates.\nSince LLMs lack prior knowledge of this distributed paradigm, to facilitate the Master LLM's understanding and application of the framework, we develop a distributed algorithm library that adheres to this distributed paradigm, from which the Master LLM can query relevant algorithm templates to generate distributed solutions within this paradigm. Specifically, we selected classic distributed graph algorithms and documented their implementations under this distributed paradigm. Some examples are presented in Appendix A.1. Drawing on prior work (Zheng et al., 2024; Meng et al., 2024a), we endeavor to write detailed reasoning steps of each part in the algorithm to encourage"}, {"title": "5 EXPERIMENTS", "content": "In this section, we summarize the key experiments conducted with GAR. We begin by highlighting some of the most exciting results from our analysis here:\n\u2022 R1: GAR achieves near-perfect accuracy on polynomial-time graph reasoning problems, significantly surpassing existing closed-source models and open-source models fine-tuned on extensive data.\n\u2022 R2: GAR maintains high accuracy on larger-scale graphs (up to 1000 nodes), demonstrating superior scalability. In contrast, as the number of nodes increases, other models exhibit a significant decline in performance or become incapable of handling the problem at all due to the context length limitation.\n\u2022 R3: GAR showcases a robust understanding and application of graph algorithms in real-world graph reasoning scenarios, highlighting its potential for addressing complex graph problems encountered"}, {"title": "5.1 EXPERIMENT 1: PERFORMANCE ON GRAPHINSTRUCT", "content": "In this experiment, we evaluate the performance of GAR on polynomial-time tasks of the GraphInstruct dataset. Problems that a single LLM struggles to solve have been effectively resolved through collaboration by agents after being decomposed into smaller, node-centric tasks.\nAs the number of nodes increases, the graph structures become more complex, making the solution of graph problems increasingly difficult. To investigate how the performance of models varies with increasing problem complexity, we conduct experiments on cycle detection and shortest path problems, gradually increasing the number of nodes from 5 to 100.\nWe see with the number of nodes increasing, both ChatGPT-4 and Graphwiz exhibit a significant decline in performance. However, the accuracy of GAR remains stable, almost unaffected by the graph size, demonstrating robust scalability. Although the scale of the graph is increasing, the information processed by each agent has not significantly increased. Each agent still only handles its own information and communicates with neighboring agents. We observe that GAR occasionally makes errors in specific cases, likely due to the increasing communication rounds as the number of nodes and edges grows. Even when handling simple node-centric tasks, a single agent still has the potential to make mistakes. Therefore, as the number of agents and communication rounds increases, the overall likelihood of errors also rises. This can be improved by enhancing the capability of individual agents (such as using stronger LLMs as the underlying reasoning model) or by more finely designed prompts."}, {"title": "5.2 EXPERIMENT 2: PERFORMANCE ON LARGE-SCALE GRAPHS", "content": "In this experiment, we evaluate the performance of current LLMs on large-scale graphs. The largest graph size handled by existing graph reasoning work is 100 nodes (Chen et al., 2024a), which is still far from sufficient for real-world graph reasoning scenarios. To evaluate the reasoning performance"}, {"title": "5.3 EXPERIMENT 3: CASE STUDY", "content": "In this experiment, we explore the application of two graph reasoning models, Graphwiz and GAR, in real-world graph reasoning scenarios. We present a case study of webpage importance analysis in Figure 5.\nAlthough GraphWiz performed well on fine-tuned tasks, it exhibits severe overfitting when faced with real-world graph problems, failing to apply the graph reasoning knowledge learned during the fine-tuning phase. Since GraphWiz uses a consistent graph node description, the sentence \"The nodes are numbered from 0 to ...\" appears across all datasets during the mixed-task instruction tuning. When the actual problem has nodes numbered from 1 to 20, it still assumes the existence of node 0. As a result, both GraphWiz models first output that the graph has 21 nodes and an incorrect number of edges. Furthermore, neither of the two GraphWiz models recognizes that this is a problem associated with web page importance ranking. Instead, they approach it as the bipartite graph check or topological sort problems they had been fine-tuned on. Additionally, neither model generates an explicit and correct reasoning path. These observations indicate that there is still a significant gap"}, {"title": "6 CONCLUSION", "content": "We first summarize three key issues faced by existing LLMs in graph reasoning tasks: limited graph scale, poor performance, and the lack of explicit reasoning paths. We then reflect on the limitations of a single LLM in addressing graph reasoning problems, such as the graph structures being too complex to memorize and understand and the overwhelming information in real-world graph reasoning scenarios. To address these challenges, we propose GraphAgent-Reasoner, a framework based on multi-agent collaboration to solve graph reasoning problems. This framework demonstrates superior accuracy and scalability, significantly surpassing existing closed-source and fine-tuned open-source models. Our experiments show its robust scalability, maintaining high accuracy on large graphs (up to 1,000 nodes). Our case study on webpage importance analysis further illustrates its capability to handle real-world graph reasoning problems. Future work will focus on designing more accurate and scalable LLM-based multi-agent graph reasoning frameworks, aiming to apply them to larger and more complex real-world reasoning scenarios."}]}