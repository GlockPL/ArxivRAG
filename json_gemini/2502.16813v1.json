{"title": "Snoopy: Effective and Efficient Semantic Join Discovery via Proxy Columns", "authors": ["Yuxiang Guo", "Yuren Mao", "Zhonghao Hu", "Lu Chen", "Yunjun Gao"], "abstract": "Semantic join discovery, which aims to find columns in a table repository with high semantic joinabilities to a given query column, plays an essential role in dataset discovery. Existing methods can be divided into two categories: cell-level methods and column-level methods. However, both of them cannot simultaneously ensure proper effectiveness and efficiency. Cell-level methods, which compute the joinability by counting cell matches between columns, enjoy ideal effectiveness but suffer poor efficiency. In contrast, column-level methods, which determine joinability only by computing the similarity of column embeddings, enjoy proper efficiency but suffer poor effectiveness due to the issues occurring in their column embeddings: (i) semantics-joinability-gap, (ii) size limit, and (iii) permutation sensitivity. To address these issues, this paper proposes to compute column embeddings via proxy columns; furthermore, a novel column-level semantic join discovery framework, Snoopy, is presented, leveraging proxy-column-based embeddings to bridge effectiveness and efficiency. Specifically, the proposed column embeddings are derived from the implicit column-to-proxy-column relationships, which are captured by the lightweight approximate-graph-matching-based column projection. To acquire good proxy columns for guiding the column projection, we introduce a rank-aware contrastive learning paradigm. Extensive experiments on four real-world datasets demonstrate that Snoopy outperforms SOTA column-level methods by 16% in Recall@25 and 10% in NDCG@25, and achieves superior efficiency-being at least 5 orders of magnitude faster than cell-level solutions, and 3.5x faster than existing column-level methods.", "sections": [{"title": "I. INTRODUCTION", "content": "The drastic growth of open and shared datasets (e.g., government open data) has brought unprecedented opportunities for data analysis. However, when confronted with massive datasets, users often struggle to find relevant ones for their specific requirements [1]. Hence, the data management community has been developing dataset discovery systems to find related tables given a query table [2].\nIn this work, we focus on semantic join discovery. Given a table repository T, a query table TQ with the specified column CQ, semantic join discovery aims to find column C from T that exhibits a large number of semantically matched cells between column C and CQ. Thus, the table with the column C can be joined with the query table TQ to enrich the features for data analysis/machine learing tasks."}, {"title": "II. PRELIMINARIES", "content": "In this section, we first present the the scope of semantic join discovery, and then provide the problem statement.\nOur goal is to design a framework that takes a query column as input, and searches for the top-k semantically joinable columns from a large table repository. Then, it is easy to locate the tables with these joinable columns. How to find the best way of joining column elements after discovery, as explored in studies [3]\u2013[5] is out of our scope. Note that, the join relationship is not a simple binary relationship (i.e., joinable or not joinable); rather, it often involves determining which column is more joinable to the query. Since performing join is time-consuming, users and data scientists prefer to prioritize columns with higher joinability, rather than considering all columns labeled as joinable without any indication of their relative join probabilities. Thus, it is beneficial for discovery methods to return the top-k columns ranked by joinabilities.\nGiven a table repository T, each table T\u2208T consists of several columns {C1,C2,...,C|T|}, where |T| denotes the number of columns in T. In this paper, we focus on textual columns, following the recent study [11]. For simplicity, we extract all the textual columns from T into a column repository R = {C1, C2, ..., C|r|}. Each column Ci consists of a set of cells {ci}. Since metadata (e.g., column names) are typically missing or incomplete in real scenarios [14], we rely solely on cell information.\nDefinition 1. (Column Matrix). Given a column C = {C1, C2,\u2026\u2026,Cn}, and a cell embedding function h(.) which transforms each ci \u2208 C to an embedding c\u2081 = h(ci) \u2208 Rd, we extend the notation of cell embedding function h(.) to represent the column matrix C = h(C) = {C1, C2, ..., Cn}.\nDefinition 2. (Cell Matching). Given two cells Ci and Cj, and the corresponding cell embeddings ci and cj, we denote ci matches cj as ci \u2243 cj if and only if d(ci, c\u2081) \u2264 7, where d(\u00b7) is a distance function, and 7 is a pre-defined threshold.\nDefinition 3. (Semantic Joinability). Given a query column CQ from a table TQ, and a column C\u2208 R, semantic joinability [10], [11] from CQ to C is defined as follows:\n\\(J(CQ, C) = |\\{cq \u2208 CQ | \u2203c \u2208 C s.t. cq = c\\}| / |CQ| \\)   (1)\nWith the definition of semantic joinability measure, we can now formalize the problem we aim to solve.\nProblem 1. (Top-k Semantic Join Discovery)\u00b9. Given a query column CQ from a table TQ, and a column repository R, top-k semantic join discovery aims to find a subset SCR where |S| = k and \u2200C\u2208 S and C'\u2208R-S, J(CQ, C) \u2265 J(CQ, C').\nEqui-join discovery can be viewed as a specific case of semantic join discovery by setting the threshold \u03c4 in Definition 2 to 0."}, {"title": "III. PROXY COLUMNS", "content": "As mentioned in Section I, it is beneficial to model c2c joinabilities. However, it is time-consuming to perform online computations to assess the relationship of the query column with each column in the repository. To tackle this, we introduce the concepts of proxy column and proxy column matrix.\nDefinition 4. (Proxy Column). Given a column space C which is a collection of textual columns, a proxy column P = {P1,P2,...,pm} \u2208 C is a representative one, based on which, each column in the repository R can pre-compute the relationships with proxy columns.\nDefinition 5. (Proxy Column Matrix). Given a proxy column P = {P1,P2,...,pm} and a cell embedding function h(\u00b7), the proxy column matrix P = h(P) = {P1,P2,\u2026\u2026,pm} \u2208 Rm\u00d7d, where pi \u2208 Rd.\nNote that the specific column repository R is just a subset of the column space C. Since Snoopy requires the column matrix and proxy column matrix as inputs (detailed later), we define the proxy-guided column projection given a proxy column matrix as follows.\nDefinition 6. (Column Projection). Given a proxy column matrix P, the proxy-guided column projection is a function \u03c0P(\u00b7), which projects a column matrix C to \u03c0P(C) \u2208 Rl indicating the value of a specific dimension in the column embedding space Rl.\nBased on the column projection, we can obtain the column embeddings. Specifically, given a set of proxy column matrices P = {P1, P2, . . ., Pl} \u2208 Rl\u00d7m\u00d7d, the column embedding of C is denoted as \\(\u03a6(C) = [\u03c0P1 (C), \u03c0P2 (C), . . . \u03c0Pl (C)] \u2208 Rl\\)."}, {"title": "IV. THE SNOOPY FRAMEWORK", "content": "In this section, we first overview the Snoopy framework. Then, we design the column representation via proxy column matrices, and present a rank-aware contrastive learning paradigm to obtain good proxy column matrices. After that, we illustrate the index and online search process. Finally, we devise two training data generation strategies for self-supervised training."}, {"title": "B. Column Representation", "content": "The effectiveness of column-level methods highly depends on column representations. However, existing methods just adopt suboptimal PTMs as column encoders, and the desirable properties of column representations for column-level methods remain under-explored. Thus, we first formalize several desirable properties of column representations, and then propose the AGM-based column projection to deduce the column embeddings.\n1) Desirable Properties: We provide some key observations based on the definition of joinability and formalize the desirable properties of column representations for column-level semantic join discovery.\nThe first observation is that each cell in the column may contribute to the joinability score. Consider the example in Fig. 1, the joinability between CQ and C1 is 3=1. If we neglect any cell in the C1, the join score declines. This observation implies that the column embedding function should consider all the cells within the column and not be constrained by the column size, which is formalized as follows.\nProperty 1. (Size-unlimited). Given a column C = {C1, C2, ...,cn} \u2208 R, which is the input of the embedding function f : R \u2192 Rl, the size n of the input column C is arbitrary.\nThe second observation is that the joinability between two columns is agnostic to the permutations of cells within each column. For instance, if we permute the column CQ in Fig. 1 from {\u201cLos Angeles\u201d, \u201cNew York\u201d, \u201cWashington\u201d} to {\u201cWashington\u201d, \u201cLos Angeles\u201d, \u201cNew York\u201d}, the joinability between CQ and C1 is still 3=1. This suggests that the column embedding should be permutation-invariant, which is formalized as follows.\nProperty 2. (Permutation-invariant). Given a column C = {C1, C2,..., Cn}, and an arbitrary bijective function \u03b4 : {1,2,..., n} \u2192 {1,2,..., n}, a permutation of column C is denoted as \\(\u0108 = {C\u03b4(1), C\u03b4(2),..., C\u03b4(n)}\\). The column representation is expected to satisfy:\n\\(f(C) = f(\u0108)\\) (2)\nRecall that the column-level methods return the top-k results through the similarity comparison of column embeddings. Hence, an ideal column embedding function f(\u00b7) needs to preserve the ranking order of columns as determined by their joinabilities in Definition 3.\nProperty 3. (Order-preserving). Given a query column CQ, two candidate columns C1 and C2, the joinability J(\u00b7) as defined in Definition 3, and the column-level similarity measurement sim(\u00b7), the ideal column representation satisfies:\n\\(sim (f (CQ), f (C1)) \u2265 sim (f (CQ), f (C2))\\) \\(\\Rightarrow J (CQ, C1) \u2265 J (CQ, C2)\\) (3)\nThe property 3 is the ultimate goal ensuring that column-level methods achieve the same effectiveness as exact solutions. However, it is challenging to achieve this due to the inevitable information loss resulting from coarse computations at the column level. Thus, we design a training paradigm to learn good proxy column matrices capable of deriving column representations that approximate this goal (Section IV-C). Note that the defined joinability in Definition 3 relies on a cell embedding function h(\u00b7). If h(\u00b7) is inferior, then the ground truth in evaluation and the learned column embedding function f() may be affected. In this paper, we follow [10] to employ fastText [16] as a cell embedding function, and show how the ground truth shifts when adopting different cell embedding functions (see Section V-F).\n2) AGM-based Column Projection: In order to consider all the cells within the column C, Snoopy first transforms it into the column matrix C = h(C) by the cell embedding function h(.). Then, it computes the column representation using C as the input. The cell embedding function h() is utilized to capture the cell semantics, so that the cells that are not exactly the same but semantically equivalence can be matched and contribute to the joinability. Several alternatives are available for the cell embedding function, including pre-trained language models [16], [17] and models tailored for entity matching [18], [19]. Note that, designing a good cell embedding function is orthogonal to this work."}, {"title": "C. Rank-Aware Contrastive Learning", "content": "To achieve Property 3, it is crucial to identify good proxy column matrices P\u2208 Rl\u00d7m\u00d7d that can map the joinable columns closer and push the non-joinable columns far apart in the column embedding space. Traditional pivot selection methods in metric spaces [22] can be extended to select proxy columns from the given column repository R, and then derive the corresponding proxy column matrices. However, these methods are constrained in the subspace R of the column space C, and are not designed for order-preserving property, resulting in inferior accuracy (see ablation study in Section V-C). Also, it is non-trivial to directly select good proxy columns that can achieve order-preserving, as columns consist of discrete cell values. To this end, we present a novel perspective that regards the continuous proxy column matrices P\u2208 Rl\u00d7m\u00d7d as learnable parameters, and introduce the rank-aware contrastive learning paradigm to learn P guided by the order-preserving objective.\nOrder-preserving entails high similarity for joinable column embeddings and low similarity for non-joinable ones. We introduce the contrastive learning paradigm to achieve this objective. Specifically, given an anchor column C, a positive column C+ with high joinability J(C, C+), a negative column set {C}=1 with low joinabilities {J(C, C\u00a1\u00af)}=1, and the column embedding function f(\u00b7), we have InfoNCE loss [23] as follows:\n\\(L = - log  \\frac{ef(C)Tf(C+)/\u03c4}{ef(C)Tf(C+)/\u03c4 + \u2211i ef(C)Tf(Ci\u2212)/\u03c4}  \\) (9)\nwhere \u03c4 is a temperature scaling parameter and we fix it to be 0.08 empirically. Note f(C)Tf(Ci) denotes the cosine similarity, as we normalize the column embedding to ensure that ||f(\u00b7)|| = 1.\nRank-Aware Optimization. In traditional InfoNCE loss, each anchor column has just one positive column, and thus, it is difficult to distinguish the ranks of different positive columns [24]. To incorporate the rank awareness of positive columns, we introduce a positive ranking list Lc = [C++,...,C+] for each anchor C. The positive columns within Lc are sorted in descending order by joinabilities, i.e., J(C,C+) > J(C,C+) > \u00b7 \u00b7 \u00b7 > J(C,C+). During training, each column Cf \u2208 R is regarded as a positive column or pseudo-negative column. Specifically, we recursively regard Cf as a positive column and {C}+1,C++2,\u2026\u2026,C++} as pseudo-negative columns. The pseudo-negative columns, along with the true negative columns {C}=1, are combined to form the negative columns for training.\nNote that, the negative column set {C}=1 is generated from the negative queue Q, which will be detailed in Algorithm 1 later. As for the positive ranking list, we design two kinds of data generation strategies to automatically construct it (see Section IV-E). We adopt the rank-aware contrastive loss [24] Lrank = \u2211j=1lj, where lj is defined as follows:\n\\(lj = -log \\frac{ef(C)Tf(C+)/\u03c4}{Z+ \u2211r\u2265(j+1)ef(C)Tf(C+r)/\u03c4}\\) (10)\nwhere Z = \u2211 ef(C)Tf(C+)/\u03c4 + \u2211i ef(C)Tf(Ci\u2212)/\u03c4 in Equation (9). Equation (10) takes the ranks into consideration. Specifically, minimizing lj requires decreasing f(C)Tf(C++); while minimizing lj+1 requires increasing f(C)Tf(C+1). Thus, l; and lj+1 will compete for the f(C)Tf(C+). Since C++1 would be regarded as negative columns j times while Cft would be regarded as negative columns only (j-1) times, it would guide a ranking of positive columns with f(C)Tf(C++) > f(C)Tf(C+1).\nIn practice, considering the training efficiency, we freeze the cell embedding function h(\u00b7), and thus, the only learnable parameters are the proxy column matrices P = {P1, P2, ..., Pl}. Since enlarging the number of negative samples typically brings performance improvement in contrastive learning [18], we maintain a negative column queue Q with the pre-defined length \u03b2 to consider more negative columns. We present the rank-aware contrastive learning process (RCL) in Algorithm 1. At the beginning, RCL would not implement the gradient update until the queue reaches the pre-defined length \u03b2 + 1 (line 5). Next, the oldest batch is"}, {"title": "D. Index and Search", "content": "After contrastive learning, Snoopy uses the learned P to pre-compute the embeddings of all the columns in the repository R. Then, Snoopy can construct the indexes for column embeddings using any prevalent indexing techniques, to boost the online approximate nearest neighbor (ANN) search. Since graph-based methods are a proven superior trade-off in terms of accuracy versus efficiency [25], Snoopy adopts HNSW [15] to construct indexes.\nFor online processing, when a query column CQ comes, Snoopy uses the learned Pt to get f(CQ). Compared with the existing PTM-based methods, Snoopy\u2019s online encoding process is more efficient due to the proposed lightweight AGM-based column projection. Then, Snoopy performs the ANN search using the indexes constructed offline and finds the top-k similar column embeddings to f (CQ) from the Vector Storage. Finally, the corresponding top-k joinable columns in the table repository are returned. We analyze the time complexity of the online and offline stages in Appendix A."}, {"title": "E. Training Data Generation", "content": "During contrastive learning, the negative column set is generated from the negative queue Q, as most column pairs in the huge repository have low joinabilities. As for the positive columns, we design two kinds of data generation strategies. Our objective is to synthesize positive columns with expected joinability scores. In this way, we can generate a ranked positive list Lc according to given ranked scores.\nText-level Synthesis. Given a column C, we randomly divide it into two sub-columns Ca and Co. We use Ca as the anchor column, and Co as the residual column. The reason why we maintain the residual column Co will be detailed later. Now we illustrate how to synthesize a positive column C for Ca with a joinability approximated to a specified score x%.\nWe randomly sample x% cells from the anchor Ca to form a sampling column Sa. However, directly using Sa as the positive column has two shortcomings: (i) the matched cells between Ca and Sa are exactly the same, without covering the semantically-equivalent cases, and (ii) each cell in Sa can find matched cell in the anchor Ca, which is not realistic. To tackle (i), we follow [12], [26] to apply straightforward augmentation operations to each cell c\u2208 Sa in text-level. Note we should guarantee that the augmentation operator would not be too aggressive that c and the augmented c\u2019 are no longer matched under the distance threshold \u03c4 in Definition 2. If that happens, we give up this augmentation and let c\u2019 = c. After that, we obtain an augmentation version S\u2019a of Sa. To tackle (ii), we concatenate Sa with the residual sub-column Co to obtain Sa||Cb. Since we can assume that duplicates are few in the original column [4], most cells in the sub-column Co do not have matches in the sub-column Ca, effectively simulating non-matched cells between the positive column and the anchor column. Finally, we apply shuffling to Sa||Co to obtain the required positive column C+.\nEmbedding-level Synthesis. An obstacle to text-level synthesis is that it is hard to determine the granularity of the applied augmentation operator, especially in an extremely small threshold \u03c4. To this end, we propose another embedding-level column synthesis strategy.\nGiven a column matrix C, analogous to the text-level method, we first horizontally divide C into two sub-matrices Ca and Ch. Then we randomly samples x% rows from Ca, and denote it as Sa. Note that each row of Sa is a cell embedding c. Next, we augment each cell embedding vector c by random perturbation. Specifically, we generate a random vector r following normal distribution N(0, \u03c3), and gets the augmented c\u2019 = c + r. Here, we also need a validation step to ensure that d(c, c\u2019) \u2264 \u0433. But the advantage is that we can reduce \u03c3 by multiplying a coefficient \u03b3\u2208 (0,1) until the augmentation is proper to make c\u2019 matches c under the threshold \u03c4. Since the augmentation is operated in the continual embedding space, it is more flexible than the text-level method."}, {"title": "V. EXPERIMENTS", "content": "In this section, we conduct extensive experiments to demonstrate the effectiveness and efficiency of our proposed Snoopy."}, {"title": "A. Experiment setup", "content": "1) Datasets: We use three real-world table repositories to evaluate the effectiveness of Snoopy and baseline methods. Wikitable is a dataset of relational tables from Wikipedia [27]. Opendata is a data lake table repository from Canadian and UK open datasets [7], [28]. WDC Small is a sample dataset with long tables from the WDC Web Table Corpus\u00b2. For each dataset T, we remove whitespace and only selected columns with a length greater than 5 and not numeric to form column repository R. Since not all datasets contain metadata, for fairness, we only use the cells within each column. To generate queries and avoid data leaks, we randomly sample 50 columns for WikiTable and WDC Small, and 100 columns for Opendata from the original corpus except those in T, following previous studies [11], [26]. For efficiency evaluation, we use a large dataset, WDC Large, which consists of 1 million columns extracted from 186,744 tables in the WDC Web Table Corpus.\n2) Baselines: The following baselines are evaluated.\nWarpGate [1] is the latest system prototype for dataset discovery, which suggests using pre-trained table embedding models as column encoders. Since the embedding model [29] used in the original paper is not available, we choose TURL [30], a well-adopted table embedding model.\nBERT [31] is a pre-trained language model. We use bert-base-uncased\u00b3 to get the embedding for each column, and use the default input length limit of 512.\nBERT* adopts the contrastive loss to fine-tune BERT for the semantic join discovery task.\nSBERT [17] is a specialized variant of BERT that is designed for sentence-level embeddings. We use MPNet [32] as the backbone and set the input size limit as 512.\nSBERTck is a variant of SBERT, which divides the unique column values by chunks to ensure the 512-token limit, and averages chunk embeddings from SBERT to derive final column embeddings.\nDeepJoin [11] is a state-of-the-art join discovery method, which fine-tunes SBERT to obtain column embeddings and samples the most frequent cells for each column to ensure the 512-token limit. We use the best-performance MPNet [32] as the backbone, following [11].\nDeepJoinck is a chunking-based variant of DeepJoin. It employs the chunking strategy only during inference, as mini-batch training is not supported with chunking.\nStarmie [26] is a state-of-the-art dataset discovery method. It contextualizes column representations via fine-tuning ROBERTa to facilitate unionable table search in data lakes. For fairness, in our evaluation, we employ the single-column encoder and fine-tune it for semantic join discovery.\nSnoopybs is a base version of Snoopy, which adopts the traditional contrastive loss in Equation (9) for training.\nCellSamp is a cell-level method with sampling by randomly selecting n = 20 cells per column to improve efficiency. It compute pairwise similarity scores of sampled cells, and the joinability score is determined as the average of the maximum similarity scores between each cell in the query column and all cells in the candidate column.\nWe implement baselines following their original settings and tune the parameters for the best-performing results. Since the PTM-based methods need textual sequences as input for fine-tuning, we use the proposed text-level synthesis strategy to construct the same training data for BERT*, DeepJoin, Starmie, and Snoopybs. We did not observe accuracy im-provements by fine-tuning TURL with our training data, as it requires some extra information such as captions and entities in the knowledge graph [30]. Consequently, we directly utilize the pre-trained TURL to implement WarpGate.\n3) Metrics: Following Deepjoin [11], we adopt Recall@k and NDCG@k to evaluate effectiveness, where k is set to 5, 15, and 25 by default. Recall@k is defined as , where S and S denote the top-k result obtained by the specific method and an exact solution, respectively. NDCG@k is defined as , where DCG@k = and IDCG@k = , and Ci and Ci denote the columns ranked in the i-th position in the results obtained by the specific method and an exact solution, respectively. For efficiency, we evaluate the runtime of all the methods. The above metrics are averaged over all the queries.\n4) Implementation Details: We implement Snoopy in Py-Torch. We set the batch size to 64, the length 8 of the negative queue to 32, and the momentum coefficient a to 0.9999. We use Adam [33] as the optimizer, and set the learning rate to 0.01. We set the number l of proxy column matrix to 90, and the cardinality m per proxy column matrix to 50 by default. For RCL, we first generate a list of sorted joinability scores, where each score is randomly generated from (0.6, 0.9), and then apply the embedding-level synthesis strategy to generate positive columns. The length of the positive ranking list is set to 3. For cell matching, we follow previous studies [10], [11] to use fastText [16] as cell embedding function, and normalize all the vectors to unit length. We use Euclidean distance as the distance function d, and the threshold of cell matching is set to 0.2 by default. All experiments were conducted on a computer with an Intel Core i9-10900K CPU, an NVIDIA GeForce RTX3090 GPU, and 128GB memory. The programs were implemented in Python4."}, {"title": "B. Effectiveness Evaluation", "content": "Table II presents the Recall@k and NDCG@k of Snoopy and other baseline methods.\nSnoopybs vs. competitors. The first observation is that the proposed Snoopybs consistently outperforms other PTM-based methods across almost all evaluation metrics on the three datasets. Specifically, Snoopybs demonstrates an average improvement of 12% in Recall@25 and 8% in NDCG@25, compared with the best column-level competitor. We contribute this improvement to the high-quality column embeddings derived by AGM-based column projection, which is capable of capturing the implicit relationships between column pairs. Note that, while Snoopybs exhibits slightly lower Recall@5 compared to certain baselines on specific datasets, its NDCG@5 consistently outperforms them. The discrepancy stems from the fact that some joinable columns with the same joinability are ordered sequentially in the returned results.\nSnoopy vs. competitors. With rank-aware optimization, Snoopy outperforms the existing SOTA column-level methods by 16% in Recall@25 and 10% in NDCG@25 on average. This is because the rank-aware optimization takes a list of joinable columns into consideration, which enables Snoopy to better distinguish the ranks of different joinable columns.\nTo demonstrate the superiority of our column embeddings in bridging the semantics-joinability-gap, being size-unlimited, and permutation-invariant, we conduct in-depth analyses.\nBridge the semantics-joinability-gap. First, we randomly select 1K columns from Opendata and use the trained Deepjoin and Snoopy to encode these columns into embeddings. We then visualize these embeddings using t-SNE. The embedding distribution of Deepjoin is more uniform, indicating less evident similarity differences compared to Snoopy. This is because Deepjoin\u2019s embeddings focus more on the column semantic types rather than cell semantics, resulting in many columns having similar and indistinguishable embeddings. We then compute the joinability of each query"}, {"title": "C. Ablation Study", "content": "We conduct an ablation study of key components of Snoopy, with results shown in Table IX.\nFirst, we replace the the AGM-based column projection (CP) with the widely-used pooling techniques, i.e., max"}, {"title": "D. Efficiency Evaluation", "content": "We report the runtime of Snoopy and baseline methods. We omit the results of some methods because they demonstrate similar results to the specific methods already included. We also include PEXESO [10], which is a cell-level exact solution. We vary the number of columns in the WDC Large dataset from 100K to 1M, and report the average online processing time per query over 50 independent tests,\nWe have the following observations: (i) PEXESO and Snoopy demonstrate high efficiency in online encoding. However, other PTM-based methods need a relatively longer online encoding time (10x longer for BERT*, Starmie and DeepJoin, and 20x longer for WarpGate compared"}, {"title": "E. Parameter Sensitivity", "content": "We study the influence of four important hyper-parameters on the performance of Snoopy.\nFirst, we explore the impact of the number m of elements in each proxy column. We vary the value of m and show the result ,It is observed that the performance of Snoopy is not sensitive to the hyper-parameter m.\nNext, we vary the number l of used proxy columns, and show the results . It is observed that as l increases from 30 to 90, Recall@25 exhibits a noticeable improvement, which demonstrates that more information can be captured by increasing the number of proxy columns. When I continues to increase, the recall no longer increases but tends to be stable. Thus, it is advisable to set l to a relatively large value. For best performance across all datasets, we set 1 to 90.\nThen, we vary the threshold + of cell matching from 0.1 to 0.3, and show the Recall@25 . It is observed that the performance is relatively stable under different thresholds \u03c4, indicating that Snoopy is capable of accommodating different degrees of semantic join. Note when \u03c4 is set to 0, semantic-join degrades to equi-join."}, {"title": "F. Further Experiments", "content": "We further (i) explore how ground truth in evaluation shifts when using different cell embedding functions; (ii) evaluate the effectiveness of Snoopy under the dynamic scenario; and (iii) explore some optimizations to overcome the size limits in existing PTM-based methods.\n(i) Impact of cell embedding function. We explore two cell embedding functions: Word2vec, which is less powerful, and MPNet-based sentence-embedding model, which is more powerful than the default fastText. Specifically, for each query column, we first obtain its top-25 ranked column list Lf based on the semantic joinability using fastText. Then, we recompute joinabilities between the query column and those 25 columns using Word2vec and MPNet to generate new ranked lists Lw and Lm, respectively. Finally, we measure ground truth shifts by quantifying the similarity between rankings Lf and Lw (resp. Lm) using \\(1 -  \\frac{6 \u2211di^2}{s(s^2-1)} \u03a3\u2208 [0,1]\\), where p is the Spearman's rank correlation coefficient [37], di represents the rank difference of column Ci between Lf and Lw (resp. Lm), and s is the list length. The results are presented in Table V. We can observe that the shifts are small on all three datasets, demonstrating that while absolute embedding values may differ, the relative rankings derived by different cell embedding functions are similar. Notably, MPNet exhibits smaller shifts than Word2vec, indicating that the default fastText is closer to the MPNet than Word2vec.\n(ii) Effectiveness in the dynamic scenario. To simulate a dy-namic scenario where data are constantly added while fixing"}, {"title": "VI. RELATED WORK", "content": "Dataset discovery has been widely studied in the data management community [2], [39], with table search as the primary application. The main sub-tasks of table search are joinable table search and table union search.\nJoinable table search. To support joinable table search, most studies [6]\u2013[9], [40]\u2013[42] focus on equi-join and utilize syntactic similarity measures to determine joinanility between columns. To take semantics into consideration, PEXESO [10] proposes a semantic joinability measure, and designs a cell-level exact algorithm under this measure using word embeddings. To enhance efficiency, the following column-level solutions, such as DeepJoin [11] and WarpGate [1], perform coarser computation at column-level to approximate the re-sults of cell-level solutions. However, the effectiveness is poor due to the suboptimal column embeddings. In contrast, our Snoopy is an effective column-level framework pow-ered by the proxy-column-based column embeddings. Recent works [20], [43] on semantic overlap set search are related"}, {"title": "VII. CONCLUSIONS", "content": "This paper proposes Snoopy, an effective and efficient se-mantic join discovery framework powered by proxy columns. We devise an approximate-graph-matching-based column projection function to capture column-to-proxy-column relationships, ensuring size-unlimited and permutation-invariant col-umn representations. To acquire good proxy columns, we present a rank-aware contrastive learning paradigm to learn proxy column matrices for embedding pre-computing and online query encoding. Extensive experiments on four real-world table repositories demonstrate the superiority of Snoopy in both effectiveness and efficiency. In the future, we plan to consider the downstream data analysis and study the task-oriented join discovery."}, {"title": "APPENDIX A TIME COMPLEXITY ANALYSIS", "content": "We denote the cardinality of proxy column set as I and the cardinality per proxy column as m. During the offline stage, the complexity of pre-computing all the column embeddings is O(ml|C||R|) = O(|C||R|), where |R| denotes the number of columns in the repository, and denotes the average size of columns in the repository; and the time complexity of index construction using HNSW is O(|R| log |R|). During the online stage, the complexity of computing the query column embedding is O(ml|CQ|) = O(|CQ|), where |CQ| is the size of the query column CQ; and the time complexity of ANN search is O(log |R|). Consequently, the overall time complexity of online processing is O(|CQ|+ log |R|)."}, {"title": "APPENDIX B EFFECTIVENESS OF EQUI-JOIN DISCOVERY", "content": "To demonstrate the effectiveness of Snoopy in equi-join search, we compare its R@25 with Deepjoin, which can also deal with approximate equi-join discovery. We omit the exact algorithms such as JOSIE [6] and MATE [42], as their accuracy is 1. The approximate algorithm like LSH Ensemble [7] is also excluded, as it has been validated that Deepjoin outperforms LSH Ensemble in equi-join search [11]. The results are shown . We can see that the accuracy of Scorpion also outperforms Deepjoin."}]}