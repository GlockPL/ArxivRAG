{"title": "ENHANCING SMART ENVIRONMENTS WITH CONTEXT-AWARE CHATBOTS USING LARGE LANGUAGE MODELS", "authors": ["Aurora Polo-Rodr\u00edguez", "Laura Fiorini", "Erika Rovini", "Filippo Cavallo", "Javier Medina-Quero"], "abstract": "This work presents a novel architecture for context-aware interactions within smart environments, leveraging Large Language Models (LLMs) to enhance user experiences. Our system integrates user location data obtained through UWB tags and sensor-equipped smart homes with real-time human activity recognition (HAR) to provide a comprehensive understanding of user context. This contextual information is then fed to an LLM-powered chatbot, enabling it to generate personalised interactions and recommendations based on the user's current activity and environment. This approach moves beyond traditional static chatbot interactions by dynamically adapting to the user's real-time situation. A case study conducted from a real-world dataset demonstrates the feasibility and effectiveness of our proposed architecture, showcasing its potential to create more intuitive and helpful interactions within smart homes. The results highlight the significant benefits of integrating LLM with real-time activity and location data to deliver personalised and contextually relevant user experiences.", "sections": [{"title": "1 Introduction", "content": "The increasing global elderly population presents significant challenges to healthcare systems and caregivers [1]. Although many older adults prefer to age in place, the rising costs of in-home care and the shortage of caregivers create a pressing need for innovative solutions [2]. Smart environments, equipped with various sensors and activity recognition technologies, offer a promising avenue to support independent living and alleviate the burden on healthcare providers [3].\nRecent advances in human activity recognition (HAR) use sensor fusion approaches [4], which combine data from vision sensors, wearables, and ambient sensors to identify activities of daily living (ADL) with increasing granularity. Integrating indoor location systems, such as Ultrawide Band (UWB), further enhances HAR by providing precise user location and enabling the identification of individual activities in multi-occupancy settings. This granular understanding of user behaviour allows for personalised interventions and support.\nTo further enhance the capabilities of smart environments, this work leverages the power of Large Language Models (LLMs) [5]. LLMs have demonstrated remarkable abilities in natural language processing, enabling the development of sophisticated conversational agents or chatbots [6]. [7] have showcased the promising conversational abilities of task-oriented dialogue systems, particularly with In-Context Learning based user simulation in zero-shot settings, underscoring the potential of this innovative approach. By integrating LLMs with contextual information derived from HAR [8] and indoor localisation, we can create chatbots capable of understanding user needs and providing customised assistance in real time. Proposing a chatbot to provide assistance with tasks and generate recommendations proactively is difficult. Such a chatbot could provide companionship, cognitive support, and even emergency assistance, significantly improving the safety and well-being of elderly people living alone, but currently they need user context data [9]. This fusion of LLM with smart environment technologies opens new possibilities for intuitive and personalised user interactions."}, {"title": "2 Related works", "content": "HAR using sensors relies on a network of interconnected devices to monitor daily activities [3]. While this data provides valuable insights into Activities of Daily Living (ADL), it also raises significant privacy concerns [10]. Consequently, systems utilizing less intrusive binary sensors and wearables have become widely adopted [11]. However, HAR in smart homes presents a considerable challenge. Human activity is inherently complex, varying not only daily but also between individuals with unique habits and abilities.\nSmart home environments often house multiple occupants, which presents a significant challenge in accurately identifying individual activities [12]. Many smart home devices lack the capacity to determine who triggered a sensor, making it difficult to distinguish ADLs in multioccupant settings [13]. This ambiguity hinders research progress in this area, leaving many crucial questions unanswered and slowing the development of effective solutions for multi-occupant HAR.\nTo overcome limitations of single-sensor approaches in HAR, researchers are exploring indoor technology combined with data fusion methods. Although UWB provides precise localisation [14, 15], its sensitivity to obstacles requires the use of heat maps for enhanced spatial representation [16, 17, 18]. Integrating UWB with nearby sensors, such as wearables, provides richer contextual information, improving activity recognition accuracy, particularly in multi-occupant settings [19, 18]. Furthermore, incorporating fuzzy logic helps to manage uncertainty and differentiate concurrent activities [20, 21]. Advanced hardware and processing techniques further optimise data analysis for improved HAR accuracy [22].\nWhile these approaches advance the field of HAR, they often lack the ability to provide personalised and contextually relevant assistance to users to identify and solve specific real-world problems [23]. This is where LLM and chatbots offer a significant opportunity [24, 25]. LLMs can process and understand natural language, allowing the development of chatbots capable of engaging in meaningful conversations with users and fragile people [26]. By integrating LLMs with HAR systems, chatbots take advantage of the activity data collected to provide activity recognition [27], customised support, such as reminders, evaluation of mental status [28], loneliness [29], and even emotional support [30] that improves responsible use of social care [31]. For example, a chatbot could remind a user to take their medication according to their daily routine and detected activity, or offer encouragement and motivation if it senses that the user is struggling with a particular task [30]. This combination of LLM and HAR has the potential to revolutionise the way smart environments assist and interact with users, creating truly personalised and supportive living spaces; however, the lack of context generates delusion in real-life deployments [9].\nAlthough existing research explores various aspects of smart environments and activity recognition, this work presents a novel approach by integrating LLM with context-aware real-time HAR and indoor localisation. This fusion of technologies enables the development of context-aware chatbots capable of providing personalised assistance and enhancing user experiences in unprecedented ways. By combining the power of LLMs with granular activity and location data, this architecture paves the way for truly intelligent and supportive smart environments that cater to the unique needs of each individual."}, {"title": "3 Materials and Methods", "content": "This section details the key components and methodologies that underpin our approach to multi-occupancy activity recognition and its integration with a context-aware chatbot. We begin by describing the sensing infrastructure used to capture user interactions within the smart environment. This involves a network of ambient sensors that monitor the home, coupled with precise indoor localisation using UWB technology. Subsequently, we describe the HAR models used to interpret these sensor data and identify individual activities in real-time. Finally, we explain how these sensing and activity recognition capabilities are integrated with a Large Language Model (LLM) to create a chatbot capable of understanding and responding to user needs in a contextually relevant manner."}, {"title": "3.1 Sensing Multi-occupancy Activity Recognition", "content": "In this section, we describe the materials and models related to sensing the smart environment in the current proposal to connect chatbots for context-aware user interaction using LLM.\nFirst, ambient sensors are deployed to configure a smart home that captures user interactions with various elements of the home. These sensors, including contact sensors for doors and windows, temperature and humidity sensors, motion sensors, vibration sensors, and power consumption sensors, provide a rich stream of data about the user's activities and environment. These data is transmitted wirelessly through MQTT to a central hub running Home Assistant, enabling seamless integration and analysis [21]. The sensor data is then processed and converted into a normalised representation between [0,1] [32], where semantic is related to terms such as active state (e.g., door open, motion detected) or degree of humidity.\nSecond, this work uses UWB technology for precise indoor location. Wearable UWB devices, in the form of wristwatches, act as low profile tags to track individuals within the smart home [33]. Our approach employs innovative fingerprinting techniques to improve location accuracy, particularly in challenging Non-Line-of-Sight scenarios [34]. This method allows for a reduction in the number of UWB anchors required, leading to a cost-effective and efficient deployment. By implementing auto-encoders with CNN, ConvLSTM2D and LSTM networks, [18] demonstrates the reliable presence of location heatmaps, even under strenuous conditions in an experimental home environment involving multiple occupants.\nThird, HAR models enable real-time recognition of inhabitant activities. These models can be broadly categorised into knowledge-based and data-driven approaches. Knowledge-based approaches (e.g., [21, 35]) leverage expert knowledge to define the temporal and interactional patterns that characterise activities through predefined rules. In contrast, data-driven approaches learn activity patterns from labelled data, analysing user location and sensor activity to predict activities in multi-occupancy environments. Deep learning approaches have shown particularly promising results in this domain. In [33], authors effectively identify individual activities by analysing the proximity of the user and interactions with nearby sensors using an ensemble of deep learning models. Their findings demonstrate that GRU and Conv1D + GRU with attention mechanisms achieve the best performance in accurately predicting user activities in multi-occupancy settings in real-time.\nIn conclusion, these three fundamental components provide the building blocks for a multi-occupancy activity recogni-tion system capable of accurately identifying activities within indoor environments by utilising precise localisation and environmental sensor activation."}, {"title": "4 Connecting Chatbots for Context-Aware User Interaction using LLMs", "content": "This section delves into the integration of LLMs with the smart environment sensing capabilities described previously. The goal is to create a chatbot capable of understanding and responding to user needs in a context-sensitive manner. This is achieved by feeding real-time location and activity information to the LLM, allowing it to generate relevant and personalised interactions. Our proposed architecture centres around an LLM-powered chatbot that receives a continuous stream of contextual data. This data encompasses:\n\u2022 User Location: Precise indoor location derived from the UWB tags provides an understanding of the user's current position within the smart home. This allows the chatbot to tailor its responses based on the user trazability.\n\u2022 Activity Recognition: Real-time activity information from HAR models informs the chatbot about the user current actions. This enables the chatbot to anticipate needs and offer relevant assistance (e.g., \"Would you like me to play some music while you are cooking?\" when the user is detected cooking).\nThis combined contextual information is processed and formatted into a structured prompt that is fed to the LLM. The LLM then uses its language and knowledge processing capabilities to generate a suitable response, recommendation, or action. His will be exemplified with Google Gemini in the following case study section.\nIntegrating a chatbot powered by LLM with real-time activity and location data offers significant advantages:\n\u2022 Personalised and Contextual Dialogue: The LLM receives the daily activity of users (e.g., cooking, working) and location (e.g., kitchen, office) as context within its prompt. This allows the chatbot to generate responses that are directly relevant to the user's situation and environment, making the interaction more natural and helpful."}, {"title": "\u2022 Proactive and Adaptive Assistance", "content": "By analysing the user's real-time data and historical patterns through HAR, the chatbot can anticipate needs and offer assistance before being explicitly asked. For example, if the user starts cooking, the chatbot might proactively offer a food recipe. The chatbot also learns from past interactions and observed behaviour to tailor its communication style and recommendations to individual users."}, {"title": "\u2022 Natural and Flexible Interaction", "content": "The chatbot utilises text-to-speech (TTS) and speech-to-text (STT) technolo-gies to enable natural communication. Users can interact with the chatbot through voice commands using various devices, such as smartphones, or ambient microphones. The chatbot's responses are then converted into natural-sounding speech and relayed through devices like earphones or smart home speakers. This multimodal approach caters to different user preferences and situational contexts."}, {"title": "\u2022 Intelligent Environment Control", "content": "Beyond conversation, the LLM can interpret user requests and actions to directly control actuators in the smart environment. For example, if the user says Turn off the lights\" or the chatbot detects that the user has left the room, the LLM can trigger the appropriate command to turn off the lights. This seamless integration of language understanding and action execution enhances the convenience and automation of the smart home experience.\nIt is important to note that user privacy is a top priority. All activity and location data are securely collected, stored and processed with strict adherence to privacy protocols in edge-fog architectures."}, {"title": "5 Case study", "content": "The proposed architecture was implemented within a supervised flat, inhabited by three frail adults who live inde-pendently. The apartment had six rooms: living room, office, kitchen, bathroom, and two bedrooms.\nEach room was equipped with ambient sensors and UWB tags described in Section 3.1 to facilitate the precise location and activity tracking of the occupants. Data collection was carried out over a two-day interval, during which residents participated in their daily activities. Concurrently, the virtual assistant facilitates interactions based on the contextual data it obtains. The activities that the deployed system [33] is capable of recognising include:\n\u2022 Toileting: Interactions with the toilet or faucet, detected through the bathroom sensors.\n\u2022 Resting: Prolonged sitting near the sofa in the living room."}, {"title": "\u2022 Exit", "content": "Detection of users leaving the apartment via door sensors."}, {"title": "\u2022 Cooking", "content": "Interactions with kitchen appliances (microwave, stove, refrigerator, sink), each equipped with sensors."}, {"title": "\u2022 Showering", "content": "Detection of changes in humidity and temperature during shower use."}, {"title": "\u2022 Computer Use", "content": "Monitored by tracking power consumption in the workspace."}, {"title": "\u2022 Sleeping", "content": "Extended rest near the bed in the bedroom."}, {"title": "\u2022 General Kitchen Activity", "content": "Presence and interaction with kitchen appliances such as microwave, stove, and fridge.\nThis information was processed in real-time and used as input for the LLM-powered chatbot to enable contextually aware and personalised user interactions, adapting its responses based on the location of the user and the detected activities. The study adhered to the ethical guidelines defined in the DTS21-00047 project where all participants were fully informed about the objectives, methodologies, and rights of the study, subsequently providing their written informed consent to participate."}, {"title": "5.1 Context-Aware Chatbot Setup", "content": "This section outlines the setup and configuration of our context-aware chatbot, which leverages the Gemini Flash 1.5 model to deliver context-sensitive responses. This model excels in dynamic applications, processing up to 60 tokens per minute with a maximum response length of 2048 tokens, making it well-suited for dynamic conversations with minimal delay. Continuous learning ensures that the model adapts to evolving user needs, while customisation options allow tailoring to specific use cases.\nThe configuration incorporates several core components to optimise user interaction:\n\u2022 Role definition: The chatbot's role is defined initially to guide its interactions with users based on routines and specific environmental context.\n\u2022 Activity-specific prompts: User context is tracked to generate prompts that respond to each user's activity, leveraging a mapping of activities to specific rooms to maximise contextual relevance.\n\u2022 Location-based assistance: The chatbot is aware of the current room and activity of the user, providing suggestions, reminders, or alerts that align with their immediate surroundings.\n\u2022 Proactive and adaptive interaction: The chatbot uses historical data from the HAR model to adapt prompts, anticipating the user's needs and refining responses over time.\nThe chatbot configuration begins with an initial prompt that defines its role, guiding interactions with users in a way that aligns with their individual routines and environment. The setup describes the residents of a super-vised living facility, specifying the relevant contextual details for each user, such as household composition, typ-ical daily activities, and individual conversational needs. The core configuration of the chatbot is defined by the init_context and question_format parameters, which provide guidelines for interaction and response gener-ation. The init_context prompt instructs the chatbot to engage users through dynamic conversations, considering"}, {"title": "Role configuration", "content": "[16fe]\ncontext=\"The user you are going to talk to is called John and he is 60 years old,\nhe lives with his wife and son.\"\n[5b66]\ncontext=\"The user you are going to talk to is called Mary and she is 55 years old,\nshe lives with her husband and son.\"\n[ed9c]\ncontext=\"The user you are going to talk to is called Michael and he is 27 years\nold, he lives with his parents.\"\nThese configurations enable the chatbot to adapt its conversational tone and content to each user's circumstances, allowing for an empathetic and personalised approach. To further enhance relevance, each activity is associated with a specific room to enhance contextual relevance: cooking activities are mapped to the kitchen, while showering and toileting take place in the bathroom. Activities involving PC use are typically associated with the office, although they may occur in other areas as well. Sleeping is assigned to the bedroom, resting is associated with the living room, and exiting is designated at the exit door area. This mapping allows the chatbot to dynamically interpret and respond based on the user's location and activity context. For instance, if a user enters the kitchen, the chatbot can prioritize conversational topics related to cooking or food preparation.\nTo enhance response quality and contextual awareness, a queue component manages real-time prompts by leveraging activity history and analysing the temporal dynamics between user actions and chatbot replies. This mechanism ensures the continuity of the interaction and the relevance of the dialogue, effectively maintaining the conversational context. First, we establish a structured timeline by converting initial and end dates into Unix timestamps, ensuring comprehensive coverage of the user's activity history. For each user, the system accesses a historical activity dataset that contains activity types, start times, and end times. This data enables the construction of a pre-question sequence, facilitating smooth transitions between related activities. By referencing previous activities, the system incorporates contextual information such as the previous location and time into the prompt, enhancing the relevance of subsequent"}, {"title": "5.2 High-Scoring Prompt-Response Examples", "content": "To evaluate the effectiveness of the chatbot's context-aware interactions, we analyzed the highest-scoring responses based on their relevance and interest level for the user. Table 5.2 presents selected prompt-response pairs for the user \"Mary,\" highlighting the dynamic and personalised responses generated in different contexts. These interactions demonstrate the chatbot's ability to tailor its responses according to the user's ongoing activities and preferences, promoting engagement and contextual relevance. It is essential to note that the provided table presents a summarised version of the prompt, as the original contains an extensive record of the individual's activities throughout the day. The full code and results can be accessed in the publicly available GitHub repository.\nAs previously introduced, all prompts adhere to the following structure: user_context + pre_act_format +\nquestion_format. For the current example, the components are defined as follows:\n1. user_context: \"The user, referred to as Mary, is 55 years old and resides with her husband and son.\"\n2. pre_act_format: Historical data is presented in the following format: \"At 2024-07-26 02:01:00, the user enters the bedroom and begins sleeping until 2024-07-26 03:18:00.\" In this example, the table illustrates a condensed version of the activities used as input for the chatbot prompt.\n3. question_format: \"It is [TIME column) and the user has been [ACTIVITY column]. What would you say now [TIME column) for dynamic entertainment, questions, or suggestions, taking into account the activities she was developing without being repetitive? The output should be a single response structured as (text, score), where the score represents a value of 0-100 indicating the potential relevance or interest for the user.\"\nThe examples shown in Table 5.2 illustrate the ability of the model to adapt responses based on contextual cues in real time, improving the relevance of interactions with the user."}, {"title": "6 Conclusions and future works", "content": "This research presents an innovative system that combines LLM, HAR, and precise indoor location to create context-sensitive interactions in smart environments. Our findings underscore the potential of this architecture to offer personalised, responsive assistance that aligns closely with user needs, particularly benefiting ageing individuals or frail individuals who need regular support in daily activities. The novelty lies in the systematic and structured approach to context-aware prompting, specifically tailored to the application of supervised living by means of:\n\u2022 Precisely defined prompt components: The clear separation of user context, and question and answer format allows for modularity and easier modification.\n\u2022 Tight integration of activity, location, and time to create a strong sense of context.\n\u2022 The relevance score, automatically computed by LLMs, ensures that responses are not only high quality but also directly relevant and impactful for the user's needs.\n\u2022 Emphasis on historical data and temporal dynamics enables the chatbot to maintain a coherent conversation over time.\nFuture research will investigate the expansion of this system integration to smart speakers in supervised living environments over extended periods, aiming to provide users with a consistent and familiar connection to the assistant throughout their homes. To further personalize the user experience, enhanced learning capabilities will be explored, allowing the model to learn and adapt to individual behavior patterns, recognising specific routines and preferences. Beyond home settings, the deployment of this system in assisted living facilities and residential care environments holds promise in transforming it into a valuable tool for cognitive stimulation and companionship. This could support mental well-being by providing timely reminders of medication, daily activities, and participation in cognitive exercises.\nMoreover, future work should consider the impact of prompt structure on the quality of LLM responses. Specifically, it would be beneficial to examine the effects of incomplete pre_act_format prompts on the output. Understanding how variations in prompt completeness influence response quality can inform strategies for optimizing prompt design and enhancing the system's robustness.\nIn addition to these areas, embedding the assistant within wearable devices and companion robots presents another compelling avenue for development. This integration could enable seamless and private interactions, eliminating the need for multiple speakers and offering immediate access to assistance as users move through different spaces. Companion robots, in particular, could further improve accessibility and user comfort by proactively bringing the assistant to the user, adapting to their location and individual needs, and fostering a more interactive and engaging experience. This approach could strengthen the assistant's role in promoting user autonomy and overall well-being by providing both companionship and practical support."}]}