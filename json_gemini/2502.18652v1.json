{"title": "INDEPENDENT MOBILITY GPT (IDM-GPT): A SELF-SUPERVISED MULTI-AGENT LARGE LANGUAGE MODEL FRAMEWORK FOR CUSTOMIZED TRAFFIC MOBILITY ANALYSIS USING MACHINE LEARNING MODELS", "authors": ["Fengze Yang", "Xiaoyue Cathy Liu", "Lingjiu Lu", "Bingzhang Wang", "Chenxi (Dylan) Liu"], "abstract": "With the urbanization process, an increasing number of sensors are being deployed in transportation systems, leading to an explosion of big data. To harness the power of this vast transportation data, various machine learning (ML) and artificial intelligence (AI) methods have been introduced to address numerous transportation challenges. However, these methods often require significant investment in data collection, processing, storage, and the employment of professionals with expertise in transportation and ML. Additionally, privacy issues are a major concern when processing data for real-world traffic control and management. To address these challenges, the research team proposes an innovative Multi-agent framework named Independent Mobility GPT (IDM-GPT) based on large language models (LLMs) for customized traffic analysis, management suggestions, and privacy preservation. IDM-GPT efficiently connects users, transportation databases, and ML models economically. IDM-GPT trains, customizes, and applies various LLM-based AI agents for multiple functions, including user query comprehension, prompts optimization, data analysis, model selection, and performance evaluation and enhancement. With IDM-GPT, users without any background in transportation or ML can efficiently and intuitively obtain data analysis and customized suggestions in near real-time based on their questions. Experimental results demonstrate that IDM-GPT delivers satisfactory performance across multiple traffic-related tasks, providing comprehensive and actionable insights that support effective traffic management and urban mobility improvement.", "sections": [{"title": "1 Introduction", "content": "Urbanization drives economic growth, enhances access to services and opportunities, and fosters cultural and social development in concentrated areas. However, it also challenges the equilibrium between infrastructure supply and travel demands, resulting in mobility issues that can slow economic activity due to increased congestion, longer commute times, and higher pollution levels. A report published by the United States Department of Transportation (USDOT) [1] reveals that the vehicle miles of travel grew 2.1% faster than the public road and street mileage between 2010 and 2022, even when accounting for the effects of the pandemic. Concurrently, the annual hours of delay per commuter in \"very large\" cities rose by 5 hours from 2010 to 2019, prior to the pandemic. These factors collectively diminish living quality and could lead to resident dissatisfaction [2, 3, 4]. Therefore, it is significant for transportation agencies like DOTs to address mobility challenges within current transportation systems and enhance network resilience. To achieve this goal, they need to identify the current traffic demands and road system bottlenecks by deploying an extensive array of sensors and devices to collect data, including loop detectors, surveillance cameras, radar or LiDAR sensors, and GPS devices [5, 6]. These sources generate substantial quantities of data, such as speed, traffic volumes, and density [7], providing transportation agencies with a detailed understanding of network mobility and supporting the development of more accurate and reliable traffic models. Nevertheless, the surge of big data also presents great opportunities as well as significant challenges, such as processing efficiency, data privacy and security issues, as well as the increased labor costs associated with implementing advanced technologies like Machine Learning (ML) applications.\nLeveraging the vast influx of big data, numerous ML techniques have been integrated into transportation systems to capture the temporal-spatial dependencies of traffic data, thereby addressing various mobility challenges. To efficiently harness the potential of traffic data, ML models such as statistical models and deep learning (DL) models offer a broad spectrum of analytical techniques for traffic agencies. Among these, DL models like neural networks (NN) are particularly beneficial for traffic data analysis due to their capabilities in complex pattern recognition, feature extraction, and capturing non-linear spatio-temporal correlations [8, 9, 10, 11, 12]. For example, Convolutional Neural Networks (CNNs) are well-suited for spatial data analysis and can proficiently process data in grid formats such as images or road network grids; while Recurrent Neural Networks (RNNs), especially Long Short-Term Memory (LSTM) networks, excel at capturing temporal dependencies over sequences of data. Although these state-of-the-art ML models significantly enhance the utility of traffic data, their direct implementation introduces several challenges:\n\u2022 Time Consumption and Efficiency: Traffic agency analysts take a non-real-time to fetch, process, and analyze large volumes of traffic data. This delay can hinder timely decision-making and real-time response to changing traffic conditions.\n\u2022 Scalability and Error Management: Manual analysis struggles to scale effectively with the vast amounts of traffic data generated by modern sensor deployments. Data overload can lead to potential oversights and errors due to fatigue.\n\u2022 Costs and Resource Requirements: Employing human analysts involves significant expenses, including salaries, ongoing training, and infrastructure for manual data collection and processing.\n\u2022 Data Privacy: Data privacy is a critical issue when human analysts manually process traffic data in ML/AI implementations. The manual handling of sensitive information, such as travel routes, timestamps, and personal vehicle data, increases the risk of data breaches or non-compliance with privacy regulations [13].\nNevertheless, the advent of AI agents empowered by large language models (LLMs) mitigates the challenges caused by human analysts applying traditional ML models or neural networks (NNs) [14]. LLMs, such as OpenAI's GPT series, are transformer models that excel in understanding and generating human-like text by learning from vast amounts of textual data, making them highly effective for natural language processing tasks [15]. In the context of evaluating traffic patterns, AI agents utilize the capabilities of LLMs to function as intermediaries that simplify the interaction with complex ML models, offering intuitive natural language interfaces. These interfaces, brought by LLMs, facilitate ease of use for non-expert users, enabling them to conduct complex queries and interpretations more efficiently, thereby reducing the need for specialized ML expertise.\nMoreover, by integrating various ML models with the natural language processing abilities of LLMs, AI agents alleviate the need for traffic agencies to possess extensive ML knowledge or undergo specific training [16], thus reducing additional labor costs associated with implementing ML models and improving operational efficiency. Additionally, LLM agents contribute to minimizing the risk of data leakage by acting as secure mediators in the processing of sensitive personal travel data, obviating direct human access. Due to their capacity to analyze extensive volumes of unstructured data from diverse sources [17] or to query structured data from databases [18, 19], LLM agents efficiently identify"}, {"title": "2 Literature Review", "content": "The demand to derive traffic movements and patterns from data efficiently in order to ameliorate urban mobility challenges enables traffic agencies to adopt advanced ML methodologies. In this context, LLMs serve as a pivotal tool, potentially enhancing the deployment of ML models in mobility data analysis. This section seeks to encapsulate and evaluate contemporary research on the role of LLMs in two key areas: 1) the challenges associated with these approaches, and 2) the emerging role of LLMs and the multi-agent frameworks in overcoming these challenges. Prior to further discussion on LLMs, this section provides an overview of the current state of research on ML applications in the traffic field, which may serve as a foundational basis for the potential integration of LLMs."}, {"title": "2.1 ML in mobility analysis", "content": "Traditional statistical models have long been used for traffic forecasting and analysis; however, the non-linear and complex nature of traffic patterns often limits their effectiveness. The advent of ML, particularly deep learning (DL)"}, {"title": "2.2 AI Agents and LLMs", "content": "The emergence of AI agents empowered by LLMs offers potential solutions to the above-mentioned challenges. AI agents are autonomous systems that interact with their environment through sensors and actuators to make decisions and perform tasks, aiming to achieve specific objectives efficiently and effectively [38]. LLMs, such as OpenAI's GPT series and LLaMA, have demonstrated remarkable capabilities in understanding and generating human-like text [15]. In transportation, LLMs can serve as intermediaries between users and complex ML models, enabling natural language interfaces, automated data processing, and enhanced decision support. Current LLM-related research in the transportation field can be classified into LLMs as predictors, synthetic data generators, assistants, and evaluators."}, {"title": "2.2.1 LLM-as-a-Predictor", "content": "LLMs are well-suited for predicting spatial-temporal traffic data due to their ability to capture complex dependencies, integrate multimodal data, and model sequential patterns effectively. The R2T-LLM [39] was proposed as a novel traffic flow prediction model leveraging LLMs for both accurate and explainable traffic forecasting. However, as noted in the paper, generating coherent and contextually relevant explanations alongside predictions remains a challenge. To help LLMs better understand time-series data, Ren et al. [40] effectively leveraged pre-trained LLMs for traffic prediction, showing strong performance in both full-sample and few-shot scenarios. However, combining CNNs and GCNs to handle spatiotemporal features increases computational complexity, which may pose challenges for implementation in resource-constrained or real-time systems. Another approach to improving LLMs' understanding of spatial-temporal data is to tokenize timesteps and locations for embedding in the models. For instance, ST-LLM [41] introduced a partially frozen attention strategy that effectively captures global spatial-temporal dependencies, though its reliance on spatial-temporal embeddings can hinder its suitability for real-time decision-making applications such as dynamic traffic management systems. UrbanGPT [42] utilized spatiotemporal instruction-tuning to achieve accurate zero-shot predictions in urban scenarios. Although this model is designed for generalization, fine-tuning may still be needed to optimize results for specific urban contexts, which could be challenging for organizations lacking the necessary expertise or computational resources."}, {"title": "2.2.2 LLM-as-a-Generator", "content": "LLMs are adept at generating realistic sequence data, making them particularly useful for generating traffic data in simulations. While challenges remain in ensuring the fidelity and diversity of the generated data, LLMs have been widely employed to simulate complex systems such as urban traffic flows and human mobility patterns [43]. For example, SeGPT, a framework leveraging ChatGPT, excels at generating dynamic and complex scenarios for autonomous vehicle trajectory prediction, aiding in model testing and adaptation across various real-world conditions [44]. However, generalizing across different driving scenarios, particularly in low-data environments, remains a challenge. Similarly, Chang et al. presented a framework for generating rare and complex corner scenarios for autonomous vehicle testing using LLMs, enhancing scenario diversity and interoperability [45]. Nonetheless, the reliance on LLMs to generate complex multi-agent scenarios introduces significant complexity in model design and implementation, which may make it difficult to ensure that the scenarios accurately reflect real-world conditions. MobilityGPT [46], by leveraging a gravity model and road connectivity matrix, successfully generated realistic synthetic trajectories. However, the absence of formal privacy guarantees for the generated data raises concerns when such synthetic data is intended to preserve privacy, potentially exposing sensitive information."}, {"title": "2.2.3 LLM-as-an-Assistant", "content": "LLMs can act as powerful assistants, enhancing various aspects of operations, management, and user interaction. Zhang et al. [21] introduced TrafficGPT, which combines ChatGPT with traffic foundation models (TFMs) to enable natural language interaction with traffic data analysis and decision-making processes. The model translates natural language queries into prompts for TFMs, which then analyze traffic data to produce actionable insights and recommendations. This innovative approach improves the accuracy, efficiency, and reliability of urban traffic management decisions. Similarly, DriveLLM [47] is a framework that integrates LLMs into autonomous driving systems, enhancing commonsense reasoning and decision-making in dynamic environments. However, in complex environments with multiple moving objects, DriveLLM tends to make overly cautious decisions.\nResearch on LLM-as-an-Assistant in the transportation field remains relatively underdeveloped compared to their use as predictors or generators. Although some frameworks have explored LLMs for enhancing traffic management and autonomous driving through natural language interaction and decision-making, the scope and depth of this research remain limited. The input methods in these studies may not always be flexible or generic enough, as users might be uncertain about the best approach to achieve traffic project objectives. Additionally, the frameworks require substantial human interaction, which may not always be the most efficient use of time and effort."}, {"title": "2.2.4 LLM-as-a-Judge", "content": "To evaluate LLM-generated results, traditional methods like BLEU [48], ROUGE [49], and METEOR [50] focus on word and phrase matching but lack semantic and reasoning evaluation. Recent approaches like BERTScore [51] and MoverScore [52] use contextual embeddings to assess semantics but are sensitive to nuances in word embeddings and may misinterpret out-of-context phrases. To address these issues, LLM-based evaluation methods such as QAGScore, GPTScore, G-Eval, and Prometheus have been developed. These methods offer better semantic understanding and interpretability. QAGScore [53] evaluates factual consistency through a question-answering approach but is dependent on question-and-answer quality. Prometheus [54] combines multiple metrics like factuality, fluency, and coherence, but its complex implementation and high computational cost are drawbacks. GPTScore [55] offers flexibility through fine-tuning for different criteria. Similarly, G-Eval [56], based on GPT models, excels at evaluating complex qualities like logical flow and coherence, aligning closely with human judgments. In this paper, though GPTScore is fast and flexible, G-Eval is preferred for its better alignment with human evaluations and logical thinking and reliable and consistent performance in scoring tasks such as coherence, factuality, and relevance.\nThis paper aims to address the research gap by advancing LLM-as-an-Assistant research and developing a self- motivating, generic framework\u2014IDM-GPT\u2014that assists users in identifying optimal analysis strategies, enhancing data analysis efficiency, decision-making, and user interaction across various transportation tasks."}, {"title": "3 Methodology", "content": "This section elaborates on the detailed mechanisms of how IDM-GPT leverages LLM-based agents to efficiently identify and manage traffic issues. The proposed multi-agent framework integrates advanced ML models with LLMs to process and analyze complex, high-dimensional traffic data. Figure 1 presents the overall process, illustrating how IDM-GPT deconstructs traffic-related tasks through a self-organizing, self-supervising, and self-optimizing approach."}, {"title": "3.1 Framework overview", "content": "This framework is designed to manage and analyze traffic data using LLMs and ML models, taking user queries as input and producing comprehensive analysis reports that include traffic insights, visualizations, and suggestions. The framework consists of five LLM-based agents:\nIV Agent: This agent receives user queries and outputs formatted questions with clear objectives and scopes. It prevents irrelevant inputs from wasting computational resources and clarifies the user's intent, time, and location scope to help create better prompts for LLMs, ensuring satisfactory results.\nSP Agent: This agent takes the validated query or retrieved dataset, drafts a prompt, optimizes it, and forwards it to the next LLM role. It is designed to generate high-performance prompts through iterative optimization.\nDBI Agent: This agent converts prompts from the previous agent into SQL queries to retrieve necessary data from the database. It ensures that user queries and database descriptions are translated into executable SQL queries effectively.\nDAS Agent: This agent uses the optimized prompts, including the retrieved datasets, to produce diagrams, analyses, and discussions represented by figures, tables, and text files. It employs various ML models, including NN, to analyze traffic data. Depending on the query, the LLM Data Analyst selects appropriate ML models to identify traffic patterns and reasons for traffic conditions, generating valuable insights for transportation improvements.\nSS Agent: This agent takes the results from the DAS Agent and produces the final comprehensive analysis report, which includes visualizations and detailed insights. It checks the quality of the analysis results to ensure accuracy and relevance to the user query. Unsatisfactory results are looped back for further refinement.\nThe entire framework ensures a seamless process from user query to detailed analysis report, leveraging LLMs and ML models for optimal traffic data analysis and insight generation. The examples of prompts of each agent have been attached in Appendix 1."}, {"title": "3.2 IV Agent", "content": "The process of this agent is illustrated in Figure 2. This process ensures that user queries are properly framed and relevant to transportation-related issues before further processing. This research firstly uses an LLM-based validator to do a semantic check for the input question Q by using a predefined vector database D.\nLet $q$ represent the query $Q$ as a semantic vector and $q \\in \\mathbb{R}^n$, where $\\mathbb{R}^n$ is an $n$-dimensional vector space, and $D = \\{d_1, d_2, ..., d_m\\}$ represent the set of database entries, where each $d_i \\in \\mathbb{R}^n$ is also an $n$-dimensional vector. To check the semantic similarity between the query $q$ and an entry $d_i$ in the database, this paper uses cosine similarity, which is a common measure for evaluating the similarity between two vectors in semantic space.\nThe cosine similarity $S(q, d_i)$ between the query vector $q$ and the database vector $d_i$ is given by Eq. 1:\n$S(q, d_i) = \\frac{q \\cdot d_i}{\\|q\\| \\|d_i\\|}$                                                       (1)\nWhere $\\|q\\|$ and $\\|d_i\\|$ are the Euclidean norms of the vectors $q$ and $d_i$. $S(q,d_i) \\in [-1,1]$, where 1 indicates perfect similarity, O indicates no similarity, and -1 indicates complete dissimilarity.\nTo determine if a query matches semantically with an entry in the database, a threshold $\\tau$ is set as $S(q, d_i) \\geq \\tau_d$, where $\\tau_d$ is a pre-defined threshold indicating a sufficient level of semantic similarity for query topic checking.\nNext, the Eq. 2 checks if $Q$ passes the semantic check and is a transportation-related query:\nT(X) = $\\begin{cases}  True & S(q, d_i) \\geq \\tau_d \\\\ False & S(q, d_i) < \\tau_d  \\end{cases}$                                                 (2)\nSimilarly, a general function $F$ takes $q$ and a set of reference vectors $r_i \\in \\mathbb{R}$, where $R$ is the database for vectors used to validate the existence of objective and scopes as a reference, as inputs and checks if the similarity of relevant terms or phrases in $Q$ is greater than threshold $\\tau$ :\nF(Q, R) = $\\begin{cases} True & if \\varphi(q, r_i) \\geq \\tau_r \\\\ False & if \\varphi(q, r_i) < \\tau_r  \\end{cases}$                                                        (3)\nWhere $R$ can be $O_r$ for objectives, $S_{tp}$ for time scopes, or $S_{lr}$ for location scopes.\nThis formulation allows the representation of conditions as Eq. 4 to 6:\nO(Q) = F(Q, O_r)                                                                     (4)\nS_{tp}(Q) = F(Q, S_{tp})                                                                   (5)\nS_{lr}(Q) = F(Q, S_{lr})                                                                    (6)\nFinally, the function $V(Q)$ determines if $Q$ is valid, ensuring it is transportation-related and contains both a rational objective and scope:"}, {"title": "3.3 SP Agent", "content": "To seamlessly integrate the user query Q into system instructions and generate effective LLM prompts, this paper introduces an AI agent that can optimize the prompts automatically. Building on the G-Eval method, this agent evaluates the initial prompt $P_d$, which contains Q, to identify areas for improvement. The prompt is then iteratively refined until it either reaches an optimal state or hits the maximum refining epoch, as shown in Algorithm 1. This iterative process guarantees the creation of high-quality prompts, improving the performance of complex LLM tasks within IDM-GPT, such as SQL generation and data analysis.\nAlgorithm 1 SP Agent\n1: Initialize prompt $P_d$\n2: Construct enhanced evaluation prompt $P_e$: $P_e = P_d + I_e + C_e$\n3: SET $epoch \\leftarrow 0$\n4: repeat\n5: \t$L_e$ generates chain-of-thought steps $CoT_e$\n6: \t$P_e.append(CoT_e)$\n7: \tCalculate score of $P_d$ using $Score(P_e)$\n8: \tif $Score(P_e) < \\tau_e$ then\n9: \t\tUpdate prompt $P_d \\leftarrow C(P_d)$\n10: \tend if\n11: \tINCREMENT epoch\n12: until $Score(P_e) \\geq \\tau_e$ OR epoch >= MAX epoch\n13: Return optimized prompt $P_o$\nIn this paper, we introduce an enhanced evaluation prompt $P_e$, which is derived from the initial prompt $P_d$ by adding two key components: the evaluation instructions $I_e$ and the evaluation criteria $C_e$. Specifically, $P_e$ is expressed as $P_e=P_d+I_e + C_e$.\nThe evaluation instructions $I_e$ guide the evaluator's task, for example:\nYou will receive a preliminary prompt. Your task is to refine it for clarity and specificity to improve the quality of the generated response.\nThe criteria $C_e$ outline the dimensions on which $P_d$ will be assessed, such as clarity, specificity, relevance, and brevity. An example for clarity might read:\nClarity (1-100) \u2013 The overall understandability and straightforwardness of the prompt. A clear prompt minimizes ambiguity and confusion, using simple language and avoiding jargon to ensure the task is precisely conveyed.\nAfter constructing $P_e$, the evaluation LLM $L_e$ generates chain-of-thought $CoT_e$ steps to assess $P_d$. Using the scoring function in Eq. 8, $L_e$ then scores $P_d$ based on both $P_e$ and $CoT_e$.\n$Score(P_e) = \\sum_{i=1}^{n}p(s_i) \\times s_i$                                                         (8)\nWhere $s_i$ represents the score for a given criterion, and $p(s_i)$ is the probability assigned to that score by $L_e$. This method allows $P_d$ to be scored with variance close to human judgments, minimizing the occurrence of ties.\nThen a threshold $\\tau_e$ is defined to determine if the similarity score is sufficient. If $Score(P_e) < \\tau_e$, $P_d$ will be passed through the LLM Prompt Optimizer $L_{opt}$, which generates optimization suggestions $C(P_d)$. The new prompt is then updated:\n$P_d \\leftarrow C(P_d)$                                                                (9)"}, {"title": "3.4 DBI Agent", "content": "In this research, system instructions are developed to guide the LLM in generating SQL queries, demonstrating the effectiveness of this approach. To ensure the accurate generation of SQL queries, instructions are meticulously crafted to provide detailed descriptions of the database schema and multiple examples of natural language questions paired with their corresponding SQL queries. These examples are carefully selected to illustrate the pattern and structure of the task, helping the LLM learn how to translate natural language into SQL syntax effectively. To further enhance the model's capability of handling different types of queries and generating appropriate SQL statements, examples covering a wide range of SQL operations, such as selection, filtering, aggregation, joining, and sorting, are incorporated.\nThe DBI Agent is integral to data privacy management, providing a secure interface between users and traffic databases that contain sensitive trip trajectory information. By mediating access, it minimizes direct human interaction with personal data, significantly reducing the risk of unauthorized exposure. Additionally, the agent employs customized prompts to anonymize personal travel details, ensuring compliance with data protection standards. This proactive approach not only safeguards user privacy but also strengthens data handling practices, fostering trust and reliability in managing sensitive information."}, {"title": "3.5 DAS Agent", "content": "The DAS Agent in IDM-GPT plays a crucial role in interpreting and visualizing traffic data. This agent takes an optimized prompt as input, which includes a description of the retrieved dataset. The process involves several key steps: understanding the dataset, planning the analysis, selecting appropriate machine learning models, analyzing and visualizing the data, discussing results, and deriving insights and suggestions. This process is represented in Algorithm 2.\nAlgorithm 2 DAS Agent\n1: Input: $D$, $Q_{user}$, $M$\n2: Output: Analysis result $R$, Insights $I$, Suggestions $S$\n3: $R, I, S, A \\leftarrow []$\n4: Step 1: Understanding the Dataset\n5: $D_{description} \\leftarrow Describe(D)$\n6: SET $P = \\{D_{description}, Q_{user}, M\\}$\n7: Step 2: Planning the Analysis\n8: $A \\leftarrow LLM.PlanSteps(P)$\n9: for each analysis step $a_i$ in $A$ do\n10: \tStep 3: Model Selection\n11: \t\t$M_j \\leftarrow LLM.ModelSelect(a_i, Q_{user}, M_j)$\n12: \tStep 4: Analysis and Visualization\n13: \t\t$R_j \\leftarrow M_j(D)$\n14: \tStep 5: Discussion and Insight Derivation\n15: \t\t$I_j \\leftarrow LLM.Interpret(R_j)$\n16: \t\t$S_j \\leftarrow LLM.Suggest(Q_{user}, I_j)$\n17: \t\tR.append(Rj)\n18: \t\tI.append(I)\n19: \t\tS.append(Sj)\n20: end for\n21: Return R, I, S\nAlgorithm 2 starts by accepting three inputs: the dataset $D$, the user query $Q_{user}$, and a structured description of alternative ML models $M$. The expected outputs are analysis results $R$, insights $I$ and suggestions $S$."}, {"title": "3.6 SS Agent", "content": "This agent ensures the quality of traffic analysis results by comparing them against predefined criteria and iteratively optimizing the results if necessary. In this agent, the G-Eval method is employed to obtain the evaluation score $E$ of the evaluation criteria $C$. The desired results criteria $C = \\{C_1, C_2, ..., C_n \\}$ consist of $n$ key components. Given the initial result $R$ and the desired result criteria $C$, the SS Agent operates through a series of steps to ensure the final output meets the specified criteria. This agent refines and improves the LLM's result by allowing the LLM to evaluate and improve its own output using the Recursive Criticism and Improvement (RCI) approach [57]. RCI is an iterative process designed to refine and enhance prompts to ensure they meet predefined quality standards. The process is shown in Algorithm 3.\nAlgorithm 3 SS Agent\n1: Input: $R$, $I$, $S$ from Algorithm 2, Desired Results Criteria $C$\n2: Output: Optimized Output Results $R'$, Insights $I'$, Suggestions $S'$\n3: SET $R' \\leftarrow R$\n4: SET $I' \\leftarrow I$\n5: SET $S' \\leftarrow S$\n6: SET $epoch \\leftarrow 0$\n7: repeat\n8: \t$E \\leftarrow \\mathcal{C}(R', I', S' | C)$\n9: \tif $E < E_{threshold}$ then\n10: \t\t$IS \\leftarrow \\mathcal{L}_{opt}(R', I', S' | C')$\n11: \t\t$Prompt \\leftarrow RCI(R', I', S', IS)$\n12: \t\t$R', I', S' \\leftarrow LLM.analyze(Prompt) \\{Algorithm 2\\}$\n13: \tend if\n14: \tINCREMENT epoch\n15: until $E >= E_{threshold}$ OR epoch >= MAX epoch\n16: return $R'$, $I'$, $S'$\nIn Algorithm 3 $R$, $I$, $S$ is evaluated against $C$ using an LLM reviewer $\\mathcal{L}$. This evaluation is represented by eq. 11 and eq. 12:\n$E = \\mathcal{C}(R, I, S | C)$                                                        (11)\n$E = \\sum_{i=1}^{n}p(s_i) \\times s_i$                                                                     (12)\nwhere $E$ denotes the evaluation score on how well the results meet the criteria. The evaluation score $E$ is calculated in eq. 12, where $S = \\{s_1, s_2, ..., s_t\\}$ represents a set of scores from 1 to $t$ predefined in the prompt, $p(s_i)$ represents the probability of $s_i$ calculated by the LLM. If $E$ indicates that the results are not satisfactory, i.e. $E < E_{threshold}$, the LLM generates improvement suggestions $IS$ by the optimization process $\\mathcal{L}_{opt}$. Based on $IS$, $R_{old}$, $I'$, and $S$, $R$ is regenerated by prompting with the RCI approach and calling Algorithm 2 to produce improved result $R_{new}$. The process iterates until $E$ meets or exceeds the threshold $E_{threshold}$, or the number of recursions reaches the maximum MAX epoch. This iterative optimization ensures that the traffic analysis results are continuously improved until they meet the predefined quality standards."}, {"title": "4 Experiments & Results Evaluation", "content": "This section aims to validate the performance of the proposed IDM-GPT in real-world transportation applications, especially focusing on the role of LLM in the IV Agent, SP Agent, DBI Agent, DAS Agent, and SS Agent. The data used in the experiment was collected from the loop detectors installed in the Greater Seattle Region. During the experiment, the similarity score between the outputs from IDM-GPT and the analysis results from human operators was used to evaluate the system's performance. Finally, sample results are presented to demonstrate the effectiveness of IDM-GPT."}, {"title": "4.1 Experiment Configuration", "content": "In this study, GPT-40 serves as the LLM for IDM-LLM, with the system constructed using Python 3.9 and OpenAI APIs. The experiments are conducted on a PC equipped with an NVIDIA RTX 4060 GPU, an Intel Core i9 CPU, and 32 GB of RAM, ensuring a robust computational environment. The choice of GPT-40 is driven by a balance between performance and cost considerations. The ML models provided to IDM-GPT for selection include traditional models and NNs, such as CNNs, LSTMs, and GNNs. For complex real-world tasks conducted by traffic agencies, fine-tuned LLMs can replace GPT-40, while modified ML models can be employed to achieve better performance, enhanced reliability, and reduced costs.\nFor the SP Agent, a threshold of $\\tau$ = 0.8 is set, and seven criteria are used: 1) clarity and precision, 2) context and relevance, 3) directiveness, 4) appropriate length, 5) structured format, 6) objective and neutral, 7) avoiding ambiguities, and 8) multiple questions.\nFor the DBI Agent, this paper defines 7 prompt-SQL categories to guide the LLM in generating SQL queries. These include select, conditional, join, aggregate, filter-with-join, date range, and group by queries, each designed to address specific data needs like retrieving, filtering, or segmenting information. Each category provides a structured prompt-SQL example, enabling the LLM to accurately map user queries to SQL by referencing targeted examples, thus enhancing query precision and effectively meeting user requirements. The example of the prompt-SQL pairs has been attached in Appendix 1 Example of prompt of DBI Agent.\nFor model selection in the DAS Agent, this paper provides 6 ML models for the LLM to choose from. The models include LSTM for handling long-term temporal patterns and traffic predictions, GNN for modeling and understanding spatial relationships, autoencoders for detecting traffic patterns, random forest for reasoning tasks, reinforcement learning for optimal routing selection, and Hidden Markov Models for detecting traffic flow irregularities.\nFor the SS Agent, the evaluation criteria for analysis results are described in the following sub-section. The total evaluation score ranges from 0 to 1, with a threshold $E_{threshold}$ set at 0.8. The maximum number of epochs is set to 3 for iterative refinement and assessment."}, {"title": "4.2 Evaluation Criteria", "content": "The LLM results evaluation criteria consist of two components: numerical results evaluation (NRE) and textual results evaluation (TRE). The NRE involves coding algorithms to validate the quality of the data retrieved from databases and to assess the accuracy of numerical analysis results generated by LLMs. The TRE focuses on evaluating the discussions of findings, insights, and suggestions derived from those insights using well-established criteria for LLM output evaluation. These criteria include coherence, relevance, factual accuracy, and logical flow, which are commonly applied in LLM evaluation frameworks such as BLEU, ROUGE, METEOR, and GPTScore. The detailed evaluation framework ensures a comprehensive assessment of both numerical and textual aspects of the LLM outputs, enhancing the reliability and quality of the results.\n\u2022 Data Integrity (DI): Verify that the input data used in the analysis is accurate, complete, and representative of the traffic conditions.\n\u2022 Result Correctness (RC): For queries with ground truth answers, like predictions and incident detections, evaluate the LLM's result in terms of MSE.\nGiven the open-ended nature of the analysis model selection and results of IDM-GPT, the G-Eval method is leveraged for evaluation. The evaluation criteria of the results include:\n\u2022 Model Validation (MV): Ensure the existence of ML model evaluation metrics such as mean absolute error (MAE), root mean square error (RMSE), R-squared, and precision/recall for classification tasks."}, {"title": "4.5 Ablation Study", "content": "IDM-GPT consists of five agents, with the DBI Agent and DAS Agent being essential to the framework's functionality, while the other three agents can be omitted. To validate the effectiveness of the IV Agent, SP Agent, and SS Agent, an ablation study was conducted by repeating the experiment and sequentially omitting each agent. The results of the average evaluation scores are compared among different agent-skipped systems and the baseline system without any agent skipped. The evaluation is summarized in Table 3.\nWhen the IV Agent is omitted, the framework performs poorly on the DI, RC, and CR scores. Without reformatting the user query or extracting its objective and scope, the LLM-based DBI Agent struggles to understand the user's intent, resulting in inadequate dataset retrieval. Consequently, the DAS Agent fails to generate relevant insights, leading to incorrect and ineffective responses to the user query.\nThe absence of the SP Agent lowers performance across all criteria. Without prompt optimization, the prompts become unclear, diminishing the effectiveness of LLM-based agents like DBI and DAS. Sub-optimally structured prompts cause IDM-GPT to overlook important requirements, resulting in inaccurate analyses and incomplete visualizations, which hinders its ability to derive meaningful insights."}, {"title": "5 Conclusions", "content": "Acquiring relevant traffic data and selecting appropriate models to support traffic management can be costly, time-consuming, and labor-intensive for transportation agencies. The complexity of advanced ML models demands significant resources for accurate results, while the widespread use of data collection devices raises concerns over personal mobility data privacy. IDM-GPT, as an AI agent, addresses these challenges by streamlining traffic data analysis, enabling the efficient and accurate processing of high-dimensional, spatio-temporal traffic data"}]}