{"title": "LOTUS: Enabling Semantic Queries with LLMs Over Tables of Unstructured and Structured Data", "authors": ["Liana Patel", "Siddharth Jha", "Carlos Guestrin", "Matei Zaharia"], "abstract": "The semantic capabilities of language models (LMs) have the potential to enable rich analytics and reasoning over vast knowledge corpora. Unfortunately, existing systems lack high-level abstractions to perform semantic queries at scale. We introduce semantic operators, a declarative programming interface that extends the relational model with composable AI-based operations for semantic queries over datasets (e.g., sorting or aggregating records using natural language criteria). Each operator can be implemented and optimized in multiple ways, opening a rich space for execution plans similar to relational operators. We implement our operators and several optimizations for them in LOTUS, an open source query engine with a Pandas-like API. We demonstrate LOTUS' effectiveness across a series of real applications, including fact-checking, extreme multi-label classification, and search. We find that LOTUS' programming model is highly expressive, capturing state-of-the-art query pipelines with low development overhead across these diverse applications. Specifically, on the FEVER dataset for fact-checking application, LOTUS' programs can reproduce FacTool, recent state-of-the-art pipeline, in few lines of code, and implement a new pipeline with a simple change of operators that improves accuracy by 9.5%, while offering 7 - 34\u00d7 lower execution time. In the extreme multi-label classification task on the BioDEX dataset, LOTUS reproduces state-of-the art result quality with its join operator, while providing an efficient algorithm that runs 800\u00d7 faster than a naive join. In the search and ranking application, LOTUS allows a simple composition of operators to achieve 5.9 \u2013 49.4% higher nDCG@10 than the vanilla retriever and re-ranker, while also providing query efficiency, with 1.67 \u2013 10\u00d7 lower execution time than LM-based ranking methods used by prior works. LOTUS is publicly available at https://github.com/stanford-futuredata/lotus.", "sections": [{"title": "INTRODUCTION", "content": "The powerful semantic capabilities of modern language models (LMs) create exciting opportunities for building AI systems that reason over vast knowledge corpora. Many applications require complex reasoning over large amounts of data, including both unstructured and structured data. For example a researcher reviewing recent ArXiv [2] preprints may want to quickly obtain a summary of relevant papers from the past week, or find the papers that report the best performance for a particular task and dataset. Similarly, a medical professional may automatically extract biomedical characteristics and candidate diagnoses from many patient reports [32]. Likewise organizations may wish to automatically digest lengthy transcripts from internal meeting transcripts and chat histories to validate hypotheses about their business needs and productivity [5]. Each of these tasks require a form of bulk semantic processing, where the Al system must process large amounts of data in often complex query patterns to perform the reasoning task at hand. Supporting the full generality of these applications with efficient and easily programmable query systems would have transformative impact. This prospect, however, raises two important and challenging questions: first, how should developers express semantic queries, and secondly, how should we design the underlying query system to achieve high efficiency and accuracy."}, {"title": "THE LOTUS PROGRAMMING MODEL", "content": "We now introduce the LOTUS programming model and show its expressive power in allowing developers to declaratively specify AI-based query pipelines that bulk process large datasets of structured and unstructured data. LOTUS extends the relational model with semantic operators, which we show in Table 1. These operators can be easily composed together with standard relational operators to build powerful programs that are transparently optimized (Section 3). In this section, we describe each semantic operator and our API for them in LOTUS, grounding each in concrete examples. While our current API implementation extends Pandas [12], LO- TUS' semantic operators could be used with other existing relational query languages and APIs, such as SQL."}, {"title": "Datatypes", "content": "LOTUS' data model consists of tables with structured and unstructured text fields, and our current implementation extends Pan- das [12]. Figure 2 shows an example LOTUS program that loads data about ArXiv papers and performs a summarization task, which finds relevant papers, filters according to whether the paper claims to outperform a specific baseline, and then summarizes the remaining papers into a single digest. We briefly describe two core compo- nents of LOTUS programming model: its data model (Section 2.1.1), and its parameterized natural language expressions (Section 2.1.2) for specifying semantic operations over the data."}, {"title": "Data Model", "content": "LOTUS is designed to seamlessly extend the relational model. Each row in the table, represents a logical entity. Table columns may contain either structured data or unstructured fields with free-form natural-language text. LOTUS' semantic-relational operators can take both of these data-types as inputs. Figure 3 shows an example table, where each rows represents an ArXiv paper document, with fields for the paper's title, ArXiv URL, abstract, ArXiv domain categories, and the publication date. These columns are then passed as parameters to semantic-relational op- erators, such as sem_search, sem_filter, sem_agg, as shown in Figure 2. Additionally, LOTUS supports semantic similarity indices over natural-language text columns to provide optimized semantic query processing. These indices create embeddings over each document in the column to capture semantic similarity using embedding distance metrics. Semantic indexes can be created off-line and then loaded us- ing sem_index and load_sem_index. Figure 2 provides an example program, where upon reading the ArXiv papers data from a CSV file, the programmer loads a semantic index over the abstract column. The program then repeatedly uses the semantically-indexed col- umn in subsequent LOTUS operations, involving semantic search, filtering and aggregation."}, {"title": "Parameterized Natural Language Expressions (langex)", "content": "A core principle of LOTUS is to provide users with a declarative interface that separates the user-specified, logical query plan from its underlying implementation. As such, users program with LOTUS' semantic operators by writing parameterized natural language expressions (langex\u00b9), rather than directly prompting an underlying LM. Figure 2 shows an example of this, where the programmer provides a langex as the parameter to the sem_filter (line 18) and sem_agg (line 19) operations. Programmers write each langex in natural language text, parameterized by one or more data columns, which are indicated in the double brackets within the formatted string. The function of these expressions varies according to the semantic operator used and may represent a predicate, aggrega- tion, comparator function, or projection in natural language. For instance, as shown in Figure 2, the langex signature of sem_filter"}, {"title": "Semantic Operators", "content": "We now overview each semantic operator and their corresponding LOTUS API. Table 1 provides a concise summary of each operator.\nSem_filter returns the subset of rows that pass the filtering condi- tion, specified by the user's langex. As Figure 4 shows, the langex signature provides a semantic predicate over one or more table columns and can be answered by a binary \"True\" or \"False\" answer. Sem_topk ranks a set of rows according to the user-defined criteria, and returns the K rows that best match the ranking criteria. The signature of the langex provides a general ranking criteria according to one or more columns. The underlying system can use this langex to impose a ranking over any subset of rows, according to the chosen implementation. As Figure 5 shows, the programmer uses the langex to specify arbitrary reasoning-based ranking criteria, such as ranking paper abstracts by the most outrageous claim made. Programmers can also optionally specify a group-by parameter to indicate a subset of columns to group over during ranking, as shown in 6. The groupings are defined using standard equality matches over the group-by columns. To use groupings according to semantic similarity, users can also perform a sem_cluster_by and pass the resulting cluster_id column as the group-by column parameter. Sem_join combines data from two tables, evaluating the user's predicate to return the set of rows from the left and right table that pass. As Figure 7 shows, users specify the right join table, a langex, and optionally, the join key of the left and right tables. Here the langex contains two or more columns, and provides a predicate over the left and right tables. By default, the operator performs an inner join over the two tables, and can alternatively perform left, right or outer joins, if specified. Sem_sim_join provides a variant of the semantic join, such that rows are matched according to their semantic similarity, rather than an arbitrary natural-language predicate. Akin to an equi-join in standard relational algebra, the semantic similarity join is a specialized semantic join. Figure 8 provides an example, where one table contains papers with an indexed column of abstracts, and the other table contains a list of research interests. The user specifies the left and right table join keys, and a parameter K. The left join key may or may not be indexed, whereas the the right join key must be a semantically indexed column with its index loaded. The operator performs a left join such that for each row in the left table, the output table will contain K matching rows from the right table with the highest similarity scores. The programmer can also optionally specify a return column containing the semantic similarity scores of each joined row. Sem_agg performs an aggregation over all rows of the table. As Figure 9 shows, the langex signature provides a commutative and associative aggregation function, which can be applied over any subset of rows to produce an intermediate results. Semantic aggre- gations can be useful for many tasks involving many-to-one reduc- tion patterns, such as summarization or question-answering over multiple documents. Similar to sem_topk, users can also specify a group-by parameter to use. We also provide additional flexibility, by allowing the programmer to compose semantic aggregations with sem_partition_by, which provides finer-granularity control over how documents are grouped over in each LM invocation. We describe this further below, and show its use in Section 3 for over- riding the default commutativity and associativity assumptions for some tasks. Sem_partition_by creates a row partitioning over the table, which will be used by sucessive calls to sem_agg to decide which rows to group together within each LM invocation. We find in Section 3 that this can non-trivially affect the result quality of aggregation tasks, like summarization. As Figure 10 shows, sem_partition_by takes a function, which outputs a group-id for each row. LOTUS natively supports a semantic cluster function, which takes the number of clusters to create and a column, but users can also specify arbitrary partition functions. The group-ids output by the partition function indicate to the system which rows should be grouped to- gether, in a best-effort manner, during LM invocations. The system will aggregate over documents within each group, before merging intermediate results across groups. Sem_map performs a natural language projection over an exist- ing column and outputs a new column in the table. As shown in Figure 11, the user's langex specifies what to project. This operator provides general functionality and simulates logically row-wise data-flow similar to prior works that use LLM-UDFs in relational languages [60, 61]. These semantic projections are broadly useful for a variety of tasks, such as row-wise summarization, classifica- tion, and entity-extraction. Sem_extract provides similar functionality to sem_map but pro- vides the answers by returning a list of sub-strings from the source text. This functionality is useful for applications, such as entity ex- traction or fact-checking, where snippet-finding or verified quotes may be preferable to synthesized LLM-based answers. As Figure 12, the user's langex signature specifies a projection, similar to sem_map. Sem_index generates a semantic similarity index over the specified data column, as shown in Figure 13. To generate the semantic index, users first use the settings module to declare a retrieval model, which will be used for generating semantic embeddings and indexing the column data. The sem_index operator takes a column and a local directory path, to which the generated semantic index will be stored. As the figure shows, users can separately index multiple columns of the table. Load_sem_index re-loads the stored semantic index upon reading the table data from disk, as shown in Figure 14. The user specifies the column corresponding to the semantic similarity index and the directory where the index was saved. Sem_search performs a top-k semantic similarity search over a semantically-indexed column, as Figure 14 shows. The user specifies the table column to search over, a query in natural language, a target K of the number of results to return, and optionally indicates whether to return similarity scores as a column in the returned table. LOTUS also exposes advanced relevance-based re-ranking func- tionality for search. Users can specify a re-ranker model, as shown in Figure 15, and then set the n_rerank parameter during the se- mantic search. The semantic search in this case will first find the top-K most relevant documents according to the retriever model, and then re-rank the top-K found documents to return the top n_rerank ones using the re-ranker model. Sem_cluster_by assigns a group to each row of the table according to semantic similarity. This operator is akin to a relational group_by, but uses semantic similarity to determine the groups, rather than equality over the specified column. As Figure 16 shows, the user specifies an indexed column to cluster, and the number of clusters to create. The returned table augments the input table with an additional column that specifies the assigned cluster_id of each row. Users can optionally also return the similarity scores between each row and its cluster centroid in an additional column of the returned table."}, {"title": "IMPLEMENTING AND OPTIMIZING SEMANTIC OPERATORS", "content": "Semantic operators create a rich design space, allowing for a diverse set of algorithmic decisions and optimizations which have significant consequences on system efficiency and accuracy. We identify multiple possible algorithms for these operators, noting their performance implications. LOTUS' query engine aims to automatically exploit this rich design space to provide an optimized implementation of each individual operator and composite pipelines. Specifically, LOTUS employs a series of novel algorithms designed to leverage the semantics of each operator in order to maximize parallel batched-inference opportunities, use model cascades [28, 46, 48, 78, 83] with a lightweight scoring function unique to our setting, leverage the semantic similarity index, and perform algorithmic approximations for expensive operations (e.g. joins). We see in Section 4 that these decisions can significantly improve efficiency while maintaining high quality results for LOTUS' query pipelines. While our initial investigation studies several operator-specific design decisions unique to the semantic bulk processing setting, we envision a rich set of additional optimization opportunities. Several prior works demonstrate performance gains in both logical query plan optimizations (e.g. operator re-ordering [57, 58, 61, 64]) and other general LM-approximation techniques (e.g. code synthesis [24, 58] and prompt adaptation [28]), which we find to be promising opportunities for LOTUS' implementation, left to future work. LOTUS' current implementation extends the Pandas API [12]. We leverage VLLM [53] to perform efficient batched inference, and we use FAISS [43] for efficient vector similarity search."}, {"title": "sem_filter", "content": "LOTUS' semantic filter runs batched LLM calls over a set of rows, prompting the model to output a boolean value for each row to indicate whether the record passes the user's natural language predicate. Figure 18 shows an example of the operator-specific filtering instruction, which is managed transparently by the system."}, {"title": "Optimizations", "content": "We leverage model cascades, using an efficient scoring function unique to our setting, to further optimize the filter function. Many prior works have studied model cascades for ML tasks [28, 46, 48, 78, 83], leveraging a relatively cheap and inaccurate proxy model, along with an accurate but expensive oracle model in order to reduce the inference cost by routing easy queries to the small model, and resorting to the large model where necessary. Typically, a scoring function provides confidence scores over the proxy model's outputs, and allows the system to decide when to route examples to the larger model. Applying this paradigm to LMs introduces several challenges, including generating a reliable scoring function. Several works study this problem, suggesting to fine-tune a smaller LM to score each question along with the answer produced by the weak LLM [28], or invoking multiple sampling paths from the small LM and evaluating self-consistency to build a confidence score [83]. While these methods provide general-purpose scoring functions, LOTUS' scoring function leverages the operator semantics to provide a lighter-weight scoring function, which avoids the execution time penalty of scoring with an additional model or re-sampling from the proxy-model. Specifically, LOTUS' cascade scoring function leverages the binary-label output of each LM invocation. The system first batch-processes each record using the cheaper LM, then computes confidence scores by exponentiation the log-probabilities for the output LLM tokens corresponding to the True or False answer. For records with confidence scores below the user-defined threshold, the system then passes these records in batch to the larger LM. As we show, in Section 4, leveraging model cascades in this way for semantic filtering can significantly improves the system's efficiency while maintaining high quality results for some tasks."}, {"title": "sem_topk", "content": "Performing a semantic top-k ranking requires logically reasoning across rows, entailing joint reasoning over often large amounts of data. Implementing an efficient algorithm introduces many important design decisions pertaining to managing LM context length limits, grouping documents within each LM context window to achieve high quality LM-based comparisons over subsets of the data, and choosing an efficient top-k ranking algorithm to com- bine LM-based comparisons. These decisions have notable performance implications on efficiency and result quality, as we show in Section 4. While prior works have studied LM-based passage re-ranking [30, 33, 56, 65, 69-72, 74] and ranking with noisy com- parisons [26, 73] with the goal of achieving high quality results in a modest number of total LM calls or comparisons, LOTUS' implementations provides a generalized ranking algorithms for arbitrary natural language expressions and aims to produce both high quality results and low query execution time. We leverage several algorithmic design decisions and optimizations to achieve this."}, {"title": "Algorithms", "content": "Prior LM-based sorting and ranking works suggest several methods for performing LM-based comparisons. Specifically, prior works primarily study three classes of methods: point- wise ranking methods [30, 33, 56, 72, 82], list-wise ranking methods [65, 69, 70, 74], and pair-wise ranking methods [71, 73]. Point- wise methods output a relevance score for each document independently; while these methods are fully parallelizable across rows, prior work [30] shows they provide poor accuracy due to difficulty in calibrating scores across prompts. We note that these methods can be implemented in LOTUS with a sem_map, but are not the focus of our semantic top-k operator due to their quality limitations. By contrast, list-wise methods feed a partial list of 10 to 20 documents to the LM and prompt it to output a ranking over these, which can be aggregated using a sliding window approach. Unfortunately, prior works shows these methods are often prone to prediction failures [74] and sensitive to document ordering in the prompt [71]. Pairwise-prompting methods instead offer a simple and effective approach that feeds a single pair of documents to the LM in each invocation, prompting the model to perform a comparison and output a binary label. This method has been shown to be an effective base unit for ranking with relatively high robustness to input order sensitivity [71]. To aggregate pairwise comparisons, we consider several ranking algorithms, including a quadratic sorting algorithm, a heap-based top-k algorithm and a quick-select-based top-k ranking algorithm. The quadratic ranking algorithm obtains a comparison between each pair of input documents, and uses a win rate to determine a ranking over all elements before selecting the k best. In contrast, the heap-based algorithm maintains a heap of size k, and makes a linear pass over the data, updating the heap when more promising elements are found. Each time a new element is inserted or removed from the heap, the algorithm performs a series of sequential LM comparisons to update the data structure. Lastly the quick-select based algorithm proceeds in successive rounds, each time choosing a pivot, and comparing all other remaining elements in the document set to the pivot item to determine the rank of the pivot. Because each round is fully parallelizable, we perform these LM- based comparisons efficiently in batch before recursing in the next round."}, {"title": "Discussion", "content": "As the core LM-based computation unit over subsets of the data, LOTUS' current implementation uses pair-wise rankings, following recent prior work [71], which demonstrates its effectiveness. We also find this choice useful for implementing further optimizations, such as model cascades, described below."}, {"title": "Optimizations", "content": "LOTUS' top-k algorithm is amenable to several optimizations. First, the top-k algorithm's pair-wise compar- isons each invoke the LM to output a binary label, which is amenable to model cascades. To implement this, we use a simple an efficient scoring procedure based on log-probabilities of the generated tokens. We describe this procedure above for sem_filter (Section 3.1.1) and apply an equivalent procedure here. In Section 4, we demonstrate this optimization allows programmers to leverage small, cheap models in conjunction with large, expensive models to obtain high accuracy results at reduced cost. Additionally, LOTUS can leverage the semantic index to optimize pivot selection for some queries, rather than resorting to random pivot selection. This optimization is useful when there exists corre- lation between the rankings imposed by the user's arbitrary sorting criteria and the rankings imposed by semantic similarity scores. In this case, LOTUS can sort the document set based on embedding distances to the user's query, and select the (k + \u20ac)-th item, rather than a random item, as the first pivot. This can reduce the number of LM comparisons required by subsequent rounds in the quick- select algorithm, leading to higher query efficiency at no accuracy loss. We believe fruitful future work will automatically estimate correlation between semantic similarity scores and the user-defined ranking criteria to transparently apply this optimization."}, {"title": "sem_join", "content": "Performing the semantic join involves evaluating the user's natural language predicate on each pair of rows in the left and right table. Implemented naively, this can be prohibitively expensive, incurring a quadratic number of LM calls with respect to to the size of the left and right join tables. LOTUS thus implements several algorithms suitable for a variety of settings, highlighting the rich design space, which we plan to further optimize over in future work. Here we describe the design patterns currently implemented, which we find to be useful for real-world tasks that we evaluate in Section 4."}, {"title": "Algorithms", "content": "The first join algorithm implements the nested- loop join pattern with efficient LM batch processing to maximize GPU utilization rather than naively looping over each pair of rows and invoking the LM. This yields an $O(N_1 N_2)$ LM call complexity, where $N_1$ and $N_2$ are the table sizes of the left and right join tables respectively. As Figure 18 shows, each LM call instructs the model to output a boolean value after evaluating the user's natural language predicate. This quadratic join algorithm is suitable for small join tables. Alternatively, we implement a map-search-filter join pattern which can be used to approximate the quadratic join algorithm, while incurring fewer LM calls. This algorithm first performs a semantic mapping over the left join key to the domain of the right join key. In the example provided by Figure 20, which joins paper abstracts with the datasets they use, the map step would invoke the LM over each abstract, instructing the model to output the dataset used. This step is un-grounded in the sense that the LM is not given knowledge of right join table, but may optionally leverage user-specified demonstrations. Following the semantic projection, the algorithm then leverages the semantic index and performs a similarity search over the right join table to find candidates likely to pass the predicate. In the example, this search would retrieve a list of datasets from the right table for each paper, using semantic similarity of the datasets to the LM projection output in the first step. The semantic similarity search is parameterized by K, which is automatically set based on the user's specified LM call budget. Lastly, the algorithm performs a filter over the candidate pairs and outputs the joined table of tuples pairs that pass. This join algorithm partially mimics the information flow of prior work [31] and abstracts away intermediate steps by instead allowing users to specify an LM call budget for the join. The LM call complexity of this algorithm is $O(N_1.K)$. Lastly, we implement a search-filter join pattern. This algo- rithm first performs a semantic similarity join using a similarity index on the right join key, with the left join key embedded on the fly. In the example provided by Figure 20, this step would retrieve K semantically similar datasets from the right table for each paper abstract in the left table. The batched semantic-similarity search sets the search parameter K according to the user's specified LM call budget, similar to the map-search-filter algorithm. The search results provide candidate tuple pairs, which are then evaluated in batch using the filter operation to gather the final set of rows that pass the user's language predicate. This algorithm obtains an LM call complexity of $O(N_1K)$."}, {"title": "Discussion", "content": "These join patterns offer performance tradeoffs suitable for different settings. The nested-loop algorithm offers an efficient solution when the join tables are sufficiently small, whereas the map-search-filter and search-filter patterns are suitable approx- imations that can apply efficiently over large tables, due to their linear LM call complexity in table size. The expected result quality of either approximation likely varies depending on the presence of"}, {"title": "sem_agg", "content": "Performing semantic aggregations are inherently challenging because, similar to the semantic top-k, it requires logically reasoning across rows. Thus, the operator's implementation must efficiently orchestrate the LM over large amounts of data, while managing long context inputs, which may degrade result quality [59] or overflow the underlying model's context length. LOTUS aims to abstract away such low-level details from the user and provides an efficient implementation, designed to support high quality results and provide the programmer with flexibility."}, {"title": "Algorithms", "content": "LOTUS' implementation builds on and generalizes the LM-based summarization pattern studied by prior research works [19, 27, 81] and deployed systems [8, 14]. These implementations primarily leverage one of two aggregation patterns: either a fold pattern, which produces a sequential, linear pass over the data while iteratively updating an accumulated partial answer, or a hierarchical reduce pattern, which recursively aggregates the input data to produce partial answers until a single answer remains."}, {"title": "Discussion", "content": "By default, LOTUS' aggregation implements the hierarchical pattern, which allows for greater parallelism during query processing and has been shown to produce higher quality results for tasks like summarization in prior work [27]. However, LOTUS' partition function can be used to override the default functionality and generalizes the information flow of prior implemen- tation by allowing users to specify arbitrary groupings over the data. Each unique group specified by the partition function will be aggregated with as few LM invocations as possible according to the model context length, before being merged with other groups. This allows the user to perform a fold pattern, as well as arbitrary user-defined patterns."}, {"title": "Optimizations", "content": "Preliminary results show that achieving high- quality semantic-aggregations is non-trivial and sensitive to the document's input ordering and grouping. We see qualitative evi- dence of this in a summarization task of 50 ArXiv paper abstracts, which we show in Figure 21. We contrast the summarization results of a naive semantic aggregation (Figure 22) performed over the paper abstracts with the semantic aggregation performed using a partitioning function based on semantic similarity (Figure 23). The semantic aggregation using the partitioner first clusters documents based on semantic similarity, then aggregates each cluster before performing aggregations across clusters. As the figures show the two methods result in significantly different summaries. While the latter demonstrates qualitatively more cohesion and effectively ab- stracts general themes across papers, the former omits details and tends to list low-level details from individual papers rather than capturing higher-level themes. We leave a quantitative study of this to future work and believe that semantic aggregations create a rich design space for optimization."}, {"title": "sem_map & sem_extract", "content": "Both LOTUS' semantic map and extract run batched LM calls over a set of rows, prompting the LM with the user's arbitrary natural- language expression to generate a new column. Both functions can be fully parallelized over rows, and LOTUS implements efficient batched inference with VLLM [53]. To implement sem_extract, LOTUS prompts the model to answer the user's langex with direct quotes, and the system then verifies that these snippets returned by the LM match the reference text."}, {"title": "Semantic Indexing", "content": "LOTUS supports several different algorithms for its semantic index. To generate the semantic similarity index, LOTUS' sim_index op- erator first batch processes the user-specified column to generate"}, {"title": "EVALUATION", "content": "We now evaluate LOTUS' programmability and efficiency through three diverse applications: fact-checking (Section 4.1), extreme multi-label classification (Section 4.2), and search and ranking (Section 4.3). For each of these applications, we see that state-of-the-art quality results are achievable with low development overhead, us- ing LOTUS programs with a few lines of code and a few or even one semantic operator. In addition, our results demonstrate interesting implementation and optimization choices introduced by semantic operators. Specifically, we find that: \u2022 On the FEVER dataset [77] for fact-checking, LOTUS pro- grams can reproduce FacTool [29], a recent state-of-the-art pipeline, in few lines of code, and implement a new pipeline with a simple change of operators that improves accuracy by 9.5%, while offering 7 - 34\u00d7 lower execution time. \u2022 On the BioDEX dataset [32] for the extreme multi-label classification task, LOTUS reproduces state-of-the art re- sult quality [31] with it's join operator, while providing an efficient algorithm that runs up to 800x faster than a naive join, demonstrating the power of LOTUS' declarative interface. \u2022 On the SciFact dataset [76] and two newly-constructed paper datasets for the search and ranking application, LO- TUS's semantic top-k operator achieves 5.9 - 49.4% higher nDCG@10 than a vanilla retriever and re-ranker, while also running 1.67 - 10x faster than alternative LM-based ranking methods used by prior works [71]. Unless otherwise stated, we run our local model experiments with 4 A100 GPUs using Llama 3 models [7], with a batch size of 64 running on vLLM [53]. For our experiments that use OpenAI's GPT models [11], we run with 64-way thread parallelism."}, {"title": "Application: Fact-Checking", "content": "We evaluate on FEVER [77], a claim verification dataset. We use the development dataset, which contains about 38,000 total claims, of which we sample 500 for our evaluation. Each claim is labeled with one of three labels, \"Supported\", \"Refuted\", or \"NotEnoughInfo\", and the task is to correctly determine the label of each claim, leveraging evidence from a corpus of 5.5 million Wikipedia articles. We merge the latter two labels in to a single class, \"Not Supported\", following prior work [29] for our evaluation."}, {"title": "Baselines", "content": "FacTool [29] is a recent research work that pro- poses a multi-step pipeline for fact-checking involving, claim ex- traction, query generation, tool querying, evidence collection, and"}, {"title": "LOTUS Programs", "content": "We compose several intuitive LOTUS pro- grams, each in less than 50 lines of code. For each one, we use ColBERT as the retriever model for creating the semantic index, and we use Llama 70B as the primary LM, and Llama 8B and TinyL- lama for cascade optimizations. First, we compose a pipeline designed to directly re-implement FacTool's information flow in LOTUS. Figure 24 shows the pseu- docode for the LOTUS-FacTool pipeline. The two tables are shown by wiki_df, which stores the Wikipedia articles, and claim_df, which stores the claims from the FEVER dataset. After loading the semantic index to wiki_df, the pipeline first performs a semantic map over each claim to generate two search queries, which are then used to perform a semantic similarity join over the corpus of Wikipedia articles. The program then concatenates the context retrieved for each claim, and performs a sem_map to output whether the claim is true or false, along with a revised claim if the claim is false. We use the same prompts found in FacTool [6], which include 3 demonstrations for generating search queries in the first sem_map, and chain-of-thought prompting in the second sem_map. The next program, LOTUS-fact-filter, makes a simple, single- operator modification to the LOTUS-FacTool program, replacing the semantic map at the end of the query pipeline, with LOTUS' semantic filter operation. We use 3 demonstrations for the filter. Figure 25 shows the pseudocode for this program. We evaluate this program with and without model cascades for the semantic filter operation. Lastly, we compose an alternative pipeline, LOTUS-fact-join. As the pseudocode shows in Figure 26, the pipeline first performs a semantic map over each claim to obtain a set of sub-claims. From this, we create the claimed_facts_df, which separates each sub- claim into a different row. Next, the pipeline uses these sub-claims to perform a semantic similarity join over the Wikipedia corpus, then"}, {"title": "Results", "content": "Table 2 demonstrates the powerful abstraction that LOTUS provides, allowing programmers to quickly write and test programs that compose simple operators to obtain state-of-the- art results. We report the accuracy of each benchmarked method, an estimate of lines of code (LoC), and execution time in seconds both with and without batching. We see that FacTool's implemen- tation offers strong accuracy performance on the FEVER datasets, however the full repository required several hundred lines of code, highlighting the development burden of building these applications without abstractions for semantic-bulk processing. By contrast, each LOTUS program offers comparable or higher accuracy, in rel- atively few lines of code. We also note that FacTool implements its method without batching, whereas LOTUS, by default, leverages batched LM execution for efficiency. To provide an apples-to-apples comparison, we compare FacTool's un-batched implementation to the LOTUS programs both with and without batching. First, we see from the Table 2 that LOTUS-FacTool is able to reproduce the result quality and efficiency of the original method's implementation, with 6.5 points higher accuracy and 1.2\u00d7 lower execution time without batching. The LOTUS-FacTool implementation with batching further decreases execution time compared to the original FacTool implementation by 10x. We see that the next LOTUS pipeline simply changes a single operation, switching the sem_map to a sem_filter, and maintains similar result quality to LOTUS-FacTool while further reducing execution time by 1.72\u00d7 in the batched implementation. Leveraging LOTUS' filter operation allows the programmer to further optimize the program using model cascades, which increases accuracy by 3 points and"}]}