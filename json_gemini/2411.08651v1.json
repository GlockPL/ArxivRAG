{"title": "Estimating unknown parameters in differential equations with a reinforcement learning based PSO method", "authors": ["Wenkui Sun", "Xiaoya Fan", "Lijuan Jia", "Tinyi Chu", "Shing-Tung Yau", "Rongling Wu", "Zhong Wang"], "abstract": "Differential equations offer a foundational yet powerful framework for modeling interactions within complex dynamic systems and are widely applied across numerous scientific fields. One common challenge in this area is estimating the unknown parameters of these dynamic relationships. However, traditional numerical optimization methods rely on the selection of initial parameter values, making them prone to local optima. Meanwhile, deep learning and Bayesian methods require training models on specific differential equations, resulting in poor versatility. This paper reformulates the parameter estimation problem of differential equations as an optimization problem by introducing the concept of \"particles\" from the particle swarm optimization algorithm. In this framework, the solution is represented as a swarm of particles, each embodying a candidate solution through its position and velocity. The particles iteratively update through mutual interactions, facilitating convergence toward an optimal solution. Building on reinforcement learning-based particle swarm optimization (RLLPSO), this paper proposes a novel method, DERLPSO, for estimating unknown parameters of differential equations. We compared its performance on three typical ordinary differential equations with the state-of-the-art methods, including the RLLPSO algorithm, traditional numerical methods, deep learning approaches, and Bayesian methods. The experimental results demonstrate that our DERLPSO consistently outperforms other methods in terms of performance, achieving an average Mean Square Error of 1.13 \u00d7 10-05, which reduces the error by approximately 4 orders of magnitude compared to other methods. Apart from ordinary differential equations, our DERLPSO also show great promise for estimating unknown parameters of partial differential equations. The DERLPSO method proposed in this paper has high accuracy, is independent of initial parameter values, and possesses strong versatility and stability. This work provides new insights into unknown parameter estimation for differential equations.", "sections": [{"title": "1 Introduction", "content": "At every moment, vast amounts of data are being collected through various human activities. Uncovering the hidden dynamics from these data is a fundamental yet challenging problem across many different fields [1]. Ordinary differential equations (ODEs) model the rates of change in dynamic processes across time or space. They are extensively used to describe complex systems in science, physics, economics, pharmacokinetics, neurophysiology, and systems biology [2]. Accurately estimating the parameters of equations is crucial in scientific research for drawing reliable and valid conclusions. Unknown or inaccurately estimated parameters can lead to results that misrepresent reality, hindering our understanding of scientific phenomena and laws. Therefore, accurately estimating these parameters before analyzing the system is particularly important to avoid such issues [3]. ODEs are prevalent in various research fields, but universally accepted methods for estimating their parameters are lacking. This limitation hampers our understanding and prediction of system behavior, highlighting the critical need to estimate unknown parameters in ODES.\nThere are two commonly used methods for parameter estimation in ODEs: numerical solution methods and non-parametric methods. Numerical methods use the least squares method to fit the ODE solutions to observed data, providing parameter estimates that accurately represent actual behavior. However, due to the lack of analytical solutions for many ODEs, these methods can be computationally intensive. In contrast, non-parametric methods bypass explicit ODE solutions, utilizing smoothing techniques for estimation. While this reduces computational overhead, it complicates optimization, making it more sensitive to noise and prone to converging on local optima. Edsberg et al. [4] used numerical methods for parameter estimation, which have some drawbacks: using ODE solvers can increase computational complexity [3], and optimization methods may heavily rely on initial parameter values, making them prone to getting trapped in local optima.\nTo improve computational efficiency, Varah [5], Ramsay and Silverman [6], as well as Chen and Wu [7], proposed a simplified two-stage method to avoid the direct numerical solution of ODEs. In the first stage, the state functions and their first-order derivatives are estimated from observed data and treated as fixed variables. In the second stage, the parameters are estimated using standard least squares methods. This method performs well for simple ODEs. However, accuracy may diminish when estimating higher-order derivatives in many ODEs. To improve efficiency and increase estimation accuracy, Ramsay et al. [8] proposed the parameter cascade method, a generalized smoothing technique. This method models the unknown solutions of ODEs as a linear combination of B-splines, applying penalized smoothing to the observed data. The penalty term, defined by the ODEs, helps prevent overfitting of the non-parametric function.\nRecent advancements in Bayesian methods for parameter estimation in ODEs have been notable. Wakefield [9] and Lunn [10] applied Bayesian methods to pharmacokinetic models. However, the computational intensity of this Bayesian approach stems from the need to numerically solve the ODEs at each iteration of the Markov Chain Monte Carlo (MCMC) process, significantly affecting efficiency. Huang et al. [11] proposed a Bayesian method that replaces ODEs constraints with probabilistic expressions and integrates them with non-parametric data fitting into a joint likelihood framework, using a MCMC sampling scheme. However, this method requires prior knowledge of the structure of ODEs, and may not yield satisfactory results for complex ODEs.\nThe development of machine learning algorithms has significantly enhanced the numerical solution and parameter estimation of ODEs. Brunton et al. [12] combined sparse regression and machine learning with nonlinear dynamical systems to extract governing equations from noisy data, addressing the challenge of idenfitying control equations. However, this method relies on the chosen measurement variables and function basis. If chosen improperly, it may not be able to identify an accurate sparse model. Raissi et al. [13, 14] used physics-informed neural networks (PINNs) to estimate parameters in various physical systems. In this approach, parameters are incorporated as part of the network training process, and once the network training is completed, the optimized parameter values can be obtained. Additionally, Neural Ordinary Differential Equations (Neural ODEs) [15] extend deep neural networks to continuous-time applications, offering high memory efficiency, strong flexibility, and effectiveness in time series tasks. Challenges remain, however, in computational costs and parameter tuning, particularly for complex systems and large datasets, necessitating further optimization of model efficiency and training duration.\nArloff et al. [16] proposed a two-step method to address that avoids numerical challenges in stiff ODEs via polynomial approximation and reduce the parameter search space using the Particle Swarm Optimization (PSO) algorithm. This approach is effective for complex stiff ODEs, identifying feasible solutions with reduced computational load. However, it only narrows the parameter space and the quality of its solution relies on the accuracy of the polynomial approximation. PSO is a swarm intelligence algorithm known for its strong global search capability, simple parameter configuration, rapid convergence, ease of implementation, robustness, and wide applicability in complex optimization problems. Wang et al. [17] developed a large-scale optimization algorithm, RLLPSO, which integrates PSO with reinforcement learning (RL) to enhance the speed and accuracy of convergence.\nWe reformulates parameter estimation of differential equations as an optimization problem, and introduce a novel method, DERLPSO, to solve it. DERLSPO enhances RLLPSO with several novel strategies, i.e., logarithmic initialization, reinitialization mechanisms, and bottom-up update strategy, to achieve higher convegence speed, as well as more accurate and stable estimation. The DERLPSO method is independent of initial parameter values and exhibits high versatility and generalization capabilities. It has been tested on three types of ODEs: Lorenz, FitzHugh-Nagumo, and Lotka-Volterra equations, and three types of partial differential equations (PDEs): Heat, Transient convection-diffusion, and Helmholtz equations. The performance of DERLPSO has been compared with the state-of-the-art methods, including the RLLPSO algorithm, traditional numerical methods, deep learning approaches, and Bayesian methods.\nThe remainder of this paper is organized as follows. Section 2 details the proposed algorithm. Section 3 outlines the experimental procedures and discusses the results. Section 4 concludes with insights for future research."}, {"title": "2 DERLPSO Theory and Structure", "content": "Estimating unknown parameters in differential equations involves identifying undetermined constants or coefficients within the equations. The goal is to determine the specific values of these unknown parameters using available information, such as observational data, initial conditions, so that the differential equations accurately represent the dynamic behavior of the system. For example, in the Lotka-Volterra equations shown in Equation (1), x and y are referred to as state variables, representing the populations of prey and predator, respectively. The derivatives\n$\n\\frac{dx}{dt}\n$\nand\n$\n\\frac{dy}{dt}\n$\nof these variables, dx/dt and dy/dt, denote the rates of change of these variables over time due to their interactions, with t representing time. The parameters \u03b1, \u03b2, \u03b4 and \u03b3 are coefficients that characterize the interaction dynamics of the two species. This paper addresses the problem of determining the values of \u03b1, \u03b2, \u03b4 and \u03b3, given the values of x, y, and time t."}, {"title": "2.1 DERLPSO Structure", "content": "PSO is a swarm intelligence algorithm, known for its strong global search capability, simple parameter setup, fast convergence, ease of implementation, robustness, and broad applicability, making it a powerful tool for solving complex optimization problems. In this study, each particle represents a candidate parameter value for a differential equation, framing the parameter estimation problem as an optimization problem. Reinforcement learning is employed to enhance the global search capability of the PSO algorithm, thereby enabling PSO to converge to the optimal solution more quickly. RLLPSO [17] is a large-scale optimization algorithm enhanced by reinforcement learning. Specifically, RLLPSO enhances population diversity by constructing a level-based swarm structure and utilizes a reinforcement learning strategy to dynamically control the number of population levels, thereby improving search efficiency. To further improve the convergence speed, stability, and accuracy of RLLPSO, this paper introduces logarithmic initialization, reinitialization mechanisms, and a bottom-up update strategy. A novel method, DERLPSO, is proposed for solving the unknown parameters in differential equations. Logarithmic initialization effectively covers the parameter space and enhance the sampling probability of small magnitude numbers, thereby improving the search efficiency of the algorithm. Reinitialization mechanisms provides new convergence opportunities by redefining particles' positions, facilitating quicker discovery of the global optimum. The bottom-up update strategy ensures that lower-level particles update based on the accurate states of higher-level particles, thereby avoiding error accumulation and further enhancing the convergence stability and accuracy of the algorithm.\nThe diagram of the DERLPSO algorithm is presented in Fig. 1. The location and velocity of each particle, Xi and Vi are first initialized. For the Lotka-Volterra equations shown in Equation (1), \u03a7 = [\u03b1, \u03b2, \u03b4, \u03b3] and V = [\u03b1\u03c5, \u03b2\u03c5, \u03b4\u03c5, \u03b3\u03c5]. Two random initialization strategies are used to ensure good coverage of the entire search space, which can improve the diversity of the solution. Then, the particles are updated iteratively. In each iteration, LSODA or FIPY is used solve the ODEs or PDEs given the candidate parameters corresponding to each particle. Mean Square Error(MSE) between the simulated data and the fitted data was calculated, according to which the particles are sorted and layered. The number of layers is determined by Q-learning algorithm. The layering operation allows diverse update of particles. Specifically, each particle was updated according to two particles randomly selected from the previous layers. The Q-table is updated afterwards. The iteration process stops until the predefined termination conditions are reached. The pseudocode of DERLPSO is presented in Algorithm 1."}, {"title": "2.2 Initialization Strategy", "content": "This work employs two initialization strategies- Uniform and logarithmic, randomly sampling positions for half of the particles from each. For Uniform strategy, the d - th component is sampled with a uniform distribution in [\u03b2min, \u03b2max], as in Equation (2), where X represents the position of the ith particle in the dth dimension, Va represents the velocity of the ith particle in the dth dimension.\n$\nX_i^d = random(\\beta_{min}, \\beta_{max})$\n$\nV_i^d = random(\\beta_{min}, \\beta_{max})$\n$\n(2)\n$\nFor Logarithmic strategy [18], the dth component is sampled according to Equation (3), where rnd is a random number uniformly distributed in [0, 1), \u03b2dain and \u03b2damax represent the minimum and maximum values of the sampling range in the dth dimension.\n$\nX_i^d = exp(ln(\\beta_{min}) + ln(\\frac{\\beta_{max}}{\\beta_{min}}).rnd)* \\epsilon, \n$\n$\nV_i^d = exp(ln(\\beta_{min}) + ln(\\frac{\\beta_{max}}{\\beta_{min}}).rnd)* \\epsilon,$\nwhere\n$\n\\epsilon \\in \\{-1,1\\}\n$\n(3)\nLogarithmic sampling can provide a higher probability of sampling smaller magnitude values, and since logarithmic sampling can more effectively cover the entire parameter space, it can achieve the same coverage effect with fewer samples. However, since the logarithmic strategy cannot generate negative values, but the parameter values can be negative, to generate random numbers with both positive and negative values, a random factor of \u00b11 is multiplied by the random number generated by the logarithmic strategy. This is equivalent to introducing an additional sign randomness on the basis of the logarithmic strategy.\nWhen \u03b2min = 0.05 and \u03b2max = 1, the logarithmic probability distribution is shown in Fig. 2 b. It can be seen that there is a part of the values near zero that cannot be obtained. Therefore, it is important to set the \u03b2min value as close to zero as possible, so as to reduce the range of values that cannot be randomly sampled."}, {"title": "2.3 Particles Layering Strategy", "content": "To maintain the diversity of candidate solutions in the particle swarm, the algorithm uses a level-based swarm structure. The particle swarm is divided into multiple levels, with higher levels representing particles closer to the optimal value. In this algorithm, a population of N particles is divided into L levels, based on the loss values of the candidate solutions, after being sorted in ascending order. The loss value represents the MSE between the simulated data and the fitted data for the current parameters. If the particles cannot be evenly divided, the remaining particles will be assigned to the last level, as shown in Equation (4).\n$\nL_P = \n\\begin{cases}\n\\lfloor\\frac{N}{L}\\rfloor, & \\text{if } i<L \\\\\n\\lfloor\\frac{N}{L}\\rfloor +N\\%L, & \\text{if } i = L\n\\end{cases}\n$\n(4)\nFor example, when there are 20 particles divided into three levels, the first and second levels will have an equal number of particles, which is 6, and the third level will have 8 particles, as shown in Fig. 3."}, {"title": "2.4 Tier Selection Strategy", "content": "By employing level-based swarm structure, the particle swarm can maintain a good diversity, with lower-level particles having more potential learning samples, and higher-level focusing more on exploring the optimal value. However, randomly selecting two particles as samples will impose certain limitations on the convergence efficiency of the algorithm, as particles update themselves by moving closer to the particle with a lower loss value with a greater weight. To improve convergence efficiency, a competitive mechanism is introduced to increase the probability of selecting particles with lower loss values as samples for updates, and the probability of triggering this mechanism increases with the number of iterations, as shown in Equation (6),\n$\np = (\\frac{curiterator}{maxiterator})^2$\n(6)\nwhere p represents the probability of triggering the level competition mechanism during iteration, curiterator represents the current iteration number, and maxiterator represents the maximum iteration number. First, calculate the threshold p. In the subsequent two loops, a random number rand is generated each time. If the random number is less than p, trigger the following mechanism: randomly select two levels that are higher than the current particle's level, and choose the higher one. If not, a level is randomly selected that is higher than the current particle's level. After the two loops, two levels are obtained. Finally, a particle is randomly selected from each of the two levels as a sample. This increases the probability of selecting particles with lower loss values, which can accelerate the convergence of the algorithm, as shown in Algorithm 2."}, {"title": "2.5 Reinforcement Learning-guided Particle Layering", "content": "Reinforcement Learning is a type of machine learning method where an intelligent agent learns to make decisions by interacting with the environment, with the goal of maximizing cumulative rewards. Unlike supervised learning, reinforcement learning does not rely on explicit labeled data, but instead learns through trial and error by receiving feedback. In each step, the intelligent agent selects an action based on the current state, and the environment responds with a reward or penalty. The agent adjusts its strategy through this feedback, optimizing its decision-making process. Q-learning is a widely used reinforcement learning algorithm.\nQ-learning is a value function-based reinforcement learning algorithm, and Q-table is a lookup table in Q-learning that stores the Q-values corresponding to each state-action pair, in the form of a table or matrix. The Q-values represents the expected cumulative rewards that an agent will receive in the future when taking a certain action in a specific state. The core function of the Q-table is to help the agent select the optimal action based on its current state. The agent selects an action according to the Q-table in each state, and updates the Q-values based on the reward received and the next state. Through repeated iterations, the agent gradually learns to select the optimal policy that maximizes the cumulative reward. The key to Q-learning is to balance exploration and exploitation using an e-greedy strategy, and to optimize the Q-values step by step using the Bellman equation until convergence. As shown in Algorithm 4."}, {"title": "2.6 Reinitialize Strategy", "content": "Tian et al. proposed that reinitializing some poorly performing particles during iteration can lead to better convergence [20]. In the method presented in this paper, if the loss value of the global optimal particle does not reach the set threshold by the halfway point of the maximum iteration, all particles will be reinitialized based on the logarithmic strategy. Since the initialization of particles is a stochastic process, there is a possibility that particles may get trapped in local optima. Reinitializing the particles can help the algorithm escape local optima, explore a broader search space and increasing the likelihood of finding the global optimal solution."}, {"title": "2.7 Particle evaluation", "content": "To evaluate the performance of the unknown parameters represented by each particle, the LSODA [21] method or the FiPy library is used to simulate the solution vector of the differential equations under the current predicted parameters, the values of x and y in Equation (1), and compare it with the true solution vector. MSE is used to evaluate the quality of the current predicted parameters (the position information of the current particle), as shown in Equation (10),\n$\nMSE = \\frac{1}{n}\\sum_{i=1}^{n}(Y_{true} - Y_{pred})^2$\n(10)\nwhere, Ytrue represents the true solution vector of the differential equations, Ypred represents the solution vector of the differential equations simulated with the current parameters, and n denotes the length of the solution vector. A smaller MSE value indicates that the current predicted parameters are closer to the true parameters."}, {"title": "3 Experiments and Results", "content": "This paper validates the validates the proposed method using three common ODEs and three common PDEs. The six equations are: Lotka-Volterra equation, Lorenz equation, FitzHugh-Nagumo equation, Heat equation, Transient convection-diffusion equation, the Helmholtz equation."}, {"title": "3.1 Differential Equations", "content": null}, {"title": "3.1.1 Lotka-Volterra Equation", "content": "The Lotka-Volterra equation originates from a classic biological system model[22], which is often used to describe the dynamic interactions between predators and prey in biological systems, specifically the fluctuations in the population sizes of both species. These equations were independently proposed by Lotka and Volterra in 1925 and 1926, respectively. The specific structure is shown in Equation (1), where, y represents the number of predators, x represents the number of prey, and dydt and de denote the rates of change of predator and prey populations, respectively. t represents time, while \u03b1, \u03b2, \u03b4, and \u03b3 are parameters related to the interaction between the two species, all of which are positive real numbers. In this experiment, \u03b1, \u03b2, \u03b4, and \u03b3 are the unknown parameters.\nThe variation between the two variables in this ODEs exhibits periodicity, aligning with the natural developmental patterns observed in biological systems. As the prey population increases, the predator population also grows, as the prey provides an abundant food source for the predators. However, when the predator population reaches a certain threshold, the prey population begins to decline because the predation rate exceeds the prey's reproduction rate. As the prey population decreases, predators experience a shortage of food, leading to a gradual decline in their numbers. This reduction in predator pressure allows the prey population to recover. Subsequently, the predator population increases again as the prey population rises. This cyclical dynamic repeats indefinitely."}, {"title": "3.1.2 Lorenz Equation", "content": "The Lorenz equation are a simplified set of differential equations that describe the motion of fluid convection in the atmosphere [23]. The Lorenz equation were proposed by the American meteorologist Edward Lorenz. He applied"}, {"title": "3.1.3 FitzHugh-Nagumo Equation", "content": "The FitzHugh-Nagumo equation are predominantly utilized to model the dynamics of spiking neurons [24], with the detailed structure of the equation presented in Equation (12). In this experiment, \u03b80 and \u03b81 are unknown parameters.\n$\n\\frac{du}{dt} = \\gamma(u - \\frac{u^3}{3} + v + \\xi\n$\n$\n\\frac{dv}{dt} = - (u - \\theta_0 + \\theta_1 v)\n$\n(12)"}, {"title": "3.1.4 Heat Equation", "content": "The Heat equation is a PDEs that describes the process of heat transfer. It is also known as the Fourier equation, named after the French mathematician and physicist Joseph Fourier. This equation has broad applications in physics, engineering, and many other fields, such as temperature distribution, heat transfer, and thermal conduction in materials. The law asserts that, in a homogeneous medium, the rate of heat transfer is proportional to the temperature gradient and occurs in the direction opposite to that gradient. The mathematical form of the heat conduction equation is typically represented as shown in Equation (13).\n$\n\\frac{\\partial u}{\\partial t} = a \\nabla^2 u\n$\n(13)\nIn this paper, a one-dimensional heat conduction equation is used, where u(x, t) represents the temperature at position x and time t, and denotes the rate of change of temperature with respect to time t. The parameter a represents the thermal diffusivity, a material property that describes the rate at which heat diffuses through the medium. The symbol \u22072 represents the Laplace operator, which in one-dimensional space is expressed as shown in Equation (14). In this experiment, a is the unknown parameter.\n$\n\\nabla^2 u = \\frac{\\partial^2 u}{\\partial x^2}\n$\n(14)"}, {"title": "3.1.5 Transient Convection-Diffusion Equation", "content": "The Transient Convection-Diffusion equation describes the temporal variation of a physical quantity in one-dimensional space under the combined influence of convection and diffusion. This equation has wide applications in fields such as fluid mechanics, heat conduction, and environmental science. The equation used in this paper is presented in Equation (15),\n$\n\\frac{\\partial u}{\\partial t} + v_0 \\frac{\\partial u}{\\partial x} = D \\frac{\\partial^2 u}{\\partial x^2}\n$\n(15)\nwhere, u(x, t) is the physical quantity to be solved, which is a function of spatial position x and time t. The term represents the transient term, indicating the rate of change of the physical quantity over time. The term vou is the convection term, where v is the convection coefficient, describing the influence of convection on the spatial transport of u. The term is the diffusion term, D is the diffusion coefficient, describing the effect of diffusion on the spatial distribution of u. In this experiment, v and D are the unknown parameters."}, {"title": "3.1.6 Helmholtz Equation", "content": "The Helmholtz equation is named after the German physicist Hermann von Helmholtz. It describes wave phenomena, specifically the spatial distribution of wave fields (such as electromagnetic or acoustic fields) when wave propagation is subject to some form of linear constraint or restriction. These constraints can arise from boundary conditions (such as reflection and interference of waves in a finite region) or from inhomogeneities in the medium (such as the propagation of sound waves in a layered medium). The Helmholtz equation is given in Equation (16),\n$\n\\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2} + k^2 u = 0\n$\n(16)\nwhere, u represents the physical quantity to be solved (such as the potential function in an electromagnetic field or the pressure field in a sound wave), which describes the spatial distribution of the field. It is a function of x and y. The constant k is typically related to the physical context of the problem. In this paper, the value of k is determined according to Equation (17),\n$\nk = \\frac{2 \\pi}{\\lambda}\n$\n(17)\nwhere, \u03bb represents the wavelength. In this experiment, \u03bb is the unknown parameter."}, {"title": "3.2 Model Parameters", "content": "The experimental data used was not generated from a fixed differential equations, but rather by randomly selecting unknown parameters from a certain distribution, in order to increase the randomness and generality of the data.\nConsidering that different ODEs have different data scales, the time range and initial points for simulating data were set differently. In the experiment, to verify the model's prediction performance on time series data of different lengths, experiments were conducted on data with 5, 8, and 10 time points, respectively, with specific parameters are shown in Table 1."}, {"title": "3.3 DERLPSO for ODEs examples", "content": "When evaluating model performance, this paper adopts two important indicators: MSE and Standard Deviation (SD). MSE emphasizes the average squared difference between predicted and true values, giving a larger penalty to larger errors, and can reflect the overall prediction bias of the model. SD is mainly used to measure the dispersion"}, {"title": "3.4 Compare to RLLPSO", "content": "For the RLLPSO, the settings of all parameters are consistent with the method proposed in this paper."}, {"title": "3.5 Compare to Numerical method", "content": "The Powell method in numerical methods was proposed by Powell in 1964. It is a search method based on the property that conjugate directions can accelerate convergence speed. This method does not require taking the derivative of the objective function, and can be applied even if the derivative of the objective function is not continuous. Therefore, the Powell method is a highly efficient direct search method.\nIn DERLPSO, two particle initialization strategies are employed. Thus, when performing calculations using the Powell method, validation was conducted separately for both initialization strategies."}, {"title": "3.6 Compare to Deep learning", "content": "Neural ODEs [15] can effectively solve the ODEs present in data. Since this model cannot directly extract the equation parameters, this paper modifies Neural ODEs to enable the prediction of unknown parameters in ODEs. In deep learning methods, Fully Connected Neural Networks (FCNNs), possess strong abilities in fitting multivariate and high-dimensional functions. Among all available neural networks, Recurrent Neural Networks (RNNs)stand out in modeling time series data problems due to their gated units and memory storage capabilities [25]. Encoder-Decoder or Variational Autoencoder (VAEs) models also have the ability to extract latent features from data. Therefore, this paper also uses classical deep learning methods such as FCNNS, RNNS, and VAEs to solve the parameters of ODEs. Notably, the Encoder and Decoder of the VAEs are both composed of Neural ODEs, with the network structure presented in Appendix A."}, {"title": "3.7 Compare to Bayesian method", "content": "This paper compares the performance between DEPLPSO and a Bayesian method based on MCMC sampling [11] on the Lotka-Volterra equations."}, {"title": "3.8 DERLPSO for PDEs examples", "content": null}, {"title": "4 Conclusions", "content": "This paper has improved RLLPSO and proposed the DERLPSO method for solving the unknown parameters of differential equations. This method can obtain a lower error compared to the RLLPSO. Additionally, DERLPSO can avoid the disadvantages of traditional numerical methods, such as being sensitive to initial parameter values and easily getting trapped in local optima. Compared to deep learning methods for solving parameters in differential equations, not only can it achieve higher accuracy, but it also does not require pre-training with large amounts of data. Compared to Bayesian method, it can avoid the need to unfer the specific equation structure. In summary, the DERLPSO method proposed in this paper performs well in solving unknown parameters of differential equations, with advantages such as high accuracy, strong versatility, and independence from initial parameter values.\nIt is well-known that as the complexity of the solution space of differential equations increases with the number of variables. Therefore, one direction for future work is to improve the algorithm so that it can accurately infer the unknown parameters of more complex and larger-scale differential equations.\nAlthough the method proposed in this paper demonstrates excellent global search capability and robustness in solving the unknown parameter problem of differential equations, it does not show significant improvement in computational speed compared to traditional methods. This issue limits the practical application potential of the method in high-dimensional complex models that requiring rapid iterations. Future research could consider incorporating parallel computing, distributed optimization techniques, or exploring hybrid optimization algorithms to address the current bottleneck in computational speed."}]}