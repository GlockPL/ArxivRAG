{"title": "Online Client Scheduling and Resource Allocation for Efficient Federated Edge Learning", "authors": ["Zhidong Gao", "Zhenxiao Zhang", "Yu Zhang", "Tongnian Wang", "Yanmin Gong", "Yuanxiong Guo"], "abstract": "Federated learning (FL) enables edge devices to collaboratively train a machine learning model without sharing their raw data. Due to its privacy-protecting benefits, FL has been deployed in many real-world applications. However, deploying FL over mobile edge networks with constrained resources such as power, bandwidth, and computation suffers from high training latency and low model accuracy, particularly under data and system heterogeneity. In this paper, we investigate the optimal client scheduling and resource allocation for FL over mobile edge networks under resource constraints and uncertainty to minimize the training latency while maintaining the model accuracy. Specifically, we first analyze the impact of client sampling on model convergence in FL and formulate a stochastic optimization problem that captures the trade-off between the running time and model performance under heterogeneous and uncertain system resources. To solve the formulated problem, we further develop an online control scheme based on Lyapunov-based optimization for client sampling and resource allocation without requiring the knowledge of future dynamics in the FL system. Extensive experimental results demonstrate that the proposed scheme can improve both the training latency and resource efficiency compared with the existing schemes.", "sections": [{"title": "I. INTRODUCTION", "content": "E DGE devices, such as mobile phones, smartwatches, and drones, are being increasingly adopted in our daily life and across a wide range of industries. They generate huge amounts of data at the network edge, which need to be processed in a timely fashion to enable real-time decision-making. The traditional machine learning paradigm involves transmitting data over a network to a central cloud server for processing, resulting in significant latency, communication overhead, and privacy issues. Federated learning (FL) is an emerging learning paradigm that enables multiple agents to collaboratively learn from their respective data under the orchestration of a server without sharing their raw data [1]. Deploying FL at the mobile edge is particularly challenging due to system heterogeneity. Note that edge devices usually have different hardware resources (e.g., CPU frequency, memory, storage capacity, and battery level) and operate under different communication environments. This results in different processing delays for edge devices in the local updating stage. Since the server has to wait for all participating devices to finish the local updating before proceeding to the next round, the total training speed is constrained by the slowest device. Meanwhile, FL faces challenges in data heterogeneity where non-IID data distribution across devices hinders the convergence behavior and can even lead to divergence under the highly heterogeneous case [2]. The challenges become more significant when data heterogeneity and system heterogeneity co-exist. For instance, when a device has little battery energy or a bad network connection, it cannot participate in the training even if its data is vital to training a satisfactory model. In this case, it is helpful for these devices to strategically plan their engagement in the learning process to conserve energy and improve the total learning efficiency. Some prior studies have investigated the impact of system heterogeneity aiming to improve communication, computation, and energy efficiency in FL [3]\u2013[6]. However, these research works did not consider the potential variability of resources (e.g., battery level and data rate) at edge devices and mainly follow a uniform random sampling process to select edge devices as described in the classic FedAvg algorithm [1]. Hence, the stragglers who possess fewer resources or have a bad communication environment are chosen with the same likelihood as other devices, leading to slow training speed. Another line of research in FL aims to mitigate the impact of data heterogeneity. They either design updating rules based on sample quantities to address the data imbalance issue [7], [8] or develop adaptive FL updating algorithms [9], [10] to address the diverging model update directions caused by different data distributions. However, fewer works have jointly considered the negative impacts of data and system heterogeneity. In this paper, we propose a novel Lyapunov-based Resource-efficient Online Algorithm (LROA) for FL over the mobile edges. It strategically selects the participating edge devices at the beginning of each communication round based on their available hardware resources, training data sizes, and communication environments. Meanwhile, computation and communication resources are jointly optimized in each communication round. These enable FL to operate under high degrees of data and system heterogeneity, achieving higher model accuracy, lower training latency, and better resource efficiency. Specifically, we analyze the convergence bound of the FL algorithm with arbitrary client sampling under data and system"}, {"title": "II. RELATED WORKS", "content": "Efficient FL implementation faces two substantial chal-lenges: system and data heterogeneity, both capable of de-grading model accuracy and increasing energy consumption and training latency [6], [11]. To overcome these challenges, most of the existing works focus on the resource aspect while ignoring client sampling in FL [12]\u2013[14]. Recently, a few studies have tried to investigate the impact of client sampling with resource allocation [15]\u2013[17]. However, the sampling probability of each client is assumed to be fixed across the rounds in these works, which cannot capture the dynamic changes in communication and computation resources. On the other hand, there is substantial literature to study the client sampling policy of FL solely from the learning perspective [18]\u2013[21]. The key idea of these studies is to select \"important\" clients with higher probabilities, and the importance is deter-mined either by their local gradient [18]\u2013[20] or their local training loss [21]. These approaches work well under mild system heterogeneity. However, they may diverge or suffer from high training latency and resource cost under the high degree of system heterogeneity. As shown later in Section III-B, it is important to take both system heterogeneity and potential dynamics into account when designing the client sampling policy. A few recent works mostly related to ours are [22], [23] and [24], which also consider client sampling from both system and data heterogeneity perspectives. Specifically, Luo et al. [22] proposed an adaptive client sampling algorithm to minimize the convergence time under system and data heterogeneity. However, their analysis is restricted to the convex model and ignores the influence of communication and computation on training latency. Perazzone et al. [23] proposed a joint client sampling and power allocation scheme that mini-mizes the convergence bound and the average communication time under a transmit power constraint. However, they have not considered the resources consumed for local computation. Wang et al. [24] proposed an optimization problem to mini-mize the convergence bound under the resource constraints by adaptively determining the compressed model update and the probability of local updating. However, their resource model relies on several simplified assumptions (e.g., linear compu-tation cost), which lack a detailed analysis for practical FL systems. Deng, et al. [25] utilizes a Lyapunov-based approach to maximize the Long-Term Average (LTA) training data size under LTA energy consumption constraint by solving a mix-integer problem. While they consider a blockchain-assisted FL system, the block mining time and energy consumption are the cores of their formulated optimization problem. Different from these studies, our goal in this paper is to minimize the total learning latency while maintaining the model accuracy by jointly optimizing the client sampling policy, communication, and computation resource allocations under both system and data heterogeneity."}, {"title": "III. SYSTEM MODELING", "content": "A. FL System\nWe consider an FL system involving N edge devices (or clients) and one server. Each edge device \\(n \\in [N]\\) holds a local training dataset \\(D_n = \\{(x_i, y_i)\\}_{i \\in D_n}\\) where \\((x_i, y_i)\\) is a training example and \\(|D_n|\\) is the size of the local training dataset. The total number of training examples across N edge devices is \\(D = \\sum_{n=1}^N |D_n|\\). Additionally, we define \\(l(\\theta; x_i, y_i)\\) as the per-sample loss function, e.g., cross-entropy or mean square error, where \\(\\theta \\in \\mathbb{R}^d\\) denotes the model parameters. Then, the local objective of client n can be expressed as\n\\[F_n(\\theta) := \\frac{1}{|D_n|} \\sum_{i \\in D_n} l(\\theta; x_i, y_i).\\]\nLet \\(w_n = |D_n|/D\\) be the data weight of n-th edge device such that \\(\\sum_{n=1}^N w_n = 1, 0 < w_n \\leq 1\\). The goal of the FL is to minimize the following global objective:\n\\[\\min_{\\theta} F(\\theta) := \\sum_{n=1}^N w_n F_n(\\theta).\\]\nB. FL with Adaptive Resource Control and Client Sampling\nThe most popular algorithm to solve (2) is FedAvg [1]. Specifically, at the beginning of t-th FL round, the server"}, {"title": "IV. CONVERGENCE ANALYSIS", "content": "In this section, we derive the convergence properties of Algorithm 1 under non-convex and non-IID settings. Before stating our convergence results, we make the following as-sumptions:\nAssumption 1 (Smoothness). Each local objective function \\(F_n : \\mathbb{R}^d \\rightarrow \\mathbb{R}\\) is \\(\\beta\\)-smooth for all \\(n \\in [N]\\), i.e.,\n\\[||\\nabla F_n(\\theta) - \\nabla F_n(\\theta') || \\leq \\beta||\theta - \\theta' ||, \\forall \\theta, \\theta' \\in \\mathbb{R}^d.\\]\nAssumption 2 (Bounded gradients). There exists a constant \\(G\\geq 0\\) such that\n\\[||\\nabla F_n(\\theta)||^2 \\leq G^2, \\forall \\theta \\in \\mathbb{R}^d, n \\in [N].\\]\nAssumption 3 (Bounded Dissimilarity). There exist con-stants \\(\\gamma^2 \\geq 1, \\kappa^2 \\geq 0\\) such that \\(\\sum_{n=1}^N w_n ||\\nabla F_n(\\theta)||^2 \\leq \\gamma^2 ||\\sum_{n=1}^N w_n \\nabla F_n(\\theta)||^2 + \\kappa^2\\). If the data distributions across all devices are IID, then \\(\\gamma^2 = 1\\) and \\(\\kappa^2 = 0\\).\nAssumptions 1 and 2 are commonly used in the FL lit-erature, e.g., [27], [28] and [18]. Assumption 3 captures the dissimilarities of local objective functions under non-IID data distribution, such as [29] and [30]. Note that some recent works [22], [23] also consider arbitrary device probabilities for FL and provide convergence analyses, but they only consider convex local objectives and IID data distribution. However, deep neural networks are usually non-convex, and the data are generally non-IID over devices in FL. Thus, our analysis is more general than prior works.\nWe now state the convergence analysis result in the follow-ing theorem.\nTheorem 1 (Convergence Result with Adaptive Sampling Probabilities). Under Assumptions 1, 2 and 3, if the local learning rate \\(\\eta \\leq \\min\\{1/(32E^2\\beta^2\\gamma^2),1/(2\\sqrt{2}E\\beta)\\}, then Algorithm 1 satisfies\n\\[\\frac{1}{T} \\sum_{t=0}^{T-1} \\mathbb{E}||\\nabla F(\\theta^t)||^2 \\leq \\frac{4(F(\\theta^0) - F^*)}{\\eta TE} + \\frac{2\\beta \\eta E G^2}{K T} \\sum_{t=0}^{T-1} \\sum_{n=1}^N \\frac{w_n^2}{q_n} + 8\\eta^2 \\beta^2 E^2 \\kappa^2.\\]"}, {"title": "V. PROBLEM FORMULATION", "content": "In this paper, we are interested in minimizing the time-average expected training latency while maintaining the model accuracy over a large time horizon. Therefore, the control problem can be stated as follows: for the dynamic FL system, design a control strategy which, given the past and the present random channel gain, chooses the CPU frequency \\(\\{f_n^t\\}\\), transmission power \\(\\{p_n^t\\}\\) and sampling probability \\(\\{q_n^t\\}\\) of edge devices such that the time-average expected training latency is minimized while keeping the high accuracy. It can be formulated as the following stochastic optimization problem:\nP1:\n\\[\\min_{\\{f_n^t\\}, \\{p_n^t\\}, \\{q_n^t\\}} \\lim_{T\\rightarrow\\infty} \\frac{1}{T} \\sum_{t=0}^{T-1} \\sum_{n=1}^N \\mathbb{E} \\frac{w_n^2}{q_n^t} T_n^t.\\]\ns.t.\n(3), (7), (6), (8), (12), (13), (14),\n(15), (16), (17).\nOne challenge of solving this optimization problem lies in the uncertainty of channel state information, which makes Prob-lem P1 stochastic. Another challenge is the energy constraint (16) brings the \"time-coupling property\" to Problem P1. In other words, the current control action may impact future control actions, making the Problem P1 more challenging to solve. Moreover, the optimization problem is highly non-convex, which is hard to solve."}, {"title": "VI. RESOURCE-EFFICIENT ONLINE CONTROL POLICY", "content": "In this section, we develop an online control algorithm to solve the stochastic optimization problem P1. Our approach utilizes the Lyapunov optimization framework [32], which eliminates the need for prior knowledge of the FL system and can be easily implemented in real-time.\nA. The Lyapunov-Based Approach\nThe basic idea of the Lyapunov optimization technique is to utilize the stability of the queue to ensure that the time-average constraint is satisfied [32]. Following this idea, we first construct a virtual energy consumption queue \\(Q_n^t\\) for each edge device \\(n \\in [N]\\), which represents its backlog of energy consumption at the current round t. The updating equation of queue \\(Q_n^t\\) is given by\n\\[Q_n^{t+1} := \\max\\{Q_n^t + a_n^t, 0\\},\\]\nwhere\n\\[a_n^t := (1 - (1 - q_n^t)^K) \\epsilon_n^t - E_n.\\]\nWe can easily show that the stability of the virtual queues (19) implies the satisfaction of the energy constraint (16). Moreover, we define the quadratic Lyapunov function as follows:\n\\[L(t):= \\frac{1}{2} \\sum_{n=1}^N (Q_n^t)^2.\\]\nFor ease of presentation, we use \\(Q^t\\) to denote the queue status \\(\\{Q_n^t, \\forall n\\}\\) at round t. The one-slot conditional Lyapunov drift can be formulated as\n\\[\\Delta(t) := \\mathbb{E}\\{L(t + 1) - L(t)|Q^t\\},\\]"}, {"title": "VII. EXPERIMENTS", "content": "A. Experiment Setup\nWe emulate a large number of devices in a GPU server and use real-world measures to set the configurations. Specifically, we consider a FL system with 120 edge devices and one server. Referring to the setting in [12], [15], [36], unless explicitly specified, the default configurations of the FL system are as follows. Each edge device has the maximum transmission power \\(p^{max} = 0.1\\) W and minimum transmission power \\(p^{min} = 0.001\\) W. The white noise power spectral density is \\(N_0 = 0.01\\) W. The maximum available CPU frequency \\(f^{max}\\) is 2.0 GHz and the minimum CPU frequency \\(f^{min}\\) is 1.0 GHz. The efficient capacity coefficient of CPU is \\(\\alpha_n = 2 \\times 10^{-28}\\). For simplicity, we ignore download cost and only consider upload time in the experiment. The total uplink communication bandwidth \\(B = 1\\)MHz. To simulate the practical commu-nication environment, we generate the random channel gain following the exponential distribution with a mean value of \\(h_n^t = 0.1\\). Note we fix the random seed of random channel gain across different runnings. Moreover, we filter out the outlier greater than 0.5 or smaller than 0.01 to ensure the generated random channel gain is within a reasonable range.\nWe use two image classification datasets: FEMNIST [37] and CIFAR-10 [38] for experiment. Due to the inherent diversity in writing styles among the writers, the FEMNIST is a naturally non-IID distributed dataset. Following [39], we first filter out the writers who contribute less than 50 samples. Subsequently, we randomly pick 120 writers from the remaining pool to simulate the devices in the FL sys-tem. For CIFAR-10 dataset, the 50,000 training images are divied into 120 devices following Dirichlet distribution [40] with concentration parameter 0.5. We train a ResNet-18 [41] (d = 11, 172, 342 total parameters) for CIFAR-10, and a CNN model with d = 6,603, 710 total parameters for FEMNIST.\nWe calculate the model update size as M = 32 x d since the model parameter is represented by a 32-bit floating point number. Server samples K = 2 times to create the selected devices set at the beginning of each communication round. The number of CPU cycles required to process a data sample is \\(C_n = 2.0 \\times 10^9\\) cycles/sample for FEMNIST and \\(C_n = 3.0 \\times 10^9\\) cycles/sample for CIFAR-10. The available energy supply is \\(E_n = 5\\)J for FEMNIST, and \\(\\bar{E}_n = 15\\) J for CIFAR-10. The total training rounds are 2000 and 1000 for CIFAR-10 and FEMNIST, respectively. Each device performs \\(E = 2\\) local epochs at each round. We adopt the SGD optimizer with the momentum of 0.9 to update the local model, where the initial learning rate is 0.05 for CIFAR-10 and 0.1 for FEMNIST."}]}