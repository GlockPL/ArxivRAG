{"title": "PREDICTING PERTURBATION TARGETS\nWITH CAUSAL DIFFERENTIAL NETWORKS", "authors": ["Menghua Wu", "Umesh Padia", "Sean H. Murphy", "Regina Barzilay", "Tommi Jaakkola"], "abstract": "Rationally identifying variables responsible for changes to a biological system can\nenable myriad applications in disease understanding and cell engineering. From\na causality perspective, we are given two datasets generated by the same causal\nmodel, one observational (control) and one interventional (perturbed). The goal is\nto isolate the subset of measured variables (e.g. genes) that were the targets of the\nintervention, i.e. those whose conditional independencies have changed. Knowing\nthe causal graph would limit the search space, allowing us to efficiently pinpoint\nthese variables. However, current algorithms that infer causal graphs in the pres-\nence of unknown intervention targets scale poorly to the hundreds or thousands of\nvariables in biological data, as they must jointly search the combinatorial spaces\nof graphs and consistent intervention targets. In this work, we propose a causality-\ninspired approach for predicting perturbation targets that decouples the two search\nsteps. First, we use an amortized causal discovery model to separately infer causal\ngraphs from the observational and interventional datasets. Then, we learn to map\nthese paired graphs to the sets of variables that were intervened upon, in a su-\npervised learning framework. This approach consistently outperforms baselines\nfor perturbation modeling on seven single-cell transcriptomics datasets, each with\nthousands of measured variables. We also demonstrate significant improvements\nover six causal discovery algorithms in predicting intervention targets across a\nvariety of tractable, synthetic datasets.", "sections": [{"title": "1 INTRODUCTION", "content": "Cells form the basis of biological systems, and they take on a multitude of dynamical states through-\nout their lifetime. In addition to natural factors like cell cycle, external perturbations (e.g. drugs,\ngene knockdown) can alter a cell's state. While perturbations can affect numerous downstream\nvariables, identifying the root causes, or targets, that drive these transitions has vast therapeutic\nimplications, from cellular reprogramming (Cherry & Daley, 2012) to mechanism of action elucida-\ntion (Schenone et al., 2013). Large-scale experiments (Replogle et al., 2022) have attempted to map\nthe effects of perturbing individual genes on single cells, and in-silico approaches (Roohani et al.,\n2023; Lotfollahi et al., 2023) have been designed for the \u201cforward\u201d inference task of predicting the\npost-perturbation expression of each gene. In principle, these models can be used within an active\nlearning framework to suggest perturbation targets (Huang et al., 2023; Zhang et al., 2023a). How-\never, the number of inference calls required scales exponentially with the size of the candidate set\n(e.g. drugs with off-target effects), rendering these approaches impractical for larger search spaces.\nThese models' predictive performance as oracles has also been called into question by subsequent\nworks (Kernfeld et al., 2023; Ahlmann-Eltze et al., 2024), highlighting the difficulty of this forward\napproach. Finally, there are limited training data for combinatorial perturbations: the most widely\nused dataset only contains around a hundred pairs (Norman et al., 2019).\nThe \"reverse\" strategy \u2013 of directly predicting targets from perturbation data \u2013 alleviates these prob-\nlems to an extent. Towards this end, it is common to assume (sometimes implicitly) that the data\nwere generated by a structured causal model, and the perturbation targets can be directly inferred\nfrom the changes to this model. While the effects of perturbations are highly contextual, specific to"}, {"title": "2 BACKGROUND AND RELATED WORK", "content": "cells in which they are applied (Nadig et al., 2024), existing methods rely on non-specific,\ndata-mined knowledge graphs as the backbones for their causal structures (Cosgrove et al., 2008;\nGonzalez et al., 2024). It is hard to quantify the extent to which these graphs are relevant to each\nsetting, as the quality and focus of assays have changed over time, and interactions present in one\ncell type may not exist in another (Huttlin et al., 2021).\nOur goal is to predict the perturbation targets that translate one set of cells into another, while infer-\nring the underlying causal structures directly from the data. We formalize this task within a causality\nframework. Specifically, given an observational dataset (e.g. gene expression of control cells) and\nan interventional dataset (e.g. perturbed cells) generated by the same system (e.g. cell type), we\nwould like to identify the variables (e.g. genes) whose data-generating mechanisms are different be-\ntween the two settings. Causal discovery algorithms have been designed to solve this exact problem,\non interventional data with unknown targets (Squires et al., 2020; Brouillard et al., 2020; H\u00e4gele\net al., 2023). These algorithms operate jointly over the spaces of graphs and intervention target sets.\nDue to this large search space, these algorithms are unable to scale to the thousands of variables and\nhundreds of thousands of observations in modern transcriptomics data, while simultaneously being\nrobust to as few as tens of observations per interventional setting (Nadig et al., 2024).\nTo address unknown intervention target prediction in context of biological perturbations, we pro-\npose causal differential networks (CDN). Drawing upon recent advances in scalable and data-\nefficient causal discovery (Wu et al., 2024), CDN first \u201cfeaturizes\" the observational and interven-\ntional datasets in terms of their predicted causal graphs, using a pretrained causal discovery module.\nThese paired, edge-level representations are then used as input to an axial attention-based classi-\nfier (Ho et al., 2020), which is supervised by ground truth intervention targets (on either real or\nsynthetic data). We thoroughly evaluate CDN on both real transcriptomic data and in synthetic set-\ntings. CDN outperforms the state-of-the-art in perturbation modeling on the five largest Perturb-seq\ndatasets at the time of publication (CRISPRi, Replogle et al. (2022); Nadig et al. (2024)), and\ntwo Sci-Plex datasets (chemical perturbations, McFaline-Figueroa et al. (2024)), without using any\nexternal knowledge. In fact, CDN is the only model that consistently ranks the ground truth per-\nturbation targets higher than would be expected by random. Moreoever, CDN is able to maintain\ndecent performance even on unseen cell lines, demonstrating its potential to generalize. Finally, on\nsynthetic settings, CDN outperforms causal discovery algorithms for unknown intervention targets.\nTo conclude, our contributions are three-fold.\""}, {"title": "2.1 IDENTIFYING PERTURBATION TARGETS", "content": "The rise of large-scale perturbation screens (Replogle et al., 2022) has enabled machine learning\napproaches for predicting perturbation targets. One line of work focuses on active learning to reduce\nexperimental costs (Zhang et al., 2023a; Huang et al., 2023), but these models require inference calls\nto an oracle model for each candidate perturbation. Given that human cells express over ten thousand\ngenes, and drugs may impact multiple targets, the search space is enormous. Moreover, subsequent\nworks have found that naive baselines (mean of the training set, linear regression) outperform these\napproaches at their intended task (Kernfeld et al., 2023; Ahlmann-Eltze et al., 2024; M\u00e4rtens et al.,\n2024). In contrast, perturbation targets can be predicted directly from data, using a variety of domain\nknowledge (Cosgrove et al., 2008; Gonzalez et al., 2024; Roohani et al., 2024). However, these\nexternal data were collected from highly inhomogenous sources, which may be inconsistent with\nthe data at hand."}, {"title": "2.2 CAUSAL DISCOVERY WITH UNKNOWN INTERVENTION TARGETS", "content": "Perturbation target prediction can be formalized as a causal discovery problem, using data generated\nunder interventions with unknown targets. Specifically, a causal graphical model is a directed graph\nG = (V, E), where nodes i \u2208 V map to random variables X\u1d62 \u2208 X, and edges (i, j) \u2208 E represent\nrelationships from X\u1d62 to X\u2c7c. There are a number of common assumptions that relate G to the data\ndistribution P\u2093, which we defer to works such as Spirtes et al. (2001); Yang et al. (2018); Zhang\net al. (2023b), since the identifiability of any particular system is not the focus of this paper.\nData generated directly from P\u2093 are known as observational data. A causal graphical model allows\nus to perform interventions by assigning new conditionals\n$P(X_i \\vert X_{\\pi_i}) \\leftarrow P(X_i \\vert X_{\\pi_i}),$ \nwhere \u03c0\u1d62 denotes the parents of node i in G. Hard interventions remove all dependence between\nX\u1d62 and \u03c0\u1d62, while soft interventions maintain the relationship with a different conditional. We denote\nthe joint interventional distribution as P\u2093'. Given an observational dataset D\u2092\u1d66\u209b ~ P\u2093 and an\ninterventional dataset D\u1d62\u2099\u209c ~ P\u2093', our goal is to predict the set of nodes I for which\n$P(X_i \\vert X_{\\pi_i}) \\neq P(X_i \\vert X_{\\pi_i}), \\forall i \\in I.$\nThis task has been well-studied in the causality literature, often as a sub-problem or setting while in-\nferring graph G from D\u2092\u1d66\u209b and (multiple) D\u1d62\u2099\u209c. Ke et al. (2019) first proposed a discovery algorithm\nfor unknown interventions, on discrete data of up to 50 variables. Jaber et al. (2020) provides iden-\ntifiability guarantees for soft interventions with unknown targets and proposes a constraint-based al-\ngorithm, which requires an exponential number of conditional independence tests with respect to the\nnumber of variables. Continuous causal discovery algorithms that are consistent despite unknown\ninterventions include DCDI (Brouillard et al., 2020) and BACADI (H\u00e4gele et al., 2023), which treat\nintervention target identities as learnable parameters of a generative model over P\u2093. DCDI uses the\nGumbel-Softmax approximation (Jang et al., 2017) to learn these categorical variables, while BA-\nCADI takes a Bayesian approach, with gradient-based methods for efficient posterior estimation (Liu\n& Wang, 2016). Finally, Varici et al. (2022) and Yang et al. (2024) frame intervention target predic-\ntion as a separate task, similar to this paper. However, the former strictly assumes linearity, while\nthe latter requires data from multiple environments, which are not available here."}, {"title": "2.3 AMORTIZED CAUSAL DISCOVERY ALGORITHMS", "content": "The majority of causal discovery algorithms operate on one or more datasets D, which correspond\nto a single graph G (Spirtes et al., 1995; Hauser & B\u00fchlmann, 2012; Mooij et al., 2020; Brouillard\net al., 2020). These algorithms must be fit or run from scratch for each data distribution a poten-ntial challenge in low-resource scenarios, where there are too few observations of too many variables."}, {"title": "3 METHODS", "content": "Our model is composed of two modules: a frozen causal featurizer, and a learned differential net-\nwork, which we refer to jointly as CDN (Figure 2). The causal featurizer is a pretrained, amortized\ncausal discovery model (Wu et al., 2024) that runs efficiently on up to a thousand nodes (Section 3.1),\nwhile the differential network is an axial-attention based classifier (Ho et al., 2020) that predicts the\nnodes whose data-generating mechanisms have changed (Section 3.2)."}, {"title": "3.1 CAUSAL FEATURIZER", "content": "The causal featurizer takes as input datasets D\u2092\u1d66\u209b and D\u1d62\u2099\u209c containing samples of N variables, gen-\nerated from observational and interventional settings. For example, D\u2092\u1d66\u209b may correspond the gene\nexpression matrix of non-targeting control cells; D\u1d62\u2099\u209c is the gene expression of the same type of\ncells, subject to a perturbation with an unknown target; and N is the number of genes detected.\nWe use an amortized causal discovery model to obtain features h\u2092\u1d66\u209b, h\u1d62\u2099\u209c \u2208 \u211d\u1d3a\u00d7\u1d3a\u00d7\u1d48, which reflect\nthe N\u00d7 N adjacency matrices of causal graphs that may have generated each dataset. Specifically,\nto featurize each dataset, we follow the three steps proposed in Wu et al. (2024).\n1. Given a dataset D, smaller batches are constructed by sub-sampling both examples and\nvariables. Heuristics like pairwise correlation are used to select variables which are likely\nto have causal relationships, to minimize unnecessary computation.\n2. Two sets of input features are generated from these batches: global summary statistics like\ncorrelation, computed over all variables, and marginal estimates, the outputs of classical\ncausal discovery algorithms (Spirtes et al., 1995) run on small subsets of variables.\n3. Finally, these two sets of features are input to a neural network (\u201caggregator\u201d), which was\ntrained to map them into causal graphs on synthetic datasets.\nWe run this procedure on D\u2092\u1d66\u209b and D\u1d62\u2099\u209c independently, treating both as \"observational\u201d datasets.\nTo obtain the graph representations for each dataset, we extract the aggregator's last layer hidden\nrepresentations before they are collapsed into binary edge predictions, yielding h\u2092\u1d66\u209b and h\u1d62\u2099\u209c. Finally,\nwe concatenate h\u2092\u1d66\u209b and h\u1d62\u2099\u209c along the hidden dimension, to obtain a paired graph representation of\nsize NX N \u00d7 2d."}, {"title": "3.2 DIFFERENTIAL NETWORK", "content": "Given the graph representation, the differential network predicts which nodes were intervened upon\n(Figure 2, right). Its architecture is composed of an axial-attention layer, followed by a linear pro-\njection. Following SEA, the axial attention layer attends separately along the rows and columns\nof the graph's adjacency matrix. This operation is equivalent to self-attention along all nodes in\nthe \"outgoing edge\" direction, with the \u201cincoming edges\" as a batch dimension, followed by the\nopposite. We use pre-layer normalization on each self-attention, followed by dropout and residual\nconnections:\nh = h + Dropout(Self-Attn(LayerNorm(h))).\nAfter the axial attention, we mean over all \"incoming edges\" and linearly project to binary node-\nlevel predictions, where a normalized 1 indicates an intervention target, and 0 indicates otherwise.\""}, {"title": "3.3 IMPLEMENTATION AND TRAINING DETAILS", "content": "For the causal featurizer, we used a frozen, pretrained aggregator from (Wu et al., 2024), which\ncorresponded to the FCI-based marginal estimates (Spirtes et al., 1995). The differential network\nwas implemented with one axial attention layer, following the same architecture as the pretrained"}, {"title": "3.4 THEORETICAL CONTEXT", "content": "This paper primarily describes a causality-inspired approach towards perturbation target prediction.\nContrary to causal discovery algorithms that are self-contained and provably sound under standard\nassumptions, we cannot \u201cprove\u201d that a pretrained model extracts correct graphs on real data, as the\ntrue graphs are unknown. Our evaluation focuses solely on perturbation target prediction, as the\nground truth is known, by (experimental) design. To contextualize the predictions of our model,\nwe provide brief sketches with regards to our model's capacity to map paired graph features to\nintervention targets. We defer formal claims to Appendix A.\nClaim 3.1 (Hard interventions, informal). Given a causal graphical model G = (V,E) and in-\ntervention targets I \u2286 V, let E' denote the adjacency matrix of mutilated graph G' after hard\nintervention on I. An axial attention layer is well-specified to map (E, E') to I.\nClaim 3.2 (Soft interventions, informal). Let G be a graphical causal model associated with data\ndistribution P\u2093, and let P\u2093' be the interventional distribution after soft intervention on I \u2286 V. Let\nR, R' denote the correlation matrices and let \u03a3, \u03a3' denote the covariance matrices of X, X'. An\naxial attention layer is well-specified to map (R, R', \u03a3, \u03a3') to \u0399."}, {"title": "4 EXPERIMENTS AND RESULTS", "content": "We evaluated CDN on seven transcriptomics datasets, with comparisons to state-of-the-art models\nfor these applications (Section 4.1). Note that these baselines all use various domain knowledge\nto inform their predictions. For completeness, we also benchmarked CDN against multiple causal\ndiscovery algorithms for unknown interventions in variety of controlled settings (Section 4.2)."}, {"title": "4.1 BIOLOGICAL EXPERIMENTS", "content": "We evaluate CDN on five Perturb-seq (Dixit et al., 2016) datasets (genetic perturbations)\nfrom Replogle et al. (2022) and Nadig et al. (2024); as well as two Sci-Plex (Srivatsan et al., 2020)\ndatasets (chemical perturbations) from McFaline-Figueroa et al. (2024). Each dataset is a real-valued\nmatrix of gene expression levels: the number of examples M is the number of cells, the number of\nvariables N is the number of genes, and each entry is a log-normalized count of how many copies\nof gene j was measured from cell i (Figure 3A). In Perturb-seq datasets, we aim to recover the gene\nwhose promoter was targeted by the CRISPR guide, and in Sci-Plex datasets, we aim to identify\nthe gene that corresponds to the drug's intended target.\nTo ensure high quality labels, we filtered perturbations to those that induced over 10 differentially-\nexpressed genes (statistically significant change, compared to control), of which the true target\nshould be present. This is to exclude perturbations with insufficient cells (low statistical power),\nwith minimal to no effect (uninteresting), and those that did not achieve the desired effect (CRISPR\nefficacy is not guaranteed). For evaluation, we limited the set of candidate targets to the top 1000\ndifferentially expressed genes, ranked by log-fold change per perturbation. If fewer genes were\ndifferentially expressed, we randomly sampled additional candidates until we reached a minimum\nof 100 genes. Finally, we also stratify genetic perturbations based on whether the target is triv-\nially identifiable as the gene with the largest log-fold change (\u201ctrivial\u201d vs. \u201cnon-trivial\"). This is\nbecause genetic perturbations are highly specific by design, but also constitute the largest single-\ncell perturbation datasets. The final data statistics are shown in Table 1, with additional details in\nAppendix B.1.\nEvaluation We consider two splits: seen and unseen cell lines (Figure 3B). In the former, models\nmay be trained on approximately half of the perturbations from each cell line, and are evaluated on\nthe unseen perturbations. In the latter, we hold out one cell line at a time, and models may be trained\non data from the remaining cell lines. Note that not all baselines can be evaluated on unseen cell\nlines. To ensure that our train and test splits are sufficiently distinct, we cluster perturbations based\non their log-fold change and assign each cluster to the same split.\nWhile perturbation target prediction appears to be a simple classification task, there are two aspects\nof the data that render standard metrics less meaningful. Not all genes can be mapped to the base-\nlines' domain knowledge, so their effects as perturbations cannot be predicted. In addition, due\nto genetic redundancy, it is common for multiple perturbations to elicit similar responses (Kern-\nfeld et al., 2023). Therefore, an \"incorrectly\" predicted target (e.g. out of 1000 genes) may not\nnecessarily indicate poor performance. Therefore, we propose the following metrics.\""}, {"title": "4.2 SYNTHETIC EXPERIMENTS", "content": "There are two considerations that motivate further experiments in controlled settings. First, while it\nwould be ideal to evaluate all algorithms on real data, current causal discovery algorithms that sup-\nport unknown interventions are not tractable on datasets with more than tens of variables. In fact,\nmany baselines require hours on even N = 10 datasets, and they do not scale favorably (Table 9)."}, {"title": "5 CONCLUSION", "content": "We presented CDN, a causal discovery-powered approach for predicting perturbation targets in the\ncontext of single-cell transcriptomics. CDN uses an amortized causal discovery algorithm to repre-\nsent a pair of observational and interventional datasets in terms of their data-generating mechanisms,\nand then trains a classifier to identify variables whose conditional independencies have changed. Our\napproach achieves the state-of-the-art in predicting perturbation targets over seven transcriptomics\ndatasets, compared to a variety of perturbation modeling baselines. CDN also surpasses causal dis-\ncovery algorithms for predicting unknown targets across synthetic settings, while only requiring a\nfraction of the runtime. Nonetheless, there is substantial space for improvement, so we hope that\nthis work and the associated datasets will inform future method development for these biological\napplications."}, {"title": "REPRODUCIBILITY STATEMENT", "content": "All source code will be made publicly available. Hyperparameter and implementation choices are\ndescribed in Section 3.3. Details regarding biological data pre-processing can be found in Sec-\ntion 4.1 and Appendix B.1. The raw data are freely available via the accession codes listed in\nTable 5. Synthetic data generation is discussed in Appendix B.2. Details required to reproduce\nbaselines are described in Sections 4.1 and 4.2, as well as Appendix C.1."}, {"title": "ETHICS STATEMENT", "content": "We use publicly available datasets which do not involve human subjects. While our work has appli-\ncations to biological understanding, our work does not directly concern the design of molecules or\nother potentially harmful agents."}, {"title": "A THEORETICAL INTUITION", "content": "While this paper focuses on biological applications, we would like to show that our model is well-specified, i.e. it has the capacity to predict correct intervention targets, given certain inputs.\nPreliminary note Continuous causal discovery works typically rely on the universality of their architectures for consistency (Brouillard et al., 2020), so this analysis also focuses on computational capacity. Theoretically, it is impossible to \u201cguarantee\" that high-dimensional representations from learned model contain or do not contain certain information. This can be tested empirically through probing, e.g. querying for grammatical structure in language models (Vuli\u0107 et al., 2020), but cannot be \"proven\" in the traditional sense. Thus, we believe that the empirical performance of our model on real datasets is its primary contribution, but provide these explanations for interested readers. In this analysis, we assume that the \"causal\" representations h contains enough information both to retain global statistics and recover the true graph E. The former is reasonable due to high model capacity, and the latter is based on high empirical performance in graph reconstruction (Wu et al., 2024). We emphasize that the latter is an empirical judgment, which may not hold on all datasets in practice.\nAxial attention architecture Our differential network is implemented using an axial attention layer, which is composed of two self-attention layers (one along each axis of the adjacency matrix) and a feed-forward network. For simplicity, we follow prior work Yun et al. (2019) and ignore layer normalization and dropout.\nOur inputs h\u2208 \u211d\u00b2\u1d48\u00d7\u1d3a\u00d7\u1d3a are 2d-dimension features, which represent a pair of N \u00d7 N causal graphs. We use h.,j to denote a length N row for a fixed column j, and h\u1d62, to denote a length N column for a fixed row i. The axial attention layer implements:\nAttnrow(h.,j) = h.,j + WoWvh.,j\u00b7\u03c3 [(W\u2096h.,j)\u1d40W<binary data, 1 bytes><binary data, 1 bytes><binary data, 1 bytes>h.,j],\nAttncol(h\u1d62,.) = h\u1d62,. + WoWvh\u1d62,\u00b7\u03c3 [(W\u2096h\u1d62,.)\u1d40W<binary data, 1 bytes><binary data, 1 bytes><binary data, 1 bytes>h\u1d62,.],\nFFN(h) = h + W\u2082 ReLU(W\u2081. h + b\u2081) + b\u2082,\nwhere Wo \u2208 \u211d\u00b2\u1d48\u00d7\u00b2\u1d48,W\u1d65,W\u2096,W<binary data, 1 bytes><binary data, 1 bytes><binary data, 1 bytes> \u2208 \u211d\u00b2\u1d48\u00d7\u00b2\u1d48, W\u2082 \u2208 \u211d\u00b2\u1d48\u00d7\u1d50,W\u2081 \u2208 \u211d\u1d50\u00d7\u00b2\u1d48,b\u2082 \u2208 \u211d\u00b2\u1d48,b\u2081 \u2208 \u211d\u1d50, and m is the FFN hidden dimension. We have omitted the i and j subscripts on the Ws, but they use separate parameters. Any self attention can take on the identity mapping by setting Wo,W\u1d65,W\u2096, W<binary data, 1 bytes><binary data, 1 bytes><binary data, 1 bytes> to 2d \u00d7 2d matrices of zeros.\nHard interventions Let G = (V, E) be a causal graphical model associated with data distribution P\u2093. Let G' = (V, E') and P\u2093' denote the causal graph and data distribution after an unknown intervention, with ground truth targets I \u2286 V. For convenience, we use E, E' both to denote sets of edges, as well as the equivalent adjacency matrices.\nIn the case of perfect interventions,\nf(x\u1d62) \u2190 z\u1d62, \u2200i \u2208 I\nwhere z\u1d62 X are independent random variables. P\u2093' is associated with mutilated graph E', where\n$E' = E \\setminus \\bigcup_{\\substack{(j,i)\\in E\\cap I}}.$ \nIn terms of the associated adjacency matrices, E \u2013 E' has 1s in each column i \u2208 I and 0s elsewhere.\nHere, the axial attention layer should implement h \u2013 h', so that when we collapse over the incoming edges, the output is non-zero only at the edge differences. Suppose the first dimension of the 2d feature stores E, and the second dimension stores E'. The row self-attention implements the identity (in the first two dimensions). Then we can set W\u2096,Q to zero, W\u1d65 to the identity, and Wo to\nWo = \\begin{bmatrix}\n1 & -1 \\\\\n0 & 0\n\\end{bmatrix}\nTo account for the residual. The FFN implements the identity, so that when we take the mean over along the rows, we recover non-zero elements at all nodes whose incoming edges were removed."}, {"title": "B DATASETS", "content": "We converted all single cell datasets to LogTP10K + 1 expression values (log-normalized, transcripts per 10,000 UMIs). Perturb-seq dataset variables represented genes that were mapped and filtered by the authors. Sci-Plex dataset variables represented genes that appeared in at least 5,000 cells (threshold chosen to achieve a similar number of genes). We performed differential expression analysis via the scanpy package (Wolf et al., 2018), using the Wilcoxon signed-rank test (Wilcoxon, 1945)"}, {"title": "Soft interventions", "content": "Soft interventions We also study soft interventions the context of causal models with non-multiplicative noise, in which intervention targets are scaled by constant factors,\nf(x\u1d62) \u2190 c\u1d62f (x\u1d62), c\u1d62 > 0\nwhere c\u1d62 are sampled at random per synthetic dataset. This choice is inspired by the fact that bio-logical perturbation effects are measured in fold-change. Here, the adjacency matrices are the same, but global statistics differ. In particular, we focus on two statistics: the correlation matrix R and the covariance matrix \u03a3. Note that while these inputs differ slightly from our main experiments (reasons discussed in Appendix D), we show that they still achieve reasonable performance in Table 8.\nSuppose x is an intervention target.\n\u2022 R - R' is non-zero in all entries i, j and j, i where i is a descendent of x, and j is any node for which R\u1d62,\u2c7c \u2260 0 (e.g. ancestors, descendants, and x, if P\u2093 is faithful to G).\n\u2022 \u03a3 \u2013 \u03a3' is non-zero in all entries i, j and j, i where i is a descendent of x or i = x, and j is any node for which \u2211\u1d62,\u2c7c \u2260 0 (e.g. ancestors, descendants, and x, if P\u2093 is faithful to G).\nAll descendants are always affected, due to the non-multiplicative noise term. These two differ in the row and column that correspond to x since\nCorr(c. x, y) = Corr(x, y)\nCov(c. x, y) = c. Cov(x, y).\nTherefore, to identify x, we should find the index in which \u2211 differs but not R. Suppose that dimensions 3-6 of h encode R, R', \u03a3, \u03a3'. Following the same strategy as the hard interventions, we can use the row attention to compute R-R', \u03a3 \u2013 \u03a3' and store them in dimensions 3, 4. Then we use the column attention to filter out variables that are independent from x by storing the sum of each column in dimensions 5, 6. While not strictly impossible, it is unlikely that a variable dependent on x would result in a column that sums to exactly 0. Thus, all columns with non-zero sums are either ancestors, descendants, or x. The feedforward network implements\nFFN(h.,3-6) = \\begin{cases} 1 & h.,3 = 0, h.,4 \u2260 0, h.,5 \u2260 0 \\\\\n0 & otherwise.\\\\\n\\end{cases}\nThis results in 1s in the rows and columns where AR and \u0394\u03a3 differ. After collapsing over incoming edges and normalizing to probabilities, the maximum probabilities can be found at the intervention targets.\nSupporting both intervention types Recall that the final output layer is a linear projection from 2d to 1. If this layer implements a simple summation over all 2d, the predicted intervention targets are consistent with both hard and soft interventions. For soft interventions, E = E', so the hard intervention dimensions will be 0. Likewise, for hard interventions, both R and \u2211 will differ as the same locations, as the underlying variable has changed, so the soft intervention dimensions will be 0. Since the two techniques produce mutually exclusive predictions, this means that both hard and soft interventions can co-exist and be detected on different nodes.\nFinally, we re-iterate that CDN operates over high-dimensional features, rather than the inputs and outputs themselves. Thus, these sketches only serve to provide context regarding the axial attention framework's computational capacity, rather than as a blueprint for the computations it performs."}, {"title": "Implementation Details", "content": "We used the latest releases of all baselines. For GENEPT, this corresponds to the v2 March 2024 update, which used newer models and additional protein data, compared to their initial pa-per (GenePT_gene_protein_embedding_model_3_text)."}]}