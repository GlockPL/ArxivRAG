{"title": "Constrained Decoding with Speculative Lookaheads", "authors": ["Nishanth Nakshatri", "Shamik Roy", "Rajarshi Das", "Suthee Chaidaroon", "Leonid Boytsov", "Rashmi Gangadharaiah"], "abstract": "Constrained decoding with lookahead heuristics (CDLH) is a highly effective method for aligning LLM generations to human preferences. However, the extensive lookahead rollout operations for each generated token makes CDLH prohibitively expensive, resulting in low adoption in practice. In contrast, common decoding strategies such as greedy decoding are extremely efficient, but achieve very low constraint satisfaction. We propose constrained decoding with speculative lookaheads (CDSL), a technique that significantly improves upon the inference efficiency of CDLH without experiencing the drastic performance reduction seen with greedy decoding. CDSL is motivated by the recently proposed idea of speculative decoding that uses a much smaller draft LLM for generation and a larger target LLM for verification. In CDSL, the draft model is used to generate lookaheads which is verified by a combination of target LLM and task-specific reward functions. This process accelerates decoding by reducing the computational burden while maintaining strong performance. We evaluate CDSL in two constraint decoding tasks with three LLM families and achieve 2.2\u00d7 to 12.15x speedup over CDLH without significant performance reduction.", "sections": [{"title": "1 Introduction", "content": "Alignment of LLMs to human preferences is important for their general applicability. Constrained decoding in large language models (LLMs) is an effective method as a post-training step to align LLM generations to human preferences such as harmless text generation (Deng and Raffel, 2023; Huang et al., 2024), faithful summarization (Wan et al., 2023), formatted generation, flow adhering planning (Roy et al., 2024), among other use cases. Within Constrained Decoding methods, the \"Lookahead\" Heuristics-based approach (CDLH) has demonstrated the best performance across several tasks (Lu et al., 2021, 2022). CDLH examines the top k beams, generates d additional tokens as \"lookahead\" for each beam, scores them using task-specific reward functions for constraint satisfaction, and selects the beam that maximizes constraint fulfillment while discarding the others. However, the computational expense of generating lookaheads makes this approach prohibitively costly in terms of runtime, limiting its practical applicability in real-world scenarios.\nSpeculative decoding (SD) is a recently proposed technique for improving the inference speed of LLMs (Leviathan et al., 2023; Chen et al., 2023). This approach employs a draft-then-verify strategy (Xia et al., 2024), utilizing a smaller and more efficient draft LLM's generation to approximate the output of a larger target LLM. At each step, the draft's output is validated by the target LLM. In transformer-based LLMs, this validation is per-"}, {"title": "2 Preliminaries", "content": ""}, {"title": "2.1 Constrained Decoding with Lookahead Heuristic (CDLH)", "content": "Common decoding techniques, such as greedy or beam search methods, generate the next token au-"}, {"title": "2.2 Speculative Decoding (SD)", "content": "With the motivation of improving the natural inference time of LLMs, speculative decoding (SD) has been proposed in recent studies (Leviathan et al., 2023; Chen et al., 2023). The key idea in speculative decoding is that complex language modeling tasks often include easier subtasks (e.g., generation of certain words are easier given the context) that can be approximated well by even a simpler, smaller, and more efficient language model. The transformer based LLMs comes with the advantage that they can process multiple tokens at a time and output their probability distribution with just a forward pass. Hence, in SD, given an LM task, a runtime efficient language model, typically a very small LLM (referred to as draft LLM, Mq), is used to draft d tokens and a much larger LLM (referred to as target LLM, Mp), verifies them with just one"}, {"title": "3 Proposed Algorithm", "content": "In this section, we first propose a novel baseline that is simple yet effective, by optimizing the looak-head mechanism of CDLH with a smaller LLM. Then we propose our algorithm \u201cconstrained decoding with speculative lookaheads\u201d which combines the paradigms of CDLH and speculative decoding. Our approach leverages the strength of both paradigms (better alignment from constrained decoding and faster decoding from speculative decoding), leading to a powerful yet practical method."}, {"title": "3.1 CDLH with Approximate Lookaheads (CDLH-Appx.)", "content": "We observe that in CDLH, the most runtime is incurred during generating the lookaheads for each candidate token, as for each token generation the LLM needs to generate k \u00d7 d additional tokens (assuming greedy rollout of lookaheads). We propose optimizing the runtime in this step by using a much smaller LLM that is computationally less expensive than the larger LLM. Hereafter, we address the smaller LLM as \u201cdraft LLM\", Mq, and the larger LLM as \u201ctarget LLM\u201d, Mp. To this end, we propose a simple yet effective baseline, where Mq generates i.e., approximates the lookaheads for Mp, resulting in faster inference. After generating the lookahead tokens, as before, the token corresponding to the highest reward is selected. We note that even though a lot of computation is shifted to the much cheaper Mq, this approach still requires generation of additional k \u00d7 d tokens by Mq just to generate one token by Mp.\""}, {"title": "3.2 Constrained Decoding with Speculative Lookaheads (CDSL)", "content": "Our algorithm begins by autoregressively speculating d lookahead tokens using the draft LLM, Mq. Speculative lookaheads are validated by target LLM, Mp, to ensure that the output from Mq adheres to the same distribution as Mp. To enforce constraints on generations, validated speculative lookaheads are scored using a task specific reward function R, which assesses their adherence to the required constraints. Next, we define a set of states and corresponding actions based on the feedback from Mp and R, that determines whether to accept or reject the speculated lookaheads. In this manner, our approach ensures maximum gain in both constraint satisfaction and runtime. This entire draft-then-validate process repeats until the desired maximum sequence length lm is achieved. The following subsections provide a detailed explanation of this procedure."}, {"title": "3.2.1 Generating Speculative Lookaheads", "content": "In CDLH, the target LLM Mp generates the looka-heads resulting in a very high runtime. Conversely, in CDLH-Appx., the lookaheads are approximated by smaller draft LLM, Mq, however, not verified by Mp, leaving room for more runtime improvement. Hence, in our proposed method, we initiate text generation using a draft model, Mq, with the aim of leveraging its cost efficiency for the lookahead process. Given an input prompt, referred to as prefix and a fixed draft length d, we generate a sequence of tokens by greedily sampling d tokens from Mq in an autoregressive manner. It is crucial to understand that these lookahead tokens are speculative at this point, as they have not yet been validated by the target Mp, to confirm alignment with its distribution. In addition, we note that the prefix comprises the initial prompt and the previously generated tokens, accumulated over multiple draft-then-validate iterations of our algorithm."}, {"title": "3.2.2 Scoring Lookaheads", "content": "Our goal is to maximize both constraint satisfaction and runtime efficiency. Hence, a generated lookahead in the previous step is evaluated by both Mp (attributes to runtime gain) and task specific reward function R (attributes to constraint satisfaction).\nValidation by Mp. We apply the principle of speculative decoding, performing a forward pass on the input prefix along with d lookahead tokens using the target Mp for validation. Using the output distribution of the d tokens by Mp, the validation can be done using the following two methods.\nHard Rejection: We take the arg max at each of the d positions on the distribution generated by Mp and obtain the tokens Mp would generate at each of the d positions. Then we compare the tokens"}, {"title": "3.2.3 Speculated Tokens Acceptance Decision", "content": "In our algorithm, the decision to finally accept or reject speculative lookaheads is determined by a combination of the acceptance score, a and the reward score, r. We define the following four states and state-specific actions based on the magnitude of a and r.\nBoth acceptance (a) and reward (r) scores are high (S1). This scenario represents an ideal situation that indicates the majority of outputs from Mq are similar to the output distribution of Mp and satisfy the constraint requirements. Hence, in this situation, every token accepted by Mp is generated. It is important to emphasize that we do not sample additional tokens from Mp, contrary to the usual practice in speculative decoding. This is because, in constraint satisfaction problems, accepting a token without verification by the reward model is inefficient and may result in constraint violation.\nAcceptance (a) is low and reward (r) is low (S2) or high (S3). In this scenario, the acceptance"}, {"title": "4 Experimental Setting", "content": ""}, {"title": "4.1 Constrained Decoding Tasks", "content": "To study the efficacy of our algorithm, we select two types of constrained decoding tasks.\nLexical Constraint: We select the constrained commonsense generation task, CommonGen (Lin et al., 2020), that requires generating a coherent sentence that describes a plausible scenario using all the provided concepts (e.g., {\u2018dog', \u2018run', 'field' } might produce \u201cThe dog runs on the field\"). This type of lexical constraints are programmatically verifiable, hence, we implement the reward function, R, for this task using a concept counting method in the generated sentence, e.g., if 2 out of 5 concepts are covered, R = 0.4.\nSemantic Constraint: For semantic constraint satisfaction, we study the Harmless Text Generation (HTG) task using the Anthropic HH-RLHF dataset (Bai et al., 2022), where a human converses with an LLM assistant and tries to prompt it to generate harmful responses. Semantic constraints are abstract (e.g., 'I can help with a murder' vs. 'I do not support murder') and are not possible to verify programmatically, requiring different type of reward modeling. Hence, as R, we use an off-the-shelf reward model, reward-model-deberta-v3-large-v2*, that provides a continuous reward score for harmlessness.\""}, {"title": "4.2 LLM Families", "content": "By design, speculative decoding based approaches require draft and target LLMs to be selected from the same LLM family in order to ensure vocabulary match. Hence, we experiment with three LLM families that have enough smaller and larger LLMs available to be used as drafts and targets. We experiment with OPT (Zhang et al., 2022): 13B as target and {125M, 350M, 1.3B} as drafts; Bloomz (Mue-nnighoff et al., 2023): 7.1B as target and {560M, 1.7B} as drafts; Qwen1.5 (Team, 2024): 7B as target and {0.5B, 1.8B} as drafts. For the CommonGen task, we use the Chat version of Qwen1.5 as we found it to be better at following the instructions."}, {"title": "4.3 Evaluation Metrics", "content": "In this paper, our goal is to improve the runtime of CDLH with speculative lookaheads. Hence, we report the following two major evaluation metrics.\nSpeedup. Following the approach by Leviathan et al. (2023), we calculate the runtime cost coefficient c as the ratio of the average tokens per second of Mp to those of Mq, with the simplest decoding method, greedy decoding. We found that the runtime complexity of the reward function, R is negligible compared to the inference time of LLMs. Hence, by disregarding the negligible runtime for R, we calculate runtime, P for each token generation, P = (c * No. of Mq calls per token) + No. of Mp calls per token. Speedup is calculated by taking the ratio of runtime of two approaches.\nConstraint Satisfaction Rate. For CommonGen, we report two constraint satisfaction metrics - (1) % Soft Constraint Satisfaction: measures the overall percentage of constraints that are satisfied across all data points, (2) % Hard Constraint Satisfaction: measures the percentage of data points where all required concepts are included. For HTG, we measure the percentage of generations that are harmless. For evaluating if a generated response is harmless, we use an off-the-shelf LLM, Llama-Guard-3-8B (Llama Team, 2024), which is fine-tuned for content safety classification task to assess the safety of the generated text. We perform a meta evaluation of this model judge and found that it is 94% reliable in identifying Harmless/Safe responses (details can be found in Appendix B)."}, {"title": "4.4 Datasets and Hyperparameter Tuning", "content": "We tune different hyper-parameters (at, rt, b) of our model using a validation set and report all the results in the test set. For validation, we sample 200 examples from CommonGen and 100 conversations from the HH-RLHF corpus. We sample disjoint 1,000 examples from CommonGen and 2,000 conversations from HH-RLHF as test sets. For the CommonGen task, we prompt the model in a two-shot manner. This is done because the performance of speculative decoding-based approaches largely depend on the instruction following capability of the draft LLMs (Yan et al., 2024) and we observe that this ability is enhanced with few-shot prompting in the CommonGen task. Moreover, we experiment with OPT family models which are not instruction tuned and rely on few-shot learning. The"}, {"title": "5 Results and Ablations", "content": "In this section, we first describe the performance of our model compared to the baseline and skyline approaches. Then, we perform an extensive ablation study and error analysis of our proposed approach."}, {"title": "5.1 Key Findings", "content": "We evaluate our approach against various algorithms detailed in Section 3. Additionally, we compare results with Beam Search (Freitag and Al-Onaizan, 2017), and Nucleus Sampling (Holtzman et al., 2019) methods. Greedy decoding serves as a skyline for runtime and a baseline for performance. CDLH represents the performance skyline and runtime baseline, while CDLH-appx. serves as a strong baseline for both runtime and performance. Results are summarized in Table 1.\nStandard Decoding Methods. When comparing greedy decoding with nucleus sampling, we observe that nucleus sampling does not improve constraint satisfaction performance. This method was proposed to increase diversity in generation (Holtzman et al., 2019) and we observe increased diversity does not contribute to better adherence to constraints. For a threshold of p = 0.9, the increased diversity in model responses leads to a significant drop in constraint satisfaction performance. Specifically, on the CommonGen task, performance decreases by ~ 3.6 17.2% compared to using a lower threshold of p = 0.5. We observe that the performance remains lower than greedy decoding even with p = 0.5. In contrast, beam search (beam_width = 3 for CommonGen and beam_width = 5 for HTG) achieves higher constraint satisfaction in many cases, benefiting from broader search space exploration relative to greedy decoding. However, it incurs a significant runtime overhead compared to greedy decoding and consistently underperforms compared to the lookahead-based methods. Hence, greedy decoding serves as an ideal skyline for runtime efficiency and a baseline for performance."}, {"title": "5.2 Ablation Study", "content": "In this section, we discuss the effect of different hyperparameters in our approach using the target-draft pairs (Bloomz-7.1B, Bloomz-1.7B), in the CommonGen task. The learning curves are generated using the validation set as described in Section 4.4 and are presented in Figure 2. Other learning"}, {"title": "6 Related Work", "content": "Speculative decoding (SD) has emerged as a technique for reducing LLM inference time with a faster small LM (Leviathan et al., 2023; Chen et al., 2023; Kim et al., 2024; Xia et al., 2024). Different optimizations and variations have been further proposed on top of SD. For example, usage of a layer-skipped lighter version of the target LLM as a draft (Zhang et al., 2024b), using a segment of the model as draft (Liu et al., 2024a), retrieval as draft (He et al., 2024), recurrent drafter (Zhang et al., 2024a), tree-based drafting (Jeon et al.), graph structured SD for managing more than one hypothesis (Gong et al., 2024), etc. Other approaches includes incorporation of contrastive learning is SD (Yuan et al., 2024), focusing on more effective tokens during SD (Lin et al., 2024), knowledge distillation in drafts for better acceptance (Zhou et al.), online SD (Liu et al.), etc. Another line of research focuses on scalability, robustness (Chen et al., 2024), and parallelism for SD (Qian et al., 2024; Sun et al., 2024; Spector and Re).\nIn a different paradigm, constrained decoding based approaches are used as an alignment technique for LLMs at post-training phase (Mudgal et al.; Huang et al., 2024). The most effective approaches (Cheng et al., 2022; Roy et al., 2024) for constrained decoding rely on lookahead-based approaches (Lu et al., 2022). As a result, controlled generation (Deng and Raffel, 2023; Beurer-Kellner et al.; Dekoninck et al.) with lookahead heuristic is prohibitively expensive in terms of runtime. In this paper, we combine the two paradigms, constrained decoding with lookahead heuristic and speculative decoding, with a goal to improve the runtime of such approaches while preserving the performance."}, {"title": "7 Conclusion", "content": "We propose constrained decoding with speculative lookaheads, a novel algorithm that combines the principles of constrained decoding with lookahead heuristics and speculative decoding, in order to improve the runtime efficiency of constrained decoding approaches. Our approach yields significant speedup over the constrained decoding with lookahead heuristics (CDLH) approach without major drop in performance and contributes to adaptability of such approaches in real-world use cases."}, {"title": "Limitations", "content": "We identify the following limitations in our study.\nRuntime-Performance Tradeoff: We note that our algorithm shows a runtime vs. performance tradeoff when compared to the performance of the skyline approach for performance, constrained decoding with lookahead heuristics. However, as shown in section 5, the performance tradeoff is not drastic if compared to the skyline for runtime, greedy decoding. We believe our approach will still increase the adaptability of the constrained decoding with lookahead heuristics based approaches in many real world online applications, despite this slight tradeoff in performance.\nTarget-Draft Pairs: In our study, we experiment with both target and draft models belonging to the same model family. This approach follows the principles of speculative decoding, which depend on achieving high acceptance rates between the target-draft model pair to realize enhanced runtime gains. Different LLM families use varying types of tokenizers, preventing the straightforward combination of the target and draft models from different LLM families. Since the output logits of both target and draft models are crucial for token verification, the presence of different tokenizers complicates this process, limiting our choice of target-draft model pairs. We note that this is a general limitation of state of the art speculative decoding-based approaches.\nReward Function: In our proposed algorithm, the reward function is distinctly isolated from other components, allowing a straightforward adaptation to different types of constraint. That requires constructing task specific reward functions and if a downstream task requires a resource-intensive reward function, the runtime will increase in constrained decoding with lookahead heuristic based approaches including our proposed algorithm.\nParameter Optimization: Our algorithm requires tuning different hyperparameters (e.g., acceptance and reward thresholds at and rt, d, etc) because of the varying capabilities and accpetance rates among different target-draft pairs. As a result, a task specific validation set is required in order to get the best out of our approach, however, it facilitates task specific adaptability of our approach.\nLLM Size: Due to computation resource limitations, we apply our approach on target LLM sizes up to 13B. However, we note that our approach is readily applicable in even larger LLMs."}, {"title": "Open Source LLM Usage", "content": "The CDLH and SD approaches in principle, require access to the LLM logits. As a result, we apply our approach on open-source LLMs only. Moreover, it is difficult to find closed source LLM families with models in varying parameter sizes so that they can be used as drafts in the speculative decoding based approaches.\nBatch Implementation: Application of speculative decoding in a batched setting is a research area on its own (Qian et al., 2024). Hence, adaptation of our algorithm in a batched setting is out of scope for this paper and we leave it as our future work."}, {"title": "Ethics Statement", "content": "We present all implementation and dataset details for reproducibility of our study (some parts are in the Appendix). The datasets and LLMs used in this paper are publicly available and permitted for scientific research. We perform meta evaluation of a model judge and the human evaluators are compensated in accordance with the standards in such tasks. The human evaluation details are presented in Appendix B. We perform extensive ablation studies in order to provide the readers an idea about potential error patters and risks associated to the proposed methods."}, {"title": "Constrained Decoding with Lookahead Heuristic (CDLH)", "content": "The constrained decoding with lookahead heuristic approach is illustrated in Algorithm 2."}, {"title": "B Meta Evaluation of the Model Judge", "content": "To evaluate the harmless text generation task, we use an external LLM, Llama-Guard-3-8B (Llama Team, 2024), which is especially fine-tuned for content safety classification task. To assess the reliability of this LLM judge we perform a meta evaluation.\nFirst, we collect the model generations in the validation set using all the baselines. Then we prompt Llama-Guard for evaluating if these responses are safe or unsafe. We use the same prompt that was proposed in the source paper (Llama Team, 2024). Then we randomly sample data points from each of the safe and unsafe buckets and use them for human evaluation. In this manner, we sample 95 (potentially) unsafe and 105 (potentially) safe responses, summing up to 200 total data points. Initially, we use Amazon SageMaker Ground Truth for the evaluation, where the annotators are presented with the same prompt as Llama-Guard (as shown in Figure"}, {"title": "C Hyperparameter Tuning", "content": "We tune several hyperparameters for our model: draft length d, acceptance threshold at, reward score threshold rt, b, and the sampling method.\nThe search space for these hyperparameters in the two tasks are summarized in Table 2.\nWe determine the draft length, d empirically in our initial stages of experiments. We determined the best values of draft length for the CommonGen and HTG tasks to be 3 and 5, respectively. For a fair comparison, we report the results with the baselines/skylines, CDLH and CDLH-appx. with the same lookahead (or draft) length in the test and validation sets."}, {"title": "D Additional Experimental Settings", "content": "In this section, we provide additional experimental settings.\nBeam search implementation: For the Beam Search algorithm, we maintain the beam width, denoted by w, to match the lookahead length specified in the CDSL method for both tasks. Specifically, for the CommonGen task, the beam search is executed with w = 3, and it is applied with w = 5 for the HTG task, to ensure a fair comparison.\nPrompts templates: The prompt templates for the CommonGen and HTG tasks are shown in Figures 3, 4, respectively. The prompt template for Llama-guard evaluation is presented in Figure 5."}, {"title": "E Ablation", "content": "In this section, we report additional ablation studies and statistics.\nRuntime cost coefficient, c: We report the runtime cost coefficient, c between different target and draft pairs in Table 5."}]}