{"title": "Neural Force Field: Learning Generalized Physical Representation from a Few Examples", "authors": ["Shiqian Li", "Ruihong Shen", "Chi Zhang", "Yixin Zhu"], "abstract": "Physical reasoning is a remarkable human ability that enables rapid learning and generalization from limited experience. Current AI models, despite extensive training, still struggle to achieve similar generalization, especially in Out-of-distribution (OOD) settings. This limitation stems from their inability to abstract core physical principles from observations. A key challenge is developing representations that can efficiently learn and generalize physical dynamics from minimal data. Here we present Neural Force Field (NFF), a modeling framework built on Neural Ordinary Differential Equation (NODE) that learns interpretable force field representations which can be efficiently integrated through an Ordinary Differential Equation (ODE) solver to predict object trajectories. Unlike existing approaches that rely on high-dimensional latent spaces, NFF captures fundamental physical concepts such as gravity, support, and collision in an interpretable manner. Experiments on two challenging physical reasoning tasks demonstrate that NFF, trained with only a few examples, achieves strong generalization to unseen scenarios. This physics-grounded representation enables efficient forward-backward planning and rapid adaptation through interactive refinement. Our work suggests that incorporating physics-inspired representations into learning systems can help bridge the gap between artificial and human physical reasoning capabilities.", "sections": [{"title": "1. Introduction", "content": "Physical reasoning, the ability to understand and predict how objects interact in the physical world, is fundamental to both human intelligence and artificial systems (Spelke, 2022). This capability underlies crucial applications ranging from robotics to scientific discovery, making it a central challenge in AI research (Lake et al., 2017). One of the remarkable aspects of human cognitive capabilities is the ability to rapidly learn from limited examples (Kim et al., 2020; Jiang et al., 2022; Lake & Baroni, 2023; Zhang et al., 2024), especially evident in intuitive physics (Kubricht et al., 2017; Bear et al., 2021). Humans can quickly abstract core physical principles after observing limited physical phenomena, enabling them to predict complex dynamics and interact with novel environments (Spelke & Kinzler, 2007; Battaglia et al., 2013; Bonawitz et al., 2019; Xu et al., 2021).\nIn contrast, current AI systems face significant limitations in physical reasoning. Despite being trained on gigantic datasets, these models still struggle to achieve human-level generalization, particularly in Out-of-distribution (OOD) settings (Lake et al., 2017; Zhu et al., 2020). The core issue lies in their tendency to overfit observed trajectories rather than capturing inherent physical principles, severely limiting their ability to compose known knowledge and predict outcomes in novel contexts (Qi et al., 2021; Li et al., 2022; Wu et al., 2023). This stark contrast between human capabilities and current model limitations has motivated the search for new approaches that can learn generalizable physical representations from minimal data.\nTo bridge this gap, we aim to develop agents with few-shot physical learning abilities that achieve robust generalization across diverse environments. This ambitious goal presents three fundamental challenges: (i) Diverse Physical Dynamics: Physical systems exhibit intricate and nonlinear dynamics shaped by complex object properties and interactions. OOD scenarios often present drastically different dynamics from training examples, requiring sophisticated representations that explicitly capture core physical principles. (ii) Risk of Overfitting: The few-shot learning setting dramatically increases the challenge of generalization compared to large-scale training approaches. Models must carefully balance between fitting observed examples and extracting broader physical principles. (iii) Interactive Reasoning: Effective physical reasoning demands more than passive observation-agents must actively engage with their environment through experimentation and feedback, adapting their understanding based on limited examples."}, {"title": "2. Related work", "content": "Physical reasoning Research in physical reasoning has progressed along two main trajectories: passive observation and interactive platforms. The passive observation approach, exemplified by the Violation-of-Expectation (VoE) paradigm (Spelke et al., 1992), evaluates physical understanding by measuring agents' ability to detect violations of intuitive physics principles (ee Baillargeon, 1987; Hespos & Baillargeon, 2001; Dai et al., 2023). While this approach has provided valuable insights into basic physical comprehension, it is limited by its inability to assess active interventions and complex reasoning.\nTo enable more comprehensive evaluation, interactive platforms such as PHYRE (Bakhtin et al., 2019), the virtual tools game (Allen et al., 2020), and I-PHYRE (Li et al., 2023) have emerged. These environments require agents to actively manipulate objects to achieve specific goals, testing not only prediction capabilities but also planning and reasoning skills. However, existing approaches in these platforms often struggle with generalization across diverse scenarios, particularly in few-shot settings where limited training data is available (Qi et al., 2021; Li et al., 2023).\nCurrent physical reasoning models face two primary challenges: the need for extensive training data and limited cross-scenario transferability. While some methods achieve strong performance within specific scenarios (Allen et al., 2020), they often fail to generalize their understanding to novel situations, falling short of human-level reasoning capabilities (Kang et al., 2024). Our work addresses these limitations by introducing a framework that unifies passive observation and interactive learning through dynamic force fields. The NFF approach enables few-shot learning of physical principles while supporting active reasoning through its interpretable force-based representation, facilitating both accurate prediction and effective intervention planning across diverse physical scenarios."}, {"title": "3. Method", "content": "Traditional approaches to modeling physical interactions typically rely on implicit representations through hidden vectors to describe object interactions. These methods use neural networks to learn state transition functions that map current scene features to future states. However, this purely data-driven approach cannot guarantee physically grounded representations, leading to poor generalization despite intensive training. We introduce NFF, which addresses these limitations by learning physics-grounded, generalizable representations through explicit force field modeling; see Figure 1 for a comparison.\nThe core of NFF is built on the physical concept of a force field-a vector field that determines the force experienced by any query object based on its state $z^q$. For a scene with N objects, we model the force field $F(\\cdot)$ at time t using a neural network operating on a relation graph G. The graph contains object nodes $V = \\{z^q(t), z^1(t), ..., z^{N-1}(t)\\}$. Following neural operator methods (Lu et al., 2021) and graph neural models (Battaglia et al., 2018), we formulate the force field function as:\n$F(z^q(t)) = \\sum_{i\\in G(q)} W(f_{\\theta}(z^i(t)) \\cdot f_{\\phi}(z^q(t)))+b$,\nwhere G(q) represents the neighbors of query q, $f_{\\theta}$ and $f_{\\phi}$ are neural networks with parameters $\\theta$ and $\\phi$, and $W\\in \\mathbb{R}^{d_{hidden} \\times d_{force}}$, $b\\in\\mathbb{R}^{d_{force}}$ map hidden features to low-dimensional forces. The state vector z incorporates zero-order (position, angle) and first-order (velocity, angular velocity) states. This representation naturally handles various physical interactions including collision, friction, spring forces, and rotation.\nRather than relying on neural decoders, NFF employs a second-order ODE integrator to compute object trajectories from the learned force field. This approach ensures physically consistent trajectories governed by fundamental principles. The dynamic change of motion for a query state follow:\n$\\frac{d^2x^q(t)}{dt^2} = \\frac{dv^q(t)}{dt} = F(z^q(t))$.\nWhile object mass theoretically affects acceleration, these mass constants are absorbed into the learned $F(\\cdot)$.\nWe solve the ODE system using numerical integration methods such as Runge-Kutta:\n$z^q(t) = ODESolve(z^q(0), F, 0, t)$,\n$\\begin{cases} x(t) = x(0) + \\int_0^t v(t) dt, \\\\ v(t) = v(0) + \\int_0^t F(z^q(t)) dt, \\end{cases}$"}, {"title": "3.1. The Neural Force Field (NFF) representation", "content": "Traditional approaches to modeling physical interactions typically rely on implicit representations through hidden vectors to describe object interactions. These methods use neural networks to learn state transition functions that map current scene features to future states. However, this purely data-driven approach cannot guarantee physically grounded representations, leading to poor generalization despite intensive training. We introduce NFF, which addresses these limitations by learning physics-grounded, generalizable representations through explicit force field modeling; see Figure 1 for a comparison.\nThe core of NFF is built on the physical concept of a force field-a vector field that determines the force experienced by any query object based on its state $z^q$. For a scene with N objects, we model the force field $F(\\cdot)$ at time t using a neural network operating on a relation graph G. The graph contains object nodes $V = \\{z^q(t), z^1(t), ..., z^{N-1}(t)\\}$. Following neural operator methods (Lu et al., 2021) and graph neural models (Battaglia et al., 2018), we formulate the force field function as:\n$F(z^q(t)) = \\sum_{i\\in G(q)} W(f_{\\theta}(z^i(t)) \\cdot f_{\\phi}(z^q(t)))+b$,\nwhere G(q) represents the neighbors of query q, $f_{\\theta}$ and $f_{\\phi}$ are neural networks with parameters $\\theta$ and $\\phi$, and $W\\in \\mathbb{R}^{d_{hidden} \\times d_{force}}$, $b\\in\\mathbb{R}^{d_{force}}$ map hidden features to low-dimensional forces. The state vector z incorporates zero-order (position, angle) and first-order (velocity, angular velocity) states. This representation naturally handles various physical interactions including collision, friction, spring forces, and rotation.\nRather than relying on neural decoders, NFF employs a second-order ODE integrator to compute object trajectories from the learned force field. This approach ensures physically consistent trajectories governed by fundamental principles. The dynamic change of motion for a query state follow:\n$\\frac{d^2x^q(t)}{dt^2} = \\frac{dv^q(t)}{dt} = F(z^q(t))$.\nWhile object mass theoretically affects acceleration, these mass constants are absorbed into the learned $F(\\cdot)$.\nWe solve the ODE system using numerical integration methods such as Runge-Kutta:\n$z^q (t) = ODESolve (z^q(0), F, 0, t)$,\n$\\begin{cases} x(t) = x(0) + \\int_0^t v(t) dt, \\\\ v(t) = v(0) + \\int_0^t F(z^q(t)) dt, \\end{cases}$"}, {"title": "3.2. Interactive planning", "content": "NFF extends beyond forward prediction to enable mental simulation for planning tasks. Given goal-directed scenarios, NFF can serve as a learned simulator to either search for action sequences that achieve the desired goal state through forward simulation, or optimize initial conditions and system parameters through backward computation.\nFor physical reasoning tasks requiring specific action sequences, we extend the NFF framework to incorporate action effects by including action features in $f_\\theta$. Through forward simulation with the NFF model, we sample multiple action sequences $A = \\{a_0, ..., a_T\\}$ and optimize according to evaluation metrics R:\n$A^* = \\underset{A}{\\operatorname{argmax}} R(F, A)$.\nThe optimal sequence $A^*$ can then be executed in the physical environment. While the forward simulation may initially deviate from actual observations, NFF's physics-based design enables efficient adaptation through new experimental data. This capability for rapid model refinement mirrors human reasoning (Allen et al., 2020) and overcomes the catastrophic forgetting challenges faced by pure neural network approaches (Dohare et al., 2024). When executed trajectories deviate from the desired goal state, the new state sequences can be directly incorporated into model optimization through the MSE loss, following the same training procedure used in the initial learning phase.\nBy inverting the ODE integrator, NFF enables the computation of initial conditions given a desired goal state. Through backward integration, the initial conditions can be determined analytically:\n$\\begin{cases} x(0) = x(t) + \\int_0^t v(t) dt, \\\\ v(0) = v(t) + \\int_0^t F(z^q(t)) dt. \\end{cases}$\nThe invertible nature of the NFF formulation makes this"}, {"title": "4. Experiments", "content": "We evaluate our approach on two physical reasoning tasks: I-PHYRE and N-body dynamics. Each task is evaluated across three distinct settings: within-scenario prediction, cross-scenario prediction, and planning. Detailed environment and dataset configurations are provided in Appendix A."}, {"title": "4.1. Environments and datasets", "content": "I-PHYRE I-PHYRE (Li et al., 2023) presents a suite of complex physical reasoning puzzles requiring multi-step interventions. The environment incorporates diverse physical interactions including gravity, collision, friction, rotation, spring dynamics, and pendulum motion. It challenges AI agents to solve puzzles with minimal environmental interactions while generalizing to unseen scenarios. For within-scenario prediction, we evaluate on 10 training games that share similar scenarios but require different solutions. The cross-scenario prediction setting extends to 30 novel games featuring noise, compositional elements, and multi-ball scenarios, with varying object properties such as block lengths, ball sizes, and object positions. In the planning setting, models must generate optimal action sequences to successfully complete each game.\nN-body The N-body problem (Newton, 1833) tests trajectory prediction for small comets orbiting a massive central planet. Using REBOUND simulator (Rein & Liu, 2012), we generate dynamics data by randomly sampling orbital parameters including radii, angles, and masses. This task evaluates the model's ability to infer gravitational laws from limited observations. The within-scenario prediction setting introduces novel initial conditions and masses, focusing on systems with 1-2 orbiting bodies tracked over 50 timesteps. Cross-scenario prediction significantly increases complexity by introducing systems with 8 orbiting bodies tracked over 100 timesteps. The planning setting challenges models to optimize initial conditions that will evolve to specified target states after 50 timesteps."}, {"title": "4.2. Learning force fields from a few examples", "content": "We qualitatively evaluate NFF's ability to learn force fields from limited training data; training implementation details are provided in Appendix B. For I-PHYRE, we train NFF on just 10 basic games with 10 trajectory samples each. From these 100 trajectories, the model successfully learns fundamental physical concepts including gravity, support, sliding, collision, friction, and spring dynamics, representing them through unified force fields (Figure 2c). To verify that NFF learns generalizable physical principles, we examine force responses to varied ball-block interactions under controlled conditions. Figure 4 shows our systematic evaluation where we independently vary individual scene parameters such as position, velocity, and angle while holding others constant, demonstrating NFF's accurate force response modeling.\nFor the N-body system, we train NFF using 200 randomly sampled trajectories from 2-body and 3-body dynamics. As shown in Figure 2e, the model successfully learns to capture the inverse gravitational field, correctly modeling the distance-dependent centripetal forces governing the mutual attraction between bodies."}, {"title": "4.3. Prediction on unseen scenarios", "content": "We evaluate the learned force fields' predictive accuracy in both within-scenario and cross-scenario settings. For I-PHYRE, we test against 20 ground truth trajectories per game, while for N-body systems, we evaluate using 200 novel initial conditions. We compare our results against established interaction modeling methods: IN (Battaglia et al., 2016) and SlotFormer (Wu et al., 2023).\nWe employ multiple complementary metrics to assess prediction quality. Beyond standard Root Mean Squared Error (RMSE), we introduce Final Position Error (FPE) (final position error) and Position Change Error (PCE) (position change error) for detailed performance analysis. FPE quantifies terminal position accuracy, while PCE evaluates the model's ability to capture motion dynamics. Additionally, Pearson Correlation Coefficient (R) measures trajectory shape alignment independent of speed variations. This comprehensive metric suite enables thorough evaluation across temporal and spatial dimensions. Detailed definitions are provided in Appendix B.2.\nAs shown in Figure 3, NFF generates physically plausible trajectories that closely match ground truth behavior, even in previously unseen scenarios. Quantitative comparisons in Figure 5 demonstrate NFF's superior performance across all metrics for both I-PHYRE and N-body tasks, with particularly strong results in cross-scenario generalization. While SlotFormer exhibits overfitting tendencies that limit its cross-scenario performance (analyzed further in Appendix C), NFF's ability to learn generalizable"}, {"title": "4.4. Planning on unseen scenarios", "content": "The trained NFF model can generate plans for novel tasks after learning from limited demonstrations. Unlike prediction tasks that evaluate trajectory accuracy, planning tasks require generating action sequences to achieve specific goals.\nWe implement a 5-round interactive learning protocol. NFF acts as a mental simulator to evaluate 500 randomly sampled action candidates, selecting the optimal sequence for physical execution. After each execution, the model updates its parameters based on observed outcomes, refining its physics understanding. This updated model then guides subsequent action proposals.\nWe quantitatively evaluate planning performance by calculating success probability $p_i$ for each game as the success rate over 20 trials in round i, with NFF updating after failures; see detailed results in Appendix E. Figure 6 compares NFF against random sampling, human performance (from Li et al. (2023)), IN, and SlotFormer using cumulative success probability: $1-\\prod_{i=1}^n(1-p_i)$ for each trial n. NFF outperforms baselines and approaches human-level performance after refinement (Allen et al., 2020), demonstrating effective few-shot learning. The poor performance of IN and SlotFormer, falling below random sampling, indicates how inaccurate dynamics modeling compromises planning."}, {"title": "4.5. Ablation study", "content": "We investigate three key factors affecting model performance: integration precision, ODE grounding, and latent dimensionality. For integration precision, we evaluate NFF on the N-body task using Euler integration at four precision levels: 1e-3, 5e-3, 1e-2, and 5e-2. Figure 7a demonstrates that higher integration precision consistently yields better performance. We also explore more integration methods in Appendix D. To study ODE grounding's impact on generalization, we compare two configurations: our NFF using predicted force fields with ODE integration, and IN using learned state transitions at matching step sizes. Figures 7b and 7c shows that ODE integration enhances generalization performance. However, at coarser step sizes (5e-2), NFF slightly underperforms IN, indicating that ODE-based approaches require fine integration precision to realize their advantages. For latent dimensionality analysis, we vary the latent interaction space dimension in NFF across 3, 16, and 256 dimensions. Results in Figure 7d reveal that lower-dimensional representations improve generalization capability. The visualization in Figure 7e confirms this finding, showing that reduced dimensionality leads to latent representations more closely matching ground truth. These ablation studies demonstrate that NFF achieves optimal few-shot learning of physical dynamics when combining high integration precision, low-dimensional latent space, and ODE-based integration."}, {"title": "5. Discussion", "content": "Modeling diverse forces While NFF has demonstrated effectiveness in modeling fundamental physical forces like gravity, support, and collision, its principles extend naturally to broader domains. The framework can potentially model social forces (Shu et al., 2015; Xie et al., 2017; Wei et al., 2017; 2018; Shu et al., 2021) and biological forces governing migration patterns and human motion (Netanyahu et al., 2024). Limitations Like existing approaches (Battaglia et al., 2016), NFF operates on symbolic states, setting aside perception challenges. The integration of raw sensory input with physics learning remains an open challenge, requiring investigation into various representation frameworks."}, {"title": "6. Conclusion", "content": "We present NFF, a force field-based representation framework for modeling physical interactions that exhibits human-like few-shot learning, generalization, and reasoning capabilities. Our experiments on two challenging physical reasoning datasets demonstrate NFF's ability to learn diverse physical concepts and rules from limited observations. This initial exploration of force field opens new possibilities for developing physical world models through representation learning, potentially bridging the gap between symbolic physics understanding and learning-based approaches."}]}