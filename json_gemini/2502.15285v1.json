{"title": "Offload Rethinking by Cloud Assistance for Efficient Environmental Sound Recognition on LPWANS", "authors": ["Le Zhang", "Quanling Zhao", "Run Wang", "Shirley Bian", "Onat Gungor", "Flavio Ponzina", "Tajana Rosing"], "abstract": "Learning-based environmental sound recognition has emerged as a crucial method for ultra-low-power environmental monitoring in biological research and city-scale sensing systems. These systems usually operate under limited resources and are often powered by harvested energy in remote areas. Recent efforts in on-device sound recognition suffer from low accuracy due to resource constraints, whereas cloud offloading strategies are hindered by high communication costs. In this work, we introduce ORCA, a novel resource-efficient cloud-assisted environmental sound recognition system on batteryless devices operating over the Low-Power Wide-Area Networks (LPWANs), targeting wide-area audio sensing applications. We propose a cloud assistance strategy that remedies the low accuracy of on-device inference while minimizing the communication costs for cloud offloading. By leveraging a self-attention-based cloud sub-spectral feature selection method to facilitate efficient on-device inference, ORCA resolves three key challenges for resource-constrained cloud offloading over LPWANs: 1) high communication costs and low data rates, 2) dynamic wireless channel conditions, and 3) unreliable offloading. We implement ORCA on an energy-harvesting batteryless microcontroller and evaluate it in a real world urban sound testbed. Our results show that ORCA outperforms state-of-the-art methods by up to 80x in energy savings and 220\u00d7 in latency reduction while maintaining comparable accuracy.", "sections": [{"title": "1 Introduction", "content": "Recent advances in intelligent environmental monitoring highlight machine learning-based environmental sound recognition, leveraging ultra-low-power sensing in embedded systems which offers advantages over vision-based solutions [3, 25, 33]. These applications are usually deployed in remote and resource-constrained areas, such as forests, wildlife reserves, or urban environments, where energy-efficient operation is crucial for continuous, autonomous monitoring. They demonstrate potential in biological research, such as classifying bird vocalizations in the rainforest [44], and in city-scale sensing applications, such as monitoring noise pollution and traffic flows [10, 30, 39].\nDespite their potential, edge devices' limited processing power and energy constraints make high-accuracy on-device predictions challenging [13, 19, 20, 27]. To overcome these limitations, recent efforts focus on edge-cloud collaboration [3, 14, 16, 57]. Compared to on-device learning, edge-cloud collaboration offloads inference tasks to the cloud server via wireless networks like Bluetooth LE, Wi-Fi, and LTE [3, 14, 16, 57]. This improves accuracy and reduces latency, but adds network dependency and energy overheads of costly wireless communication. Additionally, network coverage is a key factor in matching the diverse application scenarios. LTE provides wide coverage but is power-hungry for resource-constrained devices. In contrast, BLE and Wi-Fi are energy-efficient but have limited range, making them unsuitable for wide-area sensing applications. For instance, biologists deploy sensor nodes for acoustic bird species identification across vast rainforest areas [54]. Similarly, civil engineers and researchers use sensor nodes for large-scale acoustic sensing and classification in urban noise monitoring [49]. Although not sufficiently explored in previous studies, we find Low-Power Wide-Area Networks (LPWANs) ideal for these scenarios, balancing range and communication efficiency in edge-cloud collaborations.\nIn this paper, we introduce a novel resource-aware cloud-assisted machine learning system, ORCA (Offload Rethinking by Cloud Assistance), tailored for environmental sound recognition on ultra-low-power batteryless devices operating over LPWANs like LoRa networks. First, we leverage LPWANs to enable low-power, wide-area, and long-range edge-cloud collaboration for wide-area sound sensing applications. Second, we propose a novel cloud assistance strategy for high-accuracy, resource-efficient, and LPWAN-adapted cloud offloading. In cloud assistance, instead of on-device inference as Figure 1(a) or offloading by splitting the pipeline across wireless channels and generating inference results on the cloud as Figure 1(b), ORCA keeps the entire inference pipeline on edge devices while leveraging the server for assistance. Specifically, the server identifies the most important input features sampled and uploaded by the edge devices. Here, we focus on identifying the most important frequency-domain features as previous studies show their effectiveness in environmental sound classification [35]. After that, the server provides the edge device with feature importance information through the downlink. This process is shown as the red arrows in Figure 1(c). The edge devices can now use the given information to selectively process and perform inference on the most important features as the blue arrow in Figure 1(c), thereby saving energy and time by scaling down the inputs and improving accuracy. As a result, the role of the server is now \"assisting\" edge devices for inference, avoiding edge devices being dependent on it. Specifically, ORCA tackles three key challenges of cloud assistance over LPWANS:\n(1) High communication costs and low data rate: Though LPWANs like LoRa are \"low-power\", wireless communication remains resource-intensive, e.g., 40x for uplink and 6\u00d7 for downlink to the average power of on-device inference [29]. Additionally, LPWANs operate at a low data rate, e.g., 0.3-5.5 kbps in 125 kHz LoRa channel [6]. Therefore, previous data streaming on BLE, Wi-Fi, or LTE [16, 57] is infeasible. In ORCA, we tackle this problem with cloud assistance, transmitting a low-resolution spectrogram from edge to cloud and selecting important features. ORCA implements this process by feeding the low-resolution spectrogram into a pre-trained vision transformer and extracting the feature importance masks from the self-attention maps. Our results show that the low-resolution spectrogram not only saves payloads but is also effective in learning the importance of features.\n(2) Dynamic communication cost: Wireless channel conditions are variable due to dynamic environments. To ensure reliable transmission, LPWANs adjust configurations like transmission power. Previous assumptions of constant wireless costs are impractical for energy-sensitive batteryless devices [3, 57]. In ORCA, we dynamically optimize the \"assistance resolution\", the size of the spectrogram for uplink transmission and feature selection, to balance payload size and energy cost based on real-time communication feedback. For example, when communication cost is low, we select a larger size of spectrogram to improve feature extraction on the server and eventually increase the on-device classification accuracy. On the opposite, when communication cost is high, we switch to a smaller size of spectrogram for cloud assistance which result in lower classification accuracy.\n(3) Unreliable offloading: Factors such as signal attenuation, interference, and environmental obstacles can lead to unreliable data transmission, resulting in packet loss and the need for retransmissions. This further challenges the reliability of the end-to-end offloading services. The previous server-dependent solution addresses this problem by resource-inefficient retransmission [14]. In ORCA, when a packet loss occurs, we switch to local on-device inference only without cloud assistance, i.e., we keep the blue arrow only and ignore the red arrows in Figure 1(c). This benefits from the design of maintaining the inference pipeline on-device, thereby saving the costs required for retransmission.\nApplication Scenarios: ORCA can operate over batteryless sensor networks in the wild, where distributed batteryless sensor nodes collect audio samples and perform resource-efficient cloud-assisted learning by connecting to an existing LPWAN gateway or a standalone edge server through wireless channels. As an aforementioned example [49], batteryless sensor nodes powered by small solar panels can be strategically deployed in outdoor urban environments to monitor noise pollution. These nodes connect to established LoRa infrastructure and edge servers for resource-efficient cloud-assisted noise monitoring over hundred-meter to kilometer-scale distances. This setup enables continuous urban noise monitoring without battery replacements or maintenance, ensuring long-term, low-cost sustainability for smart city applications.\nContributions: (1) We propose a novel cloud assistance strategy for environmental sound recognition on resource-limited embedded systems and LPWANs. By leveraging vision transformer architecture for subspectral feature selection and efficient on-device spectral encoding convolutional neural networks (CNNs), ORCA achieves 2.5-12.5 \u0440.\u0440. accuracy improvements on five public environmental sound datasets. (2) We provide optimized assistance resolution strategies under dynamic communication costs and packet losses to ensure resource-efficient cloud assistance in dynamic environments. (3) We build a real-world testbed to evaluate accuracy, payload size, energy consumption, inference latency, and system overhead using collected LoRa traces. ORCA achieves up to 80\u00d7 energy savings and 220\u00d7 latency reduction, while maintaining accuracy comparable to state-of-the-art methods. We release an open-source LoRa library for batteryless computing on the ultra-low-power MSP430 microcontroller\u00b9."}, {"title": "2 Background and Related Works", "content": "Audio Processing: Audio signals are high-dimensional time-series data with complex patterns and temporal dependencies, making analysis challenging. Recent work in efficient sound classification uses Short-Time Fourier Transform (STFT) with CNNs or self-attention models to extract key time-domain features [3, 31]. These methods rely only on time-domain features and often perform poorly in environmental sound recognition. Additionally, STFT introduces overhead and lacks flexibility for selective frequency analysis, as it provides uniform resolution across bands. On the another hand, recent studies show that sub-spectral features in the frequency domain are effective for acoustic scene classification, as environmental sounds often have unique frequency distributions [7, 35]. Therefore, we explore using sub-spectral features for resource-efficient sound recognition.\nWavelet Transform: The wavelet transform provides a flexible approach for sub-spectral feature extraction, enabling analysis of non-stationary audio signals by decomposing them with orthonormal basis functions in L2 space [9, 22, 24]. Compared to STFT, the wavelet transform provides better localization in both time and frequency domains [3, 31]. The discrete wavelet transform (DWT) [48] uses a high-pass filter and a low-pass filter at various levels to break the signal into detailed and approximate coefficients. DWT focuses on low-frequency decomposition, while the wavelet packet transform (WPT) [23] provides a more detailed and flexible decomposition by analyzing both low and high frequencies, offering a comprehensive signal representation across all frequency bands. Recent research has explored integrating wavelet transforms with deep learning for sound recognition [12, 32, 38, 56]. However, since frequency-domain features are not uniformly distributed, fine-tuning resolution is essential for efficient classification."}, {"title": "2.2 Cloud Offloading", "content": "Offloading Solution: Cloud offloading allocates partial computations to a cloud server, reducing the workload on edge devices. We summarize recent works in Table 1. DeepCOD [57], SEDAC [3], and LimitNet [14] split the inference pipeline across wireless channels. FLEET [16] adds early exits for resource savings. CACTUS [41] exchanges models for context-aware inference. We refer to these solutions as \"cloud-dependent,\" as their functionalities rely on the server. However, collaboration over LPWANs is limited by resource constraints and unreliable channels, making cloud-dependent strategies impractical. First, cloud-dependent approaches ignore edge resource constraints, offloading even basic inference task to the server. In contrast, empirical measurements show LoRa radios consume up to 40\u00d7 more power for uplink and 6\u00d7 for downlink than on-device computation [29]. Additionally, unreliable channels make consistent offloading infeasible. Data packets may be lost or corrupted during transmission, and edge devices may lack resources for retransmission. To tackle these challenges, we propose a novel cloud assistance solution, contrasting with cloud-dependent strategies. In ORCA, the complete inference pipeline remains on edge devices for inference reliability. The server assists edge devices in identifying key input features, reducing their computational load."}, {"title": "3 Preliminary Study", "content": "Study 1: WPT Depths and Spectrogram Resolution. As discussed in Section 2.1, the Wavelet Packet Transform (WPT) decomposes signals into finer sub-frequency bands at each level, with spectrogram resolution depending on WPT depth. Greater depth improves classification but increases computational cost. We conduct a preliminary study on WPT depth in environmental sound classification using ESC10 [37] and US8K [45]. On an MSP430 microcontroller [51], we implemented a simple CNN classifier using WPT spectrograms at varying resolutions, measuring accuracy and energy consumption. Figure 2 shows that higher resolution improves accuracy but greatly increases energy consumption, highlighting the need for cost-efficient approaches to balance performance and efficiency. This experiment also implies that to achieve good classification in on-cloud inference, high-resolution spectrogram will need to be transmitted. This results in even larger energy and communication overhead for edge devices, hence motivating keeping the inference pipeline local.\nStudy 2: Effects of Frequency Bands. WPT also allows us to selectively upsample frequency-domain resolutions on certain frequency bands. We argue that the discriminative information for different sound classes is distributed differently across different frequency bands. To verify that, in the second preliminary experiment, we classify spectrograms of the same resolution but with either high-frequency bands only or low-frequency bands only. The results, shown in Figure 3, indicate that, for sounds of helicopters, waves, and drilling, high-frequency bands are more important for making the correct classification, whereas low-frequency bands are more important for some other classes.\nThese observations motivate the use of frequency-domain attention to guide the wavelet transform in generating multi-resolution spectrograms, achieving high accuracy while minimizing WPT and classification costs. This insight informs the design of our novel neural architecture, detailed in the following section."}, {"title": "4 ORCA Design", "content": "Based on the observations and discussions in Section 2 and 3, we argue that an ideal edge-cloud collaborative learning system over LPWANs should have the following design considerations. First, to tackle the unreliability of wireless channels, a cloud-assisted strategy should be adopted rather than the state-of-the-art cloud-dependent offloading. Second, to adapt to the low bit rates of LPWANs and the on-device resource constraints, we demand a more efficient information exchange strategy. Additionally, from an audio processing perspective, we look for a more effective feature selection method to reduce input size and therefore reduce on-device computation overheads while maintaining comparable accuracy performances. Informed by these demands, we introduce our novel design of a resource-aware cloud-assisted environmental sounds recognition system, primarily operating over LoRa networks. Our system features resource-aware and communication-adaptive cloud assistance, enabling efficient and flexible cloud offloading under resource constraints and unreliable communications. Furthermore, we apply a novel self-attention-based frequency band feature selection method with the wavelet transform to effectively select important features for efficient on-device inference. We illustrate the workflow of the ORCA cloud-assisted framework in Figure 4:\nStep 1: Initially, the edge device preprocesses audio signals using low-level WPT to generate a low-resolution spectrogram. Preprocessing details are in Section 4.2, and optimized resolution selection based on wireless channel feedback, e.g., Adaptive Data Rate (ADR), is discussed in Section 4.5.\nStep 2: The resulting low-resolution spectrogram is transmitted to the server via uplink LoRa channel, using ADR-recommended parameters.\nStep 3: Upon receiving the low-resolution spectrogram, the server processes it using a pre-trained contrastive vision transformer [11] to extract an attention mask through attention rollout [1]. Details of the cloud model are provided in Section 4.3.\nStep 4: The extracted attention mask, along with ADR feedback, is sent back to the edge device via downlink. Resource efficiency adaptations using ADR feedback are further discussed in Section 4.5."}, {"title": "4.1 Overview", "content": "Based on the observations and discussions in Section 2 and 3, we argue that an ideal edge-cloud collaborative learning system over LPWANs should have the following design considerations. First, to tackle the unreliability of wireless channels, a cloud-assisted strategy should be adopted rather than the state-of-the-art cloud-dependent offloading. Second, to adapt to the low bit rates of LPWANs and the on-device resource constraints, we demand a more efficient information exchange strategy. Additionally, from an audio processing perspective, we look for a more effective feature selection method to reduce input size and therefore reduce on-device computation overheads while maintaining comparable accuracy performances. Informed by these demands, we introduce our novel design of a resource-aware cloud-assisted environmental sounds recognition system, primarily operating over LoRa networks. Our system features resource-aware and communication-adaptive cloud assistance, enabling efficient and flexible cloud offloading under resource constraints and unreliable communications. Furthermore, we apply a novel self-attention-based frequency band feature selection method with the wavelet transform to effectively select important features for efficient on-device inference. We illustrate the workflow of the ORCA cloud-assisted framework in Figure 4:\nStep 1: Initially, the edge device preprocesses audio signals using low-level WPT to generate a low-resolution spectrogram. Preprocessing details are in Section 4.2, and optimized resolution selection based on wireless channel feedback, e.g., Adaptive Data Rate (ADR), is discussed in Section 4.5.\nStep 2: The resulting low-resolution spectrogram is transmitted to the server via uplink LoRa channel, using ADR-recommended parameters.\nStep 3: Upon receiving the low-resolution spectrogram, the server processes it using a pre-trained contrastive vision transformer [11] to extract an attention mask through attention rollout [1]. Details of the cloud model are provided in Section 4.3.\nStep 4: The extracted attention mask, along with ADR feedback, is sent back to the edge device via downlink. Resource efficiency adaptations using ADR feedback are further discussed in Section 4.5."}, {"title": "4.2 Preprocessing", "content": "To minimize communication costs, ORCA employs a low-resolution wavelet spectrogram as a compact and informative abstraction for cloud assistance. We use the WPT with depth n to extract coarse frequency-domain features from the input audio waveform, producing a spectrogram S with a frequency dimension of 2\u207f. To generalize features over time and reduce payload size, we apply average pooling along the time axis, transforming S into a square matrix S\u2090 in dimension of 2\u207f. We refer to S\u2090 as the cloud-assisted spectrogram and define its dimension as the cloud assistance resolution R\u2090 = 2\u207f, with selection details in Section 4.5."}, {"title": "4.3 Attention Mask Generation", "content": "In this section, we discuss how the server identifies important features from the assistance spectrogram S\u2090. Specifically, we define important features as the most informative frequency bands, guided by preliminary studies. The edge device then leverages this information, encoded as an attention mask, to enhance on-device inference accuracy in later steps."}, {"title": "4.3.1 Vision Transformer for Assistance Spectrogram", "content": "ORCA server-side design leverages the self-attention mechanism to dynamically encode the importance of input features. The server processes the assistance spectrogram S\u2090 by patching it into tokens and computing a self-attention map to highlight key regions. We show the attention computation in Figure 5. First, we adopt the same architecture from the vision transformer [11] and divide the input spectrogram into p\u00b2 patches. To preserve the spectrogram's spectral-temporal properties, we apply positional encoding by adding trainable encoding to each patch. Next, we pass the patches through a convolutional patch embedding layer, encoding each patch into an embedding of dimension E. The resulting embedding is passed through the i-th attention block to compute the attention matrix A\u1d62, sequentially. Formally, A\u1d62 = Softmax(Q\u1d62 \u00b7 K\u1d62\u1d40 / \u221aE), where Q\u1d62 and K\u1d62 are the query and key embeddings at each layer. The attention matrix A\u1d62 of size p\u00b2 \u00d7 p\u00b2 captures the relative importance between patch pairs, aiding in identifying the most informative frequency bands, as discussed next."}, {"title": "4.3.2 Attention Mask Generation", "content": "Recall that the attention matrix A\u1d62 represents the attention map of the i-th attention block, encoding the relative importance between patches in a spectrogram. Inspired by [1], we compute the rollout attention map A = \u220f A\u1d62 = A\u2099A\u2099\u208b\u2081\u2026A\u2081 for importance estimations. This approach aggregates attention matrices from all blocks, enhancing interpretability and preventing attention scores from vanishing. The resulting rollout attention map A has dimensions p\u00b2 \u00d7 p\u00b2. Then, we aim to identify the most informative frequency bands for the edge. Intuitively, a frequency band is informative if patches within that band have high attention scores, as this indicates that the cloud model prioritizes those patches. Therefore, let a\u1d62\u2c7c represent the rollout attention between patches i and j in A. We compute the column-wise summation C of A as C = [c\u2081, c\u2082, \u2026, c\u209a\u2082] where c\u2c7c = \u2211\u1d62\u208c\u2081\u2227{p\u00b2} a\u1d62\u2c7c. The vector C is reshaped into a 2D importance matrix C' \u2208 \u211d{p\u00d7p}, where each entry represents the importance of a patch in the input WPT spectrogram. We select frequency bands by summing contiguous k rows in C' and identifying the highest sum, where k is a predefined hyperparameter agreed upon by the server and edge device. A binary vector of length p records the selected indices, forming the spectral attention mask, which is sent to edge devices."}, {"title": "4.3.3 Contrastive Pre-Training", "content": "The method above relies on a vision transformer capable of identifying informative frequency bands from the WPT spectrogram. Given the lack of labeled data for frequency-domain feature importance information, we propose training the cloud model offline in an unsupervised manner. Inspired by contrastive learning, where the model learns to produce distinctive features via contrastive loss, we create attracting and contrasting pairs by masking random frequency bands and use triplet loss [46] on the flattened output of vision transformer as representations. Overall, the advantage of ORCA attention-based cloud assistance solution is twofold: first, it uses self-attention over spectrograms to guide clients in focusing on informative frequency bands, which not only improves inference accuracy on the resource-constrained edge devices but also reduces computational load by minimizing the edge model input size. Additionally, transmitting the low-resolution assistance spectrogram and attention masks is highly communication-efficient, significantly reducing communication costs and latency."}, {"title": "4.4 Cloud-Assisted Inference", "content": "Following the discussion on server-generated attention masks, we explore how edge devices can leverage this information for efficient on-device inference. First, we introduce the Multi-resolution Refinement module, which extracts high-resolution frequency bands guided by attention masks. After refinement, two challenges remain: (i) embedding high-resolution spectral bands and (ii) creating a multi-resolution representation for accurate and efficient inference. For (i), we propose Spectral Encoding, a trainable weight that encodes high-resolution frequency band-specific knowledge. For (ii), we employ Multi-resolution CNNs to process the combination of high-resolution bands from multi-resolution refinement and their corresponding spectral encoding for efficient on-device classification."}, {"title": "4.4.1 Multi-resolution Refinement", "content": "The server-generated spectral attention mask captures key frequency bands. It guides the edge device to selectively extract high-resolution spectrograms via wavelet transform. Let R\u2097 denote the pre-defined dimension of the low-resolution spectrogram and R\u2095 the dimension of the high-resolution spectral bands, this refinement results in R\u2097-dimensional low-resolution spectrograms and R\u2095-dimensional high-resolution spectrograms frequency bands. To further reduce dimension, adaptive average pooling is applied along the time dimension, regularizing the size of both spectrograms."}, {"title": "4.4.2 Spectral Encoding", "content": "Since each frequency band captures unique frequency-domain properties, spectrograms from different bands should be interpreted accordingly. Using separate CNNs per band [35] is memory-inefficient and costly. Instead, inspired by transformer's positional encoding, we use spectral encoding, a trainable weight that encodes frequency band-specific information. It is then concatenated channel-wise to corresponding high-resolution bands, as shown in Figure 6. This approach helps the network to learn spectral-specific knowledge independently of the input spectrogram."}, {"title": "4.4.3 Multi-resolution CNN", "content": "The next challenge is to create a multi-resolution representation for inference. As discussed in preliminary studies in Section 3, discriminative information varies between spectral bands of the spectrogram. With the full low-resolution spectrogram available from preprocessing, we use two 2-layer shallow CNN as encoder encoders, one for low resolution and one for high resolution. The encoded features are fused channel-wise into a single vector and fed into the Multi-Res classifier for final classification. This architecture reduces inference costs by leveraging spectrograms at different resolutions. If cloud assistance is unavailable, an additional Single-Res classifier is employed to process the output of the Low-Res encoder only. All components are pre-trained offline in a two-stage supervised process. First, we train the low-res encoder, high-res encoder, and multi-resolution classifier together with the attention masks generated by the pre-trained cloud vision transformer. In the second stage, we freeze all other components and train the single-resolution classifier independently."}, {"title": "4.5 Resource-Aware Scheduler", "content": "Given the high energy cost of communication and wireless uncertainty, dynamically managing data transmission size is essential for resource-efficient cloud assistance. Experimental measurements [29] indicate that the uplink phase dominates energy consumption in each communication round and varies with channel conditions. Thus, a key component of our framework is optimizing uplink data transmission. We introduce a resource-aware, communication-adaptive resolution algorithm. This algorithm dynamically schedules the assistance resolution R\u2090 (as discussed in Section 4.2) based on energy storage and communication quality for resource-efficient cloud assistance."}, {"title": "4.5.1 Communication Model", "content": "As discussed in Section 4.1, ORCA uses two communication phases for one round of cloud assistance, uplink (Tx) and downlink (Rx). It adopts the intermittent computation model from [29] which concludes an uplink and a downlink in the same power cycle with a synchronized sleep period interleaved. The key advantage of this design is maintaining inference integrity and timeliness for cloud assistance, even during prolonged power failures in batteryless systems. We illustrate this design in Figure 7. Within one power cycle, edge device initiates by restoring the communication parameters, spreading factor (SF) and transmitting power (P{Tx}) once waking up at voltage threshold V\u2092\u2099. Then it goes through sampling and preprocessing, Tx, sleeping, Rx, and on-device inference sequentially as discussed in Section 4.1. Between each power cycle, our edge device checkpoints and restores SF and P{Tx} in and out of the non-volatile memory (yellow blocks in Figure 7). This ensures their synchronizations to the server's recommendation for reliable communication. Here, the generic ADR algorithm [47] is employed to estimate the optimal communication parameters ensuring communication reliability. Every time the server receives an uplink packet, it calculates and compares the SNR margins to the optimal values and recommends the optimal SF and P{Tx} back to the edge device in downlink message. Edge device can then checkpoint these parameters for next round of communication. The next challenge is to complete restoring, preprocessing, Tx, sleep, Rx, inference, and checkpointing within one power cycle."}, {"title": "4.5.2 Adaptive Resolution", "content": "Given the proposed communication model and parameters, we first examine the key factors influencing energy consumption. Since batteryless devices usually wake up at a pre-defined voltage threshold, the energy budget per power cycle is typically fixed and can be estimated by E{cap} = 1/2C(V\u00b2{on} - V\u00b2{off}), where C is capacitance, and V\u2092\u2099 and V\u2092{ff} represent the microcontroller switching voltage thresholds (on and off, respectively), as depicted in Figure 7. We propose ORCA resource-aware adaptive resolution algorithm for cloud assistance, designed to adapt to varying communication costs and complete each round of cloud assistance within a single power cycle. Our approach determines an optimal assistance resolution R\u2090 which in turn defines the payload size S = R\u2090\u00b2 for uplink. We model the adaptive resolution algorithm with the parameters followed. The uplink energy consumption E{Tx} can be estimated as: E{Tx} = P{Tx} \u00b7 ToA = P{Tx}(R\u2090\u00b2 + S{p})/DR. where the uplink transmission time, known as the time-on-air (ToA), depends on the various data rate (DR) under different SF and can be estimated by ToA = (S + S{p})/DR for sending a payload size of S with a fixed preamble S{p}. The downlink energy cost is estimated as E{Rx} = P{Rx} T{Rx}, the product of the downlink power and the downlink window length. Additionally, E{pre}, E{sleep}, and E{inf} are for energy usage during preprocessing, sleep period, and inference, respectively, and can be considered as constants in ORCA. Moreover, to formulate the optimization problem, we define the one-hot encoded resolution selection vector x for resolution R\u2090 and the pre-estimated accuracy vector a for accuracy under different R\u2090 values. To complete a round of cloud assistance within a single power cycle, the model ensures E{pre} + E{Tx} + E{sleep} + E{Rx} + E{inf} \u2264 E{cap}. We define the following optimization problem, finding the optimal resolution selection vector x to maximize the accuracy under energy constraints:\nmax a\u1d40x s.t. E{Tx}(x) + E{pre} + E{sleep} + E{Rx} + E{inf} \u2264 E{cap}\n\u2211x = 1, x\u1d62 \u2208 {0, 1}\nThe optimal resolution selection is derived by R\u2090 = argmax(x), and, specifically, we define R\u2090 = 0 as local bypassing without cloud assistance. In practice, since the optimization search space is small (as R\u2090 is chosen from only a few options) and the capacitor is pre-selected to ensure enough budget for at least local inference without cloud assistance, we simply iterate through all feasible solutions within the energy budget and select the one with the highest estimated accuracy."}, {"title": "4.5.3 Workflow", "content": "The workflow is presented in Figure 8. Starting with the communication parameters in the yellow block, we use the energy storage E{cap} and communication parameter recommendations from the previous round as the budget and cost inputs, respectively. These inputs are applied to the optimization problem, where the edge device determines the optimal R\u2090 for maximum assistance accuracy and then uploads the low-resolution spectrogram. The server extracts and transmits the attention masks along with the ADR in the downlink back to the edge device. The edge device verifies downlink message validity using the CRC error check or by missing packets after a downlink timeout, treating invalid messages as such. If valid, the edge device proceeds with the multi-resolution inference step as described in Section 4.4. Otherwise, due to resource constraints, the device bypasses retransmission and cloud assistance, performing single-resolution on-device inference as also detailed in Section 4.4. Overall, ORCA using fixed energy budgets and dynamic data size offers two major advantages. First, unlike reconfigurable energy storage solutions, which require additional hardware and may face durability or read-write cycle limitations [5, 8, 29], our strategy does not require extra hardware. Second, our algorithm intelligently balances communication costs and accuracy gains by adaptively selecting the amount of resources for cloud assistance. As shown in Figure 9: (i) when communication cost is low, the edge device sends a high-resolution spectrogram for better inference accuracy; (ii) when communication cost is high, it sends a low-resolution spectrogram with a smaller payload to manage energy cost, resulting in lower accuracy; (iii) if communication is unstable with packet loss, the device bypasses cloud assistance and performs local inference to avoid costly retransmissions."}, {"title": "5 Algorithm Evaluation", "content": "In this section, we assess the effectiveness of ORCA's sub-spectral feature selection algorithm for environmental sound classification using public datasets."}, {"title": "5.1 Experimental Setup", "content": "Datasets and Model. We evaluate ORCA's model architecture using several public environmental sound datasets, including ESC10 [37], ESC-nature, ESC-animal, the subsets of ESC50 [37], US8k [45], and DESED [53]. The multi-resolution spectral encoding CNN model as discussed in Section 4.4 includes two convolutional layers for each of the low-resolution and high-resolution encoders, and a multi-resolution classifier consisting of two convolutional layers followed by one fully-connected layer.\nBaselines. We compare ORCA's attention-based subspectral feature selection strategy with the following state-of-the-art audio feature selection baselines:"}, {"title": "5.2 Comparisons to the State-of-the-art", "content": "Figure 10 presents the comparisons for baseline methods and ORCA over five datasets with K = 12.5%, 25%, 37.5%, and 50%, as we observe negligible accuracy difference from the high-resolution baseline at K = 50% and higher. ORCA achieves accuracy closest to the high-resolution baseline, outperforming other efficient baseline methods at each K value. Under extreme resource constraints at K = 12.5%, ORCA shows only a 2-5 percentage point (p.p.) accuracy drop compared to the high-resolution baseline, surpassing other baselines by up to 20 p.p. As K increases, ORCA's accuracy approaches the high-resolution baseline while remaining significantly above other designs. At K = 50%, ORCA's accuracy degradation is just 0.2-2.5 p.p., consistently outperforming other efficient baselines by 2.5-12.5 p.p., demonstrating the effectiveness of ORCA. A key difference between ORCA multi-resolution design and single-resolution methods is in handling less informative regions. Single-resolution methods like SEDAC [3] and SubSpectralNet [35] discard these regions entirely. In contrast, our results show that simpler processing of less informative regions, alongside sophisticated processing of the most informative ones, yields superior performance with minimal overhead."}, {"title": "5.3 Ablation Study", "content": "In this section", "values": "inference resolution (R\u2097 and R{h"}, "and assistance resolution (R\u2090) as discussed in Section 4. In ORCA, the selection of R\u2097 and R{h} is pre-defined based on the developer's choices and hardware capabilities. On the other hand, the assistance resolution R\u2090 represents the resolution of the low-resolution spectrogram sent to the server for attention mask generation and determines the cost of communication. This parameter is dynamically adjusted in ORCA system based on communication quality as mentioned in Section 4.5.\nEffects of Inference Resolution (R\u2097 and R{h}): Figure 11 presents the accuracy of various multi-resolution configurations for on-device inference. Single-resolution setups are used for comparison purposes and indicated by the spectrogram dimensions (e.g., 8, 16, 64). Multi-resolution setups are denoted by a combination of R\u2097 and R{h}, separated by a plus symbol (e.g., 16+64 for R\u2097 = 16 and R{h} = 64). The results demonstrate that both R\u2097 and R{h} influence the classification accuracy. For example, 16+64 outperforms 8+64 due to the lower low-resolution dimension, while 8+64 outperforms 8+32 due to the lower high-resolution dimension. Overall, our experiments show a relationship between inference resolutions and accuracy. Higher resolutions demonstrate superior performances while requiring more computational resources. On the opposite, lower resolutions show degraded accuracy while being budget-friendly.\nEffects of Assistance Resolution (R\u2090): Figure 12 presents how the assistance resolution R\u2090 influences the classification accuracy. The number represents R\u2090, and \"local-only\" is for local on-device inference only without cloud assistance. Our results demonstrate"]}