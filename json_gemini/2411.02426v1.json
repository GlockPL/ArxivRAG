{"title": "Diagnostic Performance of Deep Learning for Predicting Gliomas' IDH and 1p/19q Status in MRI: A Systematic Review and Meta-Analysis", "authors": ["Somayeh Farahani", "Marjaneh Hejazi", "Mehnaz Tabassum", "Antonio Di Ieva", "Neda Mahdavifar", "Sidong Liu"], "abstract": "Gliomas, the most common primary brain tumors, show high heterogeneity in histological and molecular characteristics. Accurate molecular profiling, like isocitrate dehydrogenase (IDH) mutation and 1p/19q codeletion, is critical for diagnosis, treatment, and prognosis. This review evaluates MRI-based deep learning (DL) models' efficacy in predicting these biomarkers. Following PRISMA guidelines, we systematically searched major databases (PubMed, Scopus, Ovid, and Web of Science) up to February 2024, screening studies that utilized DL to predict IDH and 1p/19q codeletion status from MRI data of glioma patients. We assessed the quality and risk of bias using the radiomics quality score and QUADAS-2 tool. Our meta-analysis used a bivariate model to compute pooled sensitivity, specificity, and meta-regression to assess inter- study heterogeneity. Of the 565 articles, 57 were selected for qualitative synthesis, and 52 underwent meta-analysis. The pooled estimates showed high diagnostic performance, with validation sensitivity, specificity, and area under the curve (AUC) of 0.84 [prediction interval (PI): 0.67-0.93, I\u00b2=51.10%, p < 0.05], 0.87 [PI: 0.49-0.98, I\u00b2=82.30%, p < 0.05], and 0.89 for IDH prediction, and 0.76 [PI: 0.28-0.96, I\u00b2=77.60%, p < 0.05], 0.85 [PI: 0.49-0.97, I\u00b2=80.30%, p < 0.05], and 0.90 for 1p/19q prediction, respectively. Meta-regression analyses revealed significant heterogeneity influenced by glioma grade, data source, inclusion of non-radiomics data, MRI sequences, segmentation and feature extraction methods, and validation techniques. DL models demonstrate strong potential in predicting molecular biomarkers from MRI scans, with significant variability influenced by technical and clinical factors. Thorough external validation is necessary to increase clinical utility.", "sections": [{"title": "Introduction:", "content": "Gliomas, the most common and lethal primary tumors of the central nervous system, display significant histological and molecular variability, emphasizing the importance of accurate diagnosis for effective treatment and prognosis [1]. Key genetic markers, including the isocitrate dehydrogenase (IDH) mutation and 1p/19q codeletion, are crucial for the molecular classification and management of gliomas according to the most recent World Health Organization (WHO) Central Nervous Systems Tumors classification system [2]. Traditional diagnostic methods, such as biopsies, are invasive and often fail to capture the full spectrum of tumor heterogeneity [3]. The foundation of noninvasive glioma diagnostics is magnetic resonance imaging (MRI), supported by the European Association of Neuro-Oncology (EANO) 2021 guidelines due to its ability to delineate tumor characteristics [4]. However, interpreting MRI data can be challenging due to human limitations and radiological \"mimics,\" which make it hard to distinguish gliomas from conditions like inflammatory diseases, stroke, and infections [5].\nAdvancements in radiomics have begun to address these challenges by extracting intricate features from medical images to enhance diagnostic precision [6]. Radiomics analysis contains two primary methodologies: feature-engineered and deep learning (DL) radiomics modeling [7]. The former involves processes such as image segmentation, feature extraction, and statistical analysis, each step significantly influencing subsequent outcomes, particularly noticeable in MRI models [8]. Concerns regarding the reliability of manually segmented, handcrafted features have spurred the integration of DL into radiomics. This fusion encompasses end-to-end DL for direct classification and pre-trained models for feature extraction, addressing common data limitations in medical imaging [7, 9].\nSince the introduction of DL into radiomics, numerous studies have aimed to enhance the performance of genotyping gliomas by predicting IDH and 1p/19q codeletion [10\u201312]. Given extensive research, there is a critical need for a systematic review to synthesize and quantify existing data thoroughly. Current reviews often focus on conventional radiomics, primarily analyzing IDH mutations with machine learning methods. Additionally, some works concentrate solely on specific glioma grades or particular MRI modalities (e.g., dynamic susceptibility contrast (DSC) MR perfusion imaging and T2-FLAIR mismatch) for predicting either IDH mutation or 1p/19q codeletion, often neglecting the simultaneous prediction of these biomarkers across various glioma grades and imaging techniques [13\u201317]. More importantly,"}, {"title": "Methods", "content": "This study includes a systematic literature review and meta-analysis following the Preferred Reporting Items for Systematic Reviews and Meta-analysis (PRISMA) guidelines. Ethical approval was unnecessary due to the nature of the study [18]. This study is registered on PROSPERO, number CRD42024542505."}, {"title": "Search Strategy and Study Selection", "content": "We systematically searched the PubMed, Scopus, Ovid, and Web of Science databases for radiogenomics studies applied to glioma, covering the past decade up to February 27, 2024 (Supplementary, Section 1). We also screened relevant article bibliographies for further identification. Inclusion criteria were studies involving glioma of any WHO grade, prediction of IDH and/or 1p/19q codeletion status using MRI sequences, application of DL algorithms in radiomics workflow, availability of data for a 2 \u00d7 2 diagnostic table, and publication in English. Exclusion criteria were non-original research types and non-human studies. Records were managed using Zotero software (version 6.0.36). Two reviewers (S.F., M.T.) independently screened abstracts and full texts in two rounds, resolving disagreements through discussion."}, {"title": "Data Extraction", "content": "Two reviewers (S.F. and M.T.) independently collected data on study design, patient characteristics, datasets used, MRI sequences, data augmentation techniques, and computational methodologies using a standardized form (Supplementary, Section 2). Performance metrics, including the diagnostic confusion matrix, were obtained from training and training and validation datasets (data not previously exposed to the model, such as held-out test sets or external cohorts).\nMissing values were addressed by first contacting corresponding authors; if there was no response, metrics were computed using the reported metrics and patient counts for altered and"}, {"title": "Quality Assessment", "content": "The risk of bias and applicability concerns were evaluated using a modified QUADAS-2 tool [19], incorporating relevant items from the Checklist for Artificial Intelligence in Medical Imaging (CLAIM) and the radiomics quality score (RQS). Key considerations included clarity in imaging protocols, appropriate data selection and missing data handling, use of reliable reference standards, and avoidance of severe genotype imbalances. Additionally, the index test evaluation assessed the use of multiple segmentations and the robustness of model predictions. Concerns about applicability, particularly regarding validation on unseen sets, were addressed to ensure generalizability across diverse clinical settings. If data was insufficient, we contacted authors for clarification via email. Moreover, the methodologies, strengths, limitations, quality, and translatability of studies were evaluated using RQS, assessing each study on 16 components, with cumulative scores ranging from -8 to 36 [20]. Three reviewers (S.F. and N.M. for QUADAS-2 and S.F. and M.T. for RQS) independently conducted assessments, resolving discrepancies through discussion (Supplementary, Sections 3 and 4)."}, {"title": "Statistical Analysis", "content": "The meta-analysis was meticulously conducted, quantifying the deep learning model's performance in classifying abnormalities in molecular markers, with statistical significance set at p < 0.05. A bivariate random-effects model pooled sensitivity, specificity, and 95% confidence intervals across studies (\u22655), and SROC curves. Heterogeneity was evaluated using Cochran's Q test, I\u00b2 statistic, prediction intervals, and SCC between sensitivity and FPR (threshold effect indicated by SCC >0.6) [21, 22]. Subgroup analyses explored sources of heterogeneity based on tumor grade, the inclusion of clinical information, data augmentation, data source (single or multi-center), image segmentation methods, DL models, the level of DL integration in the radiomics pipeline, the use of pretrained models, MRI sequences, and validation methods in instances with enough studies [23]."}, {"title": "Results", "content": "Leave-one-out meta-analysis assessed each study's impact on the overall effect size. Publication bias was estimated using funnel plot and Egger's test. We also calculated the statistical power of the included studies across a range of effect sizes, which is crucial for detecting true effects and assessing the robustness of our results [24]. Statistical analyses were conducted using R packages 'mada', 'dmetar,' \u2018metameta\u201d, and \u2018metafor' (R Stats v4.4.1) and the MetaBayesDTA web application (version 1.5.2).[25]"}, {"title": "Study Characteristics", "content": "Five hundred sixty-five unique articles were initially identified through primary searches and relevant study bibliographies. Following screening and full-text reviews, 57 studies were eligible for qualitative analysis, of which 52 were included in the meta-analysis (Figure 1). One study [26] was excluded as it served solely for external validation of another study [27].\nOur analysis revealed that China and the USA dominate global research in this field, significantly outpacing other countries' publication volume (Figure 2A). Additionally, surveyed studies spanned various sample sizes, ranging from 42 to 2648 patients.\nIn our qualitative analysis, we identified three primary imaging data sources: private (in-house), public datasets, and a hybrid of both (Figure 2B). In-house collections accounted for 31.57% of the data, while 29.82% relied solely on public datasets, mainly The Cancer Imaging Archive (TCIA). Approximately 38.59% of the studies combined both sources for enhanced research robustness and data diversity. Among these, 63.15% utilized data augmentation techniques- either conventional methods or Generative Adversarial Networks (GANs)\u2014to mitigate overfitting or address imbalanced genotype classes.\nThe extensive use of public datasets influenced MRI sequence choices, with conventional methods employed in 82.45% of studies. The combination of T1, T1CE, T2, and T2-FLAIR sequences was most prevalent, accounting for more than one-third of cases. Advanced techniques such as diffusion and perfusion-weighted imaging were less common, found in 5.26% of studies individually or 12.28% in combination with other sequences. Notably, T2- FLAIR was the most utilized sequence, appearing in 17.54% of studies with one sequence and 49.12% with four sequences (Figures 2C and 2D)."}, {"title": "Convolutional Neural Networks (CNNs)", "content": "Convolutional Neural Networks (CNNs) led tumor segmentation, comprising 57.89% of studies. Manual and semi-automatic methods were also employed, while some articles did not specify or undertake segmentation (Figure 2E). Feature extraction relied heavily on CNN-based models like AlexNet, DenseNet, and EfficientNet, employed in over two-thirds of the studies. Transformers and hybrid CNN-radiomics models followed, each appearing in about 8% of cases. Less common approaches included hybrid DL models, autoencoders, and recurrent neural networks (RNNs).\nOur review shows a rise in influential DL-radiogenomics research since 2017. Initially, CNNs dominated exclusively, making up 100% of methodologies in 2017-2018. However, diversification has since increased. By 2020, CNNs still led at 50%, with Autoencoders and RNNs emerging as alternative models. Transformers and attention mechanisms, introduced in recent years, peaked at 25% in 2024 (Figure 2G), signaling a shift to more complex architectures. These networks were integrated into radiomic workflows primarily in an end-to- end manner, while a smaller portion employed DL solely for deep feature extraction. Among the latter, many used the Random Forest method for molecular marker classification.\nIn some cases, DL was used, particularly for tumor segmentation or image preprocessing in the radiomics pipeline. Pre-trained models, predominantly based on ImageNet, were employed in approximately 73% of studies. Additionally, clinical parameters, primarily age and sex, were incorporated into half of the studies.\nIn model development and evaluation, 35 studies conducted external validation, while 38.60% did not. Additionally, 36.84% relied solely on internal validation, whereas 29 studies utilized both internal and external methods. Exclusive external validation was less prevalent, observed in only 6 studies. Figure 2F illustrates the techniques utilized, emphasizing the predominance of K-fold cross-validation."}, {"title": "Quality Assessment", "content": "According to the QUADAS-2, the overall risk of bias was high in 11 studies and low in 46 studies, mainly due to limited segmentation methods or the lack of resampling techniques to mitigate overfitting. Additionally, 11 studies raised applicability concerns due to lack of validation on unseen dataset (Supplementary, Section 3)."}, {"title": "Publication Bias and Statistical Power", "content": "Publication bias was absent, as indicated by the funnel plot and confirmed by Egger's test for both IDH (p = 0.65) and 1p/19q codeletion (p = 1.49) studies across the training and validation cohorts (Supplementary, Section 6). The statistical power analysis revealed a high detection capability for larger effect sizes in our included studies but relatively lower power for detecting smaller sensitivity and specificity measures (< 0.3) in some studies (Supplementary, section 10)."}, {"title": "IDH mutation", "content": "Most models primarily targeted IDH mutation, either alone in 68% or alongside 1p/19q prediction in 26% of studies. Over half of the research focused on Grades 2, 3, and 4 gliomas. Specifically, Grade 4 gliomas were exclusively studied in 14% of experiments, while Grade 2 gliomas were addressed in just two studies [10, 29]. In the meta-analysis, 40 studies utilized DL for feature extraction, 7 for tumor segmentation, and 1 for image processing.\nIn both training and validation cohorts (Figures 3A and 3B), IDH prediction showed no significant difference between sensitivity and specificity, with Spearman correlation coefficients (SCCs) of 0.02 (95% CI: -0.36 to 0.40) and 0.09 (95% CI: -0.22 to 0.38), respectively. In the training group, pooled sensitivity and specificity were 0.86 and 0.89, respectively, with notable heterogeneity (p = 0.00, I\u00b2 = 68.90%-66.70%). The prediction interval ranges from 0.62 to 0.96 for sensitivity and 0.75 to 0.96 for specificity, indicating that the true effect sizes in 95% of similar populations fall within these ranges. Validation diagnostic performance for IDH prediction also showed significant sensitivity and specificity heterogeneity"}, {"title": "Deep Feature Extraction Models", "content": "Table 2 details the training and validation diagnostic performance for deep feature extraction experiments. Given the significant heterogeneity across the studies, we analyzed the impact of various covariates where sufficient studies existed.\nMeta-regression analysis of the training cohorts revealed varied sensitivity and specificity across subgroups (Table 3). Studies targeting both high- and low-grade gliomas (HGG and LGG) generally achieved higher sensitivity than those focusing solely on HGG. In-house (single-center) datasets showed high sensitivity and specificity, whereas in-house (multi-center) datasets had lower sensitivity. Public data sources, particularly TCGA, demonstrated consistently high predictive performance, either alone or combined with in-house datasets. Transformers and attention-based DL models exhibited superior specificity compared to other approaches. End-to-end DL models for direct classification also achieved higher specificity than DL used solely for feature extraction in radiomics workflows. Models incorporating conventional MRI sequences showed improved sensitivity over advanced techniques. Validation methods played a significant role in specificity, with models validated both internally and externally showing higher specificity than those validated internally only.\nIn the validation cohorts, glioma grade contributed to heterogeneity, with HGG models showing lower sensitivity compared to combined LGG and HGG models. Consistent with training diagnostic performance, public datasets consistently achieved the highest specificity. DL and semi-automatic-based segmentation outperformed manual and non-segmentation models. Combining CNNs with radiomics did not improve estimates over CNNs alone. Models using DL in an end-to-end approach performed better than those using DL for feature extraction only. Multiple MRI sequences, especially four sequences, showed higher sensitivity and specificity."}, {"title": "DL Exclusively for Tumor Segmentation", "content": "Some studies reported separate performance metrics for DL and conventional radiomics features. Including these and those focused solely on DL for tumor segmentation, eight experiments reported training performance (pooled sensitivity: 0.83, specificity: 0.86), and seven provided validation metrics (pooled sensitivity: 0.77, specificity: 0.76) (Table 2). Subgroup analyses were not conducted due to the limited number of experiments."}, {"title": "1p/19q Codeletion", "content": "Approximately 5% of studies focused only on 1p/19q codeletion, while 26% addressed both 1p/19q codeletion and IDH prediction, mainly in Grades 2-4 gliomas. The prediction performance of 1p/19q codeletion in training and validation cohorts (Figures 3C and 3D) showed no significant threshold between sensitivity and specificity, with SCCs of 0.03 (95% CI: -0.43 to 0.77) and 0.11 (95% CI: -0.20 to 0.40), respectively. Deep feature studies reported varied pooled sensitivity and specificity across nine experiments, indicating notable heterogeneity. Performance was lower in eleven studies using unseen datasets (Table 2). One study exclusively used DL for image segmentation [41]. Significant between-study heterogeneity is evident in the SROC curves (Figures 4C and 4D), indicated by non-overlapping 95% confidence and prediction regions. However, conducting meta-regression analyses was not feasible due to the limited number of studies.\nA sensitivity analysis identified one outlier [31] in the validation cohorts. Excluding this study resulted in a sensitivity of 0.78 (95% CI, 0.68-0.86) and a specificity of 0.83 (95% CI, 0.75- 0.88). No outliers were found in the training cohorts for sensitivity, but one [32] was identified for specificity (Supplementary, Section 5)."}, {"title": "IDH and 1p/19q Codeletion", "content": "Three experiments[38, 42, 43] aimed to predict IDH mutation and 1p/19q codeletion status simultaneously, but only one study [42] reported sufficient predictive performance. These studies extracted CNN-based features from conventional and advanced MRI scans."}, {"title": "Discussion", "content": "Our systematic review and meta-analysis critically evaluated the diagnostic performance of MRI-based DL models for predicting IDH mutation and 1p/19q codeletion in glioma patients, utilizing data from multiple studies over the past decade. Pooled validation sensitivity and specificity for IDH mutation prediction were 0.84 and 0.87, respectively, and for 1p/19q codeletion prediction, they were 0.76 and 0.85, consistent with prior research [17, 44, 45]. These results demonstrate high diagnostic performance and reliability but also reflect significant heterogeneity in model performance, highlighting the challenges of applying DL in medical imaging.\nIn studies targeting IDH prediction across Grades 2, 3, and 4 gliomas collectively, models demonstrated superior predictive performance, while those focusing solely on Grade 4 gliomas showed weaker performance, aligning with previous findings [17, 44]. The disparities in diagnostic accuracy across different glioma grades suggest that tumor grade may influence model effectiveness.\nDL-based segmentation studies showed higher sensitivity and lower heterogeneity compared to manual tumor delineation or studies lacking segmentation. This suggests that segmentation methods may impact predictive accuracy. Semi-automatic methods showed promise, indicating that combining human oversight with automated processes might achieve high accuracy.\nStudies using DL in an end-to-end approach outperformed those utilizing DL solely for feature extraction in radiomics workflows. This direct method minimizes potential errors, enhances reproducibility, and improves predictive accuracy. Previous studies indicate that DL, particularly CNNs, bypasses traditional complexities associated with radiomic workflows, leading to more robust feature extraction [27, 46]. However, our analysis demonstrated that hybrid models combining CNN-based and radiomics features did not improve performance over CNN features alone. In contrast, DL models integrating diverse algorithms, such as hybrid CNN-Transformer encoders, achieved the highest sensitivity, followed by Transformers and attention-based models. Nevertheless, the limited data in specific subgroups may affect the reliability of these results.\nContrary to prior research [17], integrating clinical data did not significantly enhance model performance in both training and validation sets. This could be due to differences in model"}, {"title": "", "content": "implementation, demographic and clinical diversity among populations, small sample sizes, and inadequate control for confounding variables. Our findings diverge from the earlier study on data augmentation [44], which also showed no notable impact on prediction accuracy. This discrepancy could stem from overrepresenting studies using data augmentation compared to those without, emphasizing the need for more balanced research designs to accurately evaluate augmentation's true effects on model performance. Furthermore, the efficacy of augmentation varies, possibly due to the use of classical methods like random rotation, translation, and Gaussian noise in some studies and DL techniques like GANs in others. Similarly, subgroup analysis comparing pre-trained and non-pre-trained models showed no significant differences in predictive performance.\nThe data source appears to significantly impact performance in IDH experiments, with models trained and validated on the same dataset achieving a higher pooled sensitivity than multi-center datasets. Single-center datasets, with consistent protocols, offer more uniform data quality. In contrast, while advantageous for generalizability and larger, diverse patient populations, multi- center and public datasets introduce more significant variability in data quality and imaging characteristics, complicating model training and potentially reducing predictive performance.\nIn examining MRI sequences' influence on predictive models, distinct patterns emerge. More sequences generally lead to higher predictive performance [45], suggesting that model performance might improve with comprehensive imaging inputs. Consistent with the prior study [44], while conventional MRI techniques exhibited lower pooled sensitivity compared to advanced methods in the validation set, their combination with advanced sequences yielded optimal diagnostic performance in both training and validation groups.\nFinally, experiments incorporating both internal and external validation methods exhibited higher sensitivity and specificity compared to models internally validated only, suggesting that a robust approach to validation can not only improve model generalizability but also enhance predictive performance.\nOne significant limitation of current studies is their predominant focus on the IDH1 mutation (R132H), with less attention given to other variants, including IDH2 mutations. Although IDH1 mutations are more prevalent, precisely identifying all potential mutations is essential for advancing precision medicine. IDH2 mutations produce the oncometabolite 2-hydroxyglutarate (2-HG), which impacts cellular metabolism and epigenetic regulation, contributing to"}, {"title": "", "content": "tumorigenesis. Gliomas with IDH mutations, including IDH2, typically exhibit better prognoses and more favorable responses to therapy compared to wild-type IDH tumors. However, these mutated gliomas are more likely to undergo malignant transformation and develop a hypermutation phenotype, which can negatively impact prognosis [47, 48]. As radiogenomics evolves, incorporating detailed mutation profiles will be essential in refining AI models, enhancing their clinical applicability, and aligning them with the precision medicine paradigm.\nPerforming statistical power analysis for studies included in a meta-analysis is crucial to ensure the reliability and validity of the results. Statistical power measures the probability of detecting an effect if it exists. Including adequately powered studies minimizes the risk of missing true effects and reduces the influence of exaggerated effect sizes, which enhances the overall credibility of the meta-analysis. By evaluating power across a range of effect sizes, researchers can better assess the robustness of their findings and ensure meaningful clinical conclusions [24]. Our analysis shows that while some studies have low power for small changes (e.g., 0.1), most have high power for larger changes (near or above 80%), indicating robust detection capabilities despite heterogeneity. Overall, the studies were sufficiently powered to detect pooled estimates.\nThe quality assessments in our systematic review revealed several areas for improvement and current limitations in the field. The median RQS score of 16 (36 %) indicates moderate methodological quality, with deficiencies across several domains. Many studies detailed image protocols but often lacked multiple time points or phantom studies, reducing reproducibility. Despite good dataset validation performance, the absence of decision curve analysis limits clinical utility insights. Additionally, the lack of prospective validation and cost-effectiveness analyses suggests that these models are not yet ready for clinical implementation. Low scores for open science practices highlight the need for greater transparency and data sharing in future research.[46] We tailored the QUADAS-2 tool by adding questions about multiple segmentation and validation on unseen datasets, contributing to the high risk of bias identified in many studies. This underscores a critical barrier to these models' generalizability and clinical translation.\nThis systematic review has several limitations. We focused on top-performing DL models and categorized them broadly due to a scarcity of articles. Nevertheless, we considered variations like including clinical data, radiomic features, or different MRI sequences within a single study as separate experiments for more detailed analysis. Our meta-regression analysis managed to address some of the heterogeneity but could not account for all observed discrepancies."}, {"title": "", "content": "However, these findings are observational rather than causal because randomization did not occur between studies, which is typical in most meta-analyses [21]. There may be other confounding variables influencing these results. This is particularly relevant given some subgroup's relatively small number of studies. Moreover, assessing the methodological quality of some studies was challenging due to poor reporting, although the use of the tailored QUADAS-2 tool and RQS facilitated a more comprehensive evaluation. Lastly, our review did not include gray literature or non-English publications despite extending our search to four major databases without detecting publication bias for IDH and 1p/19q codeletion studies.\nIn conclusion, our review highlights the substantial promise of MRI-based deep learning models in accurately predicting IDH and 1p/19q codeletion in glioma patients. Our comprehensive analysis identifies critical areas for optimizing model performance, potentially guiding future advancements in this field. Variations in MRI protocols and image quality across institutions can impact the models' reproducibility and generalizability, affecting their performance in diverse clinical settings, as shown in our work. The scarcity of large, well-annotated datasets representing a broad patient demographic also limits the effectiveness of these models. Furthermore, integrating these models into clinical workflows presents regulatory and logistical challenges, necessitating clear model validation and demonstration of clinical utility to gain the trust of healthcare professionals [49]. Overcoming these barriers requires collaboration among data scientists, radiologists, oncologists, and regulatory bodies to standardize protocols, enhance model transparency, and ensure rigorous validation."}, {"title": "Funding:", "content": "This study did not receive any funding or financial support."}, {"title": "Conflict of interest:", "content": "The authors declare that they have no conflict of interest."}, {"title": "Declaration of generative AI and AI-assisted technologies in the writing process", "content": "During the preparation of this work the author used grammarly in order to improve language and readability. After using this tool, the authors reviewed and edited the content as needed and take full responsibility for the content of the publication."}]}