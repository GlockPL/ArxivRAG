{"title": "Uncovering cognitive taskonomy through transfer learning in masked autoencoder-based fMRI reconstruction", "authors": ["Youzhi Qu", "Junfeng Xia", "Xinyao Jian", "Wendu Li", "Kaining Peng", "Zhichao Liang", "Haiyan Wu", "Quanying Liu"], "abstract": "Data reconstruction is a widely used pre-training task to learn the generalized features for many downstream tasks. Although reconstruction tasks have been applied to neural signal completion and de-noising, neural signal reconstruction is less studied. Here, we employ the masked autoencoder (MAE) model to reconstruct functional magnetic resonance imaging (fMRI) data, and utilize a transfer learning framework to obtain the cognitive taskonomy, a matrix to quantify the similarity between cognitive tasks. Our experimental results demonstrate that the MAE model effectively captures the temporal dynamics patterns and interactions within the brain regions, enabling robust cross-subject fMRI signal reconstruction. The cognitive taskonomy derived from the transfer learning framework reveals the relationships among cognitive tasks, highlighting subtask correlations within motor tasks and similarities be-tween emotion, social, and gambling tasks. Our study suggests that the fMRI reconstruction with MAE model can uncover the latent representation and the obtained taskonomy offers guidance for selecting source tasks in neural decoding tasks for improving the decoding performance on target tasks.", "sections": [{"title": "1 Introduction", "content": "In computer vision and natural language processing, reconstruction tasks serve as effective pre-training methods, guiding models to learn generalized features and achieving favorable performance on downstream tasks [7,16]. In computer vision, reconstruction tasks are widely applied in image inpainting, denoising, and super-resolution [26,28,29]. In natural language processing, reconstruction tasks can improve the accuracy and fluency of translation, and enhance the com-pleteness and creativity of content generation [3,4]. As pre-training tasks, recon-struction tasks enhance the models' ability to represent data by training them to reconstruct missing information. This capability not only enhances model per-formance on reconstruction tasks but also boosts performance on downstream tasks such as image classification, semantic understanding, and sentiment anal-ysis. Classification tasks within neural decoding have demonstrated outstanding performance in neuroscience [18,33,35]. Nonetheless, the exploration of neural signal reconstruction remains nascent.\nIn the field of neuroscience, the reconstruction of neural signals is critically important, especially in signal completion and denoising [32]. Electroencephalo-gram (EEG) and functional magnetic resonance imaging (fMRI) studies are fre-quently disrupted by signal loss or noise, originating from equipment defects, poor electrode contact, and physiological activities [5,39]. Masked reconstruc-tion pre-training methods have achieved remarkable achievements in computer vision and natural language processing, demonstrating potential in neural signal reconstruction [7,16]. In natural language processing, bidirectional encoder rep-resentations from transformers (BERT) employ a masking strategy during pre-training tasks such as language modeling and next sentence prediction, enabling the model to acquire more profound and comprehensive language features [7]. The masking strategy involves randomly masking words in the input sequence, forcing the model to focus on all potential word combinations within the context. The masked autoencoder (MAE) model masks random patches of input images and reconstructs them to learn the latent representation of the image [16,30], after the vision transformer (ViT) model addressed issues related to mask to-kens and positional embeddings [9]. The MAE has not only achieved outstanding results in image reconstruction but has also been extended to multimedia ap-plications such as audio and video [10,17]. This study proposes applying the MAE model to reconstruct resting-state and task-based fMRI, which is trained by randomly masking temporal and spatial dimensions within the fMRI data.\nThe brain demonstrates exceptional capabilities, notably the ability to gener-alize learned knowledge to new tasks and to handle multiple tasks efficiently [11,12]. Understanding the relationships among cognitive tasks is essential for compre-hending how the brain processes and coordinates cognitive functions. Relation-ships exist not only among cognitive tasks but also among various tasks processed by deep learning models. The effectiveness of transfer learning is influenced by the relationships between tasks. Transfer learning can enhance performance on target tasks by transferring knowledge from source tasks. The closer the rela-tionship between the tasks, the better the results of transfer learning tend to be [22,36]. Researchers quantify the relationships among computer vision tasks by analyzing the changes in performance of transfer learning [37]. The cognitive taskonomy not only deepens our understanding of the relationships among tasks"}, {"title": "2 Method", "content": ""}, {"title": "2.1 HCP Dataset", "content": "In this study, the fMRI data utilized were obtained from the public large-scale Human Connectome Project (HCP) S1200 dataset [27]. The fMRI data uti-lized in this study comprises resting-state and task-based fMRI data from 1,000 healthy participants. These fMRI data were preprocessed using the standard HCP pipeline [14], and then parcellated into 360 brain regions based on the multi-modal parcellation (MMP) atlas [13]. The brain regions were divided into 7 networks according to the Yeo-7 network, including the visual network (VIS), somatomotor network (SOM), dorsal attention network (DAN), ventral atten-tion network (VAN), limbic network (LIM), frontoparietal network (FPN), and default mode network (DMN) [34].\nThe task-based fMRI data from the HCP comprises seven categories of cog-nitive tasks: working memory, motor, emotion processing, gambling, language processing, relational processing, and social cognition. These categories are sub-divided into 23 subtasks, utilized by the MAE model for task-based fMRI re-construction. The working memory task requires participants to memorize and recognize a series of images, divided into eight subtasks based on target cate-gories (body, faces, places, tools) and recall steps (0-back, 2-back): 0bk body, Obk faces, Obk places, Obk tools, 2bk body, 2bk faces, 2bk places, and 2bk tools. The motor task elicits simple bodily responses through visual cues, divided into five subtasks based on the body parts involved: left foot, right foot, left hand, right hand, and tongue. The emotion processing task, which assesses the ability to recognize emotions, is divided into two subtasks: fear and neutral. The gam-bling task examines decision-making and risk assessment through a simulated card game and includes two subtasks: win and loss. The language processing task involves auditory comprehension and language reasoning, and is divided into two subtasks: math and story. The relational processing task tests logical reasoning by comparing the shapes and textures of objects and comprises two"}, {"title": "2.2 A Masked fMRI Modeling Framework", "content": "Inspired by the MAE and SIMM models [16,30], we propose a masked fMRI re-construction model that incorporates masking strategies, patch embedding with position encoding, an encoder, and a decoder. The encoder of this model initially maps the masked fMRI signals to a latent representation space, followed by the decoder, which reconstructs fMRI signals based on latent representations. In this study, we utilized three masking strategies: brain masking, time masking, and a brain and time masking, as illustrated in Fig.1. In brain masking, signals from brain regions are masked throughout the entire fMRI time series. In time mask-ing, the signal at the masked time points across all brain regions is masked. The brain and time masking randomly mask both dimensions to learn the temporal dynamic patterns of brain activity and the interactions within the brain regions for the MAE model.\nThe preprocessed fMRI data were initially divided into patches and masked accordingly. Unlike MAE, which encodes only the unmasked patches, our ap-proach, similar to simMIM [30], encodes all patches using 1D convolutional neu-ral network. After the patch embedding process, the encoded patches were given sinusoidal positional encoding. The encoder is an 8-layer transformer encoder structure that processes the input data. The decoder, which is a 6-layer trans-former decoder structure, applies layer normalization and performs a linear pro-jection to reconstruct the fMRI data. The model utilizes mean squared error (MSE) as the loss function to evaluate the difference between the reconstructed data and the original data, with optimization of model parameters occurring through backpropagation."}, {"title": "2.3 Transfer learning", "content": "The fMRI reconstruction model trained on each cognitive subtask serves as the gold standard for the source tasks. When transferring the source task to the target task, the encoder parameters of the gold standard model were fixed, and the decoder was fine-tuned using 1% of the target task data. To construct the cognitive task relationship matrix (cognitive taskonomy), we conducted transfer experiments among the 23 cognitive tasks. Each cognitive subtask was used as a source task and transferred to the other 22 tasks, forming a 23 \u00d7 23 matrix. The elements (i, j) represented the transfer from source task i to target task j. The value for each matrix element was defined as the MSE of the transferred model minus the MSE of the gold standard model (trained with 80% of the data). Finally, we applied z-score normalization to each column of the matrix, resulting in the cognitive taskonomy, as shown in Fig.6."}, {"title": "2.4 Experimental setup", "content": "In this study, we comprehensively tested the performance of fMRI reconstruction under different configurations of MAE models. The preprocessed fMRI data were divided into a 2D matrix consisting of 360 brain regions and 20 time frames, ensuring consistent time lengths for both resting-state and task-based fMRI. Specifically, we explored masking ratios of 25%, 50%, and 75%, and evaluated"}, {"title": "3 Results", "content": ""}, {"title": "3.1 Reconstruction of resting-state and task-based fMRI", "content": "To assess the impact of different masking strategies on fMRI reconstruction, we used the Pearson correlation coefficient to evaluate the reconstruction results, as shown in Fig.2. The reconstruction results of the MAE model with varying mask ratios indicate that the model can effectively learn latent features in both spatial and temporal dimensions, achieving high quality fMRI reconstruction. Although increasing the masking ratio usually leads to worse reconstruction performance, the Pearson correlation coefficient of the model reconstruction results still exceeds 0.5 at high mask ratios (e.g., 0.6), demonstrating the model's excellent reconstruction ability. To comprehensively evaluate the impact of different pa-rameter settings on performance, we conducted ablation experiments involving various masking ratios, patch sizes, and hidden sizes, as shown in Table 1. A comparison of different patch sizes showed that smaller patch sizes resulted in lower reconstruction loss. Table 1 shows that encoders and decoders with larger hidden size achieve better reconstruction performance."}, {"title": "3.2 Brain mask and time mask testing", "content": "To comprehensively analyze the differences in reconstruction difficulty among brain regions, we masked each brain region individually and calculated the Pear-son correlation coefficients for the reconstruction results. Fig.3 shows the results of the reconstruction of each brain region and brain networks. The reconstruction"}, {"title": "3.3 Relationships among cognitive tasks", "content": "This study employs a masked fMRI modeling framework with transfer learning to quantify the relationships between cognitive tasks. As illustrated in Fig.1C, the transfer learning process comprises two steps. Initially, the MAE model is trained on masked fMRI data from the source task. After training, the MAE model is transferred to the target task to evaluate the transfer performance. During fine-tuning on the target task, the parameters of the encoder are fixed, while only the parameters of the decoder are updated using 1% of the target task data. Finally, the relationship between tasks is determined by the transfer performance. Better transfer performance indicates a closer relationship between the source and target tasks, whereas poorer performance suggests a more distant relationship.\nFig.6 depicts the transfer results among the 23 cognitive tasks, reflecting the relationships between these tasks. Tasks within the same cognitive category exhibit closer relationships. For instance, the five subtasks within the motor cat-egory demonstrate strong transferability among each other, particularly between the left foot and right foot, and between the left hand and right hand. Further-more, transferability varies across different cognitive tasks. For example, tasks such as math and neutral tasks exhibit effective transferability to other tasks, whereas working memory tasks face challenges in transferring to other tasks.\nFig.7 presents the hierarchical clustering results of cognitive tasks based on the Euclidean distance matrix calculated from reconstruction results between tasks. The results demonstrate that tasks within the same cognitive category are more closely clustered. For instance, the five subtasks in the motor cate-gory are closely clustered, and the random and mental tasks within the social category are in close proximity. Notably, within the working memory category, 0-back places are closer to 0-back tools, and 2-back faces are closer to 2-back bodies. This indicates a stronger relationship between places and tools, as well as between faces and bodies. Fig.7B, Fig. 7C, and Fig. 7D employ various hierarchi-cal clustering strategies, which generally group tasks within the same cognitive category together, further illustrating the close relationships among similar cog-nitive tasks."}, {"title": "4 Discussion", "content": "In the brain masking experiments, it was observed that the reconstruction re-sults for the VIS, DAN, and FPN networks were better. The redundancy and consistency of information within brain networks may account for these differ-ences [19,20]. Information from other related regions that are more consistent with the masked brain region will assist in its reconstruction. Furthermore, some regions within these networks may demonstrate functional specialization in pro-cessing specific tasks, indicating a functional similarity among these regions [38]. This enables related regions to more effectively reconstruct missing information during reconstruction. Conversely, it was found that the LIM network presents more challenges in reconstruction compared to other brain networks. This is"}, {"title": "5 Conclusion", "content": "In this study, we employ the MAE model to reconstruct both resting-state and task-based fMRI signals and utilize a transfer learning framework to quantify the relationships between cognitive tasks. The MAE model effectively captures the temporal dynamics and interactions among brain regions, thereby enabling robust reconstruction of fMRI signals. By utilizing the transfer learning frame-work, we further quantify the relationships between cognitive tasks, revealing subtask correlations within motor tasks and identifying similarities among emo-tion, social, and gambling tasks. This study not only demonstrates the potential"}]}