{"title": "Graph Representation Learning with Diffusion Generative Models", "authors": ["Daniel Wesego"], "abstract": "Diffusion models have established themselves as state-of-the-art generative mod-\nels across various data modalities, including images and videos, due to their ability\nto accurately approximate complex data distributions. Unlike traditional genera-\ntive approaches such as VAEs and GANs, diffusion models employ a progressive\ndenoising process that transforms noise into meaningful data over multiple iter-\native steps. This gradual approach enhances their expressiveness and generation\nquality. Not only that, diffusion models have also been shown to extract mean-\ningful representations from data while learning to generate samples. Despite their\nsuccess, the application of diffusion models to graph-structured data remains rel-\native unexplored, primarily due to the discrete nature of graphs, which neces-\nsitates discrete diffusion processes distinct from the continuous methods used in\nother domains. In this work, we leverage the representational capabilities of dif-\nfusion models to learn meaningful embeddings for graph data. By training a dis-\ncrete diffusion model within an autoencoder framework, we enable both effective\nautoencoding and representation learning tailored to the unique characteristics of\ngraph-structured data. We only need the encoder at the end to extract representa-\ntions. Our approach demonstrates the potential of discrete diffusion models to be\nused for graph representation learning.", "sections": [{"title": "Introduction", "content": "Representation learning is a fundamental concept in machine learning, with the objective of learning\nuseful and informative representations of data. The goal of representation learning is to transform\nraw data into a format that can be easily processed by machine learning models, often in the form\nof compressed low-dimensional embeddings or features [Bengio et al., 2013]. These representa-\ntions are designed to capture the essential structure and patterns of the data, enabling downstream\ntasks such as classification, clustering, and generation. Representation learning has found appli-\ncations in a wide range of domains, including natural language processing (NLP), computer vi-\nsion, and graphs [Bengio, 2009, Wesego and Rooshenas, 2024b, Hinton and Salakhutdinov, 2006,\nHamilton et al., 2017]. In recent years, deep learning techniques, particularly neural networks, have\nsignificantly advanced the field of representation learning. These models are capable of learning\nhighly expressive representations from raw data, often without the need for manual feature engi-\nneering. For example, in computer vision, a variational autoencoder (VAE) has been used to extract\nlatent representations of images [Kingma and Welling, 2014, Rezende et al., 2014], while in NLP,\ntransformer-based models like BERT learn contextual embeddings of text [Vaswani et al., 2017]. In\nthe context of graph data, representation learning methods aim to learn embeddings that capture\nthe structural and feature information of nodes, edges, or entire graphs, enabling the application of\nmachine learning techniques to graph-structured data [Hamilton et al., 2017].\n\nGraphs are powerful structures that model relationships between entities, and they are widely used\nin various domains such as social networks, biological networks, transportation systems, and knowl-\nedge graphs [Hamilton et al., 2017]. In these domains, graphs represent complex systems, where\nnodes typically correspond to entities, and edges represent relationships or interactions between\nthem. The ability to analyze and extract insights from graph-structured data is critical for applica-\ntions such as recommendation systems, drug discovery, fraud detection, and social network analysis\n[Ying et al., 2018, Velickovic et al., 2018]. Graph representation learning has also become a very\nimportant component of modern graph machine learning, driven by the need to analyze and extract\ninsights from graph-structured data. The primary goal of graph representation learning is to map\ngraph-structured data into a low-dimensional vector embeddings that preserve the underlying struc-\nture and features.\nGraph representation learning plays a crucial role in transforming graph data into low-dimensional\nvector embeddings, which preserve both local and global structural information, as well as node\nand edge features [Hamilton et al., 2017]. These embeddings facilitate efficient analysis and down-\nstream tasks such as node classification, link prediction, and graph classification Kipf and Welling\n[2017]. Despite the success of traditional graph representation learning methods, such as Graph\nConvolutional Networks (GCNs), several challenges remain [Zhang et al., 2019b]. Graphs often\nexhibit highly complex structures, including varying node degrees, long-range dependencies, and\nhierarchical relationships, which make it difficult to capture the full complexity of the graph in\nlow-dimensional embeddings [Kipf and Welling, 2017]. Additionally, graph data is often hetero-\ngeneous, with different types of nodes, edges, and features, requiring methods that can effectively\nhandle this diversity in a unified framework [Zhang et al., 2019a]. Also the dynamic nature of many\ngraphs, where new nodes and edges are continuously added or removed, introduces the challenge\nof learning representations that can capture temporal evolution and adapt to changes in the graph\nstructure [Qin et al., 2023].\nOn the other hand, recent advancements in deep generative models, particularly diffusion models,\nhave opened new avenues for representation learning, offering a promising to learn meaningful rep-\nresentations [Preechakul et al., 2022]. This approach can be crucial to overcome the limitations of\ngraph representation learning. Diffusion models, Ho et al. [2020], which have gained widespread\nattention for their remarkable ability to generate high-quality samples in domains like image syn-\nthesis and molecule generation, have recently been explored for graph data [Vignac et al., 2023].\nDespite their potential, the application of diffusion models to graph representation learning remains\nan emerging area, with several challenges yet to be addressed. This study explores the use of dis-\ncrete diffusion autoencoders for graph representation learning. Discrete diffusion models, which are\ndesigned to operate on discrete data, are particularly well-suited for graph data, where the features\nare often categorical or discrete in nature. By leveraging the generative capabilities of diffusion mod-\nels, we aim to improve the quality of graph embeddings and enhance the expressiveness of learned\nrepresentations. This approach also enables unsupervised learning of graph representations, elimi-\nnating the need for labeled data, which is often scarce and expensive to obtain in many real-world\napplications. We present a detailed examination of the discrete diffusion autoencoder framework\nand evaluate its effectiveness on a set of benchmark datasets, including the Protein dataset from\nTUDatasets Morris et al. [2020].\nThe application of diffusion models to graph representation learning is still in its early stages, but it\nholds significant potential Yang et al. [2023]. Because of their ability to generate high-quality sam-\nples in various domains, they can offer several advantages for graph representation learning. The\niterative denoising process in diffusion models enables the learning of hierarchical representations\nthat capture intricate relationships within the graph structure, resulting in more informative embed-\ndings. In addition, their generative capabilities allow them to generate new graph structures, which\nis valuable for applications such as drug discovery and molecular graph generation Jin et al. [2018].\nThe main idea behind using these models for representation learning is that their strong generative\ncapabilities suggest that they must have learned a valuable, compressed representation of the graph."}, {"title": "Related Work", "content": "Diffusion Models\nDiffusion models have emerged as powerful generative models, achieving a very good performance\nin various domains, including image synthesis, molecule generation, and representation learning\n[Ho et al., 2020, Vignac et al., 2023, Yang et al., 2023, Wesego and Rooshenas, 2024a]. These mod-\nels operate by progressively adding noise to data in the forward diffusion process and learning to\nreverse this noise. This iterative framework enables the generation of high-quality samples that\nclosely resemble the data distribution. Denoising Diffusion Probabilistic Models (DDPM) intro-\nduced the foundational framework for diffusion-based generation, demonstrating their ability to\nproduce realistic images through iterative denoising [Ho et al., 2020]. Improved DDPM further\nenhanced this framework by optimizing noise schedules, learning the variance, and architectural\ndesigns [Dhariwal and Nichol, 2021]. Other notable advancements include Stable Diffusion, which\nintegrates text conditions with diffusion models in the latent space to generate high-resolution im-\nages with that are guided by texts [Rombach et al., 2021].\nDiscrete Diffusion Models\nDiscrete diffusion models extend the principles of diffusion to discrete data, making them suitable\nfor domains like text, categorical data, and graph data. Unlike continuous diffusion models, which\noperate in a continuous state space, discrete diffusion models handle data in a manner that respects\nits inherent discrete nature [Austin et al., 2023, Hoogeboom et al., 2021]. For example, in natural\nlanguage processing, discrete diffusion models can process sequences of tokens, preserving the\nintegrity of the vocabulary during both the forward noise process and the reverse denoising process.\nSimilarly, in graph generative models, discrete diffusion models can handle graphs with categorical\nnode and edge attributes, ensuring that the generated or reconstructed data adheres to the original\ndiscrete graph structure.\nGraph Diffusion Models\nGraph diffusion models leverage the principles of diffusion processes to model graph-structured data.\nThese models are particularly well-suited for capturing the complex relationships and hierarchical\nstructures inherent in graphs. Since graphs has discrete data, most diffusion models fro graphs\nhave focused on working on the discrete space using discrete diffusion models [Vignac et al., 2023,\nChen et al., 2023]. DiGress, a discrete denoising diffusion model, focuses on generating graphs with\ncategorical node and edge attributes, demonstrating its effectiveness in handling graph-structured\ndata [Vignac et al., 2023]. Wang et al. [2024] further expands the DiGress model by training it\non a combination of different graphs from different domains to increase the generalization process.\nEDGE,Chen et al. [2023], is another discrete diffusion model that generates the adjacency matrix of\nthe graph structure conditioned on a degree. They also use absorbing distribution of empty graphs\nas their final distribution decreasing the diffusion time steps of their model because of the sparsity of\ngraphs. These methods highlight the growing potential of discrete diffusion models for applications\nrequiring structured data generation."}, {"title": "Graph Representation Learning", "content": "Graph representation learning has been an important area of research, focusing on transforming\ngraph-structured data into low-dimensional embeddings that preserve structural and semantic infor-\nmation of the graph. There have been multiple previous approaches that are proposed to tackle\nthe challenges associated with learning meaningful graph representations, ranging from contrastive\nlearning techniques to generative and autoencoder-based methods. GraphCL (Graph Contrastive\nLearning) introduced a self-supervised contrastive learning framework that leverages data augmenta-\ntions to maximize the agreement between representations of the same graph under different transfor-\nmations [You et al., 2021]. GraphMAE (Graph Masked Autoencoder) adapts the masked autoencod-\ning method, commonly used in natural language processing, to graphs. It involves masking portions\nof the graph and training the model to reconstruct the masked elements, thereby learning the inner\nstructure of the data [Hou et al., 2022]. GraphVAE (Graph Variational Autoencoder) is a genera-\ntive framework that models the probabilistic distribution of graph data. By learning latent variables\nthat represent the graph structure and attributes, GraphVAE can learn to compress the graph into\nthe latent space and reconstruct it again [Kipf and Welling, 2016]. Yang et al. [2023] used diffusion\nmodels for graph representation learning by extracting outputs from different parts of the model and\nadding directional noise.\nIn this study, we propose a Diffusion Autoencoder setup to learn and extract representations similar\nto Preechakul et al. [2022] but adopted to the graph structured data. We use discrete diffusion mod-\nels as the decoders over the adjacency matrix and a GCN encoder to extract the latent representation\nz. The model is trained is solely on discrete diffusion on the decoder where gradients propagate all\nthe way to encoder."}, {"title": "Methodology", "content": "This section details the methodology of our discrete diffusion autoencoder model, which operates on\ngraph-structured data. We begin by outlining the general discrete diffusion setup and then elaborate\non its specific application within our autoencoder framework. Discrete diffusion models define\na Markov chain of diffusion steps that gradually corrupt the input data into noise. This process is\nreversed by learning a generative model that denoises the data step-by-step, ultimately reconstructing\nthe original input. A sequence of discrete random variables X0, X1, ..., XT is defined in the diffusion\nprocess, where x0 represents the original data and xr is pure noise. The transition probabilities\nq(xtxt-1) are defined such that the data distribution progressively approaches a tractable noise\ndistribution. A model po(Xt-1|xt) is learned to reverse this diffusion process, starting from the\nnoise distribution and iteratively refining the data until reaching the original data distribution.\nDiffusion models maximize the ELBO of the data log-likelihood [Austin et al., 2023] where we\ndefine po(x0) := \u222bpo(xo:T)dx1:T as the probability of the original data, where po(x0:T):=\nr(\u0445\u0442) \u041f-1 \u0420\u043e(x\u22121|xt) represents the joint probability of the entire diffusion process. The for-\nward diffusion process is defined by the probability q(x1:T|X0) := \u041f+=1q(xt|xt\u22121). Maximizing\nthe ELBO is equivalent to minimizing the following inequality:\nE [-log pe (xo)] \u2264 Eq [-log:(1)]\nwhere E [- log pe (x0)] is the expected negative log-likelihood of the data and the right side of the\nequation is the Evidence Lower Bound (ELBO) using Jensen's inequality. This can be rewritten as:\nLVB =Eq(x0) DKL[q(XT|xo)||\u0440\u04e9(XT)] + \u03a3Eq(xt/x0) DKL [q(xt-1|Xt, X0)||po(Xt-1|Xt)] - Eq(x1|xo) logo (X0X1)(2)"}, {"title": "Experiments", "content": "This section outlines the experimental setup of our proposed model and the baselines. We compare\nour model against relevant baselines on a graph classification task using the PROTEINS dataset.\nDataset\nThe PROTEINS dataset comprises 1113 graphs representing proteins, each classified as either an\nenzyme (class 1) or non-enzyme (class 0). The graphs have an average of 39 nodes, with each node\nrepresenting an amino acid and edges representing interactions between them. This dataset provides\na suitable benchmark for evaluating our model's ability to learn meaningful representations from\ngraph-structured data [Morris et al., 2020].\nBaselines\nWe compare our discrete diffusion autoencoder (DDAE) against two baseline models: Graph-VAE:\nA variational autoencoder for graphs, utilizing the same GCN encoder architecture similar to that\nused in our model. Graph-AE: A standard autoencoder for graphs, also using the same GCN\nencoder architecture.\nModel Architecture and Training\nOur model utilizes a Graph Convolutional Network (GCN) encoder to extract the latent representa-\ntion z from the input graph's features and adjacency matrix. The node embeddings from the GCN\nare aggregated using mean pooling to obtain a graph-level embedding. The decoder employs a\nUNET architecture, commonly used in diffusion models [Preechakul et al., 2022], to reconstruct the\nadjacency matrix from the latent representation and noise. A diffusion timestep of 32 was used for\nthe discrete diffusion process and a latent size of 64 dimensions is used across all models.\nEvaluation\nTo evaluate the quality of the learned graph representations, we adopt the following procedure:\nRepresentation Extraction: We remove the decoders from all models (DDAE, Graph-VAE, and\nGraph-AE) and extract the latent representation z for each graph in the PROTEINS dataset. These"}, {"title": "Conclusion and Future Works", "content": "In this paper, we introduce a discrete diffusion autoencoder model for learning representations of\ngraph-structured data. Our approach leverages the power of discrete diffusion models to capture the\ncomplex dependencies within the graph nodes and edges. By combining this generative framework\nwith an encoder network, we learn a latent representation that effectively captures the underlying\nstructure of the graph data. This representation can be used for various downstream tasks, such as\ngraph generation, classification, and other use cases.\nFor future work, we plan to extend this model in several directions. First, we aim to explore the\napplication of our model to a wider range of graph datasets. Then, we intend to incorporate multiple\nbaselines for graph classification and node classification tasks using the learned representation. This\nwill involve evaluating the effectiveness of our learned graph representations in comparison to exist-\ning methods and across diverse datasets. We believe that our discrete diffusion autoencoder model\nprovides a promising new approach for learning representations of graph-structured data."}]}