{"title": "Connectivity-Inspired Network for Context-Aware Recognition", "authors": ["Gianluca Carloni", "Sara Colantonio"], "abstract": "The aim of this paper is threefold. We inform the AI practitioner about the human visual system with an extensive literature review; we propose a novel biologically motivated neural network for image classification; and, finally, we present a new plug-and-play module to model context awareness. We focus on the effect of incorporating circuit motifs found in biological brains to address visual recognition. Our convolutional architecture is inspired by the connectivity of human cortical and subcortical streams, and we implement bottom-up and top-down modulations that mimic the extensive afferent and efferent connections between visual and cognitive areas. Our Contextual Attention Block is simple and effective and can be integrated with any feed-forward neural network. It infers weights that multiply the feature maps according to their causal influence on the scene, modeling the co-occurrence of different objects in the image. We place our module at different bottlenecks to infuse a hierarchical context awareness into the model. We validated our proposals through image classification experiments on benchmark data and found a consistent improvement in performance and the robustness of the produced explanations via class activation. Our code is available at https://github.com/gianlucarloni/CoCoReco.", "sections": [{"title": "1 Introduction", "content": "The aim of this paper is threefold and we make the following main contributions. 1) Informing the AI practitioner about the human visual system. We review fundamental notions and recent trends in the study of human vision - what are the ventral and dorsal streams and how they communicate, how top-down modulation occurs, the existence of subcortical pathways, and the importance of context in vision. This can foster human-inspired computer vision. 2) Proposing a novel biologically motivated neural network for image classification. We design a convolutional model conceptually inspired by the above-mentioned mechanism of human vision and numerically based on recent connectomic studies. 3) Presenting a new plug-and-play module to model context awareness. Our contextual attention block (CAB) can be added to any traditional feed-forward architecture to improve recognition by modelling feature co-occurence in the real world."}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 The Human Visual System", "content": "Historically, visual information processing in humans was described with the two-streams theory, which involved the existence of two anatomically distinct and functionally specialized cortical pathways, the ventral stream, which pro-cesses visual features like color, size, and dimension, and the dorsal stream, which primarily deals with the object's spatial features (location, orientation,and motion) [15,28]. The ventral stream runs from the primary visual cortex (V1) to the temporal lobe, mainly through extrastriate visual areas II (V2) andIV (V4), to the inferotemporal cortex (IT or ITC), and then to the prefrontalcortex (PFC), which is involved in linking perception to memory and action.This pathway is responsible for object recognition, categorization, and memo-rization, thus representing object shape and identity (i.e., the What? of a visualscene). Since it receives signals from the parvocellular cell (P cell) layers, whichare sensitive to color and have a higher spatial resolution but lower temporalresolution, the ventral pathway processes the feature-rich information for finelocal processing (i.e., textures and edges) in a bottom-up manner to form de-tailed representations of visual stimuli. Indeed, cortical visual areas from V1 toITC form an anatomical hierarchy in which information is processed sequentiallywith increasing complexities [16], and the invariance of those representations toposition and scale increase. In parallel, there is also an increase in the size ofthe receptive fields as well as in the complexity of the optimal stimuli for theneurons [12, 13].The dorsal stream is responsible for spatial perception, motion detectionand attention, and thus represents spatial vision and visuomotor control. In-deed, it represents object location or spatial relationships (Where?) within thevisual stimuli. Anatomically and functionally, the dorsal stream runs from V1to the parietal lobe. Since it receives retinal information from the magnocellular"}, {"title": "2.2 Ventral and Dorsal Streams Communicate", "content": "If the general belief in the 1970s to the 1990s was that of a complete division of labor by two segregated visual pathways, this started to change in the early 2000s.New evidence began to emerge calling for synergies between them: there exist\"what\" and \"where\" information in both visual processing pathways. Evidence supports the hypothesis that dorsal and ventral visual areas communicate, and there are shape-selectivity and non-action-based perceptual represen-tations in the posterior regions of the dorsal pathway [16,17,26]. Moreover, the dorsal pathway itself is composed of several sub-pathways, where at least onehas a functional, and probably necessary, role in object perception [24]. Under this light, the two streams are not segregated but constitute an important sym-biosis crucial in transmitting signals between regions. Shape encoding is thusperformed also in the dorsal pathway, and it is distinct from and not a mere du-plication of that formed in the ventral pathway. This means that dorsal objectrepresentations are dissociable from those generated in the ventral pathway andplay an independent and functional role in visual perception. Therefore, visualperception should be studied not simply as a function of one (ventral) \"what\"pathway, but rather as the joint outcome of the processing and coordination ofdifferent \"what\" regions in both cortical visual pathways."}, {"title": "2.3 A Fast Top-Down Modulation of Bottom-Up Representations", "content": "In addition to the traditional bottom-up hierarchy of representation, new mech-anisms of top-down processing were proposed [1,3,5]. There exists a non-cortical,fast, \"shortcut\" stream in which early visual inputs are sent, partially analyzed,from the early visual cortex (V1) to the prefrontal cortex (PFC). Possible inter-pretations of the crude visual input are generated in the PFC and then sent to theinferotemporal cortex (IT/ITC), subsequently activating relevant object repre-sentations, which are then incorporated into the slower, bottom-up process [2,4].Eventually, the coarse and global representations from the subcortical pathwayguide and modulate the fine local representations from the ventral pathway in a"}, {"title": "2.4 Lateral Pathways - Superior Colliculus and Pulvinar", "content": "In humans as well as other mammals, the two strongest pathways linking theeye to the brain are those projecting to the dorsal part of the LGN in thethalamus and to the superior colliculus (SC) [14]. From the former originatethe well-known schematic of ventral and dorsal streams. At the same time, thelatter constitutes the other major retino-cortical visual pathway known as thetectopulvinar pathway, routing primarily through the superior colliculus (SC)and thalamic pulvinar (Pulv) nucleus onto ventral visual area V4 and dorsalvisual area V5/MT."}, {"title": "2.5 Visual Context in Object Recognition", "content": "Context is of fundamental importance to both human and machine vision; e.g.,an object in the air is more likely to be an airplane than a pig. The rich no-tion of context incorporates several aspects including physics rules, statisticalco-occurrences, and relative object sizes, among others [6]. Indeed, context isof critical importance for locating a target object in complex scenes as it helpsnarrow down the search area and makes the search process more efficient [11].It is no surprise that AI and computer vision solutions embedding contextinformation has emerged in the literature. Examples include zero-shot visualsearch [6,11], context-aware attention networks [29], and other computer visionmodels [27], [9], [20], [18]. Unlike such solutions, as we shall see in the following,our proposal do not add computational overhead in terms of parameters, as itdoes not involve additional trainable parameters."}, {"title": "3 Methods", "content": ""}, {"title": "3.1 Architecture design", "content": "After reviewing the relevant literature, our second main contribution in this paper is the design of the connectivity-inspired context aware recognition network (CoCoReco). It is a dual-branched architecture for image classification inspired by the human ventral and dorsal streams and the tectopulvinar pathway. Moreover, we conceive a top-down modulation of the bottom-up representations from the pre-frontal cortex (PFC) and extensive afferent and efferent projections based on connectome studies. As we shall see later, we placed our contextual attention"}, {"title": "3.2 Contextual Attention Blocks", "content": "As our third major contribution, we present a new plug-and-play module to inject context awareness into the model. In fact, our CoCoReco solution also models another fundamental aspect of human vision: context. To conceive our contextual attention block, CAB, we get inspiration from [7,8] as a way to model the co-occurrence of different objects in the image scene. However, our implementation differs from theirs in the computation of attention scores (we rescale their value to avoid value explosion) and in how the enhanced feature maps are embedded to the original ones (we add them element-wise instead of concatenating them to avoid increasing parameter overhead). More importantly, we propose placing multiple CAB modules at different network bottlenecks to construct a hierarchical attention mechanism. Indeed, we use CAB on the output of: (i) the V1 layer, representing a coarse and global context, of (ii) the prefrontal cortex (PFC), representing a semantically rich, goal-oriented, context for top-down information flow, and finally of (iii) the IT/LOC layer, which is where the final representation for the object is constructed for recognition. Lastly, we propose a novel loss term, the mini-batch loss, to push the causality map of samples belonging to the same category closer, so that we foster class-based map alignment. We implement the mini-batch loss as an MSE loss between the causality map of each sample and the average causality map of samples of the same class found in the minibatch during training."}, {"title": "3.3 Experimental setup", "content": "We conceive image classification experiments on ImagenetteV2 data, a popular and freely available dataset composed of a subset of 10 easily classified classes from Imagenet (tench, English springer dog, cassette player, chain saw, church, French horn, garbage truck, gas pump, golf ball, and parachute). We utilize the version at 320x320 image resolution. We split the use the official train-val splits and further split the validation set into actual validation and external test set in proportion 60-30. We use the training set for the learning of the models, the validation as internal assessment and hyperparameter tuning, and then test the trained model on the external test data. Evaluation performance metrics were accuracy and F1-score. We repeated the experiments ten times with different random seeds. As for the total training objective of our model is a composition of cross-entropy loss, for classification correctness, and MSE loss for class-based causality map alignment. We compare our CoCoReco model with two ablation versions and one baseline model. To assess the importance of contextual awareness, we remove the CAB module from the network. To assess the importance of bottom-up and top-down modulations (projections) we remove all the skip"}, {"title": "4 Results and Discussion", "content": "Table 1 and Fig 4 summarize our findings. The former shows how our CoCoReco architecture consistently achieves the highest accuracy and F1-score among the investigated models for ten different random seeds. Indeed, we took the mean and standard deviation values across multiple runs and compared CoCoReco to its ablated versions (i.e., without CAB modules and without projections), as well as to the baseline single-branched network. To further assess the benefits of using our proposal, we conducted post-hoc class activation mapping (CAM). We found the explanations produced by our CoCoReco are better than the competing methods. Generally, they are more robust and focused on the salient object of"}]}