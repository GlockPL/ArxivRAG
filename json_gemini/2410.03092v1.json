{"title": "Strategic Insights from Simulation Gaming of AI Race Dynamics", "authors": ["Ross Gruetzemacher", "Shahar Avin", "James Fox", "Alexander K Saeri"], "abstract": "We present insights from `Intelligence Rising', a scenario exploration exercise about possible AI futures. Drawing on the experiences of facilitators who have overseen 43 games over a four-year period, we illuminate recurring patterns, strategies, and decision-making processes observed during gameplay. Our analysis reveals key strategic considerations about AI development trajectories in this simulated environment, including: the destabilising effects of AI races, the crucial role of international cooperation in mitigating catastrophic risks, the challenges of aligning corporate and national interests, and the potential for rapid, transformative change in AI capabilities. We highlight places where we believe the game has been effective in exposing participants to the complexities and uncertainties inherent in AI governance. Key recurring gameplay themes include the emergence of international agreements, challenges to the robustness of such agreements, the critical role of cybersecurity in AI development, and the potential for unexpected crises to dramatically alter AI trajectories. By documenting these insights, we aim to provide valuable foresight for policymakers, industry leaders, and researchers navigating the complex landscape of AI development and governance.", "sections": [{"title": "Introduction", "content": "As AI has seen tremendous progress in the past five years (OpenAl 2023a; Wei et al. 2022; Bommasani et al. 2021; Brown et al. 2020), and Al safety has become a widely discussed topic over the past two years (Bengio et al. 2024; Cohen et al. 2024; Hendrycks et al. 2023; Critch and Russell 2023) since the public release of ChatGPT (OpenAl 2022) in November of 2022. In these discussions, there has been significant concern over catastrophic and existential risks (e.g., societal-scale risks; Hendrycks et al. 2023; Critch and Russell 2023; Gruetzemacher et al. 2024; Grace et al. 2024) associated with advanced Al such as artificial general intelligence (AGI; Goertzel and Wang 2007) or superintelligence (Bostrom 2014). However, concern over such societal-scale Al risks from advanced Al is not new (Cave et al. 2020; Good 1966).\nThe subject of this paper is Intelligence Rising (Avin et al. 2020), a strategic simulation game intended to let participants explore the space of plausible Al futures. The purpose of Intelligence Rising is two-fold: to explore the space of plausible Al futures and to raise awareness of the catastrophic and existential risks associated with advanced Al. The game specifically deals with conditions resembling a race to advanced Al among four or more major stakeholders (national governments or tech companies; e.g., China, the United States, Google, Microsoft, Baidu, or Tencent). Intelligence Rising allows participants to experience scenarios that decision-makers may encounter in coming years related to Al research and development (R&D), Al governance and geopolitics, and societal-scale risks from Al.\nIntelligence Rising was initially developed in 2018. Through the first half of 2019, the game was a free-form role-play game and completely unstructured. The first complete structured version of the game was developed over a five-day design sprint workshop at the Future of Humanity Institute (FHI) in Oxford, UK in late summer of 2019 (Sandberg 2024). A second design sprint workshop was held at FHI in February of 2020 to further develop the game. Work pivoted to the development of an online version of the game later in the spring of 2020, and an initial online version of Intelligence Rising began testing in April of 2020. Over the course of the next year and a half, further development of the online game proceeded, and in-person games resumed in 2022.\nPrevious published work on Intelligence Rising described an initial version of the game (Avin et al. 2020), and forthcoming work will discuss evaluations that have been conducted with the games' participants to better understand the impact of the game (Mani et al. forthcoming). This paper examines another dimension of the game: the lessons learned by the facilitators who have facilitated the game over the last four years.\nThis paper is intended to summarise lessons from almost 200 hours of facilitated gameplay over 43 games. We hope these will be useful for those new to the field of Al risk or working in fields where the information could be helpful to decision-makers developing strategic plans or policy initiatives related to societal-scale risks from Al. Games have been found to be one of the most feasible techniques for anticipating Al futures (Gruetzemacher et al. 2021), and this is the first study to report results utilising this approach. To structure our reflection, we selected three specific research questions to focus on during our analysis of our experiences:\n\u2022 What key insights about the role and impact of Al over the next 10 years need to be communicated to decision-makers and policymakers?\n\u2022 What are some recurring storylines, strategies, or player behaviours that have emerged from the game?\n\u2022 How have facilitators' perspectives or insights on strategic Al futures evolved through conducting this game?\nTo address these questions, a structured elicitation, led by an elicitation expert, was conducted for Intelligence Rising's three senior facilitators. This elicitation covered lessons learnt from 43 games"}, {"title": "Literature Review", "content": "Catastrophic and existential risks from advanced Al have long been a topic of both academic (Bostrom and Crikovic 2011; Good 1966) and public interest (e.g., the Terminator movies; see Garvey 2018). With recent progress in Al, since late 2022 (OpenAl 2022; OpenAl 2023a), interest in catastrophic and existential risk from advanced Al has increased, from both academics (Bengio et al. 2024; Cohen et al. 2024; Critch and Russell 2023; Hendrycks et al. 2023) and the government (Frontier Al Taskforce 2023; \u0395\u039f 14110).\nWork on the use of foresight approaches for exploring futures involving catastrophic or existential risks from advanced Al is limited (Baum et al. 2020; Beard et al. 2020; Avin 2019; Gruetzemacher 2019). Wargaming has long been used for futures exploration and for training military officers (Perla 1990), having been used as early as in the 1960s for gaming nuclear weapons catastrophes (Dalkey 1967) and trying to minimise casualties from hypothetical nuclear conflict (Owen 1969). Today, advanced approaches are used heavily in national security and defence communities for policy analysis (Bartels 2020), and there are efforts to develop next generation wargames (Reddie et al. 2018), the most recent of which are beginning to employ Al technologies similar to some of those explored in Intelligence Rising (Jensen et al. 2024).\nRecently, futures methods have garnered interest with respect to Al (Korinek 2023), albeit more scenario-based approaches rather than gaming. Scenario-based approaches are useful for strategic planning in that they allow decision-makers to plan and prepare for various scenarios that are plausible but not necessarily likely. Scenario analysis has been in use since at least the 1960s when it was pioneered by leading strategic thinkers such as Herman Kahn at RAND (Kahn and Wiener 1967; Huss 1988), although the first academic paper on a comprehensive method for scenario creation dates to Zentner in 1975. Perhaps the most famous case of scenario analysis was by the Royal Dutch Shell Corporation during the 1973 oil crisis (Cornelius et al. 2005), in which Shell effectively utilised scenario planning to significantly outperform others in the sector in navigating the fallout from this shock event. This case study was ultimately effective at popularising the technique in the business world (Wack 1985a; 1985b). The Shell scenario planning approach is commonly associated with the intuitive logics school of scenario planning, which was derived from the work of Herman Kahn and is the most widely discussed technique in academic literature (Amer et al. 2013).\nWhile Perla's (1990) The Art of Wargaming is quintessential reading for anyone new to wargaming, the domain still lacks an authoritative or comprehensive review of the range of techniques most often used, especially for the broad scope of applications wherein the techniques are used, ranging from military applications, to policy applications, to strategic planning applications in organisations. Unlike scenario planning techniques, much about wargames is siloed away in the organisations most familiar with their use like military universities or think tanks. Often, these different organisations will have distinct approaches to wargaming that reflect the best practices of the collective experience of their lead game designers. In the subsequent paragraphs, we try to synthesise wargaming literature from various perspectives, each of which in some way is relevant to Intelligence Rising.\nWhile opinions vary about the value and best uses of wargaming (e.g., see Curry 2020; Perla and McGrady 2011; Perla 1985), it is important to note that wargaming should not necessarily be limited to military applications. Business wargames, or strategy wargames (West et al. 2018), are known to have applications in strategic planning across a wide variety of business domains (Chusil 2007) and have"}, {"title": "Methods", "content": "This methods section describes the Intelligence Rising game and its evolution over time, the facilitators, the participants, and the process by which the facilitators' reflections were collected and analysed. A discussion of the facilitators and an analysis of the 43 games considered in this study are also included."}, {"title": "The \"Intelligence Rising\" Game", "content": "An initial version of an Al strategy roleplay exercise was first explored by Owen Cotton-Barratt and Michael Page, then at the Future of Humanity Institute (FHI) in Oxford, and Shahar Avin at the Centre for the Study of Existential Risk (CSER) in Cambridge in July 2017. The unstructured exercise was iterated on by Shahar Avin, James Fox and Ross Gruetzemacher at CSER over the next two years. In September of 2019, with a broader set of collaborators, a design sprint was conducted at FHI where the initial freeform version of the Al strategy roleplay game was expanded into the first, tabletop version of \"Intelligence Rising\", described in Avin, Gruetzemacher and Fox (2020). Key features of this game included:\n\u2022 The division of players into four teams, two representing states and two representing multinational technology corporations.\n\u2022 A turn-based decision-making loop where all teams commit to actions without knowledge of other team's actions for that turn, followed by simultaneous resolution by the facilitator.\n\u2022 The per-turn decision-making was divided into two components: the selection of open-ended \"policy actions\" and an \"AI R&D allocation.\" Limiting the \"policy actions\" to two per turn introduced an attention economy.\n\u2022 A predefined \"technology tree\" that outlines dependencies in Al R&D, including basic research and possible applications, that the players explore via Al R&D allocation.\n\u2022 A numerical tracking of four resources, including three abstract \"powers\" \u2014 \"soft power\", \"hard power\", and \"cyber power\" \u2014 as well as an abstract \"budget\", all of which are influenced by, and used to resolve, the freeform \"policy actions\".\n\u2022 Teams were given the option to keep either policy actions or Al R&D allocation secret from other teams, which would then be resolved privately by the facilitator.\nFollowing a second design iteration (based on experience with running the first tabletop version) and a third design iteration (based on the need to adapt to online play during the COVID-19 pandemic), a new version of the game was created, which we refer to here as \"Intelligence Rising Online\". This new version drew on a wider pool of expertise, including in risk communication and game design. Key differences that were introduced in these iterations include:\n\u2022 Switching to online platforms for gameplay (mainly Google Slides and Discord).\n\u2022 Formalisation of team victory conditions and collective loss conditions.\n\u2022 Simplification of the technology tree into two \"lanes\", each advancing through increased \"levels\". One lane represents future advances in language and world-modelling Al capabilities, and the other represents advances in Al reinforcement learning in increasingly complex environments.\n\u2022 Addition of predefined \"concerns\" negative consequences of Al applications that can potentially be mitigated through player actions.\nThe game format still required significant on-the-spot judgement from the facilitator, when resolving freeform policy actions and narrating the events of the game. There were also small variations between how different facilitators facilitated the game, for example when deciding how to resolve actions such as the nationalisation of a corporation, or when deciding on how to resolve the degree of safety of an advanced Al system. Lessons from the different experiences were fed back to the rest of the team, allowing facilitators to learn from each other and for small modifications to be made to the game assets and rules (though no significant changes were made to the core rules and assets of \"Intelligence Rising"}, {"title": "Facilitators", "content": "The reflections in this paper are drawn from the experiences of three Intelligence Rising facilitators, who all co-created the game and are co-authors of this paper. Given the nature of the game as a facilitated roleplay exercise, and in particular, given the importance of facilitator resolution of freeform policy actions (which form the bulk of decisions made in the game), the scenarios that unfold in Intelligence Rising rely on the background knowledge of the facilitators. The subject matter domain of Intelligence Rising includes highly advanced and speculative future technical Al research, the productization and business strategy underlying the progress of a very powerful general purpose technology (Eloundou et al. 2024; Gruetzemacher and Whittlestone 2022), and the core of international relations between great powers. Given the breadth and depth of the domain, and the lack of constraints on the players' action space, adjudication of actions in real-time can be challenging. We therefore find it relevant to summarise the backgrounds and experience of the facilitators in Table 1."}, {"title": "Participants", "content": "Over the period from September 2020 to July 2024, the three facilitators identified in Table 1 facilitated 43 games of Intelligence Rising. Of these, 5 took place at conferences, where participants did not know each other prior to the game, and were unpaid. In the remaining 38 games, a pre-existing group arranged for its members to play Intelligence Rising, of which 22 were paid workshops and 17 were pro-bono; the breakdown of games by group type is as follows: Al company (4), insurance company (2), think tank or NGO (7), university course (7), non-academic training course (6), academic group (3), student groups (6), other (3). Some details of these games are listed in Appendix A.\nThe number of participants in conference games ranged from 20 to 60, and in non-conference games from 4 to 20, usually with 8-12 participants, with the \"team\" size most frequently being 2-3 participants. While generally participants did have some knowledge of the Al domain, their backgrounds with respect to their prior experience with Al development and/or Al strategy varied widely\nfrom lay knowledge to domain experts - mostly between games, but also within games.\nThe creation of the online version allowed us to facilitate Intelligence Rising remotely, but the recruitment of participant groups through word-of-mouth meant they were still relatively socially clustered (around groups interested in Al strategy and Al risks) and relatively geographically clustered (21 UK, 7 USA, 3 Belgium, 2 Sweden, 1 France, 1 Singapore, 8 fully remote)."}, {"title": "Data collection procedure, materials, and measures", "content": "While acknowledging the biases inherent in a reflections paper (outlined above in the Facilitators section), the authors adopted a structured process for collating and aggregating reflections.\nTo assist with recall (and also to support ongoing game development and facilitator training), after the completion of each game, facilitators were encouraged to fill out a game documentation form. This form covered logistics details of the game (date and location), the participant group, any modifications made to the game format before or during gameplay, and a narrative recounting of the key events of the game in the early, mid, late, and end stages of the game. The form also asks facilitators to rank the presence of eleven key themes in the specific playthrough, including agreements between states or companies, military actions or threats, espionage and cyberoperations, and competitions for R&D talent. In the relevant time period (09/2020-07/2024) there were 17 responses to the form, covering 40% of games (17/43). While all facilitators had access to the form reports of other facilitators, it was rare for these to be accessed. In preparing for the study reported in this paper, a non-facilitator author (Alexander Saeri) prepared refresher documents for each of the three facilitators with the form responses of the game they had run, which did not contain the form responses for games facilitated by other facilitators. In addition to the game documentation form, for about a quarter of games the facilitator for that game also prepared a report for the client, which covered similar topics as the game documentation form; facilitators were also encouraged to revisit those in preparation for the elicitation exercise.\nIn a discussion led by Alexander Saeri, the three facilitators agreed on three key questions to explore in this reflection study. These three research questions are:\n1. What key insights about the role and impact of Al over the next 10 years need to be communicated to decision-makers and policymakers?\n2. What are some recurring storylines, strategies, or player behaviours that have emerged from the game?\n3. How have facilitators' perspectives or insights on strategic Al futures evolved through conducting this game?\nThen, guided by the three questions and assisted by the refresher documents based on the game documentation form responses, each facilitator independently collected a list of answers, in bullet point format, for each of the questions.\nFinally, a structured aggregation session led by Alexander Saeri was conducted using Miro. Individual answers to each of the questions were presented as virtual post-it notes, and then collectively clustered by the three Intelligence Rising facilitators. The resulting clusters were then labelled during discussion, and further observations about each cluster were generated through discussion. These aggregated answers to each of the three research questions are presented and discussed in the next section."}, {"title": "Results and Discussion", "content": "This section is organised by the three research questions that are the focus of this analysis. To report the key insights, it made more sense to discuss each insight in prose. For the clusters of recurring game"}, {"title": "Research Question 1", "content": "What key insights about the role and impact of Al over the next 10 years need to be communicated to decision-makers and policymakers?\nAfter overseeing 43 games of Intelligence Rising, there are many insights about the role and impact of Al that the facilitators felt should be communicated to decision-makers and policymakers. Through the elicitation process consensus was achieved for the five most important insights. We list these below.\n1. Current and future Al systems pose a wide variety of societal-scale risks, ranging from imminent threats like disinformation and unfair outcomes to longer-term catastrophic and existential risks.\nThe seriousness of these societal-scale risks, especially those that are the most severe (i.e., those threatening entire communities around the globe or the entirety of human populations), must be impressed upon governments. There is now growing consensus that establishment of robust, verifiable and legitimate ways to encode appropriate values into Al systems (i.e., \"Al alignment\") prior to the deployment of RTAl systems is absolutely critical to mitigate the most severe risks from Al (Cohen et al. 2022; Hendrycks et al. 2022; Russell 2019; Yudkowsky 2016). This consensus was not in place when Intelligence Rising was created in 2019, yet despite this broader shift in the collective perception of Al risk (Gruetzemacher et al. forthcoming), not all governments and Al developers are acting accordingly. Therefore, it is imperative that governments be made aware of both the gravity of the alignment problem10 (Ord 2020) and the challenges in solving it (Anwar et al. 2024). Governments should also be reminded that these challenges will require not only technical solutions, including advances in Al safety research and responsible development practices (Janjeva et al. 2023), but also the effective anticipation, public debate, and sociotechnical management of Al and its potentially destabilising societal impacts (Curtis et al. 2024; Lazar and Nelson 2023).\n2. Even prior to the development of radically transformative Al, Al technologies can have dramatically destabilising effects as they rapidly advance and reshape society.\nGiven the rapid pace of progress in Al capabilities, the complexity of the risks themselves (Pilditch 2024; Bostrom 2014), and the complexity and unknown unknowns regarding potential solutions (Bengio et al. 2024; Gruetzemacher 2018), society is currently, and is expected to continue trending toward, a state of constant flux and uncertainty, leading to negative impacts on social stability. More and more resources (time, money, talent, compute, and energy) are being allocated towards the development and deployment of Al (Epoch Al 2023), and Al is expected to soon speed up Al research (Leike 2024), so it is likely that there will be continued accelerating progress (Drexler 2019). In other words, the rate of technological advancement, and its impact, is likely to increase, meaning more and larger impacts will be felt more frequently. If states don't act urgently and decisively prior to \"warning shots\" (Alaga and Schuett 2023) it may be difficult to achieve robust and effective governance of advanced Al that meaningfully addresses the risks (Genus and Stirling 2018).\n3. The power to steer the future of Al development is very unequally distributed due to several drivers for concentration, including the enormous compute requirements of the latest frontier Al models.\nSeveral factors contribute to significant positive returns on investment for Al R&D, especially for a few early movers. This means that very few companies, as well as the states that directly govern them, hold significantly more power11 than other actors with respect to affecting how Al impacts society.\nInitially, this was explored in Intelligence Rising through the dynamic of Al talent. In 2019 we could observe the concentration of research talent at Deepmind, and how a critical mass of talented researchers led to breakthroughs that made other talented researchers want to join the leading lab, creating a significant skew in the distribution of talent at frontier Al labs. The emergence of frontier competitors to Deepmind (including OpenAl, Anthropic, and others) has challenged a pure winner-takes-all take; however, with all else being equal, it is still the case that top Al talent prefers to work with other top Al talent at the labs who make the most exciting advances.\nIn recent years, we have seen compute as a dominant factor skewing the distribution of power at the Al frontier. While many recent start-ups have been able to raise enormous amounts of capital buoyed by the hype surrounding the capabilities of the latest models (e.g., Stability Al, Cohere), it is unclear whether they will be able to continue to compete without partnering with larger firms (as OpenAl and Anthropic have, e.g., with Microsoft, and Alphabet and Amazon, respectively) given the race between well-capitalised firms to acquire as many GPUs as possible.12 It is unclear whether Nvidia will retain its dominance in the training of LLMs indefinitely,13 but AMD appears to only be able to offer products that can efficiently be used to perform inference at this time (ORNL 2024; Marty et al. 2024). There is talk about trillion-dollar clusters (Hagey and Fitch 2024; Aschenbrenner 2024), but it is unclear whether\n4. There exists an information asymmetry where states and the public will constantly be catching up to deal with the impacts of the last generation of Al technologies, unless they manage to regulate the rate of progress or invest in anticipating new developments and impacts.\nRegulators have historically had to play catch up on regulating many of the most important emerging technologies of the past century. Automobiles are a classic example, with automobile regulation taking roughly one hundred years before mortality rates from vehicular accidents began to bottom out (Ramage-Morin 2008). Another more recent example is that of social media, which was unregulated for over a decade, during which it has been blamed for being misused to influence elections (Tambini 2018) and as a cause of increasing mental health issues for youth (Nesi 2020). Recently, U.S. regulators decided that warning labels were necessary for social media products (Sullivan 2024).\nWith this in mind, and given the rapid progress in Al led by private sector companies, we designed Intelligence Rising such that, unless governments take proactive action on regulation or foresight, companies will race ahead and generate concerns which states then need to deal with. We notice that in most games, despite this development-concern cycle repeating itself several times over the course of gameplay, companies' progress outpaces governments' abilities to plan for and properly govern the torrent of new challenges produced by the ever-increasing capabilities of advanced Al systems. Not only are governments slow to adapt, but the policies they pursue are often not innovative enough or forward-thinking enough to maintain relevance long (#8a in Table II). Moreover, policies that are enacted during games are generally more reactive than proactive (#8b in Table II) which effectively amounts to placing a band-aid on a wound that needs stitches. Even proactive policies are often not proactive enough in the face of rapid progress to RTAI,14 and ultimately lead to diminishing global stability. Furthermore, the policies enacted are often myopic and subject to hyperbolic discounting, which can have grave consequences in this particular high-stakes context (Gruetzemacher 2018).\nMoreover, governments are not the only core group of stakeholders that are slow to adapt, populations are as well. Progress is often so rapid that Al only becomes the determinative political issue for U.S. presidential elections in a small number of games at the end of the game.15 Moreover, we see that most of the time participants fail to demonstrate an awareness of the potential for significant path-dependence when setting policy (e.g., see Leibowitz and Margolis 1995) that the choices made along the way to RTAI will impact the context in which governance of RTAI is decided.\nThe Al safety community has been generally pleased by the increased attention paid by the U.S., the U.K., and the E.U. governments to Al risk in the wake of ChatGPT and the popularisation of generative Al (and concomitant risk awareness campaigns), but based on many games' trajectories this may not continue indefinitely. It sometimes happens in games that when strong policy actions are taken on Al safety early, then in later turns attention moves away and actions begin trending toward other policy goals. For this reason, it is possible that after governments act firmly and resolutely on Al they may become complacent, deemphasize the continuing budgetary and policymaking support for the issue, and\n5. Cooperation is a major challenge.\nIt is clear that cooperation between actors (especially between regulators) in the face of collective global problems is beneficial (Schelling 2009); however, it shouldn't be underestimated how hard that is (consider climate change for example; e.g., see De Coninck et al. 2008). In particular, there are natural technology race dynamics (Siddiqi 2000; Glaser 2000) that are encouraged here given the potential enormous returns from advanced Al (in terms of money, power, and control). Therefore, it is inevitably tempting for all powerful actors to perceive Al as a race (Cave and \u00d3 h\u00c9igeartaigh 2018), neglecting the collective threats from the technology that require coordination to address.\nWe have observed different kinds of race dynamics that can emerge: strictly between companies; between companies with the backing of states; and directly between states. Race dynamics can emerge strictly between companies especially when states give companies broad autonomy over Al development while ignoring the associated risks. Oftentimes the decisions regarding this are political, for example, in the U.S. such decisions often fall along party lines (and can change abruptly following an election). In China, such decisions are often foregone since interference of the state with private firms is more common, and firms represent the state's interests (Williams 2020). It is more common (and observed in most games) to see states engaging in proxy races through companies, e.g. through state backing of companies, state funding of companies, state procurement of company services, or public-private partnerships (PPPs). This dynamic seems natural in the U.S. because the government tends to focus on competition with China above Al development and labs tend to focus on rapid Al development. Finally, direct state competition often requires nationalisation16 efforts (due to the R&D advantage of companies), and occurs in a large minority of games.\nWhen both the U.S. and Chinese states are minimally involved, this tends to favour the U.S. and Western companies' chances of rapidly developing RTAI ahead of Chinese counterparts,17 but often fail to address safety concerns and sometimes prompts a violent response from China and rapid reduction in global stability.18 In other circumstances, which are seen more often when players more realistically portray leaders of China or the U.S., we often see races lead to endgame negotiations, though these negotiations under time pressure usually fail to identify a satisfactory arrangement for both states. Even when hastily drafted agreements are made, often there are defections that lead to cyber and/or hard power conflict in the closing minutes (e.g., see #7c in Table II). In virtually all of the above cases the outcome of the game, and the implied survival and flourishing of all of humanity, is left to the roll of dice, something that we should all find unacceptable.\nThe best chances for optimal outcomes are achieved through early recognition of the magnitude of the challenge, trust building over years, and eventually international treaties or agreements that include rigorous and robust verification protocols for the involved states and firms. However, even with an agreement in place to slow development until safe RTAI is verifiable at a very high level of confidence and with no successful attempts to violate the agreement by any parties, a dice roll is typically still required to inform the end-of-game narrative representing the dual challenges of creating effective global governance and of finding robust solutions to RTAI safety."}, {"title": "Research question 2:", "content": "What are some recurring storylines, strategies, or player behaviours that have emerged from the game?\nWhile recurring themes in games were touched upon in discussion of our first research question, we take a deeper dive in this section by providing a more comprehensive list of common recurring storylines, strategies, and player behaviours observed during our games, with clusters identified through facilitated elicitation (see Methods section). Due to the variety of themes we wish to cover here, we use Table II to outline the broad range of these recurring trends. Following the presentation of the table, we discuss some of the trends we feel salient to stakeholders working on issues related to risks from advanced Al."}, {"title": "Research Question 3:", "content": "How have facilitators' perspectives or insights on strategic Al futures evolved through conducting this game?\nThis research question directly explores how Intelligence Rising's facilitators' perspectives and insights on strategic considerations of progress toward RTAI have changed as a result of their experiences as facilitators for Intelligence Rising. Through the facilitated exercise we participated in, we identified eight distinct clusters for this research question. We discuss each of these below."}, {"title": "Geopolitical Race for Al", "content": "As a result of our experiences facilitating Intelligence Rising, our concerns over the potential consequences of a race, particularly the potential for a direct military conflict spurred by concerns over Al, have grown significantly. Because RTAI is likely to provide, or to be perceived as providing, a decisive strategic advantage to the state that acquires it or to the first state that acquires it, we are particularly concerned that states behind in a race scenario could launch risky and potentially catastrophic attacks when it becomes apparent that an adversary's deployment of RTAI is imminent. Our concern stems from our observations that the 'runner up' will likely feel justified in launching such attacks because, without a preexisting treaty regarding other states' autonomy post-RTAI, the deployment of RTAI could be perceived as an existential threat to states not allied with the deployer. Our observations indicate that this is both a catastrophic and existential risk and that it increases the catastrophic or existential risk from the deployment of an unaligned RTAI system.\nWe have also observed that players acting as the Chinese government tend to prioritise the development of aligned Al systems. As a result, games in which China 'wins' an Al race are often also games in which Al safety risks have been reduced as much as possible, reducing existential risk from this perspective. We observe that players portray China as being at least as diligent as the United States when it comes to taking Al safety seriously. The Al firms are generally portrayed as being more irresponsible than either China or the U.S. government in this regard, especially in the endgame.\nIf China does ultimately 'win' an Al race, the values that the RTAI system promulgates are very much Chinese whereas if the U.S. 'wins' the values promulgated are very much Western in nature. Because of this, we have frequently seen very strong and safe Al safety efforts result in failure in the endgame because states that are behind in the race start a conflict to prevent the lock in of hegemony and the values of an adversary. However, as researchers who live in the UK and the U.S., who are strongly committed to Western values, over the course of years facilitating Intelligence Rising we have grown more accepting of the notion of China 'winning' an Al race over time, especially when an agreement is in place to ensure the autonomy of Western states; if the Western nations 'lose' a race but maintain their autonomy and values, this is still a far better outcome than global or existential catastrophe (Ord 2020).\nIn scenarios that are not multipolar in nature (i.e., only one RTAI system emerges as dominant; Bostrom 2014), we have come to see an agreement assuring the autonomy of both democratic and non-democratic governments as being critical to success. Without these, the likelihood of a state's existential fears leading to dangerous military escalations to prevent the deployment of RTAI greatly increases. However, this takes concession on the part of leaders from both sides to let philosophically opposed forms of governance maintain and persist indefinitely in the world, something often difficult for both sides to commit to."}, {"title": "Technical and Policy Solutions", "content": "As mentioned in the previous paragraph, we have come to see that agreements ensuring states' autonomy and values between states of opposing ideologies are often a necessary condition for optimal outcomes when RTAI is created. However, there are many challenges that arise from crafting such agreements.\nA central challenge to establishing international agreements on sharing the benefits of RTAI and protecting nations' sovereignty and values is ensuring that parties will honour the agreement. For example, consider a hypothetical scenario where China had committed to an agreement that if they develop RTAI first, they would still allow Western states to develop independent RTAl systems, perhaps with some restrictions. In this scenario, what mechanisms can be put into place to ensure that after developing RTAI first they simply do not renege? Very robust technical and institutional measures would be needed to truly provide significant confidence that any agreement may be followed. Even if not cooperating on Al research, there would need to be some degree of cooperation on the technical measures being developed and integrated into Al systems to ensure such agreements are binding. Moreover, there would need to be oversight of systems' development to verify that these measures are actually integrated appropriately into systems. This itself would require a level of cooperation on the most sensitive state-level national security technological development that is previously unprecedented. We have also come to realise that there are many other significant challenges to crafting agreements"}, {"title": "Roleplay", "content": "Intelligence Rising is a strategic role-play game requiring participants to, as best as possible, act as if they were in the shoes of the leaders of the organisations and states that they are simulating. Thus, over the course of years of playing we have learned some important lessons regarding players' abilities to role-play certain characters. For one, we have observed that many players (predominantly from the U.S. and Europe) are much more comfortable portraying certain actors (e.g., Western actors"}]}