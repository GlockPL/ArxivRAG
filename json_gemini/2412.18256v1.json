{"title": "Robust Semi-Supervised Learning in Open Environments", "authors": ["Lan-Zhe Guo", "Lin-Han Jia", "Jie-Jing Shao", "Yu-Feng Li"], "abstract": "Semi-supervised learning (SSL) aims to improve performance by exploiting unlabeled data when labels are scarce. Conventional SSL studies typically assume close environments where important factors (e.g., label, feature, distribution) between labeled and unlabeled data are consistent. However, more practical tasks involve open environments where important factors between labeled and unlabeled data are inconsistent. It has been reported that exploiting inconsistent unlabeled data causes severe performance degradation, even worse than the simple supervised learning baseline. Manually verifying the quality of unlabeled data is not desirable, therefore, it is important to study robust SSL with inconsistent unlabeled data in open environments. This paper briefly introduces some advances in this line of research, focusing on techniques concerning label, feature, and data distribution inconsistency in SSL, and presents the evaluation benchmarks. Open research problems are also discussed for reference purposes.", "sections": [{"title": "1 Introduction", "content": "Semi-supervised learning (SSL) is an effective learning paradigm to improve learning performance by attempting to exploit abundant unlabeled data when labels are scarce. It has been reported that, in certain cases, such as image classification, SSL methods can achieve the performance of purely supervised learning even when a substantial portion of the labels in a given data set has been discarded [1].\nIt is noticeable that the current success of SSL is mostly based on the close environment assumption where important factors between the labeled and unlabeled data are consistent. For example, all the unlabeled instances should belong to the label set in labeled data, the features describing labeled and unlabeled data should be the same, and all labeled and unlabeled data should be sampled from an identical distribution. Figure 1 illustrates those consistent factors assumed in close environment SSL studies.\nHowever, many real-world applications involve open environments [2] where class label set, feature space, and data distribution could be inconsistent between labeled and unlabeled data. The main reason lies in the fact that the collection process of unlabeled data is different from labeled data, which lacks human supervision and easily collects data that are inconsistent with the target task. It is also impossible to manually validate the quality of unlabeled data, otherwise it goes against the SSL's purpose of reducing human labor. It has been widely reported that SSL suffers severe performance degradation problems with inconsistent unlabeled data and could be even worse than the simple supervised learning baseline which does not exploit more unlabeled data [3, 4, 5, 6, 7, 8]. Such phenomena undoubtedly violate the expectations of SSL and limit its effectiveness in more practical tasks.\nIt seems the robust SSL in open environments is relevant to studies like out-of-distribution (OOD) detection [9, 10, 11, 12], or open set recognition [13, 14]. However, these studies either assume that there is an accurate classification model or sufficient labeled data, which limits their application in SSL. There are also some unsupervised OOD detection studies [15] utilizing the power of the contrastive learning [16] framework to learn better representation for OOD detection. However, although these studies do not require labels, they still need a large amount of in-distribution data for training, while in open environment SSL it is difficult to get the clean in-distribution unlabeled data.\nDespite the grand challenges, many research efforts have recently been devoted to robust SSL in open environments. This paper will briefly introduce some advances in this line of research, focusing on approaches concerning inconsistent labels, inconsistent features, and inconsistent distributions between labeled and unlabeled data. Moreover, we introduce the benchmark dataset and performance measures applicable to evaluate the robustness of SSL in open environments and provide a public SSL toolkit for related research. Open research problems are also discussed for reference purposes."}, {"title": "2 Robust SSL in Open Environments", "content": "In the SSL task, we are given a set of training data which includes labeled data set $D_l$ consists of $n$ labeled instances $D_l = \\{(x_1, y_1), \\ldots, (x_n, y_n)\\}$ and unlabeled data set $D_u$ consists of $m$ unlabeled instances $D_u = \\{x_{n+1}, \\ldots, x_{n+m}\\}$. Usually, $m \\gg n$, $x \\in X \\in \\mathbb{R}^d$, $y \\in Y = \\{1, \\ldots, K\\}$ where $d$ is the number of feature dimension and $K$ is the number of classes. The goal of SSL is to learn a model $f(x; \\theta) : \\{X; \\Theta\\} \\rightarrow Y$ parameterized by $\\theta \\in \\Theta$ from training data to minimize the generalization risk $R(f) = E_{(x,y)}[l(f(X; \\theta), Y)]$, where $l : Y \\times Y \\rightarrow \\mathbb{R}$ refers to certain loss function, e.g., mean squared error or cross-entropy loss.\nIn open environments, unlabeled data could be inconsistent with labeled data in terms of class label space, feature dimension, and data distribution. We denote the degree of inconsistency as $t \\in [0, 1]$. A higher $t$ indicates a greater inconsistency, i.e., more unlabeled instances that are inconsistent with the target task. The robust SSL studies in open environments aim to decrease the negative impact of inconsistent unlabeled data, on the one hand, improve the performance via exploiting unlabeled data, and on the other hand, in the worst case, the SSL performance should not be worse than the supervised learning baseline which does not exploit more unlabeled data."}, {"title": "3 Label Inconsistent", "content": "Close-environment SSL studies typically assume that the class label of any unlabeled instances should be a member of the given label space $Y$. However, this assumption does not always hold. This is because unlabeled data is much easier to collect than labeled data in real-world applications, and the collection process of unlabeled data has less human verification. Thus, it is more likely for unlabeled data to have unseen classes that are irrelevant to the target task. For example, in the image classification task, unlabeled images crawled from Internet/social networking according to keywords usually contain broader category concepts than labeled data [5, 6, 17, 18]. We illustrate label inconsistency in Figure 2 to help understand the problem.\nMany researchers have pointed out that SSL is not robust to irrelevant unseen classes of unlabeled data, and could perform even worse than the simple supervised learning method that uses only a small number of labeled data [4, 5].\nThe straightforward idea to deal with this problem is to detect and remove these irrelevant unseen class unlabeled instances. It is noteworthy that this problem is different from OOD detection since OOD detection approaches typically require a large corpus of in-distribution labeled data and would fail due to the scarcity of labeled data in SSL. Recently, a simple yet effective approach was proposed to tackle the semi-supervised OOD detection issue [19]. This approach learns a new representation space via a novel distance measure in which OOD samples could be separated well with limited labeled data and in-distribution data.\nSome approaches try to decrease the negative impact of these unseen class unlabeled instances in the training process. Various scoring mechanisms have been proposed to evaluate how much contri-"}, {"title": "4 Feature Inconsistent", "content": "Close-environment SSL studies typically assume that all unlabeled instances reside in the same feature space with the labeled data. Unfortunately, this does not always hold. For example, in the image classification task, the labeled data are all color images while the unlabeled data could contain grayscale images, resulting in the loss of two color channels. In tasks dealing with tabular data, such as financial analysis tasks or recommendation systems [28], decremental or incremental features in unlabeled data are more common. Figure 3 illustrates the feature inconsistent problem in SSL.\nAs pointed out by [18], close environment SSL methods could suffer severe performance degradation when facing the feature inconsistent between labeled and unlabeled data.\nCompared with the label inconsistent problem, detecting which unlabeled instances have inconsistent features with the target task is much easier since validating the feature x is irrelevant to the label. Therefore, the straightforward method to address the feature inconsistent problem is to detect and remove all inconsistent unlabeled instances.\nHowever, this baseline method cannot effectively utilize the information behind these unlabeled data, resulting in limited performance improvement. Another approach that readily comes to mind is to remove all incremental features and fill in decremental features, whereas how to fill the missing feature to ensure the SSL performance will not degrade is still a challenging problem [18].\nThere are also studies focusing on the adversarial feature inconsistency unlabeled examples, which can be categorized into two aspects: Attack and Defense. Semi-supervised attack techniques study how to generate adversarial unlabeled examples that cause SSL predictions to be incorrect. The major techniques can be categorized as misleading se-"}, {"title": "5 Distribution Inconsistent", "content": "Close-environment SSL studies typically assume that all labeled and unlabeled data are independent samples from an identical distribution (i.e., i.i.d. samples). Unfortunately, this does not always hold. Taking the image classification as an example again, the labeled data may sampled from natural images. In contrast, the unlabeled data may be selected from the internet according to some keywords and may include cartoon images [35]. These problems also commonly happen in scenarios like sentiment analysis [5], remote sensing [36], legal judgment [37], etc. Figure 4 illustrates that ignoring the data distribution inconsistent mismatch may lead to seriously downgraded performance.\nThere have been plentiful studies concerning distribution shifts such as prior probability shifts, covariate shifts, and concept shifts. However, the relevant studies mainly focus on the training/testing distribution change and are conducted under the umbrella of domain adaptation or transfer learning [38]. In SSL studies the distribution occurs within the training data. To be able to handle various kinds of data distribution inconsistent between labeled and unlabeled data is an important requirement for robust SSL in open environments.\nThe straightforward method is to treat labeled data as the target domain and unlabeled data as the source domain and then apply domain adaptation techniques to learn new representations for all training instances to eliminate the distribution mismatch [39, 40, 41]. However, due to the label scarcity in SSL, these methods can only consider the adaptation in an unsupervised manner and ignore task-related label information.\nRecent work presented a theoretical framework that presents three main reasons why SSL algorithms can not perform well with inconsistent distributions: coupling between the pseudo-label pre-"}, {"title": "6 Evaluation Benchmark", "content": "Conventional SSL studies mainly evaluate performance on standard image classification datasets and report classification accuracy. How to fair evaluate the robustness of SSL methods in open environments is under-considered. In this section, we briefly introduce some datasets, applicable performance measures, and an open-sourced SSL toolkit."}, {"title": "6.1 Datasets", "content": "Constructing open environment SSL benchmarks that contain different extents of inconsistency between labeled and unlabeled data is important for the evaluation of robust SSL algorithms. Recently, a more realistic SSL benchmark included both label, feature, and distribution inconsistent has been provided [18]. The benchmark involves various data types in machine learning, including tabular datasets from the UCI dataset, widely applied image datasets, and text datasets. Specifically, to simulate the inconsistent labels, they construct inconsistent labeled space by randomly selecting some classes and discarding the labeled data belonging to these classes. To simulate the inconsistent features, they randomly mask features for tabular data and convert the images to grayscale, resulting in the loss of two color channels for image datasets. For the text datasets, they employ text truncation, and truncated portions are filled with \u201c< pad >\u201d. To simulate the data distribution, for image and text datasets, they adopt the Image-CLEF [48] and the IMDA/Amazon [49, 50] to construct the labeled and unlabeled data which are natural distribution shifts. For tabular datasets, they calculate the centroids of each class and use the distance between instances and class centroids to filter instances, thus constructing an environment with inconsistent data distribution."}, {"title": "6.2 Performance Measures", "content": "To achieve a fair and comprehensive evaluation of robust SSL in open environments, only reporting the classification accuracy or error is not enough. A series of performance metrics tailored for robust SSL in open environments have been proposed recently [18]. These metrics begin by defining a function $Acc(t)$, which quantifies the change in classification accuracy as a function of the inconsistency level $t$. This function is used to construct the Robustness Analysis Curve (RAC) that maps the inconsistency level $t$ to the corresponding accuracy $Acc(t)$. Unlike conventional SSL evaluations that focus solely on $Acc(0)$ or a specific $Acc(t)$, various performance metrics are proposed based on the RAC that include Area Under the RAC Curve (AUC) which captures the overall robustness of SSL"}, {"title": "6.3 Open-Sourced Toolkit", "content": "To provide easier evaluation and implementation of SSL algorithms, an open-sourced SSL toolkit: LAMDA-SSL is released [51]. LAMDA-SSL incorporates more than 30 SSL algorithms, supports various data types, and is compatible with other popular machine learning toolkits such as \u201cscikit-learn\" and \"pytorch\u201d. The toolkit is available at https://ygzwqzd.github.io/LAMDA-SSL."}, {"title": "7 Open Challenges", "content": "Though robust SSL in open environments has attracted much attention, it is still in its infancy. We hope to propose new research directions to broaden and boost robust SSL research."}, {"title": "Theoretical Issues", "content": "Many theoretical problems about robust SSL have not been addressed yet. For example, when the inconsistent unlabeled data is helpful or harmful, how the generalization performance varies with different inconsistent extents, etc. More efforts are desired to be devoted."}, {"title": "General Data Types", "content": "SSL studies mainly focus on homogeneous data, especially image data. Tabular data is also a commonly occurring data in practical tasks [28, 52]. The heterogeneous property of tabular data causes the failure of SSL algorithms. For example, consistency regularization, which is the most important technique in SSL, encourages the model to have similar output distribution on an instance and its augmented variants. The notion of augmentation simply does not exist in tabular data. Therefore, there is an urgent need to develop robust SSL techniques for more general data types."}, {"title": "Exploiting Pre-Trained Models", "content": "With the success of the \"pre-train and fine-tune\" paradigm, more and more pre-trained models have been released. Similar to the goal of SSL, selecting and adapting helpful pre-trained models can also decrease the labeled data requirement for the target task [53]. Thus, how to bridge the pre-trained model with SSL is a promising direction. Recently, there have been some studies that have tried to exploit SSL techniques with large language models [54] and vision-language models [36]. However, the robust-"}, {"title": "From Perception to Decision-making", "content": "Current SSL studies mainly focus on perceptual tasks such as image classification, while practical tasks often encounter decision-making tasks that involve interaction with the environment. The dynamic of environments poses significant challenges to robustness, meanwhile, high-quality data is expensive in decision-making tasks, posing a great need for SSL. Many researchers have been exploring how to utilize unlabeled data for reinforcement learning [55, 56] on these tasks, including reward-free or action-free data [57, 58]. Therefore, it is important to broaden robust SSL studies into decision-making tasks with interactive environments."}, {"title": "8 Conclusions", "content": "This paper introduces open environments SSL. We present a definition of this problem, in which unlabeled data could contain label/feature/distribution inconsistent with the target task, and briefly introduce some research advances in this line of research. Although we consider these inconsistent problems separately, in practice they often occur simultaneously. It can hardly be a thorough review of all the relevant work and is mostly a brief review of general principles and strategies rather than specific learning algorithms. The quality of unlabeled data is hard to validate and it is fundamentally important to enable SSL to achieve excellent performance in the usual case while keeping satisfactory performance no matter what unexpected unfortunate issues occur in unlabeled data. This is crucial for achieving robust SSL in practical tasks."}]}