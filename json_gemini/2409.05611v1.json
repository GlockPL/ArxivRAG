{"title": "Adapted-MoE: Mixture of Experts with Test-Time Adaption for Anomaly Detection", "authors": ["Tianwu Lei", "Silin Chen", "Bohan Wang", "Zhengkai Jiang", "Ningmu Zou"], "abstract": "Most unsupervised anomaly detection methods based on representations of normal samples to distinguish anomalies have recently made remarkable progress. However, existing methods only learn a single decision boundary for distinguishing the samples within the training dataset, neglecting the variation in feature distribution for normal samples even in the same category in the real world. Furthermore, it was not considered that a distribution bias still exists between the test set and the train set. Therefore, we propose an Adapted-MoE which contains a routing network and a series of expert models to handle multiple distributions of same-category samples by divide and conquer. Specifically, we propose a routing network based on representation learning to route same-category samples into the subclasses feature space. Then, a series of expert models are utilized to learn the representation of various normal samples and construct several independent decision boundaries. We propose the test-time adaption to eliminate the bias between the unseen test sample representation and the feature distribution learned by the expert model. Our experiments are conducted on a dataset that provides multiple subclasses from three categories, namely Texture AD benchmark. The Adapted-MoE significantly improves the performance of the baseline model, achieving 2.18%-7.20% and 1.57%-16.30% increase in I-AUROC and P-AUROC, which outperforms the current state-of-the-art methods. Our code is available at https://github.com/.", "sections": [{"title": "Introduction", "content": "Anomaly detection recognizes anomalous images and detects anomalous regions, which is a essential method in industrial quality applications (Bergmann et al. 2019a; Liu et al. 2024). Because obtaining and labeling anomalous samples is difficult in the real world, unsupervised anomaly detection (UAD) which discriminates outliers by learning normal sample features has gradually become the focus of research (Wu et al. 2024; Heckler, K\u00f6nig, and Bergmann 2023; Liu, Tan, and Zhou 2022). Motivated by the fact that normal samples are easy to collect, many methods learn the features distribution of normal samples by reconstructing them recently (Ristea et al. 2022; Zhang et al. 2023a). These methods assume that the reconstruction network can distinguish between representations of anomalous samples based on distributions learned from normal samples, thereby establishing the decision boundary. Other methods are based on synthetic anomalous images which are normal thus learning discriminative image features by deep learning models(Zavrtanik, Kristan, and Sko\u010daj 2021a). These methods intensely depend on the quality of the synthetic anomaly images as well as on more empirical knowledge about the defect patterns. Some methods also use memory-bank (Park, Noh, and Ham 2020; Wang et al. 2023; Hu et al. 2024) to store features of normal samples and discriminate anomalous samples by calculating feature similarity. These methods ignore the existence of unseen samples within the testing process. We summarise these current methods as shown in Figure 1, where the methods uniformly learn representations distribution for normal samples and build a single decision boundary in the same category based on the distribution. In the test time, samples outside the decision boundary are considered anomalous samples.\nThe aforementioned methods demonstrate optimal performance due to the consistency in the training datasets and exhibit minimal distribution bias between the train set and test set (e.g. Sample-a, Sample-b, and Sample-c from MVTec in Figure 1). However, the real samples are affected by variations in the lighting conditions, equipment, camera position, and other factors during the acquisition process. It results in a variation in the distribution of the samples used to learn the representations, as well as the samples to be detected. As shown in Figure 1, practical applications suffer from a large number of samples in the same category that are still \"novel type\" (e.g. different color, material in Texture AD-Cloth) exacerbating the variation in the train set. Furthermore, it is possible that the test data and the training data, which belong to the same category, may exhibit distribution bias. Unseen normal samples may be projected outside the single decision boundary, potentially leading to significant inaccuracies. In this paper, we formulate the mentioned issue in terms of two definitions. (1) Various complicated feature distributions exist in the training samples. As shown in Figure 1, samples in Texture AD-Cloth are collected from the same category (cloth), but each sample is in a completely independent data distribution due to color and material differences. It indicates that a single decision boundary in the training process is not sufficient to distinguish all samples of the same category. (2) Distribution bias in the test set and train set for normal and anomalous samples. As shown in Figure 1, the test set samples are unseen compared to the training set in Texture AD-Cloth. The application of the decision boundary derived from the training samples has been demonstrated to result in inconsistencies and inaccuracies.\nAs a significant number of real samples are excluded within the dataset, we propose a new method called Adapted Mixture of Experts (Adapted-MoE) to solve the above issue. Firstly, we use a pre-trained model on ImageNet, similar to (Roth et al. 2022; Liu et al. 2023; Lei et al. 2023), to extract feature embeddings based on the training dataset. To address the distribution of normal samples with various independent patterns, we introduced a Mixture of Expert models to deconstruct distinct distributions over the feature embeddings. A representation learning based Routing Network is proposed to route feature embeddings to expert models dedicated to discrimination. The proposed mixture of experts can learn multiple independent distributions of various normal subclasses and model several decision boundaries, eliminating the negative impact of constructing a single distribution for samples in the same category. In the testing process, we propose a Test-Time Adaption to calibrate with the distribution of unseen sample representation. Specifically, we assume that a random normal sample has a distribution with a certain pattern in the feature space. We leverage the mean and variance of the normal samples to unify the feature embeddings under the same distribution as the learned specific pattern before inputting them into the expert model via a normalization method. The major contributions of this paper are summarized as follows:\n\u2022 To our knowledge, our proposed Adapted-MoE firstly investigates the challenging problem of variation in the train set and bias between the train set and test set for anomaly detection.\n\u2022 We propose a MoE model for learning normal sample feature distribution for different subclasses. Moreover, we also designed a routing network based on representation learning to distinguish normal samples. A simple and effective test-time adaption is proposed to solve the unseen sample bias in the testing process.\n\u2022 We conduct extensive experiments to confirm the effectiveness of the Adapted-MoE on the new benchmark, called the Texture AD benchmark. This benchmark aggregates multiple samples of different patterns (e.g. different colors, different conditions of imaging) within the same category, which is much closer to the reality of the situation. The experimental results show that the proposed method significantly outperforms the previous state-of-the-art."}, {"title": "Related Works", "content": "With the rapid development of deep learning, most anomaly detection methods are divided into reconstructed-based and anomalous simulation-based models (Li, Zhu, and Van Leeuwen 2023; Liu et al. 2024).\nReconstruction-based approach. The reconstruction-based approaches assumed that anomalous samples cannot be correctly reconstructed by a feature learning method constructed based on normal samples(Cao et al. 2024). Early reconstructed-based methods used Auto-encoder network to construct the decision boundary by learning the low-dimensional features of normal images to obtain latent variables and reconstruct the normal samples using a decoder (Bergmann et al. 2019b; Baur et al. 2019; Mishra et al. 2021). As generative models have developed, some approaches have utilized generative adversarial networks (GANs)(Goodfellow et al. 2014) to improve the quality of reconstruction (Schlegl et al. 2017; Ak\u00e7ay, Atapour-Abarghouei, and Breckon 2019; Liang et al. 2023). Owing to the training instability of GANs, some methods combining auto-encoder networks and GANs have been proposed to better model normal samples (Zhou et al. 2020; Contreras-Cruz et al. 2023). Recently, diffusion models based methods have been widely used in anomaly detection tasks with their powerful generative ability (Mousakhan, Brox, and Tayyub 2023; Wu et al. 2024; Dai et al. 2024). Reconstruction-based methods rely exclusively on normal samples already present within the training set, ignoring the features of samples outside the training set. Therefore, the performance of such methods is greatly limited by the data quality of the normal samples as well as the learning ability of the reconstruction network.\nSynthesizing-based approach. The synthesizing-based approach considered the anomalous as noise, and after adding the synthesized defects to the normal samples, the network"}, {"title": "Method", "content": "The proposed Adapted MoE is elaborately introduced in this section. As shown in Figure 2, Adapted-MoE consists of a feature extractor, a routing network, test-time adaption, and several expert models. Specifically, We adopt fixed pre-trained CNNs on ImageNet(Deng et al. 2009) as the feature extractor. The features from several stages are collected. Then these features are resized to the same size and concatenated across channel dimensions to restructure the feature maps. Subsequently, the expert model with the highest correlation is assigned via the routing network. The test-time adaptation method is then employed to transfer the feature to the space that can be handled by the selected expert model. Finally, anomaly detection is achieved by the expert model.\nMixture of Experts\nMost anomaly detection methods construct the feature space based on normal samples. However, the feature distribution of normal samples in the same category is still diverse, and a single decision boundary will lead to an inaccurately determined outcome. Therefore, we propose a mixture expert model to divide normal samples from the same category into multiple expert models to learn the different feature distributions of multiple subclasses during the training process. Firstly, given the ith training sample's feature maps $X_i \\in R^{C \\times H \\times W}$ where C, H and W represent the channels, height and width of feature maps, feature embedding $X_i$ are firstly obtained by a projection layer and a global average pooling(GAP) layer $f^{GAP}$. The projection layer is composed of a 3 \u00d7 3 convolution $W_i, b_i$ to projection feature maps from ImageNet to the anomaly detection feature space:\n$X_i = f^{GAP}(\\theta(W_iX_i + b_i)) \\in R^C$ (1)\nInspired by (Wen et al. 2016), we classify m training samples using a designed center loss in our routing network.\n$L_{routing} = \\sum_{i=0}^{m} \\alpha||x_i - c_k||^2 - (1-\\alpha) y_i log(\\frac{e^{w^T x_i}}{\\sum_{new}})$ (2)\nwhere m represents the mini \u2013 batch in the training process, ck denotes the center of the kth subclass in the traning set and is updated per steps, $Y_i$ represents the subclass label for ith normal sample, n is the number of subclass in the training set and also the number of experts, w \u2208 RC\u00d7n is the classifier matrix and \u03b1 is weight adjustment parameter, with a value range of 0 to 1. As shown in Figure 3, the samples in the same subclasses are converged to the center of the subclasses by minimizing the above objective function, and the samples from different subclasses will be far away from each other in the feature space. During the inference process, Xi is routed to the expert model with maximize $x_i*c_k$ which denotes the cosine distance between xi and ck, and the final score will be calculated by the softmax function.\nAfter obtaining the feature embedding of the subclasses, we simply design a multi-layer perceptron as an expert model to construct decision boundary for independent subclass. We use feature embedding to randomly generate noise vectors and train expert models based on synthetic anomaly detection methods and the loss of expert $L_{expert}$ same as (Liu et al. 2023). The total loss $L_{total}$ is described by:\n$L_{total} = L_{routing} + \\sum_{i=1}^{m} L_{expert}^i$ (3)\nUltimately, the final anomaly detection score is obtained by aggregating the results of multiple expert models as follows:\n$result = \\frac{\\sum_{k} w_i x_{test}Expert(x_{test})}{\\sum_{k} w_i x_{test}}$ (4)\nNormalization. It is worth emphasizing that due to the similarity of the anomaly detection samples, the feature distribution of the different subclasses that are projected into the feature space is not uniform (Reiss and Hoshen 2023). Therefore, we adopt the normalization to constrain the value range of the feature embedding xi. It effectively separates the feature of different subclasses so that they can be more evenly distributed in the feature space, which can be expressed as $x_i = $. As mentioned above, the routing network is scored by cosine similarity and softmax of the classifier matrix w and feature embedding xi. Benefiting from the monotonicity of softmax, the normalized feature embedding does not affect the routing score.\nXi"}, {"title": "Test-Time Adaption", "content": "Existing methods construct feature spaces and decision boundaries based on normal samples making unseen samples considered anomalies which makes many out-of-distribution subclass samples misclassified. Based on our proposed MoE, the normal sample in the same category is divided into multiple subclasses routed to different expert models to construct independent decision boundary. However, as shown in Figure 4, the feature space learned by the expert model based on the existing training set still suffers from a bias in the feature distribution of the unseen subclasses. We assume that the feature distributions of the unseen subclasses have a certain feature distribution in feature space. Thus their decision boundaries can be obtained by simply eliminating the inconsistency of the feature distributions in the inference process. In this paper, we define this bias as distribution distance and propose a test-time adaption method to eliminate the bias between unseen samples and training samples.\nFirstly, given the feature embedding $X_{test}$ of the test sample, the closest subclass center embedding $c_k$ of the test sample in the feature space can be found by the routing network. As shown in Figure 4, the test sample distribution and the learned distribution are similar but have a distance gap. Since the kth expert model is based on training data with center ck and standard deviation which is denoted as std to construct the decision boundary. Therefore, we calibrate the distribution of test embeddings $X_{test}$ to the feature space of the kth expert model to unify the decision boundary:\n$X'_{test} = \\frac{(X_{test} \u2013 mean(x_{test})) \\times std}{std(x_{test})} + C_k$ (5)\n$X''_{test} = \\frac{X'_{test}}{|| X'_{test} ||}$ (6)"}, {"title": "Experiments", "content": "We use the center of the training data to make the feature distributions with the same measure by mean and variance and subsequently normalize the corrected embeddings to obtain the final decision boundary.\nDatasets and Metrics\nDatasets. As shown in Figure 1, existing datasets sampling data are similarly distributed in the same category (e.g., MVTec (Bergmann et al. 2019a)). To validate the proposed Adapted-MoE, we use a new dataset named Texture AD benchmark(Texture-ad 2024) in the experiments. The Texture AD benchmark is an anomaly detection dataset, which contains sampled images and defect annotations for three categories, cloth, metal, and wafer. Significantly, the Texture AD dataset provides multiple different types in subclasses under each category providing samples of various distributions. In the cloth, it provides 15 different subclasses of cloth to represent different distributions. There are 14 different wafer types included in the wafer category. In the metal category, 10 different types of metal are likewise provided to validate the anomaly detection for different distributions. To validate our method, we choose 10 subclasses for training and 5 unseen subclasses for testing in the cloth dataset, 4 unseen subclasses in the wafer dataset and 3 unseen subclasses in the metal dataset. All images in this dataset are captured using a high-resolution industrial camera (MV-CS200-10 GC) at 5472 \u00d7 3648 pixels and cropped to 1024 \u00d7 1024.\nMetrics. For anomaly detection results, we use the Area Under the Receiver Operating Curve (AUROC) to evaluate our proposed model comprehensively same as other works. Image-level anomaly detection performance is measured via the standard AUROC, denoted as I-AUROC. Moreover, a pixel-level AUROC (P-AUROC) is used to evaluate the anomaly localization.\nImplementation Details\nAll experiment codes are implemented based on the Py-torch framework and all the models are trained with one NVIDIA GeForce RTX 4080 (16 GB memory) for acceleration. We validated the effectiveness of the Adapted-MOE using SimpleNet(Liu et al. 2023) as our baseline. For the baseline, a pre-trained WideResNet50(Zagoruyko and Komodakis 2016) is used already as a feature extractor which is frozen in both training and testing processes. For fair comparisons, the SimpleNet with Adapted-MoE is trained for 160 epochs with a batch size of 8 and the learning rate is from 0.0001 to 0.0002. In Gaussian noise N(0, \u03c3\u00b2), \u03c3 is set by default to 0.015. All experimental results are the mean of 3 replicates.\nComparisons with State-Of-The-Arts\nWe compare the proposed Adapted-MoE with a number of state-of-the-art approaches on Texture AD benchmark, including SimpleNet(Liu et al. 2023), EfficientAD(Batzner, Heckler, and K\u00f6nig 2024), PyramidFlow(Lei et al. 2023), DREAM(Zavrtanik, Kristan, and Sko\u010daj 2021a), Mean-shifted (Reiss and Hoshen 2023) and MSFlow(Zhou et al. 2024). Firstly, we compared the performance of anomaly detection. Since current methods lack consideration of unseen subclasses for testing, our algorithm demonstrates superior performance. As shown in Table 1, excellent results are achieved by our Adapted-MoE on most of the unseen subclasses in three categories. Moreover, our proposed method outperforms other methods in average I-AUROC accuracy on the test set of cloth, wafer, and metal by 67.53%, 58.58%, and 66.12%, respectively. To further demonstrate the excellence of our method, we secondly compare the capability of anomaly localization on novel unseen data. As shown in Table 2, we compare the values of P-AUROC with state-of-the-art methods on three categories in Texture AD. The results show that our method outperforms existing methods in unseen subclass performance for each category as well as average accuracy. The average P-AUROC of our proposed method is 76.05%, 63.40%, and 73.76% for cloth, wafer, and metal. The results of visualization compared with SOTA are detailed in the Appendix.\nAblation Studies\nIn this section, we present ablation studies on the proposed method, including the structure of Adapted-MoE, the top k"}, {"title": "Choice of Loss Function in Routing Network", "content": "the small scale of variation within the same category of data, the loss function determines for routing networks whether they can better distinguish between different subclasses. We compared the effect of softmax loss and center loss on the average performance of the three categories of datasets, as shown in Table 4. The results show that center loss can better improve the performance of the routing network. This demonstrates that the addition of a centroid constraint can lead to a more explicit subclass space delineation.\nConclusion\nIn this paper, we propose an Adapted-MoE for addressing the data variation and bias in the same category for anomaly detection. We define the issue of the variation of feature distribution within the training data in the real world leading to failure of the single decision boundary. Furthermore, we address the challenge of bias between the test and training data. We propose a Mixture of Experts that divides same-category samples into different feature spaces via a routing network, with each expert model constructing its own independent decision boundary. We use normalization to make the samples more uniformly distributed in the feature space. In addition, we propose a Test-Time Adaption to eliminate the bias between the distribution of test samples and learned features. Extensive experiments on Texture AD demonstrate that Adapted-MoE can be simply and efficiently implemented for anomaly detection and localization.\nLimitation. This paper proposes a MoE for constructing multiple independent subclass decision boundaries. When using a dataset with a low diversity of subclasses, the performance improvement from MoE is lower than without MoE (9.24% \u2191 to 13.90%\u2191) due to over-division being redundant. In addition, an overly complex expert model design will trigger overfitting in subclass learning. Therefore, the improvement effect is more limited to algorithms with a large number of parameters. In the future, we will focus on solving the overfitting problem caused by model complexity and data mismatch, aiming for greater improvements in more complex models (You et al. 2022; Zhou et al. 2023)."}]}