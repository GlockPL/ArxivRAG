{"title": "CoopASD: Cooperative Machine Anomalous Sound Detection with Privacy Concerns", "authors": ["Anbai Jiang", "Yuchen Shi", "Pingyi Fan", "Wei-Qiang Zhang", "Jia Liu"], "abstract": "Machine anomalous sound detection (ASD) has emerged as one of the most promising applications in the Industrial Internet of Things (IIoT) due to its unprecedented efficacy in mitigating risks of malfunctions and promoting production efficiency. Previous works mainly investigated the machine ASD task under centralized settings. However, developing the ASD system under decentralized settings is crucial in practice, since the machine data are dispersed in various factories and the data should not be explicitly shared due to privacy concerns. To enable these factories to cooperatively develop a scalable ASD model while preserving their privacy, we propose a novel framework named CoopASD, where each factory trains an ASD model on its local dataset, and a central server aggregates these local models periodically. We employ a pre-trained model as the backbone of the ASD model to improve its robustness and develop specialized techniques to stabilize the model under a completely non-iid and domain shift setting. Compared with previous state-of-the-art (SOTA) models trained in centralized settings, CoopASD showcases competitive results with negligible degradation of 0.08%. We also conduct extensive ablation studies to demonstrate the effectiveness of CoopASD.", "sections": [{"title": "I. INTRODUCTION", "content": "The Industrial Internet of Things (IIoT) is a specialized form of the Internet of Things (IoT) for industrial applications, which has emerged as a driving force for the evolution of conventional manufacturing into a digital era. The key idea of IIoT is to harness the power of big data for advanced automation and optimization, by seamlessly integrating data collection, data transmission, and data analysis in an automated pipeline, where the infrastructure of IoT paves the way for reliable data collection and transmission, and machine learning (ML) algorithms enable it to extract valuable insights from massive volumes of production data, bringing forth unprecedented opportunities for downstream applications.\nMachine anomalous sound detection (ASD) is one of the most emerging tasks in IIoT, which seeks to detect machine malfunctions when only audio of normal working status is provided. Compared with fault detection tasks, the ASD task emphasizes the absence of labeled anomalies for training, which is more applicable in real production sites, since recorded malfunctions are scarce and are commonly used as validation for detection models, while data of normal working status can be readily collected. A well-performing machine ASD model is sure to significantly enhance operational efficiency, minimize downtime, and mitigate risks associated with machine failures and malfunctions.\nThe machine ASD task has been widely studied under centralized settings in recent years [1]-[7], where machine data are first aggregated on a central server before training the ASD model. However, the centralized paradigm may not be directly applicable in real scenarios, especially for small-scale factories with a limited number of machines. In common scenarios, each factory keeps a local dataset consisting of normal machine audio and minor anomalous audio, where the anomalies are only used for validation. For each of these factories, neither the quality of the training data nor the number of labeled anomalies is sufficient to develop a scalable ASD model, and the ASD model will be easily overfitted if it is built only on the local dataset. On the other hand, if these factories opt to cooperate with each other and leverage all available data, they are still capable of developing a well-performing and scalable ASD system, since both the diversity of the training data and the robustness of the validation data are improved through cooperation.\nNevertheless, training a unified ASD model in decentralized settings incurs two critical issues:\n1) Non-iid data. The machine types will likely vary across different factories, although the intrinsic patterns of all possible malfunctions may be similar in semantics.\n2) Data privacy. Business secrets such as parameter settings and production schedules can be readily inferred from the machine data. Thus the machine data should not be shared across factories.\nTo tackle these problems, we propose CoopASD, a novel framework that seeks to develop a unified and well-performing machine ASD model for dozens of small factories via co-operation while preserving privacy. CoopASD follows the architecture of FedAvg [8], where factories are considered as local clients and a central server aggregates all local updates. In the proposed scheme, each factory trains a local ASD model on its own dataset and periodically uploads the local model to the central server, while the central server aggregates these local models, updates the global model and broadcasts the updated global model to factories. The local training process is similar to the training processes in centralized settings [1]. To alleviate the convergence problem induced by the non-iid data and the overfitting problem induced by the absence of"}, {"title": "II. RELATED WORK", "content": "A typical ASD model can be decomposed into a feature extractor and an anomaly detector, where the feature extractor extracts semantic representations of the machine audio, and the anomaly detector processes the audio representation and outputs a high anomaly score if it is anomalous. Models can be roughly divided into feature-centric models and anomaly-centric models depending on the emphasis.\nFeature-centric models aim to extract semantic-rich and robust representations for machine audio, while adopting shallow anomaly detectors, such as Gaussian mixture model (GMM) and k-nearest neighbor (KNN) [12]. Liu et al. [6] proposed STgram which trains a dual path network to extract features from two perspectives. Zhang et al. [3] extended the STgram by employing three sub-networks to extract features from four hierarchies. Wilkinghoff et al. [2] utilized the inner consistency of two sub-networks to derive robust representa-tions. Han et al. [1] explored the usage of large pre-trained models for ASD.\nAnomaly-centric models explore novel ML-based anomaly detectors where the audio representations are often spectro-grams. Autoencoder [9] detects anomalies by the reconstruc-tion error of spectrograms, where anomalies are expected to have bigger reconstruction error after training the network on normal spectrograms. Jiang et al. [5] addressed the denoising problem of autoencoder by introducing a discriminator to provide more reliable gradients. Besides the autoencoder, flow model [13] learns the distribution of normal audio representa-tions and predicts the likelihood of each audio clip."}, {"title": "III. PROPOSED METHOD", "content": "This section introduces CoopASD in a bottom-up order."}, {"title": "A. ASD Model", "content": "The ASD model of factory $i$ consists of a feature extractor $f(\\cdot)$ and an anomaly detector $g_i(\\cdot)$, where $f(\\cdot)$ is shared across factories and $g_i(\\cdot)$ is constructed locally. Fig. 1 presents the general structure of the ASD model. For each normal recording $x_j$ from the local dataset of factory $i$, it is first converted to a log-mel spectrogram, then sent to the feature extractor $f(\\cdot)$. SpecAug [16] is applied to the spectrogram which masks a portion of the spectrogram to improve the robustness. The feature extractor $f(\\cdot)$ adopts a ViT [17] backbone, which splits the spectrogram into patches, encodes each patch as an embedding by a linear layer, and processes them by stacks of Transformer [18] blocks, outputting a series of patch features. An attentive statistical pooling layer [19] is appended to the ViT backbone to fuse these patch features into an utterance embedding $u_j$, and a linear layer is employed to map $u_j$ to a low-dimensional detection embedding $y_j$, which is further processed by the anomaly detector $g_i(\\cdot)$. To improve the robustness, the ViT backbone is initialized from BEATs [20], a pre-trained ViT model for audio classification.\nThe anomaly detector $g_i(\\cdot)$ of factory $i$ is a simple KNN detector. A local memory bank $M_i$ of factory $i$ is first set up by the embeddings of the local training dataset $D_i^{\\text{train}}$.\n$M_i = \\{ y_j = f(x_j) \\mid x_j \\in D_i^{\\text{train}} \\}$\nSince $D_i^{\\text{train}}$ only consists of normal audio, $M_i$ serves as a set of normality templates in the feature space. For each query embedding $y_q = f(x_q)$ of the local test dataset $D_i^{\\text{test}}$, $g_i(\\cdot)$ infers a subset $N_{i,q}^{(k)}$ of $M_i$, which consists of the top-$k$ closest embeddings of $M_i$ to $y_q$:\n$N_{i,q}^{(k)} = \\underset{\\substack{N \\subset M_i, \\|N\\|=k}}{\\text{arg min}} \\sum_{y_j \\in N} \\frac{y_j^T y_q}{\\|y_j\\|_2 \\|y_q\\|_2}$\nwhere cosine distance is adopted as the distance metric. The anomaly score is defined as the mean distance of $N_{i,q}^{(k)}$ to $y_q$:\n$g_i(y_q) = \\frac{1}{k} \\sum_{y_j \\in N_{i,q}^{(k)}} \\left( 1 - \\frac{y_j^T y_q}{\\|y_j\\|_2 \\|y_q\\|_2} \\right)$"}, {"title": "B. Local Training Process", "content": "Each factory trains an ASD model on its own dataset and periodically uploads the local model to the central server. Since labeled anomalies are not provided for training, the ASD model is trained by classifying the attributes of machine working conditions, such as speed, operation voltage and rotation velocity. These attributes are handy for collection, and each unique combination of attributes is considered a new label. A simple linear classifier $c_i(\\cdot)$ is appended to the feature extractor $f(\\cdot)$ for each factory $i$, which maps the output of $f(\\cdot)$ to the local class labels. Since attributes of different factories are completely different, the linear classifier $c_i(\\cdot)$ only predicts all locally available labels of $D_i^{\\text{train}}$ and is not uploaded to the central server.\nSince the number of available attributes is always limited for each factory, the model can easily predict these attributes after quick adaptation. To further enforce the classification task, ArcFace loss [21] is adopted in CoopASD instead of cross-entropy loss, which further restricts the decision zones:"}, {"title": "C. Global Aggregation Process", "content": "Following the framework of FedAvg [8], CoopASD trains the ASD model in a decentralized setting, by alternating between the local training processes of factories and the global aggregation process of the central server. However, directly applying vanilla FedAvg for the machine ASD task yields unsatisfactory results, which is due to the convergence problem induced by the completely non-iid data and the overfitting problem induced by the absence of labeled anomalies for training. As introduced in Section III-B, the ASD model is trained by classifying machine attributes. On the one hand, since each factory has a unique machine type, the problem is completely non-iid, where not only the machine audio but also the attributes are completely different for each factory. This incurs a severe convergence problem for the ASD model. On the other hand, as depicted in Fig. 2, the classification accuracy of machine attributes is not a valid indicator of ASD performance, and the ASD model can be easily overfitted (in most cases) or underfitted. This calls for a delicate scheduler for the alternation between the local training processes and the global aggregation process."}, {"title": "IV. EXPERIMENT", "content": "The experiment is conducted on the dataset of DCASE 2023 Task 2, a dedicated machine ASD dataset with 14 machine types. The dataset can be divided into a development set and an evaluation set, each of which consists of 7 machine types. For each machine type, the training set consists of 1000 normal clips, while the test set contains 100 normal clips and 100 anomalous clips. Each training clip is accompanied by multiple attributes of the working conditions, which are utilized as the labels of the deputy task. The experiment is conducted in a completely non-iid and domain shift setting, where each factory corresponds to a unique machine type, resulting in 14 factories. The performance is measured by the area under the receiver operating characteristic (ROC) curve (AUC) and the partial-AUC (pAUC) following the challenge rules [9]. We report the harmonic mean of all AUC and pAUC for each machine type, and a harmonic mean of the whole dataset.\nIt is noted that the DCASE 2023 dataset also features domain shift, where the 1000 normal clips of each machine type can be further divided into 990 clips from a source domain and 10 clips from a target domain. However, the domain shift problem is not discussed in the proposed scheme."}, {"title": "V. CONCLUSION", "content": "In this paper, we proposed CoopASD, a decentralized ASD framework that allows factories to cooperatively train a robust ASD model while preserving privacy. CoopASD is built on a powerful ASD model that leverages a pre-trained ViT back-bone and is trained by alternating between the local training processes of factories and the global aggregation process of the central server. The experiment under a completely non-iid and domain shift setting demonstrated the effectiveness and the generalization capability of CoopASD. Our future work will focus on reducing the number of trainable parameters and analyzing the convergence of the ASD model theoretically."}]}