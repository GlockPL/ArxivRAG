{"title": "CoopASD: Cooperative Machine Anomalous Sound Detection with Privacy Concerns", "authors": ["Anbai Jiang", "Yuchen Shi", "Pingyi Fan", "Wei-Qiang Zhang", "Jia Liu"], "abstract": "Machine anomalous sound detection (ASD) has emerged as one of the most promising applications in the Industrial Internet of Things (IIoT) due to its unprecedented efficacy in mitigating risks of malfunctions and promoting production efficiency. Previous works mainly investigated the machine ASD task under centralized settings. However, developing the ASD system under decentralized settings is crucial in practice, since the machine data are dispersed in various factories and the data should not be explicitly shared due to privacy concerns. To enable these factories to cooperatively develop a scalable ASD model while preserving their privacy, we propose a novel framework named CoopASD, where each factory trains an ASD model on its local dataset, and a central server aggregates these local models periodically. We employ a pre-trained model as the backbone of the ASD model to improve its robustness and develop specialized techniques to stabilize the model under a completely non-iid and domain shift setting. Compared with previous state-of-the-art (SOTA) models trained in centralized settings, CoopASD showcases competitive results with negligible degradation of 0.08%. We also conduct extensive ablation studies to demonstrate the effectiveness of CoopASD.", "sections": [{"title": "I. INTRODUCTION", "content": "The Industrial Internet of Things (IIoT) is a specialized form of the Internet of Things (IoT) for industrial applications, which has emerged as a driving force for the evolution of conventional manufacturing into a digital era. The key idea of IIoT is to harness the power of big data for advanced automation and optimization, by seamlessly integrating data collection, data transmission, and data analysis in an automated pipeline, where the infrastructure of IoT paves the way for reliable data collection and transmission, and machine learning (ML) algorithms enable it to extract valuable insights from massive volumes of production data, bringing forth unprecedented opportunities for downstream applications.\nMachine anomalous sound detection (ASD) is one of the most emerging tasks in IIoT, which seeks to detect machine malfunctions when only audio of normal working status is provided. Compared with fault detection tasks, the ASD task emphasizes the absence of labeled anomalies for training, which is more applicable in real production sites, since recorded malfunctions are scarce and are commonly used as validation for detection models, while data of normal working status can be readily collected. A well-performing machine ASD model is sure to significantly enhance operational efficiency, minimize downtime, and mitigate risks associated with machine failures and malfunctions.\nThe machine ASD task has been widely studied under centralized settings in recent years [1]\u2013[7], where machine data are first aggregated on a central server before training the ASD model. However, the centralized paradigm may not be directly applicable in real scenarios, especially for small-scale factories with a limited number of machines. In common scenarios, each factory keeps a local dataset consisting of normal machine audio and minor anomalous audio, where the anomalies are only used for validation. For each of these factories, neither the quality of the training data nor the number of labeled anomalies is sufficient to develop a scalable ASD model, and the ASD model will be easily overfitted if it is built only on the local dataset. On the other hand, if these factories opt to cooperate with each other and leverage all available data, they are still capable of developing a well-performing and scalable ASD system, since both the diversity of the training data and the robustness of the validation data are improved through cooperation.\nNevertheless, training a unified ASD model in decentralized settings incurs two critical issues:\n1) Non-iid data. The machine types will likely vary across different factories, although the intrinsic patterns of all possible malfunctions may be similar in semantics.\n2) Data privacy. Business secrets such as parameter settings and production schedules can be readily inferred from the machine data. Thus the machine data should not be shared across factories.\nTo tackle these problems, we propose CoopASD, a novel framework that seeks to develop a unified and well-performing machine ASD model for dozens of small factories via co-operation while preserving privacy. CoopASD follows the architecture of FedAvg [8], where factories are considered as local clients and a central server aggregates all local updates. In the proposed scheme, each factory trains a local ASD model on its own dataset and periodically uploads the local model to the central server, while the central server aggregates these local models, updates the global model and broadcasts the updated global model to factories. The local training process is similar to the training processes in centralized settings [1]. To alleviate the convergence problem induced by the non-iid data and the overfitting problem induced by the absence of labeled anomalies, three regularization methods are adopted in the local training process, namely sampling, selective upload and early stop. It is noted that machine data are not transferred between factories in both the training and inference stages, thus preventing privacy leakage.\nThe experiment is conducted on the dataset of DCASE 2023 Task 2 [9] in a completely non-iid and domain shift setting, where each factory has a unique machine type. CoopASD demonstrates competitive results on all 14 machine types, with minor degradation of 0.08% compared with the state-of-the-art (SOTA) models in centralized settings [1]\u2013[3], [10], [11]. We also conduct extensive ablation studies to showcase the efficacy of the modifications. To the best of our knowledge, we are the first to explore the machine ASD task under decentralized settings.\nThe main contributions of CoopASD can be summarized:\n1) We propose CoopASD, a novel framework that enables factories to cooperatively develop a unified ASD model when no anomalies are presented for training.\n2) CoopASD combines the machine data and computation resources of all factories while preserving privacy.\n3) Regularization methods are adopted to stabilize CoopASD, enabling it to converge in a completely non-iid and domain shift setting.\n4) The performance of CoopASD is comparable with SOTA models under centralized settings with minor degradation of 0.08%."}, {"title": "II. RELATED WORK", "content": "A typical ASD model can be decomposed into a feature extractor and an anomaly detector, where the feature extractor extracts semantic representations of the machine audio, and the anomaly detector processes the audio representation and outputs a high anomaly score if it is anomalous. Models can be roughly divided into feature-centric models and anomaly-centric models depending on the emphasis.\nFeature-centric models aim to extract semantic-rich and robust representations for machine audio, while adopting shallow anomaly detectors, such as Gaussian mixture model (GMM) and k-nearest neighbor (KNN) [12]. Liu et al. [6] proposed STgram which trains a dual path network to extract features from two perspectives. Zhang et al. [3] extended the STgram by employing three sub-networks to extract features from four hierarchies. Wilkinghoff et al. [2] utilized the inner consistency of two sub-networks to derive robust representa-tions. Han et al. [1] explored the usage of large pre-trained models for ASD.\nAnomaly-centric models explore novel ML-based anomaly detectors where the audio representations are often spectro-grams. Autoencoder [9] detects anomalies by the reconstruc-tion error of spectrograms, where anomalies are expected to have bigger reconstruction error after training the network on normal spectrograms. Jiang et al. [5] addressed the denoising problem of autoencoder by introducing a discriminator to provide more reliable gradients. Besides the autoencoder, flow model [13] learns the distribution of normal audio representa-tions and predicts the likelihood of each audio clip."}, {"title": "B. Anomaly Detection in Decentralized Settings", "content": "Multiple anomaly detection approaches have been proposed under the framework of federated learning (FL). Li et al. [14] detected malicious clients of a FL system by reconstructing the local model weights updates. Nguyen et al. [15] pro-posed DioT which monitors the packet transmission of an IoT network and detects malicious devices, by modeling the likelihood of the packet sequence."}, {"title": "III. PROPOSED METHOD", "content": "This section introduces CoopASD in a bottom-up order."}, {"title": "A. ASD Model", "content": "The ASD model of factory i consists of a feature extractor f(\u00b7) and an anomaly detector gi(\u00b7), where f(\u00b7) is shared across factories and gi() is constructed locally. Fig. 1 presents the general structure of the ASD model. For each normal recording xj from the local dataset of factory i, it is first converted to a log-mel spectrogram, then sent to the feature extractor f(.). SpecAug [16] is applied to the spectrogram which masks a portion of the spectrogram to improve the robustness. The feature extractor f(.) adopts a ViT [17] backbone, which splits the spectrogram into patches, encodes each patch as an embedding by a linear layer, and processes them by stacks of Transformer [18] blocks, outputting a series of patch features. An attentive statistical pooling layer [19] is appended to the ViT backbone to fuse these patch features into an utterance embedding uj, and a linear layer is employed to map uj to a low-dimensional detection embedding yj, which is further processed by the anomaly detector gi(.). To improve the robustness, the ViT backbone is initialized from BEATs [20], a pre-trained ViT model for audio classification.\nThe anomaly detector gi(\u00b7) of factory i is a simple KNN detector. A local memory bank Mi of factory i is first set up by the embeddings of the local training dataset Dtrain.\n\nMi = {yj = f(xj) | x j\u2208Dtrain} \\tag{1}"}, {"title": "B. Local Training Process", "content": "Each factory trains an ASD model on its own dataset and periodically uploads the local model to the central server. Since labeled anomalies are not provided for training, the ASD model is trained by classifying the attributes of machine working conditions, such as speed, operation voltage and rotation velocity. These attributes are handy for collection, and each unique combination of attributes is considered a new label. A simple linear classifier ci(\u00b7) is appended to the feature extractor f(\u00b7) for each factory i, which maps the output of f(\u00b7) to the local class labels. Since attributes of different factories are completely different, the linear classifier ci(\u00b7) only predicts all locally available labels of Drain and is not uploaded to the central server.\nSince the number of available attributes is always limited for each factory, the model can easily predict these attributes after quick adaptation. To further enforce the classification task, ArcFace loss [21] is adopted in CoopASD instead of cross-entropy loss, which further restricts the decision zones:\n\nL =\\frac{1}{N} \\sum_{j=1}^{N}  log(\\frac{e^{s \\cdot cos(\\theta_{l_{j}}+m)}}}{\\sum_{c=1,c\\neq l_{j}}^{C_{i}}e^{s \\cdot cos(\\theta_{c})}+e^{s \\cdot cos(\\theta_{l_{j}}+m)}})  \\tag{4}\n\nwhere lj is the label of yj, Ci is the number of classes of Diest, and s and m are two hyperparameters that constrain the decision zones. \u03b8 is the angle between yj and the registered embedding of the c-th class, which is the c-th column of the weight W of the linear classifier ci(\u00b7):\n\\theta_{c} = arccos(\\frac{W^{T}y_{j}}{||W_{c}||_{2} ||y_{j}||_{2}}) \\tag{5}"}, {"title": "C. Global Aggregation Process", "content": "Following the framework of FedAvg [8], CoopASD trains the ASD model in a decentralized setting, by alternating between the local training processes of factories and the global aggregation process of the central server. However, directly applying vanilla FedAvg for the machine ASD task yields unsatisfactory results, which is due to the convergence problem induced by the completely non-iid data and the overfitting problem induced by the absence of labeled anomalies for training. As introduced in Section III-B, the ASD model is trained by classifying machine attributes. On the one hand, since each factory has a unique machine type, the problem is completely non-iid, where not only the machine audio but also the attributes are completely different for each factory. This incurs a severe convergence problem for the ASD model. On the other hand, as depicted in Fig. 2, the classification accuracy of machine attributes is not a valid indicator of ASD performance, and the ASD model can be easily overfitted (in most cases) or underfitted. This calls for a delicate scheduler for the alternation between the local training processes and the global aggregation process."}, {"title": "IV. EXPERIMENT", "content": "The experiment is conducted on the dataset of DCASE 2023 Task 2, a dedicated machine ASD dataset with 14 machine types. The dataset can be divided into a development set and an evaluation set, each of which consists of 7 machine types. For each machine type, the training set consists of 1000 normal clips, while the test set contains 100 normal clips and 100 anomalous clips. Each training clip is accompanied by multiple attributes of the working conditions, which are utilized as the labels of the deputy task. The experiment is conducted in a completely non-iid and domain shift setting, where each factory corresponds to a unique machine type, resulting in 14 factories. The performance is measured by the area under the receiver operating characteristic (ROC) curve (AUC) and the partial-AUC (pAUC) following the challenge rules [9]. We report the harmonic mean of all AUC and pAUC for each machine type, and a harmonic mean of the whole dataset.\nIt is noted that the DCASE 2023 dataset also features domain shift, where the 1000 normal clips of each machine type can be further divided into 990 clips from a source domain and 10 clips from a target domain. However, the domain shift problem is not discussed in the proposed scheme."}, {"title": "D. Ablation Study", "content": "1) Centralized versus Decentralized: The competitive per-formance of CoopASD can be attributed to both the power-ful ASD model and the well-designed iterative scheme. To showcase the efficacy of the two contributions respectively, CoopASD is compared with the same ASD model trained under a centralized setting, which is demonstrated in Table II. Compared with Table I, the centralized ASD model is 1.14% better than previous ASD models, while switching to a decen-tralized setting only incurs degradation of 1.22%.\n2) Regularization Methods: Compared with FedAvg, three techniques are adopted in CoopASD to improve ASD per-formance, namely sampling, selective upload and early stop. Table III validates the effectiveness of the proposed techniques, where the performance gradually increases from 64.81% to 67.65% when applying the proposed techniques progressively. This proves the efficacy of the techniques.\n3) Cooperative versus Solo: Table IV compares the results of cooperative training and solo training, where solo training means each factory trains the model individually. Cooper-ative training yields a slightly better ASD model with an improvement of 0.15%, which is probably due to the improved diversity of the training data and the underlying similarity of different malfunctions. More importantly, the ASD model obtained by cooperative training is much more robust, since it is unified and has been validated on multiple test sets. Therefore, factories are more willing to develop a unified ASD system through cooperation."}, {"title": "E. Sampling Probability", "content": "Fig. 4 compares different sampling probability p, where bigger probability generally yields consistently better results, and the best result is achieved when p = 0.5."}, {"title": "V. CONCLUSION", "content": "In this paper, we proposed CoopASD, a decentralized ASD framework that allows factories to cooperatively train a robust ASD model while preserving privacy. CoopASD is built on a powerful ASD model that leverages a pre-trained ViT back-bone and is trained by alternating between the local training processes of factories and the global aggregation process of the central server. The experiment under a completely non-iid and domain shift setting demonstrated the effectiveness and the generalization capability of CoopASD. Our future work will focus on reducing the number of trainable parameters and analyzing the convergence of the ASD model theoretically."}]}