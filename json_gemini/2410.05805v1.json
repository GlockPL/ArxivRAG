{"title": "POSTCAST: GENERALIZABLE POSTPROCESSING FOR\nPRECIPITATION NOWCASTING VIA UNSUPERVISED\nBLURRINESS MODELING", "authors": ["Junchao Gong", "Siwei Tu", "Weidong Yang", "Ben Fei", "Kun Chen", "Wenlong Zhang", "Xiaokang Yang", "Wanli Ouyang", "Lei Bai"], "abstract": "Precipitation nowcasting plays a pivotal role in socioeconomic sectors, espe-\ncially in severe convective weather warnings. Although notable progress has been\nachieved by approaches mining the spatiotemporal correlations with deep learn-\ning, these methods still suffer severe blurriness as the lead time increases, which\nhampers accurate predictions for extreme precipitation. To alleviate blurriness,\nresearchers explore generative methods conditioned on blurry predictions. How-\never, the pairs of blurry predictions and corresponding ground truth need to be\ngenerated in advance, making the training pipeline cumbersome and limiting the\ngenerality of generative models within blur modes that appear in training data. By\nrethinking the blurriness in precipitation nowcasting as a blur kernel acting on pre-\ndictions, we propose an unsupervised postprocessing method to eliminate the blur-\nriness without the requirement of training with the pairs of blurry predictions and\ncorresponding ground truth. Specifically, we utilize blurry predictions to guide the\ngeneration process of a pre-trained unconditional denoising diffusion probabilis-\ntic model (DDPM) to obtain high-fidelity predictions with eliminated blurriness.\nA zero-shot blur kernel estimation mechanism and an auto-scale denoise guid-\nance strategy are introduced to adapt the unconditional DDPM to any blurriness\nmodes varying from datasets and lead times in precipitation nowcasting. Exten-\nsive experiments are conducted on 7 precipitation radar datasets, demonstrating\nthe generality and superiority of our method.", "sections": [{"title": "INTRODUCTION", "content": "Precipitation nowcasting, which mostly depends on radar echo data, plays a vital role in predicting\nlocal weather conditions for up to six hours (CLIMA & TE). Accurately predicting precipitation\nevents is one of the core tasks in weather prediction. It could mitigate the socioeconomic impacts of\nextreme precipitation events and serve as a critical tool for transportation management, agricultural\nproductivity, and other aspects. Hence, many excellent methods have been proposed in recent years.\nTraditional methods for radar-based precipitation nowcasting rely on statistical models and physi-\ncal assumptions (del Moral et al., 2018; Woo & Wong, 2017). Although these methods have the\nadvantage of computational efficiency and high explainability, the chaotic and nonlinear nature of\nshort-term precipitation means that the various physical and statistical assumptions introduced in tra-\nditional methods have inherent limitations. These methods are only suitable for cases with smooth\nand simple motion patterns over short periods. Therefore, researchers explore the use of deep learn-\ning to mine the spatiotemporal correlations in precipitation nowcasting. These methods treat precip-\nitation as a task of spatiotemporal prediction, predicting future radar echoes given the sequence of\nhistorical observations. By designing modules to better model the spatiotemporal dynamics in pre-\ncipitation nowcasting, many attempts have provided solid improvements in the evaluation of Critical\nSuccess Index (CSI) (Shi et al., 2015; Wang et al., 2022; Gao et al., 2022b;a). However, they often"}, {"title": "RELATED WORK", "content": null}, {"title": "PRECIPITATION NOWCASTING", "content": "Notable progress has been achieved by applying deep learning in precipitation nowcasting (Chen\net al., 2023; Han et al., 2024b; Xu et al., 2024; Han et al., 2024a; Gong et al., 2024). The ini-\ntial attempts are deterministic methods focusing on spatiotemporal modeling. Researchers explore\ndifferent spatiotemporal modelling structures such as RNN (Shi et al., 2015; Wang et al., 2022),\nCNN (Gao et al., 2022a; Tan et al., 2023), and Transformer (Gao et al., 2022b). However, these\nmethods have a shortage of blurry predictions, which hamper the nowcasting of extreme events.\nProbabilistic methods are proposed to alleviate blurriness (Ravuri et al., 2021; Gao et al., 2024;\nZhao et al., 2024). To further enhance precipitation nowcasting with accurate global movements,\nlater methods combine blurry predictions with probabilistic models. DiffCast (Yu et al., 2024),\nand CasCast (Gong et al.) exploit how to generate small-scale weather pattern conditioning on the\nblurry predictions. Although these deterministic-probabilistic coupling methods achieve both global\naccuracy and local details, they suffer from repeating training for different contexts and require\nblurry predictions as data for training. From the perspective of deblur, Our method is proposed\nto simplify the complex training process and enhance the generality for wide use in different\ncontexts."}, {"title": "IMAGE DEBLUR WITH DIFFUSION MODELS", "content": "Diffusion-based models have been widely investigated in image deblurring tasks since it is capable\nof generating high-quality clean images (Song & Ermon, 2019; Ho et al., 2020; Song & Ermon,\n2020; Fei et al., 2023). As a pioneering work, a U-Net architecture is trained in (Ho et al., 2020)\nwith a denoising objective to iteratively refine the generated image starting from pure Gaussian\nnoise. For instance, Austin et al. (2021) introduced Discrete Denoising Diffusion Probabilistic\nModels (D3PMs) as a way to generalize the multinomial diffusion model by incorporating non-\nuniform transition probabilities.\nDiffusion models can be conditioned on class labels or blurry images to further enhance the per-\nformance of deblurring effects (Dhariwal & Nichol, 2021; Saharia et al., 2022). Ren et al. (2023)\nproposes the icDPM, which can better understand the blur and recover the clean image with the\nblurry input and guidance from the latent space of a regression network. However, these methods\nmerely use the blurry image as a form of guidance, rather than attempting to simulate the blurriness\nitself, which renders them incapable of achieving a more precise and complete removal of the blur."}, {"title": "METHOD", "content": "In precipitation nowcasting, the increasing blurriness with lead time is a crucial problem to be\nsolved, as the blurriness impedes the accurate spatiotemporal modeling of small-scale weather pat-\nterns, which are related to most extreme precipitation events. Previous methods, utilizing the pairs\nof blurry predictions and observations to train models for the predictions of local weather patterns,\nare challenged to generalize well to blur modes that do not appear in training. Instead of directly\npredicting small-scale weather patterns by conditioning on historical observations and blurry predic-\ntions, we propose a new pipeline composed of estimating the blurriness in precipitation nowcasting\ndirectly and deblurring the blurry predictions with an unconditional diffusion model."}, {"title": "EXPLICITLY MODELING OF THE BLURRINESS IN PRECIPITATION NOWCASTING", "content": "There are many blur modes in blurry predictions of precipitation. On the one hand, the blurriness\nin predictions varies depending on the changes in lead time or fluctuations in weather conditions,\ninfluencing both the future probabilities and magnitudes of future changes. On the other hand,\ndemonstrated by the visualizations in Appendix A.2, the differences in spatiotemporal modeling\nalso have impacts on blurriness.\nWe first propose to explicitly model these blur modes in precipitation nowcasting with a unified\nformulation:\n$y' = conv(K_{S,T,M}, y).$\n(1)"}, {"title": "UNSUPERVISED DEBLUR FOR ANY BLUR MODES IN PRECIPITATION NOWCASTING", "content": "Inspired by the formulation of Equation 1, fuzzy prediction could be tackled by solving the fuzzy\ninverse problem $K_{S T,M}$. However, in precipitation nowcasting, weather conditions vary with space\nand time, lead time changes in different application scenarios, and spatiotemporal modeling con-\ntinuously advances. As a result, it is prohibited to generalize to all blur modes in precipitation\nnowcasting by supervised training with pairs composed of blurry predictions and observations.\nTo cope with countless blur modes in precipitation nowcasting, we proposed an unsupervised de-\nblurring method based on a pre-trained unconditional diffusion model. Specifically, there is a zero-\nshot blur estimation mechanism and an auto-scale gradient guidance strategy to generalize our\nmethod to any blur modes in precipitation nowcasting.\nAs shown in Figure 2, our method adds guidance with the blur kernel $K_{S,T,M}$ and blurry prediction\ny' in each reverse step of the pre-trained diffusion model. The parameter of $K_{S,T,M}$ is randomly ini-\ntialized and dynamically optimized at each step of the sampling process. In each reverse steps, there\nare two parts named \u201cAdding Guidance\u201d and \u201cParameter Update\u201d, respectively. During \u201cAdding\nGuidance", "Parameter Update\", while the blur\nkernel connects the blurry prediction y' and the generated radar image $x_0$. To implement our zero-\nshot blur estimation mechanism, we employ $\\nabla_{\\varphi_t} L_{y, \\tilde{x_0}}$, the gradients of distance metric L respect\nto kernel parameter $\\varphi_t$, to estimate the blur kernel from scratch by dynamically updating the param-\neter itself. Additionally, the distance metric L also provides the gradients respect to $x_t$, $\\nabla_{\\tilde{x_0}} L_{y, \\tilde{x_0}}$,\nwhich is utilized to guide the sampling of $x_{t-1}$.\nSpecifically, the sampling process of the diffusion model transforms distribution $p_{\\theta}(x_{t-1}|x_t)$ into\nconditional distribution $p_{\\theta}(x_{t\u22121}|x_t, y')$. Previous work (Dhariwal & Nichol, 2021) have derived the\nconditional transformation formula in the reverse process:\n$\\log p_{\\theta}(x_t|x_{t+1},Y') = \\log (p_{\\theta}(x_t|x_{t+1})p(y'|x_t)) + N_1$\n(2)\n$\\approx \\log p_{\\theta}(z) + N_2 \\qquad z \\sim N(z; \\mu_{\\theta}(x_t, t) + \\Sigma \\nabla_{x_t} \\log p(y'|x_t)|_{x_t=\\mu}, \\Sigma I),$\n(3)\nwhere $N_1 = \\log p_{\\theta}(y'|x_{t+1})$, $N_2$ is a constant related to the gradient term $\\nabla_{x_t} \\log p(y'|x_t)|_{x_t=\\mu}$.\nAnd the variance of the reverse process $\\Sigma = \\Sigma_{\\theta}(x_t)$ is set as a constant. Based on this derivation,\nreverse process $p_{\\theta}(x_{t-1}|x_t, y')$ integrates the gradient to update the mean $\\mu_{\\theta}(x_t, t)$ generated from\nthe pretrained DDPM. We exploit the gradient of distance metric L to approximate the value of\n$\\nabla_{x_t} \\log p(y'|x_t)$:\n$\\nabla_{x_t} \\log p(y'|x_t)|_{x_t=\\mu} = -s \\nabla_{x_t} L(K_{\\varphi}(x_0), y').$\n(4)\nAmong them, s is the scaling factor employed to control the degree of guidance and plays a vital role\nin the quality of radar image generation. However, as there are numerous blur modes in precipitation\nnowcasting, it is difficult to set the guidance scale s for each blurry mode. Instead, we propose an\nauto-scale gradient guidance strategy to adaptively derive s for any blurry prediction from an\nempirical formula:\n$s = \\frac{(x_t - \\mu)^T g + C}{L(K_{\\varphi}(\\tilde{x_0}), y')},$\n(5)\nwhere g refers to the $\\nabla_{x_t} \\log p(y'|x_t)|_{x_t=\\mu}$ and $C = \\log p(y'|x_t)|_{x_t=\\mu}$. The detailed derivation\nprocess of s is shown in Appendix A.4.\nThe details of PostCast are shown in Algorithm 1. PostCast undergoes T reverse steps to gradually\nrestore pure Gaussian noise $x_T \\sim N(0, I)$ to high-quality precipitation images.\n$K_{\\varphi}$ represents the blur kernel $K_{S,T,M}$ with parameter $\\varphi$ at step t in the reverse progress\"\n    },\n    {\n      \"title\": \"EXPERIMENTS\",\n      \"content\": \"This section includes the setups of the experiments and the analysis of the results. We begin with\nimplementation details in Section 4.1, and evaluation metrics in Section 4.2. In Section 4.3, 4.4,\nand 4.5, we present comprehensive experiments exhibiting the high generability of PostCast to\nenhance the extreme part of predictions generated by classical spatiotemporal methods. Finally, the\nablation study of PostCast and further analysis of the blur kernel $K_{S,T,M}$ and auto-scale guidance\nare presented in Section 4.6.\"\n    },\n    {\n      \"title\": \"IMPLEMENTING DETAILS\",\n      \"content\": \"We uniformly resize the radar images from all datasets to 256 \u00d7 256. Five datasets, including\nSEVIR (Veillette et al., 2020), HKO7 (Shi et al., 2017), TAASRAD19 (Franch et al., 2020), Shang-\nhai (Chen et al., 2020), and SRAD2018 (SRAD, 2018), are selected to train the unconditional\nDDPM, while the other datasets (SCWDS CAP30 (Na et al., 2021), SCWDS CR (Na et al., 2021),\nMeteoNet (Larvor & Berthomier, 2021)) are prepared for out-of-dataset testing to evaluate the gen-\neralization of each method. More details of each dataset can be found in Appendix A.6. We follow\n(Dhariwal & Nichol, 2021) to train our DDPM model. We utilize the pre-trained unconditional diffu-\nsion model on ImageNet for better initialization and fine-tune it on SEVIR, HKO7, TAARSARD19,\nShanghai, and SRAD2018 using AdamW with $\u03b2_1 = 0.9$ and $B_2 = 0.999$ in 16-bit precision with\nloss scaling, while keeping 32-bit weights, Exponential Moving Average (EMA), and optimizer\nstate. We use an EMA rate of 0.9999 for all experiments. We use PyTorch, and train the models\non NVIDIA Tesla A100. Our PostCast uses a blur kernel with a size of 9 x 9. We use the same\nnoise schedule as for training. To recover the prediction with a distribution of real observation, we\nimplement our method with 1000 step DDPM. The cosine learning rate policy is used with initial\nlearning rates 0.0002 for PostCast and the $\u03b2_t$ we utilize undergoes a linear increase from $\u03b2_1 = 10^{-4}$\nto $\u03b2_T = 0.02$.\"\n    },\n    {\n      \"title\": \"EVALUATION METRIC\",\n      \"content\": \"Following (Zhang et al., 2023), we choose the Critical Success Index (CSI) for evaluation. In the\nfield of meteorology, CSI assesses consistency and accuracy between precipitation predictions and\"\n    },\n    {\n      \"title\": \"EVALUATION ON MULTIPLE DATASETS\",\n      \"content\": \"Table 1 presents the quantitive evaluation results of our method's performance gain for extreme\nprecipitation nowcasting. Specifically, TAU (Tan et al., 2023), PredRNN (Wang et al., 2022),\nSimVP (Gao et al., 2022a), and EarthFormer (Gao et al., 2022b) are all independently trained on\nthe evaluated datasets. These five datasets are used to train our unconditional DDPM, which makes\nthis evaluation in-domain. As shown in Table 1, our method can be applied to all of these pre-\ndiction methods including RNN-based, CNN-based, and Transformer-based. It demonstrates that\nour method is not sensitive to the way how the spatiotemporal correlations are modeled. On each\ndataset, there are significant improvements in extreme precipitation evaluation when applying our\nmethod, which is attributed to the local weather patterns recovered by our method as exhibited in\nFigure 3. Besides, it reveals the potential of our method to adapt to different blur modes in precipi-\"\n    },\n    {\n      \"title\": \"EVALUATION AT ANY LEAD TIME\",\n      \"content\": \"Encouraged by the generality of PostCast among datasets and models, in this section, we exhibit\nthe ability of PostCast to be generalized to arbitrary lead times such as 30 min, 60 min, and 90 min,\nwithin a zero-shot manner. An example is visualized in Figure 4, showing our method enhances local\ndetails and boosts the predictions of extreme values. As shown in Table 2, we conduct experiments\non SEVIR and HKO7. For both datasets, no matter which spatiotemporal prediction models are\nused, our method consistently increases the CSI scores of the highest thresholds (32.24 kg/m\u00b2 for\nSEVIR, and 30 mm/h for HKO7). Specifically, in SEVIR, the highest CSI scores of 30 min, 60\nmin, and 90 min reach 0.252, 0.144, and 0.106, respectively. The highest CSI scores evaluated on\nHKO7 reach 0.394, 0.326, and 0.266 for the lead time of 30 min, 60 min, and 90 min. The consistent\ngain indicates the generality of our method among different lead times.\"\n    },\n    {\n      \"title\": \"DEBLURRING ON OUT-OF-DISTRIBUTION DATASETS\",\n      \"content\": \"We compare our method with the other two supervised methods (DiffCast (Yu et al., 2024) and\nCasCast Gong et al.) on three out-of-distribution datasets. The quantitative results are presented in\nTable 3. CAP30 and CR represent different modalities (constant altitude plan of 3 km and composite\nreflectivity) in SCWDS. These 3 datasets are excluded from both the fine-tuning of our unconditional\nDDPM. CasCast and DiffCast are trained with the same datasets used by our unconditional model\nfor fair comparisons. On SCWDS CAP30 and SCWDS CR datasets, our method notably improves\nthe nowcasting of extreme precipitation. Specifically, the highest P16 of our method reaches 0.269\nand 0.338, while other methods only achieve 0.226 and 0.283. On MeteoNet, our method achieves\ncompetitive performance when applied on SimVP and EarthFormer, while on TAU and PredRNN,\"\n    },\n    {\n      \"title\": \"ABLATION STUDY\",\n      \"content\": \"In this section, we conduct ablation to validate the effectiveness of our proposed zero-shot blur\nestimation mechanism and auto-scale gradient guidance strategy. Additionally, further analysis\nof the blur kernel estimation and the auto-scale guidance is conducted.\nTable 4 presents the results of the ablation study on SEVIR and HKO7. \u201cKernel": "tands for the zero-\nshot blur estimation mechanism, and \u201cGuidance Scale\u201d represents the auto-scale gradient guid-\nance strategy. As shown in Table 4, when the deblur progress is equipped with neither \u201cKernel\" nor\n\"Guidance Scale\u201d, it exhibits relatively low CSI scores for extreme precipitation nowcasting. When\nthe \"Kernel\" is solely applied, there are significant gains on both SEVIR and HKO7, especially on\nthe CSI-P1 evaluated pixel-wisely. In particular, the CSI-P1 of SEVIR reached 0.038 and that of of\nHKO7 reached 0.059, indicating the importance of estimating the blur modes. Further, \u201cGuidance\nScale\" improves the gain of \u201cKernel\u201d, which suggests adaptively scaling the guidance contributes to\nbetter guidance.\nFurther experiments are conducted to reveal the influence of \u201cKernel\u201d and \u201cGuidance Scale\". As\nshown in Figure 5 (a), for the SEVIR dataset, the mean of the kernel stabilizes around 2.65 at reverse"}, {"title": "PRELIMINARY", "content": "Diffusion model is a generative framework that encompasses both the forward and reverse pro-\ncesses. The forward process gradually destroys the original training data xo by adding Gaussian\nnoise successively, which is defined as a Markov chain:\n$q(x_1,\\cdots, x_T|x_0) = \\prod_{t=1}^{T} q(x_t|x_{t-1}).$\n(6)\nPure Gaussian noise can be obtained after T diffusion steps when T is large enough. Each diffusion\nsteps is defined by the given parameter series $\u03b2_t$, which refers to the variance of the forward process.\nIt can be set as a known constant or learned with a separate neural network head (Nichol & Dhariwal,\n2021).\n$q(x_t|x_{t-1}) = N(x_t; \\sqrt{1 \u2013 \u03b2_t}x_{t-1}, \u03b2_tI).$\n(7)\nThe reverse process is the inversion of the forward process, aiming to simulate noise from the noise\ndistribution at each diffusion step and recover data from it. However, the mean and variance of the\nreverse process conditional distribution $p_{\\theta}(x_{t-1}|x_t) = N(x_{t-1}; \u03bc(x_t, t), \u03a3I)$ is difficult to calcu-\nlate directly. Therefore, we need to learn a noise simulation function $\u03f5(x,t)$ parameterized by\nparameter $\u03b8$ to approximate the mean of the conditional probabilities, which enables the model to\nsimulate and eliminate noise in the data sampled from the reverse process.\nBayesian formula can be utilized to transform the conditional distribution as follows: Bayesian\nformulas can be employed to derive the mean and variance for each step in the reverse process\n$p_{\\theta}(x_{t-1}|x_t)$.\n$q(x_{t-1}|x_t, x_0) = \\frac{q(x_t|x_{t-1},x_0)}{q(x_t|x_0)} q(x_{t-1}|x_0)$\n(8)\nDirectly expanding the three terms at the right-hand of Equation 8, the mean $\u03bc_\u03b8$ and variance $\u03a3_\u03b8$\ncan be represented by the following equation:\n$\\mu_{\\theta}(x_t, t) = \\frac{1}{\\sqrt{a_t}} (x_t - \\frac{\u03b2_t}{\\sqrt{1 - \\bar{a}_t}} \u03f5_\u03b8(x,t))$\n(9)\n$\\Sigma_{\\theta}(x) = \\frac{1 - a_{t-1}}{1 - \\bar{a}_t} \u03b2_t I$\n(10)\nwhere $a_t = 1 \u2212 \u03b2_t$ and $\\bar{a}_t = \\prod_{i=1}^{t} a_i$, which indicates that the variance of the reverse process\n$\u03a3 = \u03a3_\u03b8(x_t)$ is a constant.\nDiffusion model utilizes maximum likelihood estimation to obtain the probability distribution of\nMarkov transition in the reverse process. Specifically, the noise prediction function $\u03f5(x, t)$ is\ntrained with the purpose of optimizing the following surrogate denoising objective.\n$E_{\u20ac \u223cN (1,I),t\u223c[0,T]} [||\u20ac \u2013 \u20ac_\u03b8(x_t, t)||^2].$\n(11)"}, {"title": "EMPIRICAL FORMULA OF GUIDANCE SCALE", "content": "Previous work (Dhariwal & Nichol, 2021) has derived the conditional distribution formula in the\nsampling process:\n$\\log p_{\\theta} (x_t x_{t+1}, y) = \\log (p_{\\theta}(x_t x_{t+1})p(y|x_t)) + N_1,$\n(12)\nwhere $N_1$ refers to the conditional distribution $p_{\\theta}(y x_{t+1})$. Since it isn't dependent on $x_t$, it can be\nseen as a normalizing constant. For the first term, the posterior $q(x_t|x_{t+1})$ used for sampling is hard\nto calculate directly. Therefore, we utilize the model with parameter $\u03b8$ pre-trained on five datasets to\napproximate the conditional probabilities."}]}