{"title": "Online Housing Market", "authors": ["Julien Lesca"], "abstract": "This paper studies an online variant of the celebrated housing market problem (Shapley & Scarf, 1974), where each agent has a single house and seeks to exchange it for another based on her preferences. In this online setting, agents may arrive and depart at any time, meaning that not all agents are present on the housing market simultaneously. I extend the well-known serial dictatorship and Gale's top trading cycle mechanisms to this online scenario, aiming to retain their desirable properties such as Pareto efficiency, individual rationality, and strategy-proofness. These extensions also seek to prevent agents from strategically delaying their arrival or advancing their departure. I demonstrate that achieving all of these properties simultaneously is impossible in the online context, and I present several variants that achieve different subsets of these properties.", "sections": [{"title": "1. Introduction", "content": "Allocating indivisible resources to agents is a fundamental problem in computational social choice, which lies at the intersection of economics (Thomson, 2011) and computer science(Klaus, Manlove, & Rossi, 2016; Manlove, 2013). The decision maker in such problems must consider both the preferences of the agents over the resources and their strategic behavior. In this paper, I focus on a specific problem known as the housing market in the matching theory literature(Shapley & Scarf, 1974), where each agent is endowed with a single resource that they are willing to exchange for another. Furthermore, I assume that no monetary compensation is allowed to offset any unfavorable exchanges during the process. Despite its simplicity, this problem has many applications, including the exchange of dormitory rooms for students(Chen & S\u00f6nmez, 2002), the trade of used items(Swapz, 2025), kidney exchanges where incompatible donor/recipient pairs exchange viable organs for transplants (Ferrari, Weimar, Johnson, Lim, & Tinckam, 2015), and many more (see, e.g., (Bir\u00f3, 2017) for additional applications).\nIn this paper, I assume that the preferences over resources are ordinal, which is a standard assumption for the housing market. By doing so, I implicitly assume that the decision maker cannot assess the magnitude of preferences between resources, either because this information is unavailable or because it is too costly to obtain through interaction with the agents. The procedure for reallocating resources among agents is centralized, and the decision maker aims to produce an allocation that is as efficient as possible\nUnder ordinal preferences, Pareto optimality is an appropriate efficiency measure, aiming to find allocations where no agent can be made better off without harming another. In the standard offline setting, this requirement can be satisfied by the serial dictatorship (SD) procedure, sometimes called picking-sequence(Bouveret & Lang, 2014). In this procedure, agents are arranged in a specific order, and each agent, one by one, selects their most preferred resource from the pool of remaining resources. However, this process is not individually rational, as some agents may end up with resources less desirable than their initial endowments. This is undesirable because agents may be incentivized to avoid participating in the trade for fear of being worse off. The well-known Gale's top trading cycle (TTC) procedure(Shapley & Scarf, 1974) circumvents this drawback by ensuring individual rationality while computing an allocation that is Pareto optimal.\nSince the procedure is centralized, the decision maker must interact with agents to gather their preferences over resources. However, during this process, agents may misreport their preferences in an attempt to manipulate the procedure and achieve a more favorable outcome. Mechanism design, a subfield of game theory, seeks to create procedures where truthfully revealing preferences is a dominant strategy for agents(Hurwicz & Reiter, 2006). Both serial dictatorship and TTC procedures possess this property. Moreover, it has been proven that the TTC procedure is the only mechanism that is simultaneously individually rational, Pareto efficient, and strategy-proof(Ma, 1994).\nThe standard offline setting assumes that all agents participating in the exchange are available at the same time, and that the exchange procedure is conducted during this period. However, in many contexts, this requirement is unrealistic or too demanding, making it difficult to gather a larger set of agents for the exchange. In more realistic scenarios, agents are only available during restricted time periods, meaning that some may not be able to participate in the exchange simultaneously. This is the case, for example, with online exchange websites(Swapz, 2025), where agents do not arrive at the marketplace at the same time and cannot remain indefinitely before their swaps take place. This type of scenario is referred to as online(Albers, 2003), or dynamic, in the context of matching(Baccara & Yariv, 2021). In this paper, I show how the standard procedures, serial dictatorship and TTC, can be adapted to fit an online environment."}, {"title": "Outline", "content": "Section 2 provides a non exhaustive list of related works, that are connected either to the housing market problem or the online version of social choice problems. Section 3 provides the main definitions of the main properties that I seek to achieve for my mechanisms. Sections 4 to 6 provide online mechanisms based on the famous serial dictatorship procedure. More specifically, Section 4 considers first a static variant of this procedure, where assignment of items to non leaving agents are irrevocable. Section 5 relax this requirement by considering a dynamic version of serial dictatorship procedure. Section 6 consider a safe version of the serial dictatorship where no agent can be allocated an item that she least prefer than her own. Finally, Section 7 introduce multiple online variants of the TTC procedure."}, {"title": "2. Related Works", "content": "Related works encompass studies on variants of the housing market problem and investigations into online versions of social choice problems."}, {"title": "2.1 Housing Market Problem Variants", "content": "Multiple variants of the standard housing market have been explored in the literature. First, the extension to exchanges involving multiple items has been extensively studied. Fujita et al. (Fujita, Lesca, Sonoda, Todo, & Yokoo, 2018) proposed a TTC-like procedure that selects a Pareto optimal allocation (which belongs to the core) under restricted preferences over sets of resources. This work was extended to problems where multiple copies of items exist, and similar results were found under slightly different restrictions on preferences (Sikdar, Adali, & Xia, 2019). When agents can exchange multiple resources, the problem of computing an individually rational and Pareto efficient allocation is known to be NP-hard, even for additive preferences (Aziz, Bir\u00f3, Lang, Lesca, & Monnot, 2016). A sufficient condition to achieve strategy-proofness has also been provided(Aziz, 2020).\nOther extensions have considered exchange situations where agents are embedded in a social network. In some cases, the possible exchanges are constrained by the structure of the social network(Damamme, Beynier, Chevaleyre, & Maudet, 2015; Gourv\u00e8s, Lesca, & Wilczynski, 2017; Saffidine & Wilczynski, 2018; Huang & Xiao, 2019). Others have viewed the social network as a means to advertise the exchange procedure, designing mechanisms to incentivize agents to invite their neighbors to participate(Kawasaki, Wada, Todo, & Yokoo, 2021; You, Dierks, Todo, Li, & Yokoo, 2022).\nFinally, other works have explored extensions of the preference model used to describe agents' preferences. Standard algorithms have been adapted to handle cases with indifferences (Aziz & de Keijzer, 2012; Saban & Sethuraman, 2013). In another direction, the scope of the preference model can extend beyond simply considering the resource allocated to an agent. For instance, some works (Lesca & Todo, 2018; Aziz & Lee, 2020) have introduced preference models that also take into account the identity of the agent receiving an individual's initial endowment."}, {"title": "2.2 Online Problems in Social Choice", "content": "Multiple social problems related to my exchange problem have been examined through the lens of online procedures. In fair division, which aims to allocate resources fairly, several online variants have been explored(Aleksandrov & Walsh, 2020; Sankar, Louis, Nasre, & Nimbhorkar, 2021; Hosseini, Huang, Igarashi, & Shah, 2024). For instance, strategy-proofness and Pareto efficiency have been studied in this context(Aleksandrov, Aziz, Gaspers, & Walsh, 2015), alongside envy-freeness. Various extensions of the serial dictatorship procedure have been proposed to achieve these properties(Aleksandrov & Walsh, 2019). The online electric vehicle charging problem(Gerding, Perez-Diaz, Aziz, Gaspers, Marcu, Mattei, & Walsh, 2019), which focuses on scheduling charging for customers arriving in an online fashion, also shares similarities with my problem. However, in both cases, the online setting differs from mine, as resources do not arrive dynamically and are known to the procedure from the outset.\nThe online setting has also been explored in the context of stable matching, where preferences are two-sided and pairs of agents are matched to achieve stability, with applications such as student-university allocations. The case where students or universities arrive in an online fashion has been studied (Doval, 2022), and mechanisms based on the standard deferred acceptance algorithm have been proposed to address this issue. Online updates to the instance may also arise from the fact that the matching process consists of multiple rounds, during which agents may unexpectedly or strategically alter their revealed preferences between rounds(Cechl\u00e1rov\u00e1, Gourv\u00e8s, & Lesca, 2019; Dur & Kesten, 2019; Bampis, Escoffier, & Youssef, 2023). In the same vein, but closer to my setting as it addresses the one-sided problem of assigning resources to agents, an online version where preferences are elicited incrementally by querying agents has been considered (Hosseini, Menon, Shah, & Sikdar, 2021). A procedure that elicits preferences to achieve Pareto-optimality while minimizing the number of queries has been proposed.\nFinally, numerous works have focused on dynamic kidney exchange (\u00dcnver, 2010; Ashlagi & Roth, 2021), where donors and/or recipients arrive in an online fashion. Most of these studies consider compatibility (0-1 preference models) rather than ordinal preferences. Furthermore, they often assume the allocation process can be probabilistic, rely on probabilistic assumptions about arrival and/or departure, and aim to reduce the expected waiting time before a transplant(Bloch & Cantala, 2017; Anderson, Ashlagi, Gamarnik, & Kanoria, 2017; Baccara, Lee, & Yariv, 2020). Others focus on maximizing the expected number of matched pairs(Awasthi & Sandholm, 2009; Dickerson, Procaccia, & Sandholm, 2012). The design of strategy-proof and individually rational mechanisms has also been considered for transplant centers participating in national exchange programs(Ashlagi, Fischer, Kash, & Procaccia, 2015; Hajaj, Dickerson, Hassidim, Sandholm, & Sarne, 2015).\nIt is worth noting that there is a substantial body of literature on online algorithms (Borodin & El-Yaniv, 1998), which aim to maximize the sum of the weights of matched pairs in an online assignment problem where weights are assigned to pairs to be matched(Mehta, 2013). However, in my context, these approaches assume that preferences are cardinal and aim to maximize the agents' social welfare, i.e., the sum of their utilities. Their goal is to design online algorithms with a high competitive ratio, where the competitive ratio is the smallest ratio between the value of the computed allocation and the value of the optimal offline allocation."}, {"title": "3. Preliminary", "content": "Let N = {1,...,n} denote the set of agents. Each agent i owns a single good\u00b9 ei, called her initial endowment. Let T = [t\u00af,t+] denote the timeline during which the market is open, where t\u00af and t+ represent the opening and closing times of the market, respectively. For each agent i, a\u017c and di represent her arrival and departure times in the market, with ai, di \u2208 T such that t\u00af < ai < di < t\u207a. To simplify the setting, I assume that no two arrival or departure times occur simultaneously. Let E = {e1,..., en} represent the set of items belonging to the agents in N. Each agent i has a strict ordinal preference Yi over the items in E, such that ej \u27a2i ek means agent i strictly prefers ej over ek. Furthermore, symbol \u2265i stands for i or =. An instance of the online exchange problem is represented by the set of tuples {(i, ei, ai, di, \u27a2i)}i\u2208N. Without loss of generality, I assume that the agent indices are ordered by increasing arrival times, i.e., such that a\u2081 < a2 < ... < an hold. Let I denote the entire set of possible instances.\nMy goal is to allocate to each agent a single item such that each item is assigned only once. In other words, I search for an allocation M : N \u2192 E such that M(i) \u2260 M(j) for each i \u2260 j. The timeline constraints are such that each agent will leave the market with an item which belongs to an agent that arrived in the market earlier than her departure time. For any t \u2208 T, let N<t denote the subset of agents arriving before t, i.e., containing any agent i \u2208 N such that ai < t. For a given instance I \u2208 I, an allocation M is I-compatible if M(i) \u2208 E<d; holds for each agent i, where E<t = {ei : i \u2208 N<t} for each t \u2208 T. For any instance I, the set of I-compatible allocations is denoted M(I).\nAn exchange algorithm A returns an I-compatible allocation for each instance I. By abuse of notation, I assume that A\u00bf(I) denotes the item allocated to agent i by algorithm A for instance I. In the online version of the problem, the algorithm should make a decision on the allocation for an agent when she leaves the market, without knowing the agents that arrive after her departure. In other words, the mechanism should make a decision only based on the agents that already visited the market by the departure time of the agent. For any t \u2208 T, let I<t denote a truncated copy of I restricted to the agents of N<t.\nDefinition 1. An exchange algorithm A is online if for each instance I and for each agent i, Ai(I) = Ai(I<di) holds.\nThe choice between online exchange algorithms should be guided by the properties fulfilled by the allocation that they compute. To compare the online exchange algorithms, I consider multiple standard desiderata properties that could be considered as desirable or necessary. The first one is a standard definition of efficiency in multi-agent decision problems.\nDefinition 2. Allocation M' Pareto-dominates allocation M if for each agent i, M'(i) \u2265i M(i) holds, and for at least one agent j, M'(j) >j M(j) holds. For a given instance I, let S denote a given subset of M(I). Allocation M is S-Pareto optimal (S-PO), if there is no allocation M' of S that Pareto-dominates it.\nThe standard notion of Pareto optimality corresponds to M(I)-PO, as illustrated by the following example.\nExample 1. Consider instance I described in Figure 1. The timeline, containing the arrival and departure times of the agents, as well as their preferences are provided in the left part of the figure. Three different allocations are graphically described in the right part of the figure. For example, allocation M is such that M(1) = e2, M(2) = e3, and M(3) = e1. Note that M is not I-compatible, as agent 2 receives an item from an agent who arrives later than d2. Therefore, M does not belong to M(I). On the other hand, allocations M' and M\" are both I-compatible. It is also easy to verify that both M' and M\" are M(I)-PO.\nAs suggested in Example 1, restricting comparisons to I-compatible allocations allows for the existence of efficient solutions, even if better ones exist but are incompatible with the online setting.\nDefinition 3. An exchange algorithm A is individually rational (IR), if for each instance I, Ai(I) \u2265i ei holds for any agent i.\nThe individual rationality property belongs to the set of properties that incentivize agents to participate in the exchange algorithm, as no agent will receive an item that is less desirable than her initial endowment. Another standard property related to the manipulative power of agents, through misreporting their preferences, is called incentive compatibility. I generalize the notion of incentive compatibility to also take into account manipulations related to arrival and departure times.\nDefinition 4. An exchange algorithm is strongly incentive compatible (SIC), if for each agent i and for each pair of instances I and I' such that I' = I \\{i, ei, ai, di, \u27a2i} \u222a {i, ei, ai, di,>} and a\u017c \u2264 a < d; \u2264 di, A\u00bf(I) \u2265i A\u00bf(I') holds. It is a-IC (respectively d-IC) if the above inequality holds only when di = d'; (respectively a\u00a1 = a;).2 Finally, it is weakly incentive compatible (WIC), if the above inequality holds only when both a\u2081 = a and d\u2081 = d.\nNote that the notion denoted WIC in my setting corresponds to the standard notion of incentive compatibility in the offline setting. Note also that I implicitly assumed that the manipulative power of an agent concerning her arrival and departure time is restricted, since she cannot claim an arrival time earlier than her true arrival time, nor a departure time later than her true departure time. This assumption is made because I do not believe that this type of misreporting is realistic in an exchange market. Furthermore, my goal is to push agents to stay as long as possible in the market to obtain a better allocation."}, {"title": "4. Static Serial Dictatorship Procedure", "content": "In this section, I consider an exchange algorithm based on the serial dictatorship procedure, which is described in Algorithm 1. The standard version of the serial dictatorship procedure is based on a permutation of the agents defining the order in which each agent will choose her item among the remaining ones. I slightly generalize these permutations by considering permutation functions whose order depends on the instance. More formally, \u03a0:\u0399 \u2192 NN denotes this permutation function, which is such that for any instance I and for any i\u2208 {1,...,n}, \u03a0\u00bf(I) denotes the agent choosing at position i. Despite the fact that this permutation theoretically may depend on the full instance, I assume in this paper that it only depends on the arrival and departure times of the agents. An example of such a permutation is the ascending departure permutation d which ranks the agents according to their departure times, and more specifically by increasing departure times, i.e., such that ds(1) < ds(2) < ... < ds(n).\nIn Algorithm 1, every iteration of the \"for\" loop corresponds to the departure of an agent, specifically agent \u03b4(i), whose departure time is the ith earliest. However, the order in which the agents choose their items is determined by the permutation function \u03a0. Therefore, before agent d(i) chooses her item, all agents that are ranked before her according to II must choose their items. In this static (or greedy) version of the algorithm, once an agent has chosen an item, she is permanently matched to it, even if more desirable items arrive later. Note that the procedure besti returns the most preferred item of agent i from a given set of items. Algorithm 1 is designed to be online, as only the part of the instance corresponding to agents who have already arrived, I<ds(i), is used at iteration i, during the departure of agent d(i). However, the permutation used as input must be consistent with this online algorithm in the sense that the order of agents already matched to items must not change when new agents arrive. Otherwise, an agent might be matched multiple times or ignored by the algorithm.\nDefinition 5. The permutation function II is static online consistent (SOC), if for each agent i, and for any positions i' and j' such that I\u00bf\u00bf(I) = i and j' < i', \u03a0;,(I) = \u03a0;'(I<d\u2081) holds.\nThe following proposition shows that Algorithm 1 is online and weakly incentive compatible when the permutation used is SOC."}, {"title": "4.1 The Ascending Departure Permutation", "content": "As suggested by the following proposition, the ascending departure permutation 8, that orders the agents by increasing departure time, is a good candidate to be used with Algorithm 1.\nProposition 2. The ascending departure permutation d is SOC.\nProof. I must show that for each agent i, and for any positions i' and j', such that I\u00bf'(I) = i and j' < i', the equality \u03a0;'(I) = \u03a0;'(I<d\u2081) holds when II = \u03b4. Note first that agents \u03a0\u2081(I'), \u03a0\u2082(\u0399'), . . ., \u03a0\u00bf' (I') are the i' agents with the smallest departure times in I'. Instance I is an upper set of I'. Furthermore, any agent k that belongs to I but not to I' must have an arrival time later than di, since dk > ak > di. Therefore, the i' agents with the smallest departure times are the same in both I and I'. Finally, their relative order remains consistent in both \u03a0(I) and I(I') because their departure times are identical in both instances.\nExample 2. Let me run Algorithm 1 with the ascending departure permutation d on the instance described in Figure 1. At the departure of agent 2, she selects item e\u2081 that she prefers to e2. Then, at the departure of agent 3, she selects item e2 that she prefers to e3. Finally, agent 1 leaves the market with e\u0437, which is the only remaining item. The resulting allocation corresponds to M' described in Figure 1.\nNote that when Algorithm 1 is used with the ascending departure permutation d, the algorithm allows each agent to choose the best remaining item upon leaving the market. The following proposition demonstrates that selecting the ascending departure permutation d as the permutation function in Algorithm 1 results in a Pareto efficient outcome for any instance.\nProposition 3. For any instance I \u2208 I, Algorithm 1, using the ascending departure permutation d as input, returns a M(I)-PO allocation.\nProof. The main argument of the proof is that the matching M returned by Algorithm 1 must be lexicographically optimal among the matchings of M(I) according to the order provided by the ascending departure permutation d applied to I. Let P denote the subset of allocations that may Pareto-dominate M. According to Algorithm 1, M(\u03b4(1)) must be the most favored item of agent \u03b4(1) in E<ds(1). Therefore, all matchings in P must allocate M(\u03b4(1)) to agent \u03b4(1) to Pareto-dominate M. Provided that M(\u03b4(1)) is allocated to agent 8(1), Algorithm 1 allocates to agent (2) her most favored item in E<d$(2) \\ {M(\u03b4(1))}. Thus, all matchings in P must allocate M(\u03b4(2)) to agent \u03b4(2) to Pareto-dominate M. By applying the same reasoning to the remaining agents in the order given by d, I conclude that P can only contain a single allocation, which corresponds to M. Since a matching cannot Pareto-dominate itself, no matching in M(I) Pareto-dominates M.\nThe following proposition shows that there is no other online exchange algorithm that always returns a Pareto-efficient outcome.\nProposition 4. Algorithm 1 using the ascending departure permutation d is the only online exchange algorithm that returns for any instance I an M(I)-PO allocation.\nProof. By contradiction, let A denote an online exchange algorithm that behaves differently than Algorithm 1 using the ascending departure permutation d as input. This means that there exists an instance I and an agent j such that Aj(I) does not correspond to the assignment made by Algorithm 1 with the ascending departure permutation d. In other words, agent j does not receive her most favorite item among those in E<ds(j) minus the items already assigned to agents leaving earlier than her. Furthermore, I assume without loss of generality that, among the set of agents in this situation, agent j is the one who leaves the earliest. Let M denote the allocation obtained by Algorithm 1 with the ascending departure permutation d applied to I. Let i denote the agent who receives M(j) instead of agent j in A(I), i.e., such that A\u00bf(I) = M(j). By assumption, dj < di must hold since, otherwise, an agent arriving earlier than agent j would not receive the same item as in M.\nTo show the contradiction, I construct a new instance I' by adding dummy agents to I. For any agent k leaving after dj, let k' be a dummy agent such that ak = dj+ke, with e > 0 small enough for all these agents to arrive earlier than any other arrival or departure, and dk large enough to leave after any other agent of I. The preferences of the agents in I' are as follows. For any agent k that was already in I and leaving after dj, her most favorite item is ek', followed by the items of I ranked in the same order, and finally all the other items of I' ranked in arbitrary order. Dummy agent i''s preferences are Aj(I) >i' M(j) >i' ..., where all the other items are ranked in arbitrary order. Finally, the most favorite item of any other dummy agent k' is Ak(I), and all other items are ranked arbitrarily.\nNote first that since A is online, both Aj (I') = Aj (I'<d\u2081) and Aj(I<dj) = Aj(I) hold. Furthermore, since all dummy agents arrive later than dj, I<d; = I'<d; holds, which implies with the former equalities that Aj(I') = A;(I). Now concerning the assignment of the other agents, based on their preferences and since A is M(I')-PO, I can say that for each dummy agent k', I have Ak\u2032(I') = Ak(I), and for each regular agent k leaving after dj, I have Ak(I') = ek. More precisely for i' I have A\u00a1,(I') = A\u00bf(I) = M(j). Note that except for agents i' and j, any agent receives her most favorite item.\nBut now consider the almost same allocation, say M', as the one constructed by A, except that agent j receives M(j) and agent i' receives Aj(I). Note that by construction, M' should belong to M(I') since A is an online exchange algorithm, and therefore A(I<d;) = A(I'd\u2081) belongs to M(I'd\u2081) (for agent j and the ones leaving after her), A(I') belongs to M(I') (for all other agents except agent i'), and av < di holds (for agent i'). Agent j and dummy agent i' receive in M' a strictly better item than the one offered by algorithm A. Therefore, M' Pareto dominates A(I'), leading to a contradiction since A is M(I')-PO."}, {"title": "4.2 The Ascending Arrival Permutation", "content": "Propositions 3 and 4 tell us that when we want an online algorithm that always returns an efficient outcome, we should focus on Algorithm 1 using the ascending departure permutation das input. Furthermore, Proposition 1 and 2 attest that this algorithm is WIC. However, it is easy to check that Algorithm 1 using the ascending departure permutation das input is neither a-IC, d-IC nor IR. Therefore, I should consider other permutation functions as input of Algorithm 1. Another candidate is the ascending arrival permutation a, which ranks the agents by increasing arrival time i.e., such that \u03b1\u03b1(1) < \u03b1\u03b1(2) < ... < da(n). Note that this permutation corresponds to the identity because I have assumed that a\u2081 < a2 < ... < an. The following proposition shows that the ascending arrival permutation a is consistent with Algorithm 1.\nProposition 5. The ascending arrival permutation a is SOC.\nProof. Note first that for any instance I and for any agent i and j such that aj < ai, ai < di implies that aj < di, and therefore agent j belongs to I<d\u2081. Furthermore, for any agent k that belongs to I \\ I<d\u2081, ai < di < ak hold, and therefore k cannot be ranked before agent i according to the ascending arrival permutation a applied to I. Finally, the arrival time of each of these agents is the same in I and I<d\u2081. Therefore, the positions of the i first ranked agents according to the ascending arrival permutation a are the same for I and I<di\nExample 3. Let me run Algorithm 1 with the ascending arrival permutation a on the instance described in Figure 1. At the departure of agent 2, agent 1 selects first and picks e2, which she prefers to e\u2081. Then, agent 2 selects the last remaining item at d2, which is 21. Finally, at the departure of agent 3, she picks the last remaining item at d3, which is e3. The resulting allocation corresponds to M\" described in Example 1.\nThe following proposition shows that the choice of the ascending arrival permutation a as input of Algorithm 1 incentivizes agents to truthfully report their departure time.\nProposition 6. Algorithm 1 using the ascending arrival permutation a as input is d-IC.\nProof. Note first that the ascending arrival permutation a is SOC according to Proposition 5, and therefore by Proposition 1, I know that no agent has an incentive to misreport her preferences. So I only need to show that no agent has an incentive to misreport her departure time. Note also that as soon as the arrival time is not modified, changing the departure time of an agent has no impact on the ranking dictated by the ascending arrival permutation a. I am going to show that if the reported departure time of an agent, say i, is delayed after a new event, which may be the departure of another agent or the arrival of a new agent, then her most favorite remaining item is either the same or even better. More formally, let I be an instance and I' be the same instance except that the new departure time di of agent i is delayed to be later than the arrival time aj or the departure time dj corresponding to the event occurring right after di i.e., either (i) di < dj < d; or (ii) di < aj < d'. In both cases (i) and (ii), all iterations of the \u201cfor\u201d loop of Algorithm 1 applied to instance I and I' before reaching di are the same, since only the departure time of agent i has changed. Note that if agent i has to choose during one of these iterations for I, agent i chooses the same item for I' and is ultimately assigned the same item. Therefore, I can focus on the case where agent i does not choose until it leaves the market at di in I.\nLet me first consider case (i), where agent j leaves earlier than i in I' whereas she left later in I. I consider at the same time the two iterations of the \"for\" loop corresponding to di and dj in I, and dj and d' in I', which are the first two iterations that differ between I and I'. Note that since there is no event occurring between di and dj in I, and between dj and di in I', at the end of these two iterations, the same subset of agents picks an item for I and I', which should be a subset of agents ranked before either agent i orj in the ascending arrival permutation a. Furthermore, they choose their items according to the same order (the one dictated by the ascending arrival permutation a), and from the same subset of items. Therefore, each one of them chooses the exact same item for both I and I', including agent i who has no incentive to delay her arrival time.\nFinally, let me consider case (ii), where di < aj < d'i. Note that a new item arrives to the market, namely ej, before agent i leaves the market. This new item may have consequences on the choices made by the agents who choose before i according to the ascending arrival permutation a. More specifically, one of them may choose ej instead of the item they selected for I. Once item ej has been chosen, say by agent k, it is no longer available, but the item that agent k chose in I at the same phase is now available and takes the place of ej as an additional item to choose from. So each agent choosing before i either picks the same item as in I, or picks ej, or another item abandoned by an agent choosing earlier. Therefore, when it is the turn of agent i to choose, the item assigned to her in I is available, as well as an additional item, which may be ej or another item abandoned by an agent choosing earlier. Consequently, she picks either the same item as in I or an item that she prefers.\nIn summary, if agent i delays her departure time, then she receives either the same item or a new one that she prefers. In other words, she has no incentive to report an earlier departure time than her true one, and the algorithm is d-IC.\nThe following proposition shows that no other permutation function, apart from the ascending arrival permutation a, makes Algorithm 1 d-IC.\nProposition 7. The ascending arrival permutation a is the only input that ensures Algo- rithm 1 is both online and d-IC.\nProof. Let II be an online permutation function that is different from the ascending arrival permutation a. This means that there is an instance I with two agents i and j, whose positions according to I(I) are i' and j', respectively, such that both ai > aj and i' < j' hold. In other words, agent i arrives later but is ranked before agent j according to II. By contradiction, assume that I makes Algorithm 1 d-IC. Let I' be a copy of instance I with the exception of the departure time d'; of agent j, which happens earlier than dj. More precisely, I assume that aj < d'; < a\u017c hold. Since Algorithm 1 applied with II is d-IC', the item assigned to agent j for I' should be no better than the one assigned to her for I. Furthermore, since Algorithm 1 is online, agent j should receive the exact same item for instances I'd and I'. Assume that the preferences of the agents are such that ej is the most favorite item of agents i and j, and any other agent k prefers her own item ek to any other one. It is clear that in that case, each agent receives her own item during Algorithm 1 applied to I'd since each agent prefers her own item (note that agent i is not part of I'd). It implies that agent j receives also ej when Algorithm 1 is applied to I' with the ascending arrival permutation a as input. Since agent j receives her most favorite item for I', she should receive the exact same item in I. But since agent i is ranked before agent j in the ascending arrival permutation a, she picks first and chooses ej, which is also her most favorite item. Therefore, agent i should also receive item ej for I, leading to a contradiction since ej can be assigned only once.\nNote that this statement is not as strong as Proposition 4 since it does not rule out any other d-IC online exchange algorithm than Algorithm 1 using the ascending arrival permutation a as input. In the next sections, we will see another d-IC algorithm based on the top trading cycle procedure.\nWith Algorithm 1 using the ascending arrival permutation a, I obtain the property of d-IC. It is easy to check that the property of a-IC is not achieved with the ascending arrival permutation a, and I wonder whether there is a permutation function that achieves this property with Algorithm 1. The answer provided by the following proposition rules out the existence of such a permutation function.\nProposition 8. There is no online permutation function that makes Algorithm 1 a-IC.\nProof. By contradiction, assume that there exists an online permutation II that makes Algorithm 1 a-IC. Consider the following instance I with 3 agents, such that a\u2081 < a2 < d2 < a3 < d3 < d\u2081. The preferences of the agents are e3 >1 \u20ac1 >1 \u20ac2, C1 >2 \u20ac2 >2 \u20ac3, and C1 >3 e3 >3 \u20ac2. Note that since the algorithm is a-IC, agent 1 should be assigned item e\u0437, which is her most favorite item. Otherwise, by changing her arrival time to a such that d2 < a\u2081 < a3, leading to"}]}