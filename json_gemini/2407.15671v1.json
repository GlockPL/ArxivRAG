{"title": "Problems in AI, their roots in philosophy, and implications for science and society", "authors": ["M.J. Velthoven", "E.J. Marcus"], "abstract": "Artificial Intelligence (AI) is one of today's most relevant emergent technologies. In view thereof, this paper proposes that more attention should be paid to the philosophical aspects of AI technology and its use. It is argued that this deficit is generally combined with philosophical misconceptions about the growth of knowledge. To identify these misconceptions, reference is made to the ideas of the philosopher of science Karl Popper and the physicist David Deutsch. The works of both thinkers aim against mistaken theories of knowledge, such as inductivism, empiricism, and instrumentalism. This paper shows that these theories bear similarities to how current AI technology operates. It also shows that these theories are very much alive in the (public) discourse on AI, often called Bayesianism. In line with Popper and Deutsch, it is proposed that all these theories are based on mistaken philosophies of knowledge. This includes an analysis of the implications of these mistaken philosophies for the use of Al in science and society, including some of the likely problem situations that will arise. This paper finally provides a realistic outlook on Artificial General Intelligence (AGI) and three propositions on A(G)I and philosophy (i.e., epistemology).", "sections": [{"title": "Introduction", "content": "Artificial Intelligence (AI) is one of the hottest topics of the moment. Specialized applications of AI continue to expand and improve, making AI increasingly relevant as an emergent technology. Forms of AI are already being used across science and society (Hadwick, 2022). Whilst the fruits of AI are warmly received, there is a lack of attention for the philosophical aspects of AI technology and the use thereof. This deficit is generally combined with philosophical misconceptions about the growth of knowledge. Unfortunately, these are not merely theoretical problems. In this paper, we outline why these deficits are in fact real problems with implications for science and society.\nThis paper refers to the ideas of the philosopher of science Karl Popper and the physicist David Deutsch (section 1). Part of their work is aimed against mistaken theories of knowledge such as inductivism, empiricism, and instrumentalism. This paper shows that these theories bear similarities to how current Al technology operates. It also shows that these theories are very much alive in the (public) discourse on AI, often by the name of Bayesianism (sections 2 and 3). With reference to Popper and Deutsch, this paper argues that all these theories are based on mistaken philosophies of knowledge. Identifying such deficits is an important task of philosophy: to point out what we do not know, why some of our existing knowledge is mistaken, and what problems our ignorance gives rise to. This paper analyses the implications of these mistaken philosophies for the use of Al in science and society (section 4).\nDespite the philosophical problems associated with AI, we recognize the potential of AI to bring great benefits in many fields. This potential makes it even more important to have sufficient awareness of how current AI works and what it can and cannot do. In this paper, we outline some of the likely problem situations that will arise as a result of the lack of such awareness. This paper also provides an outlook to the future, including a realistic outlook on Artificial General Intelligence (AGI) (section 5). This part of the paper proposes that decent public policy on AGI requires a sound underlying philosophy and that progress in philosophy is a key requirement for AGI. The paper ends with a conclusion and three propositions (section 6)."}, {"title": "A brief introduction to the ideas of Karl Popper and David Deutsch", "content": "''I think (like you, by the way) that theory cannot be fabricated out of the results of observation, but that it can only be invented.\u201d \u2013 Albert Einstein in a letter to Karl Popper.\nThis section introduces the key aspects of the ideas of Karl Popper that are most relevant to this paper. Karl Popper (1902-1994) was a philosopher and academic who is mainly known for his work on the philosophy of science (in particular his Falsification Principle) (Magee, 1973; Popper, n.d., 1962). This introduction should start with two upfront warnings. The first warning is slightly obvious: Popper's ideas have immense depth and reach. One commentator (Magee, 1973) described them as \u2018'interconnecting parts of a single explanatory framework which extends to the whole of human experience\u201d (p. 16). As a consequence, any attempt at summarizing these ideas is like trying to fit an entire"}, {"title": "How does current AI technology work?", "content": "This section provides a short overview of the functioning of current AI technology. Although different variants exist, a simplified depiction of the working of many Al models would be as follows :\n1.\tData collection and cleaning of the dataset.\n2.\tTraining on a subset of the total dataset.\n3.\tTesting the model on another subset of the total dataset.\nAl engineers and scientists often add an additional evaluation step aimed at optimizing the model architecture and other parameters. This additional step takes place before the testing step (step 3) and uses another subset of the total dataset. The heavy reliance on (sub)sets of data means that current Al is generally considered to be data hungry: even small models may require thousands of data points to achieve reasonable performance.\nAs an illustrative example, suppose that an Al model would be designed to categorize images as either a \"cat\" or a \"dog\". It is also assumed that this AI model is a classical neural network in the form of a multilayer perceptron (MLP), although the specific form is not relevant for the purposes of this paper.\n1.\tIn the first phase, a database is created which includes (thousands of) pictures of cats and dogs along with labels specifying to which class each of the pictures belongs. This database is cleaned, thereby eliminating unclear pictures or pictures that do not fall within one of the categories (such as pictures of elephants).\n2.\tIn the second phase, the model is shown batches of images along with labels specifying to which class the images belong. Subsequently, the model provides predictions of whether a certain image depicts a cat or a dog. These predictions are judged using a loss function that penalizes the model for wrong predictions. In sports terms: the model concedes a goal for every wrong prediction. The model will subsequently use its own predictions and labels to update its parameters such that it will perform better in the next iteration. Usually, the model is shown the entire training dataset several times before it has optimized its parameters to the training dataset."}, {"title": "An analysis of current AI technology in view of the works of Popper and Deutsch", "content": "The previous section already provided the first hints of the similarities between the working of Al models and the philosophies which were rejected by Popper and Deutsch. In particular, the functioning of current AI much resembles the philosophy of inductivism (or its modern instantiation, Bayesianism, which we will analyze below). As Popper has shown, the method of inductivism cannot hope to create true new 'universal' or even 'more probable' statements based on individual instances. Yet this is precisely how AI systems work. Paired with the wrong philosophies of knowledge,"}, {"title": "Implications", "content": "In the previous sections we proposed that current Al technology operates similarly to mistaken philosophies of knowledge. Does this mean that we are opposed to the use of this AI technology? Quite the contrary: we recognize the many potential use cases for AI and see no convincing reason against it, provided that certain guardrails are in place. Unsurprisingly, these guardrails address the issues raised in the previous section. If these are not properly dealt with, the use of AI in combination with the aforementioned misconceptions on the growth of knowledge can result in disaster.\nAs a start, actions taken regarding AI should never be based on the misconception that the operation of AI is similar to how people think. This proposition has major implications for science and society. In the design of organizations and of policies, AI should be seen as a new technology (a tool), not as a replacement of human intelligence. Some might object and propose that AI might nevertheless perform tasks currently performed by humans and in doing so replace"}, {"title": "Outlook and a realistic philosophical perspective on Artificial General Intelligence (AGI)", "content": "We end this paper with some last observations on the holy grail of the AI debate: the potential for AGI. Although there are different interpretations of this term, AGI generally refers to artificial intelligence which equals human intelligence. Such an AGI would be able to create new explanations for anything (a 'universal explainer', as Deutsch calls it). As will have become clear from this paper, the ideas of Popper and in particular Deutsch support the notion that AGI is possible. In fact, one of Deutsch' key propositions is that AGI must be possible. Deutsch however concludes that AGI will not be achieved by the current progress in AI, no matter how good AI may become in specialized tasks such as modelling language or image recognition. Progress in current AI is much welcomed but should merely be seen as a further refinement based on the same technology and (mistaken) philosophy as was described in the previous sections of this article. Deutsch therefore finds that current AI technology is \u2013 if anything -moving away from AGI rather than towards it.\nUnsurprisingly, we find many traces of the 'inductivist\u201d and positivist\u201d schools of thought in the current AGI debate. These traces are particularly visible in the popular idea that AI will eventually turn into AGI once Al has obtained sufficient data or computer power. Deutsch is of the view that that a breakthrough in philosophy is needed before AGI even becomes remotely possible. Such a breakthrough would have to answer questions such as 'How do people make new explanations?' and 'How do people formulate criticisms?'. Without answers to these questions, even an AI that is fed with all the computer power and data in the universe will not become an AGI.\nUnfortunately, the current discourse on AGI rarely includes a clear formulation of the underlying philosophy of participants in the discussion. As a result, participants are free to make the wildest predictions about the likelihood of achieving AGI soon and its potential consequences without providing any clues on the philosophical requirements for Al to reach the level of AGI (see, e.g., (Macey-Dare, 2023)). In our view, the discourse on AGI requires a clear"}, {"title": "Conclusion: three propositions", "content": "This paper has analyzed current AI technology and criticized its philosophical aspects. In its criticism, the paper has made specific reference to the ideas of Karl Popper and David Deutsch. It has become apparent that there are many similarities between the operation of current AI technologies and mistaken philosophies on the growth of knowledge which were criticized by Popper and Deutsch. This paper proposed that this has significant implications for the use of AI. We summarize our conclusions in the following three propositions, which should be kept in mind for any (public) policies on Al and AGI.\n1.\tInformation created by current AI is not new 'knowledge' as created by humans: humans should therefore remain at the 'creative steering wheel'. Al is an instrument and cannot by itself formulate new (scientific) theories.\n2.\tIt follows that current AI cannot by itself generate truly new explanations whereas humans can. An important implication is that human actors should continue to bear the ultimate responsibility to explain the application of AI. This will inevitably include cases in which Al is successfully used as an instrument even though its operation itself cannot be explained (black box AI).\n3.\tProgress in current AI may result in specialized applications that bring great benefits to science and society. However, there is no reason to believe that further development of current AI technologies will result in the creation of an Al that is truly on par with human intelligence (also called AGI). In fact, the current developments in AI are actively moving away from realizing AGI."}]}