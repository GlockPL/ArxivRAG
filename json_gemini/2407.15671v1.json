{"title": "Problems in AI, their roots in philosophy, and implications for\nscience and society", "authors": ["M.J. Velthoven", "E.J. Marcus"], "abstract": "Artificial Intelligence (AI) is one of today's most relevant emergent technologies. In view thereof, this paper proposes\nthat more attention should be paid to the philosophical aspects of AI technology and its use. It is argued that this deficit\nis generally combined with philosophical misconceptions about the growth of knowledge. To identify these\nmisconceptions, reference is made to the ideas of the philosopher of science Karl Popper and the physicist David\nDeutsch. The works of both thinkers aim against mistaken theories of knowledge, such as inductivism, empiricism, and\ninstrumentalism. This paper shows that these theories bear similarities to how current AI technology operates. It also\nshows that these theories are very much alive in the (public) discourse on AI, often called Bayesianism. In line with\nPopper and Deutsch, it is proposed that all these theories are based on mistaken philosophies of knowledge. This\nincludes an analysis of the implications of these mistaken philosophies for the use of Al in science and society,\nincluding some of the likely problem situations that will arise. This paper finally provides a realistic outlook on\nArtificial General Intelligence (AGI) and three propositions on A(G)I and philosophy (i.e., epistemology).", "sections": [{"title": "Introduction", "content": "Artificial Intelligence (AI) is one of the hottest topics of the moment. Specialized applications of AI continue to\nexpand and improve, making AI increasingly relevant as an emergent technology. Forms of AI are already being used\nacross science and society (Hadwick, 2022). Whilst the fruits of AI are warmly received, there is a lack of attention for\nthe philosophical aspects of AI technology and the use thereof. This deficit is generally combined with philosophical\nmisconceptions about the growth of knowledge. Unfortunately, these are not merely theoretical problems. In this paper,\nwe outline why these deficits are in fact real problems with implications for science and society.\nThis paper refers to the ideas of the philosopher of science Karl Popper and the physicist David Deutsch (section 1).\nPart of their work is aimed against mistaken theories of knowledge such as inductivism, empiricism, and\ninstrumentalism. This paper shows that these theories bear similarities to how current Al technology operates. It also\nshows that these theories are very much alive in the (public) discourse on AI, often by the name of Bayesianism\n(sections 2 and 3). With reference to Popper and Deutsch, this paper argues that all these theories are based on mistaken\nphilosophies of knowledge. Identifying such deficits is an important task of philosophy: to point out what we do not\nknow, why some of our existing knowledge is mistaken, and what problems our ignorance gives rise to. This paper\nanalyzes the implications of these mistaken philosophies for the use of Al in science and society (section 4).\nDespite the philosophical problems associated with AI, we recognize the potential of AI to bring great benefits in many\nfields. This potential makes it even more important to have sufficient awareness of how current AI works and what it\ncan and cannot do. In this paper, we outline some of the likely problem situations that will arise as a result of the lack\nof such awareness. This paper also provides an outlook to the future, including a realistic outlook on Artificial General\nIntelligence (AGI) (section 5). This part of the paper proposes that decent public policy on AGI requires a sound\nunderlying philosophy and that progress in philosophy is a key requirement for AGI. The paper ends with a conclusion\nand three propositions (section 6)."}, {"title": "A brief introduction to the ideas of Karl Popper and David\nDeutsch", "content": "This section introduces the key aspects of the ideas of Karl Popper that are most relevant to this paper. Karl Popper\n(1902-1994) was a philosopher and academic who is mainly known for his work on the philosophy of science (in\nparticular his Falsification Principle) (Magee, 1973; Popper, n.d., 1962). This introduction should start with two upfront\nwarnings. The first warning is slightly obvious: Popper's ideas have immense depth and reach. One commentator\n(Magee, 1973) described them as \u2018\u2018interconnecting parts of a single explanatory framework which extends to the whole\nof human experience\u201d (p. 16). As a consequence, any attempt at summarizing these ideas is like trying to fit an entire"}, {"title": "How does current AI technology work?", "content": "This section provides a short overview of the functioning of current AI technology. Although different variants exist,\na simplified depiction of the working of many Al models would be as follows :\nData collection and cleaning of the dataset.\nTraining on a subset of the total dataset.\nTesting the model on another subset of the total dataset.\nAl engineers and scientists often add an additional evaluation step aimed at optimizing the model architecture and\nother parameters. This additional step takes place before the testing step (step 3) and uses another subset of the total\ndataset. The heavy reliance on (sub)sets of data means that current Al is generally considered to be data hungry: even\nsmall models may require thousands of data points to achieve reasonable performance.\nAs an illustrative example, suppose that an Al model would be designed to categorize images as either a \u201ccat\u201d or a\n\u201cdog\u201d. It is also assumed that this AI model is a classical neural network in the form of a multilayer perceptron (MLP),\nalthough the specific form is not relevant for the purposes of this paper.\nIn the first phase, a database is created which includes (thousands of) pictures of cats and dogs along with\nlabels specifying to which class each of the pictures belongs. This database is cleaned, thereby eliminating\nunclear pictures or pictures that do not fall within one of the categories (such as pictures of elephants).\nIn the second phase, the model is shown batches of images along with labels specifying to which class the\nimages belong. Subsequently, the model provides predictions of whether a certain image depicts a cat or a\ndog. These predictions are judged using a loss function that penalizes the model for wrong predictions. In\nsports terms: the model concedes a goal for every wrong prediction. The model will subsequently use its own\npredictions and labels to update its parameters such that it will perform better in the next iteration. Usually,\nthe model is shown the entire training dataset several times before it has optimized its parameters to the\ntraining dataset."}, {"title": "An analysis of current AI technology in view of the works of\nPopper and Deutsch", "content": "The previous section already provided the first hints of the similarities between the working of Al models and the\nphilosophies which were rejected by Popper and Deutsch. In particular, the functioning of current AI much resembles\nthe philosophy of inductivism (or its modern instantiation, Bayesianism, which we will analyze below). As Popper has\nshown, the method of inductivism cannot hope to create true new 'universal' or even 'more probable' statements based\non individual instances. Yet this is precisely how AI systems work. Paired with the wrong philosophies of knowledge,"}, {"title": "Implications", "content": "In the previous sections we proposed that current Al technology operates similarly to mistaken philosophies of\nknowledge. Does this mean that we are opposed to the use of this AI technology? Quite the contrary: we recognize the\nmany potential use cases for AI and see no convincing reason against it, provided that certain guardrails are in place.\nUnsurprisingly, these guardrails address the issues raised in the previous section. If these are not properly dealt with,\nthe use of AI in combination with the aforementioned misconceptions on the growth of knowledge can result in disaster.\nAs a start, actions taken regarding AI should never be based on the misconception that the operation of AI is similar to\nhow people think. This proposition has major implications for science and society. In the design of organizations and\nof policies, AI should be seen as a new technology (a tool), not as a replacement of human intelligence. Some might\nobject and propose that AI might nevertheless perform tasks currently performed by humans and in doing so replace"}, {"title": "Outlook and a realistic philosophical perspective on\nArtificial General Intelligence (AGI)", "content": "We end this paper with some last observations on the holy grail of the AI debate: the potential for AGI. Although there\nare different interpretations of this term, AGI generally refers to artificial intelligence which equals human intelligence.\nSuch an AGI would be able to create new explanations for anything (a 'universal explainer', as Deutsch calls it). As\nwill have become clear from this paper, the ideas of Popper and in particular Deutsch support the notion that AGI is\npossible. In fact, one of Deutsch' key propositions is that AGI must be possible. Deutsch however concludes that\nAGI will not be achieved by the current progress in AI, no matter how good AI may become in specialized tasks such\nas modelling language or image recognition. Progress in current AI is much welcomed but should merely be seen as a\nfurther refinement based on the same technology and (mistaken) philosophy as was described in the previous sections\nof this article. Deutsch therefore finds that current AI technology is \u2013 if anything -moving away from AGI rather than\ntowards it.\nUnsurprisingly, we find many traces of the 'inductivist\u201d and positivist\u201d schools of thought in the current AGI debate.\nThese traces are particularly visible in the popular idea that AI will eventually turn into AGI once Al has obtained\nsufficient data or computer power. Deutsch is of the view that that a breakthrough in philosophy is needed before AGI\neven becomes remotely possible. Such a breakthrough would have to answer questions such as 'How do people make\nnew explanations?' and 'How do people formulate criticisms?'. Without answers to these questions, even an AI that is\nfed with all the computer power and data in the universe will not become an AGI.\nUnfortunately, the current discourse on AGI rarely includes a clear formulation of the underlying philosophy of\nparticipants in the discussion. As a result, participants are free to make the wildest predictions about the likelihood of\nachieving AGI soon and its potential consequences without providing any clues on the philosophical requirements for\nAl to reach the level of AGI (see, e.g., (Macey-Dare, 2023)). In our view, the discourse on AGI requires a clear"}, {"title": "Conclusion: three propositions", "content": "This paper has analyzed current AI technology and criticized its philosophical aspects. In its criticism, the paper has\nmade specific reference to the ideas of Karl Popper and David Deutsch. It has become apparent that there are many\nsimilarities between the operation of current AI technologies and mistaken philosophies on the growth of knowledge\nwhich were criticized by Popper and Deutsch. This paper proposed that this has significant implications for the use of\nAI. We summarize our conclusions in the following three propositions, which should be kept in mind for any (public)\npolicies on Al and AGI.\nInformation created by current AI is not new 'knowledge' as created by humans: humans should therefore\nremain at the 'creative steering wheel'. Al is an instrument and cannot by itself formulate new (scientific)\ntheories.\nIt follows that current AI cannot by itself generate truly new explanations whereas humans can. An important\nimplication is that human actors should continue to bear the ultimate responsibility to explain the application\nof AI. This will inevitably include cases in which Al is successfully used as an instrument even though its\noperation itself cannot be explained (black box AI).\nProgress in current AI may result in specialized applications that bring great benefits to science and society.\nHowever, there is no reason to believe that further development of current AI technologies will result in the\ncreation of an Al that is truly on par with human intelligence (also called AGI). In fact, the current\ndevelopments in AI are actively moving away from realizing AGI."}]}