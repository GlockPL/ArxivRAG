{"title": "Uncertainty Estimation in Multi-Agent Distributed Learning\nfor AI-Enabled Edge Devices", "authors": ["Gleb Radchenko", "Victoria Andrea Fill"], "abstract": "Initially considered as low-power units with limited autonomous processing, Edge IoT devices have seen a\nparadigm shift with the introduction of FPGAs and AI accelerators. This advancement has vastly amplified\ntheir computational capabilities, emphasizing the practicality of edge AI. Such progress introduces new\nchallenges of optimizing AI tasks for the limitations of energy and network resources typical in Edge\ncomputing environments. Our study explores methods that enable distributed data processing through AI-\nenabled edge devices, enhancing collaborative learning capabilities. A key focus of our research is the\nchallenge of determining confidence levels in learning outcomes, considering the spatial and temporal\nvariability of data sets encountered by independent agents. To address this issue, we investigate the application\nof Bayesian neural networks, proposing a novel approach to manage uncertainty in distributed learning\nenvironments.", "sections": [{"title": "INTRODUCTION", "content": "Traditionally, Internet of Things (IoT) Edge devices\nhave been perceived primarily as low-power\ncomponents with limited capabilities for autonomous\noperations. However, in recent\nyears, the focus of IoT research has shifted towards\noptimizing knowledge exchange and implementing\nAl on edge devices. These advancements are largely\ndue to the innovation of FPGAs and AI accelerators,\nwhich have exponentially increased the\ncomputational capabilities of Edge devices. This evolution raises critical questions that system\ndevelopers should address:\nKnowledge Exchange: How can we implement\nseamless knowledge sharing between edge\ndevices to refine machine learning algorithms\nwhile maintaining data privacy?\nResource Management: What strategies can\neffectively manage the computational power of\nthese increasingly autonomous, high-\nperformance devices?\nSpatiotemporal Locality: How can we address\nthe localized nature of data to ensure real-time\nor near-real-time task execution?\nThe challenges presented by limited resources on\nedge devices and the spatiotemporal locality of data\nare particularly significant. These issues require new\napproaches to manage computational capabilities and\nefficiently perform tasks in real-time or near-real-\ntime modes.\nThe goal of this research is to investigate the\nalgorithms and methods for deploying distributed\nmachine learning within the framework of\nautonomous, network-capable, sensor-equipped, AI-\nenabled edge devices. Specifically, we focus on\ndetermining confidence levels in learning outcomes,\nconsidering the spatial and temporal variability of\ndata sets encountered by independent agents. To\naddress this issue, we investigate the potential of the\nDistributed Neural Network Optimization (DiNNO)\nalgorithm, aiming to extend it for\norganizing distributed data processing and"}, {"title": "2 RELATED WORK", "content": null}, {"title": "2.1 Distributed Machine Learning\nMethods", "content": "Distributed machine learning (ML) algorithms,\ndistinguished by their communication mechanisms,\nprimarily support the exchange of model parameters,\nmodel outputs, or hidden activations. These\nexchanges can be enabled through peer-to-peer or\nclient-server architectures. The\nprimary approaches utilized within these algorithms\nmay be categorized as follows."}, {"title": "2.1.1 Federated Learning", "content": "Federated Learning (FL) orchestrates the periodic\ntransmission of local training parameters (e.g.,\nweights and gradients of a neural network) from\nworkers to a central parameter server. This server\nthen performs model averaging and disseminates the\nupdated global model to the workers. Such a strategy\nnot only may preserve data privacy by avoiding the\nneed for raw data exchange but also may enhance\ncommunication efficiency through adjustable\ntransmission intervals. The authors\nof  identify FL as a solution to\nchallenges in edge computing environments, such as\nunwanted bandwidth loss, data privacy issues, and\nlegalization concerns. They highlight that FL allows\nfor co-training models across distributed clients, such\nas mobile phones, automobiles, and hospitals, via a\ncentralized\nserver while maintaining data\nlocalization.\nThe authors of  propose an\nextension of the FL model, called FedFog, designed\nto enable FL over a wireless fog-cloud system. The\nauthors address key challenges such as non-\nidentically distributed data and user heterogeneity.\nThe FedFog algorithm performs local aggregation of\ngradient parameters at fog servers and a global\ntraining update in the cloud."}, {"title": "2.2.2 ADMM-derived Methods", "content": "Alternating Direction Method of Multipliers\n(ADMM)-derived Methods (such as\nDiNNO , GADMM, and CADMM)\naim to implementation of distributed learning in the\nabsence of a central coordinating entity by enabling\ncommunication directly between the neighboring\nworker nodes in a peer-to-peer (P2P) manner. One\ncritical issue of FL and such P2P learning methods is\nthat the communication overhead is proportional to\nthe number of model parameters, limiting their\nefficacy in supporting deep neural networks ."}, {"title": "2.1.3 Federated Distillation", "content": "Federated Distillation utilizes the exchange of\nmodel outputs, which are significantly lower in\ndimensionality compared to the full model sizes for\ndistributed learning. In this approach, each worker\nperforms local iterations based on its individual loss\nfunction. This process is enhanced with a\nregularization component that measures the\ndiscrepancy between the worker's predicted output\nfor a specific training sample and the aggregated\nglobal output for the same class. A widely known\napplication of knowledge distillation is model\ncompression, through which the knowledge of a large\npretrained model may be transferred to a smaller\none."}, {"title": "2.1.4 Split Learning", "content": "Split Learning (SL) partitions multi-layer neural\nnetworks into segments, thus making it possible to\ntrain large-sized deep NN that exceed the memory\ncapacities of a single edge device. This approach\ndivides the NN into lower NN segments on the\nworkers' devices, each containing raw data and a\nshared upper NN segment hosted on a parameter\nserver. The NN cut layer is a boundary between the\nlower and upper NN segments. Workers compute the\nactivations at the NN cut layer and send these\nactivations to the parameter server. The parameter\nserver uses these activations as inputs for the upper\nNN segment to continue the forward pass, compute\nthe loss, and initiate the backward pass. Gradients\ncalculated at the cut layer are then transmitted back to\nthe workers, allowing them to update the weights of\nthe lower NN segments. However, the efficacy of SL\nin terms of communication is subject to ongoing\ndiscussion ."}, {"title": "2.1.4 Multi-agent Reinforcement Learning", "content": "Multi-agent Reinforcement Learning extends\nbeyond traditional regression or classification\nobjectives to address scenarios where environmental\ndynamics influence worker decisions. In such\ncontexts, workers must learn these dynamics and\nadapt their strategies based on the knowledge\nacquired through interactions with the environment\nand among themselves ."}, {"title": "2.2 Uncertainty Estimation and\nBayesian Neural Networks", "content": null}, {"title": "2.2.1 Bayesian Neural Networks", "content": "In a conventional neural network architecture, a linear\nneuron is characterized by a weight (w), a bias (b),\nand an activation function (fact). Given an input x, a\nsingle linear neuron performs the following\noperation:\ny = fact (w.x + b) \\tag{1}\nwhere y is the output of the neuron.\nBayesian Neural Networks (BNNs) employ a\nBayesian approach to train stochastic neural\nnetworks. Instead of\ndeterministic weights and biases, they utilize\nprobability distributions, denoted P(w) for weights\nand P(b) for biases. Typically, these distributions are\napproximated as Gaussian, with mean and standard\ndeviation derived from the training data. Hence, a\nBayesian neuron outputs a range of possible values,\nnot just one. So, the operation of a Bayesian Linear\nneuron can be described as:\nP(x) = fact (P(w) x x + P(b)) \\tag{2}\nIn a BNN, the Gaussian distributions for weights\nand biases may be defined by the mean \u00b5 and the\nstandard deviation \u03c3 For weights, the\ndistribution P(w) is modeled as a Gaussian\ndistribution with a mean w\u00b5 and a standard deviation\nWo, where:\nw = log(1 + e^{Wp}) \\tag{3}\nThe parameter wo ensures that the standard\ndeviation is always positive. Similarly, the\ndistribution P(b) for biases is represented as a\nGaussian distribution with a mean bu and a standard\ndeviation bo, where:\nb = log(1 + e^{bp}) \\tag{4}\nDuring the forward pass of a Bayesian neuron,\nthese distributions are sampled to obtain a weight and\nbias for each neuron. The sampled weights and biases\nare then used to compute the neuron's output. The\nparameters Wu, Wp, bu, bp are learned during NN\ntraining to optimize the network's performance.\nUnlike conventional NNs, which employ a\nsingular forward pass, BNNs might conduct multiple\nforward passes. The mean and standard deviation of\nthese outputs are then computed. Depending on the\nproblem type the neural network addresses, these\nmean and standard deviation values can indicate the\nmodel's uncertainty for each point in the input data\nspace."}, {"title": "2.2.2 Kullback-Leibler Divergence", "content": "Kullback-Leibler Divergence (KL Divergence)\n is\nemployed to account for the difference between the\nGaussian distributions that represent the parameters\nof the BNN. KL Divergence serves as a measure to\nquantify the dissimilarity between two probability\ndistributions and can be generally computed as:\nDKL(g || h) = \\int g(x)log(\\frac{g(x)}{h(x)}) dx \\tag{5}\nwhere g(x) and h(x) are two probability density\nfunctions defined over the same support. The concept\nof \"expected excess surprise\" captures the core idea\nbehind KL Divergence, reflecting the expected\ndegree of \"surprise\" encountered when another\n\"model\" distribution approximates an actual\ndistribution. As outlined by , if \u039d\u03bf (\u03bc\u03bf, \u03c3\u03bf) and N\u2081(\u03bc\u2081, \u03c3\u2081) are two normal"}, {"title": "3 COLLABORATIVE MAPPING\nCASE", "content": "As a case study for a distributed AI application\noperating within the Edge Cloud, we have chosen a\ncollaborative environment mapping problem. This\ntask involves deploying a network of independent,\nrobotic edge devices (robots) at various starting\npoints. Each device is tasked with building a coherent\nmap of the environment, utilizing installed sensors,\nand exchanging knowledge about the environment\nwith other devices.\nThese devices are designed to update a local ML\nmodel with newly acquired data samples and"}, {"title": "4 DISTRIBUTED EDGE\nLEARNING APPROACH", "content": "To optimize the DiNNO algorithm for edge\ncomputing environments, it is essential to transition"}, {"title": "5 DISTRIBUTED UNCERTAINTY\nESTIMATION", "content": "To address uncertainty estimation in the distributed\nmapping problem, we incorporate a BNN by\nreplacing the conventional linear layers in the neural\nnetwork with Bayesian Linear Layers. The\narchitecture of the BNN is detailed as follows :\nInput Layer (2): x, y an input coordinate\nrepresenting the global position on the\nenvironment map.\nSIRENLayer (256): a layer with a sinusoidal\nactivation function suitable for Neural Implicit\nMapping."}, {"title": "6 IMPLEMENTATION AND\nEVALUATION", "content": "Based on floor plans sourced from the CubiCasa5K\ndataset, we generated 3D interior models in STL\nformat for robotic exploration. To simulate the\nbehavior of autonomous agents, these 3D interior\nmodels were imported into the Webots simulation\nplatform , where we deployed models\nof TurtleBot robots for navigation within these\nenvironments . Webots support\nimplementing of 3D models of robotic systems and\nenvironments, including simulating the most typical\nsensors, such as cameras and LiDAR. This\nmethodology enabled us to use advanced LiDAR\nsensor models, incorporating realistic noise and\nmeasurement uncertainties into our experiments."}, {"title": "6.1\nSingle-Agent Uncertainty Estimation", "content": "We conducted a series of experiments with a\nsingle isolated agent to evaluate the effectiveness of\nthe BNN architecture proposed in Section 5 for\nestimating uncertainty in neural network outcomes\nand the impact of the klweight parameter from\nEquation (7). The agent was trained exclusively on\nlocal data during the experiment without exchanging\ninformation with other agents. The visualization of\nthe training results is presented in Figure 5.\nTo generate outputs from the Bayesian neural\nnetwork, 50 queries were made for each pair of input\ncoordinates (x, y). Subsequently, a visualization was\ncreated to illustrate the mean values and standard\ndeviations of the neural network responses.\nIt was observed that a low value of the klweight\nparameter leads to a low variance in the neural\nnetwork's results, which does not allow for\ndistinguishing the \"hallucinations\" of the neural\nnetwork from areas with sufficient data to form a\ngeneral understanding of the environment.\nConversely, a high klweight parameter value results\nin excessive noise and a high degree of uncertainty in\nthe neural network's results. Therefore, to ensure that\nthe Bayesian neural network provides an effective\nassessment of uncertainty, fine-tuning of the klweight\nparameter during the training process is required."}, {"title": "6.2 Multi-Agent Uncertainty Estimation", "content": "To assess the effectiveness of Bayesian neural\nnetworks in estimating uncertainty within distributed,"}, {"title": "7 CONCLUSIONS", "content": "Within the scope of this paper, we addressed a\nproblem of uncertainty estimation within distributed\nmachine learning based on Al-enabled edge devices.\nWe set up a simulation of a collaborative mapping\nproblem using the Webots platform; introduced an\nepoch-based decentralized consensus algorithm to\nsupport the decentralized peer-to-peer exchange of\nNN parameters among agents; and integrated\ndistributed uncertainty estimation into our models by\napplying Bayesian neural networks.\nOur experiments indicate that BNNs can\neffectively support uncertainty estimation in a\ndistributed learning context. However, to ensure an\neffective assessment of uncertainty by the BNN, we\nhighlighted the need for precise tuning of the learning\nhyperparameters during training. We also determined\nthat applying Kullback-Leibler divergence for\nparameter regularization resulted in a 12-30%\nreduction in validation loss during the training of\ndistributed BNNs compared to other regularization\nstrategies.\nFor future work, we suggest exploring how\ndistributed learning with BNNs can be tailored for\nembedded Al hardware. This would involve refining\nthe NN architecture to suit the resource constraints of\nAI-enabled edge devices. We also plan to explore task\nmanagement and offloading strategies within the\nmulti-layered fog and hybrid edge-fog-cloud\nenvironments to improve computational efficiency\nand resource utilization."}]}