{"title": "RETRIEVAL AUGMENTED DIFFUSION MODEL FOR\nSTRUCTURE-INFORMED ANTIBODY DESIGN AND OP-\nTIMIZATION", "authors": ["Zichen Wang", "Yaokun Ji", "Jianing Tian", "Shuangjia Zheng"], "abstract": "Antibodies are essential proteins responsible for immune responses in organisms,\ncapable of specifically recognizing antigen molecules of pathogens. Recent ad-\nvances in generative models have significantly enhanced rational antibody de-\nsign. However, existing methods mainly create antibodies from scratch without\ntemplate constraints, leading to model optimization challenges and unnatural se-\nquences. To address these issues, we propose a retrieval-augmented diffusion\nframework, termed RADAb, for efficient antibody design. Our method leverages\na set of structural homologous motifs that align with query structural constraints to\nguide the generative model in inversely optimizing antibodies according to desired\ndesign criteria. Specifically, we introduce a structure-informed retrieval mech-\nanism that integrates these exemplar motifs with the input backbone through a\nnovel dual-branch denoising module, utilizing both structural and evolutionary in-\nformation. Additionally, we develop a conditional diffusion model that iteratively\nrefines the optimization process by incorporating both global context and local\nevolutionary conditions. Our approach is agnostic to the choice of generative\nmodels. Empirical experiments demonstrate that our method achieves state-of-\nthe-art performance in multiple antibody inverse folding and optimization tasks,\noffering a new perspective on biomolecular generative models.", "sections": [{"title": "1 INTRODUCTION", "content": "Antibodies, essential Y-shaped proteins in the immune system, are pivotal for recognizing and neu-\ntralizing specific pathogens known as antigens. This specificity primarily arises from the Comple-\nmentarity Determining Regions (CDRs), which are crucial for binding affinity to antigens (Jones\net al., 1986; Ewert et al., 2004; Xu & Davis, 2000; Akbar et al., 2021). The design of effective\nCDRs is therefore central to developing potent therapeutic antibodies, a dominant class of protein\ntherapeutics. However, the development of these antibodies typically relies on labor-intensive ex-\nperimental methods such as animal immunization or screening extensive antibody libraries, often\nfailing to produce antibodies that target therapeutically relevant epitopes effectively. Thus, the abil-\nity to generate new antibodies with pre-defined biochemical properties in silico carries the promise\nof speeding up the drug design process.\nComputational efforts in antibody design have traditionally involved grafting residues onto exist-\ning structures (Sormanni et al., 2015), sampling alternative native CDR loops to enhance affini-\nties(Aguilar Rangel et al., 2022), and using tools like Rosetta for sequence design improvements\nin interacting regions (Adolf-Bryfogle et al., 2018). Many recent studies have focused on applying\ndeep generative models to design antibodies (Luo et al., 2022; Martinkus et al., 2024; Zhu et al.,\n2024). They take advantage of geometric learning and generative models to capture the higher-\norder interactions among residues directly from the data. These innovations provide more efficient\nmethods to search sequence and structure spaces.\nAlbeit powerful, current generative models struggle to design antibodies that adhere to structural\nconstraints and exhibit desired biological properties. This challenge primarily arises from a lack of"}, {"title": "2 RELATED WORK", "content": "Antibody Design Computational antibody design primarily follows two paths: conventional energy\nfunction optimization methods and machine learning approaches. Early antibody design methods\nwere often limited to sequence similarity and energy function optimization (Lapidoth et al., 2015;\nAdolf-Bryfogle et al., 2018). Recent success of machine learning approaches mainly falls into two\ndirections: antibody sequence design and antigen-specific antibody sequence-structure co-design.\nThe methods used for antibody sequence design mainly include language-based models (Ruffolo\net al., 2021; Olsen et al., 2022; Wang et al., 2023a) and inverse folding models (Dreyer et al., 2023;\nH\u00f8ie et al., 2024). The other line focuses on antibody sequence-structure co-design mainly taking\nantibody-antigen complex as a graph, then using graph networks to extract features and predict the"}, {"title": "3 PRELIMINARIES AND NOTATIONS", "content": "Antibody consists of two heavy chains and two light chains. Each chain's tip has a complementary\nsite that specifically binds to a unique epitope on the antigen. This site includes six complementary-\ndetermining regions (CDRs): CDR-H1, CDR-H2, and CDR-H3 on the heavy chain, and CDR-L1,\nCDR-L2, and CDR-L3 on the light chain (Presta, 1992; Al-Lazikani et al., 1997).\nOur work represents each single protein residue in terms of the residue type $s_i\\in$\n{ACDEFGHIKLMNPQRSTVWY}, the coordinate $x_i \\in R^3$, and the orientation $O_i \\in$\nSO (3), where $i = 1, ..., N$ and N is the number of residues in the complex. Concretely, assuming the\nCDR sequence to be generated includes m amino acids and starts from position a, it can be denoted\nas $R = \\{s_j | j \\in \\{a + 1, ..., a + m\\}\\}$. Let M be the length of the antibody, the antibody frame-\nwork is defined as $C_{ab} = \\{(s_i, x_j, O_j) | i \\in \\{1, ..., M\\} \\backslash \\{a + 1, ..., a + m\\}, j \\in \\{1, ..., M\\}\\}$. The\nantibody framework sequence is defined as $S_{ab} = \\{s_i | i \\in \\{1, ..., M\\} \\backslash \\{a + 1, ..., a + m\\}\\}$. The\nantigen is defined as $C_{ag} = \\{(s_i, x_i, O_i) | i \\in \\{M + 1, ..., N\\}\\}$. The retrieved CDR-like fragments\nare defined as $A = \\{\\tilde{A}_i | i \\in \\{1, ..., k\\}\\}$. The goal of our framework is to extract the antibody\nCDR structure from the antibody framework complex $C_{ab}$, then input it into the retrieval module to\nretrieve A, and ultimately predict the distribution of R through $C_{ag}, C_{ab}$ and A."}, {"title": "3.2 DIFFUSION MODEL FOR ANTIBODY DESIGN", "content": "Due to diffusion models' excellent performance and controllability, there are now many diffusion-\nbased works that have achieved notable results (Luo et al., 2022; Villegas-Morcillo et al., 2023;\nKulyt\u0117 et al., 2024). To be specific, they are denoising probabilistic diffusion models that transform\nthe amino acid type s, the backbone Ca atom coordinates x, and the amino acid orientation O during\nthe diffusion process. We focus on sequence, of which the forward process perturbs the data in the\nfollowing ways (Hoogeboom et al., 2021):\n$q(s_t | s_{t-1}) = Multinomial \\Bigg( (1 - \\beta_t) \\cdot onehot (s_{t-1}) + \\beta_t \\cdot \\frac{1}{20} \\cdot 1 \\Bigg)$ (1)"}, {"title": "4 METHODS", "content": "We propose RADAb (as demonstrated in Figure 2), a novel structure-informed retrieval-augmented\ndiffusion framework for antibody sequence design and optimization. The model uses a structural\nretrieval algorithm to search for antibody homologous structures and take their sequences as condi-\ntional inputs for the diffusion model to provide homologous patterns and evolutionary information."}, {"title": "4.1 STRUCTURAL RETRIEVAL OF CDR FRAGMENTS", "content": "The structure of a protein is determined by its sequence, and protein sequences that can fold into\nsimilar structures exhibit similar properties. These structurally similar protein sequences contain\nrich evolutionary information. Based on this, we perform retrieval in the PDB database using CDR\nstructures, aiming to obtain fragments that are similar to the real CDR and have homologous se-\nquences, with the expectation that they possess similar functions.\nTo balance the quality of results and the retrieval speed, we use MASTER (Zhou & Grigoryan,\n2015) for the search. MASTER uses the root-mean-square deviation (RMSD) of backbone atoms as\na similarity measure. It queries structural fragments composed of one or more non-contiguous seg-\nments and can find all matching fragments from the database within a given RMSD threshold. This\nallows for fast and accurate searches in the PDB database for protein motifs. Note that MASTER\ncan utilize only the backbone information without any leakage of sequence data during the search\nprocess. The retrieval procedure is described in Algorithm 1 and detailed in Appendix A.3.\nFor the retrieved results, we use the RMSD with the real backbone structure as a score to rank them\nand filter out the input CDR fragment. For ease of use, we further constructed a CDR-like fragments"}, {"title": "4.2 MODEL ARCHITECTURES", "content": "The model takes the antigen-antibody complex's structure and sequence context, along with the\nsequences of the CDR-like fragments, as conditional inputs to iteratively denoise. The first branch of\nthe model learns the global context information of the complex, while another branch takes the local\nhomologous information of CDR-like fragments as input, aiming to learn the functional similarity\nand evolutionary information of residues with similar structure. The two branches are combined to\ngenerate the antibody CDR sequence jointly."}, {"title": "4.2.1 GLOBAL GEOMETRY CONTEXT INFORMATION BRANCH", "content": "Context encoder A protein is formed by the connection of multiple residues. The features of a\nsingle residue mainly include the residue type, backbone atom coordinates, and backbone dihedral\nangles. The features of each pair of residues mainly include the types of both residues, sequential\nrelative position, spatial distance, and pairwise backbone dihedrals. These features are concatenated\nand then input into two separate MLPs. The output is denoted as $z_i$ and $y_{ij}$.\nEvolutionary encoder Recent advances have shown the structure-informed protein language model\n(PLM) is an excellent tool for creating protein sequence embeddings and providing evolutionary\ninformation (Zheng et al., 2023; Shanker et al., 2024). Thus, we take ESM2 (Lin et al., 2023) as an\nantibody sequence encoder, aiming to capture the evolutionary relations of antibody residues. The\nstate of antibody sequence with CDR at timestep t is fed into it and output is defined as $e_t$.\nStructure-informed network The above encoding is used as conditional input to the Structure-\ninformed network. They, along with the CDR sequence and structural state at the current time step,\nwill be input into a stack of Invariant Point Attention (IPA) (Jumper et al., 2021) layers, and jointly\ntransform into a hidden representation $h_i$. Subsequently, the hidden representation $h_i$ is transformed\nby an MLP to obtain the probability representation $r_{global}$ of the amino acid type at each CDR site.\nThis probability representation is then input to the local CDR-focused branch."}, {"title": "4.2.2 LOCAL CDR-FOCUSED INFORMATION BRANCH", "content": "Post-processing of CDR-like fragments We first remove the CDR portions from the antibody se-\nquences to obtain the antibody framework sequences. Then, we fill these fragments' short sequences\ninto the antibody framework sequences, thereby constructing a CDR-like sequence matrix E.\nCDR-focused Axial Attention The local CDR-like branch is constituted of a stack of axial atten-\ntion layers, referred to as CDR-focused Axial Attention. Given that the CDR-like fragments exhibit\nstructures similar to actual CDRs, we employed a tied row attention mechanism used in MSATrans-\nformer (Rao et al., 2021) to leverage these retrieval results. In the standard axial attention (Ho et al.,\n2019) mechanism, each row and column are considered independently. However, in MSA (Multi-\nple Sequence Alignment), each sequence exhibits relatively similar structural features. Our matrix\nformat is well-suited for adopting a tied row attention mechanism to fully utilize the structural simi-\nlarity. When calculating the attention scores for each row, this mechanism simultaneously considers\nthe scores of other rows. This approach not only leverages the structural similarity but also reduces\nmemory usage.\nThe input to CDR-focused Axial Attention is a pseudo-MSA matrix P in equation 3. The first\nrow of this matrix is initially filled with the antigen-antibody framework sequence, with the CDR\nregion populated by the noisy sequence $R_t$ (sampled by $r_{global}$) at the current time step t. From\nthe second row to the k-th row (where k is chosen to be 16, meaning the top 15 retrieved CDR-like\nsequences are used as conditional input), the rows are filled with the CDR-like sequence matrix E.\nThe constructed matrix P is then input to CDR-focused Axial Attention to create the homologous\nembedding and calculate the probability representation $r_{local}$ (equation 4).\nP = concat ((Sab UR), E) (3)\nrlocal [j] = Gcol (P.,j,t) for all j \u2208 col, (4)\nrlocal[i] = Gtiedrow (Pi.., t) for all i \u2208 row\nThe row self-attention is computed to capture the internal relationships within the antibody-antigen\nsequences, while the column self-attention is computed to capture the relationships between the\nCDR residues and the CDR-like residues.\nSkip connection for information fusion Although the probability distribution of the CDR region\ncreated by the antigen-antibody context features has already been fed into the network, to prevent\nthe loss of antigen-antibody context information during forward propagation, the embedding $r_{local}$\nand $r_{global}$ are added by a skip connection module (He et al., 2016), then execute softmax to obtain\nthe final probability distribution."}, {"title": "4.3 MODEL TRAINING AND INFERENCE", "content": "The overall training objective The training objective is to minimize the probability distributions\npredicted by the network under two conditions at each time step and the true posterior distribution\nat the same time step. Therefore, we choose KL divergence between the two distributions at each\nresidue in the CDR region as the training loss function,\n$L_{type} = E_{R_t\\sim p} \\Big[-\\sum_{j}^m D_{KL} \\Big(q \\Big(s_t^{j-1} | s_t^j, s_t\\Big) \\Big|| p \\Big(s_t^{j-1} | R_t, C_{ab}, C_{ag}, A\\Big)\\Big) \\Big]$ (5)\nThe training objective of the whole diffusion process is:\n$L = E_{t\\sim Uniform \\{1...T\\}} L_{type}$ (6)\nConditional reverse diffusion process We employ DDPM to generate sequences. The model starts\nfrom time step T, initializing each site of the antibody CDR region as a uniform distribution. Then,\nthrough the frozen ESM encoder E(\u00b7), learned global context network F(\u00b7)[j] and the local CDR-\nfocused network G(\u00b7)[j], they predict the noise distribution at each time step jointly and denoise\nstep-by-step:\net = E(Sab UR) (7)"}, {"title": "5 EXPERIMENTS", "content": "To evaluate the performance of our model's generation, we utilize two tasks: antibody CDR se-\nquence inverse folding (Section 5.1) and antibody optimization based on sequence design (Section\n5.2), to compare with the baselines. Additionally, we conducted ablation experiments and further\nanalysis to demonstrate the effectiveness of the retrieval-augmented method (Section 5.3).\nThe dataset for training the model is obtained from the SAbDab and our established CDR-like\nfragments dataset. Following the previous work (Luo et al., 2022), we first eliminated structures\nwith a resolution lower than 4\u00c5 and removed antibodies that target non-protein antigens. Chothia\n(Chothia & Lesk, 1987) in ANARCI (Dunbar & Deane, 2016) is used for renumbering antibody\nresidues. We clustered the SADab datasets based on 50% sequence similarity in the CDR-H3 region,\nand chose 50 PDB files comprising 63 antibody-antigen complex structures as the test set. To ensure\ndistinct training and test sets, we removed structures from the training set that were part of the same\nclusters as those in the test set."}, {"title": "5.1 \u0391\u039d\u03a4\u0399\u0392ODY CDR SEQUENCE INVERSE FOLDING", "content": "Baselines For traditional methods, we simulated a method of grafting using CDR-like data in the\nprocess of rational antibody design. Specifically, we directly graft the retrieved top-1 CDR-like\nfragment onto the antibody framework, termed Grafting. For deep learning methods, we selected\na series of state-of-the-art protein inverse folding models for comparison with our work, including\nProteinMPNN (Dauparas et al., 2022), a model that utilizes message passing neural network to\ndesign sequences with a fixed protein backbone; ESM-IF (Hsu et al., 2022), a protein inverse folding\nmodel that trained on millions of predicted structures; Diffab-fix (Luo et al., 2022), which can fix the\nbackbone structure and iteratively generate candidate sequences from pure noise in sequence space\nusing diffusion; AbMPNN (Dreyer et al., 2023), a model fine-tuned ProteinMPNN on antibody\nsequence and structure. Because it is not open-sourced, we evaluate it on its own test set. For more\nbaseline details, please refer to Appendix A.5.\nMetrics To evaluate the accuracy and rationality of the sequences generated by the model, we se-\nlected the following three popular evaluation metrics: (1) Amino Acid Recovery (AAR,%): AAR\nrefers to the ratio of positions where the designed sequence and the true CDR sequence have the\nsame amino acid; (2) Self-consistency RMSD (scRMSD, \u00c5 ): To calculate scRMSD, we refold the\nantibody sequences generated by the model using ABodyBuilder2 (Abanades et al., 2023). Then, we"}, {"title": "5.2 ANTIBODY FUNCTIONALITY OPTIMIZATION", "content": "In this section, we focus on the evolution of antibody sequences and evaluate whether the structure\nof the evolved sequence has greater functionality compared to the structure of the folded original\nsequence. To this end, we first fold the designed CDR-H3 sequences with framework sequences and\nthe original real antibody sequences into complete protein structures using ABodyBuilder2. Then,\nwe use FastRelax and InterfaceAnalyzer in PyRosetta (Alford et al., 2017) to relax the structure and\ncalculate the binding energy AG of the antibody-antigen complex.\nMetrics We use various metrics to evaluate the efficacy and functionality of our designed antibodies:\n(1) \u2206\u2206G: This metric represents the difference in binding energy between the complex with the\ndesigned CDR folded into the structure and the original complex binding energy. (2) \u0394AG-seq:\nThis metric measures the difference in binding energy between the complex with the designed CDR\nsequence folded into the structure and the binding energy of the original antibody sequence folded\ninto the structure. It aims to eliminate errors introduced by the folding tool, allowing for a direct\ncomparison of sequence functionality. (3) IMP-seq: This metric indicates the percentage of designed"}, {"title": "5.3 ANALYSIS", "content": "Ablation We conducted a series of ablation experiments for CDR-H3 following the settings de-\nscribed in Section 5.1 to validate the effectiveness and relative contributions of the additional con-\nditions and data we introduced. The specific objectives are: (1) to verify the effectiveness of the\nretrieval augment module; (2) to assess the validity of the retrieved data; and (3) to evaluate the\neffectiveness of the evolutionary embedding.\nAs shown in Table 4, We demonstrated the retrieval augment module's effectiveness by inputting\nthe CDR sequence's ground truth into this module. We also removed the retrieval augmentation\nmechanism and the evolutionary embedding mechanism respectively to validate their effectiveness.\nThe experimental results show that both the retrieval augmentation module and the evolutionary em-\nbedding module individually improve performance, and using them together maximizes the model's\nperformance.\nEffect of retrieval dataset To further analyze the benefits brought by the retrieval mechanism and\nretrieved motifs, we conducted a series of comparative experiments on the value k of CDR-like\nfragments selected as conditions in the diffusion network, as shown in Figure 4. We found that\nwhen the value of k is low, it brings negative benefits to the model, which may be due to overfitting.\nAs the value of k increases, the model performance also gradually improves. When k equals 15, the\nmodel achieves the best performance. But when k exceeds 15, the additional information instead\nintroduces noise to the model, leading to performance degradation."}, {"title": "6 CONCLUSION AND FUTURE WORKS", "content": "In this work, we propose a retrieval-augmented diffusion generative model RADAb for antibody se-\nquence design. This model leverages global geometric information and local template information,\nincorporating these conditions into the diffusion process to enhance antibody sequence design and\noptimization. Experimental results demonstrate that RADAb achieves state-of-the-art performance\nacross multiple tasks. The main limitation of this work is that it has not yet been fully validated in\nwet lab experiments, which will be one of the major tasks in the future. Since we have proposed a"}, {"title": "A ADDITIONAL DETAILS", "content": ""}, {"title": "A.1 MODEL DETAILS", "content": "For feature dimensions, we set the single residue feature dimension to 128 and the pair feature\ndimension to 64. We leverage 6 IPA layers to capture geometry information. ESM2 650M is utilized\nin our model to create the embedding of antibody sequences, and the embedding dimension is 1280.\nIn the local CDR-focus network, two layers of axial attention were used (two tied row self-attention\nand two column self-attention). The embedding dimension is 384, the hidden dimension is 1536,\nand number of attention heads is 6."}, {"title": "A.2 IMPLEMENTATION DETAILS", "content": "Our model was developed and executed within the PyTorch framework. For training, We chose the\nAdam optimizer with a learning rate of 0.0001, weight decay of 0.0, and momentum parameters\nbetal and beta2 set to 0.9 and 0.999, respectively. To dynamically adjust the learning rate, we\nemployed plateau as learning rate scheduler. When the validation loss plateaued, the learning rate\nwas reduced by a factor of 0.8, with a minimum learning rate set to 5e-6. The scheduler's patience\nwas set to 10 epochs. The batch size is 8 during training. We design 8 samples for each CDR in the\ntest set. All experiments are run on a single RTX4090 GPU, with a memory storage of 24GB.\nDue to the high variability and specificity of the CDRH3 region, and it is considered the most criti-\ncal part in determining antigen-antibody binding. We conducted separate training for the sequence\ndesign of this region, adding and removing noise only for the CDRH3 region in each training itera-\ntion, with a total of 100,000 iterations. The other five regions, being more conserved, were trained\ntogether for a total of 250,000 iterations (approximately equivalent to 50,000 iterations per region).\nThe reverse generation process time step t is set to 100."}, {"title": "A.3 IMPLEMENTATION OF STRUCTURAL RETRIEVAL", "content": "The input consists of the backbone atom coordinates of each amino acid in the CDR region, forming\na set of coordinate points X. T represents the structures of all proteins in the PDB database. A\nrepresents a set of protein fragments representing CDR-like fragments corresponding to the input\nCDR structure. C represents the set of fragments of each structure with a length of m. J represents\na linear motif centered on residue j in the structure, with a length equal to the query fragment.\nAssume that the coordinates of residue j are aligned with the central residue of X, and then com-\npute the RMSD of X when aligned onto 7. If the input contains discontinuous multiple structures,\nCRMSD will be the cumulative RMSD of these structures. MaxA, maxB, and maxC are three dif-\nferent upper-bound thresholds. These thresholds are selected to improve the speed and accuracy of\nthe retrieval algorithm (For detailed proof, please refer to MASTER (Zhou & Grigoryan, 2015))."}, {"title": "A.4 IMPLEMENTATION OF CDR-LIKE DATABASE CONSTRUCTING", "content": "To eliminate the computational overhead caused by structural retrieval during the model's training\nand inferencing, we followed previous work (Aguilar Rangel et al., 2022) and initially executed the\nretrieval algorithm on all CDR structures of all antibodies to construct a CDR-like database.\nEach of the CDR structures is used as a query to search for structurally similar motifs in the PDB\ndatabase. The MASTER algorithm is used to match all CDRs against the entire PDB database to find\nCDR-like structures. This structural search is based on the Kabsch algorithm, using the RMSD of\nthe Ca coordinates. For CDR fragments of length 4, the RMSD threshold is 0.4, and the threshold is\nincreased by 0.05 \u00c5 for each additional residue (with a maximum threshold set to 1.0 \u00c5). In this way,\nwe obtain a CDR-like fragments database corresponding to all CDR structures. Except for strictly\nfiltering out results identical to real CDR sequences, no CDR sequence information was leaked in\nthis process."}, {"title": "A.5 BASELINE DETAILS", "content": ""}, {"title": "A.5.1 TRADITIONAL METHODS", "content": "Rosetta-Fixbb (Adolf-Bryfogle et al., 2018) Rosetta-Fixbb can use energy functions for antibody\nCDR sequence design. Since DiffAb has already been proven to outperform it (Luo et al., 2022; Wu\n& Li, 2023) on sequence design task, we did not conduct additional comparisons.\nGrafting To simulate the rational design commonly used in traditional antibody design methods,\nwhich often involves grafting CDR loops. For each CDR region, we directly selected the top-1 frag-\nment(best) from the retrieval database for the structures in the test set and replaced the corresponding\noriginal CDR loop sequences with it."}, {"title": "A.5.2 DEEP LEARNING METHODS", "content": "ProteinMPNN (Dauparas et al., 2022) ProteinMPNN is a deep learning framework for protein se-\nquence inverse folding. It leverages a message passing neural network to model the complex rela-\ntionships between amino acids in a protein structure. We use the antibody's backbone structure as\ninput and keep the sequences outside the CDR regions to be designed fixed. We design sequences\nfor each CDR region separately. The sampling temperature is set to the default value of 0.1.\nEsm-IF1 (Hsu et al., 2022) Esm-IF1 is a protein sequence inverse folding model trained on millions\nof AlphaFold2 predicted structures. We use the antibody's backbone structure as input and keep the\nsequences outside the CDR regions to be designed fixed. We design sequences for each CDR region\nseparately. The sampling temperature is set to the value of 0.2.\nDiffab-fix (Luo et al., 2022) Diffab is a diffusion model that can design sequences of CDR re-\ngion with a fixed CDR backbone. It takes antigen-antibody framework context as condition to\ndesign CDR sequence. For a fair comparison, we retrained it with the default training configuration\nfixbb.yml.\nAbMPNN (Dreyer et al., 2023) AbMPNN is fine-tuned by antibody structure data and predicted\nOAS (Observed Antibody Space) structure data. Its model architecture is consistent with Protein-\nMPNN but achieves better performance in antibody inverse folding. We use the antibody's backbone\nstructure as input and keep the sequences outside the CDR regions to be designed fixed. However,\nit is not open-sourced yet, so we evaluate it on its own test set. We design sequences for each CDR\nregion separately. The sampling temperature is set to the default value of 0.1."}, {"title": "A.6 EXPERIMENT ON CDR-H3'S LENGTH", "content": ""}, {"title": "B RESTRICT THE EVOLUTION SPACE BY STRUCTURAL RETRIEVAL", "content": "The search space for protein sequences is vast. If the length of the sequence to be designed is L, the\nsearch space is 20L. General deep learning methods have already significantly reduced the sequence\nsearch space, generating sequences of much higher quality than random sequences. However, it is\nstill challenging to find mutation spaces with high fitness. To restrict this space, we first fix the\nbackbone structure of the CDR region, limiting the space to a specific area. Subsequently, we add\nmore constraints to the mutation space by retrieving the PDB database for motifs similar to the CDR\nbackbone structure and taking them as the model's conditions, as shown in Figure 2 C."}, {"title": "C STRUCTURE RECONSTRUCTION", "content": "To reconstruct the antibody structure, we use ABodyBuilder2 (Abanades et al., 2023), a deep learn-\ning model capable of predicting antibody light chain-heavy chain complexes. It is significantly faster\nthan AlphaFold2 and offers higher prediction accuracy. We insert the designed CDR sequences into\nthe antibody framework sequence, input it into ABodyBuilder2 to fold, and use OpenMM relax to\nobtain the structure corresponding to the new CDR sequences. Subsequently, we align the structure\nto the real antibody framework. Finally, we use the fastrelax function in PyRosetta (Alford et al.,\n2017), with the score function set to ref2015 and max iteration set to 1000, to relax the structure."}, {"title": "D TRAINING AND INFERENCE ALGORITHM", "content": "In this section, we provide a detailed algorithm for the training (Algorithm 2) and inferencing (Al-\ngorithm 3) processes."}, {"title": "D.1 TRAINING ALGORITHM", "content": ""}, {"title": "D.2 SAMPLING ALGORITHM", "content": ""}, {"title": "E CASE STUDY", "content": "We select a portion of the optimized antibodies in Figure S2. They achieved lower binding energy\ncompared to the original antibody structures. Various examples demonstrate that redesigning anti-\nbody sequences in the CDR regions by fixing the backbone structure can produce antibodies with"}, {"title": "F LIMITATIONS", "content": "Quality of retrieved data Due to the inherent limitations of the MASTER algorithms, the retrieved\nlinear motifs may have structural issues. Despite careful screening and filtering, a tiny portion of the\ndata might have lengths that differ from the original CDR loops or may even become discontinuous\ndue to missing residues. These exceptional cases may have a negative impact on our model. We\nhope that advances in structural retrieval and improvements in alignment will jointly address this\nissue.\nComputational Cost When constructing the CDR-like fragments database, searching the entire\nPDB database using all CDR structures from the SabDab database takes approximately 100 hours."}]}