[{"title": "Classifier-Free Guidance is a Predictor-Corrector", "authors": ["Arwen Bradley", "Preetum Nakkiran"], "abstract": "We investigate the theoretical foundations of classifier-free guidance (CFG). CFG is the dominant method of conditional sampling for text-to-image diffusion models, yet unlike other aspects of diffusion, it remains on shaky theoretical footing. In this paper, we first disprove common misconceptions, by showing that CFG interacts differently with DDPM (Ho et al., 2020) and DDIM (Song et al., 2021), and neither sampler with CFG generates the gamma-powered distribution \\(p(x|c)^{\\gamma}p(x)^{1-\\gamma}\\). Then, we clarify the behavior of CFG by showing that it is a kind of predictor-corrector method (Song et al., 2020) that alternates between denoising and sharpening, which we call predictor-corrector guidance (PCG). We prove that in the SDE limit, CFG is actually equivalent to combining a DDIM predictor for the conditional distribution together with a Langevin dynamics corrector for a gamma-powered distribution (with a carefully chosen gamma). Our work thus provides a lens to theoretically understand CFG by embedding it in a broader design space of principled sampling methods.", "sections": [{"title": "Introduction", "content": "Classifier-free-guidance (CFG) has become an essential part of modern diffusion models, especially in text-to-image applications (Dieleman, 2022; Rombach et al., 2022; Nichol et al., 2021; Podell et al., 2023). CFG is intended to improve conditional sampling, e.g. generating images conditioned on a given class label or text prompt (Ho and Salimans, 2022). The traditional (non-CFG) way to do conditional sampling is to simply train a model for the conditional distribution \\(p(x | c)\\), including the conditioning \\(c\\) as auxiliary input to the model. In the context of diffusion, this means training a model to approximate the conditional score \\(s(x, t, c) := \\nabla_x \\log p_t (x | c)\\) at every noise level \\(t\\), and sampling from this model via a standard diffusion sampler (e.g. DDPM). Interestingly, this standard way of conditioning usually does not perform well for diffusion models, for reasons that are unclear. In the text-to-image case for example, the generated samples tend to be visually incoherent and not faithful to the prompt, even for large-scale models (Ho and Salimans, 2022; Rombach et al., 2022).\nGuidance methods, such as CFG and its predecessor classifier guidance (Sohl-Dickstein et al., 2015; Song et al., 2020; Dhariwal and Nichol, 2021), are methods introduced to improve the quality of conditional samples. During training, CFG requires learning a model for both the unconditional and conditional scores (\\(\\nabla_x \\log p_t (x)\\) and \\(\\nabla_x \\log p_t (x|c)\\)). Then, during sampling, CFG runs any standard diffusion sampler (like DDPM or DDIM), but replaces the true conditional scores with the \"CFG scores\"\n\\[\\S(x, t, c) := \\gamma\\nabla_x \\log p_t (x | c) + (1 - \\gamma)\\nabla\\log p_t(x),\\]\nfor some \\(\\gamma > 0\\). This turns out to produce much more coherent samples in practice, and so CFG is used in almost all modern text-to-image diffusion models (Dieleman, 2022). A common intuition for why CFG works starts by observing that Equation (1) is the score of a gamma-powered distribution:\n\\[p_{t,\\gamma}(x|c) := p_t(x)^{1-\\gamma}p_t(x|c)^{\\gamma},\\]"}, {"title": "Preliminaries", "content": "We adopt the continuous-time stochastic differential equation (SDE) formalism of diffusion from Song et al. (2020). These continuous-time results can be translated to discrete-time algorithms; we give explicit algorithm descriptions for our experiments."}, {"title": "Diffusion Samplers", "content": "Forward diffusion processes start with a conditional data distribution \\(p_0(x|c)\\) and gradually corrupt it with Gaussian noise, with \\(p_t (x|c)\\) denoting the noisy distribution at time \\(t\\). The forward diffusion runs up to a time \\(T\\) large enough that \\(p_T\\) is approximately pure noise. To sample from the data distribution, we first sample from the Gaussian distribution \\(p_T\\) and then run the diffusion process in reverse (which requires an estimate of the score, usually learned by a neural network). A variety of samplers have been developed to perform this reversal. DDPM (Ho et al., 2020) and DDIM (Song et al., 2021) are standard samplers that correspond to discretizations of a reverse-SDE and reverse-ODE, respectively. Due to this correspondence, we refer to the reverse-SDE as DDPM and the reverse-ODE as DDIM for short. We will mainly consider the variance-preserving (VP) diffusion process from Ho et al. (2020), although most of our discussion applies equally to other settings (such as variance-exploding). The forward process, reverse-SDE, and equivalent reverse-ODE for the VP conditional diffusion are (Song et al., 2020)\n\\[\\begin{aligned}\\\\&\\text{Forward SDE}: &\\ dx = - \\frac{1}{2}\\beta_t x dt + \\sqrt{\\beta_t}dw. \\\\\\&\\text{DDPM SDE}: &\\ dx = - \\frac{1}{2}\\beta_t x dt - \\beta_t \\nabla_x \\log p_t(x|c)dt + \\sqrt{\\beta_t}dw \\\\\\&\\text{DDIM ODE}: &\\ dx = - \\frac{1}{2}\\beta_t x dt - \\frac{1}{2} \\beta_t \\nabla_x \\log p_t(x|c)dt.\\end{aligned}\\]\nThe unconditional version of each sampler simply replaces \\(p_t(x|c)\\) with \\(p_t(x)\\). Note that the score \\(\\nabla_x \\log p_t (x|c)\\) appears in both (4) and (5). Intuitively, the score points in a direction toward higher probability, and so it helps to reverse the forward diffusion process. The score is unknown in general, but can be learned via standard diffusion training methods."}, {"title": "Classifier-Free Guidance", "content": "CFG replaces the usual conditional score \\(\\nabla_x \\log p_t (x|c)\\) in (4) or (5) at each timestep \\(t\\) with the alternative score \\(\\nabla_x \\log p_{t,\\gamma}(x|c)\\). In SDE form, the CFG updates are\n\\[\\begin{aligned}\\text{CFGDDPM}:\\ \\ dx &= -\\frac{1}{2}\\beta_t x dt - \\beta_t \\nabla_x \\log p_{t,\\gamma}(x|c)dt + \\sqrt{\\beta_t}dw \\\\\\\\ \\text{CFGDDIM}: \\ \\ dx &= -\\frac{1}{2}\\beta_t x dt - \\frac{1}{2} \\beta_t \\nabla_x \\log p_{t,\\gamma}(x|c)dt, \\end{aligned}\\]\nwhere \\(\\nabla_x \\log p_{t,\\gamma}(x|c) = (1 - \\gamma)\\nabla_x \\log p_t(x) + \\gamma\\nabla_x \\log p_t (x|c)\\)."}, {"title": "Langevin Dynamics", "content": "Langevin dynamics (Rossky et al., 1978; Parisi, 1981) is another sampling method, which starts from an arbitrary initial distribution and iteratively transforms it into a desired one. Langevin dynamics (LD) is given by the following SDE (Robert et al., 1999)\n\\[dx = \\frac{1}{2} \\nabla \\log p(x)dt + \\sqrt{\\epsilon}dw.\\]\nLD converges (under some assumptions) to the steady-state \\(p(x)\\) (Roberts and Tweedie, 1996). That is, letting \\(p_s(x)\\) denote the solution of LD at time \\(s\\), we have \\(\\lim_{s\\rightarrow\\infty} p_s(x) = p(x)\\). Similar to diffusion sampling, LD requires the score of the desired distribution \\(p\\) (or a learned estimate of it)."}, {"title": "Misconceptions about CFG", "content": "We first observe that the exact definition of CFG matters: specifically, the sampler with which it used. Without CFG, DDPM and DDIM generate equivalent distributions. However, we will prove that with CFG, DDPM and DDIM can generate different distributions, as follows:"}, {"title": "Classifier-Free as a predictor-corrector", "content": "The previous sections illustrated the subtlety in understanding CFG. We can now state our main structural characterization, that CFG is equivalent to a special kind of predictor-corrector method (Song et al., 2020)."}, {"title": "Predictor-Corrector Guidance", "content": "As a warm-up, suppose we actually wanted to sample from the gamma-powered distribution:\n\\[p_{\\gamma}(x|c) \\propto p(x)^{1-\\gamma}p(x|c)^{\\gamma}.\\]\nA natural strategy is to run Langevin dynamics w.r.t. \\(p_\\gamma\\). This is possible in theory because we can compute the score of \\(p_\\gamma\\) from the known scores of \\(p(x)\\) and \\(p(x | c)\\):\n\\[\\nabla_x \\log p_{\\gamma}(x | c) = (1 - \\gamma)\\nabla_x \\log p(x) + \\gamma\\nabla_x \\log p(x | c).\\]\nHowever this won't work in practice, due to the well-known issue that vanilla Langevin dynamics has impractically slow mixing times for many distributions of interest (Song and Ermon, 2019). The usual remedy for this is to use some kind of annealing, and the success of diffusion teaches us that the diffusion process defines a good annealing path (Song et al., 2020; Du et al., 2023). Combining these ideas yields an algorithm remarkably similar to the predictor-corrector methods introduced in Song et al. (2020). For example, consider the following diffusion-like iteration, starting from \\(x_\\tau \\sim \\mathcal{N}(0, \\sigma_\\tau)\\) at \\(t = T\\). At timestep \\(t\\),\n1. Predictor: Take one diffusion denoising step (e.g. DDIM or DDPM) w.r.t. \\(p_t(x | c)\\), using score \\(\\nabla_x \\log p_t (x | c)\\), to move to time \\(t' = t - \\Delta t\\).\n2. Corrector: Take one (or more) Langevin dynamics steps w.r.t. distribution \\(p_{t',\\gamma}\\), using score\n\\[\\nabla_x \\log p_{t',\\gamma}(x | c) = (1 - \\gamma)\\nabla_x \\log p_t (x) + \\gamma\\nabla_x \\log p_t (x | c).\\]"}, {"title": "SDE limit of PCG", "content": "Consider the version of PCG defined in Algorithm 1, which uses DDIM as predictor and a particular LD on the gamma-powered distribution as corrector. We take \\(K = 1\\), i.e. a single LD step per iteration. Crucially, we set the LD step size such that the Langevin noise scale exactly matches the noise scale of a (hypothetical) DDPM step at the current time (similar to Du et al. (2023)). In the limit as \\(\\Delta t \\rightarrow 0\\), Algorithm 1 becomes the following SDE (see Appendix B):\n\\[dx = \\underbrace{ADDIM(x, t)}_{\\text{Predictor}} + \\underbrace{\\Delta_{LD}^G(x, t, \\gamma)}_{\\text{Corrector}} =: \\Delta_{PCG}^{DDIM} (x, t, \\gamma),\\]\nwhere \\(\\text{ADDIM}(x, t) = -\\frac{1}{2} \\beta_t(x - \\nabla \\log p_t (x|c))dt\\) and\n\\[\\Delta_{LD}^G(x, t, \\gamma) = -\\frac{1}{2} (\\underbrace{(1 - \\gamma)\\nabla \\log p_t(x) + \\gamma \\nabla \\log p_t(x|c)}_{\\text{guidance}}) dt + \\sqrt{\\beta_t}dw.\\]\nAbove, \\(\\text{ADDIM}(x, t)\\) is the differential of the DDIM ODE (5), i.e. the ODE can be written as \\(dx = \\text{ADDIM}(x, t)\\). And \\(\\Delta_{LD}^G(x, t, \\gamma)\\), where G stands for \u201cguidance\u201d, is the limit as \\(\\Delta t \\rightarrow 0\\) of the Langevin dynamics step in PCG, which behaves like a differential of LD (see Appendix B)."}, {"title": "Discussion and Related Works", "content": "There have been many recent works toward understanding CFG. To better situate our work, it helps to first discuss the overall research agenda."}, {"title": "Understanding CFG: The Big Picture", "content": "We want to study the question of why CFG helps in practice: specifically, why it improves both image quality and prompt adherence, compared to conditional sampling. We can approach this question by applying a standard generalization decomposition. Let \\(p(x|c)\\) be the \u201cground truth\u201d population distribution; let \\(p^* (x|c)\\) be the distribution generated by the ideal CFG sampler, which exactly solves the CFG reverse SDE for the ground-truth scores (note that at \\(\\gamma = 1\\), \\(p_1(x|c) = p(x|c)\\)); and let \\(p_{\\gamma}(x|c)\\) denote the distribution of the real CFG sampler, with learnt scores and finite discretization. Now, for any image distribution \\(q\\), let \\(\\text{PerceivedQuality}[q] \\in \\mathbb{R}\\) denote a measure of perceived sample quality of this distribution to humans. We cannot mathematically specify this notion of quality, but we will assume it exists for analysis. Notably, \\(\\text{PerceivedQuality}\\) is not a measurement of how close a distribution is to the ground-truth \\(p(x|c)\\) \u2013 it is possible for a generated distribution to appear even \u201chigher quality\" than the ground-truth, for example. We can now decompose:\n\\[\\underbrace{\\text{Perceived Quality } [p_{\\gamma}]}_{\\text{Real CFG}} = \\underbrace{\\text{PerceivedQuality}[p^*]}_{\\text{Ideal CFG}} - \\underbrace{(\\text{PerceivedQuality}[p^*] - \\text{PerceivedQuality}[p_{\\gamma}])}_{\\text{Generalization Gap}}.\\]\nTherefore, if the LHS increases with \\(\\gamma\\), it must be because at least one of the two occurs:\n1. The ideal CFG sampler improves in quality with increasing \\(\\gamma\\). That is, CFG distorts the population distribution in a favorable way (e.g. by sharpening it, or otherwise).\n2. The generalization gap decreases with increasing \\(\\gamma\\). That is, CFG has a type of regularization effect, bringing population and empirical processes closer.\nIn fact, it is likely that both occur. The original motivation for CG and CFG involved the first effect: CFG was intended to produce \u201clower-temperature\u201d samples from a sharpened population distribution (Dhariwal and Nichol, 2021; Ho and Salimans, 2022). This is particularly relevant if the model is trained on poor-quality datasets (e.g. cluttered images from the web), so we want to use guidance to sample from a higher-quality distribution (e.g. images of an isolated subject). On the other hand, recent studies have given evidence for the second effect. For example, Karras et al. (2024) argues that unguided diffusion sampling produces \u201coutliers,\u201d which are avoided when using guidance \u2013 this can be thought of as guidance reducing the generalization gap, rather than improving the ideal sampling distribution. Another interpretation of the second effect is that guidance could enforce a good inductive bias: it \"simplifies\u201d the family of possible output distributions in some sense, and thus simplifies the learning problem, reducing the generalization gap. Finally, this generalization decomposition applies to any intervention to the SDE, not just increasing guidance strength. For example, increasing the Langevin steps in PCG (parameter \\(K\\)) also shrinks the generalization gap, since it reduces the discretization error.\nIn this framework, our work makes progress towards understanding both terms on the RHS of Equation 18, in different ways. For the first term, we identify structural properties of ideal CFG, by showing that \\(p^*\\) can be equivalently generated by a standard technique (an annealed Langevin dynamics). For the second term, the PCG framework highlights the ways in which errors in the learned score can contribute to a generalization gap, during both the denoising step and the LD step (the latter would move toward an inaccurate steady-state distribution)."}, {"title": "Open Questions and Limitations", "content": "In addition to the above, there are a number of other questions left open by our work. First, we study only the stochastic variant of CFG (i.e. CFGDDPM), and it is not clear how to adapt our analysis to the more commonly used deterministic variant (CFGDDIM). This is subtle because the two CFG variants can behave very differently in theory, but appear to behave similarly in practice. It is thus open to identify plausible theoretical conditions which explain this similarity\u00b9; we give a suggestive experiment in Figure 6. More broadly, it is open to find explicit characterizations of CFG's output distribution, in terms of the original \\(p(x)\\) and \\(p(x|c)\\) \u2013 although it is possible tractable expressions do not exist.\nFinally, we presented PCG primarily as a tool to understand CFG, not as a practical algorithm in itself. Nevertheless, the PCG framework outlines a broad family of guided samplers, which may be promising to explore in practice. For example, the predictor can be any diffusion denoiser, including CFG itself. The corrector can operate on any distribution with a known score, including compositional distributions as in Du et al. (2023), or any other distribution that might help sharpen or otherwise improve on the conditional distribution. Finally, the number of Langevin steps could be adapted to the timestep, similar to Kynk\u00e4\u00e4nniemi et al. (2024), or alternative samplers could be considered (Du et al., 2023; Neal, 2012; Ma et al., 2015)."}, {"title": "Stable Diffusion Examples", "content": "We include several examples running predictor-corrector guidance on Stable Diffusion XL (Podell et al., 2023). These serve primarily to sanity-check our theory, not as a suggestion for practice. For all experiments, we use PCGDDIM as implemented explicitly in Algorithm 2\u00b2. Note that PCG offers a more flexible design space than standard CFG; e.g. we can run multiple corrector steps for each denoising step to improve the quality of samples (controlled by parameter K in Algorithm 2).\nCFG vs. PCG. Figure 1 illustrates the equivalence of Theorem 3: we compare CFGDDPM with guidance \\(\\gamma\\) to PCGDDIM with exponent \\(\\gamma' := (2\\gamma - 1)\\). We run CFGDDPM with 200 denoising steps, and PCGDDIM with 100 denoising steps and \\(K = 1\\) Langevin corrector step per denoising step. Corresponding samples appear to have qualitatively similar guidance strengths, consistent with our theory.\nEffects of Guidance and Corrector. In Figure 5 we show samples from PCGDDIM, varying the guidance strength and Langevin iterations (i.e. parameters \\(\\gamma\\) and K respectively in Algorithm 2). We also include standard CFGDDIM samples for comparison. All samples used 1000 denoising steps for the base predictor. Overall, we observed that increasing Langevin steps tends to improve the overall image quality, while increasing guidance strength tends to improve prompt adherence. In particular, sufficiently many Langevin steps can sometimes yield high-quality conditional samples, even without any guidance (\\(\\gamma = 1\\)); see Figure 7 in the Appendix for another such example. This is consistent with the observations of Song et al. (2020) on unguided predictor-corrector methods. It is also related to the findings of Du et al. (2023) on MCMC methods: Du et al. (2023) similarly use an annealed Langevin dynamics with reverse-diffusion annealing, although they focus on general compositions of distributions rather than the specific gamma-powered distribution of CFG.\nNotice that in Figure 5, increasing the number of Langevin steps appears to also increase the \"effective\" guidance strength. This is because the dynamics does not fully mix: one Langevin step \\(K = 1\\) does not suffice to fully converge the intermediate distributions to \\(p_{t,\\gamma}.\\)"}, {"title": "Conclusion", "content": "In this paper, we have shown that while CFG is not a diffusion sampler on the gamma-powered data distribution \\(p_0(x)^{1-\\gamma}p_0(x|c)^{\\gamma}\\), it can be understood as a particular kind of predictor-corrector, where the predictor is a DDIM denoiser, and the corrector at each step t is one step of Langevin dynamics on the gamma-powered noisy distribution \\(p_t(x)^{1-\\gamma'}p_t(x|c)^{\\gamma'}\\), with \\(\\gamma' = (2\\gamma - 1)\\). Although Song et al. (2020)'s Predictor-Corrector algorithm has not been widely adopted in practice, perhaps due to its computation expense relative to samplers like DPM++ (Lu et al., 2022b), it turns out to provide a lens to understand the unreasonable practical success of CFG. On a practical note, PCG encompasses a rich design space of possible predictors and correctors for future exploration, that may help improve the prompt-alignment, diversity, and quality of diffusion generation."}, {"title": "A.1 Counterexample 1 Detail", "content": "Counterexample 1 (equation 10) has\n\\[\\begin{aligned}&p_0(x) \\sim \\mathcal{N}(0,2) \\\\&p_0(x|c = 0) \\sim \\mathcal{N}(0, 1). \\end{aligned}\\]\nThe \\(\\gamma\\)-powered distribution is\n\\[\\begin{aligned}&p_{0,\\gamma}(x|c = 0) = p_0(x|c)^{\\gamma}p_{c=0}(x)^{1-\\gamma} \\propto e^{-\\frac{x^2}{2}}e^{-\\frac{x^2(1-\\gamma)}{4}} = e^{-\\frac{x^2(2+\\gamma-1)}{4}} \\\\&\\sim \\mathcal{N}(0, \\frac{2}{\\gamma+1}). \\end{aligned}\\]\nWe consider the simple variance-exploding diffusion defined by the SDE\n\\[dx = \\sqrt{t}dw.\\]\nThe DDIM sampler is a discretization of the reverse ODE\n\\[\\frac{dx}{dt} = \\frac{1}{2} \\nabla_x \\log p_t (x),\\]\nand the DDPM sampler is a discretization of the reverse SDE\n\\[dx = -\\nabla_x \\log p_{t,\\gamma}(x)dt + dw.\\]\nFor CFGDDIM or CFGDDPM, we replace the score with CFG score \\(\\nabla_x \\log p_{t,\\gamma}(x)\\).\nDuring training we run the forward process until some time t = T, at which point we assume it is fully-noised, so that approximately\n\\[p_T(x|c = 0) \\sim \\mathcal{N}(0, T)\\]\n(in this case the exact distribution \\(p_T(x|c = 0) \\sim \\mathcal{N}(0, T + 1)\\) so we need to choose \\(T \\gg 1\\) to ensure sufficient terminal noise). At inference time we choose an initial sample \\(x_T \\sim \\mathcal{N}(0, T)\\) and run CFGDDIM from \\(t = T \\rightarrow 0\\) to obtain a final sample \\(x_0\\).\nCFGDDIM For Counterexample 1, the CFGDDIM ODE has a closed-form solution (derivation in section A.5):\n\\[\\text{CFGDDIM}: \\ \\frac{dx}{dt} = \\frac{1}{2} \\nabla_x \\log p_{t,\\gamma}(x) = -x\\underbrace{\\frac{\\gamma}{2(1+t)} + \\frac{1 - \\gamma}{2(2+t)}}_{a(t)}.\\]\n\\[a(t) = \\frac{\\gamma}{2(1+t)} + \\frac{(1-\\gamma)}{2(2+t)} = \\frac{(2-1)t+2}{2(2+t)(1+t)}\\]\n\\[a(t) \\xrightarrow[t \\rightarrow \\infty]{} \\frac{\\gamma}{2(1+t)}\\]\n\\[a(t) \\xrightarrow[]{} x_t\\frac{(2+\\gamma-1)t+2}{t^2}\\]\n\\[\\Rightarrow x_t = x_T* (\\frac{(t+1)}{(T+1)})^a * (\\frac{(t+2)}{(T+2)})^b\\]\n\\[= x_T*\\frac{(t+1)^{(2\\gamma-1)}}{(T+1)^{(2\\gamma-1)}}\\]\n\\[a+b=\\gamma+(1-\\gamma)=1\\]\n\\[(T+1)(T+2)^{1-\\gamma}\\approx (T+1)^{2-\\gamma}\\]\n\\[(1+t)(2+t)^{1-\\gamma}\\approx (1+t)^{2-\\gamma}\\]\n\\[a=b=\\gamma\\]\n\\[x = \\frac{x(1+\\gamma)^{(3-\\gamma)}}{(1+T+T^2)}\\]\n\\[= (1+\\frac{a}{x})^x\\]\n\\[a = lim(1+\\frac{1}{2})^2\\]\n\n\n\nThat is, for a particular initial sample \\(x_T\\), CFGDDIM produces the sample \\(x_t\\) at time \\(t\\). Evaluating at \\(t = 0\\) and taking the limit as \\(T \\rightarrow \\infty\\) yields the ideal denoised \\(x_0\\) sampled by CFGDDIM given an initial sample \\(x_T\\):\n\\[x_0^{CFGDDIM}(x_T) = x_T \\frac{2^{1-\\gamma}}{(T+ 1)^{\\gamma}(T+2)^{1-\\gamma}} \\\\ \\rightarrow x_T \\frac{2^{1-\\gamma}}{T} \\text{ as } T \\rightarrow \\infty.\\]"}, {"title": "A.2 Counterexample 2", "content": "Counterexample 2 (10) is a Gaussian mixture with equal weights and variances.\n\\[\\begin{aligned}&c \\in \\{0,1\\}, p(c = 0) = \\frac{1}{2} \\\\&p_0(x_0|c) \\sim \\mathcal{N}(\\mu^{(c)},\\sigma), \\ \\mu^{(0)} = -\\mu, \\ \\mu^{(1)} = \\mu \\\\&p_0(x_0) \\sim \\frac{1}{2} p_0(x_0|c = 0) + \\frac{1}{2} p_0(x_0|c = 1).\\end{aligned}\\]\nWe noted in the main text that if \\(\\mu\\) is sufficiently large enough that the clusters are approximately"}, {"title": "A.3 Counterexample 3", "content": "We consider a 3-cluster problem to investigate why CFGDDIM and CFGDDPM often appear similar in practice despite being different in theory. Counterexample 3 (10) is a Gaussian mixture with equal weights and variances. We vary the variance to investigate its effect on CFG.\n\\[\\begin{aligned}&c \\in \\{0,1,2\\}, p(c) = \\frac{1}{3} \\\\&p_0(x_0|c) \\sim \\mathcal{N}(\\mu^{(c)}, \\sigma), \\ \\mu^{(0)} = -3, \\ \\mu^{(1)} = 0, \\ \\mu^{(2)} = 3 \\\\&p_0(x_0) \\sim \\frac{1}{3} p_0(x_0|c = 0) + \\frac{1}{3} p_0(x_0|c = 1) + \\frac{1}{3} p_0(x_0|c = 2).\\end{aligned}\\]\nWe run CFGDDIM and CFGDDPM with \\(\\gamma = 3\\), for \\(\\sigma = 1\\) and \\(\\sigma = 2\\). Results are shown in Figure 6."}, {"title": "A.4 Generalization Example 4", "content": "We consider a multi-cluster problem to explore the impact of guidance on generalization:\n\\[p_0(x) \\sim \\mathcal{N}(0,10)\\]\n\\[p_0(x|c = 0) \\sim \\sum_i w_i \\mathcal{N}(\\mu_i, \\sigma),\\]\n\\[\\begin{aligned} &\\mu = (-3, -2.5, -2, -1.5, -1, -0.5, 0, 0.5, 1, 1.5, 2, 2.5) \\\\ &w_i = 0.0476 \\ \\forall i \\neq 6; \\ w_6 = 0.476 \\\\ &\\sigma = 0.1\\end{aligned}\\]"}, {"title": "A.5 Closed-form ODE/SDE solutions", "content": "First, we want to solve equations of the general form \\(\\frac{dx}{dt} = -a(t)x + b(t)\\), which will encompass the ODEs and SDEs of interest to us. All we need for the ODEs is the special \\(b(t) = a(t)c\\), which is easier.\nThe main results are\n\\[\\begin{aligned}&\\frac{dx}{dt} = a(t)(c - x) \\\\&\\Rightarrow x(t) = c + (x_T - c)e^{A(T)-A(t)}\\end{aligned}\\]\nwhere \\(A(t) = \\int a(t)dt\\)\nand\n\\[\\begin{aligned}&\\frac{dx}{dt} = -a(t)x+b(t) \\\\&x(t) = e^{-A(t)} (\\int e^{A(t)}b(t)dt - B(T)) + x_Te^{A(T)-A(t)} \\end{aligned}\\]\nwhere \\(A(t) = \\int a(t)dt, B(t) = \\int e^{A(t)}b(t)dt\\).\nFirst let's consider the special case \\(b(t) = a(t)c\\), which is easier. We can solve it (formally) by separable equations:\n\\[\\begin{aligned}&\\frac{dx}{dt} = a(t)(c - x) \\\\&\\Rightarrow \\int \\frac{1}{c-x} dx = \\int a(t)dt = A(t) \\\\&\\Rightarrow -\\log(c- x) = A(t) + C \\\\& c-x = e^{-A(t)-C} \\\\&\\Rightarrow x(t) = c + Ce^{-A(t)}.\\end{aligned}\\]\nNext we need to apply initial conditions to get the right constants. Remembering that we are actually sampling backward in time from initialization \\(x_T\\), we can solve for the constant \\(C\\) as follows, to obtain result (20):\n\\[\\begin{aligned}&x_T = c + Ce^{-A(T)} \\\\&C = e^{A(T)} (x_T - c) \\\\&x(t) = c + (x_T - c)e^{A(T)-A(t)}.\\end{aligned}\\]\nWe will apply this result to CFGDDIM shortly, but for now we note that for a VE diffusion \\(dx = \\sqrt{t}dw\\)"}, {"title": "A.6 Exact Denoiser for GMM", "content": "For the experiments in Figure 2, we used an exact denoiser, for which we require exact conditional and unconditional scores. Exact scores are available for any GMM as follows. This is well-known (e.g. Karras et al. (2024)) but repeated here for convenience."}, {"title": "B PCG SDE", "content": "We want to show that the SDE limit of Algorithm 1 with K = 1 is\n\\[dx = \\text{ADDIM}(x, t) + \\Delta_{LD}^G(x, t, \\gamma).\\"}]}, 0, "p_t(x_t"]