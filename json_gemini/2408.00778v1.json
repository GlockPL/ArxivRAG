{"title": "Frontend Diffusion: Exploring Intent-Based User Interfaces through Abstract-to-Detailed Task Transitions", "authors": ["Qinshi Zhang", "Latisha Besariani Hendra", "Mohan Chi", "Zijian Ding"], "abstract": "The emergence of Generative Al is catalyzing a paradigm shift in user interfaces from command-based to intent-based outcome specification. In this paper, we explore abstract-to-detailed task transitions in the context of frontend code generation as a step towards intent-based user interfaces, aiming to bridge the gap between abstract user intentions and concrete implementations. We introduce Frontend Diffusion, an end-to-end LLM-powered tool that generates high-quality websites from user sketches. The system employs a three-stage task transition process: sketching, writing, and coding. We demonstrate the potential of task transitions to reduce human intervention and communication costs in complex tasks. Our work also opens avenues for exploring similar approaches in other domains, potentially extending to more complex, interdependent tasks such as video production.", "sections": [{"title": "1 INTRODUCTION", "content": "The development of Generative AI, particularly the capabilities of Large Language Models (LLMs) in interpreting and executing natural language, may be viewed as heralding the first new user interface paradigm shift in 60 years [8]. This shift moves from command-based interactions, typified by command line interfaces and graphical user interfaces, to intent-based outcome specification [8]. This emerging intent-based paradigm potentially enables users to communicate their intentions to machines without necessarily translating them into machine-comprehensible commands, whether through programming languages or graphical buttons. This shift may foster interfaces that support more abstract human expressions, especially for command-intensive tasks such as coding [2, 3].\nCurrently, the interfaces for command-intensive tasks continue to necessitate substantial human intervention, where individuals typically specify incremental steps while AI generates corresponding code, akin to agile programming [11]. However, ongoing advancements in Generative AI capabilities suggest the potential for developing a framework that may bridge the gap between intent-level expression and command-level implementation, potentially enhancing output quality while reducing the need for extensive human intervention. Previous research has demonstrated that Generative AI, such as Large Language Models (LLMs), can complete fixed-scope content curation tasks based on human intent without further intervention or intent iteration. For example, LLMs have shown promise in text summarization tasks [6]. However, Gener-ative Al require greater human intervention for tasks involving increasing amounts of information [4, 7]. It motivates us to develop more effective scaffolding paradigm for Generative AI to respond to human intent and complete tasks in an agent-like manner.\nRecent research has indicated the feasibility of bridging intent expression in abstract tasks to concrete implementation at a more granular level. Examples include the transition from sketching to writing [1] and from design to data analysis [5]. Building upon these findings, we propose exploring more extensive intent-to-command transitions, such as progressing from sketching to writing (planning) and ultimately to coding (see Figure 2). Our choice of website frontend generation as a user interface coding task [10] is motivated by its similarity to sketching. In both cases, the code or sketch serves as a representation of visual elements [9]."}, {"title": "2 SYSTEM DESIGN", "content": "We introduce Frontend Diffusion, an end-to-end LLM-powered high-quality frontend code generation tool, spanning from sketching canvas to website previews. As outlined in the introduction, the frontend generation task progresses through three stages: sketching, writing, and coding Our system utilizes the Claude 3.5 Sonnet language model (Sonnet)\u00b9 for all text and code generation. While Claude represents one of the most advanced language models as of July 2024, we anticipate rapid developments in Generative AI. Therefore, the task transition techniques described herein are designed to be model-agnostic, ensuring their applicability to future, more advanced Generative Al models."}, {"title": "2.1 Sketching: Visual Layout Design and Theme Input", "content": "The system's initial phase comprises a graphical user interface with two key components: a canvas panel for visual representation of the envisioned website layout, and a prompt panel for textual descriptions of the website theme. Upon completion of the user's sketch and theme input, the user can activate the code generation process via \"Generate\" button. The system then converts the sketch into SVG format, followed by a subsequent transformation into JPG format. This two-step conversion process was implemented based on empirical evidence from our tests, showing that language models exhibit better performance when processing images in JPG format compared to images in SVG format."}, {"title": "2.2 Writing: Product Requirements Document Generation", "content": "This phase transforms the user's visual and textual inputs into a structured document, referred to as the Product Requirements Document (PRD), which serves as a blueprint for the website's de-velopment process. The PRD generation process leverages Sonnet. To enhance the visual appearance of the generated websites, the system integrates the Pexels API\u00b2 for image retrieval. The language model is specifically prompted to include image terms and size descriptions (e.g., [school(large)]). These descriptors are subsequently utilized to query the Pexels API, which returns relevant image URLs for incorporation into the PRD."}, {"title": "2.3 Coding: Website Generation and Iterative Refinement", "content": "The coding phase of the system consists of two primary compo-nents: (1) Initial code generation: the system utilizes the generated PRD and the original user prompt as inputs for code generation, employing Sonnet to produce the initial website code; (2) Iterative refinement: the system implements an iterative refinement process to automatically enhance the generated website with richer func-tionality and reduced flaws. This process involves analyzing the initial code to generate optimization suggestions, merging these suggestions with the original theme, and utilizing the enhanced theme along with the previously generated PRD to regenerate the code. The system executes this iterative refinement process multiple times (by default, n=4). Users can navigate between iterations by selecting preview thumbnails displayed at the interface's bottom, and can access or copy the generated code for each version."}, {"title": "3 RESULTS AND DISCUSSION", "content": "The generated websites, as illustrated in Figure 3, exhibit gener-ally satisfactory visual appearances. These include contextually appropriate textual content, imagery, color schemes, layouts, and functionalities. Those results align with our \"intent-based\" objective of only requiring users to express their intent and scaffolding Generative AI to deliver the final output, potentially reducing the communication costs between users and Generative AI systems.\nThis task transition paradigms may motivate further exploration of intent-based interfaces, potentially extending to more complex tasks with interdependent components such as video generation. For example, we might envision an abstract-to-detailed task transition process for generating video advertisements that begins with sketches and thematic inputs, transitions to script writing, then proceeds to generate textual and visual descriptions of storyboards, followed by video generating end editing, and culminating in iterative video refinement. We aim to further investigate the potential of intent-based user interfaces in streamlining complex, interde-pendent workflows across various domains.\nFuture work could focus on studies empirically validating the effectiveness of this task transition approach in more diverse and com-plex task environments. Additionally, research into optimizing the task transition process and enhancing the quality of inter-task com-munication may yield improvements in the overall performances."}]}