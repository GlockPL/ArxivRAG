{"title": "Auto-Regressive Moving Diffusion Models for Time Series Forecasting", "authors": ["Jiaxin Gao", "Qinglong Cao", "Yuntian Chen"], "abstract": "Time series forecasting (TSF) is essential in various domains, and recent advancements in diffusion-based TSF models have shown considerable promise. However, these models typically adopt traditional diffusion patterns, treating TSF as a noise-based conditional generation task. This approach neglects the inherent continuous sequential nature of time series, leading to a fundamental misalignment between diffusion mechanisms and the TSF objective, thereby severely impairing performance. To bridge this misalignment, and inspired by the classic Auto-Regressive Moving Average (ARMA) theory, which views time series as continuous sequential progressions evolving from previous data points, we propose a novel Auto-Regressive Moving Diffusion (ARMD) model to first achieve the continuous sequential diffusion-based TSF. Unlike previous methods that start from white Gaussian noise, our model employs chain-based diffusion with priors, accurately modeling the evolution of time series and leveraging intermediate state information to improve forecasting accuracy and stability. Specifically, our approach reinterprets the diffusion process by considering future series as the initial state and historical series as the final state, with intermediate series generated using a sliding-based technique during the forward process. This design aligns the diffusion model's sampling procedure with the forecasting objective, resulting in an unconditional, continuous sequential diffusion TSF model. Extensive experiments conducted on seven widely used datasets demonstrate that our model achieves state-of-the-art performance, significantly outperforming existing diffusion-based TSF models.", "sections": [{"title": "Introduction", "content": "Time series forecasting (TSF) plays a pivotal role in various real-world applications, including transportation planning, energy management, and financial market analysis. With the development of deep-learning technology, numerous advanced deep-learning TSF models have been proposed. Notably, diffusion-based models have emerged as\nTime series can be viewed as a continuous progression of data points, where each new point is influenced by past data points and includes some random noise. This relationship can be expressed as:\n$X_t = \\phi_1 X_{t-1} + \\phi_2 x_{t-2} + \\cdots + \\phi_p X_{t-p} + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} + \\cdots + \\theta_q \\epsilon_{t-q} + \\epsilon_t,$\nwhere $x_t$ represents the value at time step $t$, and $\\epsilon_t$ represents the random noise. Our model fully leverages the inherent features of time series, which exhibit continuous sequential evolution and form a chain of dependencies characterized by prior information. Unlike previous diffusion methods that focus solely on denoising, ARMD is designed to simulate and learn the underlying evolution of the series.\nDuring the final sampling/forecasting phase, the model begins with the historical time series and gradually transforms it into the future time series. This approach aligns the sampling process with the ultimate prediction objective, removing the need for conditional generation. Consequently, our method improves stability during both training and sampling, resulting in enhanced forecasting performance.\nInspired by classical time series theory, specifically ARMA, and viewing the evolution of time series as an entire diffusion process, we propose the Auto-Regressive Moving Diffusion (ARMD) model as the first continuous sequential diffusion-based TSF model.\nBy employing a simple sliding operation, our method leverages the valuable intermediate information of the time series as intermediate states within the diffusion process. This approach successfully aligns the diffusion mechanism with the true evolution of time series, naturally leading to improved performance.\nThe proposed ARMD is extensively evaluated on the common TSF benchmarks, and the experimental results demonstrate that our method achieves state-of-the-art forecasting performance."}, {"title": "Related work", "content": "Traditional TSF models, such as ARMA and ARIMA, are based on statistical methods that assume linear relationships between past and present observations to identify patterns. Recently, deep-learning models have gained prominence in TSF applications. Temporal convolution networks (TCNs) are a significant branch of deep-learning models, with several TCN-based models leveraging convolution layers to learn temporal dependencies. Transformer-based models are also widely used in TSF. Among them, PatchTST segments the time series into multiple tokens and uses an attention module to learn relationships between them. Client and iTransformer apply the attention mechanism on the inverted dimensions to capture multivariate correlations. Additionally, DLinear demonstrates the efficacy of linear models in TSF tasks.\nIn the realm of diffusion-based TSF models, TimeGrad is a notable denoising diffusion model that generates future values in an auto-regressive manner, effective for short-term forecasting but prone to error accumulation and slow inference for long-term predictions. CSDI avoids auto-regressive inference and incorporates a self-supervised strategy through additional input masking. SSSD builds on CSDI by replacing Transformers with a structured state space model, addressing quadratic complexity issues. However, both CSDI and SSSD face the boundary disharmony problem. TimeDiff addresses these limitations with additional inductive biases specifically designed for time series data. D3VAE leverages a coupled diffusion probabilistic model to augment data, integrates multi-scale"}, {"title": "Preliminary", "content": "Time Series Forecasting. Given a historical time series $X_{-L+1:0}$, where $L$ denotes the series length. The objective of TSF is to forecast the future values of the same series, denoted as $X_{1:T}$, where $T$ represents the number of time steps to forecast. $X_{-L+1:T}$ can be either a univariate time series or a multivariate time series.\nDiffusion Models. The traditional diffusion models first progressively add noise (Ho, Jain, and Abbeel 2020) to the original data $X^0$ through a forward diffusion process, producing noised data $X_T$. Then the diffusion process is reversed to reconstruct the original data or generate the new data. The intermediate state in each step of diffusion can be calculated based on the original data $X^0$ and the random noise applied at each step. Trained to predict the added noise or the intermediate state at each step, diffusion models generate new instances by iterative sampling from white Gaussian noise. Diffusion models have been widely applied in diverse fields and have demonstrated notable advantages in generation quality.\nDiffusion Models for TSF in ARMD. In our proposed ARMD, TSF is aligned with diffusion models by associating the time series with states in the diffusion process, and their relationship is further discussed in the supplemental materials. The future series $X_{1:T}$ would serve as the initial state of the diffusion process. Following the notation convention in (Shen and Kwok 2023), the initial state is further indicated as $X^T_{1:T}$. Conversely, the historical time series $X_{-L+1:0}$ is the final state of the diffusion process, which is further denoted as $X^T_{T+1:0}$. Here, the upper index of $X$ indicates its state in the diffusion process, while the lower index represents the time steps it encompasses. In ARMD, the length of the historical series matches that of the future series, allowing the historical series to be defined as $X^{T}_{1:T+1:0}$. The intermediate state corresponds to a series transitioning from the future series to the historical series, denoted as $X^{\\tau}_{1-\\tau:T-\\tau}$"}, {"title": "Proposed Model", "content": "In this section, we propose Auto-Regressive Moving Diffusion (ARMD), a novel continuous sequential diffusion-based model for TSF. An overview of our proposed model is depicted in Fig. 2.\nForward Diffusion (Evolution) of ARMD\nIn ARMD, the evolution of a time series is conceptualized as a diffusion process. Here, the future series $X_{1:T}$ serves as the initial state of the forward diffusion (evolution) process. In contrast, the historical series $X^T_{T+1:0}$ represents the final state, as opposed to white Gaussian noise commonly used in traditional diffusion models. Unlike conventional approaches that progressively add noise, the intermediate state $X^{-t:T-t}_{1}$ in ARMD corresponds to sliding the $X_{1:T}$ by $t$ steps, approaching the historical series $X^T_{T+1:0}$. This approach leverages the properties of time series, where each intermediate state in the diffusion process reflects an intermediate series in the time series evolution. The process where $X^{-t:T-t+1}_{1}$ is diffused to $X^{-t:T-t}_{1}$ represents a single-step movement towards the historical series, as illustrated in Fig. 2, akin to the $q$ process in denoising diffusion probabilistic model (DDPM) (Ho, Jain, and Abbeel 2020). The process can be formally expressed as:\n$X^{-t:T-t}_{1} = Slide(X^{-t+1:T-t+1}_{1}, 1),$\nwhere $Slide(X, k)$ denotes the $k$-step movement of the series window $X$ towards the historical series. Furthermore, at any time step $t$, $X^{-t:T-t}_{1}$ can be directly obtained using $X_{1:T}$, similar to the process in DDPM. According to the fundamental equation of DDPM in Equation (14), the $t$-step forward process can be rewritten as:\n$X^{-t:T-t}_{1} = Slide(X_{1:T}, t) = \\sqrt{\\bar{a}_t} X_{1:T} + \\sqrt{1 - \\bar{a}_t} z_t,$\nwhere $z_t$ represents the evolution trend from the series $X_{1:T}$ to $X^{-t:T-t}_{1}$, functionally similar to the noise added in the original DDPM. Given that each time step of $X^{-t:T-t}_{1}$ is deterministic, $z_t$ can be calculated as:\n$z_t = \\frac{1}{\\sqrt{1 - \\bar{a}_t}} (\\frac{1}{\\sqrt{\\bar{a}_t}}X^{-t:T-t}_{1} -X_{1:T}).$\nHere, $z_t$ serves as the ground truth for the optimization objective at each time step. In this diffusion scheme, the maximum number of diffusion steps $T$ equals the length of the series to be predicted.\nReverse Denoising (Devolution) of ARMD\nThe reverse process in ARMD utilizes the historical series $X^T_{T+1:0}$ to iteratively generate (forecast) the future series $X^0_{1:T}$. At each devolution step, the linear-based devolution network $R(.)$ predicts the evolution trend $z_t$, which is used to devolve $X^{-t:T-t}_{1}$ to $X^{-t+1:T-t+1}_{1}$. Given an intermediate state (series) $X^{-t:T-t}_{1}$ and the diffusion step $t$, $R(.)$ predicts $X^0 (X^t, t, 0)$ for the future series $X^0_{1:T}$. More specifically, within the devolution network $R(.)$, a linear module first provides a prediction of the distance $D$ from the input $X^{-t:T-t}_{1}$ to $X^0_{1:T}$:\n$D = Linear(X^{-t:T-t}_{1}).$\nThen, the diffusion step $t$ is used to adaptively balance the interaction between the distance prediction $D$ and the input $X^{-t:T-t}_{1}$, enabling the network to produce more accurate predictions. Particularly, as $t$ decreases, the input $X^{-t:T-t}_{1}$ becomes closer to the target $X^0_{1:T}$, so the model's output should increasingly resemble the input, placing less emphasis on $D$. Conversely, as $t$ increases, the model places greater reliance on $D$. This adaptive balancing can be mathematically expressed as:\n$X^0(X^t, t, 0) = \\frac{W(t) * X^{-t:T-t}_{1} + (1 - bW(t)) * D}{(1 + cW(t))^d},$\nwhere $W(t)$ represents a weight coefficient that decreases as $t$ increases, ranging from 0 to 1. We initialize $W(t)$ with the predefined coefficients $\\bar{a}_t$ of DDPM, and it is updated along with the linear module's parameters during training. The hyper-parameters $b$, $c$, and $d$ are leveraged to balance the interaction between the distance prediction $D$ and the input $X^{-t:T-t}_{1}$. To increase sample diversity and prevent over-fitting, a small deviation is added to the input of $R(.)$ during the training process. More details concerning these hyper-parameters are shown in the supplemental materials.\nAfter obtaining the prediction $X^0(X^t, t, 0)$, the predicted evolution trend $\\hat{z}(t, 0)$ can be calculated as:\n$\\hat{z}(t, 0) = (\\frac{1}{\\sqrt{\\bar{a}_t}} X^{-t:T-t}_{1} - X^0(X^t, t, 0))/\\sqrt{\\frac{1}{\\bar{a}_t} - 1}.$\nWith the ground truth $z_t$ calculated in Equation (3) and the prediction $\\hat{z}(t, 0)$, the training objective is formulated as:\n$L_e = E_t[|z_t - \\hat{z}(t, 0)|].$\nSampling/Forecasting of ARMD\nIn the sampling phase, starting from the historical series $X^T_{T+1:0}$, ARMD iteratively generates the future series $X^0_{1:T}$, which successfully aligns the sampling process with the TSF objective, making the model an unconditional diffusion TSF model. The method follows the sampling approach from DDIM , replacing the predicted noise $\\epsilon_\\theta(x_t, t)$ with the predicted evolution trend $\\hat{z}(t, 0)$. The sampling process from $t$ to $t - 1$ (akin to the $p$ process in DDPM/DDIM) can be expressed as:\n$X^{-t:T-t+1}_{1} = \\sqrt{\\bar{a}_{t-1}} (\\frac{X^{-t:T-t}_{1} - \\sqrt{1 - \\bar{a}_t} \\hat{z}(t, 0)}{\\sqrt{\\bar{a}_t}}) + \\sqrt{1 - \\bar{a}_{t-1} - \\sigma_t^2} \\hat{z}(t, 0) + \\sigma_t \\epsilon_t,$\nwhere $\\hat{z}(t, 0)$ is the predicted evolution trend at the time step $t$, and $\\epsilon_t \\sim N(0, I)$. Since the series evolution in ARMD is deterministic, we remove the noise term $\\sigma_t \\epsilon_t$. The content within the parentheses in the first term is actually $X^0(X^t, t, 0)$. Thus, the simplified equation is:\n$X^{-t:T-t+1}_{1} = \\sqrt{\\bar{a}_{t-1}} X^0(X^t, t, 0) + \\sqrt{1 - \\bar{a}_{t-1} - \\sigma_t^2} \\hat{z}(t, 0).$\nTo accelerate sampling, $k$ steps can be skipped at each iteration, and the process can be further inferred as:\n$X^{-t+k:T-t+k}_{1} = \\sqrt{\\bar{a}_{t-k}} X^0(X^t, t, 0) + \\sqrt{1 - \\bar{a}_{t-k} - \\sigma_t^2} \\hat{z}(t, 0).$"}, {"title": "Experiments", "content": "Experimental Settings\nThe proposed ARMD is extensively evaluated on seven widely used benchmark datasets, including Solar Energy, Exchange, Stock, and four ETT datasets. We compare ARMD with five advanced diffusion-based TSF models: Diffusion-TS, MG-TSD, TSDiff, D3VAE, TimeGrad. Additionally, some other advanced TSF models, including iTransformer, TimesNet, DLinear, PatchTST, and Client are also compared with ARMD.\nFor all datasets, the historical length and prediction length are both set to 96. Following the evaluation methodology employed in a previous study , we calculate the mean squared error (MSE) and mean absolute error (MAE) on z-score normalized data, enabling a consistent assessment of various variables. More details concerning experiment settings are shown in the supplemental materials.\nComparison with Diffusion-Based Models\nThe multivariate forecasting results, comparing our proposed ARMD with various advanced diffusion-based TSF models, are summarized in Table 1, with each model's results averaged over 10 sampling runs. Notably, ARMD demonstrates superior forecasting performance, achieving optimal results in 12 out of the 14 experimental settings. Our extensive experiments reveal that while other diffusion-based TSF models can achieve effective results on specific datasets, they often suffer from instability, performing well in certain scenarios but deviating significantly from the true values in others, which indicates a lack of generalization across diverse data. In contrast, ARMD consistently exhibits robust performance across all datasets, suggesting a higher degree of reliability and adaptability to various multivariate forecasting challenges. Specifically, on the ETTm1 dataset, ARMD achieves a substantial 47.7% reduction in MSE and a 30.1% reduction in MAE compared to the second-best model, D3VAE. On the Stock dataset, ARMD surpasses TSDiff, the second-best model in this setting, with a 28.8% reduction in MSE and a 26.3% reduction in MAE. Furthermore, ARMD attains more than a 10% reduction in both MSE and MAE on the Solar Energy, ETTh1, and Exchange datasets compared to the nearest competitor. These results indicate that ARMD is the best diffusion-based TSF model.\nComparison with Other TSF Models\nAs demonstrated in Table 2, ARMD consistently outperforms other advanced models in multivariate TSF tasks. The comparative results for other TSF models are primarily sourced from iTransformer , with the Stock dataset being an exception, where additional evaluations are conducted using official implementations to ensure a thorough analysis. ARMD achieves the highest number of best counts, indicating its consistent ability to surpass other TSF methods across multiple benchmarks. These results not only establish ARMD as the leading diffusion-based TSF model but also underscore its superiority over existing models. Overall, these findings highlight ARMD's promise as a robust and effective solution for multivariate TSF tasks.\nQualitative Analysis\nAs illustrated in Fig. 3, we qualitatively analyze the performance of ARMD by comparing it with the advanced diffusion-based model, Diffusion-TS. Given the same historical series, both models make 10 independent predictions for the future series. Our analysis reveals that ARMD consistently produces more stable and accurate predictions, particularly in scenarios involving high peak values. This is in contrast to Diffusion-TS, which shows greater variability"}, {"title": "Ablation Studies", "content": "In this section, we set a range of ablation experiments to testify diverse components of the proposed ARMD.\nIntermediate State Generation Method. ARMD generates intermediate states using a sliding-based method to maintain series continuity. An alternative method to generate intermediate states involves interpolating between the initial series $X_{1:T}$ and final series $X_{1T+1:0}$, as described by:\n$X^{-t:T-t}_{1} = X_{1.T} + (X^0_{1T+1:0} - X_{1:T}) * t/T$.\nThe results of using these interpolation-based intermediate states are presented in the second row of Table 4. The results indicate that our sliding-based method consistently outperforms the interpolation-based approach across all settings, underscoring its superiority in preserving series continuity.\nDevolution/Denosing Learning Method. The devolution network of ARMD take a distance-based method to provide the prediction $X^0(X^t, t, 0)$ and $\\hat{z}(t, 0)$, differing from conventional approaches. Traditional denoising (devolution) networks often utilize a t-embedding-based method. In this approach, the model initially generates a prediction based on the input intermediate state, then embeds the time step $t$ to generate a t-embedding, and finally combines the t-embedding with the initial prediction to produce the final output. The results of applying this t-embedding-based method within the devolution network are shown in the third row of Table 4, demonstrating that our distance-based method outperforms the t-embedding-based method across all settings.\nBackbone of the Devolution Network. Many existing diffusion-based TSF models use a Transformer-based backbone in the denoising network. Nevertheless, the devolution network in ARMD uses a linear-based backbone, which accelerates training and sampling. The impact of replacing the linear-based backbone with a Transformer-based backbone is presented in the fourth row of Table 4. The results show that the linear-based backbone outperforms the Transformer-based backbone in most settings (11 out of 14).\nDeviations to the Intermediate States. To enhance the diversity of intermediate states and prevent over-fitting, minor deviations are added to the input of the devolution network during the training process. The consequences of removing these deviations are detailed in the fifth row of Table 4, highlighting their critical role in preventing over-fitting.\nNoise in the Sampling Process. Given that the series sampling/forecasting process is deterministic, the noise term $\\sigma_t \\epsilon_t$ in Equation (8) is set to 0 during sampling/forecasting. The results of adding sampling noise are shown in the last row of Table 4, showing that introducing randomness leads to a decline in model performance."}, {"title": "Conclusion", "content": "Inspired by the classic ARMA theory, we creatively introduce an Auto-Regressive Moving Diffusion (ARMD) model for TSF, which reinterprets the evolution of time series as a diffusion process. Particularly, regarding the target future series as the initial state, and the historical series as the final state, the intermediate series are generated with the series slide operations to complete the diffusion process. In this manner, the sampling procedure of the diffusion model becomes the series forecasting, which denotes that the diffusion mechanism is successfully aligned with the TSF objective, and further resulting in an unconditional, continuous sequential diffusion TSF model. The proposed ARMD is validated across seven widely used datasets, and the experimental results show that our method effectively suits the unique characteristics of time series data, and achieves superior forecasting performance."}, {"title": "Supplemental Materials for\"Auto-Regressive MovingDiffusion Models for Time SeriesForecasting\"", "content": "Preliminary of Diffusion Model andConditional DDPMs for TSF\nDiffusion models have been widely applied in various fields, typically comprising a forward diffusion process and a reverse process. A prominent example of these models is the Denoising Diffusion Probabilistic Model (DDPM). In the forward diffusion process of DDPM, noise is gradually added to the input $X^0$, transforming it into a white Gaussian noise $X_T$ over $T$ diffusion steps. At each time step $t \\in [1,T]$, the diffused sample $X_t$ is acquired through scaling the previous sample $X_{t-1}$ by $\\sqrt{1 - \\beta_t}$ and subsequently introducing noise, as described by:\n$q(X_t|X_{t-1}) = N(X_t; \\sqrt{1 - \\beta_t}X_{t-1}, \\beta_tI),$\nHere, $\\beta_t \\in [0,1]$ denotes the noise variance, which follows a predefined schedule. From this, it can be derived that:\n$q(X_t|X^0) = N(X_t; \\sqrt{\\bar{a}_t}X^0, (1 - \\bar{a}_t)I).$\nwhere $a_t = 1 - \\beta_t$ and:\n$\\bar{a}_t = \\prod_{k=1}^{t} a_k.$\nAs $t$ increases, $a_t$ decreases, and it is chosen as predefined deviation coefficient and devolution coefficient in our proposed ARMD. In DDPM, $X_t$ can be directly computed as:\n$X_t = \\sqrt{a_t}X^0 + \\sqrt{1 - \\bar{a}_t}\\epsilon,$\nwhere $\\epsilon$ is sampled from $N (0, I)$. The reverse denoising process of DDPM is a Markovian process, expressed as:\n$p_\\theta(X_{t-1}|X_t) = N(X_{t-1}; \\mu_\\theta(X_t,t), \\Sigma_\\theta(X_t,t)).$\nIn practice, $\\Sigma_\\theta(X_t,t)$ is generally kept constant at $\\sigma_tI$, while $\\mu_\\theta(X_t,t)$ is usually predicted by a neural network parameterized by $\\theta$. $\\mu_\\theta(X_t,t)$ can be defined in two ways: (1) noise-based $\\mu_\\epsilon (\\epsilon_\\theta)$ or (2) data-based $\\mu_X (X_\\theta)$, and these two different definitions can lead to different optimization objectives.\nIn TSF, the aim is to forecast the future values $X_{1:F}$ of a time series given its historical series $X_{-L+1:0}$. Here, $F$ is the length of the series to be predicted, and $L$ is the length of the historical series. Previous approaches typically utilize conditional DDPMs for TSF, modeling the distribution:\n$p_\\theta(X_{1:F}|c) = p(X_{T:F}) \\prod_{t=1}^{T} p_\\theta(X^t_{1:F}|X^{t-1}_{1:F}, c),$\nwhere $X_{T:F} \\sim N(0, I)$, and $c = g(X^0_{-L+1:0})$ is the output of the conditioning network $g$ that takes the historical series $X^0_{-L+1:0}$ as input, and:\n$p_\\theta(X_{1:F}|X^t_{1:F}, c) = N(X_{1:F}; p_\\theta(X^t_{1:F}, t|c), \\sigma_t^2I).$\nHowever, this conditional-based approach is less straightforward compared to the method employed by ARMD."}, {"title": "Connection between ARMD and ARMA", "content": "The Autoregressive Moving Average (ARMA) model is a classic approach in TSF that combines two components:\nAutoregressive (AR) Component: The AR component models the time series using past data points. It assumes that the current data point can be expressed as a linear combination of previous points and a noise term.\n$X_t = \\phi_1 X_{t-1} + \\phi_2 X_{t-2} + \\cdots + \\phi_p X_{t-p} + \\epsilon_t.$\nAR components are particularly adept at handling time series data with long-term trends.\nMoving Average (MA) Component: The MA component models the time series using past forecast errors (noises). It assumes that the current data point can be expressed as a linear combination of past error (noise) terms.\n$X_t = \\mu + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} + \\cdots + \\theta_q \\epsilon_{t-q} + \\epsilon_t.$\nMA components can effectively handle time series data with sudden changes or significant noise.\nARMA Model: Combining both components, the ARMA model can be represented as:\n$X_t = \\phi_1 X_{t-1} + \\phi_2 x_{t-2} + \\cdots + \\phi_p x_{t-p} + \\theta_1 \\epsilon_{t-1} + \\theta_2 \\epsilon_{t-2} + \\cdots + \\theta_q \\epsilon_{t-q} + \\epsilon_t.$\nThe ARMA model combines the strengths of AR and MA components, capturing trend information in time series while also accommodating sudden changes.\nIn our proposed ARMD, instead of explicitly adding noise, the forward diffusion (evolution) process in our model involves sliding the time series data from the future series $X_{1:T}$ to the historical series $X_{T+1:0}^T$. For each diffusion step from $X_{1-t:T-t}$ to $X_{1-t-k:T-t-k}$, the process can be viewed as incorporating noise into the series based on the ARMA assumption, and each data point $x_i$ in the shifted series $X^T_{1-t-k:T-t-k}$ contains the introduced noises from the time steps of $i + 1 : i + k$.\nDuring the reverse denoising (devolution) process, the model devolves $X^T_{1-t-k:T-t-k}$ to $X_{1-t:T-t}$. The devolution network of ARMD is linear-based, wherein each data point $x_i$ can be modeled as a linear combination of the preceding $k$ time steps. This also aligns with the ARMA assumption. These consistencies with ARMA provide theoretical support for the effectiveness of our diffusion model, ARMD, in time series forecasting."}, {"title": "Deviation added in the Training Process", "content": "A small proportion of deviation is added to the input of the devolution network to increase sample diversity and prevent over-fitting during the training process. Specifically, for the input $X_{1-t:T-t}$, the corresponding deviation can be expressed as $\\eta_{0:t} * \\epsilon$, where $\\eta_{0:t}$ is the deviation coefficient following a predefined schedule, and $\\epsilon$ is sampled from $N(0, I)$. Here, we utilize the predefined diffusion coefficients in DDPM, where $\\eta_{0:t}$ equals $\\bar{a}_t$ in equation (13), with the deviation proportion being smaller when closer to the historical series and larger when closer to the future series. This choice is reasonable because the closer $X_{1-t:T-t}$ is to the historical series $X_{T+1:0}^T$, the more it aligns with the ultimate goal of predicting $X_{1:T}^0$ from $X_{T+1:0}^T$, thus the deviation should be correspondingly reduced."}, {"title": "Hyper-parameters of the Devolution Network", "content": "The hyper-parameters $b$, $c$, and $d$ in Equation (5) are utilized to balance the relation between the distance prediction $D$ and the input $X_{1-t:T-t}$ of the devolution network $R(.). These hyper-parameters vary across different datasets. In our experiments, the hyper-parameters $b$, $c$, and $d$ are selected through a grid search. Specifically, $b$ is chosen from {1, 1.5, 2}, $c$ is chosen from {-1, -0.5, 0.5, 1}, and $d$ is chosen from {0.3, 0.5, 1}."}, {"title": "Experiment Details", "content": "For all the benchmark datasets, we perform a 70/10/20 train/validation/test split to obtain the respective sets, consistent with previous research (Liu et al. 2024; Zhou et al. 2021). During the training process, we use the Adam optimizer with a learning rate of 1e-3 and employ the L1 loss function. The batch size is set to 128, and the default number of training iterations is set to 2,000. The sampling steps of ARMD are chosen from {1, 2, 3, 4, 6, 8, 12} via grid search, utilizing the validation set. Other diffusion-based TSF models use the default sampling steps of 100. The final evaluation is conducted on the test set. All experiments are conducted on a single NVIDIA GeForce RTX 4090 GPU with 24GB of memory."}, {"title": "Data Description", "content": "The experimental data encompasses seven widely used benchmark datasets, each distinguished by its unique set of characteristics:\nSolar Energy: This dataset includes the solar power production records in the year of 2006, which is sampled every 10 minutes from 137 PV plants in Alabama State. The dataset contains 7,177 timesteps.\nExchange : This dataset includes daily exchange rates of eight countries from 1990 to 2016, with 8 variables and 7,588 timesteps per variable, displaying significant volatility.\nETT Datasets : The ETT datasets consist of hourly-level data (ETTh1 and ETTh2) and 15-minute-level data (ETTm1 and ETTm2), with oil and load features of electricity transformers recorded from July 2016 to July 2018. Each dataset has seven variables, with ETTh datasets containing 17,420 timesteps and ETTm datasets containing 69,680 timesteps.\nStock: This dataset contains the daily historical Google stocks data from 2004 to 2019, including as features the volume and high, low, opening, closing, and adjusted closing prices. The dataset contains 3,685 timesteps."}, {"title": "Details on Comparison Models", "content": "The descriptions and implementations of comparison models are detailed as follows:\nDiffusion-TS : Diffusion-TS is a DDPM-based framework for generating high-quality multivariate time series samples. It utilizes an encoder-decoder Transformer with disentangled temporal representations and a decomposition technique to capture the semantic meaning of time series", "https": "github.com/Y-debug-sys/Diffusion-TS.\nMG-TSD : MG-TSD addresses the instability of diffusion probabilistic models in TSF by leveraging the natural granularity levels within data. The model aligns the diffusion process with smoothing fine-grained data into coarse-grained representations", "at": "https://github.com/Hundredl/MG-TSD.\nTSDiff: TSDiff is a time series diffusion model that leverages a self-guidance mechanism for conditioning during inference"}, {"https": "github.com/amazon-science/unconditional-time-series-diffusion.\nD3VAE : D3VAE is a bidirectional variational auto-encoder equipped with diffusion", "at": "https://github.com/PaddlePaddle/PaddleSpatial.\nTimeGrad : TimeGrad is an autoregressive model for multivariate probabilistic TSF that leverages diffusion probabilistic models to sample from the data distribution at each time step by estimating its gradient. By optimizing a variational bound on the data likelihood"}, {"https": "github.com/zalandoresearch/pytorch-ts.\niTransformer : iTransformer addresses the limitations of traditional Transformer models, which struggle with large lookback windows and fail to learn variate-centric representations. Instead of modifying the Transformer architecture, iTransformer applies attention and feed-forward networks on inverted dimensions. Time points are embedded into variate tokens to capture multivariate correlations, while each token is processed to learn nonlinear representations. This approach enhances performance and efficiency in TSF"}]}