{"title": "On the limits of agency in agent-based models", "authors": ["Ayush Chopra", "Shashank Kumar", "Nurullah Giray Kuru", "Ramesh Raskar", "Arnau Quera-Bofarull"], "abstract": "Agent-based modeling (ABM) seeks to understand the behaviour of complex sys- tems by simulating a collection of agents that act and interact within an environment. Their practical utility requires capturing realistic environment dynamics and adap- tive agent behavior while efficiently simulating million-size populations. Recent advancements in large language models (LLMs) present an opportunity to enhance ABMs by using LLMs as agents with further potential to capture adaptive behavior. However, the computational infeasibility of using LLMs for large populations has hindered their widespread adoption. In this paper, we introduce AgentTorch \u2014 a framework that scales ABMs to millions of agents while capturing high-resolution agent behavior using LLMs. We benchmark the utility of LLMs as ABM agents, exploring the trade-off between simulation scale and individual agency. Using the COVID-19 pandemic as a case study, we demonstrate how AgentTorch can simulate 8.4 million agents representing New York City, capturing the impact of isolation and employment behavior on health and economic outcomes. We compare the performance of different agent architectures based on heuristic and LLM agents in predicting disease waves and unemployment rates. Furthermore, we showcase AgentTorch's capabilities for retrospective, counterfactual, and prospec- tive analyses, highlighting how adaptive agent behavior can help overcome the limitations of historical data in policy design. AgentTorch is an open-source project actively being used for policy-making and scientific discovery around the world. The framework is available here: github.com/AgentTorch/AgentTorch", "sections": [{"title": "Introduction", "content": "Many of the challenges that we face today from epidemics to housing shortages to humanitarian crises are not the result of a single person's action, but the complex interplay of countless individuals taking decisions and interacting with each other over time. Agent-based models (ABMs) aim to capture these dynamics by simulating a collection of agents that act and interact within a computational world. ABMs have helped study a multitude of complex systems across epidemiology [8, 26, 22], economics [5, 6], and disaster response [21, 7]. For example, they were used to evaluate vaccination protocols during the COVID-19 pandemic [42], predict the crash of housing markets [20], and design evacuation programs for war refugees [30]. ABMs are particularly valuable for addressing these policy questions because they enable the simulation of interventions by modeling the interplay between individual behaviors and environmental dynamics. Their practical utility requires capturing realistic environments and expressive agents while efficiently simulating million-size populations.\nHistorically, the widespread adoption of ABMs has been hindered by the high computational costs associated with their simulation and calibration processes [10]. Recent advancements in deep learning have addressed some of the computational challenges associated with ABMs, enabling the simulation of complex dynamics over millions of agents using vectorized operations [12, 41] and the calibration of models to heterogeneous data sources using differentiable programming [2, 12, 32, 39, 46, 16]. In such differentiable ABMs, deep neural networks also help specify complex environment dynamics [33], and autograd helps perform sensitivity analysis which evaluates how variations in model inputs affect outputs - in zero-shot [40]. As a result, it is now feasible to simulate, calibrate, and analyze ABMs with millions of agents using commodity hardware. An important remaining limitation, however, is the lack of expressiveness and adaptability of the agents within ABMs.\nLarge language models (LLMs) have shown remarkable performance in text-based applications [35, 3, 47] which caused a surge in LLM-powered agents with the aim of tackling more general tasks LLM- agents have demonstrated potential to enable more general and adaptive human-like behavior [45, 23]. While promising work on multi-agent simulations with LLM-agents has been performed [36, 48], it has primarily been limited to tabletop games and small population scenarios. The study of large-scale complex systems, such as epidemics or supply chain networks, often requires the simulation of millions of agents, but little work has been done on scaling LLM-based agent simulations to these numbers. Furthermore, these simulations need also to incorporate adequate environment designs that capture dynamics, such as virus mutations or economic shocks, to be effective for policy design.\nIn this paper, we introduce AgentTorch to address these issues. AgentTorch is a framework for scalable simulation, calibration, and analysis of ABMs that allows for the specification of flexible agent architectures and fully differentiable environments. We employ AgentTorch to assess the suitability of LLM agents for large-scale ABM research. First, we study whether LLM-agents can reproduce population-level statistics of behaviour. Next, we introduce the concept of an LLM- archetype representing a collection of agents that share the same behavior characteristics. This approach allows us to scale simulations to millions of agents informed by LLM outputs. Finally, we benchmark the trade-off in simulation fidelity between more expressive individual LLM-agents and a coarser approach based on archetypes. We illustrate our observation through a case study of 8.4 million agents representing NYC."}, {"title": "Preliminaries", "content": "In this section, we define the tasks of simulating, calibrating, and analyzing an ABM. We introduce the relevant notation and definitions to formulate the presented experiments. We also formalize the"}, {"title": "Agent-based Modeling", "content": "Consider an ABM composed of N agents. We denote by $s_i(t)$ the state of agent i at simulation time t, which contains both static and time-evolving properties of agents. For instance, s may represent the age and sex of a person and their infected status. As the simulation proceeds, an agent i updates their state $s_i(t)$ by interacting with their neighbours $N_i(t)$ and their environment e(t), which can both also be time evolving. The neighbourhood of an agent can be specified using a graph, a proximity metric, or other methods. We denote by $m_{ij}(t)$ the message or information that agent i obtains from their interaction with agent j. In the case of an epidemiological ABM, this may represent the transmission of infection from agent j to agent i. We can then write the agent's update rule as\n$s_i(t+1) = f (s_i(t), \\cup_{j \\in N(i)}m_{ij} (t), e(t), \\theta),$\nwhere $\\theta$ are the structural parameters of the ABM. For instance, $\\theta$ may correspond to the infectivity of a virus, or the vaccination efficacy. Similarly, the environment can also have its own dynamics that depend on the agent's updates and actions,\n$e(t + 1) = g (s(t), e(t), \\theta).$\nThe specific choices of f and g define the dynamics of the ABM system and they are typically stochastic functions which can be mechanistically specified or learned from data.\nSimulating an ABM consists of picking an initial condition for the agents and environment states (s(0), e(0)) and recursively applying Equation 1 and Equation 2. Despite the very large size of the simulated state space, we are mainly interested in a collection of aggregate outcomes over agent states. For most ABMs, this corresponds to a multivariate time-series $x_t = h(s(t))$. For example, in epidemiological ABMs h corresponds to summing over the infected agents to obtain the daily number of infected agents. Once the functional form of an ABM has been set, the simulation of an ABM can be conceived as a stochastic simulator,\n$x = F(\\theta, s(0), e(0)),$\nwhere F = (f, g) \u25cb\uff65\uff65\uff65 \u25cb (f, g). The composition is repeated for T time-steps.\nA differentiable ABM is an ABM for which the gradient\n$\\eta \\nabla_{\\theta} E[F(\\theta)]$\nexists and can be computed. Note that this may not necessarily imply that F is differentiable in a conventional sense (see e.g., [4, 31]).\nCalibrating an ABM refers to the process of finding a set of structural parameters $\\hat{\\theta}$, or a probability distribution over $\\theta$, such that $F(\\hat{\\theta}, s(0), e(0))$ produces an output $\\hat{x}$ that is consistent with real-world data y. There is extensive literature on how to calibrate ABMs. Techniques include approximate Bayesian computation [37] and neural likelihood and posterior estimation [16], among others. If the ABM is differentiable, then we have access to a wide range of gradient-assisted calibration techniques such as variational inference [39, 17]. Additionally, this enables the ABM to be composed with neural networks into end-to-end differentiable pipelines [12].\nThe analyses of ABMs can be classified into three distinct types: retrospective (understanding what happened), counterfactual (what would have happened under different policies), and prospective (designing optimal policies for the future). The ability to do these analyses is what makes ABMs a powerful tool for policy design and set them as model candidates that can overcome Lucas critique [29] - a contention that argues that historical data cannot be used to predict the impact of new policies since they lead to unobserved scenarios. By using ABMs with sufficiently expressive and adaptive agents, we can overcome Lucas critique by capturing deeper causal relations between adaptability of agents and implemented policies."}, {"title": "Agency in Agent-based Models", "content": "In conventional ABMs, the agents update rule f (Equation 1) is motivated by heuristics derived from observational data or grounded in theory. For instance, in an epidemiological model, f corresponds"}, {"title": "Scaling LLM-agents for ABMs: LLM archetypes", "content": "Understanding complex systems often requires the simulation of the entire population of agents to correctly capture emergent scale-sensitive effects. For instance, while the agency or intelligence of an individual ant may be quite limited, the simulation of the entire colony captures coordination processes wherein ants use themselves as bridges for other ants to use. In these large systems, however, it is infeasible to query Equation 6 for each agent, time-step, and specific action. This problem can be overcome by recognizing that the number of different behaviors is typically much smaller than the number of agents. In other words, we only need to query the LLM to inform the behaviour over each unique set of agents' characteristics. For instance, if we consider that the behavior is purely informed by age and sex, we only need to consider one LLM query per different combination of age and sex. We refer to each of these unique combinations as archetypes.\nFor each possible agent action a, we can estimate its probability $p_a$ in Equation 6 using Monte-Carlo,\n$P_a(s_i(t), e(t), \\theta) = E [l(-\\vert s_i(t), e(t), \\theta)] \\approx \\sum_{j=1}^{M} \\xi_j with \\xi_j \\sim l(-\\vert s_i(t), e(t), \\theta).$\nBy estimating $p_a(k)$ for each archetype k, we can simulate the action of its agent by sampling the action from the archetype to which it belongs. Let K be the number of agent archetypes and A be the number of LLM-queryable actions; we can then simulate the behaviour of all agents with $K \\times A$ queries, which will be typically much smaller than the number of agents N, allowing us to scale the simulation to millions of agents."}, {"title": "Agent Torch framework", "content": "AgentTorch is a framework that enables the creation of ABMs with complex dynamics, adaptive individual behavior, and efficient simulation of million-size populations. The key features are:\n\u2022 Scalability: AgentTorch leverages vectorized computing to specify environment dynamics and interventions which enables the simulation of millions of agents on commodity hardware. For example, AgentTorch implementations of epidemiological ABMs with 60 million agents have shown improvements up to 40,000x in computational time[40] respect to models developed with traditional object-oriented frameworks [14, 25]. With the use of archetypes (subsection 2.3), these gains are preserved even when using LLM-informed agents, as opposed to frameworks like Concordia [48] which are limited to very small populations.\n\u2022 Differentiability: AgentTorch provides custom utilities to build differentiable implementations of continuous and discrete environments. With the use of gradient-assisted calibration techniques, AgentTorch can calibrate large numbers of parameters to heterogeneous datasets [12, 11]. For example, unlike in torch, you can differentiate through agent_torch.bernoulli and agent_torch.logical_and (more details in appendix A).\n\u2022 Composability: AgentTorch allows for the composition of ABMs with neural networks and LLMs, enabling the design of more expressive and flexible agent architectures. The differentiability of the environments ensures that these systems remain end-to-end differentiable. The framework provides APIs that integrate with generative agent frameworks such as LangChain and dspy LLM instances. See code snippets in Figure 1 and Figure 2.\nAgentTorch's design is motivated by active collaborations around the world, with models currently being deployed to help mitigate a measles outbreak in New Zealand [9]; capture the foraging behavior of migratory birds in Alaska; and analyze the dairy supply chain in the Pacific islands to safeguard against a potential H5N1 outbreak. Previously, AgentTorch models were used across multiple countries during the COVID-19 pandemic to evaluate immunization protocols [42, 13] deployed across multiple countries [24, 34]. The project is under active development, and we refer to the GitHub repository for tutorial notebooks, videos, reference implementations, installation guides, and contribution guidelines. To familiarize with the architecture, the project website\u00b9 includes hands-on notebooks to build a new environment and execute simulations using an existing environment. We also provide code snippets in Figures 1, 2 and 5 to introduce some framework capabilities and familiarize with the Python API.\nThe focus of this work is to explore the ability of AgentTorch to execute million-scale ABMs with LLM-guided agent behavior. In the following sections, we explore the viability of LLM agents for million-scale ABMs and their impact on simulation, calibration, and analysis using AgentTorch. We provide benchmark results and code snippets throughout the paper to demonstrate how LLM agents can be used with AgentTorch to address real-world challenges."}, {"title": "Motivating Example: COVID-19 Pandemic", "content": "The COVID-19 pandemic presents a compelling case study for demonstrating the capabilities of AgentTorch and the utility of LLM agents in ABMs. As the pandemic progressed, the complex interplay between disease dynamics, social behavior, and policy interventions posed significant challenges for designing effective public health strategies. The effectiveness of interventions was heavily influenced by human behavior, making it crucial to capture these dynamics in an ABM.\nInitially, the feedback loop between mobility behavior and disease spread led to multiple waves of infections, with people adopting more cautious behaviors when cases increased but becoming more relaxed as cases declined [44]. Government-imposed lockdowns aimed at constraining mobility but had severe economic consequences, leading to unprecedented levels of unemployment [15]. In response, stimulus payments and financial assistance programs were introduced to alleviate economic hardship and encourage compliance with interventions [27]. However, these measures had side effects on the labor market, disrupting employment dynamics and resource allocation for health interventions [18]. As the pandemic continued, \"pandemic fatigue\" set in, further influencing people's willingness to comply with public health measures like testing, quarantine, and vaccination, exacerbating the impact on health and the economy [38].\nTo better understand and address these challenges, we focus on two key aspects of individual behavior: isolation and employment. Our goal is to capture how these behaviors vary with: (1) Demographics:"}, {"title": "Benchmarking LLM as ABM agents", "content": "The goal of this section is to benchmark the capacity of LLMs to simulate behavior consistent with measurable population-wide observations. We initialize a synthetic population of 8.4 million agents representing New York City (NYC) by using data from the US census. Each agent is initialized with an age, sex, and location attribute, obtained at census-resolution (details in appendix). We focus on the time-horizon from December 2020 to March 2021, which coincides with the second round of stimulus payments in the US. We use the prompt template above to query an LLM for the action a =\"Do you go to work?\", but with 3 distinct modifications that give rise to 3 scenarios: (Prompt 1) we only provide demographic attributes of the agent, (Prompt 2) we add information about disease dynamics, (Prompt 3) we further include information about access to stimulus payments. For each scenario, we initialize 100 archetypes representing the different combinations of unique prompts over the 3 months considered within the time frame. More experimental details are in Appendix C.\nFollowing Equation 7, we obtain the probability of each archetype k performing action a for each week, $p_a (k, t)$. By sampling from the induced Bernoulli distributions, we can obtain a time-series of daily attendance to work. This procedure can be seamlessly done within AgentTorch as the coding snippet Figure 2 exemplifies. We use the LLM responses to aggregate the change in labor force participation rate across all boroughs in New York during the time frame. We then compute the correlation of this time series with observed data from the US bureau of labor statistics \u00b2. The results of the three scenarios are shown in Figure 3 for each of NYC's constituent boroughs, averaged over 5 runs for sensitivity. We observe that the correlation between the output predicted by LLM-agents and the observed data increases as we add more contextual information to the prompt, demonstrating that it is possible to tailor the behavior of LLM-agents by passing contextual information into their input prompts. We also observe that LLMs can capture collective participation behavior with very"}, {"title": "Benchmarking agency vs simulation scale", "content": "In the previous section, we demonstrated the ability of LLM archetypes to capture population-wide behaviors across space and time. We now investigate the impact of incorporating this agent behavior within ABM and analyze the trade-off between agency and simulation scale. We use the isolation and employment behavior of agents to simulate the dynamics of disease spread and labor market in New York City from time December 2020 to April 2021. Such a simulation can be seamlessly initialized with AgentTorch as shown the code snippet in Figure 1.\nEnvironment: For disease spread, we consider a standard epidemiological model (see, e.g, [8]) wherein infection spreads through contact and the probability of agent i getting infected at step t is:\n$p_i(t) = 1 - exp (-\\beta S_i (\\sum_{j \\in N(i)} \\frac{I_j(t)}{N_i})),$\nwhere N(i) is the set of neighbors of agent i, $S_i$ the susceptibility of agent i, $I_j$ the infected status of each neighbour, $n_i = #N(i)$ the total number of neighbors, and $\\beta$ a structural parameter of the ABM called the effective contact rate. The neighbourhood N(i) is given by a contact network constructed from household and mobility data in the US census.\nFor labor market, we consider a standard econometric model which related participation behavior of individual agents with aggregate unemployment rate at time t ($p_{w,t}$) as:\n$\\mu_{w,t} = \\sum_{j \\in N} \\gamma_0 W_j (t) + \\gamma_1 C_t$"}, {"title": "Analysing simulation dynamics with AgentTorch", "content": "The Lucas Critique posits that historical data can never predict what happens when a new policy is adopted, since behavior may adapt while outcome is realized. The ability to capture adaptive behavior and realistic environment dynamics make this feasible. We can this to evaluate retrospective measures, explore counterfactual scenarios and also design intervention strategies for the future."}, {"title": "Limitations and Conclusion", "content": "In this paper, we introduced AgentTorch, a scalable, differentiable, and composable framework for building agent-based models (ABMs) with adaptive individual behavior using large language models (LLMs). We demonstrated the ability of LLM agents to capture realistic population-wide behaviors and explored the trade-off between agent expressiveness and simulation scale. Using the COVID-19 pandemic as a case study, we showcased AgentTorch's capabilities for retrospective, counterfactual, and prospective analyses of complex systems. However, there are some limitations to the current work that should be acknowledged. First, while LLMs enable more expressive agent behavior, their outputs can sometimes be inconsistent or biased. Ensuring the robustness and fairness of LLM-driven agents remains an open challenge. Second, while LLM archetypes aid scalability, they may not always capture the desired heterogeneity of individual agents. Third, the actions that our LLM-based agents take are relatively simple, and more needs to be done in enabling more expressive actions of LLMs within the simulators. Despite these limitations, we believe AgentTorch represents a significant step forward in agent-based modeling, opening up new possibilities for understanding and addressing societal challenges. We hope this work will inspire further research at the intersection of ABMs and LLMs, contributing to more informed and effective policies for a better future."}, {"title": "Appendix A: AgentTorch framework", "content": "Code: The AgentTorch project is open-source at github.com/AgentTorch/Agent Torch and the documentation is available at https://agenttorch.github.io/AgentTorch/. Some quick links are given below -\n\u2022 Architecture: https://agenttorch.github.io/AgentTorch/architecture/\n\u2022 Installation: https://agenttorch.github.io/AgentTorch/install/\n\u2022 Contributing: https://agenttorch.github.io/AgentTorch/contributing/\n\u2022 Getting Started: https://agenttorch.github.io/AgentTorch/tutorials/ creating-a-model/\nThe GitHub repository includes sample models to get started and interactive tutorials to implement new models and analyze existing ones.\nFigure 6: AgentTorch provides custom utilities to differentiate through discrete stochastic and conditional operations. The example here contrasts the Bernoulli distribution, where using 'agent_torch.Bernoulli' can provide a gradient unlike 'torch.Bernoulli', and is compatible with 'torch.tensor'. Several such distributions, like 'Binomial' or \u2018Categorical', are implemented in Agent- Torch to provide (low-bias low-variance) gradients. AgentTorch implements discrete distributions using stochastic triples, as introduced in [4] and also supported in 'Julia' programming language with 'StochasticAD' package. These utilities help design ABMs as differentiable programs and ensures composability of ABMs with DNNs. We refer to the GitHub source for implementations for logical operators (e.g., agent_torch.logical_and) and comparators in AgentTorch (e.g., agent_torch.max)\nDifferentiability: As we discussed, differentiability is a key attribute of Agent Torch models. Agent-Torch uses autograd primitives to represent a ABMs with dynamics and interventions on a compute graph, which streamlines backpropagation. However, unlike DNNs on computation graphs, defining ABMs relies extensively on mechanistic operators (torch.max, torch.compare, torch.logical_and) to describe stochastic and conditional program flows. (e.g., offer a vaccine if age < 60, COVID-19 test has 65% specificity). However, these operators are conventionally non-differentiable in torch and can cause incompatibility with autograd. AgentTorch implements custom operators to differ- entiate through stochastic and conditional programs, ensuring gradient flow through the ABM. A sample code-snippet is given in figure 6. To realize this, Agent Torch integrates recent advancements in differentiable programming [49, 4] to provide a simple-to-use API for achieving low-bias low- variance gradients during backpropagation. We note this is important for agent-based modeling since gradient estimators that work well for neural network training (with millions of parameters and limited stochasticity) may not generalize well for simulations (with low-dim parameters and compositional stochasticity). For example, the Gumbel-Softmax reparameterization is shown to work well in variational autoencoders (VAEs) but fails with ABMs since it has a high-biased un- der composition [19]. On GitHub, we recommend looking at agent_torch/distributions and"}, {"title": "Appendix B: Environment and Agent specification", "content": "We provide additional details about the simulation environment, data sources, system prompt, and agent specification for our case study experiment.\nAgent: We consider 8.4 million agents that can catch and transmit infections, and be willfully em- ployed. Their state is composed of static (age, gender, income, occupation, household, geo-location) and dynamic attributes (disease status, employment status). The demographic and household charac- teristics are sampled using the 2022 American community survey (ACS), employment characteristics from the bureau of labor statistics and disease dynamics from the CDC. Agents interact with each other over household, workplace, and mobility networks. We parameterize interactions for recre- ational and workplace mobility using Google Mobility trends; and household interactions are obtained from the ACS household and migration survey. The census provides summary statistics, which we use to initialize the synthetic populations using standard methods like iterative proportional fitting [43]. Hence, we note that the agent population mimics the distribution of New York City, but is not an exact twin (since individual-level microscopic signal is not available).\nBehavior: When sampling agent behavior using an LLM, we use GPT-3.5 for all our experiments. The user prompts are given in the main paper. The system prompt is provided below:\nWe observed marginal behavioral improvements with GPT-4 but did not run scale experiments due to practical considerations (the goal of the paper is to demonstrate capabilities of the framework). We note that AgentTorch API is generic and can integrate with arbitrary offline or online LLM for sampling of behavior.\nEnvironment: Our experiments focus on the dynamics of disease spread and labor market. We use standard disease [22, 12] and labor models [28] which have been used extensively in prior work. The disease model capture agent's probability of infection given interaction neighborhood, virus transmissibility (R0) and demographic-specific susceptibility. For disease progression, we follow a standard SEIRM model [12] with discrete transitions at each agent, with generation times obtained from CDC for the delta wave (in progress during December 2020 to April 2021). The labor model captures the unemployment rate based on their individual willingness to work and insured unemployment rates. To make the environment realistic, we capture additional clinical, behavioral and financial interventions - consistent with the protocols in place at that time in the world. First, Vaccination: agent's receive vaccines under a two dose vaccination protocol, with 21 days delay by default. We consider behavioral stochasticity where agents may choose to not return for the second dose. Second, Testing: agent's have options to receive Antigen or PCR-tests (with their calibrate specificity and result time obtained from CDC data) when they exhibit symptoms. Third, Stimulus: Eligible agents receive stimulus payments at specific time intervals, as was implemented in NYC at the time. Specifically, December 2020 - March 2021 overlaps with the second stimulus check which provided adults $ 600 and additional $ 600 for every child. We note that AgentTorch helps differentiate through these stochastic dynamics and also scale the environment to large populations (8.4 million agents). Finally, we note while these experiments focused on mechanistic dynamics, the differentiability of AgentTorch allows to specify arbitrary complex dynamics. In other examples, we have modeled simulation environments with convolutional neural networks (on GitHub, see models/nca) or even generative models like LLMs. The code for this environment is available on Github at models/covid."}, {"title": "Appendix C: Benchmarking LLM as ABM Agents", "content": "Results in section 5 demonstrated the ability of LLMs to recreate labor force participation behavior across different boroughs on NYC around the time of the second stimulus payment. (December 2020 March 2021). Here, we provide additional details regarding the ability to recreate similar behavior at different points in time. We consider another time-horizon later in the pandemic (October 2021 December 2021) when stimulus payments got exhausted. We updated the prompt to include the following: \"it has been number of {weeks} since start of the epidemic\", where {weeks} specifies the duration since August 2020. We observe the response of LLM Archetype and capture it as the monthly percent change in labor force. Result in Figure 7 shows that the predicted labor force behavior exhibits a good correlation with the observed data, across boroughs. To further validate the LLM archetype's behavior, we poll the agents to sample the rationale behind their decisions. We observe agent's routinely mention \"pandemic fatigue\" which is consistent with real-world discourse from the time. Interestingly, we observe that different agent interpret this dynamic in different ways with some agents keen to return to work to mitigate financial constraints while other agent's feel depressed and less motivated to go back to work. We present a few samples of their reasoning below:\nReasoning 1: Let's think step by step in order to We have been consistently seeing a low willingness to work of 0.1 over the past few months, indicating a strong impact of pandemic fatigue. Considering the number of COVID cases and it has been 18 months since COVID started, there might be a slight increase in willingness to work due to potential financial constraints and fatigue from staying at home for an extended period.\nReasoning 2: Let's think step by step in order to produce the answer. We have been tracking the individual's willingness to work over the past few months, and we can see a gradual increase in their willingness as the number of COVID cases fluctuates. Additionally, as time passes, pandemic fatigue may be setting in, leading to a higher willingness to work. Considering the current number of COVID cases in NYC, and it has been 18 months since COVID started, we can expect the individual's willingness to work to be higher than before.\nReasoning 3: Let's think step by step in order to produce the answer. We have been observing a consistent willingness to work of 0.1 over the past few months, indicating a very low motivation to work. Considering the number of COVID cases in NYC is still relatively high and it has been 18 months since the pandemic started, the pandemic fatigue might have increased. This could further decrease the willingness to work."}, {"title": "Appendix D: Simulating with LLM as ABM agent", "content": "LLMs can capture adaptive agent behavior but are computationally expensive which prohibits simulating large populations. section 6 explore the use of LLMs as agents in ABMs, specifically focusing on the this trade-off between agency and simulation scale. Here, we provide details about prompt specification (when LLMs as used as ABM agents) and the setup for the calibration experiment presented in paper\nPrompt Specification: The user prompt includes details about individual demographics, time-varying infection statistics, pandemic duration and external interventions. When LLM are used as ABM agents, the prompt inputs are bootstrapped from the simulation. Specifically, we use the case statistics and pandemic duration from the simulation trajectory, instead of ground-truth data. We conduct such \"auto-regressive prompting\" for two reasons: i) when simulating for prospective interventions, ground-truth data is not available and hence prompt needs to be specified entirely using simulation; ii) when simulation is un-calibrated, the model peaks may not align well with real-world data. In such case, using ground-truth data is unsuitable for capturing the adaptability of behavior (especially when using time-varying information like infections). Hence, since prompt at step t depends upon simulated trajectory at step t 1, LLMs need to be sampled online during the simulation. Since behaviors cannot be sampled offline, the trade-off between simulation scale and agent behavior becomes particularly critical. We explored that with the calibration experiment.\nCalibration Experiment: We compared three agent configurations:\n\u2022 Heuristic: 8.4 million agents with behavior sampled randomly (follows from [12]). This prioritizes simulation scale over agency.\n\u2022 Archetype: 8.4 million agents with 100 LLMs as archetypes. This provides a trade-off between simulation scale and agency.\n\u2022 LLM-Agent: 100 agents with 100 LLMs AS unique per agent (follows from [36]). This prioritizes agency over simulation.\nArchetype samples behavior for each agent based on the variables in the prompt (each simulation agent maps to population archetype). LLM-Agent sub-samples the population, and also re-scales the simulation outputs during calibration.\nWe conduct calibration with the protocol introduced in [12, 39, 11] where a calibration network (CalibNN) is used to structural parameters and is optimized with gradient from the simulation output. CalibNN is used to predict RO and IUR for the disease and labor dynamics, respectively and is a GRU (since these parameters are time-varying), as in [12]. Each simulation step is a day for disease dynamics and a month for labor dynamics, consistent with real-world considerations in epidemiology and macroeconomics. For disease model, we aggregate the infection data per week and care with a running average of the CDC case data. For labor model, we compare the unemployment rate estimated at each step with the month-over-month data released by Bureau of labor statistics. We use the MSELoss in both cases.\nCalibNN uses multi-modal context data to estimate the structural parameters. This includes the following signals:\n\u2022 Data signals 1: Mobility signals. The signals originate from the record of people visiting points of interest (POIs) in various regions. According to Google, daily changes in visits to various POI categories are collected and compared with the period January 3-February 6, 2020. Additionally, we collected a daily change of visitors from Apple, which shows the relative volume of directions requested across different US states compared to January"}, {"title": "Appendix E: Analysis results", "content": "AgentTorch provides the 'agent_torch.Analysis' API to conduct analyses and interventions upon the trace of a simulation. A corresponding code snippet is provided in the main pa- per (Figure 5) and a demo video of these capabilities is also included in the README.md for github.com/AgentTorch/Agent Torch. https://agenttorch.github.io/AgentTorch/ tutorials/using-models/includes a hands-on tutorial to use the analysis capabilities of Agent- Torch. We initialize an analyzer as 'sim_analyzer = agent_torch.Analysis(simulation)'.\nRetrospective Analysis: Beyond the results presented in the main paper, 'sim_analyzer.poll' can also be used to query the state of the simulation. A sample snippet is given in the callout below:\nCounterfactual Analysis: 'sim_analyzer.query' can be used to update subset of the simulation trace and compare the relative impact of this change. We can then use this to ask \"what-if\" questions. Here, we use this API to analyze the relative impact of behavior change and variant transmissibility on prompt adaption during different stages of the pandemic. Delta (R0 = [2.5 \u2013 4.0]) and Omicron (Ro = [5.5 - 8.0]) were two variants of the COVID-19 pandemic, which emerged at different times. While Omicron was roughly 2-3 times more transmissible that Delta, it produced over 5-20 times the case intensity. This was due to coupled dynamics of behavior and disease. To analyze this, we consider two questions: \"what if we had the delta wave later?\" and \"what if we had the omicron wave earlier?\""}]}