{"title": "Language-Model Prior Overcomes Cold-Start Items", "authors": ["Shiyu Wang", "Hao Ding", "Yupeng Gu", "Sergul Aydore", "Kousha Kalantari", "Branislav Kveton"], "abstract": "The growth of recommender systems (RecSys) is driven by digitization and the need for per-sonalized content in areas such as e-commerce and video streaming. The content in these systems often changes rapidly and therefore they constantly face the ongoing cold-start problem, where new items lack interaction data and are hard to value. Existing solutions for the cold-start problem, such as content-based recommenders and hybrid methods, leverage item metadata to determine item similarities. The main challenge with these methods is their reliance on structured and informative metadata to capture detailed item similarities, which may not always be available. This paper introduces a novel approach for cold-start item recommendation that utilizes the language model (LM) to estimate item similarities, which are further integrated as a Bayesian prior with classic recommender systems. This approach is generic and able to boost the performance of various recommenders. Specifically, our experiments integrate it with both sequential and collaborative filtering-based recommender and evaluate it on two real-world datasets, demonstrating the enhanced performance of the proposed approach.", "sections": [{"title": "1 INTRODUCTION", "content": "The field of recommender systems (RecSys) has witnessed tremendous growth over the last few years driven by the increasing service digitization and the rising demand for personalized content across diverse platforms such as e-commerce and video streaming. Despite significant advancements, the unresolved item cold start problem remains a critical challenge. It arises with newly introduced items lacking sufficient interaction data, and thus struggling to be accurately recommended to users. For instance, Figure 1 illustrates that items such as laptop, dress, camera and glasses that have appeared in historical data are typically easier to recommend, whereas those never-before-seen items are challenging. This issue is especially severe in dynamic environments, such as news recommendation, where new items are constantly introduced, making it tough to identify similarities among cold items due to insufficient information.\nTo address the item cold start problem, previous works primarily fall into two major categories: content-based recom-"}, {"title": "2 RELATED WORK", "content": "As collaborative filtering-based recommenders learn user and item embeddings based on their interactions, they cannot deal with cold-start items without using their metadata. In general, recommenders that are capable of recommending cold-start items are classified into two scenarios: (1) content-based cold-start item recommendation and (2) hybrid methods, which are introduced as follows."}, {"title": "2.1 CONTENT-BASED COLD-START ITEM\nRECOMMENDATION", "content": "Content-based recommenders start with user and item fea-tures, and therefore are suitable and play a major role for rec-ommending cold-start items. User-item interactions can be incorporated as additional features to train the recommender. This process does not intend to learn item embeddings but, instead, leverage item features to during training process. This is initially presented and later published. A deep content-based recommender that performs well on cold-start items is proposed. While content-based recommenders that rely on item features can be effective, it learns the residual distribution of item characteristics based solely on their features, and therefore often misses the nu-anced, implicit relationships between items that can usually be captured through continuous item embeddings. Content-based recommenders typically have limited generalization capabilities compared to embedding-based methods. The latter can better generalize to new or unseen items by dis-cerning their position in the embedding space relative to other items, enhancing recommendation quality."}, {"title": "2.2 HYBRID METHOD FOR COLD-START ITEM\nRECOMMENDATION", "content": "Hybrid approaches combine different strategies to better cap-ture similarity among items. proposed collaborative topic regression. The approach combines prob-abilistic matrix factorization with a topic model prior and learns the distribution over the topics, which are over item descriptions. The prior is applied as a regularizer in regres-sion and yields a classic Bayesian recommendation method. This method does not learn the user-item interactions in a sequential way and therefore might suffer from capturing dependencies among items compared with sequential-based recommenders. Other methods may learn the item embed-dings to uncover their similarities in the latent space. For instance, jointly learned the latent rep-resentations in collaborative filtering as well as semantic representations of items. The semantic representations are extracted from structural, textual, and visual content. addressed the poor performance of transform-ers on short sequences. The key idea is to extend these sequences by simulated prior items, which are added before the actual items. proposed a transformer that takes into account various forms of correlation between context and sequential data via the attention mechanism. However, this approach is tied to the framework of trans-former and lacks generalization to other recommenders. used empirical Bayes to estimate the prior dis-tribution of engagement metrics of an item conditioned on non-behavioral signals. The engagement with the item can be then incorporated using posterior updates. We propose a generic and novel Bayesian-based approach that can be applied to various recommenders, ranging from sequential-based approach to CF-based recommenders, and achieves enhanced performance compared to the corresponding orig-inal method."}, {"title": "3 PROBLEM FORMULATION", "content": "We consider a recommendation problem where we recom-mend items to users. Let $I$ be the set of $N$ recommended items, indexed by $i \\in I$. Let $U$ be the set of $M$ users, in-dexed by $j \\in U$. We denote by $D \\subset I \\times U \\times \\mathbb{N}$ a dataset of user-item interactions that are indexed by time. Specifically, each interaction $(i, j,t) \\in D$ is a triplet of item $i$, user $j$, and time $t$. Without loss of generality, and since the time of making a recommendation is not used in our models, we assume that the time is represented by positive integers that index the recommendations. The first recommended item for each user is at time $t = 1$. If the user is recommended an item at time $t > 1$, they must have been recommended an item at time $t - 1$ as well. We let:\n$H_j = \\{i \\in Z : (i, j, t) \\in D\\}$\nbe the set of items that user $j$ interacted with and:\n$H_{j,t} = \\{i \\in Z : (i, j, l) \\in D, l < t\\}$\nbe the set of items that user $j$ interacted with before time $t$. We denote by $I_{j,t}$ the item that user $j$ interacted with at time $t$. Each item $i$ is associated with metadata $E_i$ that describes it. If the item is a movie, its metadata could be its title, director, or genre. If the item is a product, its metadata could be its name, price, and reviews.\nOur objective is to learn to recommend item $I_{j,t}$, that user $j$ interacts with at time $t$, given the history of their past interactions. This item is a random variable:\n$I_{j,t} \\sim p(\\cdot \\mid H_{j,t}, \\{E_i\\}_{i\\in I}),$   (1)\nwhere $p(\\cdot \\mid H_{j,t}, \\{E_i\\}_{i\\in I})$ is a distribution over all items $I$ conditioned on the history of user $j$ up to time $t$, $H_{j,t}$, and the metadata of all items, $\\{E_i\\}_{i\\in I}$. The dependence on all metadata allows us to model that the probability of recommending an item could depend on its metadata. Our goal is to learn the conditional distribution $p$ in equation 1."}, {"title": "4 SEQUENTIAL RECOMMENDER", "content": "This section has two main parts. In Section 4.1, we intro-duce a general sequential recommender. In Section 4.2, we present a regularized variant of its learning objective, where the regularizer can be interpreted as a Bayesian prior proba-bility. Finally, in Section 5, we present a more informative prior based on language models. This approach, while show-cased with sequential recommenders, can be easily adapted to other recommenders, which we show in Section 7."}, {"title": "4.1 ALGORITHM", "content": "We take the following approach. Since item metatada $E_i$ can have many forms, such as an image of the item, its text description, or reviews, we encode them into a vector $Z_i \\in \\mathbb{R}^d$. Specifically, we let $Z_i = g_\\gamma(E_i)$, where $g_\\gamma$ is a metadata encoder parameterized by $\\gamma$. With this in mind, we approximate the conditional distribution $p$ in equation 1 using a function:\n$f_\\theta(\\cdot \\mid H_{j,t}, \\{g_\\gamma (E_i)\\}_{i\\in I})$   (2)\nparameterized by $\\theta$. This function can be a recurrent neural network or a transformer, and its output is a distribution over all items $I$. The function depends on the history of user $j$ up to time $t$, $H_{j,t}$, and the encoded metadata of all items, $\\{g_\\gamma(E_i)\\}_{i\\in I}$.\nLearning of $f_\\theta$ is typically formalized as maximizing the probability of making correct recommendations over the whole dataset:\n$\\arg \\max_\\theta,\\gamma \\prod_{(i,j,t) \\in D} f_\\theta(i \\mid H_{j,t}, \\{g_\\gamma(E_i)\\}_{i\\in I}).$\nThis can be also viewed as minimizing the cross-entropy loss, $\\arg \\min_{\\theta,\\gamma} L(D; \\theta, \\gamma)$, where the cross-entropy loss is defined as:\n$L(D; \\theta, \\gamma) = \\sum_{(i,j,t) \\in D} - \\log f_\\theta (i \\mid H_{j,t}, \\{g_\\gamma(E_i)\\}_{i\\in I}).$   (3)\nThis loss can be minimized using existing optimizers, such as stochastic gradient descent and Adam. The graphical model of our ap-proach is illustrated in Figure 2."}, {"title": "4.2 REGULARIZED LOSS", "content": "In practice, a regularized loss is optimized instead, which can be written as:\n$\\widehat{L}(D;\\theta, \\gamma, \\rho) = L(D; \\theta, \\gamma) + \\rho \\sum_{i \\in I} ||Z_i||_2^2.$   (4)\nHere $\\rho > 0$ is a regularization parameter that determines the strength of the regularization. The regularization term can be interpreted as a prior probability in a Bayesian formulation as follows. First, fix item $i$ and note that:\n$|| Z_i ||_2^2 = -2 \\log \\exp \\left[ -\\frac{1}{2} Z_i^T Z_i \\right]$\n$=-2 \\log \\exp \\left[ -\\frac{1}{2} (Z_i - 0_d)^T I_d (Z_i - 0_d) \\right]$\nTherefore, up to normalizing constants, $|| Z_i ||_2^2$ is propor-tional to the logarithm of the probability density function (PDF) of $\\mathcal{N}(Z_i; 0_d, I_d)$. Following the same line of reasoning, we can derive the following:\n$\\sum_{i \\in I} || Z_i ||_2^2 = -2 \\log \\exp \\left[ -\\frac{1}{2} \\sum_{i \\in I} Z_i^T Z_i \\right]$\n$=-2 \\log \\exp \\left[ -\\frac{1}{2} (\\mathbb{Z} - 0_{dN})^T I_{dN} (\\mathbb{Z} - 0_{dN}) \\right],$ \nwhere $\\mathbb{Z} = (Z_i)_{i \\in I}$ is the concatenation of all item embeddings. Therefore, up to normalizing constants, $\\sum_{i \\in I} || Z_i ||_2^2$ is proportional to the logarithm of the PDF of $\\mathcal{N}(\\mathbb{Z}; 0_{dN}, I_{dN})$.\nTo complete our argument, we note the following. First, the cross-entropy loss $L(D; \\theta, \\gamma)$ in equation 4 is the negative log-likelihood of data $D$ given learned model parameters, in-cluding learned item embeddings $\\mathbb{Z}$. Second, the regularizer $\\sum_{i \\in I} || Z_i ||_2^2$ in equation 4 is proportional to the logarithm of the probability that item embeddings are $\\mathbb{Z}$. It follows that equation 4 is the posterior probability of model pa-rameters, including learned item embeddings $\\mathbb{Z}$, and thus $\\sum_{i \\in I} || Z_i ||_2^2$ is proportional to the logarithm of the prior probability of $\\mathbb{Z}$."}, {"title": "5 A MORE INFORMATIVE PRIOR", "content": "The regularizer in equation 4 is not informative. In particular, it is proportional to the logarithm of a probability where item embeddings $Z_i$ do not depend on each other. They are simply centered at zero vectors and have unit covariances.\nIn this work, we replace equation 4 with:\n$\\widehat{L}(D;\\theta, \\gamma, \\rho) = L(D; \\theta, \\gamma) + \\rho \\sum_{i,k\\in I} s_{i,k} || Z_i \u2013 Z_k||_2^2,$   (5)\nwhere $s_{i,k} \\in [0, 1]$ it the prior similarity of items $i$ and $k$, and $\\rho > 0$ is a regularization parameter. We assume that the similarity is symmetric, $s_{i,k} = s_{k,i}$ for any $i, k \\in I$.\nAs we show next, the new regularizer encodes the similar-ities of items. Specifically, it can be viewed as a Bayesian prior probability over their embeddings. To see this, note that:\n$|| Z_i - Z_k||_2^2 = Z_i^T Z_i \u2013 Z_i^T Z_k \u2013 Z_k^T Z_i + Z_k^T Z_k$.\nThus:\n$\\sum_{i,k\\in I} s_{i,k} || Z_i - Z_k||_2^2$\n$=-2 \\log \\exp \\left[ -\\frac{1}{2} \\sum_{i,k\\in I} s_{i,k} || Z_i - Z_k||_2^2 \\right]$\n$=-2 \\log \\exp \\left[ \\frac{1}{2} \\sum_{i \\neq k} \\lambda_{i,k} Z_i^T Z_k + \\sum_{i \\in I} \\lambda_i Z_i^T Z_i \\right].$"}, {"title": "where:", "content": "\\\\ $\\forall i \\neq k : \\lambda_{i,k} = -2 s_{i,k}, \\\\ \\forall i\\in I: \\lambda_i = 2\\sum_{k\\neq i} s_{i,k}$ \\\\\nWe can further rewrite this as a single prior distribution as follows. Let $A = (A_{i,k})_{i,k \\in I}$ be a $dN \\times dN$ block matrix, where each block $A_{i,k}$ is a $d \\times d$ matrix. Let:\n$\\forall i \\neq k : A_{i,k} = \\lambda_{i,k}I_d, \\\\ \\forall i \\in I : A_{i,i} = \\lambda_i I_d .$\nThen $\\sum_{i,k\\in I} s_{i,k} || Z_i - Z_k||_2^2$ =\n$-2 \\log \\exp \\left[ -\\frac{1}{2} (\\mathbb{Z} - 0_{dN})^T \\Lambda (\\mathbb{Z} - 0_{dN}) \\right],$ \nThe new learning objective in equation 5 is very different from equation 4. The latter treats items independently, be-cause each is regularized independently using $|| Z_i ||_2^2$, while the former encodes dependencies among the items, because of $|| Z_i - Z_k||_2^2$. The regularizer in equation 5 can also be viewed as a form of graph-based regularization , where the items are nodes and their similarities are edge weights."}, {"title": "6 LEARNING PRIOR", "content": "We compute the similarities $s_{i,k}$ using pre-trained language models (LMs). Let $X_i = LM(E_i) \\in \\mathbb{R}^{d'}$ be the LM em-bedding of metadata of item $i$. Then $s_{i,k} = g(X_i, X_k)$ for some function $g$. We make two assumptions on function $g$. The first assumption is non-negativity: for any $X_i$ and $X_k$, $g(X_i, X_k) \\geq 0$. The second assumption is symmetry: for any $X_i$ and $X_k$, $g(X_i, X_k) = g(X_k, X_i)$.\nSpecifically, we define the similarity of items $i$ and $k$ as:\n$s_{i,k} = g(X_i, X_k) = \\exp \\left[ -\\frac{1}{\\lambda} || X_i - X_k||_2^2 \\right],$   (6)\nwhere $\\lambda > 0$ is a tunable parameter. We set the parameter $\\lambda$ as follows. Let $\\hat{\\mu} = \\sum_{i \\in I} X_i$ be the mean embedding across all items. Let:\n$\\hat{\\sigma}^2 = \\frac{1}{N d'} \\sum_{i \\in I} (X_i - \\hat{\\mu})^T (X_i - \\hat{\\mu})$   (7)\nbe the average variance, across all items and embedding dimensions. Then $\\lambda = 1/\\hat{\\sigma}^2$. In an essence, $1/\\lambda$ is one standard deviation defined by data, across all items and embedding dimensions, akin to that in a normal distribution.\nTo learn more fine-grained item similarities, we also con-sider estimating a separate similarity kernel for each item $i$, which takes the local geometry of the language-model embedding space into account. Specifically, we assume that $X_i \\sim \\mathcal{N}(\\mu_i, \\Sigma_i)$, where $\\mu_i$ and $\\Sigma_i$ can be estimated empiri-cally by $X_i$ and its neighboring item embeddings. Specif-ically, for any neighboring item $i$ and item $k$, $X_i - X_k \\sim \\mathcal{N}(0, 2 \\Sigma_i)$. Let $\\mathcal{N}_i$ be indices of the $K$-nearest neighbors of embedding $X_i$ (including $X_i$). Then equation 6 becomes:\n$s_{i,k} = \\exp \\left[ -\\frac{1}{2} (X_i - \\mu_i)^T \\Sigma_i^{-1} (X_i - \\mu_i) \\right],$   (8)\nwhere\n$\\mu_i = \\frac{1}{K} \\sum_{l \\in \\mathcal{N}_i} X_l,$\n$\\Sigma_i = \\frac{1}{K} \\sum_{l \\in \\mathcal{N}_i} (X_l - \\mu_i) (X_l - \\mu_i)^T.$   (9)\nThe training process is further described in Algorithm 1."}, {"title": "7 EXPERIMENTS", "content": "In this section, we start with introducing two real-world datasets to evaluate our proposed method. Next, we present a set of comparison baselines employed in the experiments. Following that, we delve into the explanation of the cho-sen evaluation metrics in the assessment process. Finally, we evaluate the proposed method from two distinct per-spectives: (1) examining the efficacy of incorporating graph regularization, and (2) analyzing the influence of the penalty associated with the graph regularization component."}, {"title": "7.1 DATASETS", "content": "We employ two real-world datasets, MovieLens (i.e., Movie-Lens 25M) and Amazon (i.e., Amazon Prime Pantry 5-core), to evaluate the proposed method. Additionally, let cold-start (CS) items be items that have at most five instances in the whole dataset, and we further define cold-start (CS) users as those interacted with at least one cold-start item. Users inter-acted with cold-start items are extracted from each dataset\nWe encode movie topics in MovieLens dataset or item re-views in Amazon dataset using the pre-trained encoder of Sentence-BERT to serve as the prior to the proposed method."}, {"title": "7.2 BASELINE MODELS AND ABLATION STUDY", "content": "We select two models as comparison baselines, Bayesian Personalized Ranking Matrix Factorization (BPRMF) and Self-Attention based Sequential Recom-mendation (SASRec), which serve as representative recommenders of a Bayesian and a sequential model. Our proposed method, a Bayesian regu-larizer, is an enhancement to the learning objectives of other recommenders, and not a recommender itself. Therefore, we do not compare to other recommenders.\nBPRMF is a specialized algorithm used in recommenda-tion systems, particularly effective for scenarios involving implicit user feedback, like clicks or purchases. It operates under a Bayesian framework, focusing on providing person-"}, {"title": "7.3 EVALUATION METRICS", "content": "Normalized Discounted Cumulative Gain (NDCG) com-pares rankings to an ideal order where all relevant items are at the top of the list. NDCG at N is determined by dividing the Discounted Cumulative Gain (DCG) by the ideal DCG representing a perfect ranking. DCG measures the total item relevance in a list with a discount that helps address the diminishing value of items further down the list. Higher NDCG indicates better recommendation performance.\nHit Ratio (HR) is the fraction of users for which the correct answer is included in the recommendation list. Higher HR indicates better recommendation performance."}, {"title": "7.4 INSIGHTS FROM EXPERIMENTAL RESULTS", "content": "We evaluate the proposed approach against comparison base-lines on two real-world datasets according to: (1) the overall performance on general recommendation task; (2) the performance on cold-start item recommendation; (3) the effect of the localized and the global variance estimator on cold-start item recommendation and (4) the effect of the hyperparameter that penalizes the graph regularization. From the experi-mental results, we can conclude that the proposed approach demonstrates superior performance. Additionally, we have the following observations.\nThe proposed method achieves enhanced overall per-formance on recommendation. Although the proposed method is designed to recommend cold-start items, we still evaluate its performance on general recommendation (i.e., recommendation on a mixture of cold-start and gen-eral items). As illustrated in Table. 2, we find the sequen-tial model (i.e., SASRec) outperforms the Bayesian model with matrix factorization (i.e., BPRMF). On MovieLens dataset, SASRec outperforms BPRMF by 161.83% regard-ing NDCG on average, and by 263.12% regarding HR on average. On Amazon dataset, SASRec outperforms BPRMF by 55.15% regarding NDCG on average, and by 2.59% regarding HR on average. Besides, we note that the per-formance of the proposed methodologies, BPRMF-ours and SASRec-ours, exhibits a marked enhancement in com-parison to the original versions of these methods. For in-stance, the NDCG and HR of BPRMF-ours are 109.33% and 30.93% larger than BPRMF, respectively, in MovieLens dataset. In Amazon dataset, NDCG and HR of BPRMF-ours are 40.08% and 1.99% larger that BPRMF, respectively. We find similar pattern on SASRec, where NDCG and HR of SASRec-ours are 26.42% and 4.67% larger than SASRec in MovieLens dataset, respectively. In Amazon dataset, NDCG and HR of SASRec-ours are 14.12% and 0.83% larger than SASRec, respectively. The superior performance of the pro-posed method potentially results from the cold-start items contained in the dataset. The proposed method is able to well learn the behavior of those cold-start items, which cannot be captured by conventional recommenders.\nThe proposed method achieves superior performance on cold-start item recommendation. To evaluate the perfor-mance of the proposed method on recommending cold-start items, we extract users that interacted with at least one cold-start items in both MovieLens and Amazon datasets. Then we apply the proposed approach and comparison baselines to those subsets. As shown in Table 3, the proposed ap-proach is consistently superior. For instance, in MovieLens dataset, NDCG and HR of BPRMF-ours are larger than BPRMF by 58.13% and 64.65% on average, respectively. In Amazon dataset, NDCG and HR of BPRMF-ours are larger than BPRMF by 74.97% and 19.13% on average, respec-tively. Similar pattern is observed on the sequential recom-mender. Specifically, SASRec-ours is superior than SASRec by 32.53% and 71.80% on average regarding NDCG in the MovieLens and the Amazon dataset, respectively. In terms of HR, SASRec-ours outperforms SASRec by 3.04% and 14.62% on average, respectively. The superior performance of the proposed method by leveraging graph regularization to incorporate the prior knowledge based on item metadata potentially attributes to well-captured item similarity by the kernel (i.e., equation 8). The kernel enhances the item"}, {"title": "Localized covariance estimator has improved perfor-mance against the global estimation.", "content": "In addition to evalu-ating the performance on recommendation, we also assess the effect of covariance estimation in equation 9. The intu-ition of estimating localized covariance using surrounding K nearest items is to save the complexity of the estimation process from O(N) to O(K). Also, the localized estimation potentially achieves fine-grained estimation of the covari-ance, but at the risk of poor generalization to other items dur-ing the inference phase. We compare the proposed approach using localized estimation with K = \u221aN (i.e., BPRMF-ours and SASRec-ours) against those using glocal estima-tion of the covariances using all items in the dataset (i.e., BPRMF-ours-global and SASRec-ours-global). As shown in Table 3, BPRMF with the locally estimated covariance achieves 40.57% and 38.45% higher NDCG on average than the one with globally estimated covariance, in MovieLens and Amazon datasets, respectively. Additionally, in terms of HR, the localized estimator outperforms the global estimator by 5.49% and 0.63% on average in MovieLens and Amazon, respectively. This indicates that fine-grained estimation on covariance plays a significant role in the accuracy of recom-mending cold-start items. Estimating the covariance using all items might not provide informative insights in learning representation of similarly items."}, {"title": "Strength of penalty on graph regularization is crucial.", "content": "Last but not the least, we evaluate the impact of hyperpa-rameter (i.e., p in equation 5) in the recommendation perfor-mance. The hyparameter intuitively measures the strength of the graph regularization. When it is too small, then the similarity captured by the prior may not help learning item representation. When the hyperparameter is too large, then the graph regularization forces similar items to have the same representation, leading to oversmoothing issues. Figure 3 and Figure 4 measure the relative NDCG and HR compared to the baseline (e.g., p = 0), respectively. As shown in Figure 3, when p increases, the NDCG will first increases and then drops when evaluating on MovieLens dataset, for both general and cold-start item recommenda-tion. In Amazon dataset, the NDCG will increase when p increases. This might be due to more diverse items contained in Amazon dataset, causing the item representation learning assisted by similar items much challenging. In terms of HR (Figure 4), in MovieLens dataset, we observe similar pattern as the NDCG of recommending general items will increase and then drop when p increases. The NDCG will drop in general when p increases when recommending cold-start items, while it is still higher than the baseline (i.e., p = 0). In Amazon dataset, when p increases, HR will increase when recommending cold-start items and stay slightly higher than the baseline (i.e., p = 0) when recommending general items."}, {"title": "8 CONCLUSION", "content": "We propose a novel approach for cold-start item recommen-dation that leverages LMs to inject prior knowledge of items and integrates a Bayesian regularizer during the training pro-cess of the RecSys. Our experimental results demonstrate enhanced performance of recommending cold-start items of the proposed approach compared to baselines. Particularly, our method can be adapted to the learning objective of any sequential or collaborative filtering-based recommenders, as long as item metadata is available.\nWe develop our method from publicly available MovieLens 25M and Amazon Prime Pantry 5-core Ni et al. datasets. It is important to note that, like other recom-menders, our implementation will likely reflect the socioe-conomic and entity biases inherent in datasets that we use. Additionally, although our method is designed for cold-start item recommendation, we are not able to control the item that user would recommend, which may contain improper contents."}, {"title": "A REPRODUCIBILITY", "content": "Datasets and code to reproduce results of the paper is in Code is proprietary and will be released soon upon approval."}]}