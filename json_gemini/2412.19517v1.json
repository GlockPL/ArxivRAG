{"title": "Estimation of System Parameters Including Repeated Cross-Sectional Data through Emulator-Informed Deep Generative Model", "authors": ["Hyunwoo Cho", "Sung Woong Cho", "Hyeontae Jo", "Hyung Ju Hwang"], "abstract": "Differential equations (DEs) are crucial for modeling the evolution of natural or engineered systems. Traditionally, the parameters in DEs are adjusted to fit data from system observations. However, in fields such as politics, economics, and biology, available data are often independently collected at distinct time points from different subjects (i.e., repeated cross-sectional (RCS) data). Conventional optimization techniques struggle to accurately estimate DE parameters when RCS data exhibit various heterogeneities, leading to a significant loss of information. To address this issue, we propose a new estimation method called the emulator-informed deep-generative model (EIDGM), designed to handle RCS data. Specifically, EIDGM integrates a physics-informed neural network-based emulator that immediately generates DE solutions and a Wasserstein generative adversarial network-based parameter generator that can effectively mimic the RCS data. We evaluated EIDGM on exponential growth, logistic population models, and the Lorenz system, demonstrating its superior ability to accurately capture parameter distributions. Additionally, we applied EIDGM to an experimental dataset of Amyloid beta 40 and beta 42, successfully capturing diverse parameter distribution shapes. This shows that EIDGM can be applied to model a wide range of systems and extended to uncover the operating principles of systems based on limited data.", "sections": [{"title": "I. INTRODUCTION", "content": "A system of differential equations (DE) is essential for modeling the dynamics of various systems, offering scientific and mechanistic insights into physical and biological phenomena. The solutions to a DE largely depend on its parameters and determining these parameters is crucial for fitting the solutions to observed data. Specifically, the distribution of the estimates provides additional insights, such as uncertainty quantification of data or heterogeneity of underlying dynamics [1], leading to a more comprehensive understanding of the phenomena. These estimation tasks are typically performed using optimization methods that update parameters to make the corresponding solutions of the system more closely match the observational data, especially when the data are obtained by observing individual samples (subjects) over time (i.e., time series data). Different from time series data, in various fields, such as biology, economics, and political science, data are often collected from different samples or groups of individuals at multiple points in time (i.e., repeated cross-sectional (RCS) data [2, 3, 4, 5, 6]). For instance, [7] analyzed sequential data on PER protein levels in fruit flies to study the dependence of molecular characteristics on neurons. However, obtaining PER levels at different time points entailed the death of the flies, limiting continuous data collection over time. In another study, [8] used an exponential growth model to investigate how drugs affected tumor sizes in mice over time. As the study progressed, mice were sacrificed, complicating the association of observational data and resulting in RCS data. Furthermore, RCS data can be obtained from community surveys reflecting the change of opinions from different people over time (e.g., opinion polls by Gallup, the Michigan Consumer Sentiment Index, records of Congressional votes, Supreme Court decisions, and presidential statements [9, 10, 11, 12, 13]).\nWhile fitting parameters with time-series data is feasible with classical optimization methods, handling RCS data poses a challenge. Specifically, [14] demonstrated that estimating parameters using the mean value of RCS data (e.g., [7]) or a Gaussian process (GP)-based model calibration (e.g., [15, 16, 17, 18]) yields significant mismatches, resulting in incorrect interpretation of a given phenomenon. As GP-based model calibration only depends on the mean and covariance of data at each time point, it fails to capture the complete information contained within RCS data, yielding only unimodal distribution estimates. Bayesian methods, including approximate Bayesian computation (ABC) [19, 20] and Metropolis-Hastings (MH) algorithms [21, 22], also struggle to accurately estimate parameter distributions, due to their sensitivity to the prior distribution [23]. To improve their applicability, [14] developed a method to estimate parameters while preserving the information contained in RCS data. However, this method is efficient only when the number of observations in the RCS data is small because this method requires large computational costs for many artificial trajectories."}, {"title": "II. METHODS", "content": "We propose a method for estimating the distribution of parameters within a time-evolutionary ordinary differential equation (ODE), represented as\n$$y'(t) = f[y(t), p],$$ \nwhere $y(t; p) \\in \\mathbb{R}^{n_y}$ denotes the solution with dimension $n_y$ at time $t$. The set of parameters $p \\in \\mathbb{R}^{n_p}$ represents biological or physical properties (such as growth rate or carrying capacity). Here, we aim to estimate the posterior distribution of the parameter $p$ that can fit the corresponding solution $y(t; p)$ to the RCS data $Y$. Specifically, $Y$ consists of the data points $(t_r, y_{j_r})$, where $\\{t_r\\}_{r=1}^T$ denotes the $T$ observation time points and $j_r \\in \\{1, 2, ..., J\\}$ is an index with varying maximum $J_r$ depending on $r$ for the given RCS data."}, {"title": "B. HyperPINN as an emulator for DE solver", "content": "In this section, we build an emulator that can immediately provide the solution $y(t)$ of Eq. (1) given $p$. The structure of the emulator is motivated by HyperPINN ([24]), which uses two fully connected neural networks: a hypernetwork $h$ ([35, 36, 37]) and fully connected neural network $m$ (main network). Specifically, the structure of $h$, with weights and biases $\\theta_h$, is designed to map the set of parameters $p$ to the weights and biases of the main network $m$, $\\theta_m$ (detailed nodes and activation functions are provided in Table. V):\n$$\\theta_m(p) = h(p; \\theta_h).$$ \nOnce $\\theta_m(p)$ is obtained by training the hypernetwork, these values are used as the weights and biases of the main network $m$. That is, the output of the main network $m$ is directly determined by the outputs of the hypernetwork. As a result, the main network immediately produces a function $m(t; \\theta_m(p))$ that closely approximates the solution of Eq. (1), $y(t; p)$:\n$$y(t; p) \\approx m(t; \\theta_m(p)).$$\nTo train the HyperPINN for the task described above, we first define the probability distribution of parameters $p$, denoted by $\\mathcal{D}$, as well as the time interval $[t_1, t_T]$, which encompasses the period covered by the experimental data. Next, we construct two loss functions based on [24]: 1) data loss $\\mathcal{L}_{data}$ and 2) physics loss $\\mathcal{L}_{physics}$. First, $\\mathcal{L}_{data}$ is used to fit the output of the main network $m$ to the solution $y(t; p)$ by minimizing their differences:\n$$\\mathcal{L}_{data}(\\theta_h) = \\sum_{i=1}^{T_{obs}} \\mathbb{E}_{p \\sim \\mathcal{D}} |m(t_i; \\theta_m(p)) - y(t_i; p)|^2,$$ \nwhere $\\{t_i\\}_{i=1}^{T_{obs}}$ denotes the $T_{obs}$ observation time points from the experimental data. Next, we introduce physics loss, which measures how well the output of the main network $m$ satisfies the DE of Eq. (1), where $\\mathbb{E}$ represents the expectation over the probability distribution $\\mathcal{D}$. The measurement can be quantified by substituting the output of the main network into the DE:\n$$\\mathcal{L}_{physics}(\\theta_h) = \\sum_{i=1}^{T_{col}} \\mathbb{E}_{p \\sim \\mathcal{D}} \\Big|\\frac{d}{dt}m(t_i; \\theta_m(p)) - f[m(t_i; \\theta_m(p)), p, t_i]\\Big|^2,$$ \nwhere $\\{t_i\\}_{i=1}^{T_{col}}$ represents the collocation time points within the time interval $[t_1, t_T]$. By minimizing Eqs. (4,5), we expect that the output of the main network $m(t; \\theta_m(p))$ will not only closely approximate $y(t; p)$ but also accurately describe the underlying dynamics of the system. We also provide a detailed mathematical analysis for the training framework in the Supplemental materials. While the loss functions of Eq. (4-5) are useful for understanding the training frameworks theoretically, they are not efficient for implementation on computational devices. Hence, in this study, we employed discretized versions of the two loss functions of Eq. (4-5) as follows:\n$$\\mathcal{L}_{data}^{(disc)}(\\theta_h) = \\sum_{i=1}^{T_{obs}} \\sum_{j=1}^{N_p} |m(t_i; \\theta_m(p_j)) - y(t_i; p_j)|^2,$$\n$$\\mathcal{L}_{physics}^{(disc)}(\\theta_h) = \\sum_{i=1}^{T_{col}} \\sum_{j=1}^{N_p} \\Big|\\frac{d}{dt}m(t_i; \\theta_m(p_j)) - f[m(t_i; \\theta_m(p_j)), p_j, t_i]\\Big|^2.$$\nwhere $\\{p_j\\}_{j=1}^{N_p}$ denotes the set of $N_p$ parameters sampled from the probability distribution $\\mathcal{D}$. $y(t; p)$ of Eq. (1) with different $p$ can be obtained through a DE solver (e.g., LSODA in Scipy package). The choice of $N_p$ depends on the number of time points $T$, number of nodes, and type of activation function in the HyperPINN. We refer the reader to Theorems A.2 and A.3 in the supplemental materials, where detailed analyses, including error analysis, are provided. Finally, we assign weights $\\alpha, \\beta$ to the two discretized loss functions, Eq. (6-7), to prevent biases arising from the initial values of the loss functions. The units of the two loss functions are not equal in general. Therefore, the training can be conducted by minimizing the total loss function, $\\mathcal{L}(\\theta_h)$, which is defined as the sum of the two loss functions with positive weights $\\alpha$ and $\\beta$:\n$$\\mathcal{L}(\\theta_h) = \\alpha \\mathcal{L}_{data}(\\theta_h) + \\beta \\mathcal{L}_{physics}^{(disc)}(\\theta_h).$$"}, {"title": "C. WGAN framework for estimating parameter distribution", "content": "In this section, we aim to find the parameter distribution $p$ that generates the given RCS data $Y$. For this task, we obtain an initial guess of $\\pi(p)$ and sample $N$ parameters $\\{p_i\\}_{i=1}^N$. For each $p_i$, we can simultaneously obtain approximations for solutions of Eq. (1) through HyperPINN as follows:\n$$\\widehat{Y} = \\{\\{(t_r, \\hat{y}_{i,r})\\}_{r=1}^T\\}_{i=1}^N = \\{\\{(t_r, m(t_r; p_i))\\}_{r=1}^T\\}_{i=1}^N.$$\nNext, we adjust the parameter distribution $\\pi(p)$ so that the distribution of $\\widehat{Y}$ is sufficiently close to that of the given RCS dataset $Y = \\{\\{(t_r, y_{j_r})\\}_{r=1}^T\\}_{r=1}^J$. This adjustment involves measuring the difference between $\\widehat{Y}$ and $Y$ and then modifying the parameter set $\\{p_i\\}_{i=1}^N$ to minimize this difference.\nFor this task, we employ WGAN with gradient penalty, providing a correct parameter distribution through a generator [25, 46]. Using WGAN, we aim to reduce the following Wasserstein distance (with Kantorovich-Rubinstein duality [47]) between the distributions of $\\widehat{Y}$ and $Y$, denoted as $\\mu_{\\widehat{Y}}$ and $\\mu_Y$, respectively:\n$$d(\u03bc_{\\widehat{Y}}, \u03bc_Y) = \\sup_{\\{f \\in Lip(R^d, \\mathbb{R}): ||f||_{Lip} \\le 1\\}} \\mathbb{E}_{(\\hat{t}, \\hat{y}) \\sim \\mu_{\\widehat{Y}}} [f(\\hat{t}, \\hat{y})] - \\mathbb{E}_{(t, y) \\sim \\mu_Y} [f(t, y)],$$\nwhere $\\mathbb{E}$ denotes the expectation, and $Lip(R^d, \\mathbb{R})$ represents the set of all real-valued 1-Lipschitz functions on $R^d$ (i.e., $Lip(R^d, \\mathbb{R}) = \\{f : \\mathbb{R}^d \\rightarrow \\mathbb{R} \\Big| ||f||_{Lip} = \\sup_{x \\ne y} \\frac{|f(x)-f(y)|}{x-y} < \\infty\\}$). For each iteration stage of WGAN, we first sample a set of latent variables $\\{z_i\\}_{i=1}^N$ from the standard normal distribution, $\\mathcal{N}(0, 1)$. The generator $G(\\cdot; \\theta_G)$ in WGAN, with weights and biases $\\theta_G$, maps $\\{z_i\\}_{i=1}^N$ to a set of parameters $\\{p_i\\}_{i=1}^N = \\{G(z_i; \\theta_G)\\}_{i=1}^N$. Then, we immediately obtain $\\widehat{Y}$ corresponding to $\\{p_i\\}_{i=1}^N$ through the emulator in Eq. (2-3). Then, the discriminator $D(\\cdot; \\theta_D)$ in WGAN, with weights and biases $\\theta_D$, calculates the loss $\\mathcal{L}_D(\\theta_G, \\theta_D)$ (i.e., the difference between $\\widehat{Y}$ and $Y$) to minimize\n$$\\mathcal{L}_{D}(\\theta_G, \\theta_D) = \\frac{1}{N} \\sum_{k=1}^{|\\widehat{Y}|} D(t_k, \\hat{y}_k; \\theta_D) - \\frac{1}{|Y|} \\sum_{k=1}^{|Y|} D(t_k, y_k; \\theta_D) + \\lambda \\sum_{k=1}^{\\tilde{|Y|}} (||\\nabla_{\\tilde{(t_k, \\hat{y}_k)}} D(\\tilde{t_k}, \\tilde{y}_k; \\theta_D)||_2 - 1)^2,$$\nwhere the augmented data $(\\tilde{t_k}, \\tilde{y_k})$ for calculating the gradient penalty (in the last term of $\\mathcal{L}_D(\\theta_G, \\theta_D))$ are defined as\n$$(\\tilde{t_k}, \\tilde{y_k}) = \\epsilon_k(\\tilde{t_k}, \\tilde{y_k}) + (1 - \\epsilon_k)(t_k, y_k)$$\nwith uniform random coefficient $\\epsilon_k \\sim U[0,1]$ for each $k \\in \\{1, 2, ..., |Y|\\}$. Note that when $|\\widehat{Y}| > |Y|$, the subset of $\\widehat{Y}$ with size $|Y|$ for calculating the gradient penalty is chosen randomly for each iteration. The gradient penalty term enforces the discriminator $D$ to be a 1-Lipschitz function, ensuring that minimizing the loss is equivalent to finding $f$ in Eq. (8)([46]). Following the recommendations in [46], we set the coefficient $\\lambda$ to 10."}, {"title": "III. RESULTS", "content": ""}, {"title": "A. Development of Emulator-Informed Deep Generative Model (EIDGM)", "content": "The EIDGM operates in the following stages: 1) We build an emulator using HyperPINN that immediately produces the solution of the DEs corresponding to the given set of parameters. 2) Next, we randomly sample N sets of parameters through a generator of WGAN and produce corresponding solutions through the emulator (Fig. 1, Generator, Hyper-PINN). 3) Then, we measure the difference between the solutions and given RCS data via a discriminator in WGAN (Fig. 1, Discriminator). 4) By minimizing the difference and updating both the discriminator and generator, we show that EIDGM accurately captures true parameter distributions. To evaluate the efficacy of EIDGM in estimating parameter distributions, we used four different time-evolutionary DEs: an exponential growth model, a logistic population model [26], and the Lorenz system. These problems demonstrate that EIDGM can accurately estimate true parameter distributions and predict system behaviors even in the presence of data heterogeneity. Next, we compared estimation performance using different types of emulators with GP [16], DeepONet [48], and EIDGM. Among the emulators, HyperPINN generally provides accurate and precise parameter estimates (Table. I). Detailed test procedures are provided below."}, {"title": "B. Exponential growth model", "content": "The exponential growth model describes changes in population size y(t) over time t:\n$$y' = ry,$$\nwherer represents the population growth rate. We first obtain a distribution of parameters with a single peak at r = 2 (Fig. 2(a), True). After sampling 36 parameter values from the underlying distribution, we generate snapshots for each time t = 0, 0.25, 0.5, 0.75, 1, which are from the trajectories generated with 36 sampled parameters as the RCS dataset (Fig. 2(a), Observation) (also see Simulation dataset generation in the Supplemental materials for details). We next estimate parameter distributions corresponding to the RCS dataset using three different emulators: GP, DeepONet (with WGAN), and EIDGM (Fig. 2(a), Estimation, red). In this case, all three methods can accurately estimate the underlying distribution. Unlike with a single peak, only DeepONet and EIDGM can accurately estimate the parameter distributions when the underlying distributions have different peaks (Fig. 2(b-c)). We also provide quantified results using the Wasserstein distance, which measures the distance between true and estimated distributions, in Table. I."}, {"title": "C. Logistic population model", "content": "The logistic population model represents the changes in population size y(t) over time t with the maximum population size K:\n$$y' = ry(1 - y/K).$$\nWe begin by constructing distributions for r and K with a single peak, respectively (Fig. 3(a), True). Note that the peak values are derived from ranges that were estimated in previous studies ([26, 49, 50]) (also see Table I for detailed parameter values). We then sample six parameters from the two distributions. Using these parameters, we generate snapshots of the time-series for t = 0, 0.5, 1.0, 1.5, 2.0 with an initial value y(0) = 0.1 (Fig. 3(a), Observation). Similar to the exponential growth model, the estimates through EIDGM were close to each peak (Fig. 3, Estimation, yellow)."}, {"title": "D. Lorenz system", "content": "The below Lorenz system describes a simple atmospheric circulation using three key variables: the rate of convective motion in the system X, the temperature difference between the ascending and descending flows within the convection cell Y, and the deviation of the system from thermal equilibrium or the vertical temperature distribution in the convection Z:\n$$\\frac{dX}{dt} = \\sigma (Y - X),$$\n$$\\frac{dY}{dt} = X (\\rho - Z) - Y,$$\n$$\\frac{dZ}{dt} = XY - \\beta Z,$$\nwhere Prandtl number $\\sigma$ controls the ratio of fluid viscosity to thermal diffusivity, Reyleigh number $\\rho$ drives convection based on temperature differences, and $\\beta$ is related to the damping of convection. To evaluate the performance of EIDGM, we first generate three cases of RCS datasets (Fig. 4, left dots) based on three underlying parameter distributions (Fig. 4, right red/blue/green distributions). We then apply EIDGM to obtain parameter estimates (Fig. 4, right yellow distributions). The results demonstrate that EIDGM can accurately estimate the underlying parameter distributions. For exceptional cases, we draw the trajectories corresponding to the distributions obtained from EIDGM (Fig. 4, True-yellow lines). Surprisingly, these trajectories can penetrate the RCS dataset, suggesting potential identifiability issues in parameter estimation."}, {"title": "IV. APPLICATION TO REAL-WORLD RCS DATA", "content": ""}, {"title": "A. Amyloid-\u03b2 40 and 42", "content": "We estimated the growth rates and maximum population sizes for a logistic model using the amyloid-\u03b2 40 (\u0391\u03b240) and amyloid-\u03b2 42 (\u0391\u03b242) datasets (Fig. 5(a-b), left red dots). These datasets include concentrations of A340 and A\u03b242 measured at four different time points (4, 8, 12, and 18 months), with each having 12 and 13 independent observations, respectively (see [26, 49, 50] for details). The collection of all observations is RCS data because mice with high amyloid levels were sacrificed after the observation of A\u03b240 and A\u03b242. We drew parameter distributions of the logistic model with the RCS dataset (Fig. 5(a-b), right).\nWe first validate the accuracy of parameter estimates. Unlike the simulation dataset, we cannot find the underlying distributions. Hence, we directly draw 1,000 solution trajectories of the logistic model with the parameter estimates (Fig. 5(a-b), left black lines). This shows that the model solutions with estimated parameters closely match the given RCS data. Therefore, we expect that the estimated distributions are sufficiently close to the underlying parameter distributions.\nThrough this estimation, we found at least two patterns in the growth rater within both the A840 and A\u03b242 datasets. Unlike the growth rate, the maximum capacity K indicates different patterns within two datasets. Specifically, A\u03b240 converged towards a consistent maximum level of approximately 0.6 across all test subjects, whereas A\u03b242 displayed relatively variable maximum levels that depend on the individual test subject."}, {"title": "V. CONCLUSION", "content": "In this paper, we introduced the EIDGM to address the challenges of parameter estimation from RCS data in dynamic system modeling. EIDGM effectively combines the strengths of deep learning in both emulating numerical solvers and estimating complex distributions by integrating HyperPINN and WGAN. The experimental results demonstrate that EIDGM significantly improves the accuracy and reliability of parameter estimation compared to traditional methods."}, {"title": "APPENDIX", "content": ""}, {"title": "A. Mathematical analysis", "content": "This section presents a mathematical analysis of the EIDGM and it can accurately estimate parameter distributions that fit the model (Eq. (1)) to RCS data. There are three steps as follows: 1) We first establish that HyperPINN can accurately generate a solution to Eq. (1) for a given parameter set p by training with both data and physics loss functions, as defined in Eq. (5). As it cannot be realized on a computational device, we use discretized versions of the data and physics loss functions. 2) We next show that the discretization does not significantly affect the accuracy of the HyperPINN framework up to a specific error bound. 3) Finally, we demonstrate that the discretized version of the physics loss function can be minimized with sufficiently many weights and biases in HyperPINN. In summary, HyperPINN can effectively operate as a DE emulator, calculating the solutions for a given parameter set p by minimizing the discretized losses."}, {"title": "1) Training HyperPINN by minimizing both data and physics losses:", "content": "Raissi et al. introduced the original physics loss [28], $l(nn(t), \\theta_{nn})$, which measures how well an artificial neural network $nn(t)$ with weights and biases $\\theta_{nn}$ satisfies the given dynamical system of Eq. (1):\n$$l(nn(t), \\theta_{nn}) = \\Big|\\frac{d}{dt}nn(t; \\theta_{nn}) - f[nn(t; \\theta_{nn}), p, t]\\Big|^2.$$\nFor a given fixed p, previous studies have shown that neural networks $nn(t) = nn(t; \\theta_{nn})$ closely approximate the solution $y(t; p)$ of Eq. (1) when $l(nn(t), \\theta_{nn})$ becomes small over every t [51, 28, 52, 53, 54]. Specifically, we refer to the following theorem in [55], which can be derived by Gr\u00f6nwall's and H\u00f6lder's inequalities."}, {"title": "Theorem A.1.", "content": "Suppose that $f[y(t), p,t]$ is Lipschitz continuous in y with Lipschitz constant L > 0. Assume that the the neural network $nn(t)$ satisfies $|y(t_1; p) - nn(t_1; \\theta_{nn})| \\le \\delta$ for some $\\delta \\ge 0$, where $y(t; p)$ is the solution of Eq. (1). Then, the following inequality holds:\n$$|y(t; p) - nn(t; \\theta_{nn})| < \\delta + \\Big|\\int_{t_1}^t l(nn(s), \\theta_{nn}) ds \\Big| e^{L(t-t_1)}, \\text{ for } t \\ge t_1.$$\nAs we use hyperPINN to calculate the solutions for various sets of parameters p simultaneously, the original physics loss can be modified. More specifically, weights and biases $\\theta_m(P)$ in the main network $m(t)$ in HyperPINN are determined by the output of the other networks, i.e., $\\theta_m(p) = h(p, \\theta_h)$. Hence, we take an expectation $\\mathbb{E}$ over the probability density function of the parameter p, $\\mathcal{D}$, on the physics loss:\n$$\\mathcal{L}_{physics} (\\theta_h) = \\mathbb{E}_{p \\sim \\mathcal{D}}l(m(t), \\theta_m(p)).$$\nBy minimizing this loss function, we expect that the solutions from the main network with a parameter p, sampled from $\\mathcal{D}$, can accurately satisfy Eq. (1). To verify this, we first obtain the lower bound on the probability that HyperPINN prediction for given parameters p has a small value of $l(m(t), \\theta_m(p))$:\n$$P\\Big(\\frac{1}{T_{col}} \\sum_{i=1}^{T_{col}} l(m(t_i), \\theta_m(p)) \\le \\epsilon\\Big) \\ge \\prod_{i=1}^{T_{col}} P(l(m(t_i; \\theta_m(p)) \\le \\epsilon)$$\n$$\\ge \\prod_{i=1}^{T_{col}} \\Big(1 - \\frac{\\mathbb{E}_{p\\sim \\mathcal{D}}l(m(t_i), \\theta_m(p))}{\\epsilon}\\Big)$$\n$$\\ge 1 - \\sum_{i=1}^{T_{col}} \\frac{\\mathbb{E}_{p\\sim \\mathcal{D}}l(m(t_i), \\theta_m(p))}{\\epsilon}$$\n$$= 1 - \\frac{T_{col}}{\\epsilon} \\mathcal{L}_{physics} (\\theta_h).$$\nwhere the second inequality is obtained using the standard Markov's inequality. Therefore, for a given parameter p sampled from $\\mathcal{D}$, the original physics loss $l(m(t), \\theta_{nn})$ in (9) can be reduced within an error $\\epsilon$ if $\\mathcal{L}_{physics}$ is sufficiently small. Consequently by Theorem A.1, a small value of $l(m(t), \\theta_{nn})$ implies that the main network $m(t; \\theta_m(p))$ is close to the solution y(t, p) of Eq. (1)."}, {"title": "2) Difference of the two physics loss functions:", "content": "In practice, we cannot calculate the above definite integral and expectation due to the lack of computational resources. Thus, we alternatively use the discretized version of $\\mathcal{L}_{physics}$ defined in Eq. (7) as follows:\n$$\\mathcal{L}_{physics}^{(disc)}(\\theta_h) = \\frac{1}{T_{col}}\\frac{1}{N_p} \\sum_{i=1}^{T_{col}} \\sum_{j=1}^{N_p} l(m(t_i), \\theta_m(p_j)),$$\nwhere $N_p$ denotes the number of trajectories used in the discretized physics-informed loss $\\mathcal{L}_{physics}^{(disc)}(\\theta_h)$. The set of $N_p$ parameters $\\{p_i\\}_{i=1}^{N_p}$ are sampled from the probability distribution $\\mathcal{D}$. Sequentially, a set of solutions $\\{y(t; p_j)\\}_{i=1}^{N_p}$ is obtained through the DE solver (e.g., LSODA in Scipy package).\nDespite the discretization, we first show that the value of $\\mathcal{L}_{physics}^{(disc)}(\\theta_h)$ can be close to $\\mathcal{L}_{physics}(\\theta_h)$ up to specific error bounds. To show this, we briefly introduce some definitions required for the proof. Let $\\mathcal{M}$ be a class of main networks, where each main network is associated with a hypernetwork. Hypernetworks in each main network, h, consist of fully connected neural networks with different weights and biases of the i-th layer, $[W,b] = \\{W_i \\in \\mathbb{R}^{g_{i+1} \\times g_i}, b_i \\in \\mathbb{R}^{g_{i+1}}\\}_{i=1}^k$, and map p to the weights and biases of the main networks. For convenience, we denote a single element of $\\mathcal{M}$ as $m(t) = m(t; h(p, [W, b])) = m(t; h(p; \\theta_h))$, where $\\theta_h$ refers the weights W and biases b.\nUsing $\\mathcal{M}$, we first prove that there exists a subset of $\\mathcal{M}$ with a finite number of elements such that every element in $\\mathcal{M}$ is close to at least one element in this subset up to distance $\\epsilon > 0$. The distance $d_D$ between two elements $m(t)$ and $\\tilde{m}(t)$"}, {"title": "in $\\mathcal{M}$ with hypernetworks $h(\\cdot, \\theta_h)$ and $\\tilde{h}(\\cdot, \\theta_{\\tilde{h}})$ is defined by", "content": "$$d_D(m, \\tilde{m}) := \\frac{1}{T_{col}} \\sum_{i=1}^{T_{col}} \\mathbb{E}_{p \\sim \\mathcal{D}}|l(m(t_i), h(p; \\theta_h)) - l(\\tilde{m}(t_i), h(p; \\theta_{\\tilde{h}}))|.$$\nThe subset is called an $\\epsilon$-cover of $(\\mathcal{M}, d_D)$. The rigorous definition of an $\\epsilon$-cover is as follows:"}, {"title": "Definition A.1.", "content": "A set $\\{m_1, m_2, \\dots, m_c\\}$ in $\\mathcal{M}$ is called an $\\epsilon$-cover of $(\\mathcal{M}, d_D)$ if for every main network in $m \\in \\mathcal{M}$, we can always find an index $i \\in \\{1, 2, ..., c\\}$ such that $d_D(m_i, m) < \\epsilon$.\nIn Definition A.1, we denote an integer $N(\\epsilon, \\mathcal{M}, d_D)$ as the smallest number of $\\epsilon$-covers of $(\\mathcal{M}, d_D)$. Sequentially, we define the covering number that indicates the number of candidates in the class as follows:\n$$C(\\epsilon, \\mathcal{M}) := \\sup_{\\mathcal{D} \\in \\mathbb{D}} N(\\epsilon, \\mathcal{M}, d_D),$$\nwhere $\\mathbb{D}$ denotes the set of probability distributions of parameter p that share the same compact support. In a previous study, when time interval $[t_1, t_T]$ is just a point (i.e., $t_1 = t_T$), Baxter et al. showed that the absolute difference between $\\mathcal{L}_{physics}(\\theta_h)$ and $\\mathcal{L}_{physics}^{(disc)}(\\theta_h)$ has an upper bound, depending only on the covering number [56]."}, {"title": "Theorem A.2.", "content": "(Theorem 3, [56]) Given $\\epsilon > 0$ and $1 > \\delta > 0$, suppose that $T_{col} = 1$ and the number of trajectories in Eq. (5) for training, $N_p$, satisfies the following inequality:\n$$N_p \\ge \\max \\Big\\{ \\frac{64}{\\epsilon^2} \\log\\Big(\\frac{4C(\\epsilon, \\mathcal{M})}{\\delta}\\Big), \\frac{16}{\\epsilon^2} \\Big\\}.$$\nThen, the following inequality holds with probability at least $1 - \\delta$:\n$$|\\mathcal{L}_{physics}^{(disc)}(\\theta_h) - \\mathcal{L}_{physics}(\\theta_h)| \\le \\epsilon.$$\nNote that Theorem A.2 is available only when $T_{col} = 1$. In general, the number of collocation time points $T_{col}$ can be recorded multiple times. Hence, we extend the same results in the case when $T_{col} > 1$ through the following corollary:"}, {"title": "Corollary 1.", "content": "If $N_p$ satisfies\n$$N_p \\ge \\max \\Big\\{ \\frac{64}{\\epsilon^2} \\log\\Big(\\frac{4C(\\epsilon, \\mathcal{M})}{\\delta/T_{col}}\\Big), \\frac{16}{\\epsilon^2} \\Big\\},$$\nthen, the same inequality of Eq. (12) in Theorem A.2 also holds.\nProof. Suppose that we derive the $N_p$ trajectories as above."}]}