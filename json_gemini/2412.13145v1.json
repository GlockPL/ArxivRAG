{"title": "Agnosticism About Artificial Consciousness", "authors": ["Dr Tom McClelland"], "abstract": "Could an Al have conscious experiences? Any answer to this question should conform to\nEvidentialism \u2013 that is, it should be based not on intuition, dogma or speculation but on\nsolid scientific evidence. I argue that such evidence is hard to come by and that the only\njustifiable stance on the prospects of artificial consciousness is agnosticism. In the\ncurrent debate, the main division is between biological views that are sceptical of artificial\nconsciousness and functional views that are sympathetic to it. I argue that both camps\nmake the same mistake of over-estimating what the evidence tells us. Scientific insights\ninto consciousness have been achieved through the study of conscious organisms.\nAlthough this has enabled cautious assessments of consciousness in various creatures,\nextending this to Al faces serious obstacles. Al thus presents consciousness researchers\nwith a dilemma: either reach a verdict on artificial consciousness but violate\nEvidentialism; or respect Evidentialism but offer no verdict on the prospects of artificial\nconsciousness. The dominant trend in the literature has been to take the first option while\npurporting to follow the scientific evidence. I argue that if we truly follow the evidence, we\nmust take the second option and adopt agnosticism.", "sections": [{"title": "Artificial Consciousness in Context", "content": "Could an Al have conscious experiences? Not long ago, this was widely regarded as a theoretical\nquestion about an obscure science fiction scenario. Now, though, it is generally taken to be a serious\nquestion of immediate concern. The interdisciplinary literature on Al is replete with proposals on the\nprospects of artificial consciousness (AC). Government bodies are starting to take seriously the\npossibility that measures might be required to prevent, or at least regulate, the development of\nconscious Al.\u00b9 And the public at large, fed by considerable media coverage, increasingly see it as a\nquestion that must be addressed. This escalation of interest is animated by the ethical implications of\nconscious Al. Schneider captures the central ethical worry:\n'The question of whether Als could have experience will be key to how we value their\nexistence. Consciousness is the philosophical cornerstone of our moral systems, being central\nto our judgment of whether someone or something is a self or person rather than a mere\nautomaton. And if an Al is a conscious being, forcing it to serve us would be akin to slavery.\n(Schneider 2019, pp. 3-4)"}, {"title": "", "content": "The question of AC has thus become not just a question that we'd like to answer but a question we\nhave a moral imperative to answer. This flurry of interest in AC takes place against the backdrop of\nprogress in both Al and consciousness science.\nIn the context of Al research, we've witnessed various breakthroughs that have greatly enhanced the\nperformance of Al. In particular, the advancement of Large Language Models (LLMs) has given us Al\nthat can sometimes give the appearance of consciousness (Colombatto & Fleming 2024). In a notable\nincident, the Google engineer Blake Lemoine claimed that the chatbot LaMDA had achieved\nconsciousness. Although very few people - experts or otherwise - agreed with Lemoine's claim, the\nincident contributed to a growing feeling that robust tests for artificial consciousness are needed.\nBeyond LLMs, there has been progress in other forms of Al that raise serious questions about artificial\nconsciousness. Although whole-brain emulations are a long way from emulating a human brain, they\ncan emulate the neural connectome of more simple organisms such as C. elegans and, more recently,\nthe larval fruit fly (Bentley et al 2016; Winding et al 2023). If we had reason to believe these organisms\nare conscious, should we infer that their Al emulations are also conscious? Other programs are\ndesigned not to emulate whole brains but just the mechanisms thought to be responsible for\nconsciousness. Would such emulations be conscious? In computer simulations of evolution, Al evolves\nin a manner comparable to that of organisms. Given that our consciousness emerged through an\nevolutionary process, might artificial evolution also give rise to conscious entities?\nIn the context of consciousness science, there have been considerable developments in the scientific\ntools used to examine consciousness and a major expansion in the range of theories available (see\nKuhn 2024). This has contributed to a new-found confidence that questions about the distribution of\nconsciousness can (and should) be answered scientifically. Consider the question of octopus\nconsciousness. The science of consciousness is not in a position to prove whether an octopus has\nconscious experiences. But it is in a position to deliver an assessment of the likelihood of octopus\nconsciousness based on solid empirical findings rather than intuition, speculation or dogma (Birch et\nal 2021).\nSo when it comes to the question of conscious Al, the dominant view is that the question can (and\nshould) be answered scientifically. For instance, a recent major report led by Butlin and Long starts\nfrom the claim that '...the assessment of consciousness in Al is scientifically tractable because\nconsciousness can be studied scientifically and findings from this research are applicable to Al' (Butlin\n& Long et al, 2023 p. 4). We can summarise this outlook in the following principle:\nEvidentialism: positive or negative attributions of consciousness to Al should be\nbased exclusively on scientific evidence.\nCrucially, this principle isn't just meant to guide how we make judgements of artificial consciousness\nin research contexts. It is meant to guide real-world decisions about Al, such as how people should\ntreat Al, how governments should regulate the development of Al and perhaps even how the law\nshould protect Al entities. Birch captures this important practical dimension of Evidentialism:\n'Evidence-free speculations may still have their own space elsewhere - the pub or caf\u00e9, or even\nthe seminar room, book group, or lab meeting - but, for the purpose of making important,\nsober decisions affecting real lives, we need to create a space in which they are left at the\ndoor.' (2024, p. 50)\nSo given that our verdicts ought to be evidence-based, what should we conclude about the prospects\nof AC? Different authors reach different conclusions: AC-Advocates say that there is enough evidence"}, {"title": "", "content": "to conclude that the right kind of Al would be conscious while AC-Deniers say that there is enough\nevidence to conclude that Al, on its current trajectory, is unlikely to be conscious. Although most of\nthese authors reach their conclusions with caution, my aim is to show that even cautious conclusions\nare unwarranted. The evidence we have doesn't tell us either way whether Al could be conscious and\nwon't be able to tell us any time soon. So following Evidentialism, the only stance that is warranted is\nagnosticism about artificial consciousness.\nIn the next section I'll make the case for agnosticism about artificial consciousness. My argument starts\nfrom the fact that what we know about consciousness we know from human organisms. This enables\nus to make some warranted inferences about consciousness in non-human organisms, but when we\ntry to extend these inferences to sophisticated Al we hit an epistemic wall. So although the ideal of a\nscience-based measure of artificial consciousness is a good one, the reality is that it leaves us in\nepistemic limbo.\nIn Section 3 I pit agnosticism against different approaches to the assessment of AC: the theory-heavy\napproach and the theory-light approach. I argue that both approaches violate Evidentialism by taking\na 'leap of faith' that theories or markers developed with regards to organisms are also applicable to Al.\nI also consider the possibility that future progress in the science of consciousness might overcome this\nepistemic problem and argue that such optimism is unfounded. In Section 4 I address some potential\nobjections to agnosticism: that it sets epistemic standards unnaturally high; that it is detached from\nthe reality of how we attribute consciousness to entities; and that it relies on problematic metaphysical\nassumptions about consciousness. In each case I show that the objections don't stick. In Section 51\nmove on to considering the ethical consequences of agnosticism. Not reaching a verdict on whether\nsophisticated Al would be conscious leaves us with a serious dilemma about whether to develop such\nAl and how to treat it if we did. I argue that the key moral difference-maker is not consciousness as\nsuch but sentience (i.e. valenced consciousness) and that we can get enough of an epistemic grip on\nartificial sentience to guide our decision-making without having to abandon agnosticism about\nartificial consciousness.\nMy main aim in this paper is to make a case for agnosticism about artificial consciousness. My more\nmodest aim is to show that agnosticism is at least a serious option that deserves consideration. At\npresent, the main division-point in the literature is between AC-Advocates who think sophisticated Al\nprobably will be consciousness and AC-Deniers who think that it probably won't. I seek to highlight\nanother key division point, this time between AC-Gnostics who believe that we can reach evidence-\nbased verdicts on artificial consciousness and AC-Agnostics who believe that we cannot. The epistemic\nproblems presented by artificial consciousness are different in kind to those raised by, say, octopus\nconsciousness and the ethical problems are similarly distinctive. Both of these special features must\nbe kept in mind as we continue to grapple with the prospects of artificial consciousness."}, {"title": "The Case for Agnosticism", "content": "Before making the case for agnosticism, I should specify what kind of Al is under consideration. For\nthree reasons, I'm not making a case for agnosticism about current Al being conscious. The first is that\neven those favourable to AC are doubtful that current Al is conscious. For instance, Butlin & Long et al"}, {"title": "", "content": "argue that '...no current Al systems are conscious, but... there are no obvious technical barriers to\nbuilding Al systems which satisfy these indicators'. (2023, p. 1) This kind of future-orientated view is\ncommon among AC-Advocates, so an agnostic argument against them should also be targeted at future\nAl. The second reason is that these doubts about current Al being conscious are well-founded. As we\nwill see, being agnostic about whether current Al is conscious would be unnecessarily cautious. The\nthird reason is that ethical worries about AC tend to be focussed less on the Al we currently have and\nmore on the Al we might develop (e.g. the 'Run-Ahead Principle' in Birch 2024, p. 324). Whether we\ncan know if future Al will be conscious is the more serious ethical question.\nI will thus make a case for agnosticism about consciousness in hypothetical sophisticated Als i.e. the\nkind of Al to which AC-Advocates would attribute consciousness. My case for agnosticism is based on\nthe problem of applying theories and markers developed in the context of organic consciousness to\nnon-organic cases. To capture this problem, it will be helpful to focus on Als with features that would\nconstitute strong evidence of consciousness if displayed by an organism. I will call such hypothetical\ncases 'Challenger-Als'. They are challengers in the sense that they seem to be serious contenders for\nconsciousness but also challengers in the sense that they present us with a challenging epistemic\nconundrum. Different approaches suggest different indicators of consciousness."}, {"title": "The Argument for Agnosticism", "content": "The overall argument for agnosticism is simple:\n1) We do not have a deep explanation of consciousness.\n2) If we do not have a deep explanation of consciousness, then we cannot justify a verdict on\nwhether Challenger-Al is conscious.\n3) Therefore, we cannot justify a verdict on whether Challenger-Al is conscious.\nIn this section I will make a preliminary case for the two premises of the argument and unpack its\nconclusion. A fuller defence of the argument, including an assessment of whether the epistemic\nproblem is temporary or permanent, will unfold in following sections.\nStarting with the first premise, why think that we don't have a deep explanation of consciousness? A\ndeep explanation is one that tells us why a cognitive episode occurs consciously rather unconsciously.\nPut another way, it explains why there is something it's like to be in a given state rather than nothing\nit's like. However, attempts to offer such an explanation run into the 'hard problem' (Chalmers 1995).\nWhenever we identify some physical or functional state associated with consciousness, it remains a\nmystery why that state should constitute a conscious experience rather than obtaining unconsciously.\nConsider a Global Workspace Theory (GWT), such as the Dehaene-Changeux Model (Dehaene &\nChangeux 2005), according to which a state is conscious when it is made globally available to a range\nof brain processes. What is it about a state being globally distributed that makes it a conscious state?\nWhy aren't we zombies that have a global workspace but lack subjective experience? Nothing in theory\ntells us why there should be something it's like to be in a globally distributed cognitive state. Different\ntheories make different claims about what kind of state suffices for consciousness, but none explains\nwhy it would be sufficient.\nThis is not to say that existing theories of consciousness have no explanatory value. Imagine we want\nto know why someone undergoing inattentional blindness is conscious of a basketball player in their"}, {"title": "", "content": "visual field but not, say, of the gorilla. A Global Workspace Theory would answer (roughly) that a visual\nrepresentation of the player has made it into the neuronal network that broadcasts information to\nother brain areas whereas a visual representation of the gorilla has not. In a shallow sense, this tells\nus why the subject is conscious of the player: assuming that global distribution constitutes\nconsciousness, the visual representation of the player is conscious because it's globally distributed.\nBut there is a deeper question left unanswered: why would the global distribution of this visual\ninformation constitute a visual experience? The same is true for every other theory on the table: each\ntheory can informatively answer various questions about consciousness but leaves the hard question\nunanswered.\nLet's move on to the second premise of the argument: if we do not have a deep explanation of\nconsciousness, then we cannot justify a verdict on whether Challenger-Al is conscious. Were we to\ndiscover a deep explanation of consciousness that solves the hard problem, we would have no trouble\ndetermining whether a Challenger-Al is conscious. We'd understand the necessary and sufficient\nconditions of consciousness and could just check whether the Al meets the conditions. But in the\nabsence of a deep explanation we are left only with more shallow explanations, and such shallow\nexplanations are unsuited to the task.\nAgain, I will defend this claim further in due course but for now I will illustrate the point using GWT.\nStudies of consciousness in humans, such as inattentional blindness studies, yield a body of evidence\ntaken to support GWT. This theory can then give us a verdict on various difficult cases of human\nconsciousness. Based on what we know from ordinary human cases, we can reach conclusions about\nwhether a vegetative state patient is likely to be conscious, for example. We can even go a step further\nand reach conclusions about consciousness in non-human animals by looking at whether they have a\nneuronal global workspace like we do. And all such conclusions would enjoy indirect empirical support\nfrom the evidence that motivated GWT in the first place. The theory gives us what you might call\ninferred conditions of consciousness: there's nothing about the theory that explains why global\ndistribution would be necessary and sufficient for consciousness, but the evidence suggests that it is\nnecessary and sufficient in typical human subjects and we can cautiously infer that the same is true\nfor atypical humans and non-human animals.\nWhen it comes to Al, however, a deeper problem emerges. Even if there is good evidence that the\nmental states of organisms are conscious when broadcast in a global workspace, that is not enough to\ntell us that a comparable broadcasting of information in an Al would also be conscious. The evidence\nwe have says nothing about whether non-biological global workspaces also give rise to phenomenal\nconsciousness. When we take evidence from organic human consciousness and try to apply it to Al,\nour evidence hits an epistemic wall. The conditions of consciousness proposed by GWT are inferred,\nbut the inferences are only warranted if kept within an appropriate scope. Al is beyond that scope.\nA good way of highlighting this epistemic wall is to consider the debate between computational\nfunctionalist and biological accounts of consciousness. According to computational functionalism,\nconsciousness is a matter of instantiating the right kind of information processes. GWT, for instance,\nattempts to describe the software of consciousness. This software happens to be running on the\nhardware (or wetware) of the brain, but if that same software were to run on silicon chips you would"}, {"title": "", "content": "still get consciousness. It is substrate independent. On the biological account, consciousness is a matter\nof having the right kind of biological state. Consciousness is an organic phenomenon that depends on\nhow processes are physically realised. Although we might be able to simulate that phenomenon on\nsilicon, the result would merely be a model of consciousness and not itself conscious.\nNow, how can we decide between these two accounts? The putative evidence for GWT is evidence\nthat globally distributed information is conscious in organisms. But when it comes to whether the\nsame would also be true in AI, GWT hits the evidence wall. The evidence does not distinguish between\ntwo live possibilities: i) the global workspace in itself being sufficient for consciousness; ii) the global\nworkspace being integral to how consciousness is achieved in organisms but, in itself, insufficient for\nconsciousness. If GWT offered a deep explanation of consciousness that captured why global\ndistribution would constitute consciousness then we could rule out the second possibility. But the\nevidence yields at best a shallow explanation that leaves both possibilities wide open.\nThe example relies on a distinction between function and substrate that has rightly come under\ncriticism. Many have argued that we can't neatly divide the mind into levels, and that the functional\nstructure of the mind is deeply intertwined with the neural structures that realise it (Cao 2022, Godfrey\nSmith 2023, Seth 2024). But this is just one of many ways of illustrating the epistemic wall. Consider\nGodfrey Smith's (2016) suggestion that consciousness requires a subject and that subjecthood requires\nan embodied organism. This presents theories like GWT with another pair of possibilities that their\nevidence cannot select between: i) that a global workspace is sufficient for consciousness; ii) that a\nglobal workspace yields consciousness only when embedded in an organic subject. And if we look\nbeyond the debate between functional and biological accounts of consciousness and consider other\naccounts - such as dualism, panpsychism or information integration theory - we will find yet more\noptions that the evidence is unable to decide between.\nHaving made a preliminary case for the two premises, we can now move on to the agnostic conclusion.\nPresented with a Challenger-Al, the evidence available cannot discriminate between two possibilities:\ni) that the Al has these markers because it is genuinely conscious; ii) that the Al has these markers\nbecause it mirrors conscious processes without having subjective experience. The conclusion is not\nthat the evidence of consciousness is mixed, with a dead heat between evidence in favour and\nevidence against. Rather, the conclusion is that there is no real evidence to be had. The Al has features\nthat would constitute evidence were they found in an organism. But the shallow explanations available\nto us do not justify taking these features as evidence in non-biological cases. The only stance available\nto us is thus agnosticism. The term 'agnostic', introduced by T.H. Huxley, seems apposite for several\nreasons. Huxley explains:\n'I invented the word \"Agnostic\" to denote people who, like myself, confess themselves to be\nhopelessly ignorant concerning a variety of matters, about which metaphysicians and\ntheologians, both orthodox and heterodox, dogmatise with the utmost confidence.' (Huxley,\n1884)\nThis passage reflects the spirit of my proposed view. It captures the idea that, when presented with a\nChallenger-Al, we would be ignorant as to whether it is conscious. It also captures the idea that we\nshould oppose any view that reaches a verdict with any confidence. It's not about picking between\northodox and heterodox views of AC, but rather criticising both on the grounds that their confidence\nis unwarranted. Huxley goes on to elaborate his outlook:"}, {"title": "", "content": "'Agnosticism is of the essence of science, whether ancient or modern. It simply means that a\nman shall not say he knows or believes that which he has no scientific grounds for professing\nto know or believe. Consequently Agnosticism puts aside not only the greater part of popular\ntheology, but also the greater part of anti-theology. On the whole, the \"bosh\" of heterodoxy\nis more offensive to me than that of orthodoxy, because heterodoxy professes to be guided\nby reason and science, and orthodoxy does not.' (Huxley, 1884)\nAgain, this reflects the spirit of my proposal. What is at issue is whether assessments of artificial\nconsciousness can be grounded in scientific evidence. The first half of this quotation captures the\nEvidentialist principle that many in the AC literature purport to defend. The second half captures the\nproblem that Gnostics not only draw conclusions that are insufficiently supported by the evidence, but\ndo so whilst purporting to be led by the science. It is exactly this mismatch that my agnostic proposal\nis intended to highlight.\nIt is important here to distinguish agnosticism about artificial consciousness from mere uncertainty\nabout artificial consciousness. Expressions of uncertainty are ubiquitous in the literature.\n'...we can never be certain that Al is conscious, even if we could study it up close.' (Schneider\n2016, p. 198)\n'A definitive answer to this question is not currently possible, given the lack of a consensus\nview about the minimally sufficient conditions for consciousness.' (Seth 2024, p. 1)\n'At this stage, we know a lot more that is relevant than we used to know. But giving a definite\nanswer to the main questions...is not something that can be done with a lot of confidence.'\n(Godfrey Smith 2023)\n'The motto of my approach is 'no magic tricks'. We start in a position of horrible, disorienting,\napparently inescapable uncertainty about other minds, and then...the uncertainty is still there\nat the end.' (Birch 2024, p. 17)\nSuch expressions of uncertainty might appear quite agnostic. However, there is a world of difference\nbetween taking a cautious stance on whether Challenger-Al is conscious and taking no stance. The\nauthors above all offer an opinion one way or the other: Godfrey Smith and Seth (cautiously) deny that\nChallenger-Al would be conscious while Schneider and Birch (cautiously) claim that it would be. The\nrest of the quoted passage from Birch illustrates this: \u2018I am not in the business of selling magical escape\nroutes from uncertainty. My aim is to construct a framework that allows us to reach collective decisions\ndespite our uncertainty: decisions that command our confidence. (Birch 2024, p. 17, my italics)\nIf the argument for agnosticism is sound, conceding uncertainty in our conclusions is not enough. The\nonly level of confidence warranted by the evidence is no level of confidence either way. For a genuine\nexpression of such agnosticism, we can turn to Massimo Pigliucci:\n'The only examples we have of consciousness are biological. That doesn't mean that, in\nprinciple, it is not possible to build artificial consciousness, but we have no idea how to do it.\nAnd we don't know whether, in fact, it is even possible. This truly is an open question where I\nam entirely agnostic.' (Pigliucci, quoted Kuhn 2024 p. 147)"}, {"title": "Agnosticism vs. Gnostic Approaches", "content": "The previous section offered a general argument for agnosticism about artificial consciousness. This\nsection reinforces that argument by pitting agnosticism against specific approaches to artificial\nconsciousness. The approaches available can be divided according to two cross-cutting distinctions:\nthe theory-heavy and theory-light distinction (Birch 2022), and the contemporary optimism vs. future\noptimism distinction. What unites the different views is that they are all Gnostic - that is, they claim\nthat some verdict can be reached on the consciousness of Challenger-Al that conforms to\nEvidentialism."}, {"title": "Agnosticism vs. the Theory-Heavy Approach", "content": "To adopt a theory-heavy approach to consciousness is to select a particular theory of consciousness\nthen assess whether a given entity is conscious in terms of that theory. Heavy-theorists can be AC-\nAdvocates or AC-Deniers. AC-Advocates support artificial consciousness on the grounds that their\npreferred theory entails that a Challenger-Al would be conscious. AC-Deniers reject artificial\nconsciousness on the grounds that their preferred theory would say that a Challenger-Al isn't\nconscious. An initial problem here is that there are too many theories to choose from. Without even\nan approximate consensus, we don't know which theory to adopt and are left with a stalemate\nbetween contradictory proposals. The deeper problem, though, is that a theory cannot get the kind of\nevidential support needed to yield warranted conclusions about AC.\nAs discussed, any theory that gets its empirical support from human consciousness hits an epistemic\nwall when it tries to generalise to artificial consciousness. For a theory-heavy approach to work, you\nneed an empirically well-supported theory that yields a verdict (one way or the other) on whether a\nChallenger-Al is conscious. But here heavy-theorists face what I call the Evidentialist Dilemma. On the\none hand, they can adopt a modest version of their preferred theory that respects the epistemic wall\nand avoids unwarranted extrapolations to non-organic cases. But such modest theories would yield no\nverdict on whether a Challenger-Al is conscious, leading to agnosticism. On the other hand, they can\nadopt a bold version of their preferred theory that specifies the necessary and sufficient conditions of\nconsciousness as such. This theory would yield a verdict on whether a Challenger-Al is conscious, but\nat the expense of Evidentialism. It is this second horn of the Evidentialist Dilemma on which heavy-\ntheorists tend to fall.\nLet's start with how AC-Advocate heavy-theorists compromise Evidentialism. An assumption that tends\nto do a lot of heavy lifting (pun very much intended) is computational functionalism. Often this\nassumption is tacit but sometimes it is presented explicitly. For instance, Butlin & Long et al state: 'we\nadopt computational functionalism, the thesis that performing computations of the right kind is\nnecessary and sufficient for consciousness, as a working hypothesis' (2023, p. 17). Computational\nfunctionalism is the auxiliary thesis needed to get from evidence about organic consciousness to\nconclusions about artificial consciousness. But what justifies the assumption of computational\nfunctionalism? No empirical evidence is offered in favour of it. In fact, it's not even clear what kind of\nempirical evidence could speak in favour of it. This suggests that computational functionalism isn't a\nhypothesis arrived it by careful by reflection on the evidence but rather an article of faith. Here the\nAC-Advocate comes up against the epistemic wall then takes a leap of faith over it: a leap of faith that"}, {"title": "", "content": "the right computational structure suffices for consciousness. But, as Seth puts it, '...the fact that\ncomputational functionalism is so frequently assumed does not mean it is true.' (2024, p. 6)\nComputational functionalists might respond that they don't need empirical evidence for the claim as\nit enjoys a priori support from broader philosophical considerations. Chalmers's famous neural\nreplacement thought experiment offers an argument of this kind. The idea is that the neurons in your\nbrain are gradually replaced by silicon chips with the same functionality until eventually the whole\nbrain is artificial. During this process, would you cease to be conscious? Chalmers and company say no\nand infer that computational structures suffice for consciousness. But critics respond that it simply\nbegs the question. If computational functionalism is false then at some point the subject would cease\nto be conscious but, due to the preservation of function, would continue to report being conscious\n(Udell & Schwitzgebel 2021). This is representative of the wider philosophical debate around\ncomputational functionalism: a priori considerations can't settle the matter any better than empirical\nevidence.\nWhat about heavy-theorists who deny artificial consciousness? AC-Deniers agree with the foregoing\nobjections to computational functionalism but make their own unwarranted claims. This is because\nbiological theories of consciousness run into the hard problem too. Just as there's nothing about\ncomputational processes that explains why there would be something it's like to undergo some of\nthose processes, nor is there anything about biological processes that explains why there would be\nsomething it's like to undergo them. Consider the following passage from Godfrey Smith:\n'...if you ask...why there should be \"something it's like\" to be one of these organisms to have\nthis going on \u2013 why there should be something it feels like to have an endogenous large-scale\npattern of nervous system activity, modulated by events and also put into service into the\nservice of action from a point of view \u2013 then to me, there's not much of a gap here anymore.\nOnce such systems exist, it should feel like something to be them.' (Godfrey Smith 2023)\nHere Godfrey Smith seems to take a leap of faith comparable to that of the computational\nfunctionalists. He establishes some biological features associated with consciousness and concludes\nthat these features suffice for consciousness. Yet nothing about the biological processes explains why\nthey should occur phenomenally. Furthermore, none of the empirical evidence warrants inferring that\nthey are sufficient for consciousness. Crucially for the discussion of AC, the considerations offered also\nfail to warrant the conclusion that such features are necessary for consciousness.\nThe lesson here us that offering an alternative to computational functionalism isn't the same as\nshowing that computational functionalism is false. A biological theory-heavy approach faces the same\nEvidentialist Dilemma as its opponent. They can adopt a modest biological theory that infers how\nconsciousness is achieved in organisms but that stays neutral on whether it might be achieved in some\nother way for Al. Or they can adopt a bold theory that says consciousness is essentially biological,\nyielding a clear verdict on Challenger-Al but at the expense of Evidentialism. The problems with\ncomputational functionalism shouldn't push us towards denying artificial consciousness. They should\npush us towards agnosticism. The evidence doesn't tell us whether to go down the functional path or\nthe biological path, so the evidence doesn't tell us whether a Challenger-Al would be conscious."}, {"title": "Agnosticism vs. the Theory-Light Approach", "content": "Might a theory-light approach to conscious fare better? This approach was developed by Griffin and\nSpeck in the context of animal consciousness: \u2018...although no single piece of evidence provides\nabsolute proof of consciousness, [the] accumulation of strongly suggestive evidence increases\nsignificantly the likelihood that some animals experience at least simple conscious thoughts and\nfeelings' (Griffin & Speck, 2004). Without adopting any particular theory of consciousness, we can take\na meta-theoretical approach that identifies markers of consciousness that draw on a range of theories.\nThese markers might then be used to assess artificial consciousness (see Birch 2024). This approach\nhas some initial advantages over the theory-heavy approach. The hard problem might stop us from\narriving at a single explanation of consciousness, but this approach suggests we don't need to explain\nconsciousness to establish viable markers.\nHowever, the fundamental problem with this approach is much the same. Why should we believe that\nany given marker is indicative of consciousness? Something is taken as a marker of consciousness when\na theory of consciousness says that it is. And that theory should be given credence (even if not believed\noutright) because of the evidence in favour of it. But that evidence hits just the same epistemic wall\nas the theory-heavy approach. The evidence shows, at best, that these properties are markers of\nconsciousness in organisms. So applying them to Al is unwarranted. This problem is captured by\nShevlin:\n'...the theory-light approach works for non-human animals insofar as it relies on the\nassumption that a given cluster of abilities that are consciousness-dependent in humans\nwould be similarly consciousness-dependent if found in a non-human animal. This assumption\nis broadly plausible to the extent that there are broad homologies between human and animal\ncognitive architectures. Yet such homologies or even structural similarities are unlikely to apply\nwhen considering non-biological systems, since it seems prima facie unlikely (though, of\ncourse, possible) that abilities like trace-conditioning and reversal learning if present in a\nmachine would be underwritten by consciousness in the same way as biological systems.'\n(Shevlin 2024, p. 4)\nSo the theory-light approach faces the now-familiar Evidentialist Dilemma. They can adopt a modest\nset of markers that are well-supported by the empirical evidence but only applicable in the domain\nwhere the evidence was gathered viz. organisms. Or they can adopt a bold set of markers applicable\nto biological and non-biological cases but which are no longer warranted by the empirical evidence.\nOnce more a leap of faith is taken. This time it's not a leap of faith that a given theory is true. Instead,\nit is a leap of faith that the available theories taken as a whole somehow overcome the epistemic wall\nwhen none of them could do so individually. The wall is less salient here because the markers are\narrived at on the basis of numerous theories and each theory hits the wall in a different way. But hit it\nthey do. So a theory-light approach is similarly unable to reach a verdict on artificial consciousness\nwithout compromising Evidentialism."}, {"title": "Agnosticism vs. Future optimism", "content": "So far the approaches discussed have offered a verdict on artificial consciousness based on the current\nstate of consciousness science. A possible response to the agnostic arguments above is to concede\nthat although we're in a bad epistemic position today", "...as we become\nbetter able to explain, predict, and control properties of consciousness in terms of underlying\nmechanisms, the sense of mystery about how consciousness relates to matter will gradually dissolve\nand may eventually disappear (2024, p. 20).\nI suggest that such optimism is unwarranted. The problems for Gnostic views is that efforts to\nunderstand artificial consciousness face an epistemic wall. Why should we think that science is on a\ntrajectory to overcome this wall? Consider the sense of mystery that motivated Huxley": "agnosticism\nabout the underpinnings of consciousness:\n'How it is that anything so remarkable as a state of consciousness comes about as a result of\nirritating nervous tissue, is just as unaccountable as the appearance of the djinn when Aladdin\nrubbed his lamp in the story.' (Huxley 1886)\nOne might argue that the ensuing 150 years of scientific progress have lessened the mystery and, if\\"}]}