{"title": "Finetuning and Quantization of EEG-Based Foundational BioSignal Models on ECG and PPG Data for Blood Pressure Estimation", "authors": ["B\u00e1lint T\u00f3th", "Dominik Senti", "Thorir Mar Ingolfsson", "Jeffrey Zweidler", "Alexandre Elsig", "Luca Benini", "Yawei Li"], "abstract": "Blood pressure (BP) is a key indicator of cardiovascular health. As hypertension remains a global cause of morbidity and mortality, accurate, continuous, and non-invasive BP monitoring is therefore of paramount importance. Photoplethysmography (PPG) and electrocardiography (ECG) can potentially enable continuous BP monitoring, yet training accurate and robust machine learning (ML) models remains challenging due to variability in data quality and patient-specific factors. Recently, multiple research groups explored Electroencephalographic (EEG)-based foundation models and demonstrated their exceptional ability to learn rich temporal resolution. Considering the morphological similarities between different biosignals, the question arises of whether a model pre-trained on one modality can effectively be exploited to improve the accuracy of a different signal type. In this work, we take an initial step towards generalized biosignal foundation models by investigating whether model representations learned from abundant EEG data can effectively be transferred to ECG/PPG data solely with fine-tuning, without the need for large-scale additional pre-training, for the BP estimation task. Evaluations on the MIMIC-III and VitalDB datasets demonstrate that our approach achieves near state-of-the-art accuracy for diastolic BP (mean absolute error of 1.57 mmHg) and surpasses by 1.5\u00d7 the accuracy of prior works for systolic BP (mean absolute error 2.72 mmHg). Additionally, we perform dynamic INT8 quantization, reducing the smallest model size by over 3.5\u00d7 (from 13.73 MB down to 3.83 MB) while preserving performance, thereby enabling unobtrusive, real-time BP monitoring on resource-constrained wearable devices.", "sections": [{"title": "I. INTRODUCTION", "content": "Blood Pressure (BP) is one of the most critical indicators of cardiovascular health and overall physiological status [1]. Typically reported as Systolic Blood Pressure (SBP) and Diastolic Blood Pressure (DBP) pressure, normal adult val-ues range between 90-120 mmHg (SBP) and 60-80 mmHg (DBP) [2]. Elevated BP, or hypertension, is a major risk factor for severe Cardiovascular Diseases (CVDs), including stroke and heart failure [3], [4]. In 2017 alone, over 17 million deaths worldwide were linked to CVDs, with high SBP implicated in more than half of these cases [5]. These statistics highlight the urgent need for frequent or continuous BP monitoring to enable early detection and timely intervention.\nMost clinical and at-home BP measurements currently rely on cuff-based devices, which are non-invasive but provide only intermittent readings. Their bulkiness and re-quirement for patient compliance also limit their utility for continuous tracking [6], [7]. Consequently, there is substantial interest in leveraging additional physiological signals-particularly Electrocardiogram (ECG) and Photo-plethysmogram (PPG)\u2014to estimate BP without a cuff. ECG measures electrical activity of the heart, while PPG tracks blood volume changes. Both exhibit strong correlations with arterial blood pressure [8], [9], and recent deep learning methods have successfully modeled these complex relation-ships [10], [11].\nDespite these advances, several challenges remain. Al-though large-scale labeled ECG/PPG datasets exist [12], [13], [14] heterogeneity in data quality and physiological variability across patients can degrade model generalizability. Meanwhile, foundation models have emerged in biosignal re-search [15], [16], where large neural networks are pre-trained on vast amounts of (often unlabeled) data and then fine-tuned for specific tasks. Importantly, the rich temporal and spectral diversity of EEG signals enables transformer-based encoders to learn robust and generalizable representations that can effectively transferred to other biosignals [17], [18].\nIn this context, a crucial question arises: Can knowledge learned from Electroencephalogram (EEG) waveforms transfer effectively to other biosignals, such as ECG and PPG, for tasks such as BP estimation? Although EEG signals originate from neural activity, they share core time-series characteristics with ECG/PPG, potentially enabling cross-biosignal feature transfer [17], [19]. To our knowledge, this work is the first to experimentally validate an EEG-based foundation model for cuffless BP prediction using knowledge transfer from EEG to ECG and PPG without requiring additional large-scale biosignal-specific pre-trainings. This initial investigation lays the groundwork for future research, wherein a dedicated ECG/PPG foundation model could be developed by further fine-tuning the pre-trained EEG model on extensive ECG data.\nAfter demonstrating the EEG-to-ECG/PPG knowledge transfer, a second critical challenge to enable wearability is minimizing the computational requirements. Wearables have strong constraints on computational resources. In this context, quantization techniques are necessary to reduce memory footprint and inference latency [20]. Thanks to their ability to compress floating-point weights to lower-precision integer representations, quantization is a key ingredient to complement the development of foundation models for wear-ables.\nIn this paper, we demonstrate a cross-biosignal transfer learning approach where a transformer model, pre-trained only on EEG, is fine-tuned for BP estimation from ECG and PPG waveforms. In particular, no additional large-scale pre-trainings on ECG/PPG were required. We extensively evaluate this method on the MIMIC-III and VitalDB datasets, examining the trade-offs of various fine-tuning strategies, including frozen vs. unfrozen backbones. Furthermore, we incorporate dynamic INT8 quantization to reduce the model size by over 3.5\u00d7, enabling feasible deployment on edge devices.\nIn summary, the contribution of this paper is as follows:\n\u2022 We show that a large transformer model pre-trained only on EEG can be successfully adapted to estimate BP from ECG and PPG signals by relying solely on an additional fine-tuning, opening new avenues for cross-biosignal foundation models.\n\u2022 We compare frozen vs. unfrozen transformer backbones and training from scratch vs. pre-trained weights, quan-tifying their impact on convergence speed, predictive accuracy, and computational cost.\n\u2022 Our empirical results on MIMIC-III and VitalDB achieve near state-of-the-art accuracy for diastolic BP, with a mean absolute error of 1.57 mmHg, and surpass the accuracy of prior works for systolic BP, with a mean absolute error of 2.72 mmHg (1.5 \u00d7 smaller than SoA).\n\u2022 We apply dynamic INT8 quantization to reduce the model size by over 3.5\u00d7 (from 13.73 MB to 3.83 MB) with negligible performance loss, enabling resource-efficient inference for real-time BP monitoring."}, {"title": "II. RELATED WORK", "content": "BP estimation from ECG and PPG waveforms has received significant attention due to its potential for continuous, unob-trusive monitoring. Earlier work relied on classical machine learning with handcrafted features, but deep learning meth-ods have since emerged as more robust alternatives. Convolu-tional or recurrent architectures designed for ECG/PPG have shown strong performance, including ResUNet with self-attention [11], U-Net variants [21], and hybrid Convolutional Neural Network (CNN)-Recurrent Neural Network (RNN) models [22]. These architectures often outperform traditional feature-engineering approaches, particularly when both ECG and PPG signals are used [22].\nNevertheless, many existing methods train solely on ECG/PPG data, which, while plentiful [13], [14], [12], often exhibit significant variability in signal quality and patient-specific characteristics. This variability poses challenges for achieving robust generalization across populations. Recent work has explored transfer learning to overcome these issues; for example, Yang et al. [17] studied the transfer of EEG knowledge to ECG classification tasks, achieving improved performance and reduced training costs. Joshi et al. [18] also explored the transfer of EEG knowledge using a deep knowl-edge distillation framework to enhance single-lead ECG-based sleep staging. However, these studies have largely focused on within-modality or narrow domain adaptations, leaving open the broader question of whether an EEG-based foundation model can serve as a versatile starting point for generalized biosignal analysis.\nEEG has become an attractive candidate for pre-training large models not only because of the availability of large-scale EEG repositories [23] but also due to its rich multi-channel, temporal, and spectral dynamics [24]. While many time-series modalities (for example, voice) also exhibit rich temporal structure, EEG, ECG, and PPG share common physiological origins and similar noise characteristics, which facilitate the transfer of temporal pattern recognition capa-bilities. In other words, our hypothesis is that the under-lying statistical properties and multi-dimensional dynamics in EEG make it particularly well-suited for learning robust representations that can be effectively adapted to ECG/PPG tasks. Our work is the first to validate the feasibility of fine-tuning a transformer-based model initially trained on EEG (CEReBrO [15]) for arterial BP estimation using ECG and PPG data.\nBeyond accuracy, real-world deployment of BP estima-tion models calls for efficient inference. Traditional deep networks can be computationally expensive, motivating re-cent interest in quantization and other compression tech-niques [20]. Few studies have combined large-scale pre-training with post-training quantization for BP monitoring. Hence, our method integrates these two aspects: leveraging a potent EEG-based foundation model and applying quanti-zation for a compact, high-accuracy cuffless BP solution."}, {"title": "III. METHODOLOGY", "content": "This section describes our approach for estimating BP from ECG and PPG waveforms using a large EEG-based foundation model. We first detail how we adapt and fine-tune the CEReBrO architecture for BP prediction, then describe our post-training quantization steps.\nOur method builds on the CEREBRO transformer-encoder [15], originally pre-trained on a large EEG dataset (TUEG [23]). CEReBrO employs a tokenization scheme that splits time-series signals into non-overlapping patches and projects them into a latent space. Alternating self-attention blocks then process these tokens by focusing on intra-channel (temporal) correlations and inter-channel (spatial) relation-ships. This design efficiently captures both local and long-range dependencies in multi-channel biosignals. Although CEReBrO was trained on EEG data, its attention-based encoder can generalize to other biosignals sharing similar temporal structures. To adapt CEReBrO for BP estimation from ECG and PPG, we make the following modifications:\n\u2022 We feed ECG and PPG signals as two input channels, each sampled at 125,Hz and shaped into 10-second segments (2 \u00d7 1250).\n\u2022 We replace the original classification head with a single fully connected layer (MLP) that outputs two values: SBP and DBP.\nCEReBrO is then also available in three sizes-small (3.58M parameters), medium (39.95M parameters), and large (85.15M parameters).\nWe then explore two fine-tuning strategies:\n\u2022 Frozen Backbone: All transformer layers except for the first input-embedding layer and the final MLP head are frozen. This preserves most EEG-based representations while allowing partial adaptation to ECG/PPG.\n\u2022 Unfrozen Backbone: All transformer layers are un-frozen to allow deeper domain alignment, albeit with a risk of forgetting learned EEG features.\nTo measure the benefit of leveraging a pre-trained EEG en-coder, we compare fine-tuning against training from scratch (i.e., random initialization). In each setting, we train models of three different sizes (small, medium, large) for 100 epochs and extend unfrozen-backbone runs to 200 epochs to assess longer-term convergence. We use Xavier Initialization [25] when training from scratch. Performance is evaluated on the MIMIC-III and VitalDB datasets in terms of MAE, SD, and coefficient of determination (R2), as well as clinical stan-dards (British Hypertension Society (BHS) and Association for the Advancement of Medical Instrumentation (AAMI))."}, {"title": "B. Quantization", "content": "We apply post-training quantization to our fine-tuned mod-els to enable real-time deployment on resource-constrained devices. This step reduces the memory footprint and infer-ence latency while preserving clinically relevant accuracy.\nWe use PyTorch's FX Graph Mode Quantization pipeline [26] to insert quantization and dequantization opera-tions systematically. Quantization is widely employed to map floating-point (32-bit) values to lower numerical precision, typically to 8-bit integers. The range of a floating-point value, denoted by xfp, is defined as follows: $[x_{min}, x_{max}]$.\nBased on this, two characteristic values can be defined, which are essential for the quantization process: Scale $\\Delta$, which determines the step size (real-valued), while Zero-point $z$, which is an integer offset whose primary function is to ensure that the zero is mapped onto an integer. In this work, we specifically adopt two types of quantization:\n\u2022 Symmetric Quantization for weights (common when weight distributions are roughly zero-mean).\n\u2022 Asymmetric Quantization for activations (typical when ReLU shifts values positively).\nFor symmetric quantization, we have the following charac-teristic values:\n$\\Delta = \\frac{max(|x_{min}|, |x_{max}|)}{2^{b}-1}, z=0$\nBased on these values, forward quantization is done using this equation:\n$x_{int} = clip(round(\\frac{x_{fp}}{\\Delta}), -2^{b-1}, 2^{b-1} \u2013 1)$.\nAnd for asymmetric quantization the characteristic values can be calculated in the following way, where b is the number of bits:\n$\\Delta = \\frac{x_{max}-x_{min}}{2^{b}-1}, z = \\lfloor - \\frac{x_{min}}{\\Delta} +0.5 \\rfloor$.\nWhen $\\Delta$ and $z$ are determined, the forward quantization step is the following:\n$x_{int} = clip(round(\\frac{x_{fp}}{\\Delta}+ z), 0, 2^{b} \u2013 1)$,\nwhere clip(, 0, 2b \u2013 1) ensures $x_{int}$ to stay in the range [0, 2b -1] [27].\nQuantization typically involves three stages: (1) calibra-tion, where representative data is passed through the model to collect scaling statistics; (2) conversion, transforming the floating-point model into a quantized version; and (3) exe-cution, running inference with reduced-precision operations.\nWe explore both static quantization [28], which precom-putes scaling and zero points via a calibration dataset, and dynamic quantization [29], which calculates them on-the-fly, eliminating the calibration phase. While static quantization can offer speed benefits if the input distribution is stable, dynamic quantization is often more flexible for variable-length or varying data distributions and avoids the need for extra calibration data.\nOur target precision is INT8, balancing memory savings and model fidelity. We evaluate symmetric quantization for weights and asymmetric for activations (shifted by ReLU). Different observers\u2014MinMaxObserver, MovingAverageMin-MaxObserver, and HistogramObserver-estimate the range, each trading off complexity against robustness. We also employ per-channel quantization for ECG/PPG inputs, giving each signal channel a separate scale and zero point.\nOur experiments reveal that dynamic per-channel quan-tization with symmetric weights yields an optimal model size, computational speed, and accuracy trade-off. Detailed results of these experiments are presented in Section IV. This approach is critical for enabling continuous, on-device BP estimation, where both memory and energy constraints are strict."}, {"title": "IV. EXPERIMENTAL RESULTS", "content": "This section presents a comprehensive evaluation of our approach on two widely used public datasets, MIMIC-III and VitalDB, accessed through the pre-processed PulseDB resource [30]. After describing these datasets and their inte-gration in PulseDB, we introduce the evaluation metrics used for both predictive and clinical quality. We then discuss the fine-tuning experiments, focusing on how frozen/unfrozen backbones and extended epochs influence performance. Fi-nally, we assess the impact of quantization, highlighting both accuracy and practical gains.\nPulseDB aggregates and cleans segments derived from both MIMIC-III and VitalDB. It provides 10-second win-dows of synchronized ECG, PPG, and Arterial Blood Pres-sure (ABP) signals, downsampled to 125 Hz. A total of 4,941 records are extracted from MIMIC-III and 3,458 from VitalDB [30]. By leveraging PulseDB, we work with consistent data splits and standardized preprocessing.\n\u2022 MIMIC-III [13], collected from around 30,000 inten-sive care unit (ICU) patients MIMIC-III includes time-series of ECG, PPG, and ABP measurements at 125 Hz. PulseDB extracts high-quality 10-second windows to form our training and evaluation splits.\n\u2022 VitalDB [14] contains synchronized recordings from 6,153 subjects, originally sampled at 500 Hz. We down-sampled these signals to 125 Hz to match MIMIC-III, ensuring uniform sampling rates.\nUnless otherwise noted, each dataset (MIMIC-III portion and VitalDB portion within PulseDB) is randomly divided into 80% training, 10% validation, and 10% testing. This setup allows us to compare performance across two distinct clinical data sources under consistent preprocessing.\nWe employ three primary statistical metrics to assess the predictive accuracy of our BP estimation models, along with two clinical standards that gauge practical viability. Let Error = BPtarget - BPestimated be the difference between the ground-truth BP and the model prediction. We report the MAE, which highlights how significant the prediction errors are on average. SD, which captures the spread or consistency of the errors. And the coefficient of determination (R2) measures how well the model fits the observed data. These metrics reveal both the average error magnitude and the overall fit.\n\u2022 BHS: Graded A-D based on the percentage of pre-dictions falling within 5, 10, and 15 mmHg of ground truth [31]. Grade A requires at least 60% of errors <5 mmHg, 85% \u2264 10 mmHg, and 95% \u2264 15 mmHg.\n\u2022 AAMI: Considers a model valid if its mean bias is within \u00b15 mmHg and the SD of errors is below 8 mmHg [32].\nWe evaluated our fine-tuning approach under varying settings (1):(1) Frozen vs. Unfrozen backbones, (2) Small- /Medium/Large model sizes, and (3) 100 vs. 200 training epochs. For comparison, we also trained all model sizes from scratch to quantify the benefit of leveraging a pre-trained EEG foundation.\nTable II consolidates all key results for experiments utiliz-ing 100 and 200 epochs. As shown, across all three model sizes (S, M, L), using an unfrozen backbone consistently yields better MAE and SD values than freezing it. On MIMIC-III, the large (L) model achieves the lowest MAE (1.72 mmHg for DBP and 2.93 mmHg for SBP) and highest R2 (0.94 for DBP, 0.96 for SBP) at 100 epochs. On VitalDB, fine-tuning likewise improves accuracy, with the large model reaching an MAE of 2.39 mmHg for DBP and 3.77 mmHg for SBP at 100 epochs. Notably, these models often satisfy AAMI standards and achieve BHS Grade A or B.\nBy contrast, models trained from scratch require more epochs to converge and exhibit higher MAE and SD. For instance, on MIMIC-III, the large model trained from scratch attains an MAE of 2.23 mmHg (DBP) and 3.71 mmHg (SBP), compared to 1.72 mmHg and 2.93 mmHg for the fine-tuned version-demonstrating how leveraging a pre-trained backbone reduces error and speeds convergence.\nTo examine whether additional training refines the model further, we extended the unfrozen fine-tuning runs to 200 epochs. The medium and large models on MIMIC-III in-crease R2 above 0.94 for DBP and 0.96 for SBP, corroborat-ing the advantages of longer training. On VitalDB, the large model's MAE drops to 1.92 mmHg (DBP) and 3.14 mmHg (SBP), also improving R2 to 0.92 and 0.93, respectively. Depending on clinical requirements and computational bud-get, these incremental gains may be justified-particularly in offline training where slight improvements can enhance overall reliability.\nTable II displays the BHS grades and AAMI standard compliance for all 100-epoch runs. Fine-tuning typically achieves BHS Grade A or B for both DBP and SBP, and meets the AAMI criteria of \u00b15 mmHg mean error and < 8 mmHg SD. Notably, the large CEReBrO model meets Grade A for VitalDB in both DBP and SBP under unfrozen fine-tuning, indicating near-clinical reliability.\nOverall, these results demonstrate that unfrozen fine-tuning of a pre-trained EEG foundation model yields the best trade-off among accuracy, robustness, and training efficiency across two significant datasets. More importantly, these find-ings confirm that a pre-trained EEG transformer can robustly adapt to ECG/PPG-based BP estimation, reducing errors while meeting rigorous clinical standards."}, {"title": "D. Quantization Performance", "content": "We evaluate static vs. dynamic INT8 quantization (Sec-tion III-B) on our best-fine-tuned models (unfrozen, 200 epochs), examining the size-accuracy trade-off.\nAs shown in Table III, dynamic per-channel quantization with symmetric weights yields the highest R\u00b2 for both DBP and SBP across MIMIC-III and VitalDB, closely matching the unquantized baseline. In particular, the large model's DBP R2 only drops from 0.9479 to 0.9476 on MIMIC-III, a negligible difference in performance.\nAlthough static quantization yields similar compression ratios, Table IV reveals a negligible difference in final model size compared to dynamic quantization while exhibiting a slightly lower R2 in practice, which is shown in Table III. Additionally, static quantization requires a separate calibra-tion step that can complicate deployment.\nTable IV highlights a reduction factor of approximately 3.5-3.9x across all model sizes. The smallest model shrinks to 3.85 MB, enabling truly resource-limited scenarios. Mean-while, the large model is compressed to around 83 MB yet preserves top-tier predictive performance while also being suitable for embedded deployment on devices with suitable flash sizes. The quantized models also meet AAMI standards and achieve BHS Grade A on both datasets, indicating min-imal performance degradation compared to the unquantized baseline."}, {"title": "E. Comparison to SOTA", "content": "Table V compares our work to State-of-the-art (SOA). Our proposed method demonstrates a clear performance advantage over existing state-of-the-art approaches on both the VitalDB and MIMIC-III datasets. On the VitalDB dataset, our model achieves a DBP MAE of 1.92 mmHg and an SBP MAE of 3.14 mmHg. These results represent a re-duction of approximately 35% in DBP error and 32% in SBP error compared to the ResUNet+Attention approach by Jamil et al. [11], which reported MAEs of 2.95 mmHg and 4.64 mmHg for DBP and SBP respectively. Further-more, our model outperforms other recent methods such as CiGNN [33], rU-Net [34], and Fusion+Attention [35], where the latter reported even higher errors (3.76 mmHg for DBP and 5.32 mmHg for SBP). Our method achieves a DBP MAE of 1.57 mmHg and an SBP MAE of 2.72 mmHg on the MIMIC-III dataset. Notably, while the ResUNet+Attention method by Jamil et al. [11] produced a slightly lower DBP error of 1.13 mmHg, its SBP error was significantly higher at 4.55 mmHg, making our SBP performance nearly 40% better. Moreover, when compared to the hybrid ResNet-LSTM approach by Paviglianiti et al. [22], which reported errors of 2.23 mmHg (DBP) and 4.12 mmHg (SBP), our method demonstrates improvements of approximately 29% and 34% for DBP and SBP respectively. The performance gains over additional methods such as GWO-GBRT [36] and Conv-LSTM [37] further underscore the robustness of our approach. These quantitative improvements confirm that our EEG-based Foundation BioSignal design not only rivals but, in many respects, surpasses the current state-of-the-art while also offering enhanced scalability and feasibility for edge deployment."}, {"title": "F. Discussion", "content": "Our findings confirm the hypothesis that it is possible to leverage pre-trained EEG representations to enable accurate, cuffless blood pressure monitoring from ECG and PPG signals. By fine-tuning a large transformer-based backbone originally trained on EEG, we achieve low error rates that align with clinical benchmarks such as the BHS grading sys-tem and AAMI standards. Despite these encouraging results, several areas warrant deeper exploration and refinement.\nFirst, data heterogeneity remains a significant concern. Although we validated our approach on MIMIC-III and VitalDB, these datasets exhibit variations in patient demo-graphics, data quality, and clinical conditions that may not fully capture the breadth of real-world scenarios. Extending the model to broader populations or leveraging domain-adaptation techniques could bolster robustness across di-verse settings. Moreover, while our EEG-to-ECG/PPG trans-fer highlights that time-series features learned from brain activity can generalize to cardiovascular signals, a more granular examination of which latent representations transfer most effectively and whether additional modalities might further enhance performance-could inform future multi-modal foundation models.\nSecond, our work demonstrates that quantization cuts model size and computational demands with minimal ac-curacy loss, thereby opening a viable path for embedded or wearable devices. However, real-time inference on resource-constrained hardware introduces additional factors such as on-device latency, battery constraints, and environmental variability. Evaluating our quantized model on ultra-low-power microcontrollers remains essential for future devel-opments towards fully wearable deployments. Techniques such as structured pruning or model distillation may further optimize the trade-off between model capacity and energy consumption.\nFinally, although we meet clinical standards under con-trolled conditions, truly continuous monitoring in daily life entails challenges like motion artifacts, intermittent signal dropouts, and inconsistent sensor placements. Advanced ar-tifact minimization strategies [38] and sensor fusion with inertial measurement units [19] may mitigate these real-world confounders. In tandem with demographic or patient-specific calibration, such approaches could help ensure that cuffless BP estimation remains reliable over prolonged usage. These directions illuminate how cross-biosignal transfer, combined with robust compression techniques, can evolve into a clinically meaningful framework for unobtrusive, continuous blood pressure monitoring."}, {"title": "V. CONCLUSION", "content": "In this work, we demonstrated that a large transformer-based foundation model, originally trained on EEG, can be successfully adapted to estimate blood pressure from ECG and PPG with near-clinical accuracy. Using the CEReBrO model [15] as our base, we achieved MAE as low as 1.57 mmHg (DBP) and 2.72 mmHg (SBP) on the MIMIC-III dataset, and 1.92 mmHg (DBP) and 3.14 mmHg (SBP) on VitalDB. These results fulfill critical benchmarks such as the BHS Grade A and the AAMI guidelines, reinforcing the clinical viability of cross-biosignal knowledge transfer.\nBeyond raw accuracy, we showed that post-training quanti-zation substantially reduces the model footprint with minimal performance degradation. Dynamic quantization compressed the largest model from over 300 MB to approximately 80 MB an almost 3.8\u00d7 reduction\u2014while preserving MAE and R2 scores. This compression is vital for on-device, real-time BP monitoring in energy-constrained wearable systems, enabling more frequent and unobtrusive cardiovascular health assessments compared to traditional cuff-based devices.\nOur findings underscore the promise of foundation mod-els in biosignal processing and illustrate how quantization fosters practical deployment in low-resource or portable settings. Importantly, this work lays the groundwork for future research wherein the EEG-based foundation model not only serves as an effective tool for cross-biosignal transfer but also as a basis for developing dedicated ECG/PPG foundation models. Future work will explore additional com-pression methods such as pruning and distillation, integration of demographic factors for improved fairness, and further validation on embedded platforms to handle real-world arti-facts and motion conditions. By combining efficient cross-biosignal transfer and hardware-friendly optimizations, this approach offers a path toward continuous, real-time blood pressure monitoring that can enhance patient care and clinical decision-making."}]}