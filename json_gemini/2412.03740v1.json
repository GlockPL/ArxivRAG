{"title": "Exploring the Role of AI-Powered Chatbots for Teens and Young Adults with ASD or Social Anxiety", "authors": ["Dilan Mian"], "abstract": "The world can be a complex and difficult place to navigate. People with High-Functioning Autistic Spectrum Disorder as well as general social ineptitude often face navigation challenges that individuals of other demographics simply do not themselves. This can become even more pronounced with people of that specific group when they are in their teenage years and early adulthood (that being the usual age range of college students). When they are at such a vulnerable age, they can be far more susceptible to the struggles of becoming comfortable and content with social interactions as well as having strong relationships (outside their immediate family). Concerning this, the rapid emergence of artificial intelligence chatbots has led to many of them being used to benefit people of different ages and demographics with easy accessibility. With this, if there is anything that people with High-Functioning ASD and social ineptitude want when it comes to guidance towards self-improvement, surely easy accessibility would be one. What are the potential benefits and limitations of using a Mindstudio AI-powered chatbot to provide mental health support for teens and young adults with the aforementioned conditions? What could be done with a tool like this to help those individuals navigate ethical dilemmas within different social environments to reduce existing social tensions? This paper addresses these queries and offers insights to inform future discussions on the subject.", "sections": [{"title": "Introduction", "content": "To dive deeper into this subject, there are crucial facts and points to be made first. Let us investigate what it means to have a high-functioning autism spectrum disorder and social ineptitude. An understanding of this will substantially affect the validity of the arguments in the following sections.\nIn the realm of medical academia, the concept of \u201cHigh-Functioning Autism\u201d is by no means an official term used for diagnosis. It is a colloquial phrase that various people use in everyday conversations. It refers to individuals who have been diagnosed with autism; however, there is a key distinction. They are distinguished from others in this condition by being able to talk, read, write, and perform essential life skills such as putting on clothes and having meals independently (WebMD, 2023).\nAutistic Spectrum Disorder (ASD) is a developmental disorder of the brain with varying signs, symptoms, and effects. People who consistently exhibit the signs of this disorder are then put into the \"autistic spectrum\" (WebMD, 2023). Some of these people are significantly disabled while others are milder. The Intelligence Quota test scores of this vast group of people can vary widely.\nFor several years, individuals with severe symptoms alone have been diagnosed as autistic. Only approximately 30 years ago in the 1990s were milder symptoms of this disorder understood by people with them being known as having \u201cAsperger's Syndrome\u201d in the medical field (WebMD, 2023). The term itself first emerged in the 1940s after research by psychologist Hans Asperger; however, in 1994, it became an official term for diagnoses.\nThe use of this term would change in a colloquial sense however with the phrase \"High- Functioning Autism\u201d in recent years. Some individuals who are not medically educated may still use the phrase Asperger's. This may be due to a lack of understanding of the spectrum or an older diagnosis of Asperger's syndrome before what took place in 2013. In that year, the American Psychiatric Association (APA) placed all diagnosed individuals with symptoms related to autism into a single group, the aforementioned ASD (WebMD, 2023).\nIn particular, people with High-Functioning Autism are known to face challenges with communication and social interaction. Social cues/etiquette and the ability to form friendships do not naturally register with them. Social scenarios can quickly become overwhelmingly angsty, leading to a shutdown (WebMD, 2023). Eye contact with people during conversations and small talk can also be a struggle for them as well.\nSome of these people can maintain their jobs, while others may not. This is largely contingent on their experience and situation. For job interviews in particular, they could very well have all the education and skills they need, but their lack of experience with long, healthy conversations could lead to an uphill battle in getting a desired position (WebMD, 2023).\nIt is plausible that those reading this paper have heard of or even experienced social anxiety/ineptitude themselves. Even though over 60% of people have felt social anxiety at some point (Science of People, 2023), it would be beneficial to make sure that there is no ambiguity or undermining as to what this condition entails; therefore, the means and ways it occurs will be clarified in the following analysis.\nIndividuals with social ineptitude face significant difficulties in socialization, carrying conversations, and interacting with people comfortably. Similar to people with ASD, this demographic commonly misunderstands social cues and feels tense in public settings. The idea of making new friends/colleagues or being humiliated in a social environment can be a source of dread (Autism Parenting Magazine, 2024).\nOther notable signs of someone struggling with social anxiety are people they converse with not understanding the jokes they have uttered or even being offended by them. These same individuals usually have issues with preventing awkward silences in casual conversations; there is a fear that others may intentionally avoid conversing with them, and they overthink or regret what they say in conversations (Science of People, 2023). A few of them are comfortable in crowds but as much as individual interactions.\nThese are the general signs and effects of ASD and social anxiety on people at large; however, what about teenagers and young adults? Generally, they have the same symptoms as most adults, but there are unique characteristics that this specific demographic may have that others with\nthese conditions may not have. Teens are particularly vulnerable to various stresses and socio- environmental tribulations owing to the effects of puberty (Buchanan, Romer, Wray-Lake, and Butler-Barnes, 2023). They have a much higher chance of experiencing anxiety, panic disorders, and depression. This applies to individuals who find themselves in scenarios that engender their deepest fears.\nWhen we look at the common situations that young adults experience in college and early professional life, we can conclude that they are very prone to depression, anxiety, and panic (Asif, Mudassar, Shahzad, Raouf, and Pervaiz, 2020). This is often due to the societal and financial pressures that come with obtaining a desired college education and job in a competitive market.\nThis only considers the experiences of the general public in these age groups. If we factor in the added layer of people with ASD and social/anxiety, the situation would plausibly be far more concerning.\nNow that we have come to understand what ASD and social ineptitude entail, as well as the common psychological issues of teenagers and young adults, what are the implications, both beneficial and harmful of using an AI chatbot via Mindstudio.ai designed to provide ethical social advice and mental support to specific people with these conditions?\nIn the following sections, it should be noted that young adults and teenagers with ASD and/or social ineptitude are referred to as the \u201ctargeted group\u201d or \u201cgroup in question\u201d for ease."}, {"title": "Related Works", "content": "The name of the application is powered by Mindstudio.ai and has the title \u201cA-Way-Out.ai\u201d. In terms of works this could be compared to, the most prominent would be the following:\nChatGPT -\nTo begin, below are points of ChatGPT's strengths as an application:\n\u2022\tChatGPT is a very popular online general-purpose chatbot.\n\u2022\tIt has a general framework that can understand and respond to different queries without specialized content.\n\u2022\tThis application has a diverse conversational style to handle different subjects.\n\u2022\tIt naturally communicates in a casual and informal tone of speech for general queries.\n\u2022\tIt can adapt responses depending on user input.\nNow below are some of the drawbacks of ChatGPT in this regard:\n\u2022\tChatGPT can dispense functional responses, but it lacks deep specialization in any one specific area, including nuanced social and ethical advice.\n\u2022\tIt does not have a substantially deep contextual understanding of specific conditions that a professional psychologist or social worker likely would.\n\u2022\tThere is no upfront confirmation of professional psychologists or social workers having worked on and reviewed the information conveyed by ChatGPT regarding mental health support and social skills advice to the targeted group.\n\u2022\tThere are image generation/visual aids but there is a paywall of 20 USD per month.\n\u2022\tWhile both the PC and mobile app versions of ChatGPT have text-to-speech for free for the convenience of the users, it has limitations. Both versions can replay the text-to- speech reading of prompts, but they cannot pause it and rewind or fast-forward it at their convenience. Users also cannot download the audio file to keep if they wish. This could be useful if the company powering the app was to shut down operations or if the app itself was to be removed from public use or even if the user lives in a location with an unstable internet connection.\n\u2022\tChatGPT does not provide upfront reminders that the group in question should prioritize real-life counseling rather than relying on a chatbot.\nAutism Support \u2013 Social Skills \u2013\nThis is a created GPT which is available on ChatGPT. It seems to have been constructed by a company known as \u201cLevanshealth\u201d. Below are points of its positive capabilities:\n\u2022\tIt's tailored to provide support individuals with autism, focusing on social skills.\n\u2022\tIt may have common social scenarios relevant to people with autism.\n\u2022\tIt can issue structured scenario-based guidance to teach social skills.\n\u2022\tIt emphasizes being supportive and educational, using a gentle and understanding tone.\n\u2022\tSimplified language is utilized to ensure clarity and ease of understanding for people with ASD.\nNow below are some noteworthy criticisms.\n\u2022\tThis GPT does not necessarily do much to distinguish itself from just utilizing ChatGPT. To be more specific, it uses Dall-E to generate images that can help understand socially beneficial things like proper posture and more. There does not seem to be anything stopping regular ChatGPT from doing the same thing if someone were to ask for it.\n\u2022\tThere is no clarity as to whether the chatbot was approved of or at least recommended by professional psychologists or social workers during the chatbot's development phase.\n\u2022\tThere is no easily accessible information on who did recommend it such as a LinkedIn profile containing their contact information and qualifications.\n\u2022\tSimilar to a general-purpose chatbot, it may not be deeply personalized or cover a vast range of ethical dilemmas and mental health support comprehensively in a way that a real social worker or psychologist would.\n\u2022\tIt does not clearly state that the user should prioritize seeking in-person counseling rather than only relying on the application.\nWellness Buddy -\nThis is an AI application targeting Kenyan university students with a focus on mental health support, especially for anxiety and depression, in low-resource settings (Ogamba, Gitonga,\nMuriithi, Olukuru, & Sevilla, 2023). It has a primary goal to address the stigma around mental health in Kenya. Below are some positive functionalities for this app:\n\u2022\tIt has a functioning chatbot that is tailored to anxiety and depression, with added integration into the Kenyan cultural context.\n\u2022\tThe app has a focus on usability and engagement with users.\n\u2022\tIt has a strong reliance on transfer learning via neural networks.\nNow below are some potential shortcomings of the application:\n\u2022\tIt has a somewhat limited scope of mental health concerns addressed.\n\u2022\tThe app has a potential overfitting of models.\nMIT Study-Based Application\nThis is an application focused on mental health support and improving social interactions through AI chatbots, specifically with empathetic engagement (Shen, DiPaola, Ali, Sap, Park, & Breazeal, 2024). Beneath are some of its positive traits:\n\u2022\tIt uses generative AI with leveraged models like GPT for user interactions and addressing certain needs.\n\u2022\tIt highlights concerns around transparency, accuracy, and the risk of the overuse of AI for mental health support.\n\u2022\tThe study includes methods for assessing effectiveness with user feedback and professional evaluation, with an emphasis on ethical considerations in design.\nBelow are some differences between this app and my proposed Mindstudio application:\n\u2022\tThe Mindstudio app will be tailored for specifically adolescents and college-age people with high-functioning ASD or social anxiety, focusing on their unique challenges in socialization and ethical decision-making. The MIT application in contrast broadly explores empathy in AI interactions without targeting a specific demographic and their unique needs.\n\u2022\tIn terms of customization and features, the Mindstudio app will have personalized role- playing scenarios and accessibility features such as downloadable text-to-speech or a menu-driven interface tailored to user needs. In contrast, the MIT application is focused on controlled crowd-sourced studies to measure empathy levels and examine qualitative feedback.\n\u2022\tRegarding technological integration, \u201cA-Way-Out.ai\u201d will be built with a practical implementation to focus on tools like menu nodes, workflows, and visual aids. Meanwhile, the MIT app leverages fine-tuned AI models for story retrieval and generation to evaluate user reactions.\nSaarthi\nThis is an AI chatbot focused on delivering Cognitive Behavioral Therapy (CBT) and remote health monitoring for people with anxiety and depression. It is a general mental health tool\ntargeted at a broad audience seeking accessible, evidence-based treatments (Rani, Vishnoi, & Mishra, 2023). Below are some of its strengths:\n\u2022\tSaarthi has therapeutic techniques and information through Natural Language Processing.\n\u2022\tIt integrates CBT to address mental health concerns.\n\u2022\tThere is a community platform included to connect with peers and professionals.\n\u2022\tNatural Language Processing is used for personalized support.\nNow below are some of the differences between Saarthi and \u201cA-Way-Out.ai\u201d:\n\u2022\tRegarding Methodology, Saarthi is focused on applying machine learning techniques like N-Gram, TF-IDF, and sentiment analysis for text generation. It also relies on Rasa for advanced conversational abilities. \u201cA-Way-Out.ai\u201d in contrast will use a node-based interface from Mindstudio for non-programming-based functionality. It will have GPT- based responses with downloadable text-to-speech and image generation. The effectiveness of the Mindstudio app will be evaluated with professional social worker or counselor feedback.\n\u2022\tSaarthi aims to improve CBT, addressing stigma and financial limits. The application acknowledges that AI cannot replace human counseling, particularly for mental health support. Meanwhile, the Mindstudio app will highlight the importance of real-world counseling and clarify this in the app interface. It also seeks to prevent excessive reliance by promoting limits on usage and encouraging real-life interactions.\n\u2022\tWhile Saarthi has limited personalization for niche demographics like the group in question and its general focus may dilute its effectiveness for certain mental health issues, \u201cA-Way-Out.ai\u201d is wholly targeted towards the targeted group.\nMental Health Support Chatbot (Gupta et al.)\nThis AI application is designed for generalized mental health support addressing anxiety, depression, and stress with Natural Language Processing. It is generally aimed at people worldwide without emphasis on specific and niche groups (Gupta, Joshi, Jain, & Garg, 2023). Below are some of the strengths and positives of the project:\n\u2022\tThis app uses deep learning and natural language processing to process user inputs.\n\u2022\tIt has pre-filled responses and tracks user mood.\n\u2022\tTensorFlow and Keras frameworks are utilized for software architecture.\n\u2022\tThe implementation of the project uses diary logging, sentiment analysis, and habit tracking.\nBelow are some key differences between the general Mental Health Support Chatbot mentioned above and \u201cA-Way-Out.ai\u201d:\n\u2022\tGupta's chatbot is constructed from scratch with Python coding language that emphasizes natural language processing. The Mindstudio app on the other hand will use a no-code platform, using pre-designed workflows and nodes for quicker, easier-to-understand development.\n\u2022\tWhile the Gupta chatbot emphasizes conversational empathy and emotional support across broad mental health categories, the Mindstudio app is focused on certain tools for social skills, ethical advice, and roleplay scenarios for people with ASD or social anxiety of a particular age range.\n\u2022\tThe Gupta application garners feedback through NLP performance metrics rather than professional input/feedback from a social worker, counselor, or psychologist, which is the evaluation methodology of the Mindstudio app.\n\u2022\tGupta's chatbot briefly addresses ethical concerns but there is a notable lack of professional oversight, raising questions about how a real counselor, social worker, or psychologist would feel about the app's capabilities for its intended purpose.\nMy Mental Pocket \u2013\nThis is a chatbot project aimed largely at university students and faculty with an overall focus on handling depression and managing emotional health (Park, Kim, 2023). Below are some of the key differences between it and the Mindstudio chatbot:\n\u2022\tWhile My Mental Pocket is focused on university students and staff broadly for mental health support, the Mindstudio chatbot is focused on adolescents and young adults with High-Functioning ASD and/or social anxiety. The Mindstudio project addresses mental health concerns and social skills advice, with a focus on ethical decision-making and interpersonal interactions for that particular group of individuals.\n\u2022\tFeatures such as \u201cPocky\u201d, an AI chatbot, and wellness games are used to diagnose depression indicators like cognitive control with My Mental Pocket. On the other hand, \u201cA-Way-Out.ai\u201d will use tools such as conversation roleplays, visual aids, and ethical decision-making frameworks tailored to ASD-related social struggles. Accessibility will be emphasized with the Mindstudio app, with user-friendly features like image generation. Another key one is downloadable text-to-speech files that have convenient fast-forward and rewind tools.\n\u2022\tWhile the scope of My Mental Pocket is broad, it potentially may dilute the depth of guidance for specific user demographics like ASD individuals. It also has heavy reliance on theoretical models which may limit practical insights for real-world challenges. It also lacks the professional input or review of people like counselors or social workers.\nJennifer Chatbot -\nThe Jennifer chatbot was designed as an information portal during the COVID-19 pandemic to provide credible, easily accessible, and timely updates about the virus and public health measures (Xiao, Liao, Zhou, Grandison, & Li, 2023). Below are some of its attributes and capabilities:\n\u2022\tIt was built with an expert-sourcing framework with over 150 scientists and health professionals.\n\u2022\tIt has extensive manual QA curation, with regular updates based on expert reviews and changing scientific knowledge.\n\u2022\tThe app provides fact-checked, evidence-based responses to user queries with automated updates for certain categories like statistics.\n\u2022\tIt emphasizes interaction focused on reducing misinformation and gaining trust through transparency.\nBelow are some of its drawbacks and differences from \u201cA-Way-Out.ai\u201d:\n\u2022\tIt is resource-intensive due to reliance on experts for content creation and validation.\n\u2022\tUpdates for public policy and evolving disease knowledge depend on manual efforts.\n\u2022\tIts focus is solely on COVID-19-related information, with less adaptability for broad mental health concerns or user ethical concerns.\n\u2022\tJennifer can give general answers but lacks social skills support or customized roleplay scenarios."}, {"title": "Proposed Solution", "content": "There is a plethora of ways that this potential application could distinguish itself positively from the other applications and studies mentioned above:\n\u2022\tThis proposed application will have the professional input of at least one social worker who specializes in mental health support for the targeted group and coaches them on social etiquette during the app's development process.\n\u2022\tThe approved responses used as input will address complex social and ethical dilemmas from the group in question while being reviewed by at least one qualified social worker, counselor, or psychologist. The different tools the app provides will be laid out in an organized, interactable menu.\n\u2022\tIt will be catered specifically to the common interests and experiences of teenagers and young adults (late teens to early 20s). The chatbot will be tailored to their particular needs and challenges.\n\u2022\tThis chatbot will include accessibility options such as text responses and visual aids. Audio-based interaction can be very calming compared to simple text readings for stressed users, especially if the AI allows for a realistic speaking voice. Visual aids are also an easy way to engage users who may not necessarily want to just read. Imagine someone from the group in question looking for visual examples of good posture when having conversations. It is important to note that ChatGPT presents a paywall of USD 20 per month to use image generation capabilities. This also applies to all the GPTs independently constructed there as well. Individuals of the targeted group (especially those in high school from impoverished environments) may not be able to afford such services. The text-to-speech responses can be paused, rewound, fast-forwarded, and downloaded at the convenience of the user. Downloading them in particular could be very useful if the application were to be removed or cease to operate for any given reason. If the user lives in a location with unpredictable internet service, simply being\nable to quickly download audio responses with valuable counseling-related information presents the benefit of accommodation.\n\u2022\tPersonalized roleplaying scenarios for ethical decision-making will be prioritized with clear choices for female or male roleplays depending on the user's preferences. The chatbot will give the option for roleplaying as a classmate, teacher, co-worker, or workplace boss.\n\u2022\tThe application will clarify upfront in each provided tool that is accessible via the main menu that the app is not meant to replace real social workers or psychologists, rather they should be sought first as a priority.\n\u2022\tMindstudio requires the user to create an account by manually entering their email address and creating a new password. If they doubt the privacy and security of Mindstudio regarding their customized password, they can use their Gmail account and respective authentication from that avenue instead. These are the methods of protecting the accounts of people using and especially those creating applications via Mindstudio.\n\u2022\tData usage on Mindstudio involves the developer having a set budget in their workplace for Al applications being run by the company. This budget can be used by the users to interact with the created chatbots. Each AI-generated response uses tokens which all cost money, therefore subtracting from the workplace budget. The developer has the freedom to place limits as to how much they can use of the workplace budget before they can be granted access to the application again.\n\u2022\tAt least one professional and qualified social worker or counselor will be required to review the application during the design phase to give tips on how to make the Mindstudio chatbot as effective as possible. The same individual(s) will be asked to review the app once more after all proposed features have been implemented to design the overall impact the project has for its intended purpose."}, {"title": "Methodology of Building the App", "content": "Mindstudio Architecture - The chatbot has been constructed in Mindstudio as stated before. It has an interactable main menu (image below) for engagement and clarity of what it can do for the user. Mindstudio utilizes nodes in its automation to perform different functions without programming. This added to the ease of the app's creation. The menu has a starting node which uses a menu tool to connect to different portal nodes (Figure 1). These portal nodes known as \"Jump\u201d are linked to different workflows that contain the user-machine interaction process for different purposes. These purposes include advice related to ethical decision-making, social skills support, mental health, resources (i.e. organizations that work with the group in question for mental health and social skills support), visual aids (for images used to demonstrate helpful advice), and conversation roleplays.\nThe Ethical Choices, Social Skills, Resources, Mental Health, and Conversation Roleplay sections have a very similar workflow. The defining difference between them is that each workflow deals with respective concerns that are made clear in the opening prompts of all of them. The Ethical Choices workflow for example contains a starting node to begin it, the user is given the ability to use a variable called for this part of the app \u201cecvar\u201d (Figure 3). This variable\nis used in a User Input node and referenced in a succeeding Generate Text node that represents the introductory text of the workflow.\nThe introductory text is about the purpose of this branch of the app with kind words to express its focus on discussing the ethical dilemmas of adolescents from the targeted group. The text is then followed by a reference to the \u201cecvar\u201d mentioned before as this will then take the user input as the response to the app's initial prompt (Figure 4). Below that section labeled as \u201cPrompt\u201d is the Settings which include how the AI-generated response should be stored, in this case, it is saved as the variable \u201cecResponse\" to be used in the succeeding Display Content node.\nBeneath that, there are the Model Settings (Figure 5). These include which LLM model should be used to generate the response to the user prompt (this case being GPT-40 Mini) along with the Temperature and maximum tokens allowed to be used for the response. It ends with a reference to the workflow this prompt is intended for.\nFollowing that the Text to Speech node allows for the AI-generated response to have the implied text-to-speech functionality. The Mindstudio interface has the ecResponse variable stored as the text to be used by the node with its output into the Display Content node being represented by the \"ethnicAudio\u201d variable. Then beneath that there is the specific text-to-speech model being used for this functionality which in this instance is from OpenAI (Figure 6). Lastly, there is the voice option, which includes a variety of voices of different pitches. Shimmer was the one chosen here.\nThe most important node after this is the Display Content one. This node facilitates the text-to- speech to be presented to the user with the AI-generated text response in full display. The node accomplishes this with HTML syntax for the establishment of the ethicAudio variable's contents mentioned earlier with the printed content of ecResponse viewable along with it (Figure 7).\nThe final node seen above is the Chat node which terminates the initial interaction process allowing for the user to respond with another prompt in a loop of sorts.\nThis is the workflow architecture for most of the sections of the application. The only exception would be the Visual Aids section. The workflow for that section utilizes a node called Generate Image rather than the Text to Speech one. Ask it can be seen in the image below; this node uses the variable representing the response of the chatbot (in this workflow it is called visualImg) to the user prompt to generate an image rather than text-to-speech. The image is stored in the variable displayImg and beneath that includes the generation model settings. This includes which model is to be utilized, which for this workflow would be OpenAI's Dall-E 3 (Figure 8). Then the aspect ratio and pixelization quality are chosen (in this instance 1024x1024 and Standard were used respectively).\nFollowing that is the Display Content node shows the image using a different syntax than the text-to-speech node (Figure 9). Mindstudio in this case uses an exclamation mark and various brackets and braces to convey the generated image on screen with the displayImg variable. The last section of the node's content has the visualImg displaying generated text describing the image.\nAnother important section of the application is the roleplay conversations section mentioned before with both female and male character options (depending on the user's preferences). These two branches utilize female and male-sounding voices respectively. In Figure 10, the workflow for this section has a menu node which first has a prompt of what text the menu will use to introduce itself. The Menu node then has two options referencing the two respective branches to take the user to.\nIn both the male and female workflow branches, they have the same logic and structure as the Ethical Choices workflow except the variable names (i.e. user input and generated responses) are distinguished for the former two workflows.\nEvaluation Plan \u2013 The overall effectiveness of the chatbot once it is implemented will be evaluated via interviews with at least one qualified and professional social worker or counselor"}, {"title": "The Benefits", "content": "Table 1: This is the summary of all the benefits of the application\nSocial Skills Development Support - If the engineers behind an AI chatbot could conjure one that was capable of understanding the deepest and most pressing issues for the targeted group while being seen as credibly safe to use, it would, by all means, be an up-mountain battle (uphill would be an understatement). For example, if a government-funded academic institution like a university or high school were to utilize this chatbot, it is unlikely that it would even happen unless the data for the AI system were reviewed or made by professional psychiatrists, especially those who have studied the many psychological struggles of teenage life. In this way, the chatbot could be trustworthy and free of the dangers of inaccurate information (more on that in the limitations section). If this chatbot functions to have the most accurate information it can, many would undoubtedly be drawn to it as a source of information on navigating uncomfortable social\ninteractions. Thus, whenever the targeted group utilizes a chatbot with this degree of knowledge and specialty, it is plausible they would receive the type of advice that could free them from many of the psychological trappings of everyday interactions. As a simple example, let us say that there is a 14-year-old boy in high school named Richard, who has ASD. Richard goes to the library to study for a test and he notices how his peers have a copy of the textbook they all (including Richard) needed for the test while he did not. If Richard had not been in a situation where he needed to ask to borrow something from people he was unacquainted with, it could have been a source of confusion or doubt. If only Richard had access to the chatbot on his phone, he would explain his circumstances and what he was looking for. The chatbot would swiftly give him helpful and professional-based advice on handling the situation ethically, one that is most conducive to social cohesion or bridge-building. One more example could be a college student named Ria who struggles with social anxiety as a product of her introversion. If Ria was meeting peers in her class for the first time, and was curious about their likes/dislikes, but did not know how to ask about them in a way that would be socially acceptable, this would likely lead to self- doubt or increased discomfort. If Ria asked a simple question about the hobbies of a peer, but the phrase included somewhat intrusive wording, it is possible it would not bode well. Her peer may be passively offended and cease attempts to continue conversing with her. Had Ria been given access to a chatbot on her phone or laptop that could quickly tell her how to convey questions in a socially appropriate manner and also respond in a fitting way to passive-aggressive behavior, she could have either avoided that situation altogether or found a way to repair it when it went south. The natural conclusion of all this is that an AI-powered chatbot that has been professionally reviewed by psychologists or social workers from appropriate organizations could be a very easy tool for advising on dealing with confusing or troubling social situations.\nUnderstanding Social Cues and Communication \u2013 Building from the previous point, a chatbot with appropriate guidance for the group in question could help them understand the mindset and perspective of the people around them. If someone with ASD were about to start their first day of high school, a fitting AI system could reasonably give them rapid-fire information on understanding the social expectations and environment they would likely have to meet and interact with. The person from the targeted group can learn the most essential facts about how their peers might treat someone like them and some helpful tips to interact with them in a way that is conducive to social cohesion given all the ambiguities they have internally. Through continuous practice with real-world interactions and scenarios, they could gradually become accustomed to applying the essential lessons from the AI chatbot and then increase their knowledge of the nuances of how people converse and express themselves. From the reverse angle, if a student in a high school or college who is not part of the group in question wanted to learn more about the feelings of one of their classmates who are in the targeted group, then the AI chatbot could supply quick and professional information on that front. AI systems such as this can open the door to both unity and social bonding. There is also the positive outcome that through the targeted group using the app for this purpose, they can easily blend into the point where people outside the targeted group (especially those without ASD of any variant) will see just how human and how similar we all are. The fact that we all have our own struggles and challenges in which our inner strengths come to light. People can have different trials and tribulations, but they do not deem one group as socially or intellectually inferior to another.\nEase Of Access \u2013 It is no mystery that Artificial Intelligence has few if any, limits in terms of access to anyone with an Internet signal. Judging by the fact that the majority of the targeted group has the aptitude to use computers, search engines, and other tools that would provide access to the plethora of AI systems online, logically, they would not have a challenge in finding an AI system that can help them deal with their day-to-day dilemmas. According to professional resources, it seems very likely that with the widespread empire, which is the digital age, AI applications could have a much quicker reach than in-person psychologists and doctors (Ettman, and Galea, 2023). Imagine people amongst the group in question who happen to live in financially challenged regions of the globe such as South Asia, much of Sub-Saharan Africa, Eastern Europe, the Middle East, or even in lower-class neighborhoods in the Western Hemisphere. The reach of people in the targeted group includes those who come from families primarily concerned with maintaining basic necessities rather than having the privilege of affording expensive mental health support services. The establishment of a professionally reviewed app that could provide mental health advice as well as ethical tips for social dilemmas would be a major convenience for people from the group in question who lack the same economic privileges as the people who initially made the app in the first place. For many years, access to mental healthcare was mostly out of reach for people of the lower class and impoverished environments (Hodgkinson, Godoy, Beers, and Lewin, 2017). There is evidence that impoverishment can facilitate the fracturing of one's own mental health. When we apply that to the experiences of the targeted group, there is a lot of damage that can be done. People in the group in question from a lower-class neighborhood or region can have unique experiences compared to their neighbors, with their own mental health challenges and needs. We should keep in mind that impoverished neighborhoods can be correlated with higher crime rates (Toronto Security Company, 2023). This includes gang activities, a recipe for a hostile and stressful environment (National Gang Center, 2020). The targeted group would likely be much more prone to anxiety and alienation in a place where their safety is at risk when in or outside their house along with the unfriendly gang-like activity in their area. Adding to the fact that the person's parents are likely unable to afford high-standard therapists or social workers to regularly give them ethical advice specific to their conditions/needs, there is a lot of room for their livelihood to fall apart. If the specially designed Mindstudio app were made widely available for them for free via the internet, it would be a very convenient way to supply them with the temporary, helpful, and arguably necessary material for dealing with mental woes or social anxiety (the potential absence of privacy and confidentiality will be discussed in the harms section). There is also a threat to the people of the targeted group being conditioned by gang culture in these types of neighborhoods to where it becomes normal or even admirable. Gang culture, in general, can be very attractive to youth (National Gang Center, 2020). This is again keeping in mind that the group in question tends to lack knowledge of social cues and norms. Therefore, the Mindstudio chatbot could act as a temporary means of deterring them from an unethical pathway with quick accessibility.\nSupport with Addressing Trauma \u2013 Pain is universal. If pain is not a part of a living being's day- to-day antics, it is not truly living. People from the targeted group are no exception to this. Studies have shown that the targeted group, especially those with ASD, is more vulnerable to trauma due to their limited self-regulation and sense-making (Buuren, Hoekert, and Sizoo, 2021).\nThere is even evidence that people in the group in question have much higher exposure to violence, parental divorce, traumatic loss, mental illness, and substance abuse in their families (Buuren, Hoekert, and Sizoo, 2021). Trauma and stress have always found their footing through these means. An increased reign of anxiety over one's mind, especially with the targeted group, can lead to increased introversion and alienation from the surrounding external world. These conditions will eventually result in an increased aversion to interacting with people in regular environments (i.e. school, college, or work). There is no doubt that a psychologist or social worker could do great work here. What if they were to collaborate with the developer to make a Mindstudio application that takes professional input data on how to help people of the targeted group who have dealt with trauma? If a 19-year-old girl named Shalini with ASD experiences psychological abuse from one of her parents due to the use of illegal substances, which then leads to divorce, her ability to think positively and open-mindedly could be substantially hindered. The aforementioned Al system could furnish tips on how to approach the situation rationally and allow gradual healing. The sheer speed of the app with modern APIs can swiftly help her heal with temporary advice before she is able to consult an in-person social worker or psychologist, which of course should be prioritized. It should be remembered that if the information is deemed unsatisfactory by her, depending on the severity of her symptoms, the AI prompt will also provide contact information to professional organizations designed to aid people like her.\nOpen To Improvement and Innovation \u2013 When humans and machines can be made"}]}