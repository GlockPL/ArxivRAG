{"title": "XQSV: A Structurally Variable Network to Imitate Human Play in Xiangqi", "authors": ["Chenliang Zhou"], "abstract": "In this paper, we introduce an innovative deep learning architecture, termed Xiangqi Structurally Variable (XQSV), designed to emulate the behavioral patterns of human players in Xiangqi, or Chinese Chess. The unique attribute of XQSV is its capacity to alter its structural configuration dynamically, optimizing performance for the task based on the particular subset of data on which it is trained. We have incorporated several design improvements to significantly enhance the network's predictive accuracy, including a local illegal move filter, an Elo range partitioning, a sequential one-dimensional input, and a simulation of imperfect memory capacity. Empirical evaluations reveal that XQSV attains a predictive accuracy of approximately 40%, with its performance peaking within the trained Elo range. This indicates the model's success in mimicking the play behavior of individuals within that specific range. A three-terminal Turing Test was employed to demonstrate that the XQSV model imitates human behavior more accurately than conventional Xiangqi engines, rendering it indistinguishable from actual human opponents. Given the inherent nondeterminism in human gameplay, we propose two supplementary relaxed evaluation metrics. To our knowledge, XQSV represents the first model to mimic Xiangqi players.", "sections": [{"title": "I. INTRODUCTION AND BACKGROUND", "content": "The synergy between AI and board games has been particularly fruitful, leading to the development of powerful game engines that surpass human experts [1]. More recently, deep reinforcement learning has emerged as a powerful method including DeepMind's AlphaGo [2] and AlphaZero [3]\u2013[5] demonstrating superhuman performance in chess and Shogi, learning solely from game rules without supervised learning. Other notable engines include the chess engine TDLEAF [6], based on temporal difference learning, the Go engine based on deep convolutional neural networks [7], and the poker engine DeepStack, based on recursive reasoning [8]."}, {"title": "B. Imitate Human in Board Games", "content": "Many studies focus on developing board game engines that optimize winning probability, but less attention is given to engines that imitate human behavior. Robust game performance does not equate to human-like play. For example, the Monte-Carlo Tree Search algorithm is inadequate for simulating human-like gameplay [9]. Research shows that both Stockfish and Leela (an open-source AlphaZero implementation) struggle to predict human moves accurately, even when calibrated to match human performance [10]. This discrepancy arises from fundamental differences between machines and humans, such as machines' vast memory and processing capabilities. Another study found that AlphaZero prefers piece activity over material, favoring riskier, more aggressive actions [11].\nCreating an engine that performs in a human-like manner has multiple applications. It could serve as an independent game engine, offering a more enjoyable user experience, or assist human players with strategic advice. Playing alongside a human-oriented engine helps human players learn and collaborate more effectively. Additionally, such an engine can provide a robust evaluation function integrated into other game engines that prioritize optimal moves (e.g., [12], [13]).\nThe common approach to emulate human-like behavior involves predicting human actions based on game history (e.g., [12] for chess; [13] for Go; [14] for video games). Maia [10], based on AlphaZero [5], models human actions in chess in a detailed way. It is trained on human chess games to predict moves of players at specific skill levels, achieving 50% prediction accuracy, surpassing Stockfish's 37% and Leela's 42%."}, {"title": "C. Xiangqi Engines", "content": "Xiangqi (Chinese chess) is a popular board game in China with a rich history dating back to the Warring States period (c. 475 B.C.). It simulates a battle on the chessboard, where players act as commanders to checkmate the opponent's king. Xiangqi offers a vast strategy space and a large game tree complexity ($10^{150}$, [15]), exceeding that of Chess ($10^{123}$, [16]). This complexity makes it a valuable platform for AI research, modeling reasoning and planning processes.\nMost Xiangqi engines use reinforcement learning with self-play and game tree search along with other techniques [17]\u2013[21]. Despite extensive research, few studies focus on imitating human behavior in Xiangqi. Our paper is the first to address this gap, aiming to establish a benchmark and encourage further research in this field."}, {"title": "D. Contributions", "content": "The major contributions of our work are 1. Xiangqi Structurally Variable (XQSV), the pioneering neural network model adept at imitating the behaviors of human players in Xiangqi achieving an accuracy of 40% and 2. an innovative scheme of variable network structure suitable for datasets that can be intuitively partitioned according to specific criteria."}, {"title": "II. XQSV DESIGN APPROACH", "content": "In order to imitate human behavior in Xiangqi, we formulate this problem as a classification problem over all Xiangqi moves. In this section we highlight some innovative and essential design choices."}, {"title": "A. Data Preprocessing", "content": "The raw Xiangqi game data is retrieved from PlayOK.com in standard algebraic notation (SAN) format. The data pre-processing workflow is as follows: partition Elo range, extract moves, group, map moves to numbers, break the moves into records, and finally, randomize the records. This section elaborates on the three critical preprocessing steps: partition Elo range, sequential 1D input, and imperfect memory capacity."}, {"title": "1) Elo Range Partitioning", "content": "The Elo scoring system [22] serves as a sophisticated metric for quantifying the relative skill levels of players in strategy-based games, including chess and Xiangqi. The variance observed within our dataset is, in part, attributable to the diverse skill levels of the players, ranging from novices to experts. Accordingly, partitioning the data based on Elo scores serves to mitigate this variability, consequently enhancing the model's ability to accurately learn human behavior.\nAfter acquiring the raw dataset, we partitioned it into nine distinct bins based on the Elo scores of the participants, ranging from (1000,1100] to (1900, 2000]. This segmentation strategy stems from the inherent challenge posed by our predictive task, which is characterized by the substantial variability in players' abilities and performances juxtaposed against the deterministic predictions generated by our model. Ideally, the model's predictions would align with the moves most commonly executed by players. Nonetheless, if the dataset amalgamates players from a broad spectrum of skill levels, only a minority may exhibit the move deemed optimal by the model, thereby diminishing prediction accuracy."}, {"title": "2) Sequential ID Input", "content": "Numerous existing game engines utilize data input in the form of two-dimensional chessboard configurations, a method potentially favored for its efficiency in representing game history (e.g., [3], [10]). Contrarily, our XQSV anticipates a linear input in the form a sequential series of moves. This design decision is more closely aligned with the cognitive processing patterns observed in humans. Through the conduct of interviews with 30 Xiangqi players, we discovered that a predominant majority (28 out of 30) rely on the recollection of previous moves rather than the visual configurations of the chessboard to deliberate over the future moves. Given that XQSV's objective is to predict human movement, we hypothesize that it is beneficial if it operates more similarly to a human by considering the game history as a sequence of moves rather than chessboard configurations.\nIn the ablation study delineated in Section III-B, empirical evidence supports this hypothesis; the adoption of a one-dimensional move sequence as input, in lieu of two-dimensional chessboard configurations, markedly enhances the model's predictive accuracy. Such findings suggest that for the purpose of predicting human movement within the game, a model that operates in a manner congruent with human cognitive patterns yields superior performance."}, {"title": "3) Imperfect Memory Capacity", "content": "Contrary to most existing game engines which operate under the assumption of a perfect memory that provides complete access to the entire game history, our XQSV model is restricted to a limited memory capacity, denoted as m. This means it can only consider at most m moves from the past. This design decision has been adopted not only for computational efficiency, but more crucially, to better simulate the human cognitive process. It reflects the reality that during a game of Xiangqi, human players are typically unable to recall the complete history of the game owing to the inherent limitations of human brain capacity.\nFormally, suppose a game history H consists of a sequence of l moves $H = (M_1, M_2, ..., M_l)$, then we will produce l training samples (x, y) from G by going through each step while maintaining the number of history steps under m:\n$(x = M_{max(1,i-m)...i-1}, y = M_i), i = 1, ..., l,$ (1)\nwhere $M_{j...k}$ is the subsequence $(M_j, M_{j+1},..., M_k)$.\nOne might argue that artificially limiting the machine's memory is unnecessary; instead, we could supply the complete game history and allow the model to autonomously discern which move to discard. For example, long short-term memory (LSTM) [23] or gated recurrent unit (GRU) [24] have forget gates integrated into their network for this purpose. However, we note that the effective functioning of these forget gates relies upon a successful learning of the underlying data structure, which may not always be the case, particularly considering the complexity of our prediction task."}, {"title": "B. Structurally Variable RNN", "content": "XQSV employs sequential modeling and is constructed utilizing a recurrent neural network (RNN) followed by fully connected layers (FC). The network calculates the probability distribution for each move and selects the move with the highest probability. Numerous chess engines are based on convolutional neural network (CNN) or residual neural network (ResNet) (e.g., [3], [10]. However, given that our input consists of a sequence of 1D data, we chose to utilize RNN as the primary architecture. Our preliminary experiments indicated that a coarsely tuned LSTM [23] could already achieve a prediction accuracy comparable to that of CNN or ResNet. Furthermore, RNN assumes dependencies among elements within the input sequence, a condition which is applicable to sequential Xiangqi moves and makes the model better resemble the cognitive process of human brain.\nA notable innovation of XQSV resides in its variable network structure. As previously mentioned in Section II-A1, we partitioned the dataset according to different Elo ranges to minimize intra-group variation. For each Elo range, a distinctive architecture is required as players at various skill levels are likely to exhibit divergent thought processes and behaviors. For instance, it is suggested that advanced players possess a superior capability to reconstruct a chessboard situation, attributed to their capacity to encode the chessboard into larger perceptual chunks using more abstract relations [25]. Consequently, to imitate these players, a model with a more complex structure may be required, a hypothesis reaffirmed by our experiments in III-A. Thus, we introduced variability into the network structure, allowing it to adapt autonomously to players at different skill levels. In this setting, the model must not only learn to optimize network weights but also, crucially, determine the most efficacious network architecture at a higher level.\nSeveral control elements, designated as structure variables (SVs), were established to manipulate the variable structure of the network. Among these, the memory capacity m determines the number of past moves the model can consider, with different Elo ranges potentially requiring different optimal m values. This structurally variable framework can be generalized to accommodate other tasks, particularly when there is an intrinsic partitioning of the training dataset that can influence the output."}, {"title": "C. Locally Illegal Move Filter", "content": "One challenge in the move prediction task resides in the large search space. After carefully considering the rules of Xiangqi for each game piece, we successfully condensed the label space to a minimal set of 755 moves. These moves are referred to as globally legal moves.\nTo further facilitate the prediction task, we observed that these globally legal moves are not always legal given a specific board configuration. Thus, we introduce the concept of a locally legal move, which imposes stricter conditions than a global legal move: a move must not only abide by piece movement rules but also be legally executable given a specific board arrangement. For example, if a piece occupies a certain position, all moves moving the piece from a different position are deemed locally illicit. Upon examining the output of XQSV in pilot experiments, we observed that certain moves with high probabilities in the output were, in fact, not locally legal. Such prediction errors can be circumvented through the implementation of a locally illegal move filter. We report the improvement brought by this filter in Section III-B."}, {"title": "III. EXPERIMENT AND EVALUATION", "content": ""}, {"title": "A. Training XQSV on six Elo ranges", "content": "We illustrate the effectiveness, specifically the adaptability, of XQSV through its training on six Elo ranges: (1200, 1300], (1300, 1400], . . ., (1700, 1800]. Given the computational constraints and that there are ten structural variables, an exhaustive search for the optimal network structure was not feasible. Instead, we implemented a five-phase search, with each phase refining the outcome of the preceding phase. During each phase, we sought the optimal values for two structural variables, in the order presented in . For the remaining structural variables, we either utilized their optimal values found in previous phases, or, if they have not been searched, the default values as shown in the table. The best network structures identified for each Elo range are reported. We also evaluated each model on different Elo ranges in addition to the one it was trained on and visualized the results\nclearly shows that as the skill level of the player increases, a more complex network is required to imitate their gameplay. This is reflected through the larger memory capacity, a more advanced RNN layer (LSTM being more complex than GRU), reduced regularization, increased RNN hidden dimension, and a higher number of fully connected layers. This aligns with findings from cognitive psychology research (e.g., [25]) which suggests that more advanced Xiangqi players exhibit different cognitive strategies and tend to have superior recall capabilities (hence the larger m) and the ability to abstract the chessboard into cognitive chunks (necessitating a more complex network).\ndemonstrates that when tested on game records across various Elo ranges, all XQSVs achieve peak accuracy in the Elo range on which they were trained. As the Elo range deviates from this, the prediction accuracy typically declines. This clearly indicates that XQSV has effectively learned the specific playing patterns and characteristics of the Elo range it was trained on. Interestingly, we note that the decline in accuracy is less pronounced for XQSVs trained on higher Elo ranges. This could be interpreted as a reflection of advanced players' ability to emulate novice strategies, but not vice versa. In other words, certain moves may occur across all skill levels, while more sophisticated, nuanced moves are exclusive to advanced game records."}, {"title": "B. Ablation Study", "content": "In this section, we perform an ablation study to examine the effectiveness of the four key design decisions in XQSV archi-tecture, which were proposed to improve prediction accuracy in Sections II-A and II-C:\n\u2022 Elo range partitioning. To ablate this component, we rerun the experiment trained on the whole dataset of game records without Elo range partitioning.\n\u2022 Sequential 1D input. To ablate this component, we encode the game history as a sequence of 2D chessboard situations. Instead of RNN, we use a ResNet built upon CNN to process the 2D input followed by fully connected layers to output the predicted move. This is the approach taken in most of the chess engines (e.g., [3], [5], [10], [26]). For a fair comparison, we also turn this network into a structurally variable one. Most SVs in Table I not related to RNN are reusable, and in addition, we introduce two SVs for the ResNet, namely the number of convolutional blocks and the number of channels in convolutional layers.\n\u2022 Imperfect memory capacity. To ablate this component, we rerun the experiments on the game records without truncation on the moves in the far past.\n\u2022 Locally illegal move filter. To ablate this component, we rerun the experiment but removing the locally illegal move filter module.\nWhen rerunning the experiments, we perform the same multi-phase adapting and training procedure described in Section III-A; we train for the same number of epochs until convergence at the end of training. The result is reported.\nWe can observe from the table that all of the four design decisions above are essential to our model and removing any of them caused significant decrease in the prediction accuracy. Additionally, it is worth noting that the computational time increased substantially when employing an unlimited memory capacity."}, {"title": "C. Turing Test", "content": "We also performed a three-terminal Turing Test [27] to determine whether human Xiangqi players can distinguish our XQSV from a true human opponent. We invited 30 Xiangqi players with Elo scores between 1200-1500. Each participant was asked to remotely play nine Xiangqi games with three different opponents in random order consisting of the following:\n\u2022 three games with a human opponent randomly selected from the remaining 29 participants;\n\u2022 three games with our XQSV trained at Elo range 1300-1400; and\n\u2022 as a control group, three games with a mobile App called Chinese Chess downloaded from Apple's App Store.\nThe participants were aware of the above rules, and knew that which set of three games was played with the same opponent. However, they were not informed about the identities of the human and machine opponents (playing remotely allowed to hide this information from them). After each game, the participants were asked to identify which of the three opponents they believed to be human (thereby indicating the remaining two as machines)\nIn this setup, each of the three opponents received a total of 30 \u00d7 3 = 90 guesses of being human. Among these, both the human player and our XQSV were identified as human 35 times (38.89%), while the Chinese Chess App 20 times (22.22%). Note that a higher percentage score means that the opponent behaves more like a human.\nFrom the results, we see that 77.78% of guesses correctly identified the Chinese Chess App as a computer program, indicating that it, and potentially other popular Xiangqi game engines, did not perform well in imitating human moves and could provide a different gaming experience from that of playing with genuine human opponents; In contrast, our XQSV model demonstrated superior proficiency in imitating human moves, outperforming the Chinese Chess App by a moderate margin. Over the course of these 90 Xiangqi games, our XQSV model was indistinguishable from the actual human opponent, indicating that XQSV can successfully imitate human moves in Xiangqi."}, {"title": "IV. DETERMINISTIC MODEL VS. NON-DETERMINISTIC HUMAN PLAY", "content": "It is important to note that a significant challenge in this prediction task stems from the non-deterministic nature of human play, in contrast to the deterministic nature of our model: In the face of identical chessboard situations, multiple moves could be selected by various players, or even by the same player at different times, but our model will always output the same move. While we have attempted to address this issue through data preprocessing by partitioning the data according to Elo scores, this approach cannot eliminate the non-determinism inherent to the game\nTo account for this, recall that before predicting a single move, our model already computes a probability distribution over all possible moves. To incorporate the non-determinism of human-play, we can randomize the prediction by stochastically outputting each move according to the computed probability. Given the inherent non-determinism of human play, there are inevitable \u201cunfair misses", "top p probability accuracy\", where a prediction is considered correct if it is among the minimal set S of moves with the highest probabilities such that the sum of their probabilities exceeds p. In other words, we form a set of good moves by ordering all moves from highest to lowest probability, then sequentially add moves to this set until the cumulative probability exceeds the threshold p. This approach allows for a more accurate evaluation of model performance. For a given threshold p, the size of the set S is dynamically adjusted": "If there is a single correct move M, its probability will likely be high, and the set S will consist solely of this move. Conversely, if there are multiple equally good moves, each will likely have a smaller individual probability, and S will contain all of these moves. This flexible approach more accurately captures the intricacies and complexities of Xiangqi gameplay.\nWe reevaluate the model trained on Elo range 1200-1300 on the testing dataset with Elo range 1200-1300. In, we report the top k accuracy and top p probability accuracy for different k and p. Notice that the top 1 accuracy and the top 0 probability accuracy are just the ordinary (strictest) accuracy we have used in previous sections.\nAs expected, as k and p increase, the prediction accuracy generally increases as well. This is because as we expand the pool of acceptable predictions (by including more top moves or those that have a higher cumulative probability). If we make a reasonable assumption that given a chessboard situation, there are about five moves that could be considered good by human, then the accuracy of XQSV adapted to Elo range 1200-1300 is 62.30%."}, {"title": "V. DISCUSSION AND CONCLUSION", "content": "One limitation of our work lies in the discord between non-deterministic human behavior and deterministic model prediction. We attempted to counterbalance this by partitioning the data according to Elo ranges and applying a relaxed accuracy metric. However, the model could potentially benefit from other effective methodologies. For instance, predicting a player's playing style or personal traits - either via a separate or integrated network, or other methods - could further facilitate the prediction of human moves.\nTo conclude, in this paper we devised an innovative model termed XQSV (Xiangqi Structurally Variable), which employs a recurrent neural network (RNN) and dynamically alters its network structure to optimally represent Xiangqi players across different proficiency levels. We further introduced four key design approaches that substantially enhanced the predictive accuracy of our model: a local illegal move filter, an Elo range partitioning, a sequential 1D input, and an imperfect memory capacity. Evaluated on Xiangqi game data, XQSV demonstrated an approximate accuracy of 40%, which, under justifiable relaxation of evaluation metrics, increased to around 60%. Through extensive experimentation, we showed the ability of XQSV to effectively imitate human players. To the best of our knowledge, XQSV is the first model specialized in replicating human behaviour in Xiangqi, and we hope to establish a valuable benchmark for future endeavours in this research field."}]}