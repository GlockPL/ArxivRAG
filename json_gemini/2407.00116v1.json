{"title": "Generative AI for Synthetic Data Across Multiple Medical Modalities: A Systematic Review of Recent Developments and Challenges", "authors": ["Mahmoud Ibrahim", "Yasmina Al Khalil", "Sina Amirrajab", "Chang Sun", "Marcel Breeuwer", "Josien Pluim", "Bart Elen", "G\u00f6khan Ertaylan", "Michel Dumontier"], "abstract": "This paper presents a comprehensive systematic review of generative models (GANs, VAEs, DMs, and LLMs) used to synthesize various medical data types, including imaging (dermoscopic, mammographic, ultrasound, CT, MRI, and X-ray), text, time-series, and tabular data (EHR). Unlike previous narrowly focused reviews, our study encompasses a broad array of medical data modalities and explores various generative models. Our search strategy queries databases such as Scopus, PubMed, and ArXiv, focusing on recent works from January 2021 to November 2023, excluding reviews and perspectives. This period emphasizes recent advancements beyond GANs, which have been extensively covered previously.\nThe survey reveals insights from three key aspects: (1) Synthesis applications and purpose of synthesis, (2) generation techniques, and (3) evaluation methods. It highlights clinically valid synthesis applications, demonstrating the potential of synthetic data to tackle diverse clinical requirements. While conditional models incorporating class labels, segmentation masks and image translations are prevalent, there is a gap in utilizing prior clinical knowledge and patient-specific context, suggesting a need for more personalized synthesis approaches and emphasizing the importance of tailoring generative approaches to the unique characteristics of medical data. Additionally, there is a significant gap in using synthetic data beyond augmentation, such as for validation and evaluation of downstream medical AI models. The survey uncovers that the lack of standardized evaluation methodologies tailored to medical images is a barrier to clinical application, underscoring the need for in-depth evaluation approaches, benchmarking, and comparative studies to promote openness and collaboration.", "sections": [{"title": "1 Introduction", "content": "The advent of Artificial Intelligence (AI) and Machine Learning (ML) has revolutionized numerous fields, including healthcare. These technologies have the potential to transform medical research and clinical practice, offering new avenues for diagnosis, treatment, and patient care. However, the application of AI and ML in healthcare depends on the availability of large and high-quality datasets, with diverse modalities and acquisition properties. In many instances, such datasets are not readily available due to privacy concerns, restricted sharing policies, complex acquisition techniques, expensive annotation costs, as well as limited diversity in real world data. This has led to the emergence of synthetic data generation, a promising solution that leverages generative models to create artificial data that mimics real-world datasets.\nSynthetic data could serve various critical purposes in data science and machine learning, mainly facilitating data sharing while protecting privacy, augmenting existing datasets, and promoting fairness and equity in AI applications [1]. Generative models are computational algorithms capable of learning and capturing complex data distributions, enabling the generation of new samples that closely resemble real data. By leveraging techniques such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), Diffusion Models (DMs), and Large Language Models (LLMs), researchers can create synthetic medical data across various modalities, including imaging, text, time-series, and tabular data.\nOur survey aims to provide a holistic understanding of the applications of these generative models in generating medical synthetic data. We delve into three key aspects: the purpose of synthesis, generation techniques, and evaluation methods. We highlight the potential of synthetic data in addressing various clinical needs and identify gaps in current practices, such as the need for more personalized synthesis approaches and standardized evaluation methodologies. Moreover, we emphasize the importance of tailoring generative approaches to the unique characteristics of medical data and call for more in-depth evaluation approaches relevant to clinical applications. Our study encourages benchmarking and comparative studies to promote openness and collaboration.\nIn essence, this survey paper serves as a valuable resource for researchers and practitioners interested in leveraging generative models for synthesizing medical data. By shedding light on the current practices, potential, and challenges in the field of synthetic medical data generation, we hope to spur further research and innovation in this critical area of healthcare AI and ML.\nThe structure of this paper is further organized into different chapters. Section 2 provides an overview of the synthesis applications, generative models, and evaluation methods that are common across the different data types. The concepts explained in this section are essential to understand the detailed results in section 3, where the findings from the surveyed papers are presented and divided into four sections, each focusing on a specific type of medical data: Electronic Health Records (EHR) in section 3.1, physiological signals in section 3.2, medical images in section 3.3, and medical text in section 3.4. This organization allows for a detailed exploration of the use of generative models for each data type, providing readers with a comprehensive understanding of the current state of synthetic medical data generation. Section 4 reveal the insights and conclusions collected from the surveyed papers. Section 5 provides recommendations to be taken into account for future research, and 6 concludes the paper. The reader is referred to the table of contents for a smooth navigation of the paper."}, {"title": "1.1 Related work", "content": "Despite the growing interest in generative models for medical data synthesis, the review of existing survey papers in the field reveals a notable trend: a tendency towards narrow specialization, as seen in Fig.1. These papers often focus on a single data type, such as brain and heart imaging [2] or EHR [3], or they combine a single data type with one specific technology, like medical images with diffusion models [4], EHR with GANs [5], or Electrocardiography (ECG) with GANs [6]. Additionally, there is a subset of papers dedicated exclusively to data augmentation applications, which similarly specialize in either a single data type [7, 8] or a combination of one modality and one technology [9].\nThis pattern indicates a gap in the literature where comprehensive, multi-faceted analyses providing holistic overviews are less prevalent. In contrast, the proposed survey paper seeks to address this gap by covering a broader spectrum. It spans multiple data types, encompassing medical imaging, tabular EHRs, physiological signals, and clinical text notes. Furthermore, it explores various generative models, extending beyond GANS which have been extensively covered in literature, to include diffusion models and language models. The survey also emphasizes the aspect of conditional generation, which is not focused on in similar work. Additionally, we have considered a specific timeline for our review, consciously excluding older papers that have already been covered in various surveys. This approach aims to provide a more holistic understanding of the application of generative models in medical research, moving away from the trend of focusing on singular aspects. Such a comprehensive analysis could significantly enrich the medical field by offering insights that are potentially overlooked by more narrowly focused studies."}, {"title": "1.2 Review methods and protocol", "content": "Our review methodology and protocol aimed to address several key objectives and research questions. Firstly, we sought to explore the applications and purpose of synthesis beyond data augmentation in medical research. Additionally, we aimed to identify the latest generative models utilized for generating synthetic medical data. Lastly, we aimed to investigate the common protocols for evaluating synthetic data and the trade-offs between the different evaluation dimensions.\nOur review is scoped to cover a broad spectrum of modalities, including tabular data (specifically EHRs), physiological signals (primarily ECGs and Electroencephalography (EEGs)), clinical text notes, and a variety of medical images such as dermatoscopic images, mammographic images, Utrasound (US) scans, Computed Tomography (CT) scans, Magnetic Resonance"}, {"title": "1.3 Search results", "content": "The details of the literature screening processes according to the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) guidelines [10] are shown in Fig.2. Overall, 249 papers are included in the review, distributed over the different modalities as shown in Fig.3."}, {"title": "2 Synthesis application, generative technologies and evaluations", "content": "This section presents a strong foundational understanding of key concepts gathered from various surveyed papers concerning the overarching themes of (i) synthesis applications, (ii) generative technologies, and (iii) evaluation methodologies in medical data synthesis. The objective is to lay the groundwork by explaining fundamental concepts and approaches that are commonly encountered in the survey. This aids the reader in building the necessary background to understand the detailed and more specific findings presented in section 3. First, we discusses different synthesis applications in section 2.1, followed by an exploration of common generative models 2.2. Finally, in section 2.3, we delve into the diverse evaluation methods employed in the surveyed studies, offering a comprehensive view of the research landscape in this field.\nIn our paper, we introduce specific definitions for the terms \"data types\" and \"modalities\". We classify EHR, images, text, and signals as distinct data types. Within each data type, we define various modalities. For example, within medical images, modalities include CT, MRI, and others. Additionally, within each modality, there exist different modalities; for example, within MRI, modalities such as T1 and T2 weights are distinguished."}, {"title": "2.1 Synthesis applications and purpose of synthesis", "content": "Generative models are a powerful tool in machine learning and can be broadly categorized into two types: unconditional and conditional. Unconditional models take a random variable as input, allowing for the application of unconditional synthesis. On the other hand, conditional generative models introduce an additional layer of control by incorporating external information or context during the generation process that serve as additional guidance for the model. These can include images, text, semantic maps, class labels, attributes, and signals, as demonstrated in Fig.5. This added control allows conditional models to be used in a variety of synthesis applications specific to each data type shown in Fig.4.\nFor the EHR data type, the synthesis depends on the EHR format, which includes (i) Longitudinal EHR, consisting of medical codes from various patient visits; (ii) Aggregated EHR,"}, {"title": "2.2 Generation techniques", "content": "Our examination of various papers revealed a range of techniques utilized for generating synthetic medical data, with a primary focus on GANs [11], VAEs [12] and recent advancements in diffusion models [13] and language models. See Fig.6 for the basic working mechanisms of the different generative models.\nFirstly, we discuss the differences in how various generative models operate across different datatypes: EHR, medical images, medical text, and physiological signals. Next, we highlight notable state-of-the-art GANs frequently referenced in the literature. Following this, we explore diffusion models, including denoising diffusion probabilistic models and latent diffusion models, alongside discussions on different text embedding methods. Finally, we examine language models, concluding our"}, {"title": "2.2.1 Differences in generative models working mechanism per datatype", "content": "\u2022 Handling discrete variables: GANs, initially introduced for generating realistic continuous images, face challenges when applied to discrete data. Similarly, many diffusion models are Gaussian processes, operating in continuous spaces and not the discrete space. To address these issues, various techniques have been introduced. (Variational) autoencoders are commonly employed before GANs and diffusion models to condense high-dimensional and heterogeneous features into latent representations. Notably, some diffusion models like Tabular Denoising Diffusion Probabilistic Models (tabDDPM) [16] adopt a mixed sequence diffusion approach [17, 18], employing Gaussian diffusion for continuous variables and multinomial diffusion [19] for discrete variables. Others treat discrete variables similar to real-valued sequences but with further post-processing of"}, {"title": "2.2.2 GANS", "content": "Adversarial approaches, such as GANs, involve a generator and discriminator, trained to outperform each other, hence the term \"adversarial\". The generator network adapts its distribution and generates a new, reliable distribution, while the discriminator network learns to differentiate between real and augmented data. The work in [11] pioneered GANs for generating realistic images, particularly dealing with continuous data, often referred to as the vanilla GAN (Fig.7a). However, such models have been extended to different domains, such as audio and EEG signal generation [20, 21]. [22] proposed the Deep Convolutional GAN (DCGAN), that combines the original GAN with convolutional neural networks for better and more stable training. [23] proposed the Wasserstein GAN (WGAN), while [24] proposed the Least Squares GAN (LSGAN), to address challenges like mode collapse and vanishing gradients typically encountered in GANs (see Fig.7f). WGAN replaces binary classification with the Wasserstein distance. The training of WGAN was enhanced with the introduction of WGAN-GP in [25], which integrates a gradient penalty technique. Progressive Growing GAN (PGGAN)[26] is an extension of GAN training, ensuring stability for generators producing large, high-quality images. Traditional GANs struggle with stability when working with larger sizes, attempting to balance both structure and fine details. This challenge worsens as resolutions increase, often required for medical image generation, leading to training failures, while memory constraints on Graphics Processing Units (GPUs) further necessitate reducing batch size, introducing instability. As illustrated in Fig.7c, PGGAN addresses these"}, {"title": "2.2.3 Diffusion models", "content": "The original concept of the diffusion model, introduced by Diffusion Probabilistic Models (DPMs) [13], draws inspiration from non-equilibrium statistical physics. The key idea is to systematically and iteratively destroy structure in a data distribution through a forward diffusion process. Subsequently, the reverse diffusion process is learned and applied to restore the structure in the data.\nDDPM. The initial practical implementation of the diffusion model in the context of images was presented by [37], introducing Denoising Diffusion Probabilistic Models (DDPM). This approach destroys data by iteratively adding Gaussian noise to the image according to the Markov chain. To learn the reverse process, a deep neural network is needed to recover the data. Fig.8b illustrates the working mechanism of the DDPM. The current best practice for image diffusion models is to use U-Net [38] architectures for denoising. However, these architectures are tailored for image generation tasks, and may not be a viable option for other data types, especially when the training data is limited. Moreover, U-Net architectures struggle to retain temporal dynamic information and lack flexibility in handling varying input sequence lengths, thus proving inadequate for managing sequential information. In addressing this limitation, some studies [17] resort to Bidirectional Recurrent Neural Networks (BRNNs) implemented with either LSTM or GRU units. A significant drawback of diffusion models is that they operate sequentially on the entire image during both training and inference. Consequently, they demand substantial computational resources and time, making both the training to be slow as well generating an image after training. As a result, [39] speed up image generation by redefining the diffusion process as a non-Markovian one, which allows for skipping steps in the denoising process, without requiring all past states to be visited before the current state.\nLatent Diffusion Models- The Stable Diffusion Pipeline. To address computational inefficiencies of DDPMs, Latent Diffusion Model (LDM) [40] was introduced initially for images, which uses encoders to compress images from their original size in the pixel space into a smaller representation in the latent space, as illustrated in Fig.8a. Therefore, in latent diffusion, the diffusion process is performed on the latent representations rather than the original images (Fig.8b), allowing LDMs to model long-range dependencies within the data and enabling training on limited computational resources while retaining their quality and flexibility. Stable diffusion, a foundation model built based on LDM, introduces text conditioning to the model for additional control over the generation process and consists of three main components: (i) the VAE for compression (Fig.8a), (ii) a U-net based diffusion process in the latent space (Fig.8b), and (iii) a conditioning mechanism that embeds a prompt describing the image using a Contrastive Language-Image Pre-training (CLIP) text encoder [41] (Fig.8c). CLIP creates a numeric representation (embedding vector) of the prompt, mapping both the text and images into the same representational space, enabling comparison and similarity quantification. In addition to CLIP, other text encoders such as pre-trained T5X model [42], medBERT encoder [43], a Byte Pair Encoding (BPE) tokenizer [44], and Self-alignment pretraining for BERT (SAPBERT) [45] are commonly used in different publications to enable text conditioning of the models.\nThe Stable Diffusion model is widely utilized in recent publications, where the pre-trained foundation model is fine-tuned on various medical modalities without the need to initiate training from scratch. Moreover, the idea of latent diffusion models, which involves performing the diffusion process in the latent space, has been extended to both the EHR and signals data types. In these extensions, a low-dimensional representation of the high-dimensional features, including discrete ones, is learned using an auto encoder before the diffusion process."}, {"title": "2.2.4 Language models:", "content": "A fundamental aspect of language models is enhancing the linguistic capabilities of machines to understand the probability of sequences of words, enabling them to predict future or missing words in sentences [46]. The development of language models (shown in Fig.9) started from Statistical language models which were grounded in probability theories with a restriction to predicting the next word in a sequence based on a fixed number of previous words. However, these models face significant challenges in accurately predicting the next word due to the"}, {"title": "2.3 Evaluation", "content": "The evaluation of synthetic data is a multifaceted task, encompassing several dimensions that collectively determine the quality and usability of the synthetic data. We categorize the evaluation as utility, fidelity, diversity, qualitative assessment, clinical validation, and privacy. Each dimension presents unique challenges and considerations, and their comprehensive evaluation is crucial to ensure the effectiveness of synthetic data. In this survey, we analyze each of these evaluation approaches, aiming to provide a holistic view of the current synthetic data evaluation practices. The remaining of this section gives an overview of all evaluation categories considered in this paper, offering insights into their significance and the common metrics employed.\nEvaluation of utility asses the use of the synthetic data for specific tasks, such as providing additional data for improving a downstream medical AI model. Several settings exist in which the synthetic data can be used for a downstream task. The synthetic data can be used to fully train the downstream model(replacing the need to access real data), or to augment real training data. Moreover, the synthetic data can be used for validating or testing the models. These settings can be employed in different downstream applications such as supervised classification, prediction, supervised regressions, image segmentation, even reinforcement learning, with the specific metrics of each application.\nEvaluation of privacy is a critical factor that ensures the synthetic dataset cannot be exploited to reveal sensitive information about individuals in the original dataset. When it comes to EHR data, privacy evaluation typically includes testing the synthetic data for the following risks:\n\u2022 Membership inference risk: Risk against membership inference attack, where an adversary attempts to determine whether a specific data record was used in the training of a machine learning model.\n\u2022 Attribute inference risk: Risk against attribute inference attack, where an adversary wants to infer private attributes of individuals based on the available data or model's predictions.\n\u2022 Nearest neighbor adversarial accuracy risk: Risk that is based on the Nearest Neighbor Adversarial Accuracy (NNAA) metric [54]. This risk assesses the privacy risk of synthetic data by analyzing how closely the nearest neighbor (the most similar record) in the synthetic dataset resembles any real individual. A high similarity raises the risk of re-identification.\nResearchers usually apply Differential Privacy (DP) [55] mechanisms to mitigate privacy risks. DP is a rigorous and mathematically grounded framework designed to protect the privacy of individuals in the dataset. By introducing randomness into data queries or the data generation process, differential privacy ensures that the synthetic data doesn't compromise the privacy of any individual in the original dataset. It's often considered the gold standard for privacy protection in data analysis.\nEvaluation of fidelity assesses how well the synthetic data reflects the real-world characteristics and features of the original dataset, both at the individual sample level and across the entire data distribution. High fidelity indicates that the synthetic data closely resembles the original data in terms of appearance"}, {"title": "3 Results", "content": "In our survey, we've meticulously distinguished between various modalities within the realm of medical data: EHR, Physiological Signals, Medical Images, and Clinical Notes, even though some might consider all these modalities as part of a patient's EHR. Each of these categories represents a distinct dimension of patient health data, each contributing unique insights and challenges.\nEHR encompass a variety of formats, including longitudinal EHR, time-dependent EHR, aggregated EHR, and snapshot EHR. These different formats capture the patient's medical history over time, ranging from specific episodes of care to comprehensive summaries.\nPhysiological Signals, on the other hand, capture real-time physiological data such as ECG, EEG, and various other signals. These signals provide crucial information about a patient's physiological state and are often used in monitoring and diagnosing medical conditions.\nMedical Images are vital, and include modalities such as Ultrasound, Mammography, Dermoscopy, MRI, CT, X-Ray, O\u0421\u0422,"}, {"title": "3.1 EHR", "content": "EHRs are inherently heterogeneous, encompassing various types of data, including demographic data, medical codes assigned to diagnoses and procedures such as the International"}, {"title": "3.1.1 Generative models- Longitudinal format", "content": "Table 3 summarizes several models that generate synthetic longitudinal EHR data, emphasizing their ability to handle the high dimensionality of medical datasets, mainly discrete features, such as those including ICD codes. These models are capable of preserving temporal correlations across patient visits, with [70] additionally maintaining these correlations at the visit level. Despite their capabilities, none of the models explicitly address the patterns of missing data in their design.\nBeside GANS, VAE, DM, and LM have been utilized to generate longitudinal EHR. [70] approached the problem using a two-stage strategy. The initial stage sequentially estimates temporal patterns and expected patient state from visits, incorporating a self-attention layer and using RNNs. The subsequent stage generates data, conditioned on the expected patient state, utilizing WGAN and the previous EMR-WGAN [91] work. The model in [58] uses Wasserstein GAN with gradient penalty (WGAN-GP) training with a GRU generator to recursively generate sequences and a sequential discriminator that can simultaneously distinguish whether individual visits are real and whether the entire sequence are real. The model proposed is focused on the generation of uncommon diseases, which is particularly beneficial for downstream tasks involving these less frequent conditions. To generate uncommon diseases, the conditional vector is smoothed into a conditional matrix for all visits to avoid the disease appearing only in the first visit or in every visit due to the characteristics of RNN-based models. [71] used hierarchically factorized conditional VAE to generate discrete EHR sequences specific to medical conditions of interest\nThe models in [74] and [73] stand out by following a language model approach, with [74] using hierarchical autoregressive language model, treating EHR data as natural language sequences, predicting the probability of the presence of a potential medical code given the patient's medical history and the previous codes. This model is uniquely capable of synthesizing both discrete (medical codes) and continuous (average values of lab tests) features, with extremely high dimensional, emulating the heterogeneous character of EHRs. Moreover, it uses demographic and chronic disease phenotypes for conditional generation, which helps create balanced datasets for training downstream tasks on rare conditions. The model in [73]"}, {"title": "3.1.2 Generative models- Time-dependent format", "content": "The capacity to preserve temporal dependencies and correlations among clinical features is a critical functionality for models generating synthetic time dependent EHR data. The challenge of high-dimensional data generation is less pronounced in time-dependent than longitudinal format since the extensive data typically associated with medical codes is not utilized. The WGAN based model [75] is the exception, with the ability to generate high-dimensional, time-dependent records featuring 714 attributes. Conversely, [79], in its initial design, limited the dimensionality of variables to less than 100, potentially constraining its capacity to represent the complexity of medical data fully. Models like the ones in[77, 57, 76, 17] focus as well on accurately reflecting the heterogeneous nature of real-world EHR through a combination of static and temporal features. [76, 77, 17] are all proficient in handling the patterns of missing data, a critical aspect that [78] opts to eliminate through data imputation, potentially losing valuable information inherent in the absence of data. Iconically, [77] manages varying time-series sequence lengths.\nThe idea of combining an autoencoder with a GAN is widely used, mainly to establish a shared latent space representation encompassing mixed types of EHRs features, including both continuous and discrete-valued data, prior to the generation process. For instance, both [78] and [77] employ autoencoder networks followed by a WGAN-GP. While [78] utilizes a LSTM based recurrent autoencoder, [77] employs a sequential encoder-decoder network. Expanding upon this strategy, [79] incorporates a dual LSTM-based VAE. It then employs bilaterally coupled LSTM"}, {"title": "3.1.3 Generative models- Aggregated format", "content": "In the context of aggregated format generation for EHR data, all models demonstrate a range of capabilities, particularly in handling high-dimensional data. However, a significant limitation across all these models is their lack of consideration for missing data patterns. Additionally, they do not integrate both static features, like patient demographics, and temporal features, such as medical readings over time, in their generation process. This gap limits their ability to fully replicate the nuanced and comprehensive nature of real-world EHR data.\nBeyond the primary focus on aggregated format EHR, several models have also shown effectiveness in other EHR formats. For example, [81] have been effective with EEG and ECG data, demonstrating their ability to preserve temporal correlations and maintain the integrity of time-series patterns. Additionally, [18, 81, 84] proved to be effective in generating snapshot format data as well.\nEarly works on GANs for EHRs were centered around pro-"}, {"title": "3.1.4 Generative models- Snapshot format", "content": "As the snapshot format lack the time aspect, none of the models are designed to preserve temporal correlations within the datasets they handle. Additionally, [54] stands out as the only"}, {"title": "3.1.5 Diverse papers from diverse formats", "content": "Following the success of the HealthGAN model in [75, 54], [101] extends the utility, privacy, and fidelity evaluation to include fairness evaluation as well. [102] implemented federated learning to train separate GANs locally at each organization, and then combining them into a central GAN that can generate synthetic discrete EHR, such as ICD-9 codes. [103] evaluates four different GAN architectures: Tabular GAN (TGAN), CT-GAN, WGAN-GP, and conditional TableGAN (CTABGAN) on four tabular medical datasets, three of which are in the snapshot format, and one is an EEG dataset. The aim of this study is to investigate the applicability of tabular GANs to medical data and analyze whether the GAN architectures specific to tabular data outperform the more general WGAN-GP by evaluation of model quality, fidelity and privacy."}, {"title": "3.2 Time-series sgnals", "content": "In this section, we explore the generation of synthetic data for physiological signals, such as ECG and EEG. These signals are crucial for monitoring patient health. Our investigation delves"}, {"title": "3.2.1 ECGS", "content": "Various technologies are employed in the synthesis of ECG signals with many proposed methods, such as Pulse2Pulse, WaveGAN, BILSTM GAN, and TS-GAN, tailored to ECG data specifics such as morphology (appearance), durations, and intervals. The models were assessed for their ability to generate various synthetic ECG formats, including 2-lead synthesis, 12-lead synthesis, single-lead synthesis. ECG signals are commonly recorded in various formats, depending on the number of leads used. Each lead measures the electrical activity of the heart from a different angle, providing unique information about heart function. Each type of ECG provides a different level of detail and is suited for different clinical needs and settings. The 12-lead ECG is the most informative for diagnostic purposes, while single-lead ECGs are useful for continuous, everyday heart rhythm monitoring. An ECG signal is divided into heartbeats (also known as cardiac cycles), and a typical normal ECG heartbeat consists of three waves, the P wave, the QRS complex which contain the R peak, and the T wave.\nAtrial Fibrillation (AF) is a cardiac disorder where abnormal electrical impulses start firing in the atria, causing a faster heart rate, with two known clinical markers: The P waves are either absent or replaced by fibrillatory wave, and the distance between consecutive R peaks is irregular, causing a phenomena called Heart Rate Variability (HRV). To simulate the two AF markers, [105] employs a dual-GAN approach, combining LSTM-GAN to generate the R-R interval time-series and DCGAN for generating signal morphology in terms of missing P waves or presence of abnormal fibrillatory waves before the QRS complex. This underscores the necessity of composite models to capture the intricate characteristics of the signal.\nMost existing approaches to multi-lead ECG synthesis generate ECG lead signals that are independent of each other. To mitigate this, [107] introduces a 2 dimension bidirectional LSTM GAN, where the second dimension captures the physiological and spatial correlation among ECG leads of the same recording when synthesizing 12-lead ECGs. [106] also presents a LSTM based GAN architecture, where the discriminator and generator are based on LSTMs, which demonstrates superiority over previous LSTM-based models like TimeGAN [92] and C-RNN-GAN [125]. [104] follows a hybrid approach combining LSTM and Convolutional Neural Network (CNN) layers, where the model utilizes bi-LSTM layers to extract temporal features and CNN layers to extract spatial features from ECG signals.\nThe GAN technologies are further diversified in [108], which develops two state-of-the-art GAN methods, Pulse2Pulse (inspired by the U-Net architecture) and WaveGAN, to generate synthetic 12-lead ECG signals. Here, the Pulse2Pulse GAN outperforms its counterpart, highlighting the importance of architecture choice in generating realistic ECGs. [110] and [109] share a common approach to treating time-series data akin to images, with [110] employing a diffusion model for this purpose, while [109] utilizes tts-gan, a transformer-based GAN architecture. Both studies pivot away from traditional time series modeling, instead adopting image processing paradigms for ECGs.\nECGs are typically categorized based on heartbeat types, including normal beats (N), premature ventricular contraction beats (V), and fusion beats (F), with various models leveraging these class labels for conditioned generation tasks. [114]"}, {"title": "3.2.2 EEGs and other signals", "content": "Under the scope of unconditional synthesis, [128] employs a latent diffusion model to generate 30-second windows of synthetic EEG signals, while [129] uses a generative model called Causal Recurrent Variational Autoencoder (CR-VAE) integrating Granger causality [130] into a recurrent VAE framework to infer relationships between different time series variables. Given the success of language models, specifically GPT-2 [49], in different applications such as patent claims [131] and stock market analysis [132], [133] wants to explore the capabilities of language models in a brand new field of application: the generation of bio-synthetic signals. For this reason, [133] trains GPT-2 language models for generating synthetic biological signals, where a model is trained for each class separately.\n[134] uses Class conditional Wasserstein GAN (CWGAN) for generating synthetic EEG signals. However, instead of using the raw EEG signal directly, features extracted from the EEG are utilized due to the high dimensionality of the raw signal. [135] uses DDPMs to generate realistic synthetic data for a variety of physiological signals (LFP, ECoG, EEG) and evaluates if dataset-specific features such as sharp wave-ripples and ross-channel couplings were reproduced in the generated data. The work in [136] employs a diffusion model (DiffEEG) that uses the Short-time Fourier transform (STFT) spectrograms of the EEG signal segments as the condition for synthesis."}, {"title": "3.3 Medical imaging", "content": "In this section, we investigate the synthesis of medical image data across various modalities essential for diagnostic imaging. Medical imaging plays a crucial role in diagnosis, treatment planning, and monitoring of various medical conditions. Our exploration delves into the synthesis techniques tailored to each imaging modality, ranging from dermatoscopy (also known as dermoscopy) 3.3.1, mammography 3.3.2, ultrasound 3.3.3, to MRI 3.3.4, CT scans 3.3.5, X-rays 3.3.6, OCTs 3.3.7, and multiple modalities 3.3.8. Through the analysis of synthesis methods and evaluation strategies, we aim to enhance understanding of synthetic medical image data generation and its applications in healthcare research."}, {"title": "3.3.1 Dermatoscopy", "content": "The research on generative models in the field of dermoscopic imaging involves GANs and diffusion models. GANs, including variants like PGGAN, StyleGAN2 and its adaptations, and CycleGAN, have been used for data augmentation, class imbalance correction, and improving classification performance across diverse open source datasets like ISIC, Fitzpatrick 17k, ISIC, and BCN10000. These datasets are valuable resources for dermatology research, with Fitzpatrick 17k being annotated"}, {"title": "3.3.2 Mammography", "content": "The development of AI software products to enhance breast screening outcomes relies heavily on access to well-curated images. Over time, mammography technology has undergone significant evolution, transitioning from Digitized Screen-film Mammograms (DFMs) to Full-Field Digital Mammography (FFDM) and Digital Breast Tomosynthesis (DBT), thus revolutionizing breast cancer screening practices. Initially, DFMS involved X-ray images captured on film and later digitized for analysis. However, the introduction of FFDM marked a crucial advancement by allowing direct digital acquisition of breast images, eliminating the need for film processing and enabling immediate image availability. FFDM offered numerous benefits, including improved image quality, faster acquisition times, and enhanced visualization capabilities for radiologists. Building upon the advantages of FFDM, DBT emerged as a groundbreaking technique in breast imaging. DBT captures multiple X-ray images from different angles, reconstructing three-dimensional breast tissue images. This innovative approach overcomes the limitations of traditional mammography by reducing tissue overlap and providing clearer, more detailed images, especially in dense breast tissue, but at the expense of higher radiation dose. Aside from imaging techniques, the mammographic view plays a crucial role in breast cancer detection. While two-view mammography (mediolateral-oblique and craniocaudal views) is the current standard for breast cancer screening, single-view mammography remains in use in certain regions, particularly for screening specific age groups"}, {"title": "3.3.3 Ultrasound", "content": "Ultrasound synthesis using generative models spans various organs, including fetal brain, thyroid, breast, liver, muscles, and more, and different ultrasound techniques, such as Brightness Mode (B-mode) ultrasound and Elastography Ultrasound (EUS). B-mode ultrasound, commonly known as conventional ultrasound, is a widely used imaging technique in medical diagnostics. It generates 2D grayscale images of soft tissues, offering detailed anatomical information in a non-invasive manner. Despite its safety and relative comfort for patients, B-mode ultrasound has limitations in accurately assessing tissue stiffness and distinguishing between various types of lesions or abnormalities. To address these limitations, EUS is employed as an advanced technique. It evaluates tissue stiffness or elasticity by measuring the response of tissue to compression or shear waves, providing additional functional information beyond traditional B-mode ultrasound. Elastography often displays tissue stiffness"}, {"title": "3.3.4 MRI", "content": "MRI has become a ubiquitous medical imaging tool owing to its remarkable capability to generate a plethora of contrast mechanisms in soft tissues using specific pulse sequences. While acquiring images of the same anatomy with different contrasts offer a comprehensive diagnostic information"}, {"title": "Generative AI for Synthetic Data Across Multiple Medical Modalities: A Systematic Review of Recent Developments and Challenges", "authors": ["Mahmoud Ibrahim", "Yasmina Al Khalil", "Sina Amirrajab", "Chang Sun", "Marcel Breeuwer", "Josien Pluim", "Bart Elen", "G\u00f6khan Ertaylan", "Michel Dumontier"], "abstract": "This paper presents a comprehensive systematic review of generative models (GANs, VAEs, DMs, and LLMs) used to synthesize various medical data types, including imaging (dermoscopic, mammographic, ultrasound, CT, MRI, and X-ray), text, time-series, and tabular data (EHR). Unlike previous narrowly focused reviews, our study encompasses a broad array of medical data modalities and explores various generative models. Our search strategy queries databases such as Scopus, PubMed, and ArXiv, focusing on recent works from January 2021 to November 2023, excluding reviews and perspectives. This period emphasizes recent advancements beyond GANs, which have been extensively covered previously.\nThe survey reveals insights from three key aspects: (1) Synthesis applications and purpose of synthesis, (2) generation techniques, and (3) evaluation methods. It highlights clinically valid synthesis applications, demonstrating the potential of synthetic data to tackle diverse clinical requirements. While conditional models incorporating class labels, segmentation masks and image translations are prevalent, there is a gap in utilizing prior clinical knowledge and patient-specific context, suggesting a need for more personalized synthesis approaches and emphasizing the importance of tailoring generative approaches to the unique characteristics of medical data. Additionally, there is a significant gap in using synthetic data beyond augmentation, such as for validation and evaluation of downstream medical AI models. The survey uncovers that the lack of standardized evaluation methodologies tailored to medical images is a barrier to clinical application, underscoring the need for in-depth evaluation approaches, benchmarking, and comparative studies to promote openness and collaboration.", "sections": [{"title": "1 Introduction", "content": "The advent of Artificial Intelligence (AI) and Machine Learning (ML) has revolutionized numerous fields, including healthcare. These technologies have the potential to transform medical research and clinical practice, offering new avenues for diagnosis, treatment, and patient care. However, the application of AI and ML in healthcare depends on the availability of large and high-quality datasets, with diverse modalities and acquisition properties. In many instances, such datasets are not readily available due to privacy concerns, restricted sharing policies, complex acquisition techniques, expensive annotation costs, as well as limited diversity in real world data. This has led to the emergence of synthetic data generation, a promising solution that leverages generative models to create artificial data that mimics real-world datasets.\nSynthetic data could serve various critical purposes in data science and machine learning, mainly facilitating data sharing while protecting privacy, augmenting existing datasets, and promoting fairness and equity in AI applications [1]. Generative models are computational algorithms capable of learning and capturing complex data distributions, enabling the generation of new samples that closely resemble real data. By leveraging techniques such as Generative Adversarial Networks (GANs), Variational Autoencoders (VAEs), Diffusion Models (DMs), and Large Language Models (LLMs), researchers can create synthetic medical data across various modalities, including imaging, text, time-series, and tabular data.\nOur survey aims to provide a holistic understanding of the applications of these generative models in generating medical synthetic data. We delve into three key aspects: the purpose of synthesis, generation techniques, and evaluation methods. We highlight the potential of synthetic data in addressing various clinical needs and identify gaps in current practices, such as the need for more personalized synthesis approaches and standardized evaluation methodologies. Moreover, we emphasize the importance of tailoring generative approaches to the unique characteristics of medical data and call for more in-depth evaluation approaches relevant to clinical applications. Our study encourages benchmarking and comparative studies to promote openness and collaboration.\nIn essence, this survey paper serves as a valuable resource for researchers and practitioners interested in leveraging generative models for synthesizing medical data. By shedding light on the current practices, potential, and challenges in the field of synthetic medical data generation, we hope to spur further research and innovation in this critical area of healthcare AI and ML.\nThe structure of this paper is further organized into different chapters. Section 2 provides an overview of the synthesis applications, generative models, and evaluation methods that are common across the different data types. The concepts explained in this section are essential to understand the detailed results in section 3, where the findings from the surveyed papers are presented and divided into four sections, each focusing on a specific type of medical data: Electronic Health Records (EHR) in section 3.1, physiological signals in section 3.2, medical images in section 3.3, and medical text in section 3.4. This organization allows for a detailed exploration of the use of generative models for each data type, providing readers with a comprehensive understanding of the current state of synthetic medical data generation. Section 4 reveal the insights and conclusions collected from the surveyed papers. Section 5 provides recommendations to be taken into account for future research, and 6 concludes the paper. The reader is referred to the table of contents for a smooth navigation of the paper."}, {"title": "1.1 Related work", "content": "Despite the growing interest in generative models for medical data synthesis, the review of existing survey papers in the field reveals a notable trend: a tendency towards narrow specialization, as seen in Fig.1. These papers often focus on a single data type, such as brain and heart imaging [2] or EHR [3], or they combine a single data type with one specific technology, like medical images with diffusion models [4], EHR with GANs [5], or Electrocardiography (ECG) with GANs [6]. Additionally, there is a subset of papers dedicated exclusively to data augmentation applications, which similarly specialize in either a single data type [7, 8] or a combination of one modality and one technology [9].\nThis pattern indicates a gap in the literature where comprehensive, multi-faceted analyses providing holistic overviews are less prevalent. In contrast, the proposed survey paper seeks to address this gap by covering a broader spectrum. It spans multiple data types, encompassing medical imaging, tabular EHRs, physiological signals, and clinical text notes. Furthermore, it explores various generative models, extending beyond GANS which have been extensively covered in literature, to include diffusion models and language models. The survey also emphasizes the aspect of conditional generation, which is not focused on in similar work. Additionally, we have considered a specific timeline for our review, consciously excluding older papers that have already been covered in various surveys. This approach aims to provide a more holistic understanding of the application of generative models in medical research, moving away from the trend of focusing on singular aspects. Such a comprehensive analysis could significantly enrich the medical field by offering insights that are potentially overlooked by more narrowly focused studies."}, {"title": "1.2 Review methods and protocol", "content": "Our review methodology and protocol aimed to address several key objectives and research questions. Firstly, we sought to explore the applications and purpose of synthesis beyond data augmentation in medical research. Additionally, we aimed to identify the latest generative models utilized for generating synthetic medical data. Lastly, we aimed to investigate the common protocols for evaluating synthetic data and the trade-offs between the different evaluation dimensions.\nOur review is scoped to cover a broad spectrum of modalities, including tabular data (specifically EHRs), physiological signals (primarily ECGs and Electroencephalography (EEGs)), clinical text notes, and a variety of medical images such as dermatoscopic images, mammographic images, Utrasound (US) scans, Computed Tomography (CT) scans, Magnetic Resonance"}, {"title": "1.3 Search results", "content": "The details of the literature screening processes according to the Preferred Reporting Items for Systematic reviews and Meta-Analyses (PRISMA) guidelines [10] are shown in Fig.2. Overall, 249 papers are included in the review, distributed over the different modalities as shown in Fig.3."}, {"title": "2 Synthesis application, generative technologies and evaluations", "content": "This section presents a strong foundational understanding of key concepts gathered from various surveyed papers concerning the overarching themes of (i) synthesis applications, (ii) generative technologies, and (iii) evaluation methodologies in medical data synthesis. The objective is to lay the groundwork by explaining fundamental concepts and approaches that are commonly encountered in the survey. This aids the reader in building the necessary background to understand the detailed and more specific findings presented in section 3. First, we discusses different synthesis applications in section 2.1, followed by an exploration of common generative models 2.2. Finally, in section 2.3, we delve into the diverse evaluation methods employed in the surveyed studies, offering a comprehensive view of the research landscape in this field.\nIn our paper, we introduce specific definitions for the terms \"data types\" and \"modalities\". We classify EHR, images, text, and signals as distinct data types. Within each data type, we define various modalities. For example, within medical images, modalities include CT, MRI, and others. Additionally, within each modality, there exist different modalities; for example, within MRI, modalities such as T1 and T2 weights are distinguished."}, {"title": "2.1 Synthesis applications and purpose of synthesis", "content": "Generative models are a powerful tool in machine learning and can be broadly categorized into two types: unconditional and conditional. Unconditional models take a random variable as input, allowing for the application of unconditional synthesis. On the other hand, conditional generative models introduce an additional layer of control by incorporating external information or context during the generation process that serve as additional guidance for the model. These can include images, text, semantic maps, class labels, attributes, and signals, as demonstrated in Fig.5. This added control allows conditional models to be used in a variety of synthesis applications specific to each data type shown in Fig.4.\nFor the EHR data type, the synthesis depends on the EHR format, which includes (i) Longitudinal EHR, consisting of medical codes from various patient visits; (ii) Aggregated EHR,"}, {"title": "2.2 Generation techniques", "content": "Our examination of various papers revealed a range of techniques utilized for generating synthetic medical data, with a primary focus on GANs [11], VAEs [12] and recent advancements in diffusion models [13] and language models. See Fig.6 for the basic working mechanisms of the different generative models.\nFirstly, we discuss the differences in how various generative models operate across different datatypes: EHR, medical images, medical text, and physiological signals. Next, we highlight notable state-of-the-art GANs frequently referenced in the literature. Following this, we explore diffusion models, including denoising diffusion probabilistic models and latent diffusion models, alongside discussions on different text embedding methods. Finally, we examine language models, concluding our"}, {"title": "2.2.1 Differences in generative models working mechanism per datatype", "content": "\u2022 Handling discrete variables: GANs, initially introduced for generating realistic continuous images, face challenges when applied to discrete data. Similarly, many diffusion models are Gaussian processes, operating in continuous spaces and not the discrete space. To address these issues, various techniques have been introduced. (Variational) autoencoders are commonly employed before GANs and diffusion models to condense high-dimensional and heterogeneous features into latent representations. Notably, some diffusion models like Tabular Denoising Diffusion Probabilistic Models (tabDDPM) [16] adopt a mixed sequence diffusion approach [17, 18], employing Gaussian diffusion for continuous variables and multinomial diffusion [19] for discrete variables. Others treat discrete variables similar to real-valued sequences but with further post-processing of"}, {"title": "2.2.2 GANS", "content": "Adversarial approaches, such as GANs, involve a generator and discriminator, trained to outperform each other, hence the term \"adversarial\". The generator network adapts its distribution and generates a new, reliable distribution, while the discriminator network learns to differentiate between real and augmented data. The work in [11] pioneered GANs for generating realistic images, particularly dealing with continuous data, often referred to as the vanilla GAN (Fig.7a). However, such models have been extended to different domains, such as audio and EEG signal generation [20, 21]. [22] proposed the Deep Convolutional GAN (DCGAN), that combines the original GAN with convolutional neural networks for better and more stable training. [23] proposed the Wasserstein GAN (WGAN), while [24] proposed the Least Squares GAN (LSGAN), to address challenges like mode collapse and vanishing gradients typically encountered in GANs (see Fig.7f). WGAN replaces binary classification with the Wasserstein distance. The training of WGAN was enhanced with the introduction of WGAN-GP in [25], which integrates a gradient penalty technique. Progressive Growing GAN (PGGAN)[26] is an extension of GAN training, ensuring stability for generators producing large, high-quality images. Traditional GANs struggle with stability when working with larger sizes, attempting to balance both structure and fine details. This challenge worsens as resolutions increase, often required for medical image generation, leading to training failures, while memory constraints on Graphics Processing Units (GPUs) further necessitate reducing batch size, introducing instability. As illustrated in Fig.7c, PGGAN addresses these"}, {"title": "2.2.3 Diffusion models", "content": "The original concept of the diffusion model, introduced by Diffusion Probabilistic Models (DPMs) [13], draws inspiration from non-equilibrium statistical physics. The key idea is to systematically and iteratively destroy structure in a data distribution through a forward diffusion process. Subsequently, the reverse diffusion process is learned and applied to restore the structure in the data.\nDDPM. The initial practical implementation of the diffusion model in the context of images was presented by [37], introducing Denoising Diffusion Probabilistic Models (DDPM). This approach destroys data by iteratively adding Gaussian noise to the image according to the Markov chain. To learn the reverse process, a deep neural network is needed to recover the data. Fig.8b illustrates the working mechanism of the DDPM. The current best practice for image diffusion models is to use U-Net [38] architectures for denoising. However, these architectures are tailored for image generation tasks, and may not be a viable option for other data types, especially when the training data is limited. Moreover, U-Net architectures struggle to retain temporal dynamic information and lack flexibility in handling varying input sequence lengths, thus proving inadequate for managing sequential information. In addressing this limitation, some studies [17] resort to Bidirectional Recurrent Neural Networks (BRNNs) implemented with either LSTM or GRU units. A significant drawback of diffusion models is that they operate sequentially on the entire image during both training and inference. Consequently, they demand substantial computational resources and time, making both the training to be slow as well generating an image after training. As a result, [39] speed up image generation by redefining the diffusion process as a non-Markovian one, which allows for skipping steps in the denoising process, without requiring all past states to be visited before the current state.\nLatent Diffusion Models- The Stable Diffusion Pipeline. To address computational inefficiencies of DDPMs, Latent Diffusion Model (LDM) [40] was introduced initially for images, which uses encoders to compress images from their original size in the pixel space into a smaller representation in the latent space, as illustrated in Fig.8a. Therefore, in latent diffusion, the diffusion process is performed on the latent representations rather than the original images (Fig.8b), allowing LDMs to model long-range dependencies within the data and enabling training on limited computational resources while retaining their quality and flexibility. Stable diffusion, a foundation model built based on LDM, introduces text conditioning to the model for additional control over the generation process and consists of three main components: (i) the VAE for compression (Fig.8a), (ii) a U-net based diffusion process in the latent space (Fig.8b), and (iii) a conditioning mechanism that embeds a prompt describing the image using a Contrastive Language-Image Pre-training (CLIP) text encoder [41] (Fig.8c). CLIP creates a numeric representation (embedding vector) of the prompt, mapping both the text and images into the same representational space, enabling comparison and similarity quantification. In addition to CLIP, other text encoders such as pre-trained T5X model [42], medBERT encoder [43], a Byte Pair Encoding (BPE) tokenizer [44], and Self-alignment pretraining for BERT (SAPBERT) [45] are commonly used in different publications to enable text conditioning of the models.\nThe Stable Diffusion model is widely utilized in recent publications, where the pre-trained foundation model is fine-tuned on various medical modalities without the need to initiate training from scratch. Moreover, the idea of latent diffusion models, which involves performing the diffusion process in the latent space, has been extended to both the EHR and signals data types. In these extensions, a low-dimensional representation of the high-dimensional features, including discrete ones, is learned using an auto encoder before the diffusion process."}, {"title": "2.2.4 Language models:", "content": "A fundamental aspect of language models is enhancing the linguistic capabilities of machines to understand the probability of sequences of words, enabling them to predict future or missing words in sentences [46]. The development of language models (shown in Fig.9) started from Statistical language models which were grounded in probability theories with a restriction to predicting the next word in a sequence based on a fixed number of previous words. However, these models face significant challenges in accurately predicting the next word due to the"}]}]}