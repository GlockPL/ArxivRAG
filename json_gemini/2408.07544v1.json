{"title": "Planning with OWL-DL Ontologies (Extended Version)", "authors": ["Tobias John", "Patrick Koopmann"], "abstract": "We introduce ontology-mediated planning, in which planning problems are combined with an ontology. Our formalism differs from existing ones in that we focus on a strong separation of the formalisms for describing planning problems and ontologies, which are only losely coupled by an interface. Moreover, we present a black-box algorithm that supports the full expressive power of OWL DL. This goes beyond what existing approaches combining automated planning with ontologies can do, which only support limited description logics such as DL-Lite and description logics that are Horn. Our main algorithm relies on rewritings of the ontology-mediated planning specifications into PDDL, so that existing planning systems can be used to solve them. The algorithm relies on justifications, which allows for a generic approach that is independent of the expressivity of the ontology language. However, dedicated optimizations for computing justifications need to be implemented to enable an efficient rewriting procedure. We evaluated our implementation on benchmark sets from several domains. The evaluation shows that our procedure works in practice and that tailoring the reasoning procedure has significant impact on the performance.", "sections": [{"title": "1 Introduction", "content": "Automated planning continues to play a central role in many application domains such as robotics. Systems for automated planning compute plans for a planning domain which defines a set of available actions that describe how states of the system can be modified. A planning problem then consists of an initial state, a domain of objects and a goal that needs to be reached, for which the planner computes a plan in the form of a sequence of actions that would lead from the initial state to a state satisfying the goal [11, 25].\nPlanning problems classically operate under a closed world semantics, meaning that the initial state and all states that the system can go through are represented as finite first-order interpretations, which requires a suitable abstraction of the real world. In more complex scenarios, this assumption is not realistic, as agents have only limited knowledge about the world, and need to reason over complex domains. Ontologies are a widely used formalism for describing complex domain knowledge under open world semantics. Here, we assume our knowledge of the world to be generally incomplete [4]. The ontology defines terminology and background knowledge relevant for the application scenario, which allows to infer new information from an incomplete description of the world. This also gives further flexibility when specifying planning problems: for example, the available actions might depend on a configuration of the robot, whose abilities can be derived through the technical knowledge defined in the ontology.\nOur first contribution is to propose ontology-mediated planning specifications as a new framework for linking planning problems with ontologies, inspired by ontology-mediated model checking [9]. The idea is to have an ontology describing static knowledge described in description logics (DL), the central formalism for specifying ontologies, together with a specification of a planning problem in PDDL, the classical language for specifying planning problems. These two are then linked together through an interface that specifies how to translate between PDDL and DL. Each state in the planning space has then two perspectives that we also distinguish syntactically: as ground atoms in PDDL and as DL axioms. By separating the two formalisms for planning and ontologies, existing formalizations can easily be integrated, and planning and ontology experts do not have to learn a new formalism. Moreover, we achieve a true separation of concerns, allowing to specify planning problems and domain knowledge relatively independently and in dedicated languages.\nOntology-mediated planning specifications (OMPSs) are strongly related to extended Knowledge Action Bases (eKABS) [14, 8], which extend classical DL knowledge bases with actions formulated over the DL signature. One syntactical difference between eKABs and ontology-mediated planning specifications is that there is an integration rather than a separation of concerns. Another difference is that eKABs allow to refer in both pre- and post-conditions of actions to objects outside of the domain. Existing techniques for planning with eKABs rely on the idea of compilation schemes that translate the actions in an eKAB into a PDDL planning domain, so that a PDDL planning system can be used out of the shelf. The compilation scheme introduced in [8] supports DLs of the DL-Lite family, while the compilation scheme introduced in [7] supports Horn-DLs. [7] also studies the limitations of such compilation schemes in general: for DLs such as Horn-SROIQ, under common complexity theoretic assumptions, no compilation scheme that increases the size of the planning domain at most polynomially exists. Moreover, since the approach relies on Datalog rewritings, it is not applicable to DLs that are not Datalog-rewritable, such as DLs beyond the Horn fragment. This means, in this approach, disjunction, unrestricted negation and value restrictions, as well as cardinality restrictions are not allowed. For instance, it is impossible to express in a Horn DL that a robot can carry at most five objects, since this would require a cardinality restriction that is not available in Horn logics.\nOur second contribution is that we use a rewriting technique that is not restricted to Horn DLs, but can indeed be used for any DL which is supported by a reasoner, and thus in practice supports the full ontology language standard OWL DL via the reasoner HermiT [12]. Similar to existing approaches, our technique generates specifications in PDDL to be processed by an off-the-shelf planning system. However, we do not provide a compilation scheme, which would only consider the domain (i.e. set of actions) of the planning specification, but we also also take the planning problem itself into account. In other words, we solve part of the planning problem while generating the rewritings, and our solution is not problem-independent anymore. Similar to the technique for ontology-mediated model checking in [9], we make this possible through the use of justifications, which are minimal consistent sets of axioms that can be computed with standard software using DL reasoners as blackbox [21]. However, additional efforts are needed as our domains are larger than the ones considered in [9]. We thus developed new algorithms for computing justifications that are optimized to the specific form of axiom sets that are relevant when rewriting ontology-mediated planning specifications into PDDL. An evaluation on planning instances from different domains shows that these optimizations are indeed crucial for making our technique practical, and on some problems even lead to comparable performances to those of existing planning techniques optimized on less expressive DLs.\nThe framework has been previously introduced in workshop papers [19, 18], while the optimizations to make it efficient in practice have not been presented before. Additional proofs and evaluation results can be found in the appendix.\nRelated Work. Our paper relates most to research into eKABs [14, 8, 7], and into ontology-mediated model checking, whose ontologized programs have a similar structure to our ontology-mediated planning specifications [9]. All these approaches represent system states using sets of description logic axioms interpreted under the open-world semantics, on which actions can only operate by removing or adding statements. There is also another line of research that considers actions that instead directly operate on DL interpretations [2], leading to issues such as decidability of plan existence [35] and the ramification problem [26]. While [29] studies planning with such actions, there is to the best of our knowledge so far no practical system for planning with such actions.\nThere is also a relation to temporal DLs [28] and knowledge bases [3], which allow to specify changing states of a system directly through the DL. This has for instance been used in [34]. While there are even temporal DLs that consider branching time [13], the focus here is on describing possible sequences of states, and not on computing plans to achieve a specific goal.\nDescribing the behavior of a system and using an ontology to reflect on the state of it to gain more insight is also part of work on semantically lifted states [22]. This line of work is not focused on planning but on programming languages for digital twins. Another way of combining planning and ontologies is using ontologies as a modeling language to describe planning domains [1, 5, 24, 27]."}, {"title": "2 Preliminaries", "content": "Planning Problems We consider the common syntax and semantics of PDDL planning problems introduced in [11, 25] and described in detail in [10], with the extension for derived predicates [16]. Let $N_p$ be a set of predicate names, and let $O$ be a set of constants. A state $s$ over $O$ is a finite set of ground atoms over $N_p$ and $O$, which we identify with the corresponding first-order interpretation.\nWe denote a special set $N_{P,D} \\subseteq N_p$ of predicates called derived predicates. A derivation rule is of the form $r = p(\\vec{x}) \\leftarrow \\varphi(\\vec{x})$, where $\\vec{x}$ is a vector of variables, $p \\in N_{P,D}$, and $\\varphi(\\vec{x})$ is a first-order formula with free variables $\\vec{x}$ in which derived predicates occur only positively. We call $p(\\vec{x})$ the head and $\\varphi(\\vec{x})$ the body of the rule. The result of applying such a rule on a state $s$ is obtained by adding to $s$ all $p(\\vec{c})$ for which $s \\models \\varphi(\\vec{c})$, where $\\vec{c}$ is a vector of constants with the length of $\\vec{x}$. Given a set $D$ of derivation rules and a state $s$, $D(s)$ denotes the result of applying the rules in $D$ until a fixpoint is reached.\nAn action is a tuple $a = (\\vec{x}, pre, eff)$ where $\\vec{x}$ is a vector of variables, $pre$ is a first-order formula with free variables from $\\vec{x}$, and $eff = (add, del)$, where $add$ and $del$ are finite sets of atoms using only variables from $\\vec{x}$ and no derived predicates. We call $pre$ the precondition of $a$, and $eff$ the effect. If $\\vec{x} = ()$, $a$ is called ground. An instance of $a$ under $O$ is a ground action $a_{\\sigma}$ obtained by replacing all variables from $\\vec{x}$ by constants from $O$. let $\\sigma: \\vec{x} \\rightarrow O$ be the function describing the replacement. A ground action is applicable on a state $s$ if $s \\models \\sigma(pre)$ (where $s$ is treated as an interpretation), in which case the result of applying $a$ on $s$ is defined as $s(a) := (s \\setminus \\sigma(del)) \\cup \\sigma(add)$.\nA planning domain is a tuple $D = \\langle A, D \\rangle$ of a set $A$ of actions and a set $D$ of derivation rules. A planning problem is a tuple $P = \\langle O, s_0, G \\rangle$ with $O$ a set of constants, $s_0$ a state over $O$ called the initial state, and $G$ a first-order formula called goal. A PDDL planning specification is now a tuple $S = (D, P)$ of a planning domain $D$ and a planning problem $P$. A plan for such a planning specification is a sequence of states $s_0... s_n$ s.t. 1) $s_0$ is the initial state from $P$, 2) for every $i$, $0 \\leq i < n$, $s_{i+1} = s_i (a)$, where $a$ is an instance of an action from $A$ over $O$ that is applicable on $D(s_i)$, and 3) $s_n \\models G$, where $s_n$ is treated as an interpretation.\nDescription Logics and Ontologies A DL ontology is a formalization of domain knowledge based on pair-wise disjoint, countably infinite sets $N_C$ of concepts names (unary predicates), $N_R$ of role names (binary predicates) and $N_I$ of individual names (constants), which are used to build complex expressions called concepts that describe sets of individuals. For the context of this paper, ontologies are sets of axioms, which either describe terminological knowledge (TBox axioms) by putting concepts into relation with each other (e.g. by saying that a concept name describes the same set of objects than a complex concept) or describe assertional knowledge (ABox axioms) by assigning concepts and role names to specific individuals. ABox axioms are of the forms $C(a)$, $r(a, b)$, $\\neg r(a, b)$, $a = b$, $a \\neq b$, where $C$ is a concept, $a, b$ are individual names, and $r$ is a role name. Each (TBox or ABox) axiom can be translated into a sentence in first-order logic, so that we can define entailment between axioms and of axioms from ontologies based on this translation. Specifically, for an ontology $O$ and an axiom $\\alpha$, we write $O \\models \\alpha$ if $\\alpha$ is logically entailed by the axioms in $O$. For details on the different concept and axiom constructs, see [4].\nOur examples rely on the DL $\\mathcal{ALCQ}$, which is a fragment of OWL DL, and in which concepts $C$ follow the following syntax rule:\n$C ::= \\top \\mid A \\mid \\neg C \\mid C \\sqcap C \\mid C \\sqcup C \\mid \\exists r.C \\mid \\forall r.C \\mid \\geq nr.C \\mid \\leq nr.C$,\nwhere $A \\in N_C$, $r \\in N_R$. TBox axioms in $\\mathcal{ALCQ}$ are of the form $C \\sqsubseteq D$ or $C \\equiv D$, with $C$ and $D$ concepts."}, {"title": "3 Framework", "content": "3.1 Ontology-Mediated Planning\nWe capture our framework formally via ontology-mediated planning specifications, which are inspired by the ontologized programs introduced in [9]. At the heart of our framework is the notion of ontology-enhanced states, which combine a PDDL state with an ontology.\nDefinition 1 (Ontology-Enhanced State). An ontology-enhanced state is a tuple $q = (s_q, O_q)$, where $s_q$ is a set of atoms called the planner perspective of $q$, and $O_q$ is a set of DL axioms called the DL perspective of $q$.\nWhile the planner has only direct access to the planner perspective, which is a PDDL state and allows predicates of arbitrary arity, DL semantics and reasoning apply to the DL perspective of the state, which is represented using DL syntax axioms. The interface, which we define next, ensures that the two perspectives are compatible: the axioms of the DL perspective are then determined by the atoms in the planner perspective. There is also a static component in the DL perspective, which describes state-independent information such as class definitions, general domain knowledge, and the context of the planning problem. The planner can access derived information from the DL perspective using query predicates. Before we give the formal definition, we illustrate this idea with an example.\nExample 1. An example of an ontology-enhanced state is depicted in Figure 1. The scenario is inspired by the classical blocksworld planning domain. In contrast to the classical problem in which the robot has only one hand, we use an ontology to specify types of robots and their number of hands. In the example, the stacking robot is a PR2 robot [6] that can hold two blocks at a time, and if it holds two blocks, it becomes an instance of FullHands. While relatively simple, those cardinality constraints already go beyond the expressivity of Horn-ALCHOIQ, the most expressive DL currently supported by existing implementations for eKABs (see Section 1). The planner perspective is shown on the left, the DL perspective on the right, and the interface in the middle. If the atom holds(stackBot,\nblockA) becomes true in the planner perspective, this is reflected in the DL perspective by an axiom expressing a corresponding relation between the two individuals stackBot and blockA. Using the static ontology, we can infer that stackBot is an instance of the concept FullHands, because it stands in the holds relation with two different blocks. Consequently, FullHands(stackBot) is entailed. The query predicate fullHands translates to a query for instances of the concept FullHands. Because in the DL perspective, stackBot is an instance of FullHands, fullHands(stackBot) becomes true in the planner perspective of the state.\nTo implement this mechanism, the interface consists of two components, the fluent interface and the query interface.\nDefinition 2 (Interface). A fluent interface is a partial inverse-function $F: N_p \\cup O \\rightarrow N_C \\cup N_R \\cup N_I$ that assigns unary predicates to concept names, binary predicates to role names and constants to individual names. We lift $F$ to atoms by setting $F(P(t_1,...,t_n)) = F(P)(F(t_1), ..., F(t_n))$ if it is defined.\nA query interface $Q$ is a set of query specifications which are expressions of the form\n$p(x_1: C_1,..., x_n: C_n) \\leftarrow \\Phi(x_1,...,x_n)$, where\nQ1 $p \\in N_{P,D}$ is the query predicate,\nQ2 $x_1, x_n$ are the query variables,\nQ3 each $C_i$ is a DL concept specifying the static type of $x_i$,\nQ4 the query $\\Phi(x_1,...,x_n)$ is a set of ABox axioms using variables $x_1,..., x_n$ as place holders for individual names.\nA query specification defines a query predicate $p$ that can be used by the planner to access the state of the DL perspective. A query $p(x_1,...,x_n)$ translates to a complex query $\\Phi(x_1,...,x_n)$ that is evaluated on the ontology perspective. The static types $C_1, ..., C_n$ specify the range of the variables independently of the current state, which makes the definition more transparent and allows for a more efficient implementation of our planning approach. For such a query specification, we call a vector $(a_1,..., a_n)$ of individual names a candidate in an ontology $O_s$ if $O_s \\models C_i(a_i)$ for $1 \\leq i \\leq n$. In our example, we would define\nfullHands(x: Robot) $\\leftarrow$ FullHands(x),\nbut static types and concepts can also be more complex.\nWe have now all ingredients to define ontology-mediated planning specifications.\nDefinition 3. An ontology-mediated planning specification (OMPS) is a tuple $OP = (S, O_s, F, Q)$, where\n*   $S$ is a PDDL planning specification,\n*   $O_s$ is an ontology called the static ontology,\n*   $F$ is a fluent interface,\n*   $Q$ is a query interface.\nAn OMPS determines which ontology-enhanced states are compatible: a state $q = (s_q, O_q)$ is compatible to an OMPS $OP = (S, O_s, F, Q)$, where $D$ are the derivation rules in $S$, iff:\nC1 $s_q$ is a set of atoms over predicates and constants occurring in $S$;\nC2 $O_s \\subseteq O_q$;\nC3 for every $a \\in D(s_q)$ for which $F(a)$ is defined; $F(a) \\in O_q$;\nC4 $O_q$ only contains axioms required due to Conditions C2 and C3;\nC5 for every query specification $p(x_1: C_1,...,x_n: C_n) \\leftarrow \\Phi(x_1,...,x_n)$ and every candidate $(a_1,...,a_n)$ in $O_s$ s.t. $O \\models \\Phi(a_1,..., a_n)$ and $F(a_i)$ is defined for all $1 \\leq i \\leq n$, it is required that $p(F^{-}(a_1),..., F^{-}(a_n)) \\in s_q$.\nEvery planning state $s$ without query predicates can be uniquely extended to an ontology-enhanced state $ext(s, OP)$ compatible with $OP$ where $s$ is extended only by query predicate atoms.\nIt remains to define the semantics of actions and plans on OMPSS. Fix an OMPS $OP = (S, O_s, F, Q)$ with derivation rules $D$. Let $a$ be a ground action with precondition $pre$ and effect $eff = (add, del)$. Let $q$ be an ontology-enhanced state. We say that $a$ is applicable on $q$ iff $D(s_q) \\models pre$. The result of applying $a$ on $q$ is then denoted by $q(a)$ and defined as $q(a) = ext(s(a), OP)$. We can now define plans for $OP$ similarly as we did for planning specifications: Namely, a plan is a sequence $a_1... a_n$ of actions that generates a sequence $q_0q_1... q_n$ of ontology-enhanced states s.t.\nP1 $q_0 ext(s_0, OP)$, where $s_0$ is the initial state of $S$,\nP2 for each $i \\in \\{1, ..., n\\}$: $a_i$ is applicable on $q_{i-1}$, $q_i = q_{i-1}(a_i)$, and $q_i$ is consistent, and\nP3 $D(s_{q_n}) \\models G$, where $G$ is the goal of the planning problem."}, {"title": "3.2 Planning Procedure", "content": "OMPS are strongly related to eKABs, the main differences being: 1) eKABs do not explicitly define an interface, and directly integrate actions and DL axioms, and 2) eKABs allow for queries and effects with existential quantification, while our query predicates always translate to queries in which every variable is mapped to a query variable. eKABs without existentially quantified variables can thus easily\nbe translated into OMPSs, while OMPSs that only use unary and binary predicates in the planning component can be translated into eKABs. In the latter case we can use existing techniques for planning with eKABs, given that they support the expressivity of the ontology part. There are generally two techniques for planning of eKABs, which are both based on compilation schemes [30] of eKABs into PDDL programs. Such a compilation scheme handles the planning domain independently of the planning problem. The compilation schemes presented in [8] and [7] only support limited families of DLs, namely FO-rewritable DLs in the first case and Horn DLs in the second. The approach in [7] works by translating ontology axioms into derivation rules. Since derivation rules have a single atom in the head, it is not clear how such a translation would work for logics that are not Horn, and likely it is impossible.\nOur technique to planning with OMPSs is also based on rewritings into PDDL. To support full OWL DL, and thus also non-Horn description logics, we deviate however from the idea of compilation schemes. Namely, our rewriting uses the planning domain together with the planning problem, and thus solves already part of the planning problem, which has the additional advantage that there is less work for the planner to do afterwards.\nThe main idea is to instantiate all fluents and queries. Fix a OMPS OP = (S, Os, F, Q). Roughly, we transform the OMPS into a PDDL planning specification by adding to S a derivation rule for each query predicate. This rule considers all candidates for the query and specifies for each when the query would become true.\nWe define the set $\\mathcal{F}$ of fluents of OP as the set of all assertions A(a) and r(a, b) that occur in the image of F. The fluents are the only atoms in the ontology perspective that can be changed by actions. Correspondingly, we can construct for any axiom $\\alpha$ a formula $ent(\\alpha)$ that is satisfied in the PDDL perspective of a state iff $\\alpha$ is entailed by the DL perspective:\n$ent(\\alpha) = \\bigvee_{\\mathcal{B} \\subseteq \\mathcal{F}} \\bigwedge_{B \\in \\mathcal{B}} F^{-}(B) | O_s \\cup \\mathcal{B} \\models \\alpha$        (1)\nFor a given query specification q, we denote by $cnd(q)$ its candidates, i.e. the vector of constants that are compatible with the type specification. For a query specification q as in Definition 2, we construct the corresponding derivation rule $dr(q)$ as follows:\n$p(x_1,...,x_n) \\leftarrow  \\bigvee_{(\\mathcal{C}_1,...,\\mathcal{C}_n) \\in cnd(q)}  \\left(\\bigwedge_{i=1}^{n}  x_i = C_i  \\wedge  \\bigwedge_{\\alpha \\in \\Phi(\\mathcal{C})} ent(\\alpha) \\right)$\n     (2)\nWe also use a rule $Inc \\leftarrow ent(\\top \\sqsubseteq \\bot)$, where $Inc$ is a fresh nullary derived predicate, to detect states that are inconsistent from the ontology perspective. The rewriting $rew(OP)$ of the planning problem is now obtained from $S$ by adding $Inc$ as a conjunct to the goal and to the precondition of every action, and to the set of derivation rules the rule for $Inc$, as well as $dr(q)$ for all $q \\in Q$.\nTheorem 1. Let OP be an OMPS. Then, every plan for OP can be translated into a plan in rew(OP), and every plan in rew(OP) can be translated into a plan in OP, by replacing each action by the corresponding action in the other specification.\nThe feasiblity of our technique crucially depends on an efficient computation of $ent(\\alpha)$, which we discuss in the next section."}, {"title": "4 Optimized Generation of Justifications", "content": "Since the axioms in the static ontology $O_s$ are always part of the DL perspective of a state, it makes no sense to try to modify them with an action. In the following, we thus assume $O_s \\cap \\mathcal{F} = \\emptyset$.\nLet $Q$ be the set of assertions for which we need to compute $ent(\\alpha)$. Due to the monotonicity of entailment, it is sufficient to consider those subsets $\\mathcal{B} \\subseteq \\mathcal{F}$ in Equation (1) that are subset minimal. Thus, to obtain $ent(\\alpha)$ we need to compute all pairs $(\\alpha, \\mathcal{B}) \\subseteq Q \\times 2^{\\mathcal{F}}$ s.t. $O_s \\cup \\mathcal{B} \\models \\alpha$ and $\\mathcal{B}$ is minimal, where $O_s$ is the static ontology. For this, we reduce our problem to the problem of finding minimal inconsistent subsets, also called justifications [21].\nDefinition 4 (Justification). Given an ontology $O$, a subset of axioms $\\mathcal{J} \\subseteq O$ is a justification iff $\\mathcal{J} \\models \\bot$ and for all $\\mathcal{J}^{\\prime} \\subsetneq \\mathcal{J}: \\mathcal{J}^{\\prime} \\not\\models \\bot$. We denote the set of all justifications by $AllJust(O)$.\nIndeed, justifications can be used to compute what we need:\nLemma 2. For sets O and F of axioms s.t. $O \\cap F = \\emptyset$ and some axiom $\\alpha$, the following two sets are identical:\n1. $\\{\\mathcal{B} \\subseteq \\mathcal{F} | O \\cup \\mathcal{B} \\models \\alpha, \\mathcal{B} \\text{ is minimal}\\}$"}, {"title": "4.1 Basic Algorithm", "content": "Our basic algorithm is based on the Hitting-Set-Tree algorithm proposed by Reiter [32], which can also be used to generate the set of all justifications for DL ontologies [21].\nThe algorithm assumes a method SINGLEJUST(O) that returns an arbitrary justification for O. There are standard implementations available, i.e. as part of the OWL API [17], that compute SINGLEJUST(O) using a black box approach. The algorithm builds a hitting-set tree (HST) where each node is labeled with a justification, and edges are labeled with axioms. The HST has the property that, if a path from the root is labeled with axioms A and ends on a node labeled with a justification J, then J is a justification for O\\A.\nTo compute the HST, we use a recursive algorithm that starts with an arbitrary justification J for O, and then generates successor nodes by considering all possibilities of removing an axiom $a \\in J$ from O, so that eventually all justifications are found. More details on the algorithm and a proof why this algorithm works in general for DL ontologies can be found in [21].\nThe general algorithm is depicted in Figure 2. For simplicity, we omit the common optimization of cutting branches, if their path condition is a superset of an already completed path, which we still use in our implementation. The main function COMPUTEHST builds the hitting-set tree given an ontology $O_s$, a set of fluent axioms $\\mathcal{F}$, the set of all already found justifications $\\mathcal{J}$ and the content of the current path leading to the node. In lines 7-9, the algorithm checks if we already found a fitting justification, to reduce the number of calls to SINGLEJUST. Otherwise, we use SINGLEJUST in Line 11. The function SUCCESSORS generates the set of axioms to branch on. This function will be changed in the optimized versions of the algorithm. While the algorithm in [21] branches on all axioms in the justification, we only branch on the fluent axioms. This is sufficient since we do not really need all justifications, but only the ones that differ in their intersections with $\\mathcal{F}$.\nTheorem 3. Given an ontology $O$ and a set $F$ of axioms,\nALLJUSTIFICATIONS($O\\cup F, F$) computes all minimal subsets $\\mathcal{F} \\subseteq F$ s.t. $O\\cup F \\models \\bot$.\nProof. The theorem follows directly from the original proof by Reiter [32, Theorems 4.4 and 4.8], where our set of fluents $F$ corresponds to the set of \"components\" in Reiter's proof.\nIt follows from Theorem 3 and Lemma 2 that we can use this algorithm to compute all required pairs $(\\alpha, \\mathcal{B})$ and thus $ent(\\alpha)$."}, {"title": "4.2 Concept-Based Algorithm", "content": "Our first optimization of the basic algorithm considers Observations O1 and O2: If we compute the justifications of $O_s \\cup F \\cup \\{\\alpha\\}$ for each $\\alpha$ separately, we will compute all justifications for $O_s \\cup F$ several times. We avoid these redundant computations with the concept-based algorithm, which generates one HST that contains the justifications needed for all queries of the same form. For simplicity, we assume that every $\\alpha \\in Q$ is a concept assertion, i.e. an axiom of the form C(a). This is possible wlog since in OWL DL, every ABOX axiom can be equivalently expressed as concept assertion.\nFix a concept C and some $I \\subseteq N_I$ so that $Q_C = \\{C(a) | a \\in I\\}$ is a set of assertions for which we want to compute justifications. We introduce a fresh concept name $A_C$, and add to the ontology the axiom $C \\sqsubseteq \\neg A_C$ and the assertions $Q_C = \\{A_C(a) | a \\in I\\}$.\nThe following lemma shows that this ontology can be used to generate the required sets of fluent.\nLemma 4. For $O^{\\prime} = O \\cup F \\cup \\{\\sqcap_{A_C} \\subseteq \\bot\\} \\cup Q_C^{\\prime}$, the following are identical:\n1. $\\{(\\alpha, \\mathcal{B}) \\subseteq Q_C \\times 2^{F} | O_s \\cup \\mathcal{B} \\models \\alpha, \\mathcal{B} \\text{ is minimal}\\}$\n2. $\\{(C(a), J \\cap F) | J \\in AllJust(O^{\\prime}, F),  \\text{ and }  A_C(a) \\in J \\text{ or } J \\cap Q_C = \\emptyset\\}$.\nTo compute those justifications, we run the algorithm ALLJUSTIFICATIONS($O^{\\prime}, F \\cup Q_C$) with $O^{\\prime}$ as in the lemma. We need to include the additional assertions $A_C(a)$ as axioms to branch on, as we are also interested in justifications that differ only in the query that they entail. This is necessary because one combination of fluent axioms might entail several queries and in order to find all of them, we also need to branch by the query that is entailed, not only by the fluent axioms."}, {"title": "4.3 Schema-Leveraging Algorithm", "content": "Looking at the generated HSTs, e.g. in Figure 3, we observe that many justifications are structurally the same and only differ in the individuals used in the ABox axioms (Observation O3). This is especially undesired in cases where there are many individuals that occur in the same Abox axioms. This can e.g. happen if the individuals describe waypoints that can all be occupied by all mobile objects. Calling SINGLEJUST is relatively costly, since each time it has to explore the space of subsets of the current ontology, and check their consistency using calls to the black box reasoner. We can thus improve the run time of our algorithm significantly if we can reduce the number of calls to SINGLEJUST.\nWe fix a set $X$ of variables. A valuation is a partial function $val: X \\rightarrow N_I$. An axiom pattern is an axiom where some individual names may be replaced by variables. Given an axiom pattern $\\mathcal{A}$, $val(\\mathcal{A})$ denotes the set of axiom patterns obtained from $\\mathcal{A}$ by replacing each variable $x$ for which $val(x)$ is defined by $val(x)$.\nDefinition 5. A justification schema is a pair $(\\mathcal{J}, Val)$ s.t. $\\mathcal{J}$ is a set of axiom patterns, Val is a set of valuations, and for each $val \\in Val$, $val(\\mathcal{J})$ is a subset-minimal set s.t. $val(\\mathcal{J}) \\models \\bot$. We then call $val(\\mathcal{J})$ an instantiation of $(\\mathcal{J}, Val)$.\nWhenever a justification $J$ is found, we construct the corresponding axiom patterns A by replacing every individual by a distinct variable in the axioms of the justification. After that, we identify the associated justification schema $(\\mathcal{J}, Val)$, i.e. we search in the ontology $(O \\cup F \\cup Q_C)$ for fitting axioms to compute all valid valuations val, taking into account also the static type of the query. This check is purely syntactic and therefore much faster than computing the justifications with a reasoner. Using the justification schema, we compute all justifications that follow the same schema by computing $val(\\mathcal{J})$ for all valuations val in the schema. The found justification are then added to the set of all found justifications. This change in the algorithm does not affect the correctness result from Theorem 5 as it does not affect the structure of the hitting-set tree."}]}