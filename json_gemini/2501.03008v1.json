{"title": "Quality Estimation based Feedback Training for Improving Pronoun Translation", "authors": ["Harshit Dhankhar", "Asif Ekbal", "Baban Gain", "Yogesh Mani Tripathi"], "abstract": "Pronoun translation is a longstanding challenge in neural machine translation (NMT), often requiring inter-sentential context to ensure linguistic accuracy. To address this, we introduce ProNMT, a novel framework designed to enhance pronoun and overall translation quality in context-aware machine translation systems. ProNMT leverages Quality Estimation (QE) models and a unique Pronoun Generation Likelihood-Based Feedback mechanism to iteratively fine-tune pre-trained NMT models without relying on extensive human annotations. The framework combines QE scores with pronoun-specific rewards to guide training, ensuring improved handling of linguistic nuances. Extensive experiments demonstrate significant gains in pronoun translation accuracy and general translation quality across multiple metrics. ProNMT offers an efficient, scalable, and context-aware approach to improving NMT systems, particularly in translating context-dependent elements like pronouns.", "sections": [{"title": "Introduction", "content": "Document translation is a critical application of machine translation (MT), facilitating cross-lingual transfer of knowledge. In an increasingly interconnected world, multilingual communication is essential to ensure equitable access to information and services. Despite advances in neural machine translation (NMT) models and the rise of large language models (LLMs), document translation remains a challenging and relevant area of research. Traditional MT systems often process sentences independently, which can lead to inconsistencies in terminology and style across a document.\nDocument translation addresses these limitations by leveraging contextual information across sentences, paragraphs, or entire documents to produce more coherent and accurate translations. For instance, incorporating document-level context improves the handling of anaphora, lexical disambiguation, and stylistic consistency.\nVarious techniques have been employed in literature to fine-tune MT models, with the most prominent ones being: a) Supervised fine-tuning (SFT), which uses labeled data to fine-tune the model in a supervised fashion, and b) Reinforcement Learning from human feedback (RLHF) which is based on optimizing a reward function based on expert judge rankings (human preferences) and using it with Proximal Policy Optimization (PPO) to fine-tune the model. One of the major drawbacks of both methods is the explicit dependence on human experts to either label huge datasets or rank candidate translations. Furthermore, training PPO involves tuning a large set of hyperparameters and loading multiple models (reference, critic, and reward), which comes at the expense of computational power and expansive memory resources. Although less stable and faster than SFT, RLHF using PPO has shown superior performance in aligning models.\nVarious attempts have been made to integrate feedback to improve the quality of translations in the field of neural machine translation (NMT) as well. Although a few works employ real but limited human feedback, others focus on using similarity scores between candidates and reference translation as a simulated human feedback. Quality Estimation (QE) models have recently been proven to be an adept proxy for real human feedback-based reward models. These QE models, facilitated by the advent of more human evaluation data and better language models, provide a numerical score to indicate the quality of candidate translation. Our proposed framework is based on exploiting these QE model evaluations to assist the feedback training process iteratively, bypassing the requirement to perform human evaluations since it is very costly in most cases."}, {"title": "Related Works", "content": "Incorporating context is generally better than context-agnostic models. The"}, {"title": "Methodology", "content": ""}, {"title": "Framework", "content": "Given a pre-trained MT model \\(M_\\theta(x, \\theta_0)\\) with initial parameters \\(\\theta_0\\), which generates an output y based on multinomial sampling with underlying distribution \\(P_{M_\\theta}(y|x; \\theta_0)\\), our aim is to guide the model to generate better translations with a focus on pronouns using a QE-based reward function r(x, y). Note that the QE-based reward function does a reference-free estimation of the translation quality. We define the optimization objective as:\n\\begin{equation}\n\\max_\\theta E_{x\\sim D, y\\sim p_M(y|x;\\theta)}r(x, y).\n\\tag{1}\n\\end{equation}\nIn each iteration i, we choose a batch of sentence pairs {Xi, Yi} of size B. For each sample input \\(X_p \\in X_i\\), we then generate k candidate translations \\(y^1, y^2, ....y^k\\). Then, we extract the pronoun of interest from each candidate \\(y^j \\forall j\\) and calculate the reward as defined in (2). This helps our framework to choose the best proxy for human feedback (best candidate translation, say y*) and update the model parameters using iterative supervised fine-tuning (SFT). This iterative training process is presented in Algorithm 1."}, {"title": "Reward function", "content": "The reward function used for training is a linear combination of pronoun-based and translation-based reward metrics. For a given pair of sentences (xp, yp) containing the target pronoun token \\(Y_{p_i}\\) and a generated candidate translation \\(y_i^j\\), we assess overall translation quality using the COMET model \"wmt21-comet-qe-da\" that employs a reference-free evaluation approach and is built on the XLM-R architecture. This gives us Rtranslation, a normalized score between -1 and 1, where 1 means perfect translation. Next, to assess the pronoun translation reward RPGL, we identify the pronoun token \\(y_k^j\\) in candidate translation \\(y^j\\) and its \"Pronoun Generation Likelihood (PGL)\" defined as: \\(P(y_{k_j}| X_p, y_{k_{1:j-1}};\\theta)\\). If the pronoun token matches with that in reference translation, then we set the pronoun reward to PGL itself. If it does not, then it is set to -PGL. Lastly, if no pronoun token in present in the candidate in the first place, RPGL is set to 0. We are now in a position to define the overall reward r(x, yj) in Equation 2.\n\\begin{equation}\nr(x,y^j) = \\beta \\cdot R_{PGL} + \\alpha R_{translation}\n\\tag{2}\n\\end{equation}"}, {"title": "Experiments", "content": ""}, {"title": "Data for training", "content": "While a contrastive test-suite to assess pronoun translation quality called Contrapro is available, we found it to contain relatively shorter and easy-to-translate source sentences which makes it trivial for fine-tuning a pre-trained MT model. This motivated us to design our own Europarl-based filtered dataset. We start preparing our training data by adopting Europarl our base EN <-> DE sentence corpus. It contains 1920209 sentence pairs of English and German languages. To make the dataset suited for pronoun translation we adopt the following filtering process: for each pair of sentences (s, t) in English and German, extract iff\n\u2022 s contains the English pronoun it, and t contains a German pronoun that is third person singular (er, sie or es), as indicated by their part-of-speech tags.\n\u2022 Those pronouns are aligned to each other.\nNote that we only consider the pronoun \"it\" and its German translations \"er\" (Masculine), \"sie\" (Feminine) or \"es\" (Neutral) due to the crucial dependence on source or target side context for its translation quality. This corpus filtering process is also"}, {"title": "Training details", "content": "We begin the training process by considering a base pre-trained model. For our experiments, we chose the distilled 600M parameter variant of NLLB-200. In this model, we deploy an iterative Supervised Fine Tuning (SFT) trainer using the trl package from transformers library. This helps us to fine tune the model parameters on the reward-chosen candidates iteratively for each mini-batch. We choose the batch size B = 4 for our experiments. For each input sentence xp in a mini-batch, we generate k = 10 candidate translation (y1, y2...y10) through multinomial sampling. The \"most-suited\" candidate y is then greedily chosen for each sample in the mini-batch and fed into the Iterative-SFT Trainer to update the model parameters. We run the trainer for a maximum of 700 iterations with a learning rate of 6e-5 and gradient accumulation steps = 16. For assessing the model in a document-level setting, we first fine-tuned the model on a subset of our filtered dataset using Huggingface's trainer class. For fine-tuning, we train the model for 3 epochs with the hyperparameters mentioned in Table 1. This is done so that model learns to use the context but not output it in translation during generation. We perform SFT training for without-"}, {"title": "Evaluation", "content": ""}, {"title": "Training evaluation:", "content": "During training, we test model's progress in each iteration by calculating \\(R_{translation}\\) and \\(R_{PGL}\\) and averaging it over the mini-batch. These plots are presented in Fig. 3 for with-context model training and Fig. 2 for the without-context case. Moreover, in every 100 iterations, we perform a validation analysis during training. We calculate the average training reward and the cross-entropy loss in the validation set. We use these scores to keep track of model's training and to choose the model checkpoint with the highest training reward on validation set."}, {"title": "Testing evaluation:", "content": "We evaluate the best model checkpoint found during training based on several open-source benchmarks as listed below:\n\u2022 BLEU (Bilingual Evaluation Understudy)\n\u2022 COMET (Crosslingual Optimized Metric for Evaluation of Translation): We employ two versions of COMET. For direct assessment, we use the Unbabel/wmt22-comet-da model, which is fine-tuned on human evaluation data from the WMT22 Metrics Shared Task and name this COMET in the results. For quality estimation without reference translations, we use the 'wmt21-comet-qe-da' model and"}, {"title": "Results", "content": "We present the translation assessment of NLLB 600M - distilled when trained on different chosen configurations in Table 3. The evaluation results reveal that incorporating document-level context significantly enhances both pronoun-specific and general translation quality, as demonstrated by the superior performance of context-aware models across all metrics. For instance, in the EN DE direction, the context-aware ProNMT achieved a COMET score of 81.92 and a BLEU score of 26.95, compared to 73.95 and 15.2630, respectively, for the context-agnostic model. Pronoun-specific rewards, particularly those leveraging Pronoun Generation Likelihood (PGL), led to notable improvements in pronoun handling, with the context-aware model achieving a PGL score of 0.4183 versus 0.3672 for the baseline. However, models trained solely with PGL rewards underperformed on overall translation metrics, highlighting the importance of balancing PGL with Quality Estimation (QE) rewards. The combined use of QE and PGL rewards, optimized with appropriate weight configurations, yielded the best results, as evidenced by consistent improvements in batch-wise rewards during training. Context-agnostic models struggled to resolve inter-sentential dependencies, further underscoring the necessity of leveraging document-level context for coherent and accurate translations.\nWe observed two key trends in the evaluation results: first, the inclusion of document-level context significantly enhances both pronoun-specific and overall translation quality, as evidenced by the context-aware ProNMT achieving higher scores across metrics such as COMET (81.92 vs. 73.95) and BLEU (26.95 vs. 15.2630) compared to its context-agnostic counterpart.\nSecond, ProNMT's ability to jointly optimize QE and pronoun-specific rewards led to consistent improvements in external metrics like COMET and BLEU, particularly when both reward components (\\(\\alpha \\neq 0, \\beta \\neq 0\\)) were employed. This balance of rewards proved crucial for achieving concurrent gains in general translation quality and accurate handling of linguistically challenging pronoun translations."}, {"title": "Conclusion", "content": "In this paper, we introduced ProNMT, a novel framework designed to address the longstanding challenges of pronoun translation in Neural Machine Translation (NMT) systems. By leveraging Quality Estimation (QE) models and the Pronoun Generation Likelihood-Based Feedback mechanism, ProNMT effectively improves both pronoun-specific and overall translation quality without the need for extensive human annotations. Our method uniquely integrates QE-based evaluations with pronoun-specific rewards, guiding iterative fine-tuning processes that are scalable, efficient, and context-aware.\nExtensive experimental evaluations demonstrated that ProNMT consistently outperforms baseline systems across multiple metrics, including COMET, BLEU and QE models. Importantly, incorporating document-level context significantly enhanced the handling of linguistically complex elements, such as pronouns, while maintaining high performance on general translation tasks. These results validate the framework's ability to address both inter-sentential dependencies and broader document coherence in machine translation."}, {"title": "Appendix", "content": ""}, {"title": "Training on all German pronouns", "content": "In our initial experiments, we tried to incorporate all German pronouns into our training framework. We considered the following consolidated list of pronouns: ['mein', 'uns', 'euer', 'ihnen',\n'der', 'ihm', 'die', 'euch', 'diesen', 'unser', 'dem',\n'denen', 'dieses', 'meinem', 'den', 'diese', 'du',\n'seiner', 'meines', 'das', 'ich', 'deiner', 'dich', 'dir',\n'meiner', 'meinen', 'es', 'meine', 'wir', 'sein',\n'ihn', 'deren', 'diesem', 'sie', 'dessen', 'dieser',\n'mich', 'ihr', 'mir', 'derer/deren', 'dein', 'ihrer',\n'er']. Upon running ProNMT on this pronoun list, we get the results presented in Fig. 5. We attribute the noisy nature of the training curves to the noise introduced by the PGL reward and the possible ambiguity associated with translation in this scenario"}, {"title": "Source side token distribution in datasets", "content": "In this section, we will contrast the Europarl and Contrapro datasets with respect to the source side sentence token count distribution. Performing a basic statistical analysis, we get the results as presented in Table 4 and Figure 5."}, {"title": "Limitations", "content": "We identify the following limitations in our work:\n\u2022 The experiments were conducted only for NLLB 600M distilled variant. To assess the robustness of our framework across MT models, we can expand the scope of our chosen models.\n\u2022 The current framework only accommodates the translation of the pronoun \"it\". We can extend the framework to include non-overlapping pronouns, i.e., pronouns whose translation is not ambiguous.\n\u2022 We could not perform hyperparameter tuning for the SFT model training. The hyperparameters presented in Table 1 are default hyperparameters.\n\u2022 We only consider the EN\u2192DE direction in our experiments as it is considered to be a more difficult task than the opposite direction in MT."}]}