{"title": "Cross Dataset Analysis and Network Architecture Repair for Autonomous Car Lane Detection*", "authors": ["Parth Ganeriwala", "Siddhartha Bhattacharyya", "Raja Muthalagu"], "abstract": "Transfer Learning has become one of the standard methods to solve problems to overcome the isolated learning paradigm by utilizing knowledge acquired for one task to solve another related one. However, research needs to be done, to identify the initial steps before inducing transfer learning to applications for further verification and explainablity. In this research, we have performed cross dataset analysis and network architecture repair for the lane detection application in autonomous vehicles. Lane detection is an important aspect of autonomous vehicles' driving assistance system. In most circumstances, modern deep-learning-based lane recognition systems are successful, but they struggle with lanes with complex topologies. The proposed architecture, ERF-CondLaneNet is an enhancement to the CondlaneNet used for lane identification framework to solve the difficulty of detecting lane lines with complex topologies like dense, curved and fork lines. The newly proposed technique was tested on two common lane detecting benchmarks, CULane and CurveLanes respectively, and two different backbones, ResNet and ERFNet. The researched technique with ERF-CondLaneNet, exhibited similar performance in comparison to Resnet-CondLaneNet, while using 33% less features, resulting in a reduction of model size by 46%.", "sections": [{"title": "I. INTRODUCTION", "content": "Transfer Learning (TL) has been researched extensively in deep learning algorithms for re-purposing models to achieve different tasks without re-training the network repeatedly. A fundamental challenge associated with these supervised deep learning systems are the requirement for large amounts of labeled data, which can be excessively expensive or difficult to obtain in certain cases. Every supervised learning task needs a unique labeled dataset, and training a cutting-edge deep learning model needs substantial computation resources. As a result, Transfer learning has been explored as an option to reduce the training time, improve performance, use less amount of data, thus reducing the computational expense.\nIn this work, we introduce ERF-CondLaneNet which is an enhanced lane identification framework with the purpose of solving and easing the difficulty of detecting lane lines with complex topologies such as curved lanes in varying road conditions. We integrate CondLaneNet [4] with ERFNet [12] and integrate transfer learning protocols to test on two different lane detecting benchmarks, CULane [1] and CurveLanes [22] respectively. In this research, we have performed cross-dataset analysis [16] to design a method which retains precision while using a significantly less feature space on both benchmark datasets.\nCurrent research in developing lane-detection algorithms with state-of-the-art performance has grown exponentially. Some use mathematical models [19] to describe the structure of a given lane whereas others address lane detection as an energy minimization problem [21]. Traditional lane identification approaches often use hand-crafted operators to extract features [15] and then match the line shape using post-processing techniques such as the Hough transform [3][23] and Random Sampling Consensus (RANSAC) [13][2]. Others have approached the problem by segmenting the lane using supervised learning models, however, most of these algorithms confine their solutions to recognizing road lanes in a single frame of the driving environment, resulting in poor performance when dealing with demanding driving circumstances such as high shadows, severe road mark deterioration, and extreme vehicle occlusion. In certain cases, the lane may be anticipated in the wrong direction, identified just partially, or not detected at all. One of the key reasons is the information offered by the present frame selected by the researchers is insufficient for accurate lane recognition or prediction. These approaches failed to retain resilience in real-world settings because hand-crafted models cannot cope with the diversity of lane lines in diverse circumstances.\nThe objective of our research is as enumerated next:\ni) Exploring TL principles with architecture repair while retaining the precision of the existing models.\na) Extend an existing model with a backbone trans- former encoder to decrease the amount of features taken by the supervised learning pipeline.\nb) Maintain a similar or higher F-1 score for bench- mark datasets.\nii) Unify the machine learning (ML) model by incorporat- ing a diverse range of road conditions.\na) Investigate TL concepts for cross-dataset analysis."}, {"title": "II. RELATED WORK", "content": "This section describes the current deep-learning-based lane detection systems. Current approaches may be grouped into two groups depending on the strategy of line form description: Convolutional Neural Network (CNN) models, Deep Learning (DL) methods."}, {"title": "A. Convolutional Neural Network Models", "content": "Convolutional neural networks (CNNs) are used in recent lane identification techniques to train deep learning models using popular benchmarks such as TuSimple [17] and CULane [1]. Hang et al. [8] proposes two CNN techniques which are Feature Size Selection (FSS) and Degressive Dilation Block (DD Block). They introduced these methodologies to modify the existing semantic segmentation networks. EDANet [7] was chosen as their baseline architecture due to it having a good balance between the efficiency and performance speed for a well defined autonomous driving model. For proper lane lo-calisation, precise geographical information is required and so EDANet features three downsampling processes, whereas most CNNs contain multiple downsampling layers. The modified network achieved an Mean Intersection over Union (MIOU) score of 75.0 on the ITRI dataset.\nLiu et al. [6], presented a method for increasing the en-vironmental flexibility of the lane detector using Generative Adversarial Networks (GANs) to produce pictures in low-light circumstances. Their suggested approach is divided into three parts: the SIM-CycleGAN, the light conditions style transfer, and the lane identification network. They used ERFNet to evaluate their approaches on the lane detection benchmark CULane and received a 73.9 F-1 score. Researchers have also worked on formulating feed-forward networks (FFNs) for parameter predictions which are then passed on and trained with a Hungarian fitting loss [5]. This end-to-end model outputs parameters of a lane shape model based on a network which is built with a transformer encoder to capture and learn richer features from the images.\nAccording to Wang et al. [18], even if the accuracy of lane line prediction is improving, the capacity of lane markings to localize is rather limited, especially when the lane marking location is remote in nature. They offer a multi-task strategy that combines CNN's network to model semantic informa-tion with the high localization ability supplied by handmade features and forecasts the position of the vanishing line."}, {"title": "B. Deep Learning Methods", "content": "Xu et al. [22], provide CurveLane-NAS, a novel lane-sensitive architecture search framework for autonomously col-lecting both long-ranged coherent and accurate short-range curve information. It has three search modules: a feature fusion search module to investigate a better fusion of the local and global context for multi-level hierarchy features; an elastic backbone search module to investigate an efficient feature ex-tractor with good semantics and latency; and an adaptive point blending module to investigate a multi-level post-processing refinement strategy to combine multi-scale head prediction. They also introduce the benchmark called CurveLanes [14] to include the most problematic curve lanes. It has 150K images and 680K labels and their procedure model achieves an F1-score of 80. Researchers [4] introduce CondLaneNet which is a unique top-to-down lane identification framework that identifies lane instances first and then predicts the line shape for each instance dynamically. The research provides a conditional lane detection technique based on conditional convolution and row-wise formulation to re-solve the lane instance-level discriminating problem. Furthermore, they also introduce the Recurrent Instance Module (RIM) to address the issue of recognizing lane lines with complicated topologies, such as dense lines and fork lines. The advantage from their method is the real-time efficiency and end-to-end pipeline, which requires minimum post-processing. Furthermore, this approach combines accuracy and efficiency, as seen by a 78.14 F1 score and 220 FPS on CULane [1]. LaneNet is a deep learning module which has been presented by Neven et al. [9], which performs end-to-end lane detection by combining binary lane segmentation with a clustering loss function designed for one-shot instance segmentation. The network generates parameters of a perspective transformation where lane fitting is optimal.\nWang et al. [20], devised a lane detecting approach that is comprised of two deep neural networks. The lane edge proposal network uses the initial input image of a vehicle's front view to generate a lane edge proposal map. The lane line localization network is then in charge of determining the position of each lane given by the lane edge map. The use of a deep neural network endows the method with great robustness, and the two-stage detection pipeline reduces computational cost and allows the lane line localization network to be trained in a manner that combines supervised and weakly supervised learning, resulting in a significant reduction in the cost of labeling training data."}, {"title": "III. PROPOSED METHODOLOGY", "content": "In this section, we elaborate on our proposed methodology Cross Dataset Analysis with Network Refinement (CDANR) shown in Figure 1, to evaluate a transfer learning approach with architecture/network refinement. According to CDANR, initially cross dataset testing needs to be performed on the existing CondLaneNet and ERFNet architecture using the benchmark datasets, CULane and CurveLanes. Then the initial results are evaluated and analyzed to check if it meets the objectives/requirements. Initial experiments were conducted on both existing architectures ERFNet and CondLaneNet with respect to accuracy of the model as well as the number of fea-tures it uses. After evaluating, we found out that while Cond-LaneNet achieved great accuracy, it was using significantly more features than ERFNet which has been been discussed in further sections. To lay the groundwork for future transfer learning applications, it was necessary to use less parameters, and have a more generic feature extraction which we can obtain from ERFNet when compared to ResNets. Therefore, changes were made to incorporate ERFNet's architecture into the existing architecture as backbone in CondLaneNet."}, {"title": "A. ERFNet Model", "content": "ERFNet is a semantic segmentation architecture which enables the more effective use of parameters, by allowing the network to achieve very high segmentation accuracy even with a reduced feature set while satisfying resource constraints. ERFNet's implementation of the residual layer, uses the 1D factorization to speed and reduce the parameters of the original non-bottleneck layer, takes advantage of this decomposition. This module is known as \"non-bottleneck-1D\" (non-bt-1D), as it is faster and has fewer parameters than the bottleneck design while maintaining the same learning capacity and accuracy. According to Romera et al. [12], 1D kernels can be factorized for both non-bottleneck and bottleneck implementations. The non-bottleneck architecture clearly benefits more, with a direct 33% reduction in both convolutions and a significant reduction in execution time. To incorporate it within the CondLaneNet Architecture we made changes to the ERFNet Model. CondLaneNet uses ResNets, as part of their transformer encoder block. The ResNet model, has 34 convolutional layers, with 64 to 2048 feature maps being computed internally through various layers. The original ERFNet model, has 23 convolutional layers with an encoder and decoder block and 8 non-bt-1D convolutional blocks being used. For ResNets, at each residual layer, 256 feature maps are received at the module input, however the non-bt-1D convolu-tional architecture used in ERFNet, uses only 64 feature maps. This reduces the number of features extracted from the input, while keeping the same performance. The updated ERFNet model was configured to interface with the CondLaneNet architecture and the benchmark datasets. While synchronizing the configurations, 8 additional non-bt-1D bottleneck blocks were added to encase the \"extra\" features from the input. Also, 2 extra de-convolutional layers were added to upsample the features to the pixel dimensions of the input. Additionally, one downsampling layer and one upsampling layer were added to correlate with the input image dimensions from both the benchmark datasets."}, {"title": "B. CondLaneNet Architecture", "content": "Conditional Lane Detection [4] is a lane detection method based on conditional convolution, which is type of convo-lutional configuration containing adjustable kernel parame-ters that focus on instance-level distinguishing features. This method can be divided into two individual dependent steps: instance detection and shape prediction. For each instance, the instance detection step identifies the object instance and regresses a set of dynamic kernel parameters. Conditional convolutions are used to determine the instance shape in the shape prediction stage. This approach takes advantage of dynamic kernel settings. Shapes may be predicted instance by instance because each instance corresponds to a set of dynamic kernel parameters. This method achieved state-of-the-art performance on instance segmentation tasks [4]. How-ever, applying the conditional instance segmentation technique directly to lane detection is ineffective. Additionally, due to the extremely large degree of flexibility, segmentation-based shape prediction is inefficient for lane lines [11]. To address the above-mentioned issues, the conditional lane detection technique enhances shape prediction and instance identifi-cation. However, when this architecture was tested with a cross-dataset approach, i.e. trained on $T_{r_i}$, tested on $T_{e_j}$ and trained on $T_{r_j}$, tested on $T_{e_i}$, where i, j are two different datasets, CondLaneNet gives a poor performance. CULane and CurveLanes were used for the cross-dataset approach and it was observed that both models (one trained on CULane and the other on CurveLanes) perform poorly when tested on CurveLanes and CULane respectively."}, {"title": "C. CondLaneNet Architecture Repair with ERFCondLaneNet", "content": "To the best of our knowledge, through related works, there are generally two strategic machine learning approaches for improving a technique. Either focus is given on improving the accuracy which involves develop complex architectures that are computationally expensive, or the efficiency is improved (reducing model size, feature set decomposition, faster model inference time) by making significant sacrifices in network design in exchange for accuracy. Our approach is focused on improving the core elements of the CondLaneNet archi-tecture: the convolutional blocks. We utilize the conditional lane identification technique, which is based on conditional convolution and row-wise formulation, to address the issue of instance-level discrimination. We investigate re-designing the frequently used residual layers in order to make them more efficient while maintaining equivalent learning performance. Additionally, we evaluate the need for transfer learning as the existing model's accuracy varies when tested on untrained datasets. While this design may be utilized to improve current designs, we present CDANR which is an initial validation step to apply transfer learning to any particular problem. So in essence, we propose initial cross-dataset analysis, followed by architecture change by network repair as a necessity before applying computationally expensive transfer learning techniques."}, {"title": "IV. EXPERIMENTATION", "content": "To extensively evaluate CDANR, we conducted experiments on three benchmarks: CurveLanes [14], CULane [10], and TuSimple [17]. CurveLanes is a new benchmark that deals with difficult topologies including fork lines and dense lines. CULane is a big lane detection dataset with nine different scenarios that is regularly utilized. Another extensively used collection of highway driving situations is TuSimple."}, {"title": "A. Datasets", "content": "1) CULane: CULane is a large-scale, complex dataset for academic traffic lane detection research. It was gathered by cameras set on six separate automobiles throughout Beijing, each driven by a different driver. A total of 133,235 frames were retrieved from more than 55 hours of video. The dataset was split into three sections: 88880 images for training, 9675 images for validation, and 34680 images for testing. The test set was organized into nine categories, each of which corresponds to varying atmospheric and road conditions.\n2) TuSimple: The dataset was partitioned into training and testing sets, including 3626 video clips and 3626 annotated frames in training and 2782 video clips in testing. The clips are each a one-second clip with 20 frames, with the camera's view direction fairly close to the driving direction. Poly lines for lane markings are the annotations. Although most lanes have four lane markings (current lane, left/right lanes), there are at most five lane markings for some lanes. When changing lanes, the extra lane is employed since it is difficult to discern which lane is the current one.\n3) CurvedLanes: CurveLanes is a new benchmark lane detection dataset with 150K lanes pictures with a diverse range of traffic lane detection scenarios like curves and multi-lanes. It was gathered in numerous Chinese cities in real-world urban and highway environments. It's the world's largest lane detection dataset to date, and it sets a higher bar for the machine learning community.\nThe entire 150K dataset is divided into three sections: train: 100K, validation: 20K, and testing: 30K. The majority of the photos in this dataset have a resolution of 2650 \u00d7 1440 pixels."}, {"title": "V. RESULTS AND DISCUSSION", "content": "Cross dataset evaluation is very uncommon due to the com-patibility issues between the data. In this work, we performed cross dataset analysis to assess whether architectural changes are a definitive step before inducing transfer learning. To do this, the model with existing CondLaneNet architecture was trained on the CurveLanes Dataset and then tested with the CULane dataset. Consequently, the model was trained on CULane dataset and tested on CurveLanes. A similar process flow was taken for the TuSimple dataset as well. The training testing ratio was taken as 70:30 and uniform test sets have been used in this analysis.\nWe also trained the ERFNet model using the CULane Dataset, and after testing, we obtained a 97.78% IoU (Inter-section over Union) as shown in Table I. A total F-1 score of 0.7357 was recorded for CULane. Among the 9 categories present in the CULane Dataset, for normal road conditions was 0.9170 and for curved road conditions it was 0.6672.\nFor TuSimple Dataset which was trained and tested with ERFNet, we recorded a 98.35% IoU and the accuracy was 93.39%. However, due to TuSimple not having an extensive amount of features in comparison to CULane, it was disre-garded and not used in further evaluation."}, {"title": "B. Initial Cross Dataset Analysis", "content": "For the initial analysis as shown in Table II, we see that the CondLaneNet Architecture Model trained on CULane gives a moderately good F-1 Score of 0.7948 when tested on itself. It is also observed that the model when trained on CurveLanes gives a good F-1 Score of 0.8610 when tested on itself. In the first case, when the model was trained on CurveLanes and tested on CULane, we found that the F-1 score was 0.6545 but upon further investigation the recall and precision were balanced. Thus, we assume that there was a training issue and it requires different types of data to be included. For the second case where it was trained on CULane and tested on CurveLanes, we see an unusual performance where the F-1 score was 0.526 but the precision was 0.8168 and recall was 0.388 and an imbalance in recall and precision was noted. This explains that the model was not able to predict/detect curved lanes in entirety but the ones it does detect are accurate given by the high precision. In our proposed approach, we investigated architectural changes with transfer learning, if the problem can be solved."}, {"title": "C. Architecture Repair & Cross Dataset Analysis", "content": "Following, the introduction of our proposed architecture, ERFNet retained the F-1 score in other scenarios as shown in the Table III. ERFNet, due to the improved bottleneck method takes less amount of parameters during training when compared to ResNets. With 33% less feature parameters being used, it resulted in significantly reduced while maintaining the F-1 score measure. We see a slight increase in F-1 score to 0.6915, when the model was trained on CurveLanes and tested on CULane. This is due to the fact that straight lines are a subset of curved lanes. There was a further decrease in F-1 score associated with the CULane vs CurveLanes test. We assume that models trained on straight lanes cannot detect and predict curved lanes as can be seen with decreased performance for both ResNets and ERFNet. The exponential decrease in the F-1 score for ERFNet is assumed to be due to usage of lesser features based on the bottleneck method which led to lesser F-1 Score in the last case. It is expected to maintain the accuracy, an inductive transfer learning architecture will be required to align the knowledge with the learning system."}, {"title": "VI. CONCLUSION", "content": "In this study, a new architecture was proposed that consisted of ERFNet-CondLaneNet, which is an integrated car lane detection architecture with ERFNet's semantic segmentation network as the backbone. Cross dataset testing was performed to evaluate if existing architectures met the objectives. The initial results demonstrated poor performance while being computationally expensive by the existing architectures. After evaluation, refinements were proposed to the network ar-chitecture, that was then integrated and interfaced with the architecture. Using the proposed architecture, cross dataset analysis was carried out on benchmark datasets CULane and CurveLanes. During the implementation of the model, it was found out the new architecture uses less amount of parameters giving a significantly smaller model size, while retaining the same accuracy as other models in the car lane detection domain. Therefore, with a generalised feature ex-traction, where specific features are not considered, we can indeed retain the same accuracy. This lays the groundwork to further transfer learning applications for cross-vehicular lane detection systems. Although, cross-vehicular lane detection systems perform the same task, the semantic of lanes changes. For example, automobiles have lanes on the road which they have to stay within, aircrafts have lanes to stay within and the central line to adhere to."}]}