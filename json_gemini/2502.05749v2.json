{"title": "UniDB: A Unified Diffusion Bridge Framework via Stochastic Optimal Control", "authors": ["Kaizhen Zhu", "Mokai Pan", "Yuexin Ma", "Yanwei Fu", "Jingyi Yu", "Jingya Wang", "Ye Shi"], "abstract": "Recent advances in diffusion bridge models leverage Doob's h-transform to establish fixed endpoints between distributions, demonstrating promising results in image translation and restoration tasks. However, these approaches frequently produce blurred or excessively smoothed image details and lack a comprehensive theoretical foundation to explain these shortcomings. To address these limitations, we propose UniDB, a unified framework for diffusion bridges based on Stochastic Optimal Control (SOC). UniDB formulates the problem through an SOC-based optimization and derives a closed-form solution for the optimal controller, thereby unifying and generalizing existing diffusion bridge models. We demonstrate that existing diffusion bridges employing Doob's h-transform constitute a special case of our framework, emerging when the terminal penalty coefficient in the SOC cost function tends to infinity. By incorporating a tunable terminal penalty coefficient, UniDB achieves an optimal balance between control costs and terminal penalties, substantially improving detail preservation and output quality. Notably, UniDB seamlessly integrates with existing diffusion bridge models, requiring only minimal code modifications. Extensive experiments across diverse image restoration tasks validate the superiority and adaptability of the proposed framework.", "sections": [{"title": "1. Introduction", "content": "The diffusion model has been extensively utilized across a range of applications, including image generation and edit- ing (Ho et al., 2020; Kawar et al., 2022; Song et al., 2021; Xia et al., 2023; Li et al., 2023), imitation learning (Wu et al., 2024; Chi et al., 2024; Ze et al., 2024) and reinforcement learning (Yang et al., 2023; Ding et al., 2024a), etc. Despite its versatility, the standard diffusion model faces limitations in transitioning between arbitrary distributions due to its inherent assumption of a Gaussian noise prior. To overcome this problem, diffusion models (Dhariwal & Nichol, 2021; Ho & Salimans, 2022; Murata et al., 2023; Ding et al., 2024b; Chung et al., 2024; Tang et al., 2024) often rely on meticulously designed conditioning mechanisms and classifier/loss guidance to facilitate conditional sampling and ensure output alignment with a target distribution. However, these methods can be cumbersome and may introduce manifold deviations during the sampling process. Meanwhile, Diffusion Schr\u00f6dinger Bridge (Shi et al., 2023; Bortoli et al., 2023; Somnath et al., 2024) involves constraints that hinder direct optimization of the KL divergence, resulting in slow convergence and limited model fitting capability.\nTo address this challenge, DDBMs (Zheng et al., 2024) proposed a diffusion bridge model using Doob's h-transform. This framework is specifically designed to establish fixed endpoints between two distinct distributions by learning the score function of the diffusion bridge from data, and then solving the stochastic differential equation (SDE) based on these learned scores to transition from one endpoint distribution to another. However, the forward SDE in DDBMS lacks the mean information of the terminal distribution, which restricts the quality of the generated images, particularly in image restoration tasks. Subsequently, GOUB (Yue et al., 2024) extends this framework by integrating Doob's h-transform with a mean-reverting SDE, achieving better results compared to DDBMs. Despite the promising results in diffusion bridge with Doob's h-transform, two fundamental challenges persist: 1) the theoretical mechanisms by which Doob's h-transform governs the bridging process remain poorly understood, lacking a rigorous framework to unify its empirical success; and 2) while effective for global distribution alignment, existing methods frequently degrade high-frequency details such as sharp edges and fine textures-resulting in outputs with blurred or oversmoothed artifacts that compromise perceptual fidelity. These limitations underscore the need for both theoretical grounding and enhanced detail preservation in diffusion bridges."}, {"title": "2. Related Work", "content": "Diffusion with Guidance. This technique tackles conditional generative tasks by leveraging a differentiable loss function for guidance without the need for additional training (Chung et al., 2024; Shenoy et al., 2024; Bradley &"}, {"title": "3. Preliminaries", "content": "3.1. Denoising Diffusion Bridge Models\nStarting with an initial d-dimensional data distribution X0 ~qdata(x), diffusion models (Song et al., 2021; Ho et al., 2020; Sohl-Dickstein et al., 2015; Song & Ermon, 2020) construct a diffusion process, which can be achieved by defining a forward stochastic process evolving from xo through a stochastic differential equation (SDE): \n$$dxt = f(xt, t)dt + gt dwt,$$\nwhere t ranges over the interval [0, T], f : Rd \u00d7 [0, T] \u2192 Rd is the vector-valued drift function, g : [0,T] \u2192 R signifies the scalar-valued diffusion coefficient and wt \u2208 Rd is the Wiener process, also known as Brownian motion. To promise the transition probability p(xt | xs) remains Gaussian, almost all the diffusion SDEs take the following linear form (Zheng et al., 2024) in (1):\n$$f(xt,t) = f(t)xt,$$\nwhere f(t) is some scalar-valued function. To realize transition between arbitrary distributions, DDBMs introduces Doob's h-transform (S\u00e4rkk\u00e4 & Solin, 2019), a mathematical technique applied to stochastic processes, which rectifies the drift term of the forward diffusion process to pass through a preset terminal point x\u30f6 \u2208 Rd. Precisely, the forward process of diffusion bridges after Doob's h-transform becomes:\n$$dxt = [f(xt,t) + g h(xt, t, xr, T)] dt + gt dwt,$$\nwhere h(xt, t, xr, T) = \u2207x\u2081 log p(xT \u2758 xt) is the h function. The diffusion bridge can connect the initial xo to any given terminal xt and thus is promising for various image restoration tasks. Meanwhile, its backward reverse SDE (Anderson, 1982) is given by\n$$dxt  = [f(x,t) + \\frac{g^2}{2}\\nabla_{x_{t}} log \\; p(x_{t} | X_{T})\n - \\frac{g^2}{2}\\nabla_{x_{t}} log \\; p(x_{t} | x_{T})] dt + g_{t} dwt.$$\nwhere wt is the reverse-time Wiener process and the unknown term x\u2081 log p(xt | xT) can be estimated by a score prediction neural network se (Song et al., 2021).\n3.2. Generalized Ornstein-Uhlenbeck Bridge\nGeneralized Ornstein-Uhlenbeck (GOU) process describes a mean-reverting stochastic process commonly used in finance, physics, and other fields in the following SDE form (Ahmad, 1988; Pavliotis, 2014; Wang et al., 2018):\n$$dxt = \u03b8t (\u03bc \u2013 xt) dt + gt dwt,$$\nwhere u is a given state vector, \u03b8t denotes a scalar drift coefficient and gt represents the diffusion coefficient with Ot, gt satisfying the specified relationship g\u00b2 = 2120t where X2 is a given constant scalar. Based on this, Generalized Ornstein- Uhlenbeck Bridge (GOUB) is a diffusion bridge model (Yue et al., 2024), which can address image restoration tasks without the need for specific prior knowledge. With the introduction of \u03bc, xt tends to \u03bc as time t progresses. Through Doob's h-transform, denote 0s:t = \u222b 0zdz, Ot = So ozdz"}, {"title": "4. Methods", "content": "4.1. Diffusion Bridges Constructed by SOC Problem\nThe forward SDE of the Diffusion Bridge with Doob's h- transform is enforced to pass from the predetermined origin 20 to the terminal xr. With a similar purpose, UniDB constructs a SOC problem where the constraints are an arbitrary linear SDE of the forward diffusion with a given initial state, while the objective incorporates a penalty term steering the forward diffusion trajectory towards the predetermined terminal xt. Meanwhile, compared with the linear drift term"}, {"title": "4.2. Connections between SOC and Doob's h-transform", "content": "We can intuitively see from the SOC problem that when \u2192\u221e in Theorem 4.1, it means that the target of SDE process is precisely the predetermined endpoint (Chen et al., 2024b), which is also the purpose of Doob's h-transform and facilitates the following theorem:\nTheorem 4.2. For the SOC problem (12), when \u2192 \u221e, the optimal controller becomes u,\u221e = gt\u2207x\u2081 log p(xx | Xt), and the corresponding forward and backward SDE with the linear SDE form (10) are the same as Doob's h-transform as in (3) and (4).\nThis theorem shows that existing diffusion bridge models using Doob's h-transform are merely special instances of our UniDB framework, which offers a unified approach to diffusion bridges through the lens of SOC.\nFurthermore, using Doob's h-transform in diffusion bridge models is not necessarily optimal, as letting the terminal penalty coefficient y \u2192 \u221e eliminates the consideration of control costs in SOC. To support this argument, we present Proposition 4.3, which asserts that the diffusion bridge with Doob's h-transform is not the most effective choice.\nProposition 4.3. Consider the SOC problem (12), denote J(ut,y,Y) Sout,y ||2 dt+2 ||x4 - xr||2 as the overall cost of the system, u, as the optimal controller (13), then\n$$J(u,v) \u2264 I(u,\u221e, \u221e).$$\nDetailed proof of Proposition 4.3 is provided in Appendix A.3. Proposition 4.3 shows that the overall cost when considering a finite y is more favorable than when y \u2192 \u221e. Existing diffusion bridge models (Zhou et al., 2023; Yue et al., 2024), which inherently assume y\u2192\u221e, often result in suboptimal performance with blurred or overly smoothed image details. Therefore, maintaining the penalty coefficient y as a hyper-parameter is a more effective approach."}, {"title": "4.3. Training objective of UniDB", "content": "In this section, we focus on constructing the training objective of UniDB. According to maximum log-likelihood (Ho et al., 2020) and conditional score matching (Song et al., 2021), the training objective is based on the forward transition p(xt | X0, XT). Thus, we begin by deriving this probability. The closed-form expression in (14) represents the mean value of the forward transition after applying reparameterization techniques. However, this expression lacks a noise component after the transformation based on the certainty equivalence principle. To address this issue, we employ stochastic interpolant theory (Albergo et al., 2023) to introduce a noise term e with \u2642 = \u2642 = 0. We define \u1f33 = T/7 similar to (7), leading to the following forward transition:\n$$p(xt | xo, xT) = N(\u03bc\u03c4,\u03b3, \u014d'121),$$,\n$$\u03bc\u03c4,\u03b3 = e \\frac{e^{f_t}}{\\dot{d}_{t,\\gamma}} (\\frac{ \\dot{d}_t}{\\dot{d}o} xo+\n\\frac{e^{f_T}g}{\\dot{d}o} -XT + (h_t - \\frac{e^{2f_t}g_t}{\\dot{d}o} m),\\$$"}, {"title": "4.4. UniDB unifies diffusion bridge models", "content": "Our UniDB is a unified framework for existing diffusion bridge models: DDBMs (VE) (Zhou et al., 2023), DDBMs (VP) (Zhou et al., 2023) and GOUB (Yue et al., 2024).\nProposition 4.4. UniDB encompasses existing diffusion bridge models by employing different hyper-parameter spaces H as follows:\n\u2022 DDBMS (VE) corresponds to UniDB with hyper-parameter Hve(ft = 0, ht = 0, y \u2192 \u221e)\n\u2022 DDBMs (VP) corresponds to UniDB with hyper-parameter Hvp(ft = \u2212\u00bdgz, ht = 0, y \u2192 \u221e)\n\u2022 GOUB corresponds to UniDB with hyper-parameter HGOU(ft = 0t, ht = \u22120t, m = \u03bc, \u03b3 \u2192 \u221e)"}, {"title": "4.5. An Example: UniDB-GOU", "content": "It is evident that these diffusion bridge models like DDBMs (VE), DDBMs (VP) and GOUB all based on Doob's h- transform are all special cases of UniDB with y\u2192\u221e. However, according to Proposition 4.3, these models are not the effective choices. Therefore, we introduce UniDB based on the GOU process (5), hereafter referred to as UniDB-GOU, which retains the penalty coefficient y as the hyper-parameter. Considering the SOC problem with GOU process (5), the optimally controlled forward SDE is:\n$$dxt =(\u03b8t +g\\frac{2}{t} \\frac{e^{-2\u03b8t:T}}{\\gamma^{-1} + \u03c3_{t:T}^{2} })(xT - xe)dt+ge dwt,$$\nand the mean value of forward transition p(xt | xo, xT) is\n$$\u03bc\u03c4 = e^{-\u03b8_t} \\frac{1+\u03b3\u03c3_{\u03c4}^{2}}{1+ \u03b3\u03c3_{\u03be}^}{e^{\u03b8_{t}}_{XO} +\n\\frac{1-e^{\u03b8t}} {\\frac{1-\\gamma \u03c3_{\u03c4}^{2}}{1+ \u03b3\u03c3_{\u03be}}} XT.$$\nTaking UniDB-GOU as an example, we highlight the key difference between UniDB-GOU and GOUB:\n\\end{aligned}\n}\nHence, only a few lines of code need to be adjusted to generate more realistic images using the same training method. Beyond the GOUB model, our UniDB framework can be similarly extended to other diffusion bridge models.\nBuilding upon equations (20) and (21), we further present a proposition to characterize how the penalty coefficient \u03b3 affects the controlled terminal distribution as follows:\nProposition 4.5. Denote the initial state distribution xo, the terminal distribution x by the controller and the predefined terminal distribution xy, then\n$$||x-XT||2=\\frac{\u0435-20\u0442}{(1 + \u03b3\u03bb\u00b2(1 \u2013 \u0435-20))}22||XT-xo||2.$$"}, {"title": "5. Experiments", "content": "In this section, we evaluate our models in image restoration tasks including Image 4\u00d7Super-resolution, Image Deraining, and Image Inpainting. We take four evaluation metrics: Peak Signal-to-Noise Ratio (PSNR, higher is better) (Fardo et al., 2016), Structural Similarity Index (SSIM, higher is better) (Wang et al., 2004), Learned Perceptual Image Patch Similarity (LPIPS, lower is better) (Zhang et al., 2018) and Fr\u00e9chet Inception Distance (FID, lower is better) (Heusel et al., 2018). For simple expressions in the following sections, UniDB (SDE) and UniDB (ODE) are applied to represent the UniDB-GOU with reverse SDE and reverse Mean-ODE, respectively. Please refer to Appendix D and E for all related implementation details and more experiment results, respectively."}, {"title": "5.1. Experiments Setup", "content": "According to Proposition 4.5, we first quantitatively analyze the 12-norm distances between the two terminal distributions depicted in Figure 2. We computed the average distances between high-quality and low-quality images in the three datasets (CelebA-HQ, Rain100H, and DIV2K) related to the subsequent experimental section as the distances ||x-xo||2 in (23). As can be seen, for all three datasets, these distances"}, {"title": "5.2. Experimental Details", "content": "Image 4\u00d7Super-Resolution Tasks. In super-resolution, we evaluated our models based on DIV2K dataset (Agustsson & Timofte, 2017), which contains 2K-resolution high-quality images. During the experiment, all low-resolution images were 4x bicubic upscaling to the same image size as the paired high-resolution images. For comparison, we choose Bicubic interpolantion (Kawar et al., 2022), DDRM (Kawar et al., 2022), IR-SDE (Luo et al., 2023), GOUB (SDE) (Yue et al., 2024) and GOUB (Mean-ODE) (Yue et al., 2024) following abbreviated as GOUB (ODE) as the baselines.\nImage Deraining Tasks. For image deraining tasks, we conducted the experiments based on Rain100H datasets (Yang et al., 2017). Particularly, to be consistent with other deraining models (Ren et al., 2019; Zamir et al., 2021; Luo et al., 2023; Yue et al., 2024), PSNR and SSIM scores on the Y channel (YCbCr space) are selected instead of the origin PSNR and SSIM. MAXIM (Tu et al., 2022), MHNet (Gao & Dang, 2023), IR-SDE (Luo et al., 2023), GOUB (SDE) (Yue et al., 2024) and GOUB (ODE) (Yue et al., 2024) are chosen as the baselines."}, {"title": "5.3. Ablation Study", "content": "Penalty Coefficient \u03b3. To evaluate the specific impact of different penalty coefficients y on model performance, we conducted the experiments above with several different \u03b3."}, {"title": "6. Conclusion", "content": "In this paper, we presented UniDB, a unified diffusion bridge framework based on stochastic optimal control principles, offering a novel perspective on diffusion bridges. Through this framework, we unify and extend existing diffusion bridge models with Doob's h-transform like DDBMs and GOUB. Moreover, we demonstrate that the diffusion bridge with Doob's h-transform can be viewed as a specific case within UniDB when the terminal penalty coefficient approaches infinity. This insight helps elucidate why Doob's h-transform may lead to suboptimal image restoration, often resulting in blurred or distorted details. By simply adjusting this terminal penalty coefficient, UniDB achieves a marked improvement in image quality with minimal code modifications. Our experimental results underscore UniDB's superiority and versatility across various image processing tasks, particularly in enhancing image details for more realistic outputs. Despite these advantages, UniDB, like other standard diffusion bridge models, faces the challenge of computationally intensive sampling processes, especially with high-resolution images or complex restoration tasks. Future work will focus on developing strategies to accelerate the sampling process, enhancing UniDB's practicality, particularly for real-time applications."}, {"title": "A. Proof", "content": "A.1. Proof of Theorem 4.1\nTheorem 4.1. Consider the SOC problem (12), denote dt,y = y\u22121 + e2fr 92:T, fs:t = So fzdz, hs:t = Se-fzhzdz and 9:t = Se-2fzg2dz, denote ft, ht and \u011f for simplification when s = 0, then the closed-form optimal controller u is\n$$uty = 9teft:TXT \\frac{Xt - me^{f_{T}}h_{t:T}}{d_{t,\\gamma}},$$\nand the transition of xt from x0 and xt is\n$$Xt = e^{f_t}(\\frac{e^{2f_Th_r}}{do})xo+\n \\frac{e^{f_Tg}}{do},\\\\gamma}XT + (ht - \\frac{e^{2f_t}g_t}{do,\\gamma} m)$$\nProof. According to Pontryagin Maximum Principle (Levine, 1972; Kirk, 1970) recipe, one can construct the Hamiltonian:\n$$H(t, xt, ut, Pt) = \\frac{1}{2}||ut,r||2 + pt (ftxt + him + gtut) .$$\nBy setting:\n$$ \\frac{\\partial H}{\\partial u_{t,\\gamma}} = 0 $$\nSolving the Equation (28), we have:\nXt = X0,\nPt = \u03b3 (XT - xt).\nSolve the Equation (27):\n$$dxt = ftxt + h\u2081m \u2013 gipt$$"}, {"title": "A.7. Derivation of UniDB-GOU (forward SDE (20) and mean value of forward transition (21))", "content": "Consider the SOC problem with GOU process (5), the optimally controlled forward SDE is\n$$dxt =(\u03b8t +g\\frac{2}{t} \\frac{e^{-2\u03b8t:T}}{\\gamma^{-1} + \u03c3_{t:T}^{2} })(xT - xt)dt+gtdwt,$$\nand the mean value of the probability p(xt | xo, xT) is\n$$M_{y} = e^{-\u03b8_{t}} \\frac{1+\u03b3\u03c3_{\u03c4}^{2}}{1+ \u03b3\u03c3_{\u03be}^}{e^{\u03b8_{t}}_{XO} +\n\\frac{1-e^{\u03b8t}} {\\frac{1-\\gamma \u03c3_{\u03c4}^{2}}{1+ \u03b3\u03c3_{\u03be}}} XT.$$\nTaking GOUB process (5) in the deterministic form:\n$$dxt = (0+(xT - xt) + gtut,y) dt, xo \u0425\u043e. $$\n$$||x4 - XT||2=\\frac{\u0435-20\u0442}{(1 + \u03b3\u043b\u00b2(1 \u2013 \u0435-20))}22||XT-xo||2.$$"}, {"title": "A.9. Proof of Proposition 4.5", "content": "Proposition 4.5. Denote the initial state distribution x0, the terminal distribution x by the controller and the pre-defined terminal distribution xy, then\n$$||x - XT||2=\\frac{\u0435-20\u0442}{(1 + \u03b3\u043b\u00b2(1 \u2013 \u0435-20))}22||XT-xo||2.$$\nTaking t = T, then\n$$||x4 - \u0445\u0442||2=\\frac{\u0435-20\u0442}{(1 + \u03b3\u043b\u00b2(1 \u2013 \u0435-20))}22||XT-xo||2.$$"}, {"title": "B. Pseudocode Descriptions", "content": "We provide the relevant simple-version pseudo-code for our UniDB-GOU model as an example regarding the training and sampling process. The two algorithms encapsulate the core methodologies employed by our model to learn and explain how to restore HQ images from LQ images. Also, the red and the green parts highlight the main difference between UniDB and GOUB."}]}