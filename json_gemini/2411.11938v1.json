{"title": "Newclid: A User-Friendly Replacement for AlphaGeometry", "authors": ["Vladmir Sicca", "Tianxiang Xia", "Mathis F\u00e9d\u00e9rico", "Philip_John_Gorinski", "Simon Frieder", "Shangling Jui"], "abstract": "We introduce a new symbolic solver for geometry, called Newclid, which is based on AlphaGeometry. Newclid contains a symbolic solver called DDARN (derived from DDAR-Newclid), which is a significant refactoring and upgrade of AlphaGeometry's DDAR symbolic solver by being more user-friendly - both for the end user as well as for a programmer wishing to extend the codebase. For the programmer, improvements include a modularized codebase and new debugging and visualization tools. For the user, Newclid contains a new command line interface (CLI) that provides interfaces for agents to guide DDARN. DDARN is flexible with respect to its internal reasoning, which can be steered by agents. Further, we support input from GeoGebra to make Newclid accessible for educational contexts. Further, the scope of problems that Newclid can solve has been expanded to include the ability to have an improved understanding of metric geometry concepts (length, angle) and to use theorems such as the Pythagorean theorem in proofs. Bugs have been fixed, and reproducibility has been improved. Lastly, we re-evaluated the five remaining problems from the original AG-30 dataset that AlphaGeometry was not able to solve and contrasted them with the abilities of DDARN, running in breadth-first-search agentic mode (which corresponds to how DDARN runs by default), finding that DDARN solves an additional problem. We have open-sourced our code under:", "sections": [{"title": "1 Introduction", "content": "General remarks. AlphaGeometry [Trinh et al., 2024] demonstrated the ability to solve geometry problems at the level of the International Mathematical Olympiad (IMO), with performance comparable to top human competitors. At the heart of AlphaGeometry is a formal language that encodes geometric problems and theorems, rooted in JGEX [Ye et al., 2011], as well as a symbolic reasoning engine called DDAR (see Subsection 4.4.2 for more information), written in Python, which is an extension and reimplementation by Trinh et al. [2024] of an earlier symbolic AI engine [Chou et al., 2000].\nIntertwined with DDAR in the original work is a large language model (LLM), trained on a synthetic dataset of proofs generated using DDAR, that predicts new geometric clauses that DDAR can use to draw new inferences.\nAlphaGeometry's inference loop. AlphaGeometry works, at a high level, in the following way: DDAR iterates through statements that can be logically justified from previous ones until it finds what needs to be proved. There are many ways to find a new statement: An initial batch of them comes from expanding the clauses into statements by the rules described in the defs.txt file. Then, sequential iterations of the AR module that make up DDAR (see Subsection 4.4.2 for more information), followed by the application of rules in the rules.txt file is applied until the goal or a fixpoint is reached. In case of reaching a fixpoint, the LLM will be called to add a new clause so the iterations can start again.\nIssues. Despite its impressive reasoning capabilities, AlphaGeometry suffers from limitations in terms of user-friendliness, both for the end-user as well as for the programmer interested in extending the current codebase and the scope of problems it can handle.\n\u2022 User-friendliness issues: There are three main obstacles that users have to overcome to use AlphaGeometry:\nInstalling AlphaGeometry is difficult, mainly because the Meliad library,\u00b9 on which Alpha-Geometry depends, is difficult to install.\nProblems have to be input using the JGEX formal language.\nThe files rules.txt and defs.txt inside the AlphaGeometry system describe the foundations which DDAR uses to make inferences.\u00b2 Yet, during AlphaGeometry's inference loop (see above), different rules could kick that were not explicitly stated in these text files, but are hard-coded, see Section 3.4.3.\n\u2022 Coder-friendliness issues. AlphaGeometry's codebase is not modularly built, which makes it hard for someone who want to contribute code to add new features, inspect proof traces, add logs, etc. Further, the LLM is implemented in Meliad, a deep-learning Python library that is not widely used - which further makes it hard to finetune the LLM or understand its inner workings, among other desirable operations.\n\u2022 Problem scope issues. AlphaGeometry is not able to work with rather simple and fundamental theorems, notably the Pythagorean theorem, lacking support for the concept of length of a segment, used, among other things, in elementary geometry courses. This makes Alpha-Geometry a type of narrow AI system whose intelligence contrasts with human intelligence: it is inconceivable that an IMO-level competitor will be able to solve certain IMO-level geometry problems while not being able to use the Pythagorean theorem. AlphaGeometry \u201coverfits\" on Olympiad geometry problems, compared to arbitrary plane geometry."}, {"title": "Contributions", "content": "In this research work, we have focused our efforts predominantly on the DDAR solver (as opposed to the LLM) because of the relative importance of DDAR when compared to the LLM in considering the contributions of these two core components of AlphaGeometry towards its final performance on the test dataset: Two datasets were used to report the performance of AlphaGeometry: AG-30, consisting of 30 geometry problems from the IMO, as well as a larger unnamed set of 231 Olympiad-level geometry problems [Trinh et al., 2024] (no data collection protocol has been provided). We will call the latter AG-231 to distinguish between the two. Table 1 in [Trinh et al., 2024] presents a breakdown of the performance of AlphaGeometry, as a function of which combination of methods has been used (DD only, DDAR, DDAR + human heuristic, DDAR + various forms of the LLM, etc.) on the AG-30 dataset. This is augmented by Figure 6,b in the Extended Data section of [Trinh et al., 2024]: If we re-express the results on AG-30 from Table 1 in percentages, the best symbolic AI approach (DDAR + human heuristics) solves 60% of the problems, whereas the best deep-learning approach (DDAR + LLM) solves ~83.3% of the problems. Yet this increase of ~23% is reduced to an increase of merely ~6.5% on the larger and thus more representative-AG-231 dataset, where DDAR + human heuristics solve ~92.2%, and DDAR + LLM solves ~98.7% of problems. (Further, it was noted in [Sinha et al., 2024] that the number reported in Table 1 on how many problems could be solved by the classical Wu method [Wu, 1978] was underestimated since it was found that Wu's method was able to solve 15 rather than 10 problems.)\nConcretely, because of DDAR's outsized importance in AlphaGeometry, as argued above, we focused on Newclid, which uses a new symbolic solver called \u201cDDARN\u201d (DDAR-Newclid) that fixed many of the issues present in DDAR:\n1. User friendliness. The following elements were improved:\n\u2022 Simplified installation: We provide simple ways to install Newclid, in particular, via PyPI. We have removed the dependency on the Meliad library, and streamlined the installation process, see Subsection 3.1.\n\u2022 Problems can be input using an improved command-line interface (CLI), which offers endpoints to introduce agents that can manipulate DDARN, see Subsection 3.2.\n\u2022 Additionally to the new CLI, problems can also be input using the GeoGebra interface, see Subsection 3.3.\n\u2022 We have slightly expanded the scope of problems that can be solved. DDARN can use, in particular, Pythagoras theorem, see Subsection 3.4.\n2. Coder friendliness. A significant refactoring of existing classes was performed, and several tools that assist in debugging and allow the visualizing of several internal objects (such as symbolic graphs) are introduced. These improvements fall into three categories:\n\u2022 General code refactoring that does not affect the reasoning capabilities but laid the groundwork for any subsequent work that was done, see Subsection 4.1\n\u2022 improvements that affect how the reasoning works, which include changes that make adding future code easier, see Subsections 4.2, and\n\u2022 improvements that improve the DDARN reasoning engine, see Subsection 4.4, and\n\u2022 tools that make debugging and visualizing of DDARN's internal objects easier (in fact we used these to find some of the missing rules, see Subsection 4.3.\n3. Reproducibility. We have elaborated on the reproducibility of AlphaGeometry and Newclid, see Section 5."}, {"title": "4 Detailed evaluation", "content": "Lastly, we compare AlphaGeometry's DDAR to Newclid's DDARN on the five problems from the AG-30 dataset whose solution eluded AlphaGeometry, namely the IMO problems 2008 P1B, 2006 P6, 2011 P6, 2019 P2 and 2021 P3. Two problems out of these five, we argue, cannot easily be solved given the current symbolic solver framework; one problem that previously was not solvable becomes solvable using DDARN (IMO 2008 P1B), as can be seen in Section 6.\nIn the future (see Section 7), we plan to augment Newclid to also include an improved LLM, compared to the one present in AlphaGeometry, that would be one example of an agent that manipulates DDARN."}, {"title": "2 Terminology", "content": "Below, we define various terms related to functional aspects that underlie both DDAR and DDARN. Some (but not all) of these were implicitly used in [Trinh et al., 2024]. To make the inner workings of DDAR and DDARN reasoning engines more transparent, we chose to give an explicit description of all of them to enhance the conceptual understanding of DDAR and DDARN.\nWhen defining a theory for plane geometry, one is faced with the question of deciding what are the fundamental objects that will be used to describe the theory. The choice made for DDAR, and continued in DDARN, are to base the theory on points, and use them to represent other geometric objects (lines, circles, triangles, angles, ratios, relationships between objects, etc.). The relationship descriptors, such as cyclic, or cong, to denote whether a collection of points lie on a circle or two congruent segments, respectively, are called predicates. Their use dates back to the DD symbolic engine introduced by Chou et al. [2000]. Predicates work thus like a function, taking as arguments points, e.g., $\\text{cyclic } a b c d$ describes that the four points a, b, c, d are on the same circle and $\\text{cong } abcd$ describes the congruence of the two segments, \\texttt{ab} and cd, that are made up by the four points a, b, c, d. A predicate that is instantiated by points, such as the mentioned $\\text{circle } abc$, is called a statement and is the foundational element of the reasoning engine.\nIn DDAR and DDARN, inferences can be made by using three different paths: application of rules described in the rules.txt file, running the algebraic reasoning module, and resolutions that are made on the go through hard-built, not-described functions (which we call intrinsic rules).\nThe collection of statements that DDAR and DDARN store at a given point when solving a problem is the proof state of the problem at that stage. The objective of the engine is to find a specific statement, the goal, supplied by the user, in the proof state.\nWhenever we use the word symbolically in this article, we refer to something that is inferred exclusively from the proof state. As explained below, statements are not directly inserted in the proof state by a human but are either derived from the problem prescription, derived from previous statements by the inference loop that runs within DDAR and DDARN, or, in some rare cases, directly derived from a diagram of the problem through a numerical check.\nThe problem prescription, created by a human user, does not use the language of the statements and predicates apart from the establishing of the goal, but that of clauses, implemented from definitions. Clauses represent geometric constructions, and we will often refer to clauses as constructions. Most clauses will induce the generation of statements. For example, in a problem where points a, b, and c are already defined, we may define point d = incenter d abcinthe statement of the problem. In that case, when the problem is read, the statements described in the incenter definition, with those arguments, will be added to the starting point of the proof"}, {"title": "3 User Friendliness.", "content": "Below, we detail the four improvements that we made regarding user-friendliness: This includes a simplified installation process, two interfaces that we have added to Newclid to make it more user-friendly (the command line interface (CLI), and the other is a GeoGebra interface), and a section on how we expanded the problem scope that DDARN can solve.\n3.1 Easy Installation\nWe have streamlined the installation process so that it is easy to install Newclid using pip install; additionally, we are releasing it as a PyPI package. The isolation of the Meliad dependency was the main factor in making the installation easier, as running the DDARN solver now is not contingent on having Meliad installed (for AlphaGeometry, even if only DDAR was used, Meliad also had to be installed). Further, we have created an API so that Newclid can be comfortably called from other code.\n3.2 Command Line Interface (CLI)\nOur most fundamental new interface is presented to the user via the command line interface (CLI). Its main objective is to allow one to run a problem with Newclid, without having to use a Python code entry point, and with the option of a human-understandable step-by-step process, which allows the replacement of the original LLM by human decisions.\nThe CLI is characterized by a high degree of control over the solver through our current three agents (a human option, a brute-force automatic option, or a dummy option), which we detail below."}, {"title": "3.3 Geogebra Interface", "content": "One barrier to using AlphaGeometry is the need to translate a given geometric problem into the internal JGEX formal language format, which is not widely known, not widely used in other systems, and not well-documented. To make usage of this software simpler, Newclid provides an interface for a user to be able to prescribe the problem from a GeoGebra diagram of the problem instead. The big advantage is that GeoGebra has an intuitive graphic interface, is widely known by people working with Euclidean geometry (including in educational settings), and has a large community to support one's path to learning its usage.\nTo provide the statement of the problem, one has to provide a file environment containing theggb file and a goals.txt file containing the goals in JGEX format. Newclid will then use the GeoGebra construction to generate the numerical representation of the problem and the construction tools used in GeoGebra to enumerate the initial premises in the proof state, allowing the solver to operate as if the problem were prescribed in text."}, {"title": "3.4 Expanded Problem Scope", "content": "All of the extensions outlined here rely on our significant refactoring of the code, which was the foundation that made the extensions possible in terms of reasoning capabilities. In the following Subsections 3.4.1, 3.4.2, 3.4.3, 3.4.4, we mention various new additions we made. These are the by-product of our refactoring, which made these extensions, in particular, the ones made in the last section, 3.4.4, possible. Our big achievement is that Newclid is able to use the Pythagorean theorem inside other proofs, see Subsection 3.4.3.\n3.4.1 Adding New Predicates\nPredicates form the internal vocabulary used by the reasoning of the engine. We recall from the section on terminology, Section 2, that each predicate behaves as a function, with a prescribed number of arguments which correspond to points. A predicate should be thought by the user as a fact relating the arguments, such as \"the segments defined by two pairs of points being congruent\", or \"the lines through these two pairs of points being parallel\". The only human inputs of predicates are the goals of a problem, but any definition will be symbolically broken down into instances of predicates, and rules are stated in terms of predicates as well. The engine then proceeds to \"think\" using this language. Therefore, the list of predicates is the most fundamental list of notions that the engine knows.\nCrucially, AlphaGeometry lacked functional predicates that consider numerical measures of angles, ratios, and lengths. This made simple questions, such as finding the third angle of a triangle given the values of the first two, unanswerable, even if the algebraic module could easily find the information. Given that questions asking for a specific angle or distance are extremely common in Euclidean geometry and would be expected of any plane geometry solver, this was a significant limitation we sought to overcome. (Curiously, we found traces of such predicates inside the released codebase, which left us with the impression that the original intention was to include them but that this was abandoned for reasons unknown to us.)\nTo fill this gap, we patched up or added the following predicates:\n\u2022 $\\text{aconst}$. This predicate encodes the information that the angle between two lines has a given constant value (that can be given in degrees or in radians). Specifically, lines are denoted in order, each by a pair of points, and the angle is the one obtained by going in the counterclockwise direction from the first to the second line. In the original work, this predicate backed the s_angle definition and superficial predicate, but it only accepted radians as input and could"}, {"title": "3.4.2 Adding New Definitions", "content": "While predicates are prerequisites for an extension of reasoning, simply adding a predicate does not incorporate it into the engine reasoning. Information about the predicate enters the reasoning loop either by direct insertion of information in the statement of the problem or as a derivation of a rule. As can be noted from the experience of solving geometry problems in general, for problems where angles and lengths measures occur, it is usually necessary that some previous measure is provided, such as a known angle. That is particularly true in the case of lengths, as establishing a scale is always necessary in order to calculate distances.\nIn parallel, even predicates that are often derived from rules without a need for an introduction of the statement can be wanted as a premise. For example, the eqratio statement, which corresponds to the fact that the ratios between two pairs of segments are the same, usually occurs as a consequence of verification of conditions on similar triangles, but it is not unusual that a problem has such as a statement mentioned in its premises, in the form of a proportion.\nTo be able to insert those sorts of premises for problems, Newclid has to introduce new definitions. Introducing new definitions on the syntax is not a hard task from a technical viewpoint, in essence one only needs to define the characteristics of the definition on the .txt file containing the list of definitions and construct a corresponding function in the sketch.py module that creates a numerical representation of the new definition. Nonetheless, it is a crucial step in increasing the scope of the problems that can be stated for Newclid.\nWe introduced new definitions with the goal of declaring premises of problems that were not available before but could be managed by the original predicates, of declaring premises of problems that demand the new predicates (de facto including them in the reasoning possibilities of the Newclid), or of making previous definitions more flexible, either reducing conditions for their use or making the statements each definition adds more strict. We introduced the following definitions:\n\u2022 on_pline0. Similar to the previously existing on pline, but drops the requirement that the parallel lines are distinct, allowing one to have overlapping parallel lines.\n\u2022 iso_triangle0. Similar to the previously existing iso_triangle, generates the three vertices of an isosceles triangle but adds to the proof state only the fact that the triangle has two equal sides, not also a pair of equal angles as well. This should be proved.\n\u2022 iso_triangle_vertex. As in the previous definition, it creates only the apex of an isosceles triangle, but it is weaker than the original definition on_bline, which included both the congruence of a pair of sides and of a pair of angles into the proof state. This only adds congruence of a pair of sides.\n\u2022 iso_triangle_vertex_angle. This is the complementary definition to iso_triangle_vertex, which creates the apex of an isosceles triangle but only adds the statement of the angle congruence to the proof state.\n\u2022 on_aline0. This new construction of an angle equivalence adds a configuration that did not exist before. Namely, given an intersecting pair of lines, a third line, and a free point, it creates"}, {"title": "3.4.3 Adding New Rules", "content": "Increasing the number of predicates and definitions is the way to increase the number of geometric problems the engine can reason about. Such new problems can then be constructed and run, but most likely, no solution will be found since the appropriate rules are missing. In order for these problems to be solved, the reasoning side of the engine itself must be improved, and such improvements can take many forms.\nWe recall that in the original engine, conclusions can be reached by three different paths: application of rules described in the rules.txt file, the running of the algebraic reasoning module, and resolutions that are made on the go through hard-built, not-described functions, that we called intrinsic rules."}, {"title": "3.4.4 Adding New Equations to AR", "content": "1. Following the reorganization of the code, as outlined in Section 4 on Coder Friendliness, it is easy to list all rules for the addition of equations into AR. Equations are added to the systems of equations at the addition of new statements by calling a prep_ar method. We have the following instances where that happens:\n\u2022 cong ABCD: adds the equation $\\log AB = \\log CD$ to the table of ratios.\n\u2022 aconst A B CDr: adds the equation $d(CD) = d(AB)+r$ to the table of angles, where r is any real number that will be taken $\\mod$ once the statement is added to the proof state, during the DDARN inference loop.\n\u2022 lconst A B 1: adds the equation $\\log AB = \\log l$ to the table of ratios, where l is a positive number.\n\u2022 eqangle A B C D E F GH: adds the equations $d(CD) \u2013 d(AB) = d(GH) \u2013 d(EF)$ to the table of angles.\n\u2022 eqratio A B C D E F G H: adds $\\log AB \u2013 \\log CD = \\log EF \u2013 \\log GH$ to the table of ratios.\n\u2022 para A B C D: adds $d(AB) = d(CD)$ to the table of angles.\n\u2022 perp A B C D: adds $d(CD) = d(AB) + \\frac{\\pi}{2}$ to the table of angles.\nWe note that the original codebase contained separate tables of lengths and ratios. We merged them, which resulted in cleaner code, as detailed in Subsection 4.4.2, and consequently, only a table of ratios is available, referenced above, which includes all lengths. Of this list, the addition of the equations referring to cong statements was moved from the lengths table, used in AlghaGeometry, while the ones referring to aconst and lconst statements are new additions we added to the table of ratios.\n2. Further, it is now easy to add new predicates to the engine given the Predicate class we introduced, see Subsection 4.4.1. This, in turn, allowed us to easily add the predicates that allow the Pythagorean theorem to be used by DDARN."}, {"title": "4 Coder Friendliness", "content": "A significant amount of our time was dedicated to refactoring the codebase of AlphaGeometry to make the inner workings of its 16,000-line, highly entangled, complex code easier to work with, to eliminate bugs, and to add low-level functionalities that make the user's interaction with AlphaGeometry easier, and on which the previous Section 3.4 built.\nWith the exception of the preliminary numerical checking and caching of statements mentioned in Subsection 4.2, this refactoring effort had no direct impact on the reasoning engine. Each subsection below sums up the different types of changes and additions we made.\n4.1 Overall Foundational Design\nAlthough we achieved improvements on the reasoning part of the engine, a necessary step to make that possible, and one that took most of the time, was to refactor the original codebase into something more manageable.\nThe first step, and one that brought Newclid to life, was to separate the AlphaGeometry code into two halves. The first contains everything necessary for the software to solve a problem"}, {"title": "4.2 Agentic Support", "content": "The reorganization and the modularity we added to the code allow for better communication between Newclid and other software through an interface of what we call \"agents\", as mentioned earlier. As of now, the existing agents are subclasses of the larger DeductiveAgent class inside Newclid itself.\nThe currently existing agents are DDARN (which uses breadth-first-search), HumanAgent (that allows human control of the solving process), and flemmard (a dummy agent that does not try to apply anything after building the problem, and is good for testing the parts of the code beyond the reasoning), which we explain below.\nWe allow the possibility of adding similar classes that allow LLMs, such as the original transformer model from AlphaGeometry, to operate through an agent.\nIn an agentic setting, important mechanisms are 1) how different agents can interact with each other, 2) what each agent observes and what actions it can take.\nWe have implemented this by exporting the \"proof state\", carrying all the information about the statements derived by the reasoning at any given moment (agents also accept the file with the rules as input, in case they have to do derivation themselves).\nTo interact with the proof state, the agent needs to be designed with observation functions, which can directly add new clauses to the problem, match a theorem, add or change a dependency, or check a goal. The functions can be customized to access other information about the proof state, such as the current geometrical graphics of the problem and its premises.\nIn terms of code, the HumanAgent is an example of an agent that explores all the functionalities of the ProofState class.\nAs shown in Figure 3, the interactions pertain to three parts: the agent, the observation functions and the proof states. A run loop generates steps where, at each step, the agent can manipulate the proof state by matching rules, adding dependencies, and adding clauses that describe auxiliary constructions."}, {"title": "4.3 Improved Visualization and Debugging Capabilities", "content": "One important contribution to the understanding of the functioning of the code was the visualization of two structures that were implicit and entangled in the original AlphaGeometry code: the symbols graph and the dependency graph. Originally, they were both defined in the single Graph class, whose definition span almost 3000 lines of code, making it very difficult to understand. Also, there were no visualization capabilities built in, so there were no immediate ways to generate these graphs.\nAs the name suggests, the dependency graph depicts the dependency structure of the proof, namely what premises were derived, on what other premises they rely on, and what the mechanism that allowed for that derivation is. It is an and-or graph, with nodes representing statements and directed edges representing dependencies between the statements. Each dependency can consist of potentially multiple, or even zero, incoming statements and one outgoing statement, in addition to a reason citing the rule allowing the deduction of the outgoing statement from the incoming ones. There are two depictions of the dependency graph: One can see the full dependency graph, which shows all the dependencies between all the statements that DDARN derives (which appears if a solution is not found at all), or one sees the reduced dependency graph, available only in case where a problem was solved, where we traverse the full dependency graph and exclude any nodes (and corresponding edges) that are not relevant to the found solution, using the traceback.\nLess obvious is the symbols graph, which depicts all the geometric objects created in the construction of the problem and the development of the proof, and if they are composed of smaller objects, they will be connected to those basic objects."}, {"title": "4.3.1 Dependency Graph", "content": "The biggest feature that was missing that we encountered in the AlphaGeometry code, was clear documentation of the dependency structure: a datastructure that collects the statements and their dependencies in a proof. Although the original paper by Trinh et al. [2024] mentions the need for a traceback to simplify proofs and to weed out statements that were derived during the DDAR loop but that are not necessary for the proof, it does not touch on the complexity of the functions located throughout the code dedicated to registering and sorting out the dependencies of statements generated in the process.\nSuch dependencies are now stored in what is called the Dependency class, and the collection of all dependencies forms the (full) dependency graph. A dependency is typically built when a statement is checked symbolically, a rule is applied, or exceptionally when the symbols graph is synthesised by merging lines or circles, which happens when the engine finds out three points (which would correspond to three lines in the symbols graph), are actually collinear. It consists of a justification (such as the name of the rule), its premises and a conclusion. Also, when a dependency is added to the dependency graph, a function related to the conclusion predicate can be triggered, and the inner states of the AR module and the symbols graph can be modified."}, {"title": "4.3.2 Symbols Graph", "content": "Initially, the symbols graph contained many kinds of objects: points, segments, directions, angles, ratios, measurements of angles, values of ratios, the numerical value of those measures, and circles. This myriad of classes of geometric objects was necessary because many implicit derivations of facts took place through identifications of nodes on the symbols graph. In our work, we moved a big part of the reasoning responsibilities of the symbols graph, namely the ones involving congruences of measures, to the AR module, and some others were given to explicit rules. For DDARN, the cleaned-up symbols graph only stores points, lines, and circles, and the only reasoning it carries concerns detecting and storing when new points are found in already existing lines and circles (i.e. collinearity and concyclicity). It should be stressed that such identification is only accepted by the engine if there is a symbolic justification for it, the numeric recognition that a point lies on a given line on circle is not enough for the registering of that information in the symbols graph."}, {"title": "4.3.3 Using the Graphs", "content": "Visualizing this information in these graphs and inspecting them had important consequences. It turned out that they are one of the most comprehensive visual depictions one can have of the reasoning of the engine, to the point that we found out that the original s_angle definition was processed through a hidden, not entirely functional, aconst predicate because that dependency surprisingly showed up in dependency graphs (but not in the proof).\nBoth the symbols graph and the dependency graph were crucial concepts to understand the underlying structure of the reasoning beyond the information contained in generated proofs. In addition, having these visualization tools that contain a lot more information on the reasoning of the engine than the proofs was crucial for debugging, as it pointed us to incorrect or superfluous connections that were made by the engine. This information, in turn, made it possible to make various additions to fix these problems."}, {"title": "4.4 Reasoning Engine Improvements", "content": "The guiding principle of DDAR was to be able to apply theorems to a problem in a breadth-first search (BFS). To execute this idea, a series of technical challenges have arisen regarding how to structure and store the mathematical information and how to implement the search. A big part of our effort focused on creating good, flexible code structures that could execute the breadth-first strategy that DDARN employs in a better way than AlphaGeometry. In order to do so, we implemented and modified the structures described below.\n4.4.1 Predicates\nOne major step in giving the code flexibility was to create the Predicate class and to organize the most fundamental reasoning terminology of Newclid as a collection of subclasses, with a structure that can be expanded if needed and easily modified. Predicates are more complex than definitions, so a Predicate class is more complex than a definition statement on the defs.txt file, but the philosophy we followed was that the former should be as easily found and modified as the latter.\nA Predicate class contains methods to:\n\u2022 Put the arguments of the predicate in a canonical order (preparse).\n\u2022 Parse its arguments from strings to geometrical points (parse).\n\u2022 Find a dependency structure that can justify the existence of that predicate and do the symbolic check (why, add).\n\u2022 Check numerically for the validity of that predicate, do the numerical check (check_numerical).\n\u2022 Process the representation of that predicate when writing the proof, generating diagrams, or receiving and passing information to the LLM (pretty)."}, {"title": "4.4.2 Algebra Reasoning", "content": "One of the main contributions of the authors of [Trinh et al., 2024] to the development of a geometry reasoning engine was the addition of the algebraic reasoning module (AR) in tandem with the deductive database (DD) resulting in the DDAR solver, that increases the range of statements found compared to DD. AR is a symbolic engine for checking and getting the justification of statements based on an internal set of linear equations.\nThe original engine was built on three sets of linear equations, called tables: one storing information about angles, one storing information about ratios, and one storing information about lengths. Each internal linear equation is of the form $y = \\sum q_i x_i + constant$, where only the $q_i$'s are stored explicitly. When a new equation is given, it is simplified so that it contains only free variables on the right-hand side, with one variable, y, to depend on others, if necessary.\nThe goal of the AR module is to find new equations of the form $\\sum b_i x_i = Constant$, corresponding to new predicates not present in the previous equations. This involves resolving the dependency structure of the predicate found to minimize proofs at the time of the traceback. Different procedures are applied at each of those stages.\nTo find the new statements, as described in the original work by [Trinh et al., 2024], the engine applies Gaussian elimination at each table, a process that can result in a new statement or not. Each table stores information about all occurrences of predicates feeding it, but not all of them necessarily relate to the new statement found. Once a goal is found, to weed out unrelated statements in the table, the engine uses linear programming techniques to find the minimal system that satisfies the new statement, aiming at a shorter proof.\nAll those procedures are part of AlphaGeometry. In order to have a clearer algebraic module that is easier to understand and modify and that is more robust against mistakes, we made minor changes.\nThe most notable one was the removal of the length table. The lengths of segments were arguments in both the table of lengths and the one of ratios (in this case, ratios are linearized by the application of logarithms as described in [Trinh et al., 2024]). The table of lengths, though, had only simple information about the equality of segment lengths, information that we easily incorporated into the table of ratios without further negative consequences, reducing the number of tables to two.\nAs this table now has to deal with information on constant lengths, but the entries are logarithms of lengths for the linearization of ratios, we end up having to deal with the logarithms of constants. To minimize numerical instabilities and simplify symbolic manipulations, instead of storing those throughout the Gaussian elimination process, we retrieve them through numerical checks whenever the proof state has dependencies supporting the corresponding lconst statements(see Subsection 3.4.4)."}, {"title": "4.4.3 Matching", "content": "At first look, a BFS search for an automatic theorem prover may look as costly as the number of theorems it has to go through while performing the search. Our experience with AlphaGeometry shows that this is only part of the story. In fact, the process of using theorems can be separated into one that matches the theorem, that is, looks for arguments to fit the predicates in the hypothesis of the theorem, and one that applies the theorem generating a new statement from the theorem's conclusion. The matching is the combinatorially expensive step of the process, and it can make some theorems consume significantly"}]}