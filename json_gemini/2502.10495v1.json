{"title": "SWA-LDM: Toward Stealthy Watermarks for Latent Diffusion Models", "authors": ["Zhonghao Yang", "Linye Lyu", "Xuanhang Chang", "Daojing He", "YU LI"], "abstract": "In the rapidly evolving landscape of image generation, Latent Diffusion Models (LDMs) have emerged as powerful tools, enabling the creation of highly realistic images. However, this advancement raises significant concerns regarding copyright infringement and the potential misuse of generated content. Current watermarking techniques employed in LDMs often embed constant signals to the generated images that compromise their stealthiness, making them vulnerable to detection by malicious attackers. In this paper, we introduce SWA-LDM, a novel approach that enhances watermarking by randomizing the embedding process, effectively eliminating detectable patterns while preserving image quality and robustness. Our proposed watermark presence attack reveals the inherent vulnerabilities of existing latent-based watermarking methods, demonstrating how easily these can be exposed. Through comprehensive experiments, we validate that SWA-LDM not only fortifies watermark stealthiness but also maintains competitive performance in watermark robustness and visual fidelity. This work represents a pivotal step towards securing LDM-generated images against unauthorized use, ensuring both copyright protection and content integrity in an era where digital image authenticity is paramount.", "sections": [{"title": "1. Introduction", "content": "The Latent Diffusion Models (LDMs) represent a significant advancement in efficient, high-quality image generation. By leveraging Variational Autoencoders (VAEs) , LDMs transfer diffusion model operations from pixel space to latent space, allowing UNet architectures to perform denoising in a lower-dimensional space. This shift dramatically enhances computational efficiency, enabling companies and individuals with limited resources to train models for commercial usage. Consequently, popular models such as Stable Diffusion (SD), DALL-E 2, and Midjourney have emerged, facilitating the generation of high-quality, realistic images via user-accessible APIs.\nThe rapid advancements of LDMs have introduced critical challenges, particularly concerning copyright infringement and the potential misuse of generated content. Copyright violations arise when malicious actors steal and resell proprietary diffusion models, resulting in substantial financial losses for original creators. Additionally, the capability to generate hyper-realistic images has been exploited by individuals disseminating misinformation and fake news, thereby undermining public trust and social stability. Addressing these issues is paramount for safeguarding intellectual property rights and maintaining societal integrity.\nTo alleviate these issues, current LDMs employ watermarking techniques to embed pre-designed imperceptible watermarks within the generated images. Then, one can extract this watermark using corresponding methods to identify the image's origin. Existing watermark methods fall into two categories: post-processing watermarking and in-generation-process watermarking. Post-processing methods add watermarks after the images have been generated by LDMs, but they often compromise image quality . Alternatively, in-generation-process methods embed watermarks during the image generation process, which can be further divided into model-based and latent-based methods . The former embeds watermarks by modifying LDMs' parameters, such as VAE or UNet, resulting in training costs. In contrast, the latent-based methods, as shown in Figure 1, embed a watermark to the latent noise before the denoising process. This approach eliminates the need for extensive retraining and incurs minimal computational overhead, making it highly efficient for practical applications.\nHowever, a significant limitation of current latent-based watermarking techniques is their reliance on constant watermarks across all generated outputs, making them susceptible to detection by malicious users. This paper highlights this vulnerability for the first time, demonstrating that the stealthiness of existing methods can be easily compromised using only the generated images. Unlike prior works that attempt to remove watermarks without first verifying their presence , we propose an attack to determine whether an image generated by an LDM contains a watermark, which can further inform adversarial actions. This attack also serves as an evaluation metric for the stealthiness of latent-based watermarking techniques. Specifically, we design a feature extractor to identify constant watermark signals in images generated by the target LDM. Successful extraction of a constant signal indicates the presence of a watermark. Through this attack, we emphasize the urgent need to enhance the stealthiness of watermarking techniques to safeguard against unauthorized use.\nTo address this vulnerability, we introduce SWA-LDM, a plug-and-play component compatible with any latent-based watermarking method to create stealthy watermarks. Our approach randomizes the watermark by embedding image-dependent signals into generated images, effectively preventing the detection of a constant signal. The closest related work, Gaussian Shading , uses stream ciphers for randomization but incurs high management costs due to the need to remember a unique nonce for each image. In contrast, SWA-LDM leverages the inherent randomness of latent noise to generate image-dependent watermarks without additional management overhead. Specifically, we introduce a key channel sampled from the latent noise to create a random key that shuffles the watermark, ensuring uniqueness for each image. During watermark verification, SWA-LDM reconstructs the latent variable via diffusion inversion and extracts the key to retrieve the original watermark. However, inaccuracies may arise due to diffusion inversion errors and image transmission noises. To mitigate this, we propose an enhancement algorithm to store redundant keys in the key channel while preserving its distribution. The combination of randomized watermarks and key channel enhancement facilitates the generation of stealthy and robust watermarks.\nOur contributions are summarized as follows: \u2460 We are the first to expose the stealthiness vulnerabilities inherent in current latent-based LDM watermarking methods, which generate constant watermarks that can be easily exploited by malicious users for detection. Our effective watermark presence attack demonstrates this vulnerability, underscoring the critical need for enhanced watermarking strategies. \u2461 We present SWA-LDM, a versatile plug-and-play component compatible with any latent-based watermarking method, designed to create stealthy watermarks. By leveraging the inherent randomness of latent noise, SWA-LDM generates image-dependent watermarks without incurring additional management costs. Additionally, we propose an enhancement algorithm that incorporates redundant keys within the key channel, preserving its distribution while significantly improving watermark robustness. \u2462 We conduct comprehensive experiments to evaluate the proposed watermark presence attack and SWA-LDM. Results show that SWA-LDM effectively improves the stealthiness of latent-based watermarks while achieving competitive visual quality, image-text similarity, and watermarking robustness."}, {"title": "2. Background and Related Works", "content": "Latent Diffusion Models. Latent diffusion models are a computationally efficient version of diffusion models . LDMs leverage a pretrained autoencoder to compress image $x \\in R^{3 \\times H \\times W}$ in RGB space into a lower dimensional latent representation $z \\in R^{c \\times h \\times w}$. Training and sampling LDMs in the latent space significantly reduces the computational complexity. More specifically, during training, the encoder $\\mathcal{E}$ encodes the image $x$ into a latent representation by $z = \\mathcal{E}(x)$. Next, LDMs conduct diffusion and denoising process in the latent space, which converts $z$ to a latent noise $z_T$ and recovers the image latent $\\tilde{z}$ from $z_T$ respectively over $T$ timesteps. Then, the decoder $\\mathcal{D}$ reconstructs the image from the recovered latent by $\\hat{x} = \\mathcal{D}(\\tilde{z})$. During sampling, the LDMs sample a noise latent vector $z_T$ from Gaussian distribution $\\mathcal{N}(0, I)$. Subsequently, the trained LDM can utilize sampling methods like Denoising Diffusion Implicit Models (DDIM) or DPM-Solver to obtain the latent representation of the sampled image $z_S$ from $z_T$ over $T$ timesteps. Then, the decoder reconstructs the image from the latent by $x_S = \\mathcal{D}(z_S)$. Besides, one can use methods like DDIM Inversion to invert the denoising process and recover the initial noise $z$ from the generated image $x_S$.\nWatermarks for Latent Diffusion Models. LDMs enable individuals to customize their own models for specific styles of image generation via training and fine-tuning, which they can publish and exchange in the online market space such as Civitai and Tensor.art . However, these advancements have also raised concerns about the potential abuse of these models and the generated images. For instance, unauthorized commercial exploitation of LDM-generated images lacking inherent copyright protection is a significant risk. Besides, malicious users can generate realistic images to spread rumors and fake news on social media, potentially manipulating important social and economic events such as political elections and the stock market. Therefore, enhancing LDMs with copyright protection and traceability techniques is crucial. Watermarking has a long history to alleviate these issues via labeling image content, which involving incorporating watermark information into the generated images. Then, one can identify the origin of the images by verifying the watermark.\nExisting watermarking methods for LDMs can be categorized into post-processing and in-generation-process watermarks. Post-processing methods add watermarks to images after they have been generated by LDMs. For instance, the Stable Diffusion repository provides methods like DWT-DCT and RivaGAN . Despite their widespread usage, direct modification to the images can degrade image quality . Alternatively, recent research proposes in-generation-process watermarks, which integrate the watermark embedding with the image generation process. Stable Signature and AquaLora embed watermarks by fine-tuning the VAE decoder and UNet of the LDMs, respectively. These model-based methods improve the watermarked image quality but introduce substantial computational costs for training the model parameters. Conversely, recent works propose latent-based watermarks, which embed the watermarks into the latent space of the diffusion models. Tree-Ring encodes the watermark in the frequency domain of the latent noise, while Gaussian Shading maps the watermark to the latent variable following Gaussian distribution. DiffuseTrace uses an encoder model to modify the initial latent noise variable. Latent-based methods are free of model parameter modifications, making them much less computational and more user-friendly.\nWhile latent-based methods hold great promise for practical usage, our research reveals a critical issue: even though invisible, these techniques produce a constant signal across generated images. This uniformity undermines the stealthiness of the watermarks, increasing the risk of copyright infringement. To address this, we propose a plug-and-play component that integrates with existing latent-based watermarking methods and enhances their stealthiness."}, {"title": "3. Watermark Presence Attack", "content": "We introduce a promising watermark presence attack to detect the presence of latent-based watermarks by analyzing a set of images generated by the target LDM.\n3.1. Threat Model\nThe watermark presence attack targets a scenario with two parties: the model owner providing the image generation service and the watermark presence attacker.\nModel Owner. The owner of the LDM deploys it on a platform (e.g. (Face; Inc.; Tensor.art)) and provides image generation services through API access. To protect image copyrights and ensure traceability in cases of misuse, the owner embeds imperceptible watermarks in each generated image without degrading image quality. For any given image, the owner can verify whether it contains their watermark and identify the associated user, a process known as watermark verification, which must remain highly accurate even after image perturbations. The model owner controls the entire LDM, image generation, and verification process.\nWatermark Presence Attacker. The attacker aims to detect the presence of watermarks in images generated by target LDM $\\mathcal{D}_{tar}$. The attacker generates images using the API and controls only the prompts, without access to the model's internals, the initial noise, or any knowledge of the model, watermark method, or watermark detector. Also, the attacker can utilize open-source models $\\mathcal{D}_{cle}$ to generate watermark-free images with the same prompts.\n3.2. Overview\nFigure 2 illustrates our watermark presence attack, consisting of three modules: Image Generation, Feature Extraction, and Feature Analysis.\nImage Generation. In this module, we generate two image sets: the target image set $\\mathcal{I}_{tar}$ from the target LDM $\\mathcal{D}_{tar}$ and the clean image set $\\mathcal{I}_{cle}$ from the clean LDM $\\mathcal{D}_{cle}$. Both sets share the same prompt set $\\mathcal{P}$ to ensure any differences are primarily due to the watermark. These image sets are then used to train the watermark feature extractor in the next module.\nFeature Extraction. The goal of this module is to train a Watermark Feature Extractor WFE, which tries to extract the constant watermark from the generated images. To achieve this, we design three loss functions for training WFE based on the extracted features: the first loss $L_{at}$"}, {"title": "SWA-LDM: Toward Stealthy Watermarks for Latent Diffusion Models", "content": "encourages WFE to aggregate target image features to find the constant watermark signal; the second loss $L_{dtc}$ motivates the extractor to distinguish between target image and clean image features; and the third loss $L_{gc}$ let the clean image features follow a random distribution to prevent extractor from only detecting the signals caused by model difference instead of watermark. These loss components are explained in the Section 3.4. Thus, the total loss function is:\n$L_{total} = L_{at} + \\alpha L_{dtc} + \\beta L_{gc}$,\nwhere $\\alpha$ and $\\beta$ are hyperparameters to control the contribution of each loss.\nFeature Analysis. This module determines whether the target diffusion model $\\mathcal{D}_{tar}$ contains a watermark. We use the trained WFE from previous method to extract $\\mathcal{F}_{cle}$ and $\\mathcal{F}_{tar}$ from $\\mathcal{I}_{cle}$ and $\\mathcal{I}_{tar}$. Then, we measure the distribution difference between these two features using Maximum Mean Discrepancy (MMD) metric. If the feature distributions differ significantly, our method predicts that the target model is watermarked and vice versa.\n3.3. Image Generation\nWe begin by collecting a prompt set $\\mathcal{P}$ to create the training dataset, comprising $\\mathcal{I}_{cle}$ and $\\mathcal{I}_{tar}$. Ideally, a watermark-free version of the target model would be used as the clean model to generate a corresponding watermark-free image. The only distinction between the two sets is the presence of the watermark. By analyzing distributional differences, we can infer the watermark's presence\u2014if no difference is observed, the image is watermark-free; if differences exist, a watermark is likely present. In practice, attackers often have access to only an approximate watermark-free model. Since most LDMs are fine-tuned from open-source models there is a similarity between the output distributions of the target and clean LDMs. This similarity amplifies the differences caused by the watermark, facilitating effective detection of its presence.\n3.4. Feature Extraction\nIn this module we attempt to detect watermark signal in the generated images by training a Watermark Feature Extractor WFE. The WFE should have the following behaviors for successful watermark presence attack: when the watermark exists in the target images, the extractor should identify the watermark signal, causing $\\mathcal{F}_{tar}$ to converge; besides, the extractor should also identify the distribution difference between the $\\mathcal{F}_{cle}$ and $\\mathcal{F}_{tar}$ caused by the watermark: furthermore, the extractor should only detect the constant signal contributed by the watermark instead of the inherent difference between $\\mathcal{D}_{cle}$ and $\\mathcal{D}_{tar}$. To achieve these behaviors, We design three types of losses to achieve these properties. To encourage $\\mathcal{F}_{tar}$ to converge during training, we introduce"}, {"title": "SWA-LDM: Toward Stealthy Watermarks for Latent Diffusion Models", "content": "aggregating loss for targe feature $L_{at}$, which calculates the variance of the target features as shown in Equation (2):\n$L_{at} = \\frac{1}{N(N-1)} \\sum_{i=1}^{N} \\sum_{j=1, j \\neq i}^{N} || \\mathcal{F}_{tar}^i - \\overline{\\mathcal{F}_{tar}} ||^2$ (2)\nBesides, we introduce difference $L_{dtc}$ loss to distinguish the difference between the $\\mathcal{F}_{cle}$ and $\\mathcal{F}_{tar}$. $L_{dtc}$ calculates the reciprocal of the difference between the matched $\\mathcal{f}_{tar}$ and $\\mathcal{f}_{cle}$ as shown in Equation (3).\n$L_{dtc} = \\frac{1}{N^2} \\sum_{i=1}^{N} \\sum_{j=1}^{N} \\frac{1}{|| \\mathcal{f}_{tar}^i - \\mathcal{f}_{cle}^j ||^2}$ (3)\nEven if the target images are watermark-free, $L_{at}$ and $L_{dtc}$ may converge due to the model difference between $\\mathcal{D}_{cle}$ and $\\mathcal{D}_{tar}$. WFE can falsely treat the model difference as the watermark difference, which leads to false positive detection result. To alleviate this, we propose the third loss $L_{gc}$ to prevent the WFE model from learning the model-difference features. $L_{gc}$ is motivated by one property of watermarking: when the input is a watermark-free image the watermark extractor should produce a random output. Therefore, $L_{gc}$ encourages the extracted features from the clean images to follow a random distribution. Hence, $L_{gc}$ calculates the KL divergence between the $\\mathcal{F}_{cle}$'s distribution and a Gaussian distribution, as shown in Equation (4) .\n$L_{gc} = \\frac{1}{N} \\sum_{i=1}^{N} KL(\\mathcal{F}_{cle}^i || \\frac{1}{M})$ (4)\nwhere $N$ is the batch size, $M$ is the feature dimension size."}, {"title": "4. SWA-LDM", "content": "We introduce SWA-LDM, a plug-and-play component for existing latent watermarking methods that generates image-dependent watermarks to counter watermark presence attack.\n4.1. Overview\nThe framework of SWA-LDM is shown in Figure 3. During watermark embedding, SWA-LDM initializes latent noise $z_T$ sampled from a standard Gaussian distribution, which it then splits into key, noise, and watermark channels. The key and noise channels retain random noise, while the watermark channel is reinitialized with watermark-embedded noise based on the chosen latent-based watermarking method.\nTo randomize the watermark, SWA-LDM leverages the inherent randomness of latent noise by extracting a random seed (key) from the noise in the key channel. To ensure reliable key recovery to counter diffusion inversion errors and image transmission noises, we design a robust key construction mechanism and enhance the key channel for stronger key information. The key then seeds the random number generator to shuffle the watermark and noise channels, and the key channel is merged to produce the watermarked latent noise $\\tilde{z}_T$. The subsequent denoising and image generation process follows the standard procedure of LDMs.\nDuring watermark verification, SWA-LDM restores the image to latent space, obtaining $\\hat{z}_0$, and uses diffusion inversion method to approximate the original latent noise $\\tilde{z}_T$. SWA-LDM partitions $\\hat{z}_0$ to extract the key from the key channel, which is used to reshuffle the remaining channels. This process recovers the latent noise from the watermark channel, from which the watermark is extracted and verified.\nThe closest work, Gaussian Shading , using stream ciphers to encrypt latent noise, introducing randomness to the watermarked latent distribution. However, stream ciphers require a unique nonce per latent noise to achieve randomness, meaning each generated image must be paired with a specific nonce. This nonce must be managed and matched with the corresponding image during watermark verification, as it is essential for decrypting the latent noise to verify the watermark. This nonce management complicates practical implementation in LDM applications that generate high volumes of images. In contrast, SWA-LDM operates without any additional information management."}, {"title": "4.2. Watermark Embedding", "content": "Each step of watermarking embedding in SWA-LDM is illustrated below.\nChannel Splitting. SWA-LDM initializes the latent noise $Z_T \\in R^{c\\times h\\times w}$ and divide it into key channels $z_k \\in R^{c_k\\times h\\times w}$, noise channels $z_n \\in R^{c_n\\times h\\times w}$, and watermark channels $z_w \\in R^{c_w\\times h\\times w}$. The key and noise channels are filled with randomly sampled noise from a standard Gaussian distribution $\\mathcal{N}(0, I)$. Meanwhile, the watermark channel is initialized with a chosen latent-based watermarking method (e.g., (Yang et al., 2024b))\nKey Construction. SWA-LDM uses a pseudorandom number generator (PRNG) and shuffle algorithm to randomize the latent noise in the watermark and noise channel. The PRNG seed must meet three criteria: (1) each seed is randomly generated and unique per image, (2) it can be reliably reconstructed during watermark verification, and (3) it does not require additional management.\nTo achieve this, SWA-LDM derives the key $k$ directly from the latent noise. Given that LDMs transform latent noise $z_T$, sampled from a Gaussian distribution $\\mathcal{N}(0, I)$, into an image $x_0$, this approach retains the necessary randomness and ensures compatibility with diffusion inversion, fulfilling the requirements for $k$. However, during diffusion inversion, the reconstructed $z'_T$ may not perfectly match the original $z_T$, especially when $x_0$ experiences perturbations. Therefore, SWA-LDM must reliably construct $k$ even in the presence of these variances. For robustness, SWA-LDM abstracts specific elements from the latent noise to construct each bit of $k$. First, we define a mapping function to consistently sample fixed locations within the latent noise for each bit in $k$. Specifically, a mapping function $\\mathcal{M} : \\{1, 2, ..., N\\} \\rightarrow \\{(i, j,q) | i \\in [1,c_k], j\\in [1,h], q \\in [1,w]\\}$, with $N = c_k \\times h \\times w$, allows SWA-LDM to consistently access the same positions in $z$ for k-bit construction. For simplicity, $\\mathcal{M}$ is implemented as a sequential mapping, unfolding $z_k$ linearly to assign each bit of $k$.\nNext, each bit of $k$ is sampled based on the sign of specific latent variables $z_{k,i,j,q}$ within $z_k$. Letting $M$ denote the bit-length of $k$, each bit is determined as follows:\n$k = [k_1,...,k_M] \\qquad k_m =\\begin{cases}1, & \\text{if } z_{k,i_m,j_m,q_m} > 0\\\\0, & \\text{if } z_{k,i_m,j_m,q_m} \\leq 0\\end{cases}$ (5)\nwhere $(i_m, j_m, q_m) = \\mathcal{M}(m)$ indicates the index of $k_m$ in"}, {"title": "SWA-LDM: Toward Stealthy Watermarks for Latent Diffusion Models", "content": "Algorithm 1 Key Channel Enhancement\nInput: $z_k$: Latent noise in key channel, $k$: Extracted key bits, $R$: Number of redundancies, $\\mathcal{M}$: Mapping function\nOutput: $\\tilde{z}_k$: Latent noise with robust key\n/*Find the latent noise corresponding to $k_m$ */\nfor $r = 1$ to $R$ do\nfor $m = 1$ to $\\text{len}(k)$ do\n$(i, j, q) \\leftarrow \\mathcal{M}(r \\times M + m)$\n$k_m \\leftarrow 1 \\text{ if } z_{k,i,j,q} > 0 \\text{ else } 0$\nif $k_m \\neq k_m$ then\n/*Search for latent noise to swap*/\np$\\leftarrow$m+1\nwhile True do\n$(i', j', q') \\leftarrow \\mathcal{M}(r \\times M +p)$\nnew_bit$\\leftarrow 1 \\text{ if } z_{k,i',j',q'} > 0 \\text{ else } 0$\nif new_bit = $k_m$ then\n$\\text{swap}(z_{k,i,j,q}, z_{k,i',j',q'})$\nbreak\nend if\np$\\leftarrow$p+1\nend while\nend if\nend for\nend for\n$\\\\\\tilde{Z}_T \\leftarrow Z_T$\nreturn $\\tilde{Z}_T$\nfor the latent noise $z_k$.\nKey Channel Enhancement. While the key construction accounts for noise variations, it may still fail to reliably recover $k$ under perturbations. To address this, we propose a method to construct redundant key information within $z_k$, ensuring robust key extraction with minimal modification to $z_k$. Let $R$ represent the number of redundant key, and define the $r$-th redundant key as $k^r$, where $r \\in [1, R]$ and $k_m^r = k_m$ for $m \\in [1, M]$. For each redundant key $k^r$, we map it to a set of latent noise using the mapping function $\\mathcal{M}$. The latent variable $z_{k,i_n,j_n,q_n}^r$ corresponds to $k_m^r$ with $(i_n, j_n, q_n) = \\mathcal{M}(r \\times M + m)$. If the relationship between $k_m^r$ (either 0 or 1) and $z_{k,i_n,j_n,q_n}^r$ (either < 0 or > 0) does not match, we search for a latent noise element that satisfies the condition and swap the corresponding values. The key channel enhancement process is detailed in Algorithm 1. This algorithm takes the latent noise $z_k$, the key $k$, and the number of redundant key $R$ as input, and outputs the enhanced latent noise $\\tilde{z}_k$, which includes the redundant key.\nLatent Noise Shuffling. As previously discussed, SWA-LDM embeds the watermark into the latent noise of the watermark channel, resulting in $z_w$. To randomize this embedded watermark, SWA-LDM uses $k$ as a seed for the pseudorandom number generator (PCG64). The Fisher-Yates shuffle algorithm is then applied to permute $\\text{concat}(z_w, z_n)$, dispersing watermark information across the latent space. Finally, we concatenate the enhanced latent noise $\\tilde{z}_k$ with the shuffled watermark channel to form the final watermarked latent noise $\\tilde{z}_T$.\nImage Generation. After constructing the watermarked latent noise $\\tilde{z}_T$, the image generation process follows the standard procedure of the LDMs. Specifically, we utilize DDIM for denoising of $\\tilde{z}_T$. Once the denoised latent $z_0$ is obtained, the watermarked image $x_0$ is generated by applying the LDM decoder $\\mathcal{D}$: $x_0 = \\mathcal{D}(z_0)$."}, {"title": "4.3. Watermark Verification", "content": "Diffusion Inversion. For watermark verification, we use the LDM encoder $\\mathcal{E}$ to map the watermarked image $x_0$ back to the latent space, obtaining $\\hat{z}_0 = \\mathcal{E}(x_0)$. We then apply diffusion inversion over T timesteps, estimating the additive noise to recover $\\hat{z}_T \\approx \\tilde{z}_T$. Here, DDIM inversion is used to approximate the original latent noise.\nRobust Key Extraction. With $\\hat{z}_T$ obtained, we partition it to isolate the key channel $\\hat{z}_k$ containing the redundant key information and the shuffled channel. Using a fixed mapping function $\\mathcal{M}$, we extract the redundant key information from predetermined positions in $\\hat{z}_k$ to obtain both the key $k'$ and its redundant bits $\\{k'^r | r \\in [1, R]\\}$. Each bit $k'_m$ of $k'$ is determined by a majority voting mechanism, wherein if more bits are zero than one among $k_m^r$ and $\\{k_m'^r | r \\in [1, R]\\}$, $k'_m$ is set to zero; otherwise, it is set to one.\nReshuffling Watermark Information and Verification. After recovering the key $k'$, we use it as the seed for a pseudorandom number generator (PCG64) and reapply the Fisher-Yates shuffle algorithm to re-shuffle the latent noise, excluding the key channel. This reshuffled latent noise is then split to isolate $\\hat{z}_w$ and $\\hat{z}_n$. Finally, based on the latent-based watermarking method employed, we extract and verify the watermark from $\\hat{z}_w$."}, {"title": "5. Experiment", "content": "5.1. Setup\nLatent Diffusion Models. We employed three widely-used Stable Diffusion models as base models: Stable Diffusion v1-5 (SD v1-5), Stable Diffusion v2-1 (SD v2-1), and SD-XL 1.0-base (SDXL 1.0). For customized models, we downloaded 60 checkpoints from Hugging Face (Face), fine-tuned from three base models (SD v1-5, SD v2-1, and SDXL 1.0), with each base model comprising 20 different checkpoints. Detailed on these 60 checkpoints is provided in the Appendix. Compared to previous work, our study covers the largest model set to date (60 models, vs. Tree-ring with 1, Gaussian Shading with 3, and DiffuseTrace with 2).\nImage Generation Details. To generate images, we use prompts from the Stable-Diffusion-Prompts dataset. The generated image resolution is 512\u00d7512 pixels,"}, {"title": "SWA-LDM: Toward Stealthy Watermarks for Latent Diffusion Models", "content": "with latent noise dimensions set to 4\u00d764\u00d764 and a guidance scale of 7.5. We use DDIM sampling with 50 timesteps. In practice, the original prompts of the generated images are often not shared. Hence, we use an empty prompt for diffusion inversion . In this process, we set the guidance scale to 1 and perform 50 timesteps of DDIM inversion.\nBaselines. We evaluate three representative latent-noise-based watermarking methods: Tree-ring , Gaussian Shading , and DiffuseTrace . For Gaussian Shading, we test both implementations, with and without the ChaCha20 secure stream cipher, which shuffles the watermark sequence. Detail of these methods are in the Appendix.\nEvaluation Metrics. To evaluate watermark presence attacks, we use the area under the ROC curve (AUC). Attack results on watermarking methods indicate stealthiness, calculated as (1 - AUC of watermark presence attack). We benchmark watermark effectiveness by reporting AUC and TPR at 1% FPR (noted as TPR@1%FPR) and bit accuracy for encoded information. For watermarked image quality, we use the CLIP score between generated images and prompts, measured using OpenCLIP-ViT/G and the Fr\u00e9chet Inception Distance (FID) . FID, which evaluates feature similarity between generated and original images, is calculated from 5,000 images per base model generated using the MS-COCO-2017 dataset.\nSetup of Watermark Presence Attack. The attacker generates 1,000 clean images using three base models (SD v1-5, SD v2-1, SDXL 1.0) and evaluates performance by averaging results across models. For the watermark feature extractor, we use a 12-layer CNN with convolutional and fully connected layers, ReLU activations, and layer normalization, outputting a 100-dimensional feature vector. Training uses SGD optimizer with a learning rate of 0.01, momentum of 0.9, and a scheduler with a 0.5 decay factor every 50 steps. Detailed architecture is in the Appendix.\nSetup of SWA-LDM. We integrate SWA-LDM with three baseline methods: SWA-LDM with Tree-Ring (SWA-LDM(T-R)), SWA-LDM with DiffuseTrace (SWA-LDM(D-T)), and SWA-LDM with Gaussian Shading (SWA-LDM(G-S)). Each method uses a key channel count of 1 to construct an 8-bit key with 64 redundant bits. The number of watermark channels is set to 1 for SWA-LDM(T-R) and 3 for both SWA-LDM(D-T) and SWA-LDM(G-S)."}, {"title": "5.2. Comparison to Baseline Methods", "content": "Stealthiness Comparison. We conduct watermark presence attack experiments across SWA-LDM and baselines. The attack performance, summarized in the \"Stealthiness\" column of Table 1, shows the average stealthiness achieved by each method against an attacker using different base models.\nThe results show that watermark presence attacks effectively detect watermarks in baseline methods. SWA-LDM improves stealthiness and provides defense against these attacks. Among baseline methods, Gaussian Shading is the most detectable, with the lowest stealthiness, while DiffuseTrace and Tree-Ring offer slight improvements but remain vulnerable. Gaussian Shading with ChaCha20 increases stealthiness but requires costly per-image nonce management. In contrast, SWA-LDM achieves ChaCha20-level stealthiness without nonce dependency, integrating smoothly with DiffuseTrace, Tree-Ring, and Gaussian Shading. Further analysis on the base model's impact on detection is in Section 5.3.\nWatermarking Effectiveness Comparison. For the evaluation of watermark effectiveness, As detailed in Section 5.1, each base model (SD v1-5, SD v2-1, SDXL 1.0) is fine-tuned to produce 20 checkpoints, each generating 1,000 images, resulting in 60,000 watermarked and 60,000 clean images per method. As shown in Table 1, SWA-LDM maintains AUC, TPR@1%FPR, and bit accuracy comparable to original methods, with slight metric decreases due to key construction from latent noise for enhanced stealthiness. SWA-LDM also has minimal impact on FID and CLIP scores, preserving LDM-generated image quality.\nBenchmarking Watermark Robustness To evaluate the robustness of SWA-LDM, we assess its performance under seven common image perturbations as potential attacks: JPEG compression, random crop, random drop, resize and restore(Resize), Gaussian blur (GauBlur), median filter (MedFilter), brightness adjustments. The parameter ranges are shown in the Appendix. For each parameter setting of every perturbation, we used 2,000 images generated by the SD v1-5 to evaluate performance. The average verification AUC for each perturbation is reported in Table 2, which compares the robustness of various watermarking methods, both with and without the integration of SWA-LDM. Results indicate that SWA-LDM maintains robust watermark verification under moderate image perturbations, demonstrating its robustness. However, incorporating SWA-LDM impacts the original robustness of these watermarking methods, especially under high-intensity distortions. This occurs because SWA-LDM requires complete recovery of each bit in the key to retrieve the watermark, which can reduce robustness. Nevertheless, unless the image undergoes quality-compromising levels of perturbation, watermark remains practical."}, {"title": "5.3. Ablation Studies", "content": "Impact of the clean SD model on watermark presence attack. We evaluated whether the effectiveness of the watermark presence attack is influenced by the base model used by the attacker to generate clean images. Results"}, {"title": "6. Conclusion", "content": "In conclusion, we address critical vulnerabilities in latent-based watermarking methods for Latent Diffusion Models (LDMs) by exposing their susceptibility to detection through constant watermarks. We introduce a novel watermark presence attack that operates solely on generated images, setting a new standard in the field and highlighting the urgent need for enhanced watermarking strategies. To counter these vulnerabilities, we present SWA-LDM, a plug-and-"}]}