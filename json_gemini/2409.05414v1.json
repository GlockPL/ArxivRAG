{"title": "CipherDM: Secure Three-Party Inference for Diffusion Model Sampling", "authors": ["Xin Zhao", "Xiaojun Chen", "Xudong Chen", "He Li", "Tingyu Fan", "Zhendong Zhao"], "abstract": "Diffusion Models (DMs) achieve state-of-the-art synthesis results in image generation and have been applied to various fields. However, DMs sometimes seriously violate user privacy during usage, making the protection of privacy an urgent issue. Using traditional privacy computing schemes like Secure Multi-Party Computation (MPC) directly in DMs faces significant computation and communication challenges. To address these issues, we propose CipherDM, the first novel, versatile and universal framework applying MPC technology to DMs for secure sampling, which can be widely implemented on multiple DM based tasks. We thoroughly analyze sampling latency breakdown, find time-consuming parts and design corresponding secure MPC protocols for computing nonlinear activations including SoftMax, SiLU and Mish. CipherDM is evaluated on popular architectures (DDPM, DDIM) using MNIST dataset and on SD deployed by diffusers. Compared to direct implementation on SPU, our approach improves running time by approximately 1.084\u00d7 ~ 2.328\u00d7, and reduces communication costs by approximately 1.212\u00d7 ~ 1.791x.Code is available at: https://github.com/Zhaoxinxinzi/CipherDM.", "sections": [{"title": "1 Introduction", "content": "Generative models represented by Pre-trained Transformer Models [54] and Diffusion Models (DMs) [19, 50, 53] have gained significant attention due to their impressive performance in text and image generation tasks. These models have become widely utilized in Deep Learning as a Service (DLaaS) paradigm [51]. However, the utilization of such services raises concerns about privacy. In the case of ChatGPT [6] and Stable Diffusion (SD) [47], users are required to disclose their private prompts or images to service providers, such as websites or apps that possess substantial computing resources. Alternatively, service providers may release their proprietary trained model parameters to users, who can then perform inference or sampling locally.\nThe remarkable performance of DMs in image synthesis has been demonstrated in several recent works [39, 44, 45, 47, 57]. However, these works also raise concerns about privacy issues [39, 44, 47]. For instance, the fundamental work of SD [47] claims that training data used in DMs may contain sensitive or personal information, and there might be a lack of explicit consent during data collection process. On the other hand, Glide [39] emphasizes that their model has the capability to generate fake but highly realistic images, which could potentially be used to create convincing disinformation or Deepfakes. To address ethical concerns, Glide filters out training images that contain people, violence, and hate symbols, thereby reducing model's potential for misuse in problematic scenarios. Another example is the work by Ramesh [44], which trains their model on a specific dataset that is carefully filtered to ensure aesthetic quality and safety. These works primarily focus on issues of data privacy and content realism. Despite implementing measures to mitigate safety concerns, they cannot guarantee the protection of privacy information sufficiently.\nTraditional sampling phase [19, 27, 52, 60] faces risk of leaking users' private prompts or images, as well as providers' model parameters. For users, the prompts and images used in sampling process may contain sensitive information, including personal portrait, identities, habits and professions. The unauthorized collection of such information by illegal organizations poses a significant threat to user privacy. Similarly, for model providers, the training process of DMs requires substantial investments in terms of time and resources. The leakage of model details, including parameters and architecture, can significantly impact their benefits and competitive advantage. Given these concerns, it is crucial to prioritize the protection of privacy during sampling process.\nClassic privacy computing categorizes to Differential Privacy (DP) [2, 8, 14, 24], Homomorphic Encryption (HE) [3, 4, 25, 49] and Secure Multiparty Computation (MPC) [10, 12, 31, 37, 38, 40]. Although DP is generally considered as an efficient approach, it cannot effectively guarantee precision and accuracy of the calculation results. Additionally, it currently lacks rigorous security proofs. HE maintains confidentiality of data at the expense of high computational complexity. MPC offers a solution that allows mutually distrusting parties to collaboratively evaluate a function using their private inputs, while ensures that only output of the function is revealed and no party can gain additional information. This computation guarantees both privacy and correctness, preventing corrupt parties from learning anything but the output and ensuring that honest parties do not accept an incorrect output. Several works [13, 16, 22, 29, 59] have proposed MPC-based solutions for performing inference on transformer models. However, to the best of our knowledge, no MPC-based approaches for secure sampling on DMs have been developed thus far. To our conjectures, the primary reasons for absence of related work may contain unclear privacy assessment in image generation results, difficulty in integrating DMs with MPC frameworks and low sampling efficiency in private computing.\nBased on aforementioned observations, we present CipherDM, the first MPC-based inference framework that provides rigorous MPC guarantees for sampling"}, {"title": "3 Background", "content": "3.1 Diffusion Models\nDiffusion Models (DMs) utilize a two-step Markov chain process to generate image samples from initial noise images. This process can be divided into two distinct chains: the forward process and the reverse process. The forward process in DMs can be likened to a Brownian motion, where a real image $x_0$ is transformed gradually into a latent Gaussian noise space $x_T$. This procedure tends to model data distribution by approximating the intermediate images between $x_0$ and $x_T$. Besides, the reverse process, also known as the backward Markov chain, aims to generate the initial image $x_0$ by leveraging a learned Gaussian transition. Its goal is to infer the initial image distribution conditioned on the final image. By combining both forward and reverse processes, DMs can effectively capture the complex data distribution and generate high-quality samples.\nDDPM [19] is a representative diffusion model that motivates many follow-up works. To explain how CipherDM inference on DMs, we take DDPM for example and provide a brief review of its underlying mechanism. DDPM maps Gaussian distribution $N(x_T; 0,I)$ to the distribution of real images $q(x_0)$, and aims to recover initial $x_0$ from the mapped noise image.\nThe forward process gradually adds Gaussian noise to the data sample according to the variance schedule $\\beta_1,..., \\beta_T$ and finally reaches a standard Gaussian distribution $x_T \\sim N(0,I)$. Because of the well-designed variance schedule, we can express $x_t$ at any arbitrary timestep $t$ in closed form Eq. (1) with the notation $\\alpha_t := 1 - \\beta_t$ and $\\bar{\\alpha}_t := \\Pi_{i=1}^t \\alpha_i$: \n$$q(x_t|x_0) = N(x_t; \\sqrt{\\bar{\\alpha}_t}x_0, (1 - \\bar{\\alpha}_t)I)$$\n(1)\nThe reverse process starts at $p(x_T) = N(x_T; 0, I)$. Strict inference and proof conclude that the distribution of $x_{t-1}$ is also Gaussian given conditions of $x_0$ and $x_t$. Therefore, the $x_{t-1}$ at any arbitrary timestep t can also be expressed"}, {"title": "3.2 2-out-of-3 Replicated Secret Sharing", "content": "The main notations related to secret sharing and protocols are summarized in Tab. 1.\nIn 3PC setting, a secret value $x \\in Z_{2^l}$ is shared by three random values $x_0, x_1, x_2 \\in Z_{2^l}$ which satisfies $x = x_0 + x_1 + x_2$. Particularly in the 2-out-of-3 replicated secret sharing (denoted as $[\\cdot]$-sharing), party $P_i$ gets $[x]_i = (x_i, x_{i+1})$.\nWithout special declaration, we compute in $x \\in Z_{2^l}$ and omit (mod $2^l$) for brevity. We use notation $[ ]$ to represent Arithemetic Sharing, which supports arithemetic operations (e.g., +, - and \u00b7) when $l > 1$ (e.g.,l = 64). While in the case of $l = 1$ where (+, -) and \u00b7 are respectively replaced by bit-wise $\\oplus$ and $\\land$, we refer to this type as Boolean Sharing $([\\cdot]_B)$.\nAddition. Assuming $(C_1, C_2, C_3)$ be public constants and $([x], [y])$ be two secret-shared values, we can compute $[C_1x + C_2y + C_3]$ through summarizing each part of $(c_1x_0 + c_2y_0 + c_3, c_1x_1 + c_2y_1, c_1x_2 + c_2y_2)$, which can be calculated by $P_i$ locally. Typically we can get $[x + y]$ by setting $c_1 = 1, c_2 = 1, c_3 = 0$.\nMultiplication. Given two shared values $[x]$ and $[y]$, the share $[xy]$ can not be calculated by multipliating $[x]$ and $[y]$ directly. In the secure multiplication protocol $\\Pi_{Mul}$, $P_i$ first computes $z_i = x_iy_i + x_{i+1}y_i + x_iy_{i+1}$ locally and sends"}, {"title": "4 Secure Design of CipherDM", "content": "In this section, we first present an overview of CipherDM for securely sampling Diffusion Models (DMs) in Sec. 4.1. Then we introduce details of the Secure Soft-Max protocol in Sec. 4.2, the Secure Activations (SiLU and Mish [36]) protocol in Sec. 4.3 and the Secure Time Embedding protocol in Sec. 4.4.\n4.1 Overview\nCipherDM adopts a secure outsourcing computing scenario where users send their private model and input to cloud servers to attain inference result. This situation makes sense in practice, because it is easy to find a credible third-party regulator that can provide computing power. In CipherDM shown as Fig. 3, a model provider M holds private diffusion model parameters $w$, and the client C holds data $x$ (e.g., images or texts). C sends its private $x$ to cloud servers S after preprocessing locally, while M takes $w$ as input. Diffusion model architecture is typically considered public and accessible to all participants. Then S leverages an MPC engine to convert the inputs into secret sharing and distribute the"}, {"title": "4.2 Secure SoftMax", "content": "The SoftMax function is employed in the attention block of U-Net [48]. It can be expressed as SoftMax$(x[i]) = \\frac{exp(x[i]-x^{-6})}{\\sum_j exp(x[i]-x^{-6})}$, where $x$ is the maximum element of input vector x. e is a tiny and positive value (e.g., $\\epsilon = 10^{-6}$) for ciphertext and equals 0 for plaintext. As the exponentiation function takes most time of computation shown as Fig. 2, we replace it with Chebyshev polynomial [34], which can be computed as Eq. (3).\n$$negExp(x) = \\begin{cases} 0, & x <Texp \\\\ Chebyshev(x), & x \\in [Texp, 0] \\end{cases}$$\n(3)\nSupposing MPC system uses 18-bit fixed-point precision, we set $Texp = -14$ given exp(-14) < $2^{-18}$, and then fit the approximating with a maximum order of 7. The choice of this polynomial order is crucial in achieving an accurate approximation. Higher-order polynomials can capture more intricate details of the exponential function but may lead to increased computational complexity. On the other hand, lower-order polynomials may not capture the exponential behavior accurately. Accordingly, the computation of Chebyshev(x) can be expressed"}, {"title": "4.3 Secure Activations", "content": "ReLU, SiLU and Mish [36] are three main activation functions of U-Net [48] in DMs. ReLU, short for Rectified Linear Unit, is defined as ReLU(x) = max(0, x). It is a simple and computationally efficient activation function that involves only linear operations. In contrast, SiLU (Sigmoid-Weighted Linear Unit) and Mish [36] are activation functions that involve more complex non-linear operations. SiLU, also known as Swish, is defined as SiLU(x) = $x * Sigmoid(x)$ where Sigmoid(x) = $\\frac{1}{1+e^{-x}}$. Mish, proposed by Diganta Misra [36], is defined as Mish(x) = $x * Tanh(Softplus(x))$ where Softplus(x) = $ln(1+ e^x)$. To optimize the computational efficiency of exponential (exp) and hyperbolic tangent (tanh) functions, we replace them with linear piecewise fitting functions shown as Eq. (5). Considering both SiLU and Mish functions exhibit almost linear on the two sides (i.e. SiLU/Mish(x) \u2248 0 for x < -6 and SiLU/Mish(x) \u2248 x for x > 6),"}, {"title": "4.4 Secure Time Embedding", "content": "The time embedding module (tMLP) comprises one Positional Embedding layer, two Linear layers and one SiLU layer. However, the exponentiation operation in both Positional Embedding layer and SiLU layer contributes to most latency. To reduce running time we replace the exponentiation in Positional Embedding layer with Chebyshev fitting as Eq. (4), and compute SiLU layer by SiLU"}, {"title": "5 Experiments", "content": "Implementation. We implement CiperDM on top of SPU [33] in C++ and Python. SPU compiles a high-level Flax code to secure computation protocols, which are then executed by designed cryptographic backends. We run our experiments on Ubuntu 20.04.1 LTS with Linux kernel 5.4.0-146-generic. The CPU mode is Intel(R) Xeon(R) Silver 4314 CPU @2.40GHz with 500GB RAM and a single thread. We use Linux tc tool by Cheetah [23] to simulate local-area network (LAN, RTT: 0.1 ms, 1 Gbps). All frameworks are measured in both local and LAN scenes.\nModels & Datasets. We evaluate CipherDM on diffusion model architectures: DDPM, DDIM and SD. We measure the sampling performance for DDPM and DDIM over MNIST dataset. As models of SD pipeline are too large to be deployed under SPU, we only utilize the U-Net [48] module for assessment.\nBaseline. We compare CipherDM with the direct implementation on SPU.\n5.1 Inference Costs\nIn this subsection, we conduct experiments to obtain inference costs on CPU, SPU, and our CipherDM framework. Sampling costs of CipherDM are compared"}, {"title": "6 Conclusion", "content": "In this paper, we introduce CipherDM, a novel MPC framework designed to address privacy concerns in secure sampling on Diffusion Models. Our framework aims to guarantee secure sampling with MPC technology and improve the efficiency by approximating computationally expensive activation functions with accurate polynomials. Additionally, we propose secure protocols for SoftMax and SiLU/Mish activations. While the current sampling efficiency may not be practical, this work represents an important initial step towards addressing privacy issues associated with Diffusion Models. Further work will focus on enhancing computational efficiency of secure sampling by modifying the model architecture and designing more efficient underlying protocols. By combining CipherDM with other optimization methods and leveraging hardware acceleration, we envision that secure Diffusion Model sampling will become applicable in practical scenarios in the future."}]}