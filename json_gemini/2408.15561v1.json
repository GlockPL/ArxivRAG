{"title": "CGRA4ML: A Framework to Implement Modern Neural Networks for Scientific Edge Computing", "authors": ["G Abarajithan", "Zhenghua Ma", "Zepeng Li", "Shrideep Koparkar", "Ravidu Munasinghe", "Francesco Restuccia", "Ryan Kastner"], "abstract": "Scientific edge computing increasingly relies on hardware-accelerated neural networks to implement complex, near-sensor processing at extremely high throughputs and low latencies. Existing frameworks like HLS4ML are effective for smaller models, but struggle with larger, modern neural networks due to their requirement of spatially implementing the neural network layers and storing all weights in on-chip memory. CGRA4ML is an open-source, modular framework designed to bridge the gap between neural network model complexity and extreme performance requirements. CGRA4ML extends the capabilities of HLS4ML by allowing off-chip data storage and supporting a broader range of neural network architectures, including models like ResNet, PointNet, and transformers. Unlike HLS4ML, CGRA4ML generates SystemVerilog RTL, making it more suitable for targeting ASIC and FPGA design flows. We demonstrate the effectiveness of our framework by implementing and scaling larger models that were previously unattainable with HLS4ML, showcasing its adaptability and efficiency in handling complex computations. CGRA4ML also introduces an extensive verification framework, with a generated runtime firmware that enables its integration into different SoC platforms. CGRA4ML's minimal and modular infrastructure of Python API, SystemVerilog hardware, Tcl toolflows, and C runtime, facilitates easy integration and experimentation, allowing scientists to focus on innovation rather than the intricacies of hardware design and optimization.", "sections": [{"title": "I. INTRODUCTION", "content": "Scientific applications have unique and challenging con-straints to process the data quickly and closely to where the data is generated [1]. This enforces strict real-time re-quirements to process the information at tremendously high throughputs (TB/s) and low latencies. Thus, fast machine-learning scientific applications often require hardware acceler-ators implemented on FPGAs or ASICs to meet the stringent performance requirements [2].\nHLS4ML is a popular tool for developing hardware-accelerated scientific neural networks, which implements a dataflow-style architecture with layer-specific datapaths and on-chip weight storage [3]. While this methodology provides high throughput and low latency, it does not support modern, deep neural network models (DNNs) that are too big to fit fully on-chip, requiring off-chip movement of weights and data. In addition, modern neural network models require the devel-opment of optimized layer architectures, e.g., a transformer cannot easily be implemented in HLS4ML due to its intensive customization and large memory requirements for weights.\nMost accelerators presented in the literature that support DNNs do not offer usable frameworks with parametrization of their architecture or provide support for verification and SoC integration, as described in Sec. V. The frameworks available for accelerating larger models in FPGAs do not fulfill the requirements of the scientific computing community, such as more robust quantization, extensibility to add more features, and the need to eventually move from FPGA to ASIC implementation, as summarized in Table I.\nCGRA4ML bridges the gap between HLS4ML and the needs of the scientific community to implement modern, large neural network models using an easy-to-use, high-level workflow. Like HLS4ML, CGRA4ML is entirely open source, allowing the scientific community to use, develop, and build upon it. CGRA4ML is easily programmable and scalable, allowing seamless scaling to fit the resources at hand while being easy and intuitive to integrate into the fast design prototyping flow. CGRA4ML generates a parameterizable Coarse-Grained Reconfigurable Array (CGRA) to facilitate the spatial reuse of processing elements and leverage off-chip data storage to deploy modern neural network features. Our Python API works on top of QKERAS, a popular library for quantizing and training neural networks. CGRA4ML emits RTL instead of HLS code, making it more amenable to ASIC and FPGA design flows compared to HLS4ML.\nCGRA4ML builds and configures parametrized flexible CGRA that is then programmed to compute different neu-ral network models. CGRA4ML facilitates resource sharing across neural network layers, as opposed to HLS4ML, which implements each layer as a separate datapath. CGRA4ML scales beyond HLS4ML capabilities, e.g., implementing larger ResNet models that fail to synthesize with HLS4ML. This enables scientific applications that require more complex models that cannot fit within an FPGA or given area of an ASIC. We demonstrate how CGRA4ML can be extended to handle different neural network architectures, including ResNets, PointNet, and transformers. CGRA4ML implements its hardware as fully parametrized SystemVerilog RTL mod-ules; the same implementation is supported in different FPGA and ASIC tools.\nCGRA4ML is targeted to two user groups: (1) Scientists, embedded / IoT researchers who want to build and implement modern neural networks that are infeasible in HLS4ML due to their size and complexity. (2) Hardware system designers who want to iteratively test new optimizations such as new datatypes, dataflow, and compression techniques.\nCGRA4ML provides a Python API for the end-to-end workflow to allow scientists to build and implement their designs to production-ready quality without spending months on designing and verifying hardware, optimizing computation and data bottlenecks, integrating into an SoC, and writing, verifying, and optimizing runtime firmware (see Section III). The CGRA4ML infrastructure, shown in Fig I and described in Section V, is modular and extensible to allow the hardware researchers to modify any part, implement their optimizations, and get it working without building the entire system and optimizing every part of it themselves.\nTo demonstrate the capabilities of CGRA4ML and to compare with other tools our scientific users are familiar with, we present the implementations of ResNet-50, PointNet, and Particle Transformer models in Section VI. We also present the performance, power, and area comparisons of the FPGA and ASIC implementations generated by CGRA4ML.\nThe major contributions of CGRA4ML are:\n\u2022 A hardware + software + firmware co-design framework to specify, train, quantize, and implement diverse neural networks on FPGA and ASIC as CGRA-powered SoCs.\n\u2022 A CGRA architecture with dynamic reconfiguration, uni-fied dataflow, and an efficient PE design to maximize hardware utilization for modern neural networks.\n\u2022 RTL-based high-performance, modular SoC design with open-source DMAs and AXI-compliant interfaces to sup-port vendor-agnostic FPGA and ASIC design flows.\n\u2022 Automated firmware generation enabling hardware/ soft-ware partitioning that easily integrates the CGRA with on-chip processors. Our results show how to partition DNN layers across an ARM core and the CGRA.\n\u2022 Validation of results on AMD Xilinx FPGAs and ASIC implementation using Cadence tools to be taped out as an SoC with ARM-based NanoSoC platform.\n\u2022 Extensive verification support to test the neural network model against the generated RTL design and C runtime through randomized transactional testbenches."}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "Machine learning is fueling scientific discoveries in particle physics, materials, dark matter, cosmology, nuclear physics, biomedical engineering, and health monitoring [2]. Specific examples include bio-signal classification [4], tracking mag-netohydrodynamic (MHD) instabilities in fusion reactors [5], reinforcement learning for accelerator beam control [6], pulse detection for anti-neutrino detection [7], and accelerator con-trols for beam loss deblending [8].\nScientific computing increasingly relies on neural networks to process data with requirements for extremely low latencies and high throughputs. For example, the Large Hadron Collider (LHC) has \\(10^8\\) individual sensors generating data for each of the 40 million proton beam collisions per second [9].\nNeural network-based autoencoders implemented as ASICS compress data to move it off chip [10]. LHC trigger systems filter events in real-time with sub-microsecond latency require-ments and 40 MHz throughput requirements using FPGAs [11].\nThe scientific community has benefited greatly from the ease of hardware acceleration. Among the multiple tools [12] that allow FPGA implementation of neural networks, HLS4ML is very popular [13]. Yet, HLS4ML has drawbacks as discussed in the next section. CGRA4ML allows more complex models to be implemented on FPGA and ASIC-based SoCs, moving more computation to the edge. This enables more sophisticated neural networks to be deployed in scientific equipment."}, {"title": "B. HLS4ML", "content": "HLS4ML is a Python library developed by physicists for machine learning inference in FPGAs [13]. It primarily sup-ports models built and trained using QKeras, a library from Google for low-precision machine learning [14]. HLS4ML converts the model, layer by layer into customized high-level synthesis (HLS) hardware blocks, as shown in Figure 2. HLS4ML uses different HLS implementations for different HLS tools to generate the hardware accelerator depending on the resulting target (AMD Xilinx FPGA, Altera FPGA, ASIC, etc.). The most common target is AMD Xilinx Vitis/Vivado HLS, though other backends exist in various forms (Intel HLS Compiler, Siemens Catapult HLS, etc.). The dependence on HLS restricts the user to the supported vendors and requires HLS tool-specific reimplementation of each hardware layer, complicating the maintenance and verification. HLS4ML's sup-port for ASIC implementation is primarily through Catapult HLS, which currently only supports a limited subset of layers.\nThe most common HLS4ML design flow is to generate an overall IP for the entire neural network and then integrate that IP into the SoC using vendor-specific IPs such as DMAs. There are efforts for better end-to-end development. For ex-ample, HLS4ML provides a PYNQ overlay, a Python-based runtime for AMD Xilinx Zynq FPGAs. This workflow allows the physicists to focus on building and training low-precision models for their custom applications without spending months on hardware design, implementation, and verification. Yet, by and large, the ML IP core integration for production-ready designs is a separate process from HLS4ML.\nHLS4ML implements the neural network layer by layer, as shown in Fig. 2. The user controls reuse factor per layer, which defines the number of times a multiplier/accumulator is reused. The resources needed to synthesize a layer and the number of clock cycles before its hardware block can accept new data both depend on the reuse factor. Commonly, the same reuse factor is used for all layers. This results in heavy underutilization since all hardware blocks must wait for the slowest to complete. Manual tuning of the reuse factors per layer on each target FPGA to balance the dataflow takes a lot of time and effort.\nWhile the layer-by-layer approach can offer in low-latency, efficient implementation of small models that fully fit into FPGAs, it does not support modern neural network models like transformers. There have been herculean efforts to im-plement models like ResNet-50 on up to 12 interconnected FPGAs [15]. Other large models, e.g., jet tagging using a transformer [9], are implemented on GPUs because they are impossible to implement with HLS4ML. The data filtering pipeline from the detectors of the Large Hadron Collider at CERN implements a tiny autoencoder NN on an ASIC closest to the detector. The data from the ASIC is then processed by progressively more complex NNs on FPGAs and servers. CGRA4ML strives to provide a user-friendly, more customizable workflow similar to HLS4ML while supporting larger DNNs, allowing more computations to be moved to the edge and improving the accuracy of the data filtering pipeline."}, {"title": "C. CGRA", "content": "CGRAS were originally envisioned as coarse-grained FP-GAs whose programmable elements work at the word-level instead of FPGA bit-level programming [16]. Early CGRAS were classified based on their integration into the processor. Tightly coupled CGRAs integrate into a processor data path and are executed as a custom instruction, e.g., Chess [17], MATRIX [18], and DySer [19]. Loosely coupled CGRAs act more as an accelerator that executes alongside the processor, executing in tandem with the processor and communicating via on-chip interconnect. Examples of loosely-coupled CGRAs include PipeRench [20], MorphoSys [21], CHARM [22], and FPCA [23]. CGRA4ML can be characterized as a loosely coupled CGRA as it implements sub-tasks of the neural network alongside a CPU with a focus on enabling hard-ware/software partitioning across the processor and processor.\nCGRAs have seen a recent resurgence in industry and aca-demic projects. Commercial CGRAs include Samsung Recon-figurable Processor [24] and the Renesas STP Reconfigurable Processor [25]. CGRA-ME [26] is an exemplary academic framework that supports a subset of CGRA designs.\nCGRA4ML is targeted to optimize the neural networks for scientific applications with high throughput, low latency, and real-time requirements. As a result, the default CGRA design of CGRA4ML features small processing elements (PEs) to minimize resource use and an on-the-fly reconfiguration mechanism to reduce the reconfiguration overhead."}, {"title": "D. DNN Reconfigurable Architectures", "content": "Hundreds of accelerator architectures have been designed to accelerate deep neural networks in the past decade [34]- [36]. These accelerators can be categorized by their data reuse pattern as weight, input, output & row stationary and by their runtime flexibility into systolic arrays, CGRAs, and microcode processors.\nWe compare the CGRA4ML with state-of-the-art architec-tures. Caffeine [32] offers an HLS systolic array to process CNNs from the Caffe ML framework using weight major and input major mappings. Eyeriss [37] is an energy-efficient ASIC designed to accelerate CNNs using a 2D array of 168 fairly complex processing elements, each with a 16-bit multiply-accumulate, scratchpad, and a controller. ShiDianNao [38] uses a 2D mesh of functional units optimized towards the 2D feature maps of convolutional layers. Each processing element executes multiplications, additions, and comparisons using 16-bit fixed point arithmetic. The kernel elements are shifted right to left and up to down and accumulate locally.\nWhile systolic arrays with simple PEs are optimal for matrix multiplications, they are underutilized and incur a significant overhead when computing more complex layers. CGRAs that allow greater flexibility in data routing optimally utilize their PEs but are able to fit fewer PEs within given resource constraints due to the complexity of the PEs, local scratchpad memories, and routing logic. CGRA4ML aims to strike a balance between these by providing a default CGRA engine with an efficient PE design to maximize PE utilization while allowing flexibility to dynamically regroup to process layers such as convolution maximally exploiting data reuse on multiple levels (see Section IV). CGRA4ML is primarily output stationary; weights and input pixels are stored in on-chip memories to maximize utilization."}, {"title": "E. ML to FPGA/ASIC Frameworks", "content": "There are a few end-to-end frameworks available for hardware implementation of neural networks [12]. DNNBuilder [39] and FINN [28], implement a given model as a pipeline of layers, similar to HLS4ML. DNNBuilder allows the users to customize two kinds of reuse factors: channel and kernel. FINN takes in an ONNX model, possibly exported from Brevitas [40], to generate Vivado HLS IP. This can be verified in simulation before implementing on AMD Xilinx FPGAs. FINN provides a PYNQ driver for prototyping.\nAMD Xilinx Vitis AI [29] is a closed-source library that implements a Deep Learning Processing Unit an 8-bit micro-coded processor to process neural networks optimized through their stack on AMD Xilinx FPGAs. OpenVino is a similar stack for Intel FPGAs. Apache TVM, an open-source framework for embedded AI, implements a Versatile Tensor Accelerator (VTA) [27] as a GEMM processor using Xilinx HLS. LeFlow [41] emits HLS code, which has similar advantages and disadvantages as HLS4ML.\nWhile each of these frameworks targets different groups of users, the limitations in their approaches make them in-compatible with the requirements of the scientific computing community, as listed in Table I. The popularity of HLS4ML and its features: arbitrary quantization, Xilinx and Intel FPGA backends, and support for limited verification, demonstrate the unique needs of the scientific edge community. The models used in scientific applications require quantization to arbitrary bit-widths, which is made possible by QKERAS, and not supported by Vitis AI, OpenVino, or CGRA-ME, among others. In addition, their workflow involves implementing their models on FPGAs and later moving to ASIC designs, which is not possible with Vitis AI, Apache VTA, and OpenVino since their backends are implemented in vendor-specific HLS. CGRA4ML fills this gap by providing a high-level API where the users can first configure a CGRA and export it as SystemVerilog RTL for ASIC or FPGA implementation from any vendor, then build models quantized to arbitrary bitwidths, train them using QKERAS, and export the model runtime to be executed in any host CPU."}, {"title": "III. CGRA4ML OVERVIEW", "content": "CGRA4ML is designed to satisfy the unique requirements of the scientific edge computing community, borrowing from the distinctive strengths of HLS4ML and improving upon its limitations. This section describes the CGRA4ML workflow, as shown in Fig. I for implementing scientific computing applications, while Sec. V explains the technical details.\nA typical scientific computing workflow involves building custom models with quantization-aware training. CGRA4ML's Python API supports this workflow in the same way as HLS4ML. QKERAS performs quantization-aware training. QKERAS is a library that offers robust quantization options and training algorithms [14]. After training, the user exports the model, which generates intermediate inputs and outputs as integer versions of the fixed-point representation for testing.\nAfter defining the QKeras model, it is lowered into a list of bundles. A bundle is subclass of a QKERAS layer that exists in the CGRA4ML library. Its C runtime defines its functionality and runtime parameters that map the QKeras layer to the CGRA. Bundles are further described in Sec. V-A.\nCGRA4ML implements large and diverse neural networks by creating an efficient yet programmable computational array that can easily be shared across multiple neural network layers. The array's computation and data movement are design-time parameterizable (Sec. IV-A) and run-time programmable (Sec. IV-B) to accommodate a variety of DNN layer types. CGRA4ML focuses on flexibility and data movement as a key enabler for efficient scientific neural network hardware acceleration. The CGRA and the system around it is imple-mented as SystemVerilog RTL, to target any FPGA or ASIC flow. This fundamentally differs from HLS4ML, which emits HLS code that requires a separate HLS tool to lower its output to an RTL description.\nCGRA4ML provides toolflows for ASIC implementation using Cadence and Synopsys tools. Users can add paths for their technology PDKs and memory compilers to the scripts and invoke them to synthesize place and route, check DRC vi-olations, verify layout vs. schematic (LVS), and export GDSII files. CGRA4ML allows netlist verification using gate-level simulation. Users get power, performance, and area estimates through the generated reports. ASIC designers can edit and fine-tune the base scripts generated by CGRA4ML before the final tape-out. A system on chip generated through this workflow is being taped out with the ARM-based open-source NanoSoC platform as a proof of concept, as described in Sec. V-E2.\nAfter the CGRA4ML design is implemented, it must be integrated into an SoC. CGRA4ML generates an AXI-compliant [42] high-performance IP powered by built-in open-source, design tool-agnostic AXI DMAs that can be integrated into different SoCs. CGRA4ML also directly generates the C firmware. The firmware is designed as a simple header-only library, allowing users to get the design working within min-utes and then extend it by building the system-on-chip around it, adding other hardware for co-processing or moving data through external memory, ethernet, PCIe, etc. The firmware configures the CGRA and receives data to post-process and store in buffers for processing by the next layer. The workload is shared between the CGRA and the host CPU as described in Section V-C.\nVerification dominates design time [43]. Thus, ensuring that the CGRA4ML implementation matches the neural network model is critical. CGRA4ML verification infrastructure can be invoked from Python API to target Verilator, AMD Xilinx Xsim, or Synopsys VCS simulators. This verifies the user's neural network model, the SystemVerilog RTL of the gener-ated CGRA hardware, and the generated C runtime together through a randomized SystemVerilog testbench and reports the error between the outputs of the user-defined Python model and the generated hardware."}, {"title": "IV. CGRA4ML HARDWARE ARCHITECTURE", "content": "CGRA4ML is a parametrizable, efficient CGRA optimized to execute complex neural network models. CGRA4ML uses on-chip memory to cache and reuse weights, reducing data movement and energy, a pixel shifter to facilitate data reuse for intermediate results, three high-performance, open-source AXI DMAs that move data in and out of the engine, and a hardware-based DMA controller with an AXI-Lite configura-tion. The engine is described as a vendor-agnostic SystemVer-ilog design. CGRA4ML generates the C firmware to control the engine and perform data post-processing. Figure 3 gives an overview of the CGRA architecture, interfaces, and firmware.\nThe CGRA4ML engine features three high-bandwidth AXI-4 manager ports (up to 128-bit wide) to move inputs, weights, and outputs, and one AXI-Lite subordinate port to configure the engine with runtime parameters (see Table II). Three AXI DMAs operate asynchronously to pull input and weight data from off-chip memory, feed them as AXI streams, receive the CGRA outputs as an AXI stream, and store them in on-chip memory. The control generator provides the configura-tion bits to the weights cache and pixel shifter, which process the configuration into a few bits and append them to the AXI-Stream data moving through the CGRA. CGRA4ML uses the industry-standard AMBA AXI interfaces, which enhance portability and ease the integration of the CGRA into the SoC."}, {"title": "A. Parameterized CGRA Engine Definition and Generation", "content": "A user sets the CGRA engine parameters using the Python API, which includes attributes of CGRA specification:\n\u2022 Number of Rows & Columns of PEs in the CGRA\n\u2022 Depth of weights cache\n\u2022 Bitwidth of inputs, kernel, outputs, and bias\n\u2022 Bitwidth of AXI interfaces (up to 128-bits)\n\u2022 Frequency, I/O delays\n\u2022 Max. batch, kernel sizes, in-channels, height, and width\n\u2022 Valid and Ready probabilities for randomized verification\nThe specification defines the CGRA architecture, which can be reprogrammed at runtime within these constraints to execute many different models. These attributes are parameterized into the SystemVerilog hardware to generate different CGRA en-gines quickly. The parameters are made static before synthesis based on the user-defined attributes."}, {"title": "B. Dynamic Reconfiguration and Dataflow", "content": "CGRA4ML's dataflow and tiling pattern ensures weights are maximally reused, vastly reducing off-chip data move-ment. The dataflow aims to optimize data reuse patterns; the weights, inputs, and output data move through the CGRA in a predictable pattern for convolutions, dense layers, and matrix multiplications, and can be modified using the CGRA4ML attributes. This dataflow is automated, and its control is decentralized across the PEs.\nThe Python API generates the configuration bits for a layer and passes them to the C firmware. During the setup phase, the firmware writes attributes to the AXI-Lite configuration registers. During the operation, the DMA controller reads the configuration bytes and passes them along with data through"}, {"title": "C. Performance Analysis", "content": "The number of clock cycles and the off-chip data movement required to process a layer on a CGRA with R, C rows & columns of PEs are as follows:\nClock cycles \\( = O_TI_T(1 + NH_TW(1 + I_SK_H)) \\) (1)\nWeight words \\( = O_TI_TI_SK_HC \\) (2)\nInput words \\( = O_TI_TN H_T W I_S(R + K_H/2) \\) (3)\nOutput words \\( = NH_{out}W_{out}O \\). (4)\nIncreasing the number of PEs improves the performance by increasing the on-chip computation and reducing the number of iterations \\(O_T, H_T\\). The ratio between peak performance (\\(RC \times Frequency\\)) and real performance (MAC operations in a layer/time) depends on the ratio of PEs that are idle when computing a layer as follows:\nIdle PE cols ratio\\( = [C\\%K_w]/C + [O\\%O_s]K_w/[CO_T] \\) (5)\nIdle PE rows ratio\\( = [H\\%R]/H \\) (6)\nExpression (5) is minimized by our hardware and unified dataflow design that enables the C columns of CGRA to dynamically group and process Out-Channels O. For example, for a CGRA with C=96, the ratio of idle columns in each iteration: \\((C\\%K_w)/C\\) is zero for the most common layers with \\(K_w={1,3}\\), and 1%,5%, 8% for less common layers with \\(K_w={5,7,11}\\). To further minimize the overall idle ratio of columns (Exp. 5), the user can pick C such that \\([C/K_w]\\) is a factor of O for most layers. For ResNets, multiples of 3 and 4 (C=12,24,96), and for Transformers, multiples of 8 (C=8, 16, 32) are such optimal choices. Among the R columns of the CGRA, Expression 6 is minimized by choosing R as the common factor of the H of most layers of the DNNs the user wishes to run on the generated hardware."}, {"title": "V. CGRA4ML FRAMEWORK", "content": "CGRA4ML is a modular, extensible framework with a Python frontend that processes the neural network models and generates SystemVerilog RTL of specified CGRA hard-ware and SoC components, TCL toolflows for FPGA and ASIC design, a production-ready C runtime firmware, and the SystemVerilog testbench suite that verifies the users' model, generated hardware and C runtime comprehensively. This"}, {"title": "A. Bundles", "content": "The Bundle is the core building block of the CGRA4ML infrastructure that acts as the gateway between the neural network built by the user and the version that runs on the hardware. In the Python front-end, Bundle is implemented as a subclass of QKERAS Layer with additional functions. In the C runtime, Bundle is implemented as a set of runtime parameters and C functions that operate on them. A bundle is a set of QKERAS layers that can be deterministically executed on our hardware framework, as seen in Figure 6. The layers inside a bundle can be enabled or disabled, parametrized by a set of runtime parameters, and skip connections can be optionally added. A list of such Bundles forms various architectures the scientific computing community uses, including Autoencoders, ResNets, and Transformers. Given our extensible infrastruc-ture, the users can also extend and build their own bundles by adding to the Python front-end and C runtime.\nFigure 6 demonstrates the layers in ResNet-50 grouped into a list of bundles. Some bundles only have a Conv2D layer, while others include activations, pooling, flattening, and skip connections. Our intermediate representation realizes this by optionally enabling the different layers within a bundle. The Python front-end handles the transformation, verifies the intermediate outputs by comparing with QKERAS results, statically partitions them to be run on the CGRA and the CPU, and generates C firmware to execute the bundles in runtime.\nConvolutional and dense layers and matrix multiplications are repetitive but computationally heavy but tensor opera-tions that require hundreds or thousands of MAC (multiply-accumulate) to compute a single summed result. These are best suited to be accelerated in our dedicated, parameterized CGRA with R rows and C columns of processing elements that compute R\u00d7C(= 192, 768, 1024) summed values in parallel over hundreds or thousands of clocks before storing them in on-chip memory.\nPixel-wise operations like pooling are lightweight but com-plex since countless edge cases need to be handled to replicate the behavior of ML frameworks like Keras. Therefore, these are executed in software on the CPU that controls the CGRA, while the engine computes the next set of summed pixels. This way, further operations can be easily added to the firmware without rewriting and verifying the hardware.\nFor more elaborate operations such as the attention mecha-nism, we provide classes that are internally built using multiple bundles and decomposed as such during the runtime. This helps the user build models such as transformers with ease."}, {"title": "B. CGRA4ML Software", "content": "The Python library is built upon QKERAS for building and training quantized models. QKERAS was chosen because the scientific computing community widely uses it to build and implement models on FPGAs. A bundle is implemented in Python as a subclass of a QKERAS Layer, such that a list of bundles form a QModel that can be natively trained using the optimization algorithms available in QKERAS [44]. QKERAS supports fixed point, binary, and ternary quantization techniques, with various scaling and rounding options, such as rounding to the nearest even and stochastic rounding, to achieve numerical stability and to maximize accuracy in the smallest number of bits. Qkeras also provides quantized and hardware-friendly approximations to activation functions such as ReLu, Softmax, Sigmoid, and Tanh. During backprop-agation, QKERAS uses a straight-through estimator [45] to maintain stability.\nAfter the quantization-aware training, our framework de-codes the graph structure of the given neural network. The directed acyclic graph is traversed depth-first to identify depen-dencies between layers such output tensors and skip connec-tions. The runtime buffer sizes for these tensors are determined based on the tensor shapes, and their lifetimes are calculated from the graph traversal to identify at which point they should be freed during the runtime. Then, each tensor in the generated runtime is statically assigned a memory address, freeing and reusing the buffers after their lifetimes. This compile-time static allocation makes the C runtime deterministic, avoiding memory leaks."}, {"title": "C. CGRA4ML Firmware", "content": "CGRA4ML provides an optimized runtime written in generic C that can be compiled to ARM, RISC-V, or other targets. The Python front-end writes a config.h file that con-tains the model definition as a list of bundles with runtime parameters. The C runtime, compiled by the user with the model-specific config.h, handles the engine, reading inputs and writing outputs to pre-determined buffers. This allows the user to add further co-processors and Ethernet/PCIe pipelines by simply moving the data to and from these buffers.\nOur firmware is built in three layers, to be modular and extensible to new architectures & embedded systems:\n\u2022 Model specification - exported from Python API\n\u2022 Runtime - independent of the architecture & model\n\u2022 Architecture specific functions\nThe runtime is written as a set of C functions that can be compiled and executed for any architecture (x86, ARM, RISC-V), and can be interfaced with the testbench as DPI-C functions for any simulator: Vivado XSim, Synopsys VCS, Verilator (C++). The firmware runs in parallel to the CGRA, applying pixel-wise operations to the tensor computed by the CGRA in the previous iteration. Two banks of on-chip memory are used in a ping-pong configuration. Data synchronization between the host CPU and the CGRA is achieved by acquiring an releasing the lock registers implemented in the AXI-Lite configuration register bank."}, {"title": "D. CGRA4ML Verification", "content": "Verification is an often overlooked aspect of research de-signs, which results in significant friction when transitioning from FPGA to ASIC flows. When users implement sophisti-cated models and developers add new features, it is important to ensure they will work as intended on the final embedded system before investing the effort to implement them. Our verification infrastructure has been tested on Synopsys VCS, AMD-Xilinx Xsim, and Verilator (open source).\nCGRA4ML offers a sophisticated verification suite that is integrated across hardware, software, and firmware. Our randomized, transactional testbench suite is built in Sys-temVerilog and interfaces with the IP's AXI-Manager ports. The SystemVerilog Direct Programming Interface for C (DPI-C) is utilized in a novel manner to interface the runtime firmware functions with the SV testbench suite to achieve holistic verification.\nFirst, a randomized tensor is passed through the user's deep neural network model to capture intermediate and final output tensors in the software frontend. These are sliced, reshaped, and tiled to produce the expected inputs and outputs from the dataflow. During simulation, the data memory resides on the C side and is accessed from the SV side through custom functions. When the simulation begins, a function from the C runtime is called through DPI-C to load the model-specific configuration into the AXI-Lite register bank. As the simulation progresses, the AXI interfaces of the SV testbench read the data memory from the C side and feed the tensors into the RTL design. The outputs from the design are similarly stored into the memory. This process is randomized, such that the valid & ready signals of the address, data and response channels of the AXI interfaces are randomly toggled at the probability set by the user. This randomization emulates the behavior of a congested bus interface, stress-testing the system under realistic conditions and revealing bugs that would otherwise be unidentifiable. The intermediate and final results from the simulation are dumped into files, which the Python API then tests against the expected results.\nOur comprehensive verification suite ensures that the model built and trained by the user works as it should on the RTL design and the firmware of the entire embedded system, before even starting the implementation process. After implemen-tation, the same suite can be used on the gate level, time annotated netlist. This allows the developer and the user to add functionality to hardware and the runtime firmware and test it on their desktop before testing it on an FPGA, allowing agile development cycles. A set of GitHub actions running in the cloud verify the entire infrastructure using Verilator for multiple random examples after every update, enabling continuous integration and development (CI/CD), as shown in Figure 5."}, {"title": "E. FPGA & ASIC Toolflows", "content": "CGRA4ML is built to generate synthesizable SystemVer-ilog RTL hardware to support both FPGA and ASIC imple-mentation flows while being agnostic to vendor-specific tools and devices. Our hardware modules feature open AXI", "46": [47], "Toolflow": "Our design decisions ensure that inte-grating the generated IP into an FPGA system is fairly straight-forward. We provide modular TCL scripts to enable such integration, which automates the following process. On AMD-Xilinx FPGAs, the ZYNQ processing system is first configured to have three full AXI Subordinate ports with the maximum width (128-bit on ZCU104) for the highest throughput and one AXI-Lite Manager port for configuration. Their address mappings are updated, and the IP ports are connected to them. The TCL scripts then verify the connections, synthesize, place & route the design, exporting bitstream and generating reports.\nIn addition to this standard flow, the standardized AXI inter-"}]}