{"title": "CGRA4ML: A Framework to Implement Modern Neural Networks for Scientific Edge Computing", "authors": ["G Abarajithan", "Zhenghua Ma", "Zepeng Li", "Shrideep Koparkar", "Ravidu Munasinghe", "Francesco Restuccia", "Ryan Kastner"], "abstract": "Scientific edge computing increasingly relies on hardware-accelerated neural networks to implement complex, near-sensor processing at extremely high throughputs and low latencies. Existing frameworks like HLS4ML are effective for smaller models, but struggle with larger, modern neural networks due to their requirement of spatially implementing the neural network layers and storing all weights in on-chip memory. CGRA4ML is an open-source, modular framework designed to bridge the gap between neural network model complexity and extreme performance requirements. CGRA4ML extends the capabilities of HLS4ML by allowing off-chip data storage and supporting a broader range of neural network architectures, including models like ResNet, PointNet, and transformers. Unlike HLS4ML, CGRA4ML generates SystemVerilog RTL, making it more suitable for targeting ASIC and FPGA design flows. We demonstrate the effectiveness of our framework by implementing and scaling larger models that were previously unattainable with HLS4ML, showcasing its adaptability and efficiency in handling complex computations. CGRA4ML also introduces an extensive verification framework, with a generated runtime firmware that enables its integration into different SoC platforms. CGRA4ML's minimal and modular infrastructure of Python API, SystemVerilog hardware, Tcl toolflows, and C runtime, facilitates easy integration and experimentation, allowing scientists to focus on innovation rather than the intricacies of hardware design and optimization.", "sections": [{"title": "I. INTRODUCTION", "content": "Scientific applications have unique and challenging con-straints to process the data quickly and closely to where the data is generated [1]. This enforces strict real-time re-quirements to process the information at tremendously high throughputs (TB/s) and low latencies. Thus, fast machine-learning scientific applications often require hardware acceler-ators implemented on FPGAs or ASICs to meet the stringent performance requirements [2].\nHLS4ML is a popular tool for developing hardware-accelerated scientific neural networks, which implements a dataflow-style architecture with layer-specific datapaths and on-chip weight storage [3]. While this methodology provides high throughput and low latency, it does not support modern, deep neural network models (DNNs) that are too big to fit fully on-chip, requiring off-chip movement of weights and data. In addition, modern neural network models require the devel-opment of optimized layer architectures, e.g., a transformer cannot easily be implemented in HLS4ML due to its intensive customization and large memory requirements for weights.\nMost accelerators presented in the literature that support DNNs do not offer usable frameworks with parametrization of their architecture or provide support for verification and SoC integration, as described in Sec. V. The frameworks available for accelerating larger models in FPGAs do not fulfill the requirements of the scientific computing community, such as more robust quantization, extensibility to add more features, and the need to eventually move from FPGA to ASIC implementation, as summarized in Table I.\nCGRA4ML bridges the gap between HLS4ML and the needs of the scientific community to implement modern, large neural network models using an easy-to-use, high-level workflow. Like HLS4ML, CGRA4ML is entirely open source, allowing the scientific community to use, develop, and build upon it. CGRA4ML is easily programmable and scalable, allowing seamless scaling to fit the resources at hand while being easy and intuitive to integrate into the fast design"}, {"title": "II. BACKGROUND AND RELATED WORK", "content": "Machine learning is fueling scientific discoveries in particle physics, materials, dark matter, cosmology, nuclear physics, biomedical engineering, and health monitoring [2]. Specific examples include bio-signal classification [4], tracking mag-netohydrodynamic (MHD) instabilities in fusion reactors [5], reinforcement learning for accelerator beam control [6], pulse detection for anti-neutrino detection [7], and accelerator con-trols for beam loss deblending [8].\nScientific computing increasingly relies on neural networks to process data with requirements for extremely low latencies and high throughputs. For example, the Large Hadron Collider (LHC) has (100M) individual sensors generating data for each of the 40 million proton beam collisions per second [9]. Neural network-based autoencoders implemented as ASICS compress data to move it off chip [10]. LHC trigger systems filter events in real-time with sub-microsecond latency require-ments and 40 MHz throughput requirements using FPGAs [11]\nThe scientific community has benefited greatly from the ease of hardware acceleration. Among the multiple tools [12] that allow FPGA implementation of neural networks, HLS4ML is very popular [13]. Yet, HLS4ML has drawbacks as discussed in the next section. CGRA4ML allows more complex models to be implemented on FPGA and ASIC-based SoCs, moving more computation to the edge. This enables more sophisticated neural networks to be deployed in scientific equipment."}, {"title": "B. HLS4ML", "content": "HLS4ML is a Python library developed by physicists for machine learning inference in FPGAs [13]. It primarily sup-ports models built and trained using QKeras, a library from Google for low-precision machine learning [14]. HLS4ML converts the model, layer by layer into customized high-level synthesis (HLS) hardware blocks, as shown in Figure 2. HLS4ML uses different HLS implementations for different HLS tools to generate the hardware accelerator depending on the resulting target (AMD Xilinx FPGA, Altera FPGA, ASIC, etc.). The most common target is AMD Xilinx Vitis/Vivado HLS, though other backends exist in various forms (Intel HLS Compiler, Siemens Catapult HLS, etc.). The dependence on HLS restricts the user to the supported vendors and requires HLS tool-specific reimplementation of each hardware layer,"}, {"title": "C. CGRA", "content": "CGRAS were originally envisioned as coarse-grained FP-GAs whose programmable elements work at the word-level instead of FPGA bit-level programming [16]. Early CGRAS were classified based on their integration into the processor. Tightly coupled CGRAs integrate into a processor data path and are executed as a custom instruction, e.g., Chess [17], MATRIX [18], and DySer [19]. Loosely coupled CGRAs act more as an accelerator that executes alongside the processor, executing in tandem with the processor and communicating via on-chip interconnect. Examples of loosely-coupled CGRAs include PipeRench [20], MorphoSys [21], CHARM [22], and FPCA [23]. CGRA4ML can be characterized as a loosely coupled CGRA as it implements sub-tasks of the neural network alongside a CPU with a focus on enabling hard-ware/software partitioning across the processor and processor.\nCGRAs have seen a recent resurgence in industry and aca-demic projects. Commercial CGRAs include Samsung Recon-figurable Processor [24] and the Renesas STP Reconfigurable Processor [25]. CGRA-ME [26] is an exemplary academic framework that supports a subset of CGRA designs.\nCGRA4ML is targeted to optimize the neural networks for scientific applications with high throughput, low latency, and real-time requirements. As a result, the default CGRA design of CGRA4ML features small processing elements (PEs) to minimize resource use and an on-the-fly reconfiguration mechanism to reduce the reconfiguration overhead."}, {"title": "D. DNN Reconfigurable Architectures", "content": "Hundreds of accelerator architectures have been designed to accelerate deep neural networks in the past decade [34]- [36]. These accelerators can be categorized by their data reuse pattern as weight, input, output & row stationary and by their runtime flexibility into systolic arrays, CGRAs, and microcode processors.\nWe compare the CGRA4ML with state-of-the-art architec-tures. Caffeine [32] offers an HLS systolic array to process CNNs from the Caffe ML framework using weight major and input major mappings. Eyeriss [37] is an energy-efficient ASIC designed to accelerate CNNs using a 2D array of 168 fairly complex processing elements, each with a 16-bit multiply-accumulate, scratchpad, and a controller. ShiDianNao [38] uses a 2D mesh of functional units optimized towards the 2D feature maps of convolutional layers. Each processing element executes multiplications, additions, and comparisons using 16-bit fixed point arithmetic. The kernel elements are shifted right to left and up to down and accumulate locally.\nWhile systolic arrays with simple PEs are optimal for matrix multiplications, they are underutilized and incur a significant overhead when computing more complex layers. CGRAs that allow greater flexibility in data routing optimally utilize their PEs but are able to fit fewer PEs within given resource constraints due to the complexity of the PEs, local scratchpad memories, and routing logic. CGRA4ML aims to strike a balance between these by providing a default CGRA engine with an efficient PE design to maximize PE utilization"}, {"title": "E. ML to FPGA/ASIC Frameworks", "content": "There are a few end-to-end frameworks available for hardware implementation of neural networks [12]. DNNBuilder [39] and FINN [28], implement a given model as a pipeline of layers, similar to HLS4ML. DNNBuilder allows the users to customize two kinds of reuse factors: channel and kernel. FINN takes in an ONNX model, possibly exported from Brevitas [40], to generate Vivado HLS IP. This can be verified in simulation before implementing on AMD Xilinx FPGAs. FINN provides a PYNQ driver for prototyping.\nAMD Xilinx Vitis AI [29] is a closed-source library that implements a Deep Learning Processing Unit an 8-bit micro-coded processor to process neural networks optimized through their stack on AMD Xilinx FPGAs. OpenVino is a similar stack for Intel FPGAs. Apache TVM, an open-source framework for embedded AI, implements a Versatile Tensor Accelerator (VTA) [27] as a GEMM processor using Xilinx HLS. LeFlow [41] emits HLS code, which has similar advantages and disadvantages as HLS4ML.\nWhile each of these frameworks targets different groups of users, the limitations in their approaches make them in-compatible with the requirements of the scientific computing community, as listed in Table I. The popularity of HLS4ML and its features: arbitrary quantization, Xilinx and Intel FPGA backends, and support for limited verification, demonstrate the unique needs of the scientific edge community. The models used in scientific applications require quantization to arbitrary bit-widths, which is made possible by QKERAS, and not supported by Vitis AI, OpenVino, or CGRA-ME, among others. In addition, their workflow involves implementing their models on FPGAs and later moving to ASIC designs, which is not possible with Vitis AI, Apache VTA, and OpenVino since their backends are implemented in vendor-specific HLS. CGRA4ML fills this gap by providing a high-level API where the users can first configure a CGRA and export it as SystemVerilog RTL for ASIC or FPGA implementation from any vendor, then build models quantized to arbitrary bitwidths, train them using QKERAS, and export the model runtime to be executed in any host CPU."}, {"title": "III. CGRA4ML OVERVIEW", "content": "CGRA4ML is designed to satisfy the unique requirements of the scientific edge computing community, borrowing from the distinctive strengths of HLS4ML and improving upon its limitations. This section describes the CGRA4ML workflow, as shown in Fig. I for implementing scientific computing applications, while Sec. V explains the technical details.\nA typical scientific computing workflow involves building custom models with quantization-aware training. CGRA4ML's Python API supports this workflow in the same way as HLS4ML. QKERAS performs quantization-aware training. QKERAS is a library that offers robust quantization options and training algorithms [14]. After training, the user exports the model, which generates intermediate inputs and outputs as integer versions of the fixed-point representation for testing.\nAfter defining the QKeras model, it is lowered into a list of bundles. A bundle is subclass of a QKERAS layer that exists in the CGRA4ML library. Its C runtime defines its functionality and runtime parameters that map the QKeras layer to the CGRA. Bundles are further described in Sec. V-A.\nCGRA4ML implements large and diverse neural networks by creating an efficient yet programmable computational array that can easily be shared across multiple neural network layers. The array's computation and data movement are design-time parameterizable (Sec. IV-A) and run-time programmable (Sec. IV-B) to accommodate a variety of DNN layer types. CGRA4ML focuses on flexibility and data movement as a key enabler for efficient scientific neural network hardware acceleration. The CGRA and the system around it is imple-mented as SystemVerilog RTL, to target any FPGA or ASIC flow. This fundamentally differs from HLS4ML, which emits HLS code that requires a separate HLS tool to lower its output to an RTL description.\nCGRA4ML provides toolflows for ASIC implementation using Cadence and Synopsys tools. Users can add paths for"}, {"title": "IV. CGRA4ML HARDWARE ARCHITECTURE", "content": "CGRA4ML is a parametrizable, efficient CGRA optimized to execute complex neural network models. CGRA4ML uses on-chip memory to cache and reuse weights, reducing data movement and energy, a pixel shifter to facilitate data reuse for intermediate results, three high-performance, open-source AXI DMAs that move data in and out of the engine, and a hardware-based DMA controller with an AXI-Lite configura-tion. The engine is described as a vendor-agnostic SystemVer-ilog design. CGRA4ML generates the C firmware to control the engine and perform data post-processing. Figure 3 gives an overview of the CGRA architecture, interfaces, and firmware.\nThe CGRA4ML engine features three high-bandwidth AXI-4 manager ports (up to 128-bit wide) to move inputs, weights, and outputs, and one AXI-Lite subordinate port to configure the engine with runtime parameters (see Table II). Three AXI DMAs operate asynchronously to pull input and weight data from off-chip memory, feed them as AXI streams, receive the CGRA outputs as an AXI stream, and store them in on-chip memory. The control generator provides the configura-tion bits to the weights cache and pixel shifter, which process the configuration into a few bits and append them to the AXI-Stream data moving through the CGRA. CGRA4ML uses the industry-standard AMBA AXI interfaces, which enhance portability and ease the integration of the CGRA into the SoC."}, {"title": "A. Parameterized CGRA Engine Definition and Generation", "content": "A user sets the CGRA engine parameters using the Python API, which includes attributes of CGRA specification:\n\u2022 Number of Rows & Columns of PEs in the CGRA\n\u2022 Depth of weights cache\n\u2022 Bitwidth of inputs, kernel, outputs, and bias\n\u2022 Bitwidth of AXI interfaces (up to 128-bits)\n\u2022 Frequency, I/O delays\n\u2022 Max. batch, kernel sizes, in-channels, height, and width\n\u2022 Valid and Ready probabilities for randomized verification\nThe specification defines the CGRA architecture, which can be reprogrammed at runtime within these constraints to execute many different models. These attributes are parameterized into the SystemVerilog hardware to generate different CGRA en-gines quickly. The parameters are made static before synthesis based on the user-defined attributes."}, {"title": "B. Dynamic Reconfiguration and Dataflow", "content": "CGRA4ML's dataflow and tiling pattern ensures weights are maximally reused, vastly reducing off-chip data move-ment. The dataflow aims to optimize data reuse patterns; the weights, inputs, and output data move through the CGRA in a predictable pattern for convolutions, dense layers, and matrix multiplications, and can be modified using the CGRA4ML attributes. This dataflow is automated, and its control is decentralized across the PEs.\nThe Python API generates the configuration bits for a layer and passes them to the C firmware. During the setup phase, the firmware writes attributes to the AXI-Lite configuration registers. During the operation, the DMA controller reads the configuration bytes and passes them along with data through"}, {"title": "C. Performance Analysis", "content": "The number of clock cycles and the off-chip data movement required to process a layer on a CGRA with R, Crows & columns of PEs are as follows:\nClock cycles = OrI\u0442(1 + NH\u2081W(1 + IsKH)) (1)\nWeight words = OTITISKH\u0421 (2)\nInput words = OTITNHTWIs(R+KH/2) (3)\nOutput words = N Hout WoutO. (4)\nIncreasing the number of PEs improves the performance by increasing the on-chip computation and reducing the number of iterations OT, HT. The ratio between peak performance (RCxFrequency) and real performance (MAC operations in a layer/time) depends on the ratio of PEs that are idle when computing a layer as follows:\nIdle PE cols ratio=[C%Kw]/C+[O%Os]Kw/[COT] (5)\nIdle PE rows ratio=[H%R]/H (6)"}, {"title": "V. CGRA4ML FRAMEWORK", "content": "CGRA4ML is a modular, extensible framework with a Python frontend that processes the neural network models and generates SystemVerilog RTL of specified CGRA hard-ware and SoC components, TCL toolflows for FPGA and ASIC design, a production-ready C runtime firmware, and the SystemVerilog testbench suite that verifies the users' model, generated hardware and C runtime comprehensively. This"}, {"title": "A. Bundles", "content": "The Bundle is the core building block of the CGRA4ML infrastructure that acts as the gateway between the neural network built by the user and the version that runs on the hardware. In the Python front-end, Bundle is implemented as a subclass of QKERAS Layer with additional functions. In the C runtime, Bundle is implemented as a set of runtime parameters and C functions that operate on them. A bundle is a set of QKERAS layers that can be deterministically executed on our hardware framework, as seen in Figure 6. The layers inside a bundle can be enabled or disabled, parametrized by a set of runtime parameters, and skip connections can be optionally added. A list of such Bundles forms various architectures the scientific computing community uses, including Autoencoders, ResNets, and Transformers. Given our extensible infrastruc-ture, the users can also extend and build their own bundles by adding to the Python front-end and C runtime.\nFigure 6 demonstrates the layers in ResNet-50 grouped into a list of bundles. Some bundles only have a Conv2D layer, while others include activations, pooling, flattening, and skip connections. Our intermediate representation realizes this by optionally enabling the different layers within a bundle. The Python front-end handles the transformation, verifies the intermediate outputs by comparing with QKERAS results, statically partitions them to be run on the CGRA and the CPU, and generates C firmware to execute the bundles in runtime. Convolutional and dense layers and matrix multiplications are repetitive but computationally heavy but tensor opera-tions that require hundreds or thousands of MAC (multiply-accumulate) to compute a single summed result. These are best suited to be accelerated in our dedicated, parameterized CGRA with R rows and C columns of processing elements that compute R\u00d7C(= 192, 768, 1024) summed values in parallel over hundreds or thousands of clocks before storing them in on-chip memory.\nPixel-wise operations like pooling are lightweight but com-plex since countless edge cases need to be handled to replicate the behavior of ML frameworks like Keras. Therefore, these are executed in software on the CPU that controls the CGRA, while the engine computes the next set of summed pixels. This way, further operations can be easily added to the firmware without rewriting and verifying the hardware.\nFor more elaborate operations such as the attention mecha-nism, we provide classes that are internally built using multiple bundles and decomposed as such during the runtime. This helps the user build models such as transformers with ease."}, {"title": "B. CGRA4ML Software", "content": "The Python library is built upon QKERAS for building and training quantized models. QKERAS was chosen because the scientific computing community widely uses it to build and implement models on FPGAs. A bundle is implemented in Python as a subclass of a QKERAS Layer, such that a list of bundles form a QModel that can be natively trained using the optimization algorithms available in QKERAS [44]. QKERAS supports fixed point, binary, and ternary quantization techniques, with various scaling and rounding options, such as rounding to the nearest even and stochastic rounding, to achieve numerical stability and to maximize accuracy in the smallest number of bits. Qkeras also provides quantized and hardware-friendly approximations to activation functions such as ReLu, Softmax, Sigmoid, and Tanh. During backprop-agation, QKERAS uses a straight-through estimator [45] to maintain stability.\nAfter the quantization-aware training, our framework de-codes the graph structure of the given neural network. The directed acyclic graph is traversed depth-first to identify depen-dencies between layers such output tensors and skip connec-tions. The runtime buffer sizes for these tensors are determined based on the tensor shapes, and their lifetimes are calculated from the graph traversal to identify at which point they should be freed during the runtime. Then, each tensor in the generated runtime is statically assigned a memory address, freeing and reusing the buffers after their lifetimes. This compile-time static allocation makes the C runtime deterministic, avoiding memory leaks."}, {"title": "C. CGRA4ML Firmware", "content": "CGRA4ML provides an optimized runtime written in generic C that can be compiled to ARM, RISC-V, or other targets. The Python front-end writes a config.h file that con-tains the model definition as a list of bundles with runtime parameters. The C runtime, compiled by the user with the model-specific config.h, handles the engine, reading inputs and writing outputs to pre-determined buffers. This allows the user to add further co-processors and Ethernet/PCIe pipelines by simply moving the data to and from these buffers.\nOur firmware is built in three layers, to be modular and extensible to new architectures & embedded systems:\n\u2022 Model specification - exported from Python API\n\u2022 Runtime - independent of the architecture & model\n\u2022 Architecture specific functions\nThe runtime is written as a set of C functions that can be compiled and executed for any architecture (x86, ARM, RISC-V), and can be interfaced with the testbench as DPI-C functions for any simulator: Vivado XSim, Synopsys VCS, Verilator (C++). The firmware runs in parallel to the CGRA, applying pixel-wise operations to the tensor computed by the CGRA in the previous iteration. Two banks of on-chip memory are used in a ping-pong configuration. Data synchronization between the host CPU and the CGRA is achieved by acquiring an releasing the lock registers implemented in the AXI-Lite configuration register bank."}, {"title": "D. CGRA4ML Verification", "content": "Verification is an often overlooked aspect of research de-signs, which results in significant friction when transitioning from FPGA to ASIC flows. When users implement sophisti-cated models and developers add new features, it is important to ensure they will work as intended on the final embedded system before investing the effort to implement them. Our verification infrastructure has been tested on Synopsys VCS, AMD-Xilinx Xsim, and Verilator (open source).\nCGRA4ML offers a sophisticated verification suite that is integrated across hardware, software, and firmware. Our randomized, transactional testbench suite is built in Sys-temVerilog and interfaces with the IP's AXI-Manager ports. The SystemVerilog Direct Programming Interface for C (DPI-C) is utilized in a novel manner to interface the runtime firmware functions with the SV testbench suite to achieve holistic verification.\nFirst, a randomized tensor is passed through the user's deep neural network model to capture intermediate and final output tensors in the software frontend. These are sliced, reshaped, and tiled to produce the expected inputs and outputs from the dataflow. During simulation, the data memory resides on the C side and is accessed from the SV side through custom functions. When the simulation begins, a function from the C runtime is called through DPI-C to load the model-specific configuration into the AXI-Lite register bank. As the simulation progresses, the AXI interfaces of the SV testbench read the data memory from the C side and feed the tensors into the RTL design. The outputs from the design are similarly stored into the memory. This process is randomized, such that the valid & ready signals of the address, data and response channels of the AXI interfaces are randomly toggled at the probability set by the user. This randomization emulates the behavior of a congested bus interface, stress-testing the system under realistic conditions and revealing bugs that would otherwise be unidentifiable. The intermediate and final results from the simulation are dumped into files, which the Python API then tests against the expected results.\nOur comprehensive verification suite ensures that the model built and trained by the user works as it should on the RTL design and the firmware of the entire embedded system, before even starting the implementation process. After implemen-tation, the same suite can be used on the gate level, time annotated netlist. This allows the developer and the user to add functionality to hardware and the runtime firmware and test it on their desktop before testing it on an FPGA, allowing agile development cycles. A set of GitHub actions running in the cloud verify the entire infrastructure using Verilator for multiple random examples after every update, enabling continuous integration and development (CI/CD), as shown in Figure 5."}, {"title": "E. FPGA & ASIC Toolflows", "content": "CGRA4ML is built to generate synthesizable SystemVer-ilog RTL hardware to support both FPGA and ASIC imple-mentation flows while being agnostic to vendor-specific tools and devices. Our hardware modules feature open AXI, AXI-Stream, and AXI-Lite interfaces to ensure compatibility with a wide variety of SoCs and other hardware IPs. We utilize open-source AXI and AXI-Stream cores [46], [47] in our SoC generation, modified to support ASIC flow in addition to FPGA. All these modules are wrapped into a single IP that can be easily instantiated and connected to any system with AXI ports.\n1) FPGA Toolflow: Our design decisions ensure that inte-grating the generated IP into an FPGA system is fairly straight-forward. We provide modular TCL scripts to enable such integration, which automates the following process. On AMD-Xilinx FPGAs, the ZYNQ processing system is first configured to have three full AXI Subordinate ports with the maximum width (128-bit on ZCU104) for the highest throughput and one AXI-Lite Manager port for configuration. Their address mappings are updated, and the IP ports are connected to them. The TCL scripts then verify the connections, synthesize, place & route the design, exporting bitstream and generating reports. In addition to this standard flow, the standardized AXI inter-faces of CGRA4ML allow the user to integrate the generated IP into existing signal processing dataflow systems easily. Our scripts for AMD-Xilinx Vitis then create an application project, import the bitstream and C firmware, set compiler optimizations and allow the user to execute the system as baremetal.\nPetaLinux, the AMD-specific embedded Linux distribution, is widely used for higher-level applications with ZYNQ sys-tems. When executed on PetaLinux, our C firmware manages the physical to virtual address mapping to provide seam-less operation with an intuitive execution API, the same as baremetal. Our C firmware is also wrapped in Python using ctypes, allowing users to pass and receive data as Numpy arrays in a Python environment. This PYNQ API allows the user to be productive during prototyping, similar to the PYNQ API offered by HLS4ML. However, as the user moves towards"}, {"title": "VI. RESULTS", "content": "In this section, we present the results of experiments com-paring CGRA4ML to HLS4ML on ZCU104 evaluation board with Zynq UltraScale+_XCZU7EV-FFVC1156-2-E MPSoC FPGA. We also demonstrate CGRA4ML on deeper models such as ResNet-50 and PointNet, which are too large to be im-plemented using HLS4ML. Our ASIC results show the power and area efficiency of the RTL-based CGRA implemented using the ASIC flow provided with CGRA4ML.\nFig. 7 demonstrates the resource and power consumption for different PE arrays on the FPGA, with rows=8. Since larger arrays are more efficient in terms of GOPs/W, users should strive to implement the largest possible array within the available resources."}, {"title": "A. ResNet-50", "content": "ResNet-50 [49] is a deep convolutional neural network with 5.36 billion operations in 53 convolutional layers, one dense layer, two pooling layers, and 17 skip connections. Its input is a 224\u00d7224\u00d73 tensor, and outputs are 1000 classes, and it is run on an array of 7\u00d796=672 PEs.\nPerformance analysis of ResNet-50 on different CGRA array sizes is shown in Figure 8. Performance Efficiency is the ratio of (#PEs\u00d7clocks)/(MACs needed for the layer). It indicates the utilization of the MAC units over space and across time, and quantifies how well layers of different shapes and nature are dynamically mapped to the statically configured PE array. As discussed in Section IV-C, the unified dataflow with dynamic reconfiguration maximizes efficiency and minimizes off-chip data movement via heavy data reuse"}, {"title": "VII. CONCLUSION", "content": "In this paper, we introduced CGRA4ML, a framework for implementing large-scale neural networks in scientific edge computing applications. CGRA4ML successfully bridges the limitations of existing solutions by facilitating off-chip data storage and supporting a diverse array of neural network archi-tectures, including but not limited to Autoencoders, ResNets, and Transformers. Our framework intends to complement HLS4ML, a tool widely used by the scientific computing community by handling larger and more complex models that are crucial for advanced scientific computing tasks.\nThe ability of CGRA4ML to generate RTL designs and runtime firmware, and support end-to-end, vendor-agnostic ASIC and FPGA design flows is a notable advancement, providing a robust solution for researchers and developers aiming to leverage the speed and efficiency of hardware accel-eration without the traditional complexity. We demonstrate the effectiveness of our framework by comparing it with HLS4ML.\nOur contributions are not only technical but also extend to the ease of use and extensibility, thanks to CGRA4ML's modular and minimal infrastructure. Our Python API, along with its comprehensive verification system, ensures that sci-entific researchers can focus more on innovation and less on the intricacies of hardware design.\nBy detailing the framework's architecture, implementation, and potential for future enhancements, this paper provides a valuable resource for the ongoing development of edge computing technologies. We believe CGRA4ML will play a crucial role in advancing the capabilities of scientific edge computing, paving the way for more sophisticated and real-time data processing at the edge."}]}