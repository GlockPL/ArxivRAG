{"title": "Multi-Aggregator Time-Warping Heterogeneous Graph Neural Network for Personalized Micro-Video Recommendation", "authors": ["Jinkun Han", "Wei Li", "Zhipeng Cai", "Yingshu Li"], "abstract": "Micro-video recommendation is attracting global attention and becoming a popular daily service for people of all ages. Recently, Graph Neural Networks-based micro-video recommendation has displayed performance improvement for many kinds of recommendation tasks. However, the existing works fail to fully consider the characteristics of micro-videos, such as the high timeliness of news nature micro-video recommendation and sequential interactions of frequently changed interests. In this paper, a novel Multi-aggregator Time-warping Heterogeneous Graph Neural Network (MTHGNN) is proposed for personalized news nature micro-video recommendation based on sequential sessions, where characteristics of micro-videos are comprehensively studied, users' preference is mined via multi-aggregator, the temporal and dynamic changes of users' preference are captured, and timeliness is considered. Through the comparison with the state-of-the-arts, the experimental results validate the superiority of our MTHGNN model.", "sections": [{"title": "1 INTRODUCTION", "content": "Recommendation systems are playing an important role in everyone's daily life [1, 35]. In recent years, with the upgraded 4G & 5G networks, people can watch micro-videos anytime and anywhere, significantly promoting the popularity of micro-videos. Two top micro-video companies, TikTok [28] and Kwai [16], recommend micro-videos based on users' interests and profiles [36]. Especially, TikTok has attracted more than one billion monthly-active users around the world [7]. It is worth mentioning that micro-video recommendation greatly differs from the typical long-video recommendation in terms of logic and needs.\nAlthough micro-videos are attracting more and more global attention, there are only a few works on accurate personalized micro-video recommendation [3, 13, 17-21, 32, 33]. Moreover, the characteristics of micro-videos have not been fully explored yet. (i) Compared with long videos, micro-videos can better boost people's social behaviors and encourages people to comment, click, or share, which is ignored by some existing works [3, 17, 20]. (ii) The interactions in long-video recommendations are usually \"like\" or mandatory ratings. Differently, there exist multiple kinds of interactions between users and micro-videos [33], including \"like\", \"comment\", \"forward\", \"finish\" and so on. (iii) A micro-video is typically composed of multi-modal, such as music, title, tags, video content, and special effects, which is one of the specialties of micro-videos. (iv) In micro-video recommendation, capturing frequently changed preference is important because people's interests are influenced by historical interests, current viewing contents, and hot topics, and thus frequently changed over time, which is not studied by many current works [3, 20, 21, 32]. (v) Micro-videos require high timeliness as burgeoning news delivery and entertainment service as people usually prefer new micro-videos; that is, people would like to view the latest news, social hot spots, or the latest trends of the producers they followed, which has not been addressed by the existing works [3, 13, 17-21, 32, 33].\nMotivated by the above observations, in this paper, we aim to develop a new micro-video recommendation system framework that can comprehensively exploit the aforementioned characteristics"}, {"title": "2 RELATED WORKS", "content": "Micro-video has become more and more popular in recent years. In 2018, Ma et al. [20] proposed a micro-video recommendation model based on a deep neural network exploiting visual and textual information. Ma et al. [21] and Liu et al. [17] started to combine collaborative filtering with multi-modals to recommend micro-videos. While, many of the existing works since 2019 focus on graph-based methods. Wei et al. [32] proposed a graph neural network model, MMGCN, which constructs a heterogeneous graph to extract homogeneous information of multi-modals. In [13], time effects on different users were studied to develop MTIN that uses session-based video list and mines user group interests to recommend micro-videos. Furthermore, in 2021, researchers started to explore GNN information from the aspects of the contributions of multi-modals, purifying graphs, interest groups, and sequence of interactions. Cai et al. [3] proposed a heterogeneous GNN model, termed HHFAN, which utilizes a hierarchical structure to compute the contributions of multi-modals. CONDE was introduced as a way to integrate textual features and GNN to facilitate video content mining and user preference generation, as well as a denoising procedure to eliminate noisy concepts and poor clicks [18]. Yao et al. [33] tried to consider the influence of multi-type interaction. Lu et al. [19] proposed DMR to obtain various and dynamic preferences based on historical interests and trend groups. Some of the above work considered the temporal user-to-micro-video interactions, while some took into account group interests. But, none of them address the social relations and behaviors between users, users to micro-videos interactions, micro-videos to multi-modal interactions, or the multi-type user-micro-video interactions.\nTo enhance the performance of micro-video recommendation, in this paper, we propose a novel model, MTHGNN, to comprehensively exploit the characteristics of complex social relations by computing relation weights, multi-type interactions between users and micro-videos, session-based short-time interests, sequential session-based long-time feature extraction, and high timeliness of micro-videos."}, {"title": "3 PROBLEM STATEMENT", "content": "Formally, the set of users is denoted as $U$, and the set of micro-videos is denoted as $V$. Each micro-video owns its multi-modal attribute features, such as the titles of the micro-videos, the tags of the events, and the background music used by the micro-video producers, which are represented as $V_{attrs} = \\{A\\}$, with $A = \\{Tag, Title, Audio, ...\\}$. Generally speaking, a user may sequentially interact with micro-videos during different time periods. The matrix of user-video interactions is denoted by $O_{|U||V|}$ based on the implicit interactions provided by the users, where for $u \\in U$ and $v \\in V$, $o_{uv} \\in \\{0,1\\}$ is equal to 1 only if user $u$ interacts with micro-video $v$. In this paper, given any user $u$ with a set of historical interacted micro-video $V_u$, our algorithm MTHGNN is expected to output the user preference and micro-video embeddings, including the latest and historical information of user interests. First of all, for each user $u$, MTHGNN selects $M_u$ consecutive micro-videos to construct $u$'s heterogeneous graph $G_u$, in which the micro-videos interacted with $u$ are sorted based on their timestamps. Next, MTHGNN sequentially selects $m$ interacted micro-videos to form a session, which can represent a user's short-time preference. A series of sessions is defined as sequential sessions. Accordingly, user $u$'s sequential session can be expressed as $s_u = \\{s_{u,1}, s_{u,2},..., s_{u,n_u}\\}$, where $n_u \\le \\pi_{max}$ and $t_{max}$ is the predetermined maximum length of all session sets. Particularly, the set $S = \\{s_u\\}$ represents the latest session used to mine the latest user interests, and the set $S_Y = \\{s_{u,1}, s_{u,2},..., s_{u,n_u-1}\\}$ represent the"}, {"title": "4 METHODOLOGY", "content": "In this paper, a novel Multi-aggregator Time-warping Heterogeneous Graph Neural Network (MTHGNN) is proposed to solve the challenges described in Section 1. As shown in Fig. 1, our proposed model framework consists of seven components, including: (i) User-video Graph Structure and Data Processing, (ii) Heterogeneous Graph Construction, (iii) Heterogeneous Graph Sessions, (iv) Multi-aggregator, (v) Session Attention, (vi) Sample Strategy, and (vii) Model Training & Prediction. The design of these components in MTHGNN are demonstrated as follows."}, {"title": "4.1 User-video Graph Structure and Data Processing", "content": "The interaction type between users and micro-videos is helpful to mine user's preference patterns. For example, if user $u_1$ likes micro-video $v_1$ and finishes watching micro-video $v_2$, $v_1$ contributes more information to the user's preference, because \"like\" is an explicit preference that the user tells us directly, while \"finish watching\" is an implicit preference implying the user may be interested in the video. However, the traditional models do not utilize such latent information.\nTo address this problem, the interaction type is taken into account in the relation defining layer, i.e., the multi-relation is defined as $R = \\{r_{u\\rightarrow v}^{like}, r_{v\\rightarrow u}^{like}, r_{u\\rightarrow v}^{finish}, r_{v\\rightarrow u}^{finish}, r_{u\\rightarrow v}^{prod}, r_{v\\rightarrow u}^{prod}, r_{a\\rightarrow v}^{attr}, r_{v\\rightarrow a}^{attr}\\}$, where $r_{u\\rightarrow v}^{like}$ and $r_{v\\rightarrow u}^{like}$ represent the relations that user u likes micro-video v, $r_{u\\rightarrow v}^{finish}$ and $r_{v\\rightarrow u}^{finish}$ denote the relations that user u finishes watching micro-video v, $r_{u\\rightarrow v}^{prod}$ and $r_{v\\rightarrow u}^{prod}$ mean that micro-video v is produced by user u, and $r_{a\\rightarrow v}^{attr}$ and $r_{v\\rightarrow a}^{attr}$ ($a \\in A$) reveal how micro-video v is connected with"}, {"title": "4.2 Heterogeneous Graph Construction and Heterogeneous Graph Sessions", "content": "For effectively modeling the information of the users, micro-videos, and multi-modal attributes, Multi-modal Heterogeneous Graph (MHG) is used to represent the connections and relations between nodes. The global MHG is formally denoted as $G = (N, E, R)$, where $N = U \\cup V \\cup V_{attrs}$ is the set of multi-type nodes, and $E = \\{e_{i,j}|i \\in N, j \\in N\\}$ is the set of edges. If there is a kind of relation between nodes i and j, an edge $e_{i,j}$ is connected between node i and j on graph G with their corresponding relation type $r \\in R$.\nTo improve the time efficiency of training process, for each user u, the local MHG $G_u$ is constructed in the Heterogeneous Graph Construction component as presented in Algorithm 1, and then the global graph is only used in the sampling components as described in Section 4.5.\nThe purpose of constructing $G_u$ is to mine the target user's latent preference carved by the micro-videos, attributes, producers, and other users. As shown in Fig. 2, compared with a homogeneous graph, MHG reflects more social relations with a hierarchical graph structure. From Fig. 2(a), the importance of micro-videos $v_1$ and $v_2$ cannot be clearly distinguished since the nodes on the homogeneous graph does not consider the interactions of the other types of nodes. While, through our MHG in Fig. 2(b), it can be seen that the importance of micro-video $v_2$ is higher than that of $v_1$ because three paths directs $u_1$ to $v_2$. Therefore, compared with the existing graph models mentioned in related works, the MHGs of our MTHGNN can keep the original structural and modal information in the constructed graphs.\nGiven a target pair ($u, V_u$), $M_u$ interacted micro-videos are selected to construct the initial MHG $G_u$. By dividing the initial MHG $G_u$ into the latest and historical sessions, each session is extracted with m interacted micro-videos. Finally, $\\pi^u_m$ sessions are reconstructed, each of which can be regarded as a community that gathers users who have the same implicit tastes depicted by similar background music, tags, contents, or producers. To explore the high-order relationships among the users, the micro-videos, and the attributes, the number of layers is utilized to determine the size of the constructed MHG. The layer that the center node locates is defined as layer 0, and the other layers are numbered as $l \\in \\{1, 2, ..., h\\}$ based on the number of hops, h, from the center node. In the initial MHG $G_u$, the center node is the target user u; while in the component of Heterogeneous Graph Sessions, the center node can be the target u or any interacted micro-video v of u's sessions. As presented in Algorithm 1, for the target user u,"}, {"title": "4.3 Multi-aggregator", "content": "To extract the complex relationships and information from the interactions between the users and the micro-videos, a Relational Heterogeneous Message Passing (RHMP) aggregator and an Attention Heterogeneous Message Passing (AHMP) aggregator are developed to generate the user's preference embeddings and micro-video representations inspired by the work on multi-aggregator [4] and advanced aggregators [2, 12, 29]. With our constructed MHG as the input, and the outputs of RHMP and AHMP are the embeddings of the target user and the interacted micro-videos.\nRHMP starts from the target user u or anyone of u's interacted micro-video v of MHG $g_{s_i}$, where $g_{s_i} \\in g$. To clearly show the connections between nodes of two adjacent layers, $N_{g_{s_i}}^{l}$ denotes the node set at layer l of subgraph $g_{s_i}$. While $q_{g_{s_i}}(n) \\subseteq N_{g_{s_i}}^{l+1}$ is the set of the one-hop neighbors of node n at layer l of $g_{s_i}$ with $n \\in N_{g_{s_i}}^{l-1}$. The center embedding of layer l is denoted as $x^{*,l}_{g_{s_i}} \\in R^{1xd}$, where * is either u representing the target user u or v representing u's interacted micro-video v. To update the center embedding of relational information of layer (l + 1), a two-step RHMP is applied:\n$x^{*,l+1}_{g_{s_i}} = x^{*,l}_{g_{s_i}} + \\sum_{n \\in N_{g_{s_i}}^l} \\sum_{j \\in q_{g_{s_i}}(n)} \\sum_{r \\in R} (x_jW^r)W_l$\n(1)\nwhere $W_l \\in R^{dxd}$ and $W^r_l \\in R^{d\\times d}$ are the transform matrices of learning parameters, $x_j$ represents the embedding of node j, $l \\in \\{1, 2, ..., h\\}$. The RHMP consists of two parts, including relational tracing and message passing mechanism. Firstly, in the relational tracing part, the relation of each node is traced by $xW^r_l$, where the information of each node is transformed into a relational space based on r. The users have multi-type interactions"}, {"title": "4.4 Session Attention", "content": "Micro-video recommendation is highly time-dependent. With the news happening in the society, the users may be interest in the most recent micro-videos corresponding to the user's preference. Notice that these $M_u$ interacted micro-videos divided into $\\pi_u$ sessions can reflect users' preference to a certain extent. In the session attention component, the non-local operation [30] is used to seek user's historical preference from the historical local sessions, which can be performed by Eq. (6) and Eq. (7).\n$z_u = \\sum_{s_i \\in S_Y} [a_{s_i} \\otimes (z_{g_{s_i}}W')]\\\\ a_{s_i} = \\frac{exp(z_{g_{s_i}}W')}{ \\sum_{s_i \\in S_Y} exp(z_{g_{s_i}}W') }$\n(6)\n$z_u = \\frac{ z_u \\cdot [\\zeta (\\frac{ z_{g_{s_i}} \\cdot (z_{g_{s_i}} \\cdot z_{g_{s_i}})^\\tau }{\\sum_{s_i \\in S_Y} z_{g_{s_i}} \\cdot (z_{g_{s_i}} \\cdot z_{g_{s_i}})^\\tau }) ] }{ \\sum_{s_i \\in S_Y} [ \\zeta (\\frac{ z_{g_{s_i}} \\cdot (z_{g_{s_i}} \\cdot z_{g_{s_i}})^\\tau }{\\sum_{s_i \\in S_Y} z_{g_{s_i}} \\cdot (z_{g_{s_i}} \\cdot z_{g_{s_i}})^\\tau }) ] }$$\n(7)\nwhere $\\zeta(\\cdot)$ denotes the transpose of the input, and $W' \\in R^{2d \\times 2d}$ is a learnable matrix. In the original design of non-local network [30], the similarity is calculated by $exp(\\cdot)$. Since we use Sigmoid(\u00b7) function in the optimization component of our MTHGNN mechanism, the combination of $exp(\\cdot)$ and Sigmoid(\u00b7) may cause the gradient disaster. Thus, in this paper, $exp(\\cdot)$ is replaced by $\\zeta(\\cdot)$ to avoid scaling the similarity. In the session attention component, m embeddings of the latest interacted micro-video are used to fuse the historical information of each session based on the similarities generated by $\\zeta(\\cdot)$. Hence, MTHGNN can recommend a latent micro-video only when it has a high similarity with the latest m micro-videos and also meets a user's historical preference. Finally, Session Attention component generates the set of embeddings $\\{z_u, z_u, z_u, ..., z_u^m\\}$ for Model Training component."}, {"title": "4.5 Sampling Strategy", "content": "The traditional graph-based micro-video recommendation [3, 32] generates micro-video embeddings for optimization or prediction via graph training, in which we have to retrain the model if there is one new-coming micro-video or unseen micro-video. Differently, we develop a graph-free method to generate micro-video embeddings for optimization and prediction, which can deal with unseen nodes and new-coming nodes. Our sampling strategy only considers the vectors of any sampled micro-video $v_{spl}$ and its neighbors; that is,\n$z_u = \\frac{1}{\\sum P_G(v_{spl},w) } \\sum_{i \\in Q_G(v_{spl},w)} x_i$\n(8)\nwhere $Q_G(v_{spl}, w)$ is the set of $v_{spl}$'s one-hop neighbors that are of the type w on the graph G, and $w \\in N_{type} = \\{User, Video, Producer, Tag, Audio, ...\\}$ represents the node type, and $x_i$ is the primitive embedding of node i.\nWhen processing $Q_G(v_{spl}, User)$, the vector of the target user should be removed because the recommendation system is not able to know whether there is an interaction between the target user and the sampled micro-videos in advance. Hence, the user set of neighbors of v is $Q_G(v_{spl, User}) \\setminus u$.\n$Z_{v_{spl}} = \\frac{1}{N_{type}} \\sum W,$\n(9)\nwhere $z_u z_{v_{spl}}$ is the final aggregated embedding of the current sampled micro-video for the target user u. The graph-free sampling strategy is utilized to aggregate the information from different kind of nodes, which helps the model learn the weights of relations and attention.\nOn the other hand, the graph-free sampling strategy provides strong adaptive capability for real-world scenarios. In real-world recommendation, generating embeddings via graphs and model"}, {"title": "4.6 Model Training & Prediction", "content": "In the model training and prediction component, we use Eq. (10) to compute the predicted score for each sampled micro-video and rank the top-K micro-videos for recommendation.\n$\\hat{o}_{uv} = z^u z_{v_{spl}} + \\sum Z^{U}_{DS^U} = z^u z_{v_{spl}}$\n(10)\nSpecifically, $\\hat{o}_{uv}$ indicates the similarity between the target user u and the users who like $v_{spl}$ as well as the similarity between $v_{spl}$ and u's latest historical interests. If the sampled micro-video satisfies the user's interests, the predicted score $\\hat{o}_{uv}$ should be high; otherwise, a low score is given.\nFurthermore, MTHGNN is optimized by making the gap of the scores between liked and disliked micro-video maximized. To this end, BPR loss function [24] is applied for personalized micro-video recommendation. The overall loss function includes BPR loss function, relation limitation, and parameter regularization, as shown in the following.\n$\\small{ loss = \\sum_{UEU} \\sum_{v\\in V_p} \\sum_{v' \\in V_n} -logSigmoid (\\hat{O}_{uv} - \\hat{O}_{uv'}) + \\beta \\sum_{l=0}^{h-1} \\sum_{r\\in R} |W_l^r||^2_2 + \\eta \\theta^2}$ \n(11)\nin which $V_p$ is the set of interacted micro-videos, $V_n$ is the set of non-interacted Micro-videos, \u03b2 and \u03b7 are the regularization weights, Sigmoid() is the Sigmoid function, $\\theta$ contains all the learnable parameters of the model including the parameters in FFN, $W_l, W_l^r, Q,$ and W', and $||\\cdot||^2_2$ represents the Frobenius norm. The relation limitation part of the loss function limits the same relation to be similar. If there is a large gap between the transform matrices $W_l^{l+1}$ and $W_l^r$, the transformed node embeddings of different relations at the same layer might be similar, which causes the graph learning to be over-smooth, so the second term is considered in the loss function."}, {"title": "5 PERFORMANCE EVALUATION", "content": "In this section, a series of experiments are conducted to evaluate the performance of our proposed MTHGNN mechanism."}, {"title": "5.1 Datasets", "content": "We conduct experiments on two real-world datasets, including MovieLen dataset and TikTok dataset, which are described below with the statistics summarized in Table 1.\n(i) TikTok [6]: TikTok dataset is collected from real-world anonymized users and contains the interactions of \"like\", \"finish\", and \"Non-interacted\" between users and micro-videos. In our experiments, the interactions of \"like\" and \"finish\" are marked as interacted, while the interactions of \"non-interaction\" is marked as non-interacted. To exam the performance of recommendation"}, {"title": "5.3 Experiment Settings", "content": "The performance of (micro-)video recommendation is measured by the average scores of Precision@K [9] that demonstrates recommendation accuracy, Normalized Discounted Cumulative Gain (NDCG@K) [31] that describes the ranking ability, and timeliness of correctly recommended micro-videos (C-Timeliness@K) [34] that measures the freshness of the recommended micro-videos, for all the users in the testing datasets.\nA higher value of timeliness means that this micro-video is interacted by most of the recently viewed users. Hence, this micro-video is hot and latest. We only count the timeliness of correctly recommended micro-videos because people do not care the timeliness of the micro-videos they are not interested in. C-Timeliness@K is expressed by Eq. (12) and Eq. (13):\n$T = \\frac{1}{\\sum_{u \\in \\phi_G(v, User)} (t_{uv}-t^o)}$\n(12)"}, {"title": "5.4 Comparison between MTHGNN and Baselines", "content": "The comparison results are summarized in Table 3, Table 4, and Table 5, where the performance improvement is the ratio of performance difference between MTHGNN and a baseline to the baseline performance.\nIn Tables 3, 4, and 5, MTHGNN outperforms all the baselines in terms of all metrics on TikTok(1/50) and TikTok(1/5). For MovieLen, MTHGNN shows nearly the state-of-the-art performance on the scores of Precision@10 and NDCG@10 in Table 3 and Table 4, but its C-Timeliness scores are a little bit lower than those of R-GCN in Table 3 and HERec in Table 4. This is because MTHGNN tries to capture the micro-videos that the users may like in the future by considering both timeliness factor and user interest. However, for movie recommendation in MovieLen, the users may like classic"}, {"title": "5.5 Ablation Study", "content": "In the ablation study, the variants of MTHGNN are compared to understand the contributions of each component developed in MTHGNN, and the results of Precision@10, NDCG@10, and C-Timeliness@10 are presented in Table 6. These variants include: (a) Historical, where all the historical sessions are removed, and only the latest session is kept; (b) \u00acRelation, where the RHMP aggregator is removed; (c) All attention, where the AHMP aggregator is removed; (d) Single Attention, where Q at each layer is removed, and a global Q\u02b9 is used instead; (e) LSTM\u2192Mean, where the LSTM aggregator is replaced by a mean aggregator [11]; and (f) MTHGNN. The ablation study is conducted on TikTok(1/50) and MovieLen with the training rate at 80%. The results of Table 6 are analyzed in the following.\nFirstly, all of the studied components have significant contributions to the recommendation performance of our MTHGNN with different importance, which provides the flexibility to properly tailor the components of MTHGNN according to the characteristics of datasets.\nSecondly, Historical sessions are more important for micro-video recommendation than for long-movie recommendation. Usually, a user's interest in micro-videos may be influenced by currently hot news/events and thus change frequently, while such an interest"}, {"title": "5.6 Top-K Recommendation", "content": "Considering different recommendation requirements in real applications, the performance of top-K recommendation is carefully investigated by changing K from 1 to 10, from which our critical findings are described below.\n(i) The Precision@K scores on TikTok(1/50) are shown in Fig. 3(a) and Fig. 3(b), where our MTHGNN outperforms all the baselines with K increasing from 1 to 100. Such a performance comes from the novel development of our MTHGNN: (i) MHG is constructed to fully represent user information by using the information of nodes, relations between nodes, and heterogeneous structures; (ii) multiple aggregators are deployed to learn user preference through the relations and attentions; and (iii) the session attention is constructed to consider the user's latest and historical interest, where $\\pi^u_m$ sessions are used to improve the accuracy of predicting user interest. For top-K micro-video recommendation, in our MTHGNN mechanism, the micro-videos with higher prediction scores usually have higher probabilities of being the correct micro-videos and thus obtain higher rankings. As a result, when K grows up, more and more micro-videos that have lower probabilities of being the correct micro-videos are recommended, leading a decrease in the Precision@K score of MTHGNN. Especially, in Fig. 3(b), the Precision@K scores of all the compared models converge to 0.48 when K is reaching to 100 that is the maximum length of a user's testing micro-video sequence, because in TikTok(1/50), the total number of correct micro-videos is limited and may be far smaller than 100.\n(ii) In Fig. 3(c), the NDCG@K scores of MTHGNN are higher than those of the baseline models. When K is increased from 1 to 10, there is an increase in the NDCG@K scores for all the models as NDCG@K is the cumulative gain of non-negative scores of these K recommended videos. Moreover, the increase of the NDCG@K"}, {"title": "6 CONCLUSION", "content": "Micro-vides own the characteristics of social relations, multi-type interactions, multi-modals, temporal factors, and timeliness. This paper proposes a novel Multi-aggregator Time-warping Heterogeneous Graph Neural Network (MTHGNN) to address these characteristics by designing tightly coupled components, including multi-modal heterogeneous graph to simulate social relations and multi-type interactions, multi-aggregator to mine graph information from relation and attention aspects, session attention to track user interests. In this way, our MTHGNN can generate high-quality user and micro-video embeddings for accurate recommendation. The experiments can confirm the advantages of our MTHGNN compared with the state-of-the-arts on real datasets."}]}