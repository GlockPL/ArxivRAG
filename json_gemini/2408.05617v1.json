{"title": "Residual-INR: Communication Efficient On-Device Learning Using Implicit Neural Representation", "authors": ["Hanqiu Chen", "Xuebin Yao", "Pradeep Subedi", "Cong Hao"], "abstract": "Edge computing is a distributed computing paradigm that collects and processes data at or near the source of data generation. The on-device learning at edge relies on device-to-device wireless communication to facilitate real-time data sharing and collaborative decision-making among multiple devices. This significantly improves the adaptability of the edge computing system to the changing environments. However, as the scale of the edge computing system is getting larger, communication among devices is becoming the bottleneck because of the limited bandwidth of wireless communication leads to large data transfer latency. To reduce the amount of device-to-device data transmission and accelerate on-device learning, in this paper, we propose Residual-INR, a fog computing-based communication-efficient on-device learning framework by utilizing implicit neural representation (INR) to compress images/videos into neural network weights. Residual-INR enhances data transfer efficiency by collecting JPEG images from edge devices, compressing them into INR format at the fog node, and redistributing them for on-device learning. By using a smaller INR for full image encoding and a separate object INR for high-quality object region reconstruction through residual encoding, our technique can reduce the encoding redundancy while maintaining the object quality. Residual-INR is a promising solution for edge on-device learning because it reduces data transmission by up to 5.16 \u00d7 across a network of 10 edge devices. It also facilitates CPU-free accelerated on-device learning, achieving up to 2.9 \u00d7 speedup without sacrificing accuracy. Our code is available at: https://github.com/sharc-lab/Residual-INR.", "sections": [{"title": "Introduction", "content": "Al workloads are increasingly shifting from centralized cloud architectures to distributed edge systems to process data closer to where it is generated [1-5]. On-device learning, by leveraging these edge systems, offers enhanced real-time processing capabilities with adaptation to the changing environments [6, 7]. Severless edge computing, as shown in Fig. 1, is one of the most commonly used computing paradigm. As edge devices continually collect new data, AI workloads on these devices need to be updated to adapt to emerging new tasks. However, this approach necessitates data sharing and synchronization across devices to ensure that all edge devices have access to the most up-to-date data for local computation. Nonetheless, large-scale serverless edge computing can result in substantial device-to-device communication burdens. As shown in Fig. 1, for edge devices that are deployed in the wild, those device-to-device communication relies on wireless communication, which has a very limited bandwidth. For example, the bandwidth provided by 4G LTE [8] is only about 5-12 Mbps, causing a large latency with heavy communication.\nTo optimize data management and communication among edge devices, fog computing has been proposed [9, 10]. This technique integrates a fog node with higher computational and storage capacities than edge devices into the network, allowing for the offloading of intensive computation tasks and data compression [11-13]. However, the substantial"}, {"title": null, "content": "communication traffic between the fog node and edge devices remains a critical concern, especially for data-intensive computer vision tasks. Image compression offers a viable solution to reduce heavy communication loads. However, recent classical or neural image compression algorithms are computation-intensive [14-17], or optimized for perceptual quality [18, 19], making them unsuitable for resource-constrained edge devices and causing redundant compression for machine learning training.\nRecently, implicit neural representation (INR) [20-24] is emerging as a novel image compression technique by training a neural network to effectively encoding the entire image as a compact set of network parameters that can be easily stored and reconstructed. To use INR compressed images for downstream machine learning tasks, Rapid-INR [23] demonstrates its success on image classification with higher compression rate than JPEG. However, whether INR compression can be extended for communication-efficient edge on-device computer vision tasks has not been explored yet. As shown in Fig. 1, since INR compressed images can be much smaller than JPEG, compressing images into INR format at the fog node for data transmission among devices can save a large amount of data transmission.\nMotivated by the need for reducing communication among edge devices and the unexplored potential of INR in communication efficient edge computing, we propose Residual-INR, a fog computing-based communication-efficient on-device learning framework by utilizing INR to compress images/videos. Utilizing the fog node for encoding background and object to INR separately in different quality, Residual-INR remarkably reduces data transmission among edge devices while maintaining object encoding quality, thereby accelerating on-device training without large accuracy loss. Our contributions can be summarized as follows:"}, {"title": null, "content": "separate object INR enhances the encoding quality of objects through residual encoding. This approach not only reduces the combined size of the background INR and object INR compared to a single INR but also preserves object detection training accuracy. Additionally, our technique is versatile and can be integrated seamlessly with existing INR compression networks."}, {"title": "Hardware - CPU-free INR decoding with workload balancing", "content": "To address workload imbalances from varying decoding latencies due to different INR sizes, we group images with the same sized INR together for parallel decoding during training on edge device. Additionally, the compact size of INR weights allows them to be stored within device memory, enabling CPU-free training without frequent external storage access and eliminating the need for a complex software stack."}, {"title": "Mathematical modeling - An analytical math model for optimal communication strategy", "content": "We develop a mathematical model to model the data communication in the whole system. We identify the optimal compression and communication strategy-whether to send JPEG images to the fog node for INR compression or directly share JPEG images with other devices. Additionally, we determine the most communication efficient locations for training-whether at the fog node or the edge."}, {"title": "Evaluation - Thorough experiment analysis", "content": "We conduct a thorough experiment to demonstrate the advantages of Residual-INR. Compared with JPEG compression, Residual-INR reduces the average image size by up to 12.1 \u00d7 with similar object encoding quality. In an edge computing network with 10 devices, Residual-INR reduces data transmission amount by up to 5.16 \u00d7 and accelerates end-to-end training time by up to 2.9 \u00d7, without sacrificing accuracy."}, {"title": "Preliminary and Motivations", "content": "2.1 Implicit neural representation for image and video compression\nINR uses neural networks to model complex hidden features, presenting a novel method for parameterizing various data types [20-24]. The application of INR in data compression involves training a neural network to converge and then compressing the weights to reduce its size. This technique has gained increased attention in computer vision for compressing images and videos. For instance, COIN [21], COIN++ [22] and Rapid-INR [23] employ a multilayer perceptron (MLP) to compress images, encoding the relationship between pixel locations (x, y) and their RGB values, with each image having a dedicated MLP. For video compression, by utilizing similarities between adjacent video frames for a higher compression rate, NeRV [24] utilizes a single network combining MLPs and CNNs to encode the entire video sequence, taking frame indices as inputs and outputting corresponding RGB"}, {"title": "Low object reconstruction quality", "content": "Existing INR methods [21-24] usually encode one image using a single INR; however, for images with less important background and more important objects, we observe that important regions usually suffer from quality degradation. Larger INRs can improve image quality, like demonstrated in Rapid-INR; however larger INRs consume larger memory and sometimes is not better than JPEG.\nFig. 2 shows that compressing an entire image using a single INR causes object colors to blend with the background, resulting in blurred objects that are difficult to detect. Moreover, in certain object detection tasks, objects often occupy a very small portion of the image, as presented in Fig. 3 (a). Using a single INR to encode the entire image assigns equal importance to all pixels, resulting in reduced attention to objects during encoding and lower object reconstruction quality. We evaluate reconstruction quality using the Peak Signal-to-Noise Ratio (PSNR), where higher PSNR values indicate better quality. As a case study, Fig. 3 (b) illustrates the averaged PSNR for background and object regions across the DAC-SDC [25], UAV123 [26], and OTB100 [27] datasets using NeRV and Rapid-INR for encoding. Notably, the PSNR for objects is significantly lower than that for backgrounds.\nMotivated by the lower reconstruction quality of objects, which significantly affects the accuracy of detection backbone training, we propose an additional tiny INR dedicated solely to enhancing object encoding quality."}, {"title": "Residual-INR Encoding and Decoding", "content": "Our proposed Residual-INR, similar to typical INRs, has two stages for compression: encoding an image/video into its INR format, and decoding the INR back to its original format. This two-stage approach is particularly suitable for fog computing, where encoding occurs at fog nodes while decoding takes place at edge devices. This is because the INR encoding process is computationally intensive due to the need for training a neural network to converge. INR decoding is a fast and lightweight process, which even can be effectively handled by the resource-limited edge devices. As a result,"}, {"title": "Region importance aware encoding", "content": "Considering the fact that the background is less critical than the object in object detection training, encoding the background at a lower quality minimally impacts training accuracy while reduces encoding redundancy. Residual-INR optimizes encoding efficiency for smaller datasets size by differentiating between background and object encoding. As shown in Fig. 4, it refines existing INR frameworks by utilizing a smaller INR (background INR) for the entire image and adding an additional tiny INR (object INR) specifically to enhance object region encoding quality. Background INR and object INR work together during INR decoding for image reconstruction. Background INR first decodes the entire image, followed by object INR which specifically decodes and overlays the object onto the image as a patch. The goal is to make the size of background INR and object INR together smaller than the size of a single INR without sacrificing object reconstruction quality."}, {"title": "Background INR", "content": "Our background INR, developed upon Rapid-INR for images and NeRV for videos, uses a reduced size network to encode the entire image/video frame at a relatively lower quality that will not affect the object detection training accuracy. As a result, the smaller size background INR effectively minimizes redundancy in background encoding. Besides the network structure, all other configurations remain unchanged. Given the uniformity of image sizes within a dataset, the same sized Rapid-INR is used as background INR encoding. However, video sequences often vary in length in the dataset. To balance the compression rate and encoding quality, we employ differently sized NeRV as encoders according to the length of each video sequence. Although objects are decoded in low quality by background INR, the object features learned by backround INR will be utilized by obejct INR."}, {"title": "Object INR", "content": "The object INR is used to enhance the encoding quality of the object region in the format of MLPs. The object region is identified by the bounding box boundaries. Our preliminary analysis shows that the object size is typically much smaller than the overall image size (Sec. 2.2), allowing us to use a tiny object INR for high-quality, storage-efficient encoding. Objects usually vary in size in different images. To ensure each object is encoded optimally, we use"}, {"title": null, "content": "various sizes of object INRs matched to the size of each object.\nThere are two ways of encoding the objects: direct encoding using raw RGB and residual encoding using residual RGB values. Direct encoding is to simply take the object pixel coordinates as inputs and outputs the RGB values of object pixels. The output directly replaces the low-quality object region in the background INR reconstructed image. However, this method cannot fully utilize the information that the background INR has already learned, also causing some encoding redundancy. To better leverage the already learned information by background INR, we use residual encoding. As shown in Fig. 4, residual encoding starts by cropping the object region RGB values decoded by background INR and its pixel coordinates from the full image. Next, we calculate the residual RGB values by comparing the reconstructed object from the background INR to the object in the raw image. The INR learning objective then shifts from matching the raw RGB values to fitting these residual values.\nCompared to direct encoding of raw RGB values, encoding residuals using the same size INR results in better object reconstruction quality, as shown in Fig. 5. This improvement is attributable to differences in information entropy. The entropy H of a set of random variables \\(X : \\{X_1, X_2, ..., X_n\\}\\) encoded by a neural network is defined as: \\(H(X) = \u2212 \\sum_{i=1}^{n} P(x_i) \\cdot\\)"}, {"title": "Parallelized and balanced decoding", "content": "3.2.1 CPU-free INR decoding on device. Images compressed to INR format are decoded on edge devices for on-device learning. INR decoding involves neural network inference where Rapid-INR accepts image pixel coordinates and NeRV utilizes video frame temporal indices as inputs. Both of them output image RGB values. Before training starts, all INR weights are transferred once from device storage to device memory in tensor format. This minimizes frequent data exchanges between the device storage and memory during detection backbone training, enabling CPU-free training"}, {"title": "INR grouping", "content": "As shown in Fig. 7, object detection training process involves randomly sampling images from the dataset to form a batch, which helps improve convergence. To facilitate faster decoding, images in INR format within a batch should be decoded in parallel on the device. However, each image is encoded with object INRs of varying sizes, and the background INRs developed upon NeRV also differ in size. These varying sizes result in different decoding latencies. Fig. 7 demonstrates that when decoding a batch of images in parallel, the latency required depends on the image with the largest INR, leading to an unbalanced workload on device. To enhance INR decoding speed and thus accelerate on-device training, we propose grouping images with the same-sized INRs together. INR grouping ensures uniform decoding speeds within a batch, balancing the workload and improving the overall training speed."}, {"title": "Multi-Device Communication Modeling", "content": "We develop a mathematical model to explore the optimal data communication and compression strategies across multiple devices for fog computing. We aim to minimize communication in the system, i.e., transmitting JPEG images to fog nodes for INR compression or direct image transmission"}, {"title": "Communication modeling", "content": "Our serverless edge computing model is used for data transmission occurring solely among edge devices. Assuming a system comprises k edge devices, with each device transmitting the amount of data \\(m_i\\) to \\(n_i\\) receivers. The total data transmitted within the serverless edge computing system, denoted as \\(D_s\\), is given by: \\(D_s = \\sum_{i=1}^{k} n_i m_i\\)\nUnlike serverless edge computing, fog computing networks also account for data communication between the fog node and edge devices, in addition to interactions among the edge devices themselves. In fog computing, edge devices upload images in JPEG format to the fog node for INR compression. We define the INR compression rate, \u03b1, as the ratio of the compressed size to the original JPEG size: \\(\\alpha = \\frac{INR\\ Size}{JPEG\\ Size}\\). Assume \\(k_1\\) edge devices choose to upload their images for INR compression and subsequent broadcasting by the fog node, while the remaining devices transmit their images directly in JPEG format to their respective receivers. The total data transmission in this fog computing network, \\(D_f\\), is then calculated as: \\(D_f = M_1 + M_2 + M_3 = \\sum_{i=1}^{k_1} n_i (\\alpha m_i) + \\sum_{i=1}^{k_1} m_i + \\sum_{i=k_1+1}^{k} n_i m_i\\), where \\(M_1\\) represents the data broadcast by the fog node after INR compression, \\(M_2\\) is the total amount of data uploaded from edge devices to the fog node, and \\(M_3\\) accounts for the data directly exchanged among edge devices."}, {"title": "Optimal communication strategy exploration", "content": "INR compression or JPEG? Our objective is to minimize the total data transmitted for on-device learning at the edge by leveraging INR compression in fog computing. We aim for \\(D_f < D_s\\) to reduce communication costs. The difference between \\(D_s\\) and \\(D_f\\) is given by: \\(D_s - D_f = \\sum_{i=1}^{k_1} m_i \\cdot [(1 - \\alpha) \\cdot n_i - 1]\\). For \\(D_f\\) to be minimal, each term in the summation \\((1 - \\alpha) \\cdot n_i - 1\\) must be positive. From our mathematical analysis, transferring image data to the fog node for INR compression proves more communication-efficient than directly sending JPEG images to receivers, provided the number of receiving devices \\(n_i\\) for each edge device satisfies: \\(n_i > \\frac{1}{1-\\alpha}\\). This condition ensures that the benefits of INR compression outweigh the extra costs of uploading JPEG images to the fog node. Fig. 8 illustrates the improved communication efficiency achieved by using fog computing with INR compression, in comparison to serverless edge computing.\nTraining at fog node or at edge? The enhanced computational capabilities of the fog node allow for the possibility of transferring model weights to the fog node for training and subsequently transferring the trained weights back to"}, {"title": null, "content": "the edge devices. The decision between transferring model weights or images depends on which is larger: the amount of data required for on-device learning or the twice of model size. Typically, in on-device learning scenarios, the amount of new data used for fine-tuning is smaller than twice of the model size, leading to transferring INR-formatted images to the edge for training is more communication beneficial. However, in cases where the new task significantly deviates from the original task used for model training, it is more communication efficient to transfer the model weights back to the fog node for retraining."}, {"title": "Experiment Results", "content": "5.1 Experiment settings\n5.1.1 Datasets and platforms for evaluation. To demonstrate the efficiency of Residual-INR in fog computing for on-device learning, we focus on single object detection, employing YOLOv8 [31] middle size (98.8 MB) as the detection backbone. We evaluate Residual-INR using three datasets: DAC-SDC [25], UAV123 [26], and OTB100 [27]. These three datasets consist of multiple video sequences, each representing a specific object category and consisting of continuous video frames stored in JPEG format. This setup allows for two INR compression options: treating video frames as independent images using Rapid-INR, or encoding them as continuous video sequences with NeRV. The image decoding and training latency measurement are conducted on real hardware systems, using Intel 6226R CPU and NVIDIA A6000 GPU to simulate the edge computing device. To demonstrate the training speedup offered by Residual-INR, we compare our INR training pipeline with two prevalent training frameworks: PyTorch [32], which utilizes CPU for data loading and JPEG decoding, and DALI [33], which employs a mixed CPU and GPU setup for accelerated JPEG decoding. To show the system-level benefits of Residual-INR in fog computing for reduced communication, our analysis relies on simulation results derived from our mathematical model. We set the wireless communication bandwidth as 2MB/s in our experiments."}, {"title": "Detection backbone training and INR encoding", "content": "To simulate on-device learning, we initially randomly selected half of the video sequences from each dataset to train YOLOv8 and develop a pretrained model. Subsequently, we select new video sequences from the remaining half to fine-tune this pretrained model, evaluating detection accuracy on those new videos. The fine-tuning takes 10 epochs, which is sufficient for the detection backbone to converge with the new data. We adhere to the default settings of YOLOv8 for other training hyper-parameters. Notably, INR grouping is employed when training with images decoded by Residual-INR, but not with images decoded by Rapid-INR or the NeRV"}, {"title": "Object reconstruction quality", "content": "We evaluate object reconstruction quality across various encoding methods, including different JPEG qualities and INR configurations, using PSNR as the metric for object region quality. Additionally, we analyze the average image sizes produced by these methods. Fig. 9 indicates that after quantizing the background INR to 8 bits and the object INR to 16 bits,"}, {"title": "Detection backbone training accuracy with amount of data transmission", "content": "We fine-tune the YOLOv8 model using varying numbers of images sampled from new selected video sequences. As shown in Fig. 10, both the training accuracy (mAP50-95) and the data volume transferred from the fog node to a single edge device increase with the number of images used for training. Res-Rapid-INR and Res-NeRV significantly reduce the amount of data transferred compared to JPEG, Rapid-INR,"}, {"title": "Training speedup and detailed breakdown", "content": "We conduct an ablation study to show the power of Residual-INR in reducing wireless data transmission time and the advantages of INR grouping in minimizing INR decoding time. The detailed breakdown of training time, including detection backbone training, image decoding, and transmission time, is depicted in Fig. 11. Because of reduced data transmission and accelerated decoding via INR grouping, the end-to-end training time for Res-Rapid-INR and Res-NeRV showed a speedup of up to 2.9 \u00d7 and 2.25 \u00d7, respectively, compared to a PyTorch training pipeline with JPEG images decoded on a single-thread CPU. This speedup reaches 1.77 \u00d7 and 1.38 \u00d7, respectively, compared to a DALI training pipeline with GPU-accelerated JPEG decoding. INR grouping yields an average speedup of 1.40 \u00d7 for Res-Rapid-INR and 1.25 \u00d7 for Res-NeRV across three datasets."}, {"title": "Summary of different compression techniques", "content": "To do a comprehensive evaluation on various compression techniques, we compare JPEG, Rapid-INR, NeRV, Res-Rapid-INR, and Res-NeRV across multiple metrics, as illustrated in a radar graph (Fig. 12). While JPEG offers the highest object quality and detection accuracy, it incurs significant storage and communication costs. Additionally, JPEG decoding on CPUs is slow, and GPU-accelerated decoding requires a complex software stack. In contrast, Residual-INR significantly enhances storage and communication efficiency with minimal influence on object quality and detection training accuracy compared to JPEG. Additionally, it provides faster decoding speeds and higher detection accuracy than the Rapid-INR and NeRV baselines."}, {"title": "Conclusion", "content": "In this paper, we propose Residual-INR, a communication efficient fog on-device learning framework that utilizes region importance aware INRs for image and video compression. By separately encoding the object and background of an image or video frame with a smaller INR for low-quality background and a tiny INR for high-quality object encoding, Residual-INR compresses images to sizes 5.4 to 12.1 \u00d7 smaller than JPEG. Moreover, Residual-INR reduces data transmission volumes by 3.43 to 5.16 \u00d7 across a fog computing network of 10 edge devices compared to serverless edge computing. Furthermore, Residual-INR enables CPU-free on device training without the need for a complex software stack. It can achieve up to a 2.9 \u00d7 speedup compared with a PyTorch training pipeline using JPEG and up to 1.77 \u00d7 faster than accelerated training pipeline with JPEG using DALI."}]}