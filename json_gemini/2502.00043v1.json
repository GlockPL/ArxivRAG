{"title": "A scalable adaptive deep Koopman predictive controller for real-time optimization of mixed traffic flow", "authors": ["Hao Lyu", "Yanyong Guo", "Pan Liu", "Nan Zheng", "Ting Wang"], "abstract": "The use of connected automated vehicle (CAV) is advocated to mitigate traffic oscillations in mixed traffic flow consisting of CAVs and human driven vehicles (HDVs). This study proposes an adaptive deep Koopman predictive control framework (AdapKoopPC) for regulating mixed traffic flow. Firstly, a Koopman theory-based adaptive trajectory prediction deep network (AdapKoopnet) is designed for modeling HDVs car-following behavior. AdapKoopnet enables the representation of HDVs behavior by a linear model in a high-dimensional space. Secondly, the model predictive control is employed to smooth the mixed traffic flow, where the combination of the linear dynamic model of CAVs and linear prediction blocks from AdapKoopnet is embedded as the predictive model into the AdapKoopPC. Finally, the predictive performance of the prosed AdapKoopnet is verified using the HighD naturalistic driving dataset. Furthermore, the control performance of AdapKoopPC is validated by the numerical simulations. Results demonstrate that the AdapKoopnet provides more accuracy HDVs predicted trajectories than the baseline nonlinear models. Moreover, the proposed AdapKoopPC exhibits more effective control performance with less computation cost compared with baselines in mitigating traffic oscillations, especially at the low CAVs penetration rates. The code of proposed AdapKoopPC is open source\u00b9.", "sections": [{"title": "I. INTRODUCTION", "content": "WITH the acceleration of urbanization and the increase in the number of motor vehicles, traffic congestion and traffic accidents have become increasingly prominent [1]. Against this background, autonomous driving technology has emerged and is expected to become an innovative solution to alleviate traffic congestion [2], [3]. The most common application is Cooperative Adaptive Cruise Control (CACC), which relies on V2V state sharing to enable vehicles within a vehicle platoon to run at coordinated speeds to maintain a small headway [4]. This technique can enhance traffic capacity and improve safety between vehicles, which has attracted a lot of interest from academia and industry. The excellent performance of connected automated vehicles (CAVs) in a purely intelligent network environment has been widely recognized [5]. In essence, CAV is a mobile scanner that provides historical and real-time trajectory data of individual vehicles [6]. As well, it is also a dynamic actuator for adaptive control [7]. In this intelligent network ideal scenario, vehicles communicate seamlessly and autonomous driving systems operate together accurately and efficiently, thus building a highly intelligent transportation ecosystem [8]. However, the industrialization of autonomous driving technology is a complex process, and the realization of large-scale application of mobile internet and autonomous driving technology is a long process. A more realistic traffic environment is that CAVs and human-driven vehicles (HDVs) share the road. This mixed traffic flow prompts scholars to think deeply and study the performance of CAVs in complex traffic environments [9].Considering the research topics of this paper, we mainly focus on the following two key points, including the modeling of HDVs behavior and the controlling of CAVs.\nHow to model the HDVs driving behavior in dynamic traffic flow, and to predict the HDVs trajectory with high accuracy? A key goal is to simulate the dynamic driving behaviors of HDVs in mixed traffic flow. These behaviors will be essentially different due to differences in driving environments, drivers, etc. HDV adjusts its own acceleration based on the headway to the leader vehicle, velocity difference, and among others. In term of the physics-driven methods, well-known car-following models were widely employed, such as optimal velocity model [10], full velocity difference model [11], intelligent driver model [12], to describe and model the HDVs behaviors. However, it is known that these time-invariant car-following models always archives high-biased results with large error. With the rapid development of artificial intelligence, big data and computing power, the deep learning methods, including recurrent neural networks (RNN), long short-term memory model (LSTM), deep deterministic policy gradient (DDPG), etc., are being gained more and more interests in modeling the driving behaviors of HDVs. Although deep learning is superior in capturing and modeling driving behavior in complex traffic environments, due to the characteristic of nonlinearity, its shortcomings of slow solution speed and inability to meet real-time optimization control are self-evident.\nHow to control CAVs more effectively in mixed traffic"}, {"title": "flows for mitigating traffic oscillations?", "content": "As well known, the jam-absorption driving strategy in the Newell's car-following theory framework was proposed to mitigate the propagation of upstream disturbances, and the corresponding vehicles need to be selected based on the expected absorption speed and real-time traffic conditions to implement the strategy [13]. As mentioned before, CAV is a dynamic executor, and its role is no longer limited to\u201cfollower\u201d, but has been further expanded to\"leader\", which is the basic idea and connotation of the Leading Cruise Control (LCC) framework [14]. In addition, the controllability, observability and head-to-tail stability of the LCC framework were also analyzed and verified, confirming its positive role in improving traffic performance [15], [16]. Along this direction, the Data-Enabled Predictive Leading Cruise Control (Deep-LCC) was proposed [17], [18], as an alternative to parametric car-following model, to achieve safe and optimal control of CAVs in mixed platoons. The Deep-LCC has inspired this paper, however, it still exhibits certain limitations. To be specific, in order to use CAVs to positively guide HDVs, it is necessary to first understand the driving behavior changes of HDV after being affected by CAVs. In Deep-LCC, all HDVs follow a rule-based car-following model and add random high-frequency noise to construct the trajectory database. It is obviously unrealistic and limited to combine these trajectories to match the corresponding HDV expected driving trajectories for different scenarios. this is obviously not realistic and has limitations.\nOverall, the dilemmas faced by CAV control for traffic optimization in mixed traffic flow lies in accurately modeling and predicting the driving behavior of HDVs in complex scenarios, as well as meeting the requirements of effective and feasible real-time solution and optimization control in reality. Motivated by the above two requirements, the Koopman operator offers a new solution for identifying and analyzing nonlinear systems. The Koopman operator emerges as a highly suitable approach, which facilitates the handling of intricate nonlinear dynamics through linear transformations. This method allows for an efficient modeling of the HDVs behavior without introducing excessive complexity, and its linear properties are well suited for subsequent real-time optimization of mixed traffic flow. Therefore, this paper develops a multi-scenario adaptive deep Koopman predictive control framework for mixed traffic flow. The main contributions of this paper are as follows:\n\u2022 An adaptive deep Koopman network (AdapKoopnet) is proposed for modeling HDVs car-following behavior with the high-dimensional linear model;\n\u2022 A scalable state prediction model of mixed traffic flow is developed by integrating linear dynamic model of CAVs and linear prediction blocks from AdapKoopnet;\n\u2022 An adaptive deep Koopman predictive control framework (AdapKoopPC) based on the state prediction model is proposed for mitigating traffic oscillations in mixed traffic flow.\n\nThe framework of this paper is as follows. Section II mainly reviews the relevant literatures and summarizes the research gap. Section III states the AdapKoopnet. Section IV proposes the AdapKoopPC framework. Section V and Section"}, {"title": "VI conducts the experiments for HDVs longitudinal trajectory prediction and mixed traffic flow optimization control. At last, the conclusion and prospects are given in Section VII .", "content": "II. RELATED WORK\nA. Driving scenario and characteristics recognition\nRecognizing and extracting potential driving scenarios is beneficial for achieving vehicle trajectory prediction with strong generalization ability and accuracy. [19] extracted driving scenarios directly from real driving data and clustered repeated patterns into potential scenario groups without any pre-definition or rules. [20] developed a general active learning framework to annotate driving trajectory time series data and explore unknown driving scenario trajectories. Beyond scenario recognition, more research focuses on capturing driving characteristics. [21] utilized unsupervised algorithms to automatically extract descriptive driving patterns, and the clustered patterns promote a comprehensive understanding of driver behavior characteristics. In addition, identifying the driving style is also a work with practical value. For example, based on the multi-dimensional characteristics, three different driving styles are identified using an unsupervised clustering algorithm [22]. [23] employed a set of experiments to collect driving data among different drivers, and a supervised machine learning-based driving style classifier was designed to recognize the driving style. [24] defined the intermediate variable of neural process as the driving style vector and linked to an interpretable and continuous aggressiveness index. However, identifying and clustering scenarios from natural driving datasets using neural networks without relying on pre-definition or pre-labeling remains to be solved. Secondly, further extracting personalized driving features based on recognized scenarios and using them for driving behavior prediction is also worth exploring.\nB. Car following behavior modeling and trajectory prediction\nThe trajectory prediction methods of car-following behavior are mainly divided into physics-based methods, data-driven methods, and hybrid-driven methods. The physics-based method uses microscopic traffic flow models for trajectory prediction. For example, [25] explicitly considered the interactions between vehicles and proposed a dynamic Bayesian networks-based filter to estimate the behavior of traffic participants and predict their future trajectories. [26] developed a cooperative intelligent driver model that dynamically determines its acceleration based on parameters such as velocity difference and headway. With the advancement of big data and deep learning technology, data-driven methods for trajectories prediction have been emerging. [27] built spatiotemporal attention long short-term memory (STA-LSTM) for vehicle trajectory prediction, ensuring accuracy while improving interpretability. Pioneeringly, [28] first proposed a physics informed deep learning framework for car-following modeling, taking full advantage of data-driven and physics-based models to surpass existing models. Further, relying on the self-attention mechanism to achieve deeper mining of trajectory features, [29] proposed a Physics-Informed Transformer-Intelligent Driver"}, {"title": "Model to predict longitudinal vehicle trajectories.", "content": "However, there is still a contradiction between the complex deep learning model that describes the nonlinear state evolution of vehicle driving behavior and the requirement that CAV control relies on real-time solutions.\nC. CAV control for optimized mixed traffic flow\nVarious control approaches have been explored to optimize mixed traffic flow performance such as safety, efficiency and energy consumption. [30] presented a highly efficient platoons control framework based on tube MPC to address heavy computational and communication burden, which mitigates prediction uncertainty through feedback control. [31] implemented a cooperative control strategy for CAVs under the assumption of completely random disturbances triggered by HDVs. Recently, a control strategy called \u201cThe Follower Stopper controller\" was proposed, and real vehicle experiments demonstrated its ability to improve traffic flow stability [32]. To address the limitation of executing FS policies individually for all CAVs, [33] established a cellular automaton model of mixed traffic flow based on the FS strategy for CAV control, which positively affected the efficiency, oscillation, and fuel consumption of mixed traffic flow. From the perspective of collective function optimization, [34] studied the impact of different formations of CAVs on traffic performance, focusing on the formation of cooperation between CAVs using centralized optimal controllers. Besides, a traffic-smoothing controller was directly learned from trajectories based on a reinforcement learning policy gradient algorithm [35]. [36] integrated an advanced linear controller and a DPPO-based DRL controller to construct a hybrid controller, achieving stable and efficient longitudinal driving of CAVs within mixed flow. [37] developed the robust-safety-critical traffic controller in mixed traffic flow. This controller ensures collision-free safety even in the face of actuator and sensor delays, as well as disturbances from the leading HV. As traffic systems expand, a consequent problem is the dramatic increase in online computing burden, and the data-driven distributed control emerged as the times require. Surprisingly, [38] conducted data-driven mixed vehicle platoons dynamics modeling based on Koopman, which is a groundbreaking work that has attracted our high attention and interest. [17], [18] proposed distributed data-driven predictive control that directly utilizes measurable traffic data to design collision-free optimal CAV control inputs for collaboratively smoothing mixed traffic flows. However, it is difficult to demonstrate its generalization ability in other mixed traffic flow scenarios by modeling the entire traffic flow and obtaining the Koopman operator based on a dataset generated by simple physical models, which drives our idea. We expect to use Koopman theory to learn vehicle features from real-world trajectories and construct a scene adaptive and scalable control framework.\nD. The applications of Koopman theory in traffic flow\nKoopman operator theory is a mathematical framework that involves representing nonlinear systems in a higher-dimensional linear space, making it possible to study the evolution of complex systems [39]. [40] used Koopman"}, {"title": "operator to propose a model-free, data-driven approach that cleverly analyzed and predicted the evolution of highly complex nonlinear traffic flow.", "content": "[41] applied Koopman operator theory and the dynamical mode decomposition for signalized traffic flow networks control, which allows for early identification of unstable queue growth. In order to realize the real-time control of the ramp metering on the freeway efficiently, [42] proposed a model predictive controller with the trained deep Koopman model. The above methods relied on parameter estimation of physical models or modeling of nonlinear dynamics using neural networks. [43] introduced a novel data-driven vehicle modeling and control approach, employing an interpretable Koopman operator base deep neural networks in which extended dynamic mode decomposition was utilized to learn a finite-dimensional approximation of the Koopman operator. Recently, in solving non-stationary time series prediction problems, [44] proposed an efficient time series prediction model driven by Koopman theory, which hierarchically mines the dynamic system of time series.\nIII. ADAP\u039a\u039f\u039f\u03a1\u039d\u0395\u03a4: ADAPTIVE DEEP KOOP\u039c\u0391\u039d NETWORK FOR CAR FOLLOWING BEHAVIOR MODELING AND PREDICTION OF HDVS\nIn this section, a data-driven adaptive deep Koopman linear model is proposed to address the challenges associated with real-time cognition and prediction of the state of HDVs.\nA. Key terms definition\nConsidering that terms such as scenarios have different understandings in existing research. Here we define and explain several key terms that apply specifically to this paper:\nScenario is the mixed traffic flow environment in which the vehicle is located, such as free flow, synchronous flow, congestion flow, etc., and the direct explicit status includes traffic flow velocity, density, etc.\nScenario characteristics refers to the collective driving behavior exhibited by drivers in corresponding scenes, which is a potential common feature. For example, in high-velocity and high-density driving scenario, drivers generally pay more attention to the behavior of surrounding vehicles, are greatly influenced by them, and adjust their own driving behavior more frequently than usual.\nDriving characteristics is the specific manifestations of an individual driver's long-term driving habits in different driving scenarios. For example, aggressive drivers may be more conservative in high-velocity and high-density scenarios compared to free flow scenarios. However, this tendency is uncertain. Some drivers exhibit driving characteristics similar to the average of vehicle group characteristics in certain scenarios, while others are only slightly affected. Therefore, the predicted scenario classification is the comprehensive value of driver tendency and scenario characteristics themselves.\nB. Problem description\nAssuming that in high-density mixed traffic flow, HDVs not engaging in lane-changing behavior are primarily influenced by their preceding vehicles. Their driving behavior is primarily"}, {"title": "shaped by the current velocity of the preceding vehicle, their own current velocity, and the headway.", "content": "For the purpose of research, time is discretized into infinitesimally small segments, and the aforementioned process can be described by the following equations:\n$(v_i (t + 1), h_i (t + 1)) = f (v_i (t), h_i (t), V_{i\u22121} (t))$  (1)\nwhere $v_i (t), h_i (t), v_{i\u22121} (t)$ respectively represent the velocity, headway of vehicle i, and the velocity of the preceding vehicle i-1 at time t; f () denotes the state transition function. In real-world scenarios, different drivers commonly exhibit markedly diverse behaviors when faced with identical situations. This variability is intricately associated with individual driving habits, short-term fluctuations in the surrounding environment, and specific driving intentions.\nThese short-term trajectories serve as external manifestations of driver characteristics, encapsulating abundant driving semantic information. Consequently, they are employed for the identification and differentiation of heterogeneity among drivers. Therefore, the problem is defined as follows:\n$dc_i (t) = f_{dc} (x_i (t \u2212 P), x_i (t \u2212 P + 1), x_i (t))$\n$(v_i (t + 1), h_i (t + 1)) = f_{sp} (v_i (t), h_i (t), dc_i (t), V_{i\u22121} (t))$ (2)\nwhere $x_i (\u00b7) = [V_i (\u00b7), h_i (\u00b7), \\Delta v_i (\u00b7), a_i (\u00b7), l_i]^T, \\Delta v_i (\u00b7), a_i (\u00b7), l_i$ respectively represent the velocity difference, acceleration, and vehicle length of vehicle i; P, $f_{dc} (\u00b7), dc_i (\u00b7)$ respectively represent the length of historical trajectories, the mapping relationship between trajectories and driving characteristics, and the driving characteristics extracted from information containing P trajectory samples.\nAs illustrated in Eq. (2), the objective in this section revolves finding a mapping. The inputs contain the historical trajectory context, the current explicit state of the vehicle i, the velocity of the preceding vehicle i - 1, and the outputs contain the prediction velocity and headway of the vehicle i in next time step. However, the mapping is typically nonlinear, leading to significant computational delays in online optimization for mixed traffic flow. The Koopman operator theory provides an promising approach to tackle this challenge.\nC. Koopman operator theory for state prediction of HDVs\n1) Koopman operator theory: The Koopman operator theory initially provides an alternative linear dynamic description for the evolution of uncontrollable systems [39]. With slight modifications, the Koopman operator can be applied to controlled systems [45]. Therefore, the evolution of system modeled by Eq. (2) can be expressed by a linear Koopman operator in an infinite-dimensional space. Let$z_i (\u00b7) = [V_i (\u00b7), h_i (\u00b7), dc_i (\u00b7)]^T \u2208 Z$ represents the state of vehicle i, $V_{i\u22121} (t) = v$ denotes all the velocities in the velocity space V, the Koopman operator on System corresponding to Eq.(2) with the extended state $[z_i (t), v_{i\u22121} (t)]$ is defined as follows:\n$K\u03a6 (z_i (t), v_{i\u22121} (t)) = \u03a6 (z_i (t + 1), v_{i\u22121} (t + 1)) = \u03a6 (f_{sp} (z_i (t), V_{i\u22121} (t)) + \\vartheta_{v_{i\u22121}} (t))$  (3)\nwhere K is the Koopman operator in the infinite-dimensional space; $\\vartheta_{v_{i-1}} (t) = v_{i-1} (t+1)$ with a being a left shift"}, {"title": "operator. It is noteworthy that, unlike fac (\u00b7) directly acting on the state zi (\u00b7), the Koopman operator K operates on the state space functions \u03c6 (\u00b7) \u2208 Z \u00d7 V with \u03c6 : Z\u00d7V \u2192C.", "content": "Exploiting the linearity of K, it can be subjected to eigenvalue decomposition, expressed as follows:\n$K\u03a6_m (z_i (t), v_{i\u22121} (t)) = \u03bb_m\u03a6_m (z_i (t), v_{i\u22121} (t))$ (4)\nwhere $\u03bb_m, \u03a6_m (\u00b7)$ represent the eigenvalues of K and their corresponding eigenfunctions, respectively. The future states of the system can be acquired either by directly evolving zi (\u00b7) or by evolving the complete observable state through the Koopman operator:\n$f_{sp} (z_i (t), v_{i-1} (t)) = \u2211_{m=1}^{\u221e} \u03bb_m \\vartheta_m \u03a6_m (z_i (t), v_{i-1} (t))$ (5)\nwhere $ \\vartheta_m$ is the Koopman mode corresponding to the eigenvalue \u03bbm. The relationship between the original space and the observable infinite-dimensional space is depicted in Fig. 1.\nBased on Eqs. (3)-(5), the endeavor to derive a global linearized dynamic description equivalent to system modeled by Eq.(2) involves the search for Koopman eigenvalues along with their corresponding eigenfunctions and Koopman modes. Nevertheless, the Koopman operator typically encompasses an infinite number of eigenvalues. Consequently, in most instances, a global linear approximation of the system can only be achieved by identifying essential eigenvalues and their associated eigenfunctions and Koopman modes.\n2) Extended dynamic mode decomposition: The extended dynamic mode decomposition (EDMD) is a data-driven approach of finding the finite-dimensional approximation $K$ of the Koopman operator [46]. EDMD employs various basis functions, such as Radial Basis Functions (RBF) with different kernel centers and widths, to represent observable functions. It utilizes least squares regression to calculate $K$. For forced dynamics model in Eq. (2), a special way for selecting basis functions is defined in Eq. (5) to obtain :\n$\u03a6 (z_i (t), v_{i\u22121} (t)) = [\u03c6 (z_i (t))^T, v_{i-1} (t)^T]^T$ (6)\nwhere $\u03c6 (:)= [\u03c6_1(:) \u03c6_2(:) ... \u03c6_L (:)]^T$ represents a set of observable lift functions is general nonlinear. Let si (k) = \u03c6 (zi (k)), combining Eqs. (3)-(6), Eq. (7) is obtained:\n$\u03c6 (z_i (k + 1)) = K\u03c6 (z_i (k), U_{n\u22121} (k)) = K[s_n(k)  U_{n-1}(k)]^T + r$ (7)\nwherer is residual term that describes the gap between the L-dimensional approximation of the observable space and the"}, {"title": "actual lifted space of the Koopman operator, used to determine the optimal K.", "content": "However, selecting the lifting functions for the complex dynamics of System (2) poses a challenge, and advanced deep learning techniques are employed to learn K.\nD. Model architecture\nA deep learning model, based on attention mechanisms and feedforward networks, is constructed to accomplish the following tasks: 1) Extracting latent driving characteristics from historical trajectory context, which are utilized to aid in understanding and predicting the behavior of HDVs; 2) Learning Koopman lifting functions, Koopman operator approximation, and Koopman modes, the latter two of which are linear, for online optimization in CAVs .\nThe model architecture is depicted in Fig.2. For trajectory context inputs, the model incorporates a driving characteristic semantic extraction block (highlighted by the deep green dashed box in Fig.2). To handle the current vehicle state input, a multi-layer perceptron-based encoder-lifting function approximation is employed. The fusion gate mechanism integrates the encoding of driving characteristics with the explicit state encoding of the lifting space, yielding the state of the observable high-dimensional Koopman space approximation. By incorporating the future velocity of the preceding vehicle into the network, the model adaptively learns the Koopman operator approximation and achieves multi-step state predictions in the high-dimensional space. This module is denoted as the Koopman evolution block, highlighted by the pink dashed box in Fig.2. Additionally, a linear decoder, serving as an approximation for Koopman modes, is utilized to transform observations from the high-dimensional space to obtain predicted states in the original space.\n1) Driving characteristic semantic extraction block: As shown in Fig. 2, this block takes trajectory context as input, containing details as specified in the Eq. (2), and outputs a vector representing the current latent driving characteristics of the driver. The block comprises an input embedding and temporal encoding (ITE) module, a multi-head dynamic temporal interaction (DTI) module, a multi-head driving scenario recognition (DSR) module, and a driving characteristics"}, {"title": "semantic transformation (DCSE) module, each of which is detailed below.", "content": "Input Embedding and Temporal Encoding (ITE) Module\nThe input embedding layer serves to convert the trajectory context into a high-dimensional dense representation, allowing the model to comprehensively learn the trajectory features and analyze correlation between trajectory samples. The embedding is achieved through a fully connected layer with a ReLU activation function. Given that the embedding operation is conducted for each trajectory sample, a relative time encoding method is introduced to enable subsequent modules to recognize the temporal information of trajectory context [47]. The expression is as follows:\n$TE(t,2i) = sin \\frac{t}{10000^{(2i/d_{model})}}$\n$TE(t,2i+1) = cos \\frac{t}{10000^{(2i/d_{model})}}$  (8)\nwhere i, t represent the encoding feature dimension index and time step, respectively; dmodel represents the dimensionality of the encoding of each module in the AdapKoopnet, without special declaration. Subsequently, the trajectory context input embedding and temporal encoding are added together to form the output of this module. The expression is as follows:\n$H_{ITE} = ReLU (W_{IE} \u00b7 (x (T \u2013 P),\u22c5\u22c5\u22c5,x (T)) +b_{IE})+TE$ (9)\nwhere $W_{IE}, B_{IE},$ represent the weights and biases of the input embedding layer.\nMulti-Head Dynamic Temporal Interaction (DTI) Module The vehicle state undergoes continuous changes, and there exists a strong interaction and correlation between trajectory samples. This module leverages multi-head attention and feedforward layers to capture and understand the temporal interactions and dependencies within the vehicle trajectory context. Firstly, the multi-head attention mechanism projects the output of ITE into multiple subspaces. In each subspace, it independently learns interaction features within the trajectory context and facilitates feature exchange. By focusing on different subspaces, the model can better capture information from different dimensions within the trajectory context, enhancing its ability to model complex relationships between trajectory sequences. This approach not only accelerates the"}, {"title": "speed of training and inference but also contributes to a more comprehensive understanding of the intricate dynamics among trajectory samples.", "content": "The dimension of each subspace is also a hyperparameter. In AdapKoopnet, a uniform subspace dimension is adopted and denoted as datt. The calculation formula for HDTI in the figure is as follows:\n$QDTI = W_{DTI-HITE}   KOTI = W_{DTI-KHITE}$\n$VDTI = W_{DTI-HITE}$\n$HOTI = softmax (\\frac{QOTIKTI}{\u221ad_{att}})$\n$HDTI = LN (W_{DTI-att} (||^D_{h=1}HDTI) + HITE)$ (10)\nwhere $WBTI-q, WBTI\u2212k, WBTI\u2212\u03c5, WDTI-att$ represents learnable weights; || denotes the concatenate operation. LN (\u00b7) stands for Layer Normalization, a technique that normalizes the trajectory encoding along the feature dimension to mitigate the impact of internal covariate shift [48]. Unlike Batch Normalization (BN), Layer Normalization is more flexible as it is not influenced by the size of the data batch.\nAfter achieving feature exchange within the trajectory context through the attention layer, the feedforward layer is employed for the nonlinear transformation of trajectory encoding. This aims to capture the nonlinear relationships within the trajectory context, facilitating the model in learning higher-level abstract representations. The feedforward layer consists of two linear transformations and an activation function. Initially, HDTI undergoes a fully connected layer, followed by the application of the ReLU activation function, and finally passes through another fully connected layer. After HDTI goes through the feedforward layer, the output of the DTI module is obtained, calculated using the following formula:\n$HDTI = LN (W^{DTI}_{EN2} ReLU (W^{DTI}_{EN1}\u00b7 HDTI) + HDTI)$ (11)\nwhere $W^{FN-1}_{ETI}$ and $W^{FN-2}_{ETI}$ represent the weights of the feedforward layer in the DIT module.\nMulti-Head Driving Scenario Recognition (DSR) Module\nFollowing the extracting and initial abstracting of temporal interaction characteristics within the trajectory context through the DTI module, the cognitive understanding of driving scenario and the extraction of driving characteristic semantics become crucial steps. This is because, in different driving scenarios, even for the same driver, driving characteristics may vary. For example, in scenarios with large headway, drivers may not require to remain highly vigilant about their preceding vehicles, and their driving behavior tends to be smoother. Conversely, in high-density and high-velocity scenarios, drivers may concentrate more on monitoring changes in the state of preceding vehicle and respond more actively. The DSR module learns scenario information hidden within the trajectory context by adapting to relevant feature variations from a vast set of driving trajectory contexts. It dynamically recognizes and classifies the driving scenario in which the vehicle is situated."}, {"title": "Initially, Eq. (8) is utilized to generate a special encoding", "content": "token. Subsequently, this token is concatenated with the output of the DTI module HDTI, functioning as the original query. The role of this token is to extract features conducive to the cognitive understanding of driving scenarios by attending to the trajectory context encoding. These features undergo further abstraction through the nonlinear transformation of the feedforward layer. The module was associated and matched these abstracted features with the learned scenario information features of the model, achieving cognitive recognition and prediction of implicit driving scenarios within the trajectory context. Similar to the DTI module, this module conduct deep exchange and further abstraction of interaction features within the trajectory context.\nThe computational process of the DSR module is fundamentally similar to the DTI module. Its output in the feedforward layer is as follows:\n$HDSR-DS, HDSR-TC = WDSR (SE, HDTI)$ (12)\nwhere SE, WDSR, HDSR-TC and HDSR-DS represent the special encoding token, the weights of DSR module, the trajectory context encoding in Figure 4, and the special encoding token that completes the extraction of driving scenario features, respectively. HDSR-DS undergoes a linear layer to aggregate driving scenario features, resulting in a vector with the same dimension as the predefined number of scenes. After applying the softmax activation function, the driving scenario prediction vector depicted in Fig. 3 (a) is obtained. Each dimension of this vector represents the predicted probability of the trajectory context belonging to the corresponding scene. The formula is expressed as follows:\n$HDS = softmax (WDSR-DS\u00b7 (HDSR-DS))$ (13)\nRemark 1: In this study, real labels for driving scenario are not available. Therefore, the driving scenario recognition process involves a spontaneous classification process by the neural network based on a large amount of trajectory context. At the inception of the network design, the task of the DSR module is to cluster recurring trajectory patterns and interpret the generated clusters as potential scenarios. From a macro perspective, this lays the foundation for extracting semantic characteristics of driving characteristics. In Section 5, explicit features corresponding to each scenario will be visualized, although this may not necessarily be the sole basis for the classification of network.\nDriving Characteristics Semantic Transformation (DCSE) Module As mentioned in the DSR module, driving characteristics vary across different driving scenarios. The current module aims to perform driving characteristic semantic extraction guided by the predicted results of driving scenario recognition. The structural diagram of module is presented in Fig. 3 (b) .\nThe process begins by defining learnable feature weights corresponding to each scenario. These weights dynamically learn the importance of each feature in the trajectory context encoding under predefined scenarios, using an extensive training data. The features are then aggregated based on the learned importance, obtaining the relevance of each trajectory sample to driving characteristic extraction in a specific driving"}, {"title": "scenario.", "content": "Then, the relevance for each scenario is aggregated based on the probabilities predicted by the DSR module or according to user-defined scenarios. After applying the softmax activation function, the correlation between the trajectory context encoding and driving features is obtained. Based on this correlation, the trajectory context is aggregated, ultimately revealing the driving features hidden within the trajectory context. The computational formula is as follows:\n$dc (T) = softmax(HDSR-TCdsfcHDS) HDSR-TC$ (14)\nwhere dsfc, dcy respectively represent the learnable feature weights corresponding to each scenario, and the latent driving characteristic at time T.\n2) Explicit state encoder and fusion gate mechanism: The explicit state encoder is tasked with encoding the explicit state of the vehicle from the original space to an observable high-dimensional space, facilitating the action of the Koopman lifting function on the current vehicle state. This encoder initially embeds the vehicle state into a high-dimensional representation through a linear layer with a ReLU activation function. Subsequently, a Multi-Layer Perceptron (MLP) with tanh activation function is utilized to perform multiple linear transformations on the embedded representation, completing the task of encoding the explicit state of the vehicle. Next, the explicit state encoding and the latent driving characteristics of the vehicle need to be fused to form the Koopman state approximation for the current time step. The Gated Linear Unit (GLU) is introduced to accomplish this fusion task. And the computational formula is as follows:\n$es (T) = W_{ESE}.es (T)$\n$s (T) = W_{FG}. (dc (T), es (T))$ (15)\nwhere $es (T) = (v (T), h (T))^T; W_{ESE}, W_{FG}$ represents the weights of explicit state encoder and fusion gate mechanism. es (T), s (T) are the explicit state encoding and Koopman state approximation of the vehicle at time step T.\n3) Koopman evolution block and decoder: In the Koopman evolution block, the multi-step evolution in the observable high-dimensional linear system is achieved based on the Koopman operator approximation K learned through two linear layers without bias. Specifically, K comprises the system matrix A and the control matrix B. A describes the process of system state transition without control inputs, while the"}, {"title": "velocity of preceding vehicle in the prediction horizon is treated as the system control input.", "content": "This input is applied to the system through the control matrix B to complete the system evolution. The formal expression of this process is as follows:\n$s^P (T + F) = As^P (T + F \u2212 1) + BV_{\u22121} (T + F \u2212 1) = A^F s (T) + \u2211_{f=1}^F A^{F\u2212\u00b9}BV_{\u22121} (T + F \u2212 f) \u2266 \u0100^F (s (T), v_{\u22121} (T : T + F \u2212 1))$ (16)\nwhere $s^P (\u00b7), v_{\u22121} (\u00b7)$ represent the predicted state in high-dimensional space and the velocity of the preceding vehicle, respectively.\nSubsequently, the decoder, characterized as a bias-free linear layer, serves to approximate the Koopman modes and reconstruct the predicted state from the observable high-dimensional space to the original space. To minimize online computation delay for CAVs, the decoder is specifically designed as a linear layer without bias (In Section 5, the predictive performance difference between the current decoder and using an MLP as the decoder will be demonstrated). The reconstructed state variables in the original space align with the state variables input to the explicit state encoder in AdapKoopnet. The reconstruction process is expressed as follows:\n$es^P (T + f) = W_{DEC}.s^P (T + f)$ (17)\nwhere $es^P (T + f) = (v^P (T), h^P (T))^T$ represents the predicted state of the original space; $W_{DEC}$ represents the learnable weights in the decoder.\nRemark 2: In a typical trajectory prediction task, incorporating future velocities of the preceding vehicle as inputs may be impractical. However, the primary objective of AdapKoopnet is to predict the response driving behavior of HDVs to the preceding vehicle. This facilitates subsequent inferences about the required velocity of the CAVs. This makes this setup appear much more reasonable.\nE. Loss function\nLoss of AdapKoopnet is composed of reconstruction error, prediction error, and linear evolution error [49]. Specifically, the reconstruction error represents the difference between the reconstructed state obtained by embedding the current"}, {"title": "explicit state of the vehicle into a high-dimensional space and reconstructing it through the decoder, and the original state.", "content": "To achieve accurate reconstruction of"}]}