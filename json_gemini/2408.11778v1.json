{"title": "Sum of Squares Circuits*", "authors": ["Lorenzo Loconte", "Stefan Mengel", "Antonio Vergari"], "abstract": "Designing expressive generative models that support exact\nand efficient inference is a core question in probabilistic\nML. Probabilistic circuits (PCs) offer a framework where this\ntractability-vs-expressiveness trade-off can be analyzed the-\noretically. Recently, squared PCs encoding subtractive mix-\ntures via negative parameters have emerged as tractable mod-\nels that can be exponentially more expressive than monotonic\nPCs, i.e., PCs with positive parameters only. In this paper,\nwe provide a more precise theoretical characterization of the\nexpressiveness relationships among these models. First, we\nprove that squared PCs can be less expressive than monotonic\nones. Second, we formalize a novel class of PCs - sum of\nsquares PCs - that can be exponentially more expressive than\nboth squared and monotonic PCs. Around sum of squares\nPCs, we build an expressiveness hierarchy that allows us to\nprecisely unify and separate different tractable model classes\nsuch as Born Machines and PSD models, and other recently\nintroduced tractable probabilistic models by using complex\nparameters. Finally, we empirically show the effectiveness of\nsum of squares circuits in performing distribution estimation.", "sections": [{"title": "1 Introduction", "content": "We design and learn expressive probabilistic models to com-\npactly represent the complex distribution we assume has\ngenerated the data we deal with. At the same time, a key\nrequirement to effectively reason about such a distribution\nis that we can perform inference exactly and efficiently,\ni.e., tractably. This is especially relevant in safety-critical\nreal-world applications where reliable inference is required\n(Ahmed et al. 2022; Marconato et al. 2024b,a).\nQuantifying this trade-off between tractability and expres-\nsiveness can be done within the framework of probabilis-\ntic circuits (PCs) (Vergari, Di Mauro, and Van den Broeck\n2019), which are deep computational graphs that generalize\nmany tractable representations in ML and AI (Choi, Vergari,\nand Van den Broeck 2020). For example, within the frame-\nwork of PCs, guaranteeing the tractability of certain infer-\nence scenarios, e.g., marginals, MAP inference, or comput-\ning divergences, directly translates into ensuring that these\ncomputational graphs have certain structural properties (Ver-\ngari et al. 2021). Expressiveness, on the other hand, can be\ntheoretically characterized in terms of the circuit size (and\nhence number of learnable parameters) (Shpilka and Yehu-\ndayoff 2010). Furthermore, one can precisely characterize\nthat two model classes can capture the same probability dis-\ntributions, if we can reduce one to the other in polytime.\nConversely, to separate two model classes in terms of ex-\npressiveness, one has to prove that a function can be exactly\ncaptured by a circuit class but not by the other, unless this\none has exponential size (de Colnet and Mengel 2021).\nTo ensure that a circuit outputs non-negative values only\n\u2013 the minimum requirement to model a valid density \u2013 PCs\nare classically represented and learned with non-negative pa-\nrameters only, i.e., they are monotonic (Shpilka and Yehu-\ndayoff 2010). This prominent circuit class can only represent\nmixture models whose component densities are added. To\nfill this gap, Loconte et al. (2024) introduced a special class\nof non-monotonic PCs, i.e., circuits with negative parame-\nters, thus allowing to subtract mixture components as well.\nNon-negativity of the circuit outputs is ensured by tractably\nsquaring the PCs (Vergari et al. 2021). Loconte et al. (2024)\nproved an exponential separation between monotonic and\nnon-monotonic squared circuits, showing that the latter can\nbe more expressive than the former. However, one question\nremains open: can squared circuits compactly compute all"}, {"title": "2 From Circuits to Squared PCs", "content": "We denote sets of variables in bold uppercase, e.g., X =\n{X1,..., Xa} while x \u2208 dom(X) denotes an assignment\nfrom the domain dom(X). We use [n] for the set {1, ..., n}.\nWe start by defining circuits and their properties.\nDefinition 1 (Circuit (Vergari et al. 2021)). A circuit c is a\nparameterized computational graph over X encoding a func-\ntion c(X) and comprising three kinds of units: input, prod-\nuct, and sum. Each product or sum unit n receives the out-\nputs of other units as inputs, denoted as the set in(n). Each\nunit n encodes a function en defined as: (i) fn(sc(n)) if n is\nan input unit having scope sc(n) = {Y}, Y \u2208 X, where fn\nis a function defined over Y; (ii) \\prod_{j\\in in(n)} Cj (sc(j)) if n is\na product unit; and (iii) \\sum_{j\\in in(n)} \\Theta_{n,j}Cj (sc(j)) if n is a sum\nunit, where each \\Theta_{n,j} \u2208 R is a parameter of n. The scope\nof a non-input unit n is the union of the scopes of its inputs,\ni.e., sc(n) = Uj\u2208in(n) SC(j).\nW.l.o.g., we assume product units to have at most two in-\nputs. For a circuit c, this can be enforced with just a quadratic\nincrease in its size, i.e., the number of edges in it, denoted as\n|c| (Martens and Medabalimi 2014). A probabilistic circuit\n(PC) is a circuit c encoding a non-negative function, i.e.,\nc(x) \u2265 0 for any x, thus encoding a (possibly unnormal-\nized) probability distribution p(x) \u221d c(x). A PC c supports\nthe tractable marginalization of any variable subset in time\nO(|c|) (Choi, Vergari, and Van den Broeck 2020) if (i) its\ninput functions fn can be integrated efficiently and (ii) it is\nsmooth and decomposable, as defined next.\nDefinition 2 (Smoothness and decomposability (Darwiche\nand Marquis 2002)). A circuit is smooth if for every sum\nunit n, all its input units depend on the same variables, i.e,\n\u2200i, j \u2208 in(n): sc(i) = sc(j). A circuit is decomposable if\nthe inputs of every product unit n depend on disjoint sets of\nvariables, i.e, \u2200i, j \u2208 in(n) i \u2260 j : sc(i) \u2229 sc(j) = \u00d8.\nExpressive efficiency also called succinctness, or represen-\ntational power refers to the ability of a circuit class to en-\ncode a (possibly unnormalized) distribution in a polysize\ncomputational graph, i.e., whose size grows polynomially\nw.r.t. its input size. This is in contrast with \u201cexpressiveness\u201d\nintended as universal representation: all PCs with Boolean\n(resp. Gaussian) inputs can express any Boolean (resp. con-\ntinuous) distribution arbitrarily well, but in general at the\ncost of an exponential size. When we say that one class is\nexponentially more efficient or succinct than another we im-\nply there exist a distribution, also called separating function,\nthat cannot be captured by any polysize circuit belonging to\nthe second class. E.g., circuits satisfying fewer or different"}, {"title": "3 A Limitation of Squared Circuits", "content": "We show that there is a class of non-negative functions that\ncan be efficiently represented by structured-decomposable\nmonotonic circuits, whose class we denote as +sd, but for\nwhich any squared PC c\u00b2 has exponential size. As we dis-\ncussed before in Section 2, we use the property that c\u00b2 is\nthe output of the product algorithm Multiply, and therefore\nis bounded by the size of the possibly negative circuit c: by\nconstructing an exponential lower bound of the size of c, we\ntherefore obtain a lower bound on |c\u00b2|. While there could exist\nan alternative algorithm to directly construct a polynomial\nsize c\u00b2 that encodes our separating function, we conjecture\nthis is unlikely. The next theorem formalizes our finding.\nTheorem 1. There is a class of non-negative functions F\nover d = k(k + 1) variables that can be encoded by a PC\nin +sd having size O(d). However, the smallest |c\u00b2| \u2208 \u00b1\ncomputing any F \u2208 F requires |c| to be at least 2^{\u03a9(\\sqrt{d})}"}, {"title": "4 Sum of Compatible Squares Circuits", "content": "Our more expressive class of circuits will take the form of\na sum of squares (SOS), a well-known concept in algebraic\ngeometry where it is used to characterize some non-negative\npolynomials (Benoist 2017). As such, we derive a special\nSOS polynomial family that supports tractable inference, as\ncircuits can also be understood as compact representations\nof polynomials whose indeterminates are the circuit input\nfunctions (Martens and Medabalimi 2014). As we are inter-\nested in precisely tracing the boundaries of expressive effi-\nciency for circuits, we will require that our SOS forms al-\nways have polynomial size. This is in contrast with univer-\nsality results for SOS and non-negative polynomials, where\nthe interest is to prove that a non-negative polynomial can\nor cannot be written as a SOS, regardless of the model size.\nE.g., see the Hilbert's 17th problem and Marshall (2008) for\na review. To preserve tractable inference, in our class of sum\nof squares circuits, we do not only require each circuit to be\nstructured-decomposable as to efficiently square it, but also\ncompatible with all the others.\nDefinition 4 (\\Sigma^2_{cmp}). A sum of compatible squares (SOCS) PC\nc over variables X is a PC encoding c(x) = \\sum_{i=1}^r c_i(x)^2\nwhere, for all i, j \u2208 [r], c_i, c_j \u2208 \\S_{\u00b0sd} are compatible.\nWe denote this class of SOCS circuits as \\Sigma^2_{cmp}. Combin-\ning many (squared) PCs in a positive sum is equivalent to\nbuilding a finite mixture (McLachlan, Lee, and Rathnayake\n2019) having (squared) PCs as components. Although this\nlooks like a simple way to increase their expressiveness, we\nnow show that that the advantage is in fact exponential.\nTheorem 2. There is a class of non-negative functions F\nover d variables that can be represented by a PC in \\Sigma^2_{2mp} of\nsize O(d\u00b3). However, (i) the smallest PC in +sd computing\nany F \u2208 F has at least size 2^{\u03a9(\\sqrt{d})}, and (ii) the smallest\n|c\u00b2| \u2208 \u00b1 computing F obtained by squaring a structured-\ndecomposable circuit c, requires |c| to be at least 2^{\u03a9(\\sqrt{d})}.\nIn fact, we prove two alternative exponential separations\nbetween \\Sigma^2_{2mp} and both +sd and \u00b1 circuit classes, repre-\nsented in Eqs. (4) and (5). Each combines a monotonic PC\nfrom + sd and a squared one from \u00b1 and thus provides a dif-\nferent insight on how to build more expressive circuits. Our\nproof of Theorem 2 uses our first separating function fam-\nily F, built as a sum of UDISJ (Eq. (1)) and SUM (Eq. (3))\nembedded on a graph, and defined as UPS(X) =\n\\frac{1}{Z_1} (1 - \\sum_{uv \\in E} X_uX_v)^2 + \\frac{Z_2}{Z_1} \\sum_{j=1}^{|V|} X_j \\sum_{u \\in V} 2^{j-1} X_u\nwhere X = X'\u222aX\"\u222a{Z1, Z2} are Boolean variables, with\nX' = {Xv | v \u2208 V}, X\" = Uv\u2208v{Xv,j | j \u2208 [|V|]},\nand Z1, Z2 are auxiliary variables. By properly setting Z\u2081 =\n1, Z2 = 0 (resp. Z\u2081 = 0, Z2 = 1) we retrieve a PC in \u00b1\n(resp. +sd). See Appendix B.3 for the proof details.\nTheorem B.3 details our alternative exponential separa-\ntion, where we let F be the product of UDISJ times a\nquadratic form that can be easily represented as a circuit in\n+sd. We name it UTQ(X) and define it on a graph as\n (1 - \\sum_{uv \\in E} X_uX_v)^2 (1 + \\sum_{uv \\in E} X_uX_v)\nwhere X = {Xv | v \u2208 V} are Boolean variables. A first ad-\nvantage of this alternative construction is that Theorem B.3\nprovides a stronger lower bound: 2^{\u03a9(d)} instead of 2^{N(\\sqrt{d})} as\nin Theorem 2. Furthermore, multiplying circuits from +sd\nand \u00b1 provides a perspective to better understand other ex-\nisting tractable representations (Proposition 1) and build PCs\nthat can compactly encode a sum of an exponential number\nof squares. To this end, we generalize this construction to a\nproduct of tractable circuits in + sd and \\Sigma^2_{cmp}.\nDefinition 5 (\\mu SOCS). A product of monotonic by SOCS\n(\\mu SOCS) PC c over variables X is a PC encoding c(x) =\nC1(x)\u00b7C2(x), where c\u2081 \u2208 +sd and c2 \u2208 \\Sigma^2_{2mp} are compatible."}, {"title": "5 SOCS circuits Unify many Model Classes", "content": "We now extend the theoretical results presented so far to\nseveral other tractable model classes that can be reduced to\nSOCS. We start by models with complex parameters.\nComplex squared PCs. Complex parameters have been\nextensively used in ML models. First, for their semantics as\nmodeling waves, as known in physics and signal process-\ning (Hirose and Yoshida 2012; Tygert et al. 2015), E.g.,\nwe already mentioned in Section 2 that MPSs and BMs are\ngenerally defined as encoding a factorization over the com-\nplexes. Thus, a BM from quantum physics models the mod-\nulus squared |\u03c8(x)|\u00b2 = \u03c8(x)\u2020\u03c8(x), where (\u00b7)\u2020 denotes\nthe complex conjugate operation of a complex function \u03c8,\nhere factorized as a complex MPS. The tensors A1,..., Ad\nshown in Eq. (2) are generalized to have complex-valued\nentries (Or\u00fas 2013). Complex BMs have been used for dis-\ntribution estimation (Han et al. 2018; Cheng et al. 2019).\nSecondly, there is empirical evidence supporting the use\nof complex parameters to stabilize learning (Arjovsky, Shah,\nand Bengio 2015) and greatly boost the performance of ML\nmodels, PCs included (Trouillon et al. 2016; Sun et al. 2019;\nLoconte et al. 2023). Within the framework of PCs, one can\nback up this evidence with a precise theoretical characteri-\nzation and answer the question: is there any expressive ad-\nvantage in modeling PCs in the field of complex numbers?\nTo do so, we extend PCs in \u00b1 and formally define a com-\nplex squared PC as the one computing c\u00b2(x) = c(x)\u2020c(x),\ni.e., via the modulus square of a structured-decomposable\ncomplex circuit c whose parameters and input functions are\ncomplex. Computing c\u2020, the complex conjugate of c, can\nbe done efficiently in O(|c|2) via Multiply(c\u2020, c) that pre-\nserves the structural properties we need: smoothness and\nstructured-decomposability as proven in Yu, Trapp, and Ker-\nsting (2023). We denote with \u00b1\u00b2 the class of complex\nsquared PCs computing |c|\u00b2 via Multiply in this way.\nThen, we show in Appendix B.5 that, similarly to the re-\nduction of real BMs to squared PCs (Loconte et al. 2024),\ncomplex BMs can be reduced to complex squared PCs, thus\nmaking them at least as expressive as their real counterpart.\nMore crucially, we prove that any complex squared PC can\nbe efficiently reduced to a PC in \u03a3\u00b2_{cmp} with real parameters\nonly. This settles the question whether complex parameters\nbring an expressive advantage over reals through the lens of\nour Theorem 2. We formalize this result below.\nCorollary 1. Let |c|\u00b2 \u2208 \u00b1\u00b2 be a PC over variables X, where\nc is a structured-decomposable circuit computing a complex\nfunction. Then, we can efficiently represent |c|\u00b2 as the sum of\ntwo compatible PCs in \u03a3\u00b2_{\u00b1}, thus as a PC in \u03a3\u00b2_{cmp}\nThis result can be generalized to squared PCs comput-\ning the modulus square of circuits that output hypercom-\nplex numbers, e.g., quaternions, octonions and their gener-\nalizations (Shenitzer, Kantor, and Solodovnikov 1989). Hy-\npercomplex numbers have not only been studied in physics\n(Baez 2001), but also in ML to parameterize deep learning\nmodels (Saoud and Al-Marzouqi 2020; Yu et al. 2022). All\nthese squared circuits are also SOCS.\nTheorem 3. Let \\mathbb{A}_w be an algebra of hypercomplex num-\nbers of dimension 2^w (e.g., \\mathbb{A}_0 = \\mathbb{R}, \\mathbb{A}_1 = \\mathbb{C}, ...).\nGiven a structured-decomposable circuit c over X comput-\ning c(x) \u2208 \\mathbb{A}_w, we can efficiently represent a PC computing\n|c(x)|^2 = c(x)\u2020c(x) as a PC in \u03a3\u00b2_{cmp} having size O(2^{w}|c|^2).\nAppendix B.6 details our proof construction.\nSquared neural families (SNEFYs) (Tsuchida, Ong, and\nSejdinovic 2023, 2024) are recent neural estimators that\ngeneralize exponential families by replacing exponentiation\nwith a squared norm to model a distribution p(X) as:\nSNEFY_{t,\\sigma,\\mu}(x) = \\mathcal{Z}^{-1} \\mu(x) ||NN_{\\sigma}(t(x))||^2\nwhere \u03bc is the base measure, t: dom(X) \u2192 R^s the suf-\nficient statistics, NN\u03c3 is a 1-layer neural network with\nelement-wise activation function \u03c3 and Z the partition func-\ntion. Depending on the choice of t, \u03c3 and \u03bc, SNEFYt,\u03c3,\u03bc\nallows tractable marginalization (Tsuchida, Ong, and Sejdi-\nnovic 2023). Next, we show that many common parameter-\nizations of these tractable SNEFYs fall within \u03a3\u00b2_{2mp}.\nProposition 1. Let SNEFY_{t,\\sigma,\\mu} be a distribution over d vari-\nables X with \\sigma \u2208 {exp, cos}, \\mu(x) = \\mu_1(x_1)...\\mu_d(x_d),\nt(x) = [t_1(x_1),..., t_d(x_d)]^T. Then, SNEFY_{t,\\sigma,\\mu} can be en-\ncoded by a PC in \u03a3\u00b2_{2mp} of size O(poly(d, K)), where K\ndenotes the number of neural units in NN.\nWe prove it in Appendix B.7. Note that the product of a\nfactorized base measure \u03bc(x) = \u03bc\u2081(x1)\u2026\u2026\u03bc\u03b1(xd) by the\nsquared norm of a neural network (as in Proposition 1) can\nbe written as the product between a fully factorized mono-\ntonic PC computing \u03bc(x) and a SOCS PC. This is a special\ncase of our \u03bcSOCS construction (Definition 5).\nPositive semi-definite (PSD) kernels (Marteau-Ferey,\nBach, and Rudi 2020) are non-parametric estimators mod-\neling p(x) \u221d \u03ba(x)A\u03ba(x), where A \u2208 R^{r\u00d7r} is a PSD\nmatrix, and \u03ba(x) = [\u03ba(x, x(1)), ..., \u03ba(x, x(r))] \u2208 R^r is a\nkernel defined over data points {x(i)}i=1. For some choices\nof \u03ba (e.g., an RBF kernel as in Rudi and Ciliberto (2021)),\nPSD kernel models support tractable marginalization.\nSince PSD kernel models are shallow, Sladek, Trapp, and\nSolin (2023) have recently proposed to combine them with\ndeep monotonic PCs. They do so by parameterizing a sum\nunit n in a circuit to compute cn(x) = c(x)TAc(x), where\nA is a PSD matrix and c is a multi-output circuit comput-\ning an r-dimensional vector c(x) = [C1(x),..., Cr(x)]T,\nwith {Ci}i=1 being a set of non-monotonic circuits that are\ncompatible with each other (Definition 3). From now on, we\ndenote with \\S_{psd} the class of PCs computing c(x)Ac(x).\nNext, we show that PCs in \\S_{psd} are equivalently expressive"}, {"title": "6 Are All Structured PCs SOCS Circuits?", "content": "Given the increased expressiveness of SOCS PCs as dis-\ncussed so far, a natural question now is whether they can effi-\nciently encode any distribution computed by other tractable\nPC classes. Clearly, we need to restrict our attention to\nstructured-decomposable circuits, as this structural property\nis required for efficient squaring. This rules out from our\nanalysis circuits that are just decomposable or those that\nencode multilinear polynomials but are not decomposable.\n(Agarwal and Bl\u00e4ser 2024; Oliver Broadrick 2024).\nWe start by focusing on PCs in +sd, and show an upper\nbound on the size of SOCS PCs computing them.\nProposition 3. Every function computed by a PC in +sd\nover d Boolean variables can be encoded by a PC in \\Sigma\u00b2_{cmp} of\nsize O(2d).\nOur proof in Appendix B.9 rewrites the circuit as a shal-\nlow polynomial and exploits idempotency of Boolean vari-\nables w.r.t. powers. This is not surprising, as every non-\nnegative Boolean polynomial is known to be a SOS poly-\nnomial (Barak and Steurer 2016). However, it is unknown if\nthere exists a sub-exponential size upper bound for a SOCS\nPC computing PCs in +sd, leading to our first open question.\nOpen Question 1. Can any function computed by a polysize\nPC in +sd be also computed by a polysize PC in \u03a3\u00b2_{cmp}?\nIf we extend our analysis to PCs with non-Boolean in-\nputs, we connect with another classical result in algebraic\ngeometry showing there are many non-negative polynomi-\nals that cannot be written as SOS polynomials with real\ncoefficients (Blekherman 2003). E.g., Motzkin polynomial\n(Motzkin 1967) is defined as the bivariate polynomial\nF_M(X_1, X_2) = 1 + X_1^2 X_2^4 + X_1^4 X_2^2 - 3X_1^2 X_2^2\nthat while is non-negative over its domain R2, is also known\nnot to be a SOS (Marshall 2008). We generalize Motzkin\npolynomial to create a class of polynomials on an arbitrary\nnumber of variables that can be computed by PCs in \u00b1sd\nwhen equipped with polynomials as input functions but can-\nnot be computed by SOCS PCs with the same inputs.\nTheorem 4. There exists a class of non-negative functions\nF over d variables, that cannot be computed by SOCS PCs\nwhose input units encode polynomials. However, for any\nF \u2208 F, there exists a PC in \u00b1sd of size O(d\u00b2) with polyno-\nmials as input units computing it.\nAppendix B.10 details our proof. Note that the limitation\nshown in Theorem 4 remains even if we relax the compat-\nibility assumption for our SOCS (Definition 4) and obtain\na new class of sum of structured-decomposable squares cir-\ncuits. However, if we do not make any assumption on the\nfunctions computed by the input units of SOCS PCs, it re-\nmains open to formally show whether any function com-\nputed by a structured-decomposable PC can be efficiently\ncomputed by a PC in \u03a3\u00b2_{2mp}, as formalized below.\nOpen Question 2. Can any function computed by a polysize\nPC in \\S_{sd} be also computed by a polysize PC in \\Sigma^2_{cmp}?\nAnswering affirmatively to Open Question 2 would also\nsolve Open Question 1, since +sd \u2282 \u00b1sd. We visualize\nboth open questions in our expressive efficiency hierarchy\nin Fig. 1. While we do not answer to Open Question 2,\nthe following theorem shows that a single subtraction be-\ntween SOCS PCs is however sufficient to encode any func-\ntion computed by a structured-decomposable circuit.\nTheorem 5. Let c be a structured circuit over X, where\ndom(X) is finite. The (possibly negative) function computed\nby e can be encoded in worst-case time and space O(|c|\u00b3) as\nthe difference c(x) = C1 (x) - C2(x) with C1, C2 \u2208 \u03a3\u00b2_{cmp}\nWe prove it in Appendix B.11. We denote as \u0394\u03a3\u00b2_{2mp} the\nclass of PCs obtained by subtracting two PCs in \u03a3\u00b2_{cmp}. Since\n\u0394\u03a3\u00b2_{2mp} \u2282 \u00b1sd, Theorem 5 implies the expressive efficiency\nequivalence between classes \u0394\u03a3\u00b2_{2mp} and \u00b1sd, in the case of\nfinite variables domain. Our result is similar to a classical re-\nsult in Valiant (1979) but we consider circuits with different\nproperties: they show a (non-decomposable) non-monotonic\ncircuit is computable as the difference of monotonic ones,\nwe focus on structured circuits rewritten as SOCS PCs."}, {"title": "7 Empirical Evaluation", "content": "We evaluate structured monotonic (+sd), squared PCs (\u00b1,\n\u00b1\u00b2), their sums and \u03bcSOCS as the product of a monotonic\nand a SOCS PC (+sd\u00b7 \u03a3\u00b2_{cmp}, see Definition 5) on distri-\nbution estimation tasks using both continuous and discrete\nreal-world data. We answer to the following questions: (A)\nhow does a monotonic PC perform with respect to a sin-\ngle squared PC with the same model size? (B) how does in-\ncreasing the number of squares in a SOCS PC influence its\nexpressiveness? (C) how do SOCS PCs perform w.r.t. mono-\ntonic PCs as we scale them on high-dimensional image data?\nExperimental setting. Given a training set D = {x(i)}^{N}_{i=1}\non variables X, we are interested in estimating p(X) from\nD by minimizing the parameters negative log-likelihood on\na batch B \u2282 D, i.e., L = \\frac{1}{|B|}log Z-\\sum_{x\u2208B} log c(x), via gra-\ndient descent. For squared PCs in \u00b1 and \u00b1\u00b2, we can com-\npute Z just once per batch as done in Loconte et al. (2024),\nmaking training particularly efficient. We can use the same\ntrick for sums of \u00b1 and \u00b1\u00b2 PCs by rewriting L as\nL =  \\frac{B}{B}log \\frac{\\frac{1}{Z}  \\sum x \\in Bexp(2 log |c_i(x)|),\nthus requiring materializing the squared PCs |c\u2081|\u00b2, . . ., |cr|\u00b2 only\nto compute Z. It also applies to \u03bcSOCS as the circuit prod-\nuct decomposes into a sum of logs (see Appendix C.3). PCs\nare compared based on the average log-likelihood on unseen\ndata points. Next, we briefly discuss how we build PCs, and\nrefer the reader to Appendix C for more details.\nBuilding tensorized SOCS PCs. Following Mari, Vessio,\nand Vergari (2023), we build tensorized PCs by parameter-\nizing region graphs (Section 2) with sum and product lay-\ners forming a CP decomposition and vectorized input layers\n(Loconte et al. 2024). This construction allows us to govern\nmodel size by selecting how many units are placed in layers.\nWe experiment with two types of region graphs depending\non the data: for tabular data, we follow Loconte et al. (2024)\nand use random binary trees; for images, we use quad trees\n(Mari, Vessio, and Vergari 2023), that recursively split im-\nages into patches (Appendix C.2). Implementing our com-\nplex PCs in pytorch can be easily done by upcasting the\ntensor types and implementing a variant of the log-sum-exp\ntrick defined on complex numbers (Appendix C.4)\n(A) We estimate the distribution of four continuous UCI\ndata sets: Power, Gas, Hepmass, MiniBooNE, using the\nsame preprocessing by Papamakarios, Pavlakou, and Mur-\nray (2017) (see Table C.1). We compare structured mono-\ntonic PCs, and squared PCs with real or complex parameters."}, {"title": "8 Conclusion", "content": "In this paper, we unified \u2013 and separated - several recently\nintroduced tractable model classes built around the squar-\ning operation of circuits. Our precise theoretical character-\nization justifies many claims supported only by empirical\nevidence, e.g., around the use of complex parameters, and\nsystematizes the burgeoning literature of PCs. Our SOCS\ncircuit class delivers not only scalable and accurate ten-\nsorized models (Section 7) but also enables further connec-\ntions with the vast literature on SOS polynomials. Our SOCS\nexpressiveness results can be translated to the literature of\nnon-linear matrix decompositions (Lefebvre, Vandaele, and\nGillis 2024; Awari et al. 2024). As future direction, we plan\nto retrieve a rigorous latent variable interpretation for SOCS\n(Peharz et al. 2016), thus unlocking parameter and struc-\nture learning schemes (Gens and Domingos 2013; Di Mauro\net al. 2017) for non-monotonic PCs, and towards extending\nthem to continuous latent variables (Gala et al. 2024a,b) as\nto increase their expressiveness even more.\nContributions\nLL and AV conceived the initial idea of the paper. LL is re-\nsponsible for all theoretical contributions with the following\nexceptions. SM provided Theorem 2 as an alternative lower\nbound to Theorem B.3 and simplified the proofs of Theo-\nrem 1 and Theorem 4 that were originally proven by LL. LL\ndeveloped the necessary code, run all the experiments, plot-\nted the figures and wrote the paper with the help of AV. AV\nsupervised all the phases of the project and provided feed-\nback. All authors revised the manuscript critically."}]}