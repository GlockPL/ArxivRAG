{"title": "Sum of Squares Circuits*", "authors": ["Lorenzo Loconte", "Stefan Mengel", "Antonio Vergari"], "abstract": "Designing expressive generative models that support exactand efficient inference is a core question in probabilisticML. Probabilistic circuits (PCs) offer a framework where thistractability-vs-expressiveness trade-off can be analyzed the-oretically. Recently, squared PCs encoding subtractive mix-tures via negative parameters have emerged as tractable mod-els that can be exponentially more expressive than monotonicPCs, i.e., PCs with positive parameters only. In this paper,we provide a more precise theoretical characterization of theexpressiveness relationships among these models. First, weprove that squared PCs can be less expressive than monotonicones. Second, we formalize a novel class of PCs sum ofsquares PCs - that can be exponentially more expressive thanboth squared and monotonic PCs. Around sum of squaresPCs, we build an expressiveness hierarchy that allows us toprecisely unify and separate different tractable model classes such as Born Machines and PSD models, and other recentlyintroduced tractable probabilistic models by using complexparameters. Finally, we empirically show the effectiveness ofsum of squares circuits in performing distribution estimation.", "sections": [{"title": "1 Introduction", "content": "We design and learn expressive probabilistic models to compactly represent the complex distribution we assume hasgenerated the data we deal with. At the same time, a keyrequirement to effectively reason about such a distributionis that we can perform inference exactly and efficiently,i.e., tractably. This is especially relevant in safety-critical"}, {"title": "2 From Circuits to Squared PCs", "content": "We denote sets of variables in bold uppercase, e.g., X = {X1,..., Xa} while x \u2208 dom(X) denotes an assignmentfrom the domain dom(X). We use [n] for the set {1, ..., n}.We start by defining circuits and their properties.\nDefinition 1 (Circuit (Vergari et al. 2021)). A circuit c is aparameterized computational graph over X encoding a func-tion c(X) and comprising three kinds of units: input, prod-uct, and sum. Each product or sum unit n receives the out-puts of other units as inputs, denoted as the set in(n). Eachunit n encodes a function en defined as: (i) fn(sc(n)) if n isan input unit having scope sc(n) = {Y}, Y \u2208 X, where fnis a function defined over Y; (ii) \u03a0j\u2208in(n) Cj (sc(j)) if n isa product unit; and (iii) \u2211j\u2208in(n) On,jCj (sc(j)) if n is a sumunit, where each On,j \u2208 R is a parameter of n. The scopeof a non-input unit n is the union of the scopes of its inputs,i.e., sc(n) = Uj\u2208in(n) SC(j).\nW.l.o.g., we assume product units to have at most two in-puts. For a circuit c, this can be enforced with just a quadraticincrease in its size, i.e., the number of edges in it, denoted as|c| (Martens and Medabalimi 2014). A probabilistic circuit(PC) is a circuit c encoding a non-negative function, i.e.,c(x) \u2265 0 for any x, thus encoding a (possibly unnormal-ized) probability distribution p(x) \u03b1 c(x). A PC e supports the tractable marginalization of any variable subset in timeO(|c|) (Choi, Vergari, and Van den Broeck 2020) if (i) itsinput functions fn can be integrated efficiently and (ii) it issmooth and decomposable, as defined next.\nDefinition 2 (Smoothness and decomposability (Darwicheand Marquis 2002)). A circuit is smooth if for every sumunit n, all its input units depend on the same variables, i.e,Vi, j \u2208 in(n) : sc(i) = sc(j). A circuit is decomposable ifthe inputs of every product unit n depend on disjoint sets ofvariables, i.e, Vi, j \u2208 in(n) i \u2260 j : sc(i) \u2229 sc(j) = \u00d8.\nExpressive efficiency also called succinctness, or represen-tational power refers to the ability of a circuit class to en-code a (possibly unnormalized) distribution in a polysizecomputational graph, i.e., whose size grows polynomiallyw.r.t. its input size. This is in contrast with \u201cexpressiveness\u201dintended as universal representation: all PCs with Boolean(resp. Gaussian) inputs can express any Boolean (resp. con-tinuous) distribution arbitrarily well, but in general at thecost of an exponential size. When we say that one class isexponentially more efficient or succinct than another we imply there exist a distribution, also called separating function,that cannot be captured by any polysize circuit belonging tothe second class. E.g., circuits satisfying fewer or different"}, {"title": "3 A Limitation of Squared Circuits", "content": "We show that there is a class of non-negative functions thatcan be efficiently represented by structured-decomposablemonotonic circuits, whose class we denote as +sd, but forwhich any squared PC c\u00b2 has exponential size. As we discussed before in Section 2, we use the property that c\u00b2 isthe output of the product algorithm Multiply, and thereforeis bounded by the size of the possibly negative circuit c: byconstructing an exponential lower bound of the size of c, we therefore obtain a lower bound on c\u00b2. While there could existan alternative algorithm to directly construct a polynomialsize c\u00b2 that encodes our separating function, we conjecturethis is unlikely. The next theorem formalizes our finding.\nTheorem 1. There is a class of non-negative functions Fover d = k(k + 1) variables that can be encoded by a PCin +sd having size O(d). However, the smallest c\u00b2 \u2208 \u00b1computing any F \u2208 F requires |c| to be at least 2\u03a9(\u221ad)."}, {"title": "4 Sum of Compatible Squares Circuits", "content": "Our more expressive class of circuits will take the form ofa sum of squares (SOS), a well-known concept in algebraicgeometry where it is used to characterize some non-negativepolynomials (Benoist 2017). As such, we derive a specialSOS polynomial family that supports tractable inference, ascircuits can also be understood as compact representationsof polynomials whose indeterminates are the circuit inputfunctions (Martens and Medabalimi 2014). As we are inter-ested in precisely tracing the boundaries of expressive effi-ciency for circuits, we will require that our SOS forms al-ways have polynomial size. This is in contrast with univer-sality results for SOS and non-negative polynomials, wherethe interest is to prove that a non-negative polynomial canor cannot be written as a SOS, regardless of the model size.E.g., see the Hilbert's 17th problem and Marshall (2008) fora review. To preserve tractable inference, in our class of sumof squares circuits, we do not only require each circuit to bestructured-decomposable as to efficiently square it, but alsocompatible with all the others.\nDefinition 4 (). A sum of compatible squares (SOCS) PCc over variables X is a PC encoding c(x) = \u2211ri=1 c2i(x)where, for all i, j \u2208 [r], c2i, c2j \u2208 \u00b1sd are compatible.\nWe denote this class of SOCS circuits as \u03a32mp. Combin-ing many (squared) PCs in a positive sum is equivalent tobuilding a finite mixture (McLachlan, Lee, and Rathnayake2019) having (squared) PCs as components. Although thislooks like a simple way to increase their expressiveness, wenow show that that the advantage is in fact exponential.\nTheorem 2. There is a class of non-negative functions Fover d variables that can be represented by a PC in \u03a32mp ofsize O(d\u00b3). However, (i) the smallest PC in +sd computingany F \u2208 F has at least size 2\u03a9(\u221ad), and (ii) the smallestc\u00b2 \u2208 \u00b1 computing F obtained by squaring a structured-decomposable circuit c, requires |c| to be at least 2\u03a9(\u221ad).\nIn fact, we prove two alternative exponential separationsbetween \u03a32mp and both +sd and \u00b1 circuit classes, repre-sented in Eqs. (4) and (5). Each combines a monotonic PCfrom +sd and a squared one from \u00b1 and thus provides a dif-ferent insight on how to build more expressive circuits. Ourproof of Theorem 2 uses our first separating function fam-ily F, built as a sum of UDISJ (Eq. (1)) and SUM (Eq. (3))embedded on a graph, and defined as UPS(X) =\n\u22111V(1-\u03a3X Xu)\u00b2 +22X 2d-1 X (4)\nwhere X = X'UX\"\u222a{Z1, Z2} are Boolean variables, withX' = {Xv | v \u2208 V}, X\" = Uv\u2208v{Xv,j | j \u2208 [|V|]},and Z1, Z2 are auxiliary variables. By properly setting Z1 =1, Z2 = 0 (resp. Z1 = 0, Z2 = 1) we retrieve a PC in \u00b1(resp. +sd). See Appendix B.3 for the proof details."}, {"title": "5 SOCS circuits Unify many Model Classes", "content": "We now extend the theoretical results presented so far toseveral other tractable model classes that can be reduced toSOCS. We start by models with complex parameters.\nComplex squared PCs. Complex parameters have beenextensively used in ML models. First, for their semantics asmodeling waves, as known in physics and signal process-ing (Hirose and Yoshida 2012; Tygert et al. 2015), E.g.,we already mentioned in Section 2 that MPSs and BMs aregenerally defined as encoding a factorization over the com-plexes. Thus, a BM from quantum physics models themodulus squared |\u03c8(x)|2 = \u03c8(x)\u2020\u03c8(x), where (\u00b7)\u2020 denotesthe complex conjugate operation of a complex function \u03c8,here factorized as a complex MPS. The tensors A1,..., Adshown in Eq. (2) are generalized to have complex-valuedentries (Or\u00fas 2013). Complex BMs have been used for dis-tribution estimation (Han et al. 2018; Cheng et al. 2019).\nSecondly, there is empirical evidence supporting the useof complex parameters to stabilize learning (Arjovsky, Shah,and Bengio 2015) and greatly boost the performance of MLmodels, PCs included (Trouillon et al. 2016; Sun et al. 2019;Loconte et al. 2023). Within the framework of PCs, one canback up this evidence with a precise theoretical characteri-zation and answer the question: is there any expressive ad-vantage in modeling PCs in the field of complex numbers?\nTo do so, we extend PCs in \u00b1 and formally define a com-plex squared PC as the one computing c\u00b2(x) = c(x)\u2020c(x),i.e., via the modulus square of a structured-decomposablecomplex circuit c whose parameters and input functions arecomplex. Computing c\u2020, the complex conjugate of c, canbe done efficiently in O(|c|\u00b2) via Multiply(c\u2020, c) that pre-serves the structural properties we need: smoothness andstructured-decomposability as proven in Yu, Trapp, and Ker-sting (2023). We denote with 2the class of complexsquared PCs computing c\u00b2 via Multiply in this way.\nThen, we show in Appendix B.5 that, similarly to the re-duction of real BMs to squared PCs (Loconte et al. 2024),complex BMs can be reduced to complex squared PCs, thuss size of A such that A(x) = 1-2.21 B = x)dx as per\naking them at least as expressive as their real counterpart.More crucially, we prove that any complex squared PC canbe efficiently reduced to a PC in \u03a32mp with real parametersonly. This settles the question whether complex parametersbring an expressive advantage over reals through the lens ofour Theorem 2. We formalize this result below.\nCorollary 1. Let c\u00b2 \u2208 \u00b1\u00b2 be a PC over variables X, wherec is a structured-decomposable circuit computing a complexfunction. Then, we can efficiently represent c\u00b2 as the sum oftwo compatible PCs in \u00b12, thus as a PC in \u03a32mp\nThis result can be generalized to squared PCs comput-ing the modulus square of circuits that output hypercom-plex numbers, e.g., quaternions, octonions and their gener-alizations (Shenitzer, Kantor, and Solodovnikov 1989). Hy-percomplex numbers have not only been studied in physics(Baez 2001), but also in ML to parameterize deep learningmodels (Saoud and Al-Marzouqi 2020; Yu et al. 2022). Allthese squared circuits are also SOCS.\n= =Given a structured-decomposable circuit c over X comput-ng c(x) \u2208 Aw, we can efficiently represent a PC computingc\u00b2(x) = c(x)\u2020c(x) as a PC in \u03a32mp having size O(2w|c|\u00b2).\nSquared neural families (SNEFYs) (Tsuchida, Ong, andSejdinovic 2023, 2024) are recent neural estimators thatgeneralize exponential families by replacing exponentiationwith a squared norm to model a distribution p(X) as:\nSNEFY\u2081,(x) = Z\u00af\u00b9\u00b5(x) ||NN (t(x))||2\nwhere \u03bc is the base measure, t : dom(X) \u2192 Rd the suf-ficient statistics, NN is a 1-layer neural network with element-wise activation function \u03c3 and Z the partition func-tion. Depending on the choice of t, \u03c3 and \u03bc, SNEFYt,\u03c3,\u03bcallows tractable marginalization (Tsuchida, Ong, and Sejdinovic 2023). Next, we show that many common parameter-izations of these tractable SNEFYs fall within \u03a32mp\nProposition 1. Let SNEFYt,\u03c3,\u03bc be a distribution over d vari-ables X with \u03c3 \u2208 {exp, cos}, \u03bc(x) = \u03bc1(x1)\u2026\u03bc\u03b1(xa),t(x) = [t1(x1),..., ta(xa)]. Then, SNEFYt,\u03c3,\u03bc can be en-coded by a PC in \u03a32mp of size O(poly(d, K)), where Kdenotes the number of neural units in NN.\nWe prove it in Appendix B.7. Note that the product of afactorized base measure \u03bc(x) = \u03bc1(x1)\u2026\u2026\u03bc\u03b1(xd) by thesquared norm of a neural network (as in Proposition 1) canbe written as the product between a fully factorized mono-tonic PC computing \u03bc(x) and a SOCS PC. This is a specialcase of our \u00b5SOCS construction (Definition 5).\nPositive semi-definite (PSD) kernels (Marteau-Ferey,Bach, and Rudi 2020) are non-parametric estimators mod-eling p(x) \u03b1 \u03ba(x)T A \u03ba(x), where A \u2208 Rr\u00d7r is a PSDmatrix, and \u03ba(x) = [\u03ba(x, x(1)), ..., \u03ba(x, x(2))]T \u2208 Rr is akernel defined over data points {x(z)}}=1. For some choicesof \u03ba (e.g., an RBF kernel as in Rudi and Ciliberto (2021)),PSD kernel models support tractable marginalization.\nSince PSD kernel models are shallow, Sladek, Trapp, andSolin (2023) have recently proposed to combine them withdeep monotonic PCs. They do so by parameterizing a sumunit n in a circuit to compute cn(x) = c(x)T A c(x), whereA is a PSD matrix and c is a multi-output circuit comput-ing an r-dimensional vector c(x) = [c1(x),..., cr(x)]T,with {c}}=1 being a set of non-monotonic circuits that arecompatible with each other (Definition 3). From now on, wedenote with psd the class of PCs computing c(x)TAc(x).Next, we show that PCs in psd are equivalently expressive"}, {"title": "6 Are All Structured PCs SOCS Circuits?", "content": "Given the increased expressiveness of SOCS PCs as dis-cussed so far, a natural question now is whether they can effi-ciently encode any distribution computed by other tractablePC classes. Clearly, we need to restrict our attention tost-decomposable circuits, as this structural propertyis required for efficient squaring. This rules out from ouranalysis circuits that are just decomposable or those thatencode multilinear polynomials but are not decomposable.(Agarwal and Bl\u00e4ser 2024; Oliver Broadrick 2024).\nWe start by focusing on PCs in +sd, and show an upperbound on the size of SOCS PCs computing them.\nProposition 3. Every function computed by a PC in +sdover d Boolean variables can be encoded by a PC in \u03a32mp ofsize O(2d).\nOur proof in Appendix B.9 rewrites the circuit as a shal-low polynomial and exploits idempotency of Boolean vari-ables w.r.t. powers. This is not surprising, as every non-negative Boolean polynomial is known to be a SOS poly-nomial (Barak and Steurer 2016). However, it is unknown ifthere exists a sub-exponential size upper bound for a SOCSP"}]}