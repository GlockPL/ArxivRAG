{"title": "K-COMP: Retrieval-Augmented Medical Domain Question Answering With Knowledge-Injected Compressor", "authors": ["Jeonghun Cho", "Gary Geunbae Lee"], "abstract": "Retrieval-augmented question answering (QA) integrates external information, and thereby increases the QA accuracy of reader models that lack domain knowledge. However, documents retrieved for closed domains require high expertise, so the reader model may have difficulty fully comprehending the text. Moreover, the retrieved documents contain thousands of tokens, some unrelated to the question. As a result, the documents include some inaccurate information, which could lead to the reader model to mistrust the passages and could result in hallucinations. To solve these problems, we propose K-COMP (Knowledge-injected COMPressor) which provides the knowledge required to answer correctly. The compressor automatically generates the requisite prior knowledge to facilitate the answering process prior to the compression of retrieved passages. Subsequently, the passages are compressed autoregressively, with the generated knowledge being integrated into the compression process. This process ensures alignment between the question intent and the compressed context. By augmenting this prior knowledge and concise context, the reader models are guided toward relevant answers and trust the context.", "sections": [{"title": "1 Introduction", "content": "Retrieval-augmented question answering (QA) is a task where passages related to a question are appended to the prompt such that a reader model can reference them and the infer correct answer (Ahmad et al., 2019; Guo et al., 2021). However, several limitations impede retrieval-augmented approaches in closed domains with large language models (LLMs) as readers. First, the documents retrieved for closed domains require domain expertise, so the reader may not trust the whole text. When faced with unfamiliar input, the model exhibits an availability bias towards commonly known knowledge, making it more willing to believe in information they can easily recall (Jin et al., 2024). Also, retrieved passages contain thousands of tokens and are sometimes unrelated to the question, which can cause the language model to distrust the passages, perceive them as irrelevant noise, and generate answers that do not consider them. These problems lead to hallucinations (Ji et al., 2023a), which result in the model generating inaccurate answers or inferring plausible but false responses. Lastly, LLMs are sensitive to the order of retrieved documents and the prompting method. Specifically, LLMs can have difficulty finding the necessary information within lengthy input prompts, especially when key information or correct answer clues are located in the middle of the prompt (Liu et al., 2024; Xu et al., 2024b).\nTo tackle these issues, we propose K-COMP (knowledge-injected compressor). We aim to use an autoregressive LLM as a compressor with the domain knowledge needed to answer the question, and increase the alignment of the retrieved passages with the question intent. Additionally, when the compressor is trained domain-related terms and information, it becomes able to recognize the entities that occur in the question and provide descriptions for them. This process is significant for closed domains that require substantial prior knowledge. For retrieval augmentation, we use a large amount"}, {"title": "2 Related Work", "content": "Text Infilling. Models such as BERT (Devlin et al., 2019), SpanBERT (Joshi et al., 2020), T5 (Raffel et al., 2020), and BART (Lewis et al., 2020), are pre-trained using masked language modeling within a bidirectional encoder architecture. They have shown strong performance in infilling short and contiguous masked token spans. However, the bidirectional attention mechanism typically restricts the fillable span length to dimensions significantly shorter than a sentence.\nIn contrast, decoder-only models such as GLM (Du et al., 2022), CM3 (Aghajanyan et al., 2022), and InCoder (Fried et al., 2023) operate by left-to-right generation. They can accommodate variable infill span lengths. Causal masking (Aghajanyan et al., 2022) or fill-in-the-middle (Bavarian et al., 2022) methods predict masked spans from the posterior context. These methods have their generative capabilities, which increase the length of infill spans. They can also exploit the advantages of considering contextual relationships that surround the masked span. The proposed method has the capability to fill the span by considering bidirectional context, as well as align the generated summary with the question by regressively encoding the infilled span.\nPrompt Compression. Several studies have demonstrated that prompt augmentations effectively enhance the performance of LLMs across various tasks (Liu et al., 2023a; Ram et al., 2023; Ryu et al., 2023; Wang et al., 2024c; Long et al., 2023; Yagnik et al., 2024). Yet, the relevance and reliability of the augmented passages are significant challenges in prompt augmentations. In order to address this issue, recent studies have attempted to directly extract content from ambiguous and lengthy passages. Kim et al. (2024) eliminates irrelevant information while maximizing the extraction of accurate information, whereas Yang et al. (2023) leverages the black-box LLMs by applying a reward-based method during compressor training to generate summaries. RECOMP (Xu et al., 2024a) selects and augments the summary with the highest end-task performance by using prompts in which non-essential summaries are set to empty strings if necessary. LLMLingua (Jiang et al., 2023a) dynamically assigns different compression rates to various components within the prompt. In contrast, K-COMP focuses on the keywords needed to answer the question, emphasizing the alignment between the compressed context and the question."}, {"title": "3 Causal Knowledge Injection", "content": "Causal models trained using autoregressive language modeling rely exclusively on the context to the left of the generated tokens to predict subsequent tokens (Brown et al., 2020). This attribute confers an advantage in causally generating entire documents, such as text generation. However, these models show limited proficiency in tasks that require an understanding of post-positional relationships for span infilling. Conversely, masked language models excel at predicting masked spans by referencing attention scores from tokens located both anteriorly and posteriorly. Nonetheless, their training objective is limited to decoding only short"}, {"title": "4 Methods", "content": "In this section, we report our proposed approach for knowledge-injected compression and retrieval augmentation. To retrieve passages similar to a question, we construct a retrieval pipeline composed of a large corpus (\u00a74.1). Next, we explain the data processing steps for training (\u00a74.2). Finally, we detail the training scheme for K-COMP with the proposed objective and explain the inference phase for retrieval augmentation (\u00a74.3). Figure 1 shows an overview of the prompts that K-COMP consists of."}, {"title": "4.1 Retrieval Framework", "content": "Closed domain tasks have not been as thoroughly explored as open domain tasks, which have achieved notable performance enhancements using Wikipedia as a retrieval corpus (Karpukhin et al., 2020). In contrast to open domains, the challenge in closed domains is that unified corpora have not been established. Research endeavors, such as Xiong et al., 2024; Wang et al., 2024b, are currently underway to address this gap. To ensure coverage of both general and domain knowledge, we adopt the MedCorp corpus (Xiong et al., 2024) as our retrieval corpus. It combines Wikipedia, PubMed, StatPearls, and textbooks (Jin et al., 2021). As our retriever, we employ embedding-based k-NN search (Johnson et al., 2019) to mitigate bottlenecks and efficiently execute similarity searches on our large-scale corpus comprising four distinct text corpora."}, {"title": "4.2 Ground-Truth Data", "content": "Entity-Description. We rely on off-the-shelf tools to perform named-entity recognition, which identifies biomedical entities  $E = {e_i}$ in each\nquestion for masking. Retrieval corpus C is constituted of title and text pairs, with the first sentence of each text assumed to be a short description of the title (Xu et al., 2023). Subsequently, the pairs of titles and short descriptions are matched with the entities and their corresponding knowledge $d_i$. We assume that the questions in the training dataset contain at least one entity. In the absence of an entity in a given question, the data are excluded. Similarly, instances lacking a corresponding title in the retrieval corpus are also filtered out of the training dataset (Table 15).\nHowever, in the test data, K-COMP unveils a novel contribution by automatically generating domain-specific entity descriptions during inference even when no annotate exists for the entity in question. This obviates the need for costly and unnecessary tasks, such as searching for medical terms or finding definitions within the corpus.\nSummary. To synthesize gold summaries S, GPT-40-mini compresses the passages by considering {P, E} input pairs, and the number of passages used for synthesis is set to five, i.e., |P| = 5. Notably, we explicitly prohibit the inclusion of the question in the summary synthesis process. This is because incorporating the question into the input prompt for generating the summary may result in a focus shift from the generation of keyword-focused summaries to the formulation of a summary that is aimed at answering the question. Detailed instructions for the summary synthesis are provided in Table 8."}, {"title": "4.3 K-COMP", "content": "Preliminary. $q = [q_1, q_2, ..., q_N]$, where $q_N$ represents the N-th token in q. We use the special token <ent> to mask each medical entity spans within q, $q_m = [q^1, ..., <ent>, q^{N-1}]$. Also, a special <eod> token is appended at the end of the description of the corresponding entity, $d_i = [d^1,..., d^k, <eod>]$. An example is provided as follows:\n$q_m$ = What are the <ent> of <ent>?\n$d_1$ = symptom: {{description}}<eod>\n$d_2$ = Down syndrome: {{description}}<eod>\nBy concatenating $q_m$ and P in the correct sequence, the masked spans can be predicted based on the preceding and subsequent context. We"}, {"title": "5 Experiments", "content": "In this section, we evaluate K-COMP trained by causal knowledge injection and the retrieval-augmented QA task. We report the datasets and settings used in the experiments (\u00a75.1) and discuss the main results (\u00a75.2)."}, {"title": "5.1 Settings", "content": "Models. We fine-tuned Gemma-2B (Team et al., 2024) with our knowledge injection objective. Further details regarding the models and implementation can be found in Appendix A.\nDatasets. To reduce potential biases from fine-tuned medical LLMs (Han et al., 2023; Chen et al., 2023), we conduct experiments using the medical QA datasets MedQuAD (Ben Abacha and Demner-Fushman, 2019), MASH-QA (Zhu et al., 2020), and BioASQ (Krithara et al., 2023), which were not directly used for training biomedical models. Although MASH-QA and BioASQ provide gold passages containing answers, our experiments do not utilize these gold passages. Instead, we rely on passages retrieved by our retrieval framework.\nEvaluation Metrics. Since all datasets consist of long-form answers, we use the trained model to evaluate answers. We quantify the relevance of answers by using BertScore (Zhang* et al., 2020), which evaluates the similarity between two sentences by exploiting the contextual embeddings of the encoder. We also use UniEval (Zhong et al., 2022), which is a multi-dimensional evaluation metric that has high correlation and similarity with human judgment. We explicitly assess the factual consistency between generated and gold answers."}, {"title": "5.2 Results", "content": "Baselines. We compare K-COMP with standard RAG approach with top-1 and top-5 retrieved passages without applying prompt compression. We also compare with previous state-of-the-art prompt compression methods, including RECOMP (Xu et al., 2024a) and LLMLingua (Jiang et al., 2023a). Specifically, for implementing RECOMP, we use an abstractive compressor fine-tuned on our datasets, and for LLMLingua, we use Llama-2-7B (Touvron et al., 2023) for compression. The prompts for synthesizing the summaries used in RECOMP are based on the paper and can be found in Table 9. Furthermore, the efficacy of causal knowledge injection is evaluated by comparing it"}, {"title": "6 Analyses", "content": "We analyze the results from various perspectives (\u00a76.1, 6.2, 6.3). Finally, we appraise the outcomes focusing on the GPT-40 evaluation to highlight the advantages of K-COMP through comparison with previous studies (\u00a76.4)."}, {"title": "6.1 Reranking Preference", "content": "In addition to evaluating the end-task performance, it is crucial in RAG to ensure that prompts are augmented to be pertinent to the question. Although human evaluation is valuable, it demands significant resources and domain expertise, which are not readily available in our case. Instead, we propose to employ a state-of-the-art reranker to measure the relevance between the context and the question. For each question q, we execute K-COMP to generate 10 contexts using a high temperature setting (temperature=1) based on $q_m \\oplus P$. Next, we retrieve the top-10 passages related to q. Thus, we gather a total of 20 passages to be fed to the reranker. By applying Recall@K to these 20 passages, we observe the K passages that are most similar to q, and quantify the proportion of the compressor varied as K varied.\nFigure 2 illustrates Recall@K across different values of K. Specifically, we achieved Recall@1 scores of 77%, 73%, and 83% on MedQuAD, MASH-QA, and BioASQ, whereas the top-5 re-"}, {"title": "6.2 Inference Speed", "content": "In Table 3, we report the inference time and the number of tokens used in the prompt input as metrics for evaluating efficiency. Specifically, we employed Llama-3-70B as the reader model and measured the GPU runtime on MASH-QA test set. Both the compressor and reader are executed on a single NVIDIA A100 GPU with 80GB memory. Even when considering the time needed for the compressor inference, our method was able to double the throughput compared to prepending the top-5 passages, making it more efficient. Moreover, we note that inference speed is dependent on the implementation and size of the reader model. For instance, models with more parameters will suffer increased latency by increasing the number of input tokens. This phenomenon amplifies the speed advantage of K-COMP."}, {"title": "6.3 Case Study", "content": "Here, we report how K-COMP generates medical knowledge. In Table 4, K-COMP is able to address the practical utilization of X-rays in the diagnosis and monitoring of RA, and provides detailed"}, {"title": "6.4 GPT-4o Evaluation", "content": "We additionally explore the reliability of the context. Given that GPT-4 has been demonstrated to correlate highly with human judgments (Liu et al., 2023b), even in the medical domain (Nori et al., 2023), we employed GPT-4o to perform a comparative evaluation of summaries generated by baselines and K-COMP. All prompts utilized in the evaluation were structured using the identical format as presented in Table 12. Finally, we report examples of results for all baselines in Table 18 for qualitative analysis.\nQuery-Agnostic. Figure 3 compares our approach to previous studies that compress prompts"}, {"title": "7 Conclusion", "content": "In this paper, we have proposed a novel method to improve retrieval augmented QA by compressing retrieved documents focused on the questions. We have devised a comprehensive scheme for identifying medical entities and automatically generating prior knowledge. This is followed by the extension of training and inference methods, which enable the autoregressive generation of summaries that incorporate domain knowledge while considering the context causally. Furthermore, we proved that this approach is practical even when applied to unseen evaluation, which represents a novel contribution in closed domains where data is scarce."}, {"title": "Limitations", "content": "Our methodology is limited in scenarios where the NER tool is unable to automatically detect ambiguous keywords or entities that are absent from the questions. To mitigate these issues, expanding the retrieval corpus with additional text chunks can inject more knowledge into the compressor and learn domain-relevant entities, but this will drastically increase the cost of annotating the data and require enormous resources for retrieval to perform nearest-neighbor searches. Therefore, we consider extending these retrieval datastores an important task in RAG, and this can be extended in future work.\nAdditionally, our study mainly focuses on English biomedical QA, which limits generalization to other languages and domains. Current studies in closed domains face challenges due to the scarcity of datasets, posing a considerable obstacle to the broader implementation of our methodology. We believe that, among closed domains, the medical QA has relatively more data, and we have proven our methodology in this domain. However, in other specific domains, not only QA data but also retrieval corpora are yet to be established. Furthermore, data availability in languages other than English is even more limited. Nevertheless, we recognize that our methodology has significant potential for extension to other languages and domains and that such expansion is necessary to demonstrate the generalizability of our training approach. Accordingly, we regard the application of retrieval-augmented QA in closed domains as a critical area of investigation, so we intend to extend our research to encompass additional domains in the future."}, {"title": "Ethical Considerations", "content": "In our research, we employed publicly available datasets, including MedQuAD, MASH-"}, {"title": "A Experimental Details", "content": "A.1 Model Details\nTo demonstrate that our contribution works universally regardless of reader models, we used a range of large language models (LLMs) (AI@Meta, 2024; Jiang et al., 2024; Han et al., 2023; Chen et al., 2023), including a commercial model (Hurst et al., 2024), with varying parameters and purposes. All open-source models were implemented based on HuggingFace's Transformers (Wolf et al., 2020), and due to hardware constraints, we utilized AWQ (Lin et al., 2024a) models for LLMs with a substantial number of parameters. The specific model details are as follows:\nA.2 Dataset Details\nThe datasets employed in the main experiments are MedQuAD (Ben Abacha and Demner-Fushman, 2019), MASH-QA (Zhu et al., 2020), and BioASQ (Krithara et al., 2023). MedQuAD encompasses a wide range of question types related to biomedicine, such as diseases, drugs, and medical tests. MASH-QA is a dataset from the consumer health domain where answers need to be extracted from multiple, non-consecutive parts of a long document. BioASQ is a biomedical dataset derived from PubMed, designed to support a range of tasks, including question-answering, information retrieval, and summarization. We obtained each dataset from the official websites provided by the papers (e.g., GitHub). In the case of the MedQuAD dataset, since there is no test data available, we randomly split the dataset into train/validation/test sets with an 80/10/10 ratio to conduct our experiments. Additionally, we used the MEDIQA (Ben Abacha et al., 2019) for further comparison with the baseline in GPT-4o evaluation section. MEDIQA comprises three tasks: Natural Language Inference,"}, {"title": "A.3 Implementation Details", "content": "We fine-tuned Gemma-2B (Team et al., 2024) with our knowledge injection objective and also used the FineTune baseline (FineTune) with the same model. Table 16 shows the hyperparameter settings that were used for training and inference. K-COMP and FineTune were trained with the same hyperparameters and selected their optimal checkpoints based on the performance of the development set. We also trained the model via the Transforming Reinforcement Learning (Hu et al., 2024). When training on MASH-QA, we used 4 NVIDIA A100 GPUs with 80GB memory, otherwise we used 2 A100-80GB GPUs. For inference, we conducted experiments on a single A100-80GB GPU with VLLM (Kwon et al., 2023) to accelerate and efficiently perform inference."}, {"title": "B Analysis of Query-Agnostic Section", "content": "Figure 3 compares our approach to previous studies that compress prompts without relying on the query, as illustrated in the top-left panel. GPT-4o-mini is the result of summarizing only passages without questions. We referred to the prompts used when training RECOMP, which can be seen in Table 10. Selective-Context (SC) (Li et al., 2023) is a method for the removal of contexts with low self-information at the token level. SC was compressed with Llama-2-7B (Touvron et al., 2023) as that used for LLMLingua. Both methods compress prompts by considering token-level dependencies, so the resulting sentences are incomplete when decoding. As can be seen in Table 18, LLMLingua generates sequences in which words and symbols are merely listed. At the same time, SC produces fragments due to token-level pruning, which also results in incomplete sentences. Consequently, although embedding-based metrics such as BertScore (Zhang* et al., 2020) or lexical-based metrics like ROUGE (Lin, 2004) may exhibit robust performance, they are limited in qualitative evaluations. Moreover, the methodology of compressing passages without referencing the query is unsuitable for retrieval-augmented QA tasks. Thus, both GPT-4o-mini and K-COMP outperform the aforementioned baselines. In addition, it is expected that K-COMP, by referencing masked questions, provides more relevant and specialized con-"}, {"title": "C Additional baseline", "content": "In Section 5, a comparison of various baselines for RAG methods based on prompt compression is presented. However, prior RAG approaches that do not utilize compression were not implemented. Although the primary focus of our study is not to exhaustively explore non-compression-based methods, we introduce additional state-of-the-art (SOTA) baselines to facilitate a more comprehensive evaluation of the relative performance of K-COMP. Specifically, RAPTOR (Sarthi et al., 2024) has been adopted as a baseline, and experiments have been conducted under several predefined conditions. Firstly, RAPTOR requires a summarizing LLM because it recursively summarizes to construct a tree structure. Therefore, we utilized FineTune model to perform context summarization, thereby eliminating the penalty for training. Secondly, RAPTOR has a limit on corpus size due to constraints in our computational resources required for summarizing clustered chunks of the retrieval corpus. Given the massive scale of the MedCorp (Xiong et al., 2024) corpus, we have replaced it with a corpus consisting of the top 5 documents retrieved by retriever across the entire dataset. It is contended that these experimental conditions do not disadvantage RAPTOR. Rather, we believe that restricting the corpus to the top-5 retrieved documents may offer potential advantages by improving the relevance and quality of the re-"}, {"title": "D Licenses", "content": "MedQuAD, MASH-QA, BioASQ are licensed under the CC-BY-4.0, Apache-2.0, CC-BY-2.5 licenses, respectively. Gemma-2b, Nomic-embed-text-v1.5, Meta-Llama-3, Mixtral-8x7b-v0.1-AWQ, GPT-4o, MedAlpaca-13b, Meditron-70B-AWQ, Bge-reranker-large are licensed under the Gemma, Apache-2.0, Llama 3 Community, Apache-2.0, OpenAI, Creative Commons, Llama 2 Community, and MIT."}, {"title": "E Examples of Used Prompts", "content": "Please extract the content about the entity in fewer than four sentences.\n### Passage\nTherapies in Aicardi-Gouti\u00e8res syndrome.\nAicardi-Gouti\u00e8res syndrome (AGS) is a genetically determined disorder, affecting most particularly the brain and the skin, characterized by the inappropriate induction of a type I interferon-mediated immune response. In most, but not all, cases the condition is severe, with a high associated morbidity and mortality ...(skip)\nTreatments in Aicardi-Gouti\u00e8res syndrome.\nComprehensive reviews of the clinical characteristics and pathogenesis of Aicardi-Gouti\u00e8res syndrome (AGS), particularly its contextualization within a putative type I interferonopathy framework, already exist. However, recent reports of attempts at treatment suggest that an assessment of the field from a therapeutic perspective is warranted at this time ...(skip)\nNovel and emerging treatments for Aicardi-Gouti\u00e8res syndrome.\n Introduction: Aicardi-Gouti\u00e8res syndrome (AGS) is the prototype of the type I interferonopathies, a new heterogeneous group of autoinflammatory disorders in which type I interferon plays a pivotal role. The disease usually manifests itself during infancy, primarily affecting the brain and the skin, and is characterized by cerebrospinal fluid chronic lymphocytosis and raised levels of interferon-alpha and by cardinal neuroradiological features: cerebral calcification, leukoencephalopathy and cerebral atrophy ...(skip)\nAicardi-Gouti\u00e8res syndrome\nAt the moment there are no therapies specifically targeting the underlying cause of AGS. Current treatments address the symptoms, which can be varied both in scope and severity. Many patients benefit from tube-feeding. Drugs can be administered to help with seizures / epilepsy ...(skip)\nAicardi-Gouti\u00e8res syndrome\nTreatment\n### Entity\n[research, clinical trial, Disorder]"}, {"title": "F Extended Case Study", "content": "K-COMP\n### Entity\nx-ray: Form of short-wavelength electromagnetic radiation\nrheumatoid arthritis: Type of autoimmune arthritis\n### Summary\nX-rays are the most common method for assessing the degree of joint destruction in rheumatoid arthritis (RA), revealing osteopenia and joint space narrowing as the disease progresses. They are particularly useful for identifying bony erosions and assessing treatment efficacy. While imaging techniques like MRI and ultrasound are also employed, X-rays remain the most common for evaluating joint damage in RA. Early diagnosis and treatment are crucial to modify the disease's course and reduce complications. Understanding the disease's pathophysiology and imaging findings is essential for effective diagnosis and management.\nLlama-3-8B's Answer\nX-rays diagnose rheumatoid arthritis (RA) by revealing changes in the axial skeleton and joint space. As the disease progresses, early RA may not show significant changes on X-rays, but it can indicate osteopenia and joint space narrowing. Advances in imaging techniques like MRI and ultrasound enhance the ability to detect soft tissue changes and joint damage, which is crucial for accurate diagnosis and treatment management. Overall, X-rays serve as an important tool for evaluating the structural changes associated with RA.\nLlama-3-70B's Answer\nX-rays can reveal joint space narrowing and osteopenia, which are common findings in RA.\nX-rays can show early signs of joint damage in RA, such as bone erosion and synovial inflammation.\nX-rays can detect soft tissue changes and joint damage in RA, which is important for diagnosis and treatment management.\nX-rays can assess the degree of joint destruction in RA, including changes in the axial skeleton and joint space.\nFine Tune\n### Summary\nRheumatoid arthritis (RA) is a chronic systemic disease characterized by inflammation of the synovial tissue, affecting 0.5%-1.0% of the global population, with a higher prevalence in females. Modern diagnostic techniques, including X-rays, MRI, and ultrasound, are crucial for assessing joint damage and evaluating treatment efficacy. Early diagnosis and treatment are essential to modify the disease's course and reduce severe complications. Advances in imaging techniques, particularly MRI, enhance the ability to detect and manage RA more effectively. Understanding the disease's pathophysiology and various imaging findings is essential for accurate diagnosis and tailored treatment strategies. Overall, imaging plays a significant role in the management and monitoring of RA.\nLlama-3-8B's Answer\nX-rays are used to diagnose RA by detecting joint damage and erosion.\nLlama-3-70B's Answer\nX-rays are a valuable tool in the diagnosis of RA, as they can detect joint damage and erosions caused by the disease. In the early stages of RA, X-rays may not show any abnormalities, but as the disease progresses, they can reveal joint space narrowing, erosions, and deformities. X-rays can also help monitor the progression of the disease and assess the effectiveness of treatment. However, X-rays have limitations, as they may not detect early changes in the joints or soft tissue inflammation. Therefore, other imaging modalities, such as MRI and ultrasound, may be necessary to provide a more comprehensive assessment of RA."}]}