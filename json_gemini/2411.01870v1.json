{"title": "Mining and Transferring Feature-Geometry Coherence for Unsupervised Point Cloud Registration", "authors": ["Kezheng Xiong", "Haoen Xiang", "Qingshan Xu", "Chenglu Wen", "Siqi Shen", "Jonathan Li", "Cheng Wang"], "abstract": "Point cloud registration, a fundamental task in 3D vision, has achieved remarkable success with learning-based methods in outdoor environments. Unsupervised outdoor point cloud registration methods have recently emerged to circumvent the need for costly pose annotations. However, they fail to establish reliable optimization objectives for unsupervised training, either relying on overly strong geometric assumptions, or suffering from poor-quality pseudo-labels due to inadequate integration of low-level geometric and high-level contextual information. We have observed that in the feature space, latent new inlier correspondences tend to cluster around respective positive anchors that summarize features of existing inliers. Motivated by this observation, we propose a novel unsupervised registration method termed INTEGER to incorporate high-level contextual information for reliable pseudo-label mining. Specifically, we propose the Feature-Geometry Coherence Mining module to dynamically adapt the teacher for each mini-batch of data during training and discover reliable pseudo-labels by considering both high-level feature representations and low-level geometric cues. Furthermore, we propose Anchor-Based Contrastive Learning to facilitate contrastive learning with anchors for a robust feature space. Lastly, we introduce a Mixed-Density Student to learn density-invariant features, addressing challenges related to density variation and low overlap in the outdoor scenario. Extensive experiments on KITTI and nuScenes datasets demonstrate that our INTEGER achieves competitive performance in terms of accuracy and generalizability. [Code Release]", "sections": [{"title": "1 Introduction", "content": "Point cloud registration is a fundamental task in autonomous driving and robotics. It aims to align two partially overlapping point clouds with a rigid transformation. Learning-based methods have achieved remarkable success in outdoor point cloud registration. PCAM pioneered the integration of low-level geometric and high-level contextual information, inspiring subsequent works. However, these supervised methods suffer from poor generalizability and reliance on costly pose annotations, underscoring the need for unsupervised methods to address these challenges in real-world applications.\nDespite recent progress in unsupervised registration methods, the task remains challenging and underexplored, especially in outdoor scenarios where LiDAR point clouds are large-scale and complexly distributed. Some methods optimize photometric and depth consistency, limiting their applicability to indoor scenarios where RGB-D data and differentiable rendering are feasible. Others learn global alignment and neighborhood consensus, but struggle with low overlap and density variation in outdoor settings. Recent advances resort to pseudo-label-based frameworks, achieving promising results in outdoor scenarios. However, they rely solely on geometric cues to mine and filter pseudo-labels, neglecting the complementarity of high-level contextual information in feature space. Their partiality results in incomplete scene perception, leading to noisy and suboptimal optimization objectives.\nVarious 2D and 3D vision tasks have benefited from integrating both low-level and high-level information. In point cloud registration, as illustrated in Fig. 1 (Left), we observe that potential inliers (outliers) tend to cluster around positive (negative) anchors that summarize the features of existing inliers (outliers) in the feature space, respectively. This suggests that high-level contextual information is adept at discovering inliers from a global perspective of the scene. Meanwhile, low-level geometric cues have proven effective in rejecting outliers. Inspired by this, we propose a novel method, termed INTEGER, which adopts a teacher-student framework to mINe and Transfer fEature-GEometry coheRence for unsupervised point cloud registration.\nSpecifically, our method starts by initializing a teacher with synthetic pairs generated from each point cloud scan, and then transfers to real point cloud pairs with a teacher-student framework. Building upon our observations, we introduce the Feature-Geometry Coherence Mining (FGCM) module for the teacher, which first adapts the teacher to each mini-batch of real data to establish a denoised feature space. Reliable pseudo-labels, including correspondences and anchors, are then generated based on our key observation by iteratively mining potential inliers based on their similarity to anchors and rejecting outliers via spatial compatibility. These robust pseudo-labels mined by FGCM not only accurately include inlier correspondences as shown in Fig. 1 (Right), but also aggregate effective representations of inliers and outliers from the teacher. We refer to this characteristic as feature-geometry coherence. To further enhance robustness and transfer feature-geometry coherence to the student, we propose Anchor-Based Contrastive Learning (ABCont) for contrastive learning with anchors. Meanwhile, we design a succinct and efficient Mixed-Density Student (MDS) for the student to learn density-invariant features using teacher's anchors, overcoming density variation and low overlap in distant scenarios.\nWe extensively evaluate our method on two large-scale outdoor datasets, KITTI and nuScenes. By exploiting feature-geometry coherence for reliable optimization objectives, INTEGER outperforms existing unsupervised methods by a considerable margin. It even performs competitively compared to state-of-the-art supervised methods, especially in distant scenarios. To the best of our knowledge, our approach is the first to integrate both low-level and high-level information for producing pseudo-labels of unsupervised point cloud registration. Overall, our contributions are threefold:"}, {"title": "2 Related Works", "content": "Supervised Registration. There are two categories of supervised registration approaches: Correspondence-based methods first extract point correspondences and then estimate the transformation with robust pose estimators. In contrast, direct registration methods extract global feature vectors and regress the transformation directly with a neural network. Recently, a series of works have tackled distant point cloud registration, which is crucial for real-world applications.\nUnsupervised Registration. Previous researches in unsupervised registration mainly focus on indoor scenes. BYOC suggests that random 2D CNNs generate robust image correspondences for supervising 3D registration networks. Meanwhile, render-based methods leverage differentiable renders as the supervision signal of 3D registration. However, these methods are restricted to RGB-D input. To address this, Mei et al. enforce consistencies between Gaussian Mixture Models for unsupervised training, using only point cloud as input. Shen et al. introduce an inlier evaluation method based on neighborhood consensus. However, its performance drops when the overlap is low. SGP proposes a teacher-student framework for self-supervised learning from hand-crafted feature descriptors. EYOC introduces progressive training and spatial filtering to adapt the model to distant point cloud pairs gradually, demonstrating promising results in outdoor scenarios.\nRobust Pose Estimators. Pose estimators evaluate inliers and estimate poses from input correspondence sets. Traditional methods such as RANSAC suffer from inefficiencies. Learning-based methods learn to predict inliers and poses using neural networks. However, they require training and are thus constrained to supervised settings. To address this, non-parametric methods have emerged. Chen et al. introduced $SC^2$-measurements for robust inlier selection. Graph-based methods such as MAC and FastMAC approximate maximal cliques for fast and accurate inlier evaluation."}, {"title": "3 Methodology", "content": "Problem Formulation. Given two point clouds $P = \\{p_i\\} \\in \\mathbb{R}^{m\\times 3}$ and $Q= \\{q_j\\} \\in \\mathbb{R}^{n\\times 3}$, the goal of point cloud registration is to uncover the rigid transformation $T = \\{R, t\\}$ that perfectly aligns $P$ to $Q$, where $R \\in SO(3)$ is the rotation matrix and $t \\in \\mathbb{R}^{3}$ is the translation vector. When the two point clouds are acquired at a large distance d such as when $d \\in [5m, 50m]$, the registration task faces the challenges of low overlap and density variation. Therefore, it is crucial to learn density-invariant features.\nOverall Pipeline. INTEGER adopts a two-stage training scheme and a teacher-student framework. Training of INTEGER consists of two stages: First, we initialize the teacher with synthetic data. Then, we train a student model on real data with the reliable pseudo-labels mined by the teacher. The overall pipeline and proposed modules are illustrated in Fig. 2. During teacher-student training, FGCM first dynamically adapts the teacher model $\\theta$ to a data-specific teacher $\\varphi$ designated for the current mini-batch, and then mines reliable pseudo-labels with the adapted teacher. Next, the MDS learns density-invariant features by learning to match regular and sparse views of point cloud pairs supervised by pseudo-labels mined by $\\varphi$. A pseudo-label $I = \\{C,\\hat{C}, A^+, A^- \\}$ contains correspondences $C, \\hat{C}$ to supervise dense matches and sparse matches, respectively. The feature-space positive and negative anchors, denoted respectively by $A^+$ and $A_-$, serve as overall representatives of inliers and outliers in the feature space. For a correspondence $(i,j) \\in C = (p_i, q_j) \\in C$, the correspondence features are defined as $F_{(i,j)} = F_p - F_q$. Then, the positive and negative anchors $A_+, A_-$ are computed as the average of the respective features of inliers $C_+$ and outliers $C_-$"}, {"title": "3.1 Synthetic Teacher Initialization", "content": "To initialize a teacher model, Liu et al. assume that two consecutive frames approximately have no relative transformation and pretrain the teacher with the identity transformation. However, the errors introduced in such approximation lead to suboptimal initial teachers. To address this, inspired by existing efforts, we instead pretrain the teacher with synthetic pairs generated from each real scan. Specifically, we follow PointContrast to generate two partially overlap fragments for each scan. We additionally apply periodic sampling to remove points periodically with respect to a random center, simulating the irregular sampling of LiDAR. Please refer to the Appendix for a visualization of synthetic pairs."}, {"title": "3.2 Feature-Geometry Coherence Mining", "content": "With the teacher initialized on synthetic pairs, our goal is to provide reliable supervision for the student. Despite efforts to ensure an effective initialization, a distribution discrepancy persists between synthetic and real data. Hence, we introduce a train-only FGCM. As is depicted in Fig. 2, FGCM starts with Correspondence Seed Proposals for $C^0$ using a simple similarity threshold. Subsequently, Feature-Geometry Clustering extends from $C^0$ by mining additional reliable correspondences and anchors, which serve as effective optimization objectives.\nAs is illustrated in Fig. 3, for each mini-batch, we use FGCM in a two-pass manner. In the first forward pass, we perform Per-Batch Self-Adaption on the teacher model $\\theta$ to establish a denoised feature space, yielding a data-specific teacher $\\varphi$. In the second forward pass, the adapted teacher and FGCM are used to mine reliable pseudo-labels $I$, which are then used to train the student, achieving Teacher-Student Knowledge Transfer."}, {"title": "3.3 Anchor-Based Contrastive Learning", "content": "Contrastive learning has been widely adopted to train registration models. Recently, a surge of research on various tasks involves anchor-based or proxy-based approaches to facilitate contrastive learning due to their robustness against inconsistency and noise in the feature space, superiority in generalizability and ability to learn discriminative features. Therefore, we design ABCont to leverage positive and negative anchors to facilitate effective contrastive learning with the pseudo-labels, where noise and outliers are inevitable.\nAs shown in Fig. 4, with anchor-based representations, ABCont sets up a convergence target that is more robust against label noise. Moreover, it is more efficient because the number of additionally-introduced pairwise relationships is reduced.\nSpecifically, we propose the ABCont loss $L_{ABCont} = L_{reg} + \\lambda_{corr} L_{corr}$, where $L_{corr}$ is the anchor-based correspondence loss, weighted by a hyperparameter $\\lambda_{corr}$ to complement the registration loss $L_{reg}$ originally used by the feature extractors. The student's feature matching results can be classified into inliers $C_+$ and outliers $C_-$ based on the pseudo-labels from the teacher. Then, anchors $\\{A_+, A_-\\}$ from the teacher are designated as a universal inlier and a universal outlier, resulting in augmented inliers and outliers:\n$C^{\\ast} = C_+ \\cup sg(A_+),  C^{\\dagger} = C_- \\cup sg(A_-)$\nwhere $sg(.)$ denotes the stop-gradient operator, preventing gradients from flowing back to the teacher. Following existing efforts, we sample $n_p$ correspondences randomly and formulate $L_{aux}$ as a contrastive learning problem to distinguish inliers from outliers. InfoNCE loss is then applied to these correspondence features:\n$L_{corr} = -\\frac{1}{n_p} \\sum_{i=1}^{n_p} log \\frac{exp(\\beta_i)}{\\sum_{j=1}^{N_p} exp(\\beta_i) + \\sum_{j=1}^{N_{p^{\\prime}}} exp(\\beta_j^{\\prime})}$\nwhere $\\beta_i$ and $\\beta_j^{\\prime}$ are the distance between the $i^{th}$ positive correspondence and the $j^{th}$ negative correspondence, respectively. ABCont is pivotal in transferring feature-geometry coherence from the teacher to the student: the accurate pseudo-labels for correspondences, combined with anchors, enable the student to learn discriminative features efficiently. Anchors from the teacher impose direct constraints on the student's feature space, encouraging the student to replicate the teacher's feature-space matchability. This leads to a more effective transfer of feature-geometry coherence."}, {"title": "3.4 Mixed-Density Student", "content": "The density of LiDAR point clouds varies greatly with the distance to the sensor, posing challenges for matching distance point clouds effectively. To address this, it is crucial for a student model to learn density-invariant features, ensuring robust correspondences across varying point densities. Previous methods have sought density invariance through auxiliary reconstruction tasks or by identifying positive groups, but these techniques are either computationally expensive or depend on precise supervision. Xia et al. introduced a simple yet effective technique for density invariance in object detection by using features from downsampled views. Inspired by this, we propose Mixed-Density Student to learn density-invariant features from reliable correspondences.\nSpecifically, given point clouds $P$ and $Q$, we compute their sparsely-downsampled views $\\bar{P}$ and $\\bar{Q}$ with increased voxel sizes. We then extract student's features $(F_P, F_Q)$ and $(\\bar{F_P}, \\bar{F_Q})$. Using features from point clouds of different density, we compute dense matches and sparse matches through matching respective features. We then apply ABCont to both sets of matches, encouraging the extraction of similar features at corresponding spatial locations across point clouds of varying densities, thereby promoting density-invariant feature learning.\nLoss Aggregation. The student's overall training loss is aggregated as a weighted combination of $L_{ABCont}$ on both dense and sparse matches:\n$L = \\lambda_1 \\cdot L_{ABCont}^{(\\bar{P},\\bar{Q})} + (1 - \\lambda_1) \\cdot L_{ABCont}^{(P,Q)}$\nwhere $\\lambda_1$ is a weight for the sparse match."}, {"title": "4 Experiments", "content": "We mainly evaluate INTEGER on two challenging public datasets: KITTI and nuScenes. Both datasets adhere to official splits. The evaluation protocol follows the standard setting of EYOC. Please refer to the appendix for more details of implementation and experimental settings.\nMetrics Following previous works, we evaluate the registration performance using Relative Rotation Error (RRE), Relative Translation Error (RTE) and Registration Recall (RR). Related to the practical purpose of outdoor registration, we additionally report RR@ $[d_1, d_2)$ and mean Registration Recall(mRR). RR@ $[d_1, d_2)$ is registration recall w.r.t pairs with distance $d \\in [d_1, d_2)$, following . mRR is defined as the average of RR@ $[d_1, d_2)$ for all $[d_1,d_2)$. To measure the quality of correspondences in pseudo-labels, we report Inlier Ratio(IR) of the teacher in the first epoch, denoted \u201ctIR@1st Epoch\u201d.\nBaselines For supervised methods, We compare INTEGER with FCGF, Predator, SpinNet, D3Feat, CoFiNet, and Geometric Transformer(GeoTrans.). For unsupervised methods, we compare with RIENet and EYOC. Following Liu et al., we report a variant of FCGF denoted as FCGF+C, which is FCGF trained with progressive training ."}, {"title": "4.1 Performance Comparison with State-of-the-Art", "content": "Quantitative results are presented in Table 1. Our method outperforms existing unsupervised approaches and achieving state-of-the-art performance across all datasets and demonstrates superior generalizability. Notably, our unsupervised approach maintains competitive performance compared to supervised methods and even surpasses them in distant scenarios, highlighting its potential for real-world application.\nOverall Performance Compared to existing methods, our approach excels in performance. RIENet, an end-to-end unsupervised registration method for outdoor scenes, exhibits suboptimal performance, particularly in low-overlap scenarios and environments with low LiDAR resolution, such as nuScenes. Both EYOC and INTEGER adopt a teacher-student framework for unsupervised training. However, our method demonstrates superior accuracy across all evaluation metrics, overcoming challenges associated with pseudo-label discovery and the absence of feature-space knowledge transfer in EYOC.\nGeneralizability We assess generalizability on nuScenes using weights trained on KITTI. Variations in LiDAR resolutions between nuScenes and KITTI may lead to different point densities, potentially degrading extracted features. Compared to existing unsupervised methods, our approach exhibits superior generalizability to unseen datasets. This superiority can be attributed to INTEGER's design, which learns density-invariant features."}, {"title": "4.2 Analysis", "content": "Different Choices of Pose Estimator in FGCM We contend that the robustness and efficacy of FGCM are not contingent upon a specific pose estimator. To substantiate this claim, we conduct experiments employing various robust pose estimators within FGCM. The results are detailed in Table 2. For different robust pose estimators in FGCM module, we experiment PointDSC, MAC, FastMAC and $SC^2$-PCR. The results demonstrate that the effectiveness of FGCM is agnostic to choices of pose estimators, despite marginal performance discrepancies are observed. Given the iterative nature of FGCM, the efficiency of pose estimators holds paramount importance, as the module's runtime is proportional to pose estimation time. We choose $SC^2$-PCR for FGCM by default due to its superior balance in performance and efficiency.\nEffectiveness of Self-Adaption for Discriminative Features. To further understand the effectiveness of self-adaption in FGCM, we visualize the point-level feature distribution and correspondence-level similarity distribution in Fig. 5 (Please refer to the Appendix for implementation details.). The two representative samples are taken from KITTI dataset. In Fig. 5, the smaller overlap regions of point-level feature distribution between points from inliers and outliers indicate the features of inliers and outliers distribute more distant, and thus, the features are more discriminative. For correspondence-level similarity, inlier similarity should be distinct from outlier similarity to effectively differentiate between the two. With the self-adaption in FGCM, the data-specific teacher produces more discriminative features, resulting in a less noisy feature space conducive to the subsequent feature-based approach employed in FGCM."}, {"title": "4.3 Ablation Study", "content": "We conduct ablation studies to evaluate the efficacy of INTEGER on the KITTI dataset. We present mRR and registration errors in a distant scenario where d\u2208 [40,50). Various alternative configurations of INTEGER are compared in Table 3. Our method exhibits superior performance compared to alternatives, demonstrating the effectiveness of our design. This superiority may be attributed to the features-geometry coherence: With FGCM, correspondences in pseudo-labels possess discriminative features, facilitating effective knowledge transfer in feature space using ABCont. Additionally, MDS significantly enhances performance in distant scenarios. The combination of Per-Batch Self-Adaption and Feature-Geometry Clustering in the FGCM module yields more substantial improvement than using either alone. The removal of Per-Batch Self-Adaption marginally degrades the quality of pseudo-labels, emphasizing the importance of denoising the feature space. When synthetic teacher initialization is removed (w/o S.T.I), we employed the same way as EYOC to pretrain the teacher. We find that synthetic teacher initialization greatly enhances the initial teacher's performance. Please refer to the Appendix for more qualitative results on generated synthetic pairs."}, {"title": "5 Conclusion", "content": "In this paper, we present INTEGER, a novel unsupervised method for point cloud registration that integrates low-level geometric and high-level contextual information for reliable pseudo-labels. Our method introduces Feature-Geometry Coherence Mining for dynamic teacher self-adaption and robust pseudo-label mining based on both feature and geometric spaces. Then, we propose Mixed-Density Student to learn density-invariant features. We also introduce Anchor-Based Contrastive Learning for effective contrastive learning using anchors. Extensive experiments on two large-scale outdoor datasets validate our method's efficacy. Despite being unsupervised, it achieves results comparable to state-of-the-art supervised methods and surpasses existing unsupervised methods, particularly in distant scenarios. Furthermore, our approach exhibits superior generalizability to unseen datasets."}, {"title": "Limitations", "content": "The main limitations of the proposed method are twofold:\n\u2022 Our method is subject to the quality of the teacher. If the teacher is inaccurate, the feature space may become too noisy, potentially impeding Feature-Geometry Clustering in FGCM, especially in distant scenarios. One potential remedy is to devise a more robust strategy for initializing the teacher.\n\u2022 Our method is slightly slower to obtain pseudo-labels compared to existing efforts due to the proposed iterative method used in FGCM of the FGCM module. Future work may involve devising a more efficient strategy for mining pseudo-labels."}]}