{"title": "Real-time Ship Recognition and Georeferencing for the Improvement of Maritime Situational Awareness", "authors": ["Borja Carrillo Perez"], "abstract": "In an era where maritime infrastructures are paramount supports of societies, the need for advanced maritime situational awareness solutions has become increasingly important. Existing ship monitoring procedures, such as the Automatic Identification System (AIS), have limitations, suffer from delayed updates and are vulnerable to cyberattacks. Other technologies, such as satellite imagery and radar, face challenges in real-time applications due to delays in acquiring and processing data. The use of optical camera systems and image processing can improve situational awareness, allowing real-time usage of maritime infrastructure footage. However, the number of video streams available poses a challenge for maritime operators, who could be helped by summarized spatial information of recognized ships, irrespective of their size and type, and presented on a map in real-time. This motivates the development of automated ship recognition and georeferencing technologies. Moreover, the deployment of such camera systems, equipped with an embedded device, allows for local data processing on the edge to minimize network demand, energy usage, decrease latency, cut costs, and enhance data protection.\nThis thesis, integrating six of my publications, presents a comprehensive investigation into leveraging deep learning and computer vision to advance the research in real-time ship recognition and georeferencing for the improvement of maritime situational awareness. I present a novel dataset for ship recognition and georeferencing, ShipSG, which facilitates the development and validation of recognition and georeferencing methodologies. The dataset contains 3505 images and 11625 ship masks with their corresponding class, geographic position and length. Through a series of studies of state-of-the-art deep-learning-based object recognition algorithms, I introduce a custom real-time segmentation architecture, ScatYOLOv8+CBAM. This architecture was created and optimized for the NVIDIA Jetson AGX Xavier as embedded system. ScatYOLOv8+CBAM incorporates the 2D scattering transform, a novel addition that enhances YOLOv8 in real-world applications such as ship segmentation. Additionally, the performance is further improved with the integration of attention mechanisms. The proposed architecture exceeds in more than 5% the performance of state-of-the-art methods, achieving a mean Average Precision (mAP) of 75.46%. The inference speed, once the customized architecture is deployed on the embedded system using TensorRT, is of 25.3 ms per frame. Furthermore, I address the need for precision in recognizing small and distant ships and their real-time processing of full-resolution images on embedded systems, with an enhanced slicing mechanism that performs batch inference and merges predictions, achieving mAP improvements ranging from 8% to 11%. The recognized ships are georeferenced using my proposed method, which automatically calculates the georeferencing pixel of the recognized ships, and uses homographies to provide the geographic position of ships from single images, without prior camera knowledge. In the quantitative analysis, the georeferencing method achieved a positioning error of 18 m \u00b1 10 m for ranges inside the port basin (up to 400 m) and 44 m \u00b1 27 m outside (from 400 m to 1200 m). The main findings reveal significant advancements in maritime situational awareness with the practical demonstration of the applicability of the methodologies in real-world scenarios, such as the detection of abnormal ship behaviour, camera integrity assessment and 3D reconstruction. The approach not only outperforms existing methods in terms of accuracy and processing speed but also provides a framework for seamlessly integrating recognized and georeferenced ships into real-time systems, enhancing operational effectiveness and decision-making for maritime authorities. The integration of these methodologies into embedded systems represents a pivotal advancement in the domain, offering a scalable and efficient solution for improving maritime situational awareness and response capabilities. This thesis contributes to the maritime computer vision field by establishing a benchmark for ship segmentation and georeferencing research, demonstrating the viability of deep-learning-based recognition and georeferencing methods for real-time maritime monitoring.", "sections": [{"title": "Introduction", "content": "Maritime infrastructures are an essential component towards the support of societal needs, economic activities, mobility, and the advancement of renewable energy sources [1]. This highlights the reason why their security, integrity, and operational safety are crucial. In response, maritime research is aiming at developing, testing, and validating systems to thoroughly assess and operate these infrastructures [2]. Such initiatives aim to cultivate a proactive and informed understanding of maritime contexts, essential for accurately determining the protection status of infrastructures in real-time and enabling prompt action against various threats, including major accidents, natural disasters, and organized crime [1]. Maritime situational awareness, facilitated by advanced technologies and data integration, is critical for a proactive and informed understanding of maritime environments [3]. It encompasses real-time monitoring and drives innovative solutions to enhance the security, safety, structural integrity, and operational reliability of infrastructures against various threats [4].\nIn the improvement of maritime situational awareness the introduction of advanced instruments and sensors plays a key role, which should be designed not only to recognize elements of interest but also to suggest practical measures to both users, for operational decisions, and authorities, for regulatory compliance and emergency response [5]. Enhancing maritime situational awareness with technology represents a significant advancement for smart ports, exemplifying the potential for improved maritime operations [6].\nThe International Maritime Organization (IMO) mandates that vessels exceeding 300 gross tonnage are equipped with Automatic Identification System (AIS) transceivers, which broadcast crucial data including identification numbers, type, position, course, and speed through encoded radio messages [7]. This system is pivotal for Vessel Traffic Services (VTS) and nearby vessels, facilitating marine traffic awareness, critical operations such as collision avoidance, and search and rescue missions. AIS transmissions occur at intervals ranging from 2 to 10 seconds when ships are underway, which can be extended by up to 6 minutes when stationary\u00b9. Such intervals may leave gaps in real-time monitoring, highlighting the need for systems capable of analyzing situations with a significantly shorter interval to aid in the prevention and response to potential maritime complications [8]. Furthermore, the open standards employed by the AIS exposes it to various cyber threats, including spoofing, hijacking attacks, and denial of service, underscoring the vulnerability of the system [9-13]. Therefore, despite significant efforts, real-time ship monitoring for improved maritime situational awareness only using AIS continues to pose a challenge for VTS [14].\nOther available sources for the improvement of maritime situational awareness are satellite imagery and radar systems [15]. However, their processing for real-time maritime situational awareness faces challenges due to the time-sensitive nature of data acquisition, periodic satellite overpasses, and processing delays (~15 minutes per data cycle), impacting the immediacy and utility of the information [16]. Moreover, revisit times of satellites can range from hours to days.\nOptical camera systems, on the other hand, due to their accessibility, cost-efficiency, and ease of deployment, are key in rapidly assessing ship traffic, enhancing maritime situational awareness through views of the infrastructure from strategic positions [17]. The vast number of video streams available can present a challenge for operators [18]. The efficiency of real-time recognition is significantly boosted by image processing technologies applied to optical monitoring [17]. This motivates the use of computer vision and deep learning to automatically recognize and locate geographically (georeference) ships on a map, irrespective of their type or size. This process can support the operational decision-making procedures of maritime authorities by providing them with spatial information in a timely manner [19].\nEarly detection of potential threats and the prevention of accidents are significantly enhanced by employing optical cameras when used at full-resolution, ensuring detailed and precise imagery for monitoring purposes [20, 21]. Therefore, a key challenge in maritime monitoring is the recognition of small and distant ships, which is crucial for safety and security at maritime infrastructures, as it helps in early threat detection and accident prevention [20].\nObject georeferencing involves linking physical objects to specific locations on the Earth's surface for spatial integration and analysis, a process that can extend to objects captured within an image [22]. For the improvement of maritime situational awareness, once ships are recognized in real-time from monitoring images, the display of their geographical positions on maps using georeferencing enables a better spatial understanding of the situation [19].\nShip detection methods which use monitoring footage to present a bounding box surrounding the detected ship, can be used to improve maritime situational awareness [23, 24]. However, ship segmentation provides a more accurate georeference for the ships using the segmented masks, as shown in Figure 1.1. The georeferenced pixel can be better inferred from the segmented mask of an object than from a surrounding bounding box, which usually contains unnecessary background. The center and bottom-center of the bounding box, given the perspective of the image, provide a more erroneous georeference compared to the point that lies at the intersection point between the ship hull and the water below the bridge or wheelhouse, where the navigation antenna is located. This rationale motivates the exploration of ship segmentation methods beyond bounding box detection, and paves the way for the development of a method to automatically identify the pixel for georeferencing within this thesis.\nFurthermore, the processing using embedded devices powered with a Graphics Processing Unit (GPU), equipped with monitoring cameras and placed at maritime infrastructures, represents a step forward in maritime situational awareness [25, 26]. These systems can enable on-site deep-learning-based ship recognition, offering significant advantages such as reduced network bandwidth and energy usage, minimized latency, and enhanced security [27]. The local processing of images using embedded systems directly at the infrastructure facilitates the spatial understanding of the maritime situation [28]. Recognized and georeferenced ships using an embedded system can then be seamlessly integrated into web services, allowing their display (e.g. on maps) within the situational awareness system [19]. This enhances real-time visualization and enriches the overall situational awareness by providing operators with accurate and timely spatial information [19].\nReal-time and accurate ship recognition, classification, and georeferencing are essential, not just for improved spatial visualization. Beyond visualization, its combination with other data sources, such as AIS, satellite imagery and radar systems can further enhance the overall situational understanding [19]. Therefore, the faster the image processing occurs, the better it supports the creation of a comprehensive real-time situational picture by fusing with additional maritime data, thereby elevating the operational effectiveness of maritime situational awareness efforts [19].\nWe have seen, that in the context of enhancing maritime situational awareness, optimized real-time processing is paramount. The objective, therefore should be to ensure that the developed ship recognition and georeferencing system operates with the highest possible accuracy and the shortest inference times on embedded systems. This dual focus on speed and accuracy is critical for facilitating the fusion of the developed methodologies with other sensor data and services, thereby enabling safer, more secure, and more efficient maritime operations.\nThis thesis presents a compilation of explorations, methods and results proposed in the publications shown in Chapter 10, which will be referenced throughout the manuscript from [BCP-I] to [BCP-VI]. The goals and contributions of this thesis, achieved within these publications, are summarized as follows:\n\u2022 Production of a real-world maritime dataset for ship recognition and georeferencing, advancing the research field of maritime situational awareness.\nContribution: Creation and publication of the ShipSG dataset, which provides a comprehensive set of annotated images for ship recognition and georeferencing [BCP-II].\n\u2022 Investigation and development of a ship recognition architecture that seeks for enhanced real-time ship recognition, able to run in real-time embedded systems.\nContribution: In-depth study of state-of-the-art methods for ship recognition, using ShipSG and other datasets [BCP-I][BCP-II][BCP-III][BCP-IV].\nContribution: Introduced ScatYOLOv8+CBAM, an innovative ship recognition architecture optimized for real-time processing on embedded systems [BCP-V].\n\u2022 Proposal of an efficient solution for processing full-resolution images on embedded systems, allowing the recognition of small and distant ships.\nContribution: Introduced an improved slicing method that enables the processing of full-resolution images for the recognition of small and distant ships on embedded systems [BCP-VI].\n\u2022 Innovation in the field of ship georeferencing using monocular images by developing a methodology that does not rely on prior camera knowledge.\nContribution: Developed a novel ship georeferencing methodology using homographies that operates without requiring prior camera calibration [BCP-I][BCP-II][BCP-V].\n\u2022 Optimization of real-time ship recognition and georeferencing methodologies for their deployment on embedded systems, balancing performance with computational efficiency.\nContribution: Further improvement of the ScatYOLOv8+CBAM architecture for efficient deployment on embedded systems, balancing computational efficiency with high performance [BCP-VI].\n\u2022 Demonstration of the practical application of the methodologies by integrating them into systems for improved maritime situational awareness in a variety of applications.\nContribution: Successfully integrated the developed methodologies into applications such as ship georeferencing displays including map-based visualization, abnormal ship behavior detection, camera integrity assessment, and 3D ship reconstruction, showcasing their effectiveness in enhancing maritime situational awareness [BCP-I][BCP-II][BCP-III][BCP-IV][BCP-V].\nThe remaining chapters of this thesis are organized as follows:\nChapter 2 Fundamentals of Modern Object Recognition\nThis chapter dives into the technical background of modern object recognition, introducing key concepts. It explores how deep learning has transformed computer vision for object recognition and how it can be leveraged.\nChapter 3 Relevant State of the Art\nThis chapter focuses on relevant state-of-the-art, highlighting areas in ship recognition and georeferencing where current research falls short. The chapter presents maritime datasets and object recognition methods essential for this thesis as well as potential improvements, prior ship georeferencing research and deployment on embedded systems.\nChapter 4 ShipSG: Ship Segmentation and Georeferencing Dataset\nThis chapter presents the creation of ShipSG2, a novel dataset for ship recognition and georeferencing. ShipSG provides the foundation for this thesis, enabling the development and evaluation of the methods presented in the subsequent chapters.\nChapter 5 Ship Recognition for Improved Maritime Awareness\nThis chapter shows the initial exploration of deep-learning-based methods for ship detection and segmentation, revealing their potential applications, such as ship georeferencing, abnormal ship behavior detection, camera integrity assessment, and 3D ship reconstruction. The study of state-of-the-art instance segmentation methods sets the stage for the custom developments and analysis proposed in subsequent chapters.\nChapter 6 Advanced Ship Recognition for Real-time Operation\nThis chapter addresses the need for fast and accurate algorithms on embedded systems for real-world use. While ship detection was proven to perform well, deploying instance segmentation (better for ship georeferencing) on embedded systems was shown to be a significant challenge. This chapter addresses this gap by proposing a customized real-time segmentation method (ScatYOLOv8+CBAM), deployed on an embedded system. It also proposes a method to improve the segmentation accuracy for small and distant ships by processing full-resolution images, crucial for better maritime situational awareness."}, {"title": "Fundamentals of Modern Object Recognition", "content": "As motivated in Chapter 1, the combination of computer vision and deep learning offers a potent solution for automatic ship recognition using optical monitoring cameras. This chapter provides a technical overview of concepts to understand modern object recognition, starting with the role of supervised learning in computer vision, and followed by the use of deep learning for the two computer vision tasks of interest in this thesis, object detection and instance segmentation.\nComputer vision is a discipline within Artificial Intelligence (AI) that allows machines to process and interpret visual data. By harnessing algorithms and data, computer vision systems can identify and classify objects, and make decisions based on visual inputs similar to the way humans do [29]. The field of computer vision has significantly advanced with deep learning, a subfield of machine learning, particularly through the use of Convolutional Neural Networks (CNNs) [29]. Preceding computer vision approaches relied on hand-engineered feature extraction. Deep learning, on the other hand, utilizes vast amounts of visual data to train hierarchical structures of neurons that excel at identifying patterns to therefore perform automatic feature extraction [30]. Thanks to the use of GPUs, deep learning with CNNs have significantly surpassed the performance of traditional algorithms in tasks like image classification, object detection, and instance and semantic segmentation [31]. The computational power of GPUs, due to the parallel processing capabilities, enabled the training of deep networks with millions of parameters, allowing for the extraction of complex features from large datasets.\nMachine learning algorithms are commonly categorized into supervised learning, which requires labeled data for training, unsupervised learning, which operates on unlabeled data to find patterns, and semi-supervised learning, which uses a combination of labeled and unlabeled data to train models [32]. In certain real-world applications, supervised learning is preferred for training models with real-world annotated datasets, ensuring accurate identification and categorization of objects represented in the data [33].\nIn supervised learning, models are trained on datasets labeled by human experts [34]. During training, the supervised model adjusts its parameters by measuring the deviation from the actual labels [32]. Therefore, the annotation process involves pairing each training sample with its corresponding output labels, serving as a learning guide for the model. In computer vision tasks, such as image classification, labeled training images are used to predict classes on validation images [35]. In object detection tasks, the annotations and training extends for the classification and localization of objects in the image within bounding boxes. Segmentation tasks demand detailed annotations, labeling each pixel by class [36].\nIn summary, supervised learning has greatly advanced computer vision tasks, while also highlighting the continuous need for models that can learn effectively from annotated data.\nObject recognition in computer vision involves identifying and classifying objects in images [29]. Two main tasks in the field are object detection and instance segmentation, which are essential for machine interpretation of visual data and widely used in autonomous driving, monitoring, surveillance and medical imaging applications, among others [33, 36]. Figure 2.1 depicts the difference between object detection and instance segmentation.\nObject Detection aims to locate and classify objects within an image, including the determination of their presence and exact location within bounding boxes.\nInstance Segmentation advances beyond detection with bounding box by identifying each object instance in an image at the pixel level, delineating its shape with a mask. Unlike semantic segmentation, which classifies each pixel within the image as belonging to a certain class, instance segmentation recognizes each object instance separately and the rest is considered background.\nModern deep learning architectures for detection and segmentation tasks extensively use CNNs, featuring a combination of a backbone, a neck and head structure [29].\nFigure 2.2 illustrates a standard deep learning object recognition architecture. In CNN-like architectures, a feature map is the output of one filter (also known as kernel) applied across the previous layer to detect specific features [29]. In the case of an object recognition architecture, the backbone focuses on extracting features by learning to recognize task-relevant patterns in visual data, performing changes in feature map resolution (width, height and channel number). The arrows in Figure 2.2 represent the flow of data through the network layers. As data progresses through the backbone, the resolution typically decreases to reduce the spatial dimensions while increasing the depth (number of channels) to create more abstract and complex feature representations [29]. Conversely, in the neck, the resolution can either decrease or increase. Typically, in object detection and instance segmentation tasks, the neck often includes upsampling to increase spatial information, allowing a more accurate location of objects of interest [29]. The neck fuses and aggregates features from different resolutions, acting as a bridge between the backbone and the head. The head performs specific tasks based on these features, such as detection, segmentation, and classification. Although they are different tasks, detection and segmentation share similarities in terms their architecture, with each head designed to perform the desired task. However, the design of backbone and neck can be tailored to perform better for the task of interest.\nAs illustrated by Figure 2.2, deep learning architectures for object recognition that use CNNs typically comprise blocks that represent combinations of structured layers to process the visual data. These blocks include include a combination of convolutional, pooling, upsampling, activation and regularization layers [38].\nConvolutional layers apply filters (kernels) to the input to create feature maps. These filters contain learned weights, which are adjusted during training to optimize feature extraction (see Figure 2.3). The convolution operation involves sliding the filter over the input to compute dot products between the filter weights and local regions of the input, generating feature maps that capture different aspects of the input data. Though not depicted in Figure 2.3, to further adjust the output, a learnable bias term is normally also added to each output element.\nPooling layers perform a fixed operation to reduce the spatial dimensions of the feature maps, down-sampling the input to reduce computational load and enhance invariance to small translations. As seen in Figure 2.4, there are two common types of pooling: max pooling and average pooling. Both types of pooling effectively reduce the spatial dimensions while preserving important spatial features. Moreover, pooling layers reduce the spatial resolution of feature maps to combat overfitting, which happens when a model memorizes training data, failing to generalize to new, unseen data.\nIn contrast to pooling, upsampling layers perform the opposite operation by increasing the spatial dimensions of the feature maps. Upsampling can be achieved through various methods, such as nearest-neighbor interpolation, bilinear interpolation, or transposed convolutions [29]. Upsampling layers are used to increase resolution when finer detail is necessary.\nActivation layers introduce non-linearity, enabling the network to capture complex patterns [38]. Typical activation functions include Rectified Linear Unit (ReLU) and Sigmoid-Weighted Linear Unit (SiLU). The ReLU, given by $f(x) = max(0, x)$, function provides a linear output that is zero for negative inputs and linear with a slope of 1 for positive inputs. SiLU, given by $f(x) = x\u00b7 \u03c3(x)$, incorporates a sigmoid function, described as\n\u03c3(x) = 1/(1 + e^{-x}) (2.1)\nallowing it to handle negative inputs more dynamically by scaling the output in a non-linear fashion.\nRegularization layers, such as dropout and batch normalization, are also integrated into CNN architectures. Dropout randomly omits neurons during training to enhance generalization, while batch normalization scales the output of a layer to have a mean of zero and a variance of one, which can expedite training and improve overall performance [38].\nState-of-the-art deep learning architectures, such as those that will be described in Chapter 3, often combine the above-presented layers in innovative ways to enhance model performance and efficiency. For instance, methods like ResNet, normally used as backbone in object recognition architectures, introduce skip connections that allow gradients to flow more easily through very deep networks, facilitating training [40]. Other advancements involve combining the layers in specific configurations to achieve desired properties. For example, Feature Pyramid Networks (FPNs) employ a combination of convolutional and upsampling layers to create feature maps at different scales, allowing the model to better handle objects of varying sizes within an image [41]. Additionally, various forms of attention mechanisms (see Section 2.2.2) can be integrated using these building blocks to selectively focus on relevant parts of the feature maps, leading to improved performance [42]. In summary, the combination of layers are foundational and their interactions is crucial for the advancements in contemporary deep learning models.\nNeural networks use attention mechanisms to allow models to dynamically focus on the most relevant parts of the input data, enhancing their ability to process complex information [42, 43]. Initially introduced in Natural Language Processing (NLP) for tasks like language translation [43], attention mechanisms have since become integral to various deep learning applications, including computer vision. At the core of these mechanisms are attention weights, learned during training, which determine the importance of different parts of the input [44]. For example, in language translation, this results in an n \u00d7 n attention matrix or map, where n is the number of words [43].\nThe implementation of attention mechanisms involves the calculation of the attention weights using a score function [43]. This is achieved by applying the input to a learned weighted matrix that computes relevance scores using functions like dot product [42], or pooling operations (e.g., max pooling, average pooling) [45]. These scores create an attention map, highlighting the importance of different input parts. The network uses this map to prioritize crucial information, learning to distribute focus effectively across the input data.\nIn computer vision, the term attention translates to individual pixels attending to other pixels, or patches of pixels attending to other patches, leading to an attention map that captures the relationships across different regions of the image [46]. However, this poses significant computational challenges. To address these challenges, various strategies have been proposed in the literature:\n\u2022 Dimensionality reduction with convolutional layers and pooling operations are often used to reduce the dimensions of the input before applying attention, decreasing the computational load by working with smaller feature maps [45, 47].\n\u2022 Hierarchical attention mechanisms apply attention at different scales or hierarchies, allowing the model to first focus on broad, coarse details and progressively refine its attention to finer details, thus significantly reducing complexity [48].\n\u2022 Local attention restricts the attention mechanism to a local neighborhood around each pixel, limiting the number of interactions and thereby reducing the computational burden [49].\n\u2022 Spatial attention mechanisms identify important spatial locations within an image, thus allowing the model to concentrate on critical regions [50].\n\u2022 Channel attention mechanisms focus on identifying important feature channels within a CNN, thereby improving the model's feature representation [47].\nAttention mechanisms are, therefore, used to enhance the ability of models to focus on key parts of an image. Specifically for computer vision tasks, they have been incorporated to CNNs to improve performance in large-scale image classification tasks [47, 51]. Additionally, they have been applied in object detection and instance segmentation tasks by incorporating spatial and channel-wise attention, which improves feature representation and accuracy [45, 47, 52, 53].\nTo accurately classify objects, after they are detected or segmented, the final layer of the head, usually a fully connected layer [30], provides a confidence score for each potential prediction, which reflects the likelihood that a recognized object belongs to a specific class. Multiple prediction proposals (bounding boxes or masks) for the same object require further postprocessing beyond the head to enhance the accuracy and reliability of a prediction. Standard object recognition architectures include postprocessing after the head to refine the bounding boxes or segmentation masks recognized by the model and to eliminate redundant predictions [29]. A key component of this postprocessing phase is Non-Maximum Suppression (NMS) [54], a technique designed to eliminate redundant bounding boxes or segmentation masks that pertain to the same object. Essentially, NMS ensures that each detected object is represented exclusively by the single, most accurate bounding box or mask, thereby preventing clutter and providing a clearer output.\nTo decide which bounding boxes or masks to keep and which to discard, NMS relies on the confidence scores of the predictions, together with a metric known as Intersection over Union (IoU). This metric measures the overlap between two areas\u2014in this case, the area of overlap between a predicted bounding box or mask and the ground truth, as shown in Figure 2.5. The IoU helps in determining the accuracy of the predictions by quantifying how closely the predicted bounding boxes or masks align with the actual objects in the image.\nMathematically, $B_{IOU}$ (bounding box) and $M_{IOU}$ (mask) can be denoted as:\n$B_{IOU} = \\frac{area(B_{pred} \\cap B_{gt})}{area(B_{pred} \\cup B_{gt})}$ (2.2)\n$M_{IOU} = \\frac{area(M_{pred} \\cap M_{gt})}{area(M_{pred} \\cup M_{gt})}$ (2.3)\nThis ratio ranges from 0 to 1, where 0 indicates no overlap and 1 indicates perfect overlap. In practice, an IoU threshold is set (e.g., 0.5 or 50%) to classify predictions as true positives or false positives. The NMS filters the best final prediction from the possible proposals, represented as $P_{final} = NMS(P, S, \\tau)$, for a set of predictions P (either masks or bounding boxes) with associated confidence scores S and an IoU threshold \u03c4.\nFollowing the discussion of object recognition architectures and postprocessing, it becomes relevant to address the practical aspects of implementing these frameworks. PyTorch [55] is a popular deep learning library for computer vision, valued for its dynamic computation graph and efficient GPU memory management. Its straightforward syntax simplifies the implementation of supervised CNNs, making it ideal for research and development. This thesis leverages PyTorch to develop models for ship recognition.\nThe training process of CNNs for object detection and segmentation includes forward and backward propagation, as illustrated by Figure 2.6.\nDuring forward propagation, the input data is fed through the network to output a prediction. The choice of loss function is crucial for model performance. Commonly used loss functions for different tasks include Binary Cross-Entropy Loss, Focal Loss, Bounding Box Loss, Objectness Loss, and Pixel-wise Cross-Entropy. Each of these loss functions addresses specific aspects of the prediction problem, such as class imbalance (Focal Loss) or spatial localization accuracy (Bounding Box Loss). These loss functions, sometimes used in combination or with other loss functions, help the model learn from its mistakes and achieve optimal performance [31]. Further description and mathematical definitions of these loss functions can be found in reference [29].\nBackward propagation, based on a loss function, then adjusts the network weights to minimize discrepancies between the predictions and the ground truth [38]. This adjustment process involves calculating gradients of the loss function with respect to the network parameters. These gradients indicate the direction and magnitude of the changes needed to reduce the loss.\nOptimization algorithms use these gradients to update the network parameters iteratively. Common optimization algorithms include Stochastic Gradient Descent (SGD), Adam, RMSprop, and AdaGrad [30]. Each algorithm has its strengths and is chosen based on the specific requirements of the task. The goal is to minimize the loss function, thereby improving the performance of the model. The learning rate, a key factor in this process, determines the size of the updates. Optimization involves multiple passes through the dataset, known as epochs, where the network parameters are refined to achieve better accuracy and generalization [30].\nEvaluating the performance of object recognition models is critical to understanding their effectiveness and accuracy. The mean Average Precision (mAP) is a commonly-used metric to evaluate object detection and segmentation performance [56]. Expressed in percentage, it is calculated as the mean of all the Average Precisions (AP) for all classes present in the dataset at a given IoU threshold. This is, mathematically:\nmAP_{\\tau} = \\frac{1}{C} \\sum_{c=1}^{C} AP_{\\tau,c} (2.4)\nHere, $mAP_{\\tau}$ represents the mAP at an IoU threshold \u03c4, calculated by averaging the AP values across all C classes. For the calculation of AP for each class, true positives are counted when the IoU of the prediction exceeds the given threshold \u03c4. In the case of object detection, a true positive is confirmed when the IoU of the predicted bounding box exceeds the IoU threshold. For instance segmentation, true positives are based on the overlap between the predicted mask and the ground truth mask at the IoU threshold. This distinction in true positive calculation signifies the different evaluation approaches between object detection and instance segmentation.\nIt is common in the field of object recognition to refer to mAP as a short form of $mAP_{0.5:0.95}$ [29]. The $mAP_{0.5:0.95}$ accounts for mAP values at IoU thresholds that range from 0.5 to 0.95, in increments of 0.05. The formula would therefore be defined as:\nmAP = \\frac{1}{N} \\sum_{\\tau=0.5}^{0.95} mAP_\\tau (2.5)\nWhere N represents the number of thresholds, which is 10 in the case of the range 0.5: 0.95. This comprehensive evaluation across several IoU thresholds provides insights into the performance of the model at different levels of strictness in object localization against the ground truth.\nAdditionally, the mAP can accomodate objects of varying sizes by further categorizing it based on the pixel area of the detected objects [56]:\n\u2022 $mAP_s$ (small) if area \u2264 $32^2$ pixels\n\u2022 $mAP_m$ (medium) if $32^2 < area \u2264 96^2$ pixels\n\u2022 $mAP_l$ (large) if area > $96^2$ pixels\nThis distinction per object size allows for a more detailed analysis of performance, especially in datasets with a wide range of object sizes, by highlighting its ability to detect small, medium, and large objects.\nIn order to compare results with existing standards, datasets such as COCO [56], with over 330,000 images and detailed annotations, are used as a resource for training and evaluating computer vision models in object detection and instance segmentation. Its diverse image collection makes it a valuable resource for researchers and developers. In the literature of experimental general purpose object recognition, it is a standard practice to evaluate general-purpose object recognition models performance using COCO as a benchmark [29] with the mAP as metric."}, {"title": "Relevant State of the Art", "content": "Expanding on the foundations of Chapter 2", "34": ".", "33": ".", "57": ".", "58": ".", "56": "or PASCAL VOC [59", "17": "Seaships7000 [60", "61": ".", "63": "however the restricted access makes the experimental validation using them not possible. The accessible datasets", "64": "is a synthetic ship dataset that contains images rendered from synthetic 3D scenes for instance segmentation in six ship classes", "65": "highlights the fact that while annotations for ship datasets should include more complex data such as latitude and longitude of the ship"}, {"17": ".", "19": ".", "27": "but comes with the trade-off of lower computational power compared to high-end systems [25"}, {"19": ".", "relevant": "n\u2022 YOLOv4-CSP [67", "68": ".", "32": "and serve a set of provisional bounding boxes for the object detection task. YOLOv4-CSP presented a substantial enhancement in speed and accuracy by leveraging two"}]}