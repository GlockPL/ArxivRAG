{"title": "TractShapeNet: Efficient Multi-Shape Learning with 3D Tractography Point Clouds", "authors": ["Yui Lo", "Yuqian Chen", "Dongnan Liu", "Jon Haitz Legarreta", "Leo Zekelman", "Fan Zhang", "Jarrett Rushmore", "Yogesh Rathi", "Nikos Makris", "Alexandra J. Golby", "Weidong Cai", "Lauren J. O'Donnell"], "abstract": "Brain imaging studies have demonstrated that diffusion MRI tractography geometric shape descriptors can inform the study of the brain's white matter pathways and their relationship to brain function. In this work, we investigate the possibility of utilizing a deep learning model to compute shape measures of the brain's white matter connections. We introduce a novel framework, TractShapeNet, that leverages a point cloud representation of tractography to compute five shape measures: length, span, volume, total surface area, and irregularity. We assess the performance of the method on a large dataset including 1065 healthy young adults. Experiments for shape measure computation demonstrate that our proposed TractShapeNet outperforms other point-cloud-based neural network models in both the Pearson correlation coefficient and normalized error metrics. We compare the inference runtime results with the conventional shape computation tool DSI-Studio. Our results demonstrate that a deep learning approach enables faster and more efficient shape-measure computation. We also conduct experiments on two downstream language cognition prediction tasks, showing that shape measures from TractShapeNet perform similarly to those computed by DSI-Studio. Our code will be available at: https://github.com/SlicerDMRI/TractShapeNet.", "sections": [{"title": "1 Introduction", "content": "Recent studies have shown the potential of tractography shape measures to provide insight into the brain's structural connections [29,22] and their relationship to human cognition [17,16]. However, existing methods for computation of shape measures can be highly time consuming, particularly when dealing with large-scale diffusion MRI (dMRI) tractography datasets including thousands of participants and many millions of tractography streamlines. One challenge is that existing methods require an intermediate step to convert geometric tractography streamline data to an image data representation using a voxel grid [29,22]. Computing shape measures directly from geometric tractography data, while reducing runtime and enhancing computational efficiency, remains a challenge.\nIn recent years, deep learning methods have been successful in dMRI tractography analysis [12], but computing shape measures in a way that can best take advantage of deep networks remains an open challenge. Deep learning using point clouds is promising for the analysis of geometric structures in fields like 3D object retrieval and medical imaging [10]. A point cloud is a finite set of points with 3D coordinates and optional attributes such as normals or features. In dMRI tractography, white matter connections are represented as streamlines that consist of sequences of points (Fig. 1). Recent works have demonstrated the potential of point-based neural networks for the analysis of dMRI tractography in tasks such as parcellation, filtering, and prediction of cognitive performance [28,7,2]\nTo the best of our knowledge, no deep learning methods have focused on computing white matter tractography shape, and point-cloud-based deep networks have not yet been applied to tractography to compute relevant shape features. We identify a research gap where efficient deep learning models have the potential to improve the runtime and processing speed, making it feasible to deploy shape analyses on very large brain tractography datasets.\nThe main contribution of this work is to explore the potential of a deep point cloud model to compute a set of tractography shape measures. We propose an end-to-end, time-efficient, multi-shape learning strategy to compute individual shape measures using individual fiber clusters as input as shown in Fig. 2."}, {"title": "2 Methods", "content": "This study evaluates our proposed method on the large-scale Human Connectome Project Young Adult (HCP-YA) dataset, which includes 1065 healthy young adults (575 females and 490 males, 28.7 years old on average) [26,25]. Whole brain tractography is generated from each subject's dMRI data using a two-tensor unscented Kalman filter method [18]. Tractography is then parcellated into individual fiber clusters using an anatomically curated tractography brain atlas [30]. We focus on the key task of shape computation for association pathways [29]. We employ fiber clusters within ten left hemisphere association tracts of arcuate fasciculus (AF), cingulum bundle (CB), extreme capsule (EmC), inferior longitudinal fasciculus (ILF), middle longitudinal fasciculus (MdLF), and uncinate fasciculus (UF). This results in 73 fiber clusters per subject, for a total of 77,745 clusters across the 1,065 subjects for training and testing our methods.\nWe compute ground truth shape measures for each fiber cluster using DSI-Studio [29]. Detailed definitions of the shape measures can be seen in [29,16]. We select five shape descriptors for analysis in this study: length, span, volume, total surface area, and irregularity. Length is the average streamline length of the fiber cluster, span is the distance between the two ends of the fiber cluster, and volume is the volume of voxels occupied by the fiber cluster. We include total surface area and irregularity because we have shown that they are highly informative for the prediction of individual cognitive performance [16]. Total surface area is the area of the outermost or surface voxels occupied by the fiber cluster, while irregularity quantifies how different the fiber cluster shape is from an idealized cylinder.\nOur model is trained using the right-anterior-superior (RAS) coordinates coordinate points of individual fiber clusters as independent (input) variables, with the shape measures as the dependent (output) variables. Following TractGeoNet [7], we represent each fiber cluster as a point cloud. We construct 73 point clouds for every subject, corresponding to the 73 fiber clusters. We leverage a random sampling strategy to select N random points from each cluster as input for the deep learning model. Random sampling has previously been shown to be an effective strategy for the analysis of tractography as point clouds [7] because this strategy achieves an equal probability of selection across all points [21].\nThis work proposes a novel multi-shape learning framework that aims to efficiently output shape measurements of the fiber clusters with a deep learning approach. The overall pipeline of the proposed work is shown in Fig. 2. The input to the model is the point cloud representation of fiber clusters constructed in Section 2.3. We follow a Siamese network design containing two identical subnetworks with shared weights [4,7]. The identical subnetworks adopt the PointNet architecture, which has been widely applied for processing point clouds [1,5], including tractography data [28,7]. We retain the MLP network design and remove the spatial transformation net for our subnetwork architecture to preserve fiber tract anatomical size information [28,7] and to reduce floating-point operations per second for better efficiency [1].\nWe introduce a hybrid loss function $\\mathcal{L}_{total}$ that combines the subnetwork loss functions ($\\mathcal{L}_1$, $\\mathcal{L}_2$) with a proposed weighted pairwise Siamese-Fourier loss function ($\\mathcal{L}_{SF}$) to optimize the model performance as shown in Equation (1). The subnetwork loss functions calculate the error between the output and the ground truth. The weighted pairwise loss function $\\mathcal{L}_{SF}$ complements this by capturing patterns across a Fourier frequency domain. As shown in Equation (2), we utilize the discrete Fourier transformation (DFT) to transform our predicted output and ground truth shape measures into Fourier frequency domain representations [8,19]. This transform can potentially enhance multi-shape learning by leveraging global relationships across the different shape measures. $e^{\\frac{-i2\\pi kn}{N}}$ is Euler's formula that transforms the Fourier frequency domain, where k and n represent the kth frequency component and the nth sample, respectively. $\\mathcal{L}_{SF}$ calculates the mean squared error between the output differences (0\u2081 - 0\u2082) and corresponding ground truth differences (GT\u2081 - GT\u2082) in Fourier frequency space:"}, {"title": "2.5 Implementation Details", "content": "The model is trained and evaluated with a train test split of 80% and 20%. The model is set with a batch size of 128 for 200 epochs. The initial learning rate is 0.0005 with the Adam optimizer [13] with a weight decay of 0.005. The scheduler updates the learning rate with a decay factor (gamma) of 0.1 every 200 steps. We tuned the weight (a) of the Siamese Fourier loss function loss and set it to 3 for optimal performance. The code is implemented using PyTorch v1.13 [20]. All experiments are conducted on the Jetstream2 cloud computing environment, configured with an NVIDIA A100 40 GB GPU, 117 GB of RAM, and 32 CPU cores [11,3]."}, {"title": "3 Experiments and Results", "content": "We employ the Pearson correlation coefficient (Pearson's r) [23] and the normalized mean squared error (nMSE) to evaluate model performance. Pearson's r measures the strength and direction (positive or negative) of the correlation between predicted and ground-truth shape measurements. nMSE measures the error between the predicted and ground truth values [15,14]. nMSE is normalized to a range between 0 and 1, where an nMSE value close to 0 represents a low error when compared to the ground truth.\nWe compared our proposed TractShapeNet with different baseline methods, PointNet and TractGeoNet, as shown in Tables 1 and 2. PointNet is a state-of-the-art baseline method for deep learning utilizing point clouds [5]. TractGeoNet is a state-of-the-art network for performing regression using tractography data represented as point clouds [7]. We trained these networks on our shape prediction task, including modification of their output layers and fine tuning, with implementation details as described in Section 2.5.\nTables 1 and 2 give the Pearson correlation coefficient (r) and the nMSE performance for the compared methods. The results show that point-based deep learning enables computation of shape measures. We observe that TractShapeNet has the highest performance across all shape measures. This is apparent particularly in the more challenging shape measures known to have higher anatomical variability or lower reliability, such as volume, total surface area, and irregularity [29]. This suggests that the proposed TractShapeNet is better at learning these shape features from input point clouds.\nWe calculate the average inference runtime in milliseconds (ms) to compute the five shape measures for individual fiber clusters. Results in Table 3 show that deep point cloud models show faster inference runtimes than DSI-Studio. Although TractShapeNet is slightly less efficient than TractGeoNet, it offers a tradeoff with improved performance across all shape measures."}, {"title": "3.4 Evaluation of Downstream Testbed Task", "content": "To investigate the effectiveness of shape measures from TractShapeNet, we perform a widely applied downstream testbed task, the prediction of subject-specific language performance on the NIH Toolbox Picture Vocabulary Test (TPVT) and NIH Toolbox Oral Reading Recognition Test (TORRT) [17,6,9,27,16]. Using subject-specific shape measures as inputs, we leverage a least absolute shrinkage and selection operator (LASSO) machine learning model to predict TPVT and TORRT [24,16]. Results in Table 4 show that the shape measures from TractShapeNet perform similarly to those computed by DSI-Studio. We believe the performance on these downstream tasks illustrates that TractShapeNet has captured some intrinsic white matter tractography shape information. This comparison demonstrates that deep point cloud models can generate informative shape measures for studying the brain's white matter and its relationship to language cognition."}, {"title": "4 Conclusion", "content": "In this study, we proposed a novel deep learning framework to compute tractography shape measures with successful application on the HCP-YA dataset. Our proposed model outperforms other point cloud models across all shape measures. Our proposed model enables efficient and effective fiber cluster shape computation."}, {"title": "5 Compliance with ethical standards", "content": "This study uses public HCP imaging data; no ethical approval was required."}], "equations": ["\\mathcal{L}_{total} = \\mathcal{L}_1+\\mathcal{L}_2 + a \u00d7 \\mathcal{L}_{SF}", "e^{\\frac{-i2\\pi kn}{N}}", "\\mathcal{L}_{SF}", "\\mathcal{L}_{total}"]}