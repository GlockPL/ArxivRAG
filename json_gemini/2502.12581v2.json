{"title": "The Majority Vote Paradigm Shift: When Popular Meets Optimal", "authors": ["Antonio Purificato", "Maria Sofia Bucarelli", "Anil Kumar Nelakanti", "Andrea Bacciu", "Fabrizio Silvestri", "Amin Mantrach"], "abstract": "Reliably labelling data typically requires annotations from multiple human experts. However, humans are far from being perfect. Hence, it is a common practice to aggregate labels gathered from multiple annotators to make a more confident estimate of the true label. Among many aggregation methods, the simple and well-known Majority Vote (MV) selects the class label polling the highest number of votes. However, despite its importance, the optimality of MV's label aggregation has not been extensively studied. We address this gap in our work by characterising the conditions under which MV achieves the theoretically optimal lower bound on label estimation error. Our results capture the tolerable limits on annotation noise under which MV can optimally recover labels for a given class distribution. This certificate of optimality provides a more principled approach to model selection for label aggregation as an alternative to otherwise inefficient practices that sometimes include higher experts, gold labels, etc., that are all marred by the same human uncertainty despite huge time and monetary costs.", "sections": [{"title": "1 Introduction", "content": "Data labeling or annotation is crucial for numerous real-world machine learning tasks like, for example, search and retrieval (Gligorov et al., 2013), medical imaging (Wang et al., 2019), and translation and summarization (Sarhan and Spruit, 2020). If humans were perfect at labelling data, a single round of annotation would suffice, however, the probability that the annotator gives the correct answer (which we define as annotator reliability) varies widely across its population. Hence it is common to gather a noisy label set (Li et al., 2014) by requesting annotations from distinct annotators for each task before aggregating them (Huang et al., 2023). The most commonly used aggregation method is Majority Vote (MV). MV estimation selects the class label that receives the highest number of votes from distinct annotators for a given task. Despite being easy to implement, it fails to recover true labels when incorrect annotations begin to dominate. The theoretical lower bound on the minimum achievable error given the true annotator noise was described by Nitzan and Paroush (1981). Assuming there is an oracle revealing the true annotator noise and class distribution, it reduces to the maximum a posteriori estimate with each vote weighted by the odds ratio of the annotator's reliability and the class distribution. Correspondingly, we refer to this estimate as the oracle MAP (OMAP) that is practically unknown without access to such an oracle. This makes the problem ill-posed (Spurling et al., 2021; Shi et al., 2021) for which numerous methods have been proposed in literature. The earliest from Dawid and Skene (1979) (DS) uses expectation-maximization (EM), followed by other iterative (Whitehill et al., 2009; Hovy et al., 2013) and non-iterative methods (Li et al., 2019b; Yang et al., 2024a). Some of these methods offer guarantees on the expected error rate E[R] of their estimate \u0177 of the true label y. They help understand \u201cHow many more annotations would I need for E[R] to be arbitrarily small?\u201d or say \u201cWhat is minimum E[R] reachable given my annotation budget?", "Which method is to be preferred for label aggregation on my data?": "r \u201cDoes MV achieve the lowest achievable error for my annotation job?", "as": "R= {19}] {9,9} [[\\hat{y}\\neq y]]$"}, {"title": "2 Related work", "content": "In practice, MV is the most popular method due its implementation. A popular alternative is a group of iterative solvers that update estimates of task labels and model priors (of class distribution and annotator reliability) in successive loops. Dawid and Skene (1979) and more recent variants of iterative methods (Karger et al., 2014; Li and Yu, 2014; Li et al., 2019a; Chen et al., 2023) are examples of these methods. The parameters are estimated via an EM algorithm. Spectral algorithms that use the eigenspace of the annotator-label matrix of annotations have also been proposed (Ghosh et al., 2011; Zhang et al., 2014; Tenzer et al., 2022) that have some similarities to iterative solvers (see Karger et al. (2014)). Methods that leverage other principles like Bayesian formulation have also been studied. Li et al. (2019b) use the mean-field variational method to mine latent source relationships through tensor decomposition and object clustering. Yang et al. (2024a) view the label aggregation task as a dynamic system, with task identifiers serving as time-slices. Using a Dynamic Bayesian Network to model this system, they develop two label aggregation algorithms. Li et al. (2019a) proposed a Bayesian model based on conjugate prior and iterative EM reasoning for highly redundant labeled data. Similarities can be drawn among various methods and where feasible, they theoretically bound E[R] as exp(-O(vr)) for some measure of crowd reliability r and annotation volume v. They fundamentally differ in the implicit assumptions on the priors in model specification and the solver used that are necessary for the bounds to hold true. For example, Karger et al. (2014) assumes sparse assignment of samples to annotators, while Dalvi et al. (2013) requires large eigengap for annotator-label annotation matrix. Designing annotation jobs where the assumptions hold is non-trivial since they are not easily verifiable making it a trial-and-error to evaluate them suitability in practice."}, {"title": "3 Gap in MV and MAP methods", "content": "Notation. The number of tasks, annotators, and classes are represented by N, H, and C, respectively. v denotes class distribution with subscript i when referring to class with label i, i.e., $v_i:=P(y=i)$ (Barber, 2012). We assume that annotators are conditionally independent on the true label y, $P(y_a, y_b | y) = P(y_a | y)P(y_b | y)$. This assumption models how crowdsourcing platforms (i.e., Mechanical Turk or Toloka) work in practice where annotators cannot see the answers of other annotators to the same sample.\nWe employ the noise transition matrix approach, which is widely adopted in the literature Bucarelli et al. (2023); Patrini et al. (2017) and has been validated to accurately represent real-world phenomena Liu et al. (2023). The noise transition matrix for annotator a, $T_a := P(x_a^{k}=j|y_k =i)$ is the probability of incorrectly assigning label j for the task x that has true label $y_k = i$. We denote by $x_a$ the annotations for a task with true label y of which $y_a$ is an estimate from method a. Correspondingly, $(yMV)_k$, $(yMAP)_k$ refer to the label obtained through majority vote and maximum a posteriori aggregation respectively for task k, i.e.,\n$(yMV)_k = \\underset{c \\in \\{1,...,C\\}}{\\operatorname{argmax}} \\sum_{h=1}^{H} \\mathbb{1} [x_h^k = c]$, and\n$(yMAP)_k =  \\underset{c\\in \\{1,...,C\\}}{\\operatorname{argmax}} P(y_k = c | x_{h1}, x_{h 2} ... x_h)$.\nOracle MAP refers to the case where both v and the true T are known while estimated MAP uses the estimate $\\tilde{T}$ and $\\tilde{v}$.\nProblem statement. Given a set of task annotations {$x_1, x_2...x_N$}, with $x_k \\in \\{0,1\\}^H$, we characterize the parameter space (v,T) where the gap in probabilities of MV and oracle MAP of recovering the"}, {"title": "3.1 Characterisation for symmetric class noise", "content": "We restrict our analysis in this section to one-parameter models with $e=T_{01}=T_{10}$ for ease of analysis and defer the more general two-parameter case to Section 3.2. Substituting $T_{MV}$ and $T_{OMAP}$ in Equation 1 with their expressions, we get the equality conditions as a function of parameters v and H. For all other cases that fail this condition OMAP is better than MV with a non-zero gap.\nTheorem 3.3 (MV optimality criterion for one-parameter T for binary tasks). If the probability of a label flip, $\\rho = T_{01} = T_{10}$, is less than 0.5 and denoting by v=P(y = 0) the class zero distribution we have that:\n$P(y_{OMAP} = y) = P(y_{MV} = y) iff \\rho<\\nu<1 - \\rho$.\n$\\rho < 0.5$ translates to better than random labellers that is the most general case of non-adversarial annotators with no other constraints (Karger et al., 2013; Li et al., 2019b; Bucarelli et al., 2023). Notice that if $\\rho < v < 1- \\rho$ it also holds that $\\rho < 1-\\nu < 1- \\rho$. The condition in this theorem can be rewritten as $\\frac{\\rho}{1-\\rho} < \\frac{v}{v} < \\frac{1-\\rho}{\\rho}$. This indicates that the class imbalance ratio must fall within the range defined by the odds ratio associated with the noise rate of the dataset and its inverse. For a perfectly balanced dataset, this condition is always satisfied. However, as a dataset becomes more imbalanced, the maximum noise rate at which MV remains optimal decreases. The proof of Theorem 3.3 can be found in Appendix A.3. The condition for equality of MV and MAP is a rather simple and elegant boundary in Equation 3.3 beyond which their probability gap begins to widen. Our results are valid sample-wise and provide conditions under which it is true that, for a given annotated sample, the probability that the label predicted by OMAP matching the gold label is equal to the one of MV unlike previous works Li and Yu (2014); Karger et al. (2014), which give results in terms of mean error rate. Correspondingly, this result can be used for optimal label estimates without access to an oracle if only we knew that (v, T) satisfies Equation 5. However, this verification of the bounds itself assumes access to the"}, {"title": "3.2 Extension to asymmetric class noise", "content": "We extend Theorem 3.3 to the more general case of $T_{01} \\neq T_{10}$ that corresponds to admitting noise models with unequal sensitivity and specificity. It translates to annotators confusing class 1 to class 0 and vice-versa with different error rates. In this case, the necessary and sufficient condition for probability of MV recovering the same label as that of oMAP aggregation is provided by the following theorem:\nTheorem 3.4 (MV optimality criterion for two-parameter T for binary tasks). Assuming better than random annotators' reliability (Karger et al., 2013; Li et al., 2019b; Bucarelli et al., 2023), namely $T_{00}, T_{11} > 0.5$, labeling binary tasks, we have that:\n$P(y_{OMAP} = y) = P(y_{mv} = y)$ if and only if $\\frac{\\delta c}{1} \\frac{1}{\\sqrt{p}}$.\nwhere $\\rho = \\frac{T_{00}T_{11}}{(1-T_{00})(1-T_{11})}$ and $\\delta c = \\frac{T_{cc}}{1-T_{oc}}$.\nThe proof of this theorem can be found in Appendix A.3. The condition in Equation 3.4 holds for $v_0$ if and only if it holds for $v_1$. Therefore, it is sufficient to verify the condition for just one of them. We emphasize that for $T_{01} = T_{10}$ we recover the condition of Theorem 3.3 and the inferences from Section 3.1 generalize to this case."}, {"title": "3.3 Verification without an oracle", "content": "Theorems 3.3 and 3.4 characterise the optimality criterion for MV under the one and two-coin case respectively. However, they require true T and v for verifiability, both of which are usually unknown. Nevertheless, with only their estimates, we will still be able to verify the bounds with high confidence. We define $f(T)=(\\frac{\\delta c}{1})^{\\frac{1}{2}} , h(T)=(\\frac{1}{\\delta c})^{\\frac{1}{2}}$ and $g(v)=\\sqrt{\\frac{v}{v}}$.\nTheorem 3.5. Given an approximation of the noise transition matrix T, such that $||T -T||_2 < \\epsilon$ holds with probability at least 1 \u2013 y, we define $\\tilde{i} = T^{-1} \\tilde{\\nu}$, where v is an approximation of the noisy label distribution. If $v_0$ and $v_1$ are so that $\\eta \\le v_c \\le 1 - \\eta$, for $0 < \\eta < 1$, $\\xi < T_{cc} \\le 1 - \\xi$ for $0 < \\xi < 1$ and the following inequalities hold:\n$ \\left\\{\\begin{array}{l}g(\\tilde{v})-f(\\tilde{T}) > \\psi + \\epsilon \\chi\\\\h(\\tilde{T})-g(\\tilde{v}) > \\psi + 4\\epsilon \\chi \\end{array}\\right.$ \nthen it follows that\n$ f(T) < g(v) < h(T)$\nwith probability 1 \u2013 2y + $2\\epsilon e^{2N}$, where:\n$\\psi = \\frac{\\xi}{\\lambda_{min}(T)} \\frac{\\lambda_{min}(T)-\\xi}{\\lambda_{min}(T) + \\sqrt{C}} min(T,1-T)^{2}$ and\n$\\chi = max(\\xi, \\frac{1}{\\mathcal{H}} log \\frac{1-T_{cc}}{T_{cc}})^{2} + max(\\xi, \\frac{1}{\\mathcal{H}+1} log \\frac{T_{cc}}{1-T_{cc}})^{2}$.\nThe proof of this theorem is in Appendix B. This bound depends on the quality of T and $ \\nu $ via the parameter $\\xi$. The conditions on $\\eta$ and $\\xi$ describe the amount of imbalance in class distribution and the annotator noise tolerable for the theorem to hold. Specifically, $\\eta$ is lower bound on the fraction of samples from the minority class and annotators reliability should be better than random by a margin of $\\xi$.\nThis theorem states that given estimates ($\\tilde{\\nu}$, T), it is feasible to determine with high probability if (v,T) satisfies Theorem 3.4 enabling a practical method for the verification of MV's optimality. Suitable estimators ($\\tilde{\\nu}$, T) from literature with the required estimation guarantee can be chosen. Bonald and Combes (2017) use agreement between annotator triplets from a pool of annotators with better than random average reliability with at least three informative annotators. Similarly, Bucarelli et al. (2023) leverage pairwise annotator agreement assuming all annotators are better than random."}, {"title": "3.4 Beyond equal reliability condition", "content": "In this section, we relax the equal reliability assumption and present two different settings.\nUniformly perturbed T. In this setting annotators' noise transition matrices are not fixed but are sampled from a distribution. Specifically, for a fixed \u03c3, the noise transition matrix of annotator h is given by:\n$T_h = \\begin{pmatrix} T_{00} - \\sigma_h & T_{01} + \\sigma_h \\\\ T_{10} + \\sigma_h & T_{11} - \\sigma_h  \\end{pmatrix}$,\n$\\sigma_h$ ~ Unif[-\u03c3, \u03c3]\nWe seek the conditions under which the expected performance of MV equals that of oMAP, or, more formally:\n$E[P(y^{MV} = y)] = E[P(y^{oMAP} = y)].\nWe take expectation over annotator distributions, so the derived conditions will depend only on the number of annotators and not on their specific matrices. We can prove that, if o is small enough, the conditions of Th. 3.4 ensure Eq. 7 holds. Specifically, we require:\n$\\sigma log \\frac{T_{00}}{T_{10}} -[A_c], 1 - A_c-[A_c]]$, where Rc = is as defined in Eq. 3.\nAnnotators of two categories. Here we consider two groups of annotators A and B with different reliabilities with noise transition matrices respectively $T_A$ and $T_B$. W.l.o.g. we can assume |A| < |B| and |A| < []. Under the assumption $p_A = p_B$, (which holds for instance, when $(T_A)_{cc} = (T_B)_{cc}$), we derive conditions under which MV is equivalent to OMAP. These conditions are given by:\n$\\frac{T_{B_{cc}}}{T_{A_{cc}}} $ \nwith $\\delta_{B,A}$"}, {"title": "4 Experiments", "content": "We empirically verify our results comparing MV against OMAP for various parameter configurations. Simulations are used for validating Theorems 3.3 and 3.4 that require true data generating (v, T). Theorem 3.5 that uses estimated (v, T) is verified on simulated data. We compare our results with different methods in the literature, namely, Dawid-Skene Dawid and Skene (1979), GLAD (Whitehill et al., 2009), MACE (Hovy et al., 2013), IWMV (Li and Yu, 2014), BWA (Li et al., 2019a), IAA (Bucarelli et al., 2023) and LA (Yang et al., 2024a). Annotator count H is used as available for all real data while it is set to H = 3 in all simulations unless stated otherwise. Here we report experiments with the same noise transition matrix shared by all annotators. Additional experiments that relax this assumption, as discussed in Section 3.4, are presented in Section D of the Appendix. Code for reproducing the results is shared in supplementary material and additional experimental details are in Section C.1 of the Appendix.\nSimulated symmetric noise with oracle (RQ1). We illustrate Theorem 3.3 in Figure 3a marking points in the parameter space where MV performs optimally in blue distinguishing them from those where it underperforms OMAP (in red). The plot obtained through simulations accurately reflects the theorem's conditions. Towards the left on x-axis are the low-noise regimes where MV is optimal even for skewed class balance. As the noise increases to the right, MV's optimality is restricted to fewer v closer to 0.5. This, however, is when we use the true generating noise that is unavailable for real-world cases. So, for comparison, we make similar plots with its estimate from two methods, IWMV and IAA, in Figures 3b and 3c respectively. Evidently, there is a distortion in the blue region where MV is optimal that grows with the estimation error. While IWMV largely retains the shape, IAA distorts it further with a higher number of suboptimal parameters falsely marked as optimal for MV. We further inspect the actual difference in the probability scores of MV and oMAP from Figure 3a on a heatmap in Figure 3d. Large magnitude differences are restricted to extreme cases of skewed class distribution with noisy labels on the top and bottom corners to the right. Note that this is the worst-case scenario with H = 3, and the blue region where MV is optimal grows larger with the size of the annotator pool, however, with the caveat that we need exponentially more annotators. This is illustrated in Figure 3e where we draw four distinct parameter configurations to plot the gap $P(y_{oMAP}) \u2013 P(y_{MV})$ for increasing H. (v,T) for the orange curve satisfies Theorem 3.3 and is flat all through independent of H as it should be. MV is suboptimal for the other three parameter configurations at lower H with a gap relative to OMAP that vanishes asymptotically as predicted by Li and Yu (2014).\nSimulated asymmetric noise (RQ1). Similar visualisations for the two-parameter model with H = 3 are plotted in Figure 2 for various values of v. Blue colored {(T00, T11)} pairs are MV optimal satisfying Equation 3.4 while red regions have MV underperforming OMAP. Notice how the region where MV is optimal lying around the line $T_{00} = T_{11}$ are maximum for v = 0.5 shrinking as we move away to 0.1 or 0.9 similar to the one-parameter model in Figure 3a.\nQuantitative evaluation on simulation (RQ1). We simulate data for four different configurations, see Table 1a. Two for one-parameter models of which \u03b1-Data fails the optimality condition for MV in Equation 5 while \u03b2-Data satisfies it. Similarly, for the tw"}, {"title": "5 Discussion and conclusion", "content": "MV is often considered naive for crowdsourced labeling and, before this paper, its optimality remained unexplored. It was unknown whether it could reach the theoretically optimal oMAP bound, which uses complete knowledge of annotators' noise, and the conditions under which it would match that optimal bound. We address this problem for identical annotators annotating binary tasks. We identify sufficient and necessary conditions for MV to be equivalent to oMAP. Our major finding is that when classes are well balanced, MV is robust to a wide range of annotator noise levels exactly matching the oMAP bound and as the class distribution skews, annotator reliability becomes increasingly important for MV to be optimal. Furthermore, we also extended our findings to some of the scenarios involving annotators with varying reliabilities.\nExperiments show that verifying the conditions using estimated quantities is often sufficient, thereby making our findings applicable to real-world scenarios. Finding a suitable aggregation method currently relies on evaluating multiple hypotheses through trial-and-error on a dev set with expert generated gold labels that suffer from the same annotator uncertainty. It is particularly challenging for critical tasks like medical diagnostics where the accuracy of individual labels is paramount that the instance-level optimality derived in this work guarantees. This also serves as a guide for future research to focus effort on those regions of the parameter space where MV is not optimal."}, {"title": "Impact Statement", "content": "This paper presents work whose goal is to advance the field of Machine Learning. There are many potential societal consequences of our work, none which we feel must be specifically highlighted here."}]}