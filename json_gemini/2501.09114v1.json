{"title": "GENERATIVE MEDICAL IMAGE ANONYMIZATION BASED ON LATENT CODE PROJECTION AND OPTIMIZATION", "authors": ["Huiyu Li", "Nicholas Ayache", "Herv\u00e9 Delingette"], "abstract": "Medical image anonymization aims to protect patient privacy by removing identifying information, while preserving the data utility to solve downstream tasks. In this paper, we address the medical image anonymization problem with a two-stage solution: latent code projection and optimization. In the projection stage, we design a streamlined encoder to project input images into a latent space and propose a co-training scheme to enhance the projection process. In the optimization stage, we refine the latent code using two deep loss functions designed to address the trade-off between identity protection and data utility dedicated to medical images. Through a comprehensive set of qualitative and quantitative experiments, we showcase the effectiveness of our approach on the MIMIC-CXR chest X-ray dataset by generating anonymized synthetic images that can serve as training set for detecting lung pathologies. Source codes are available at https://github.com/Huiyu-Li/GMIA.", "sections": [{"title": "1. INTRODUCTION", "content": "Medical images often contain sensitive information that can be linked to individual patients [1], posing risks of privacy breaches and identity attack. Therefore, robust anonymization techniques are essential to safeguard patient confidentiality while preserving the clinical utility of the images.\nWith the rise of generative models like Generative Adversarial Networks (GANs), new approaches have emerged that leverage the generative power of these networks to tackle anonymization by creating synthetic data. This approach ensures that while the synthetic data retains key statistical properties and utility for analysis, it no longer corresponds to any real individual, offering a robust solution for protecting sensitive information. For instance, Jeon et al. [2] introduced k-SALSA, a framework utilizing a GAN-based approach to synthesize a K-anonymous dataset from private retinal images. However, the process of sample aggregation in the latent space comes with the drawback of reducing the dataset size by a factor of k. To address this issue, Pennisi et al. [3] introduced a latent space navigation strategy to generate a diverse range of images. However, due to the weak supervision in the navigation process, the clinical interpretability of the generated images remains limited.\nUnlike existing generative medical image anonymization methods that typically rely on GAN inversion approach (\"E-training\"), where the encoder is trained with a fixed pre-trained StyleGAN generator to discover the latent representation of an input image, we approach the learning of the latent code as an image reconstruction task. This involves using a custom encoder and a co-training scheme to achieve a precise projection of the input image in its latent space. Furthermore, we adopt the latent code optimization technique from [4] to explicitly manage the trade-off between identity protection and data utility, incorporating deep identity and utility losses tailored specifically for medical images."}, {"title": "2. PROPOSED METHOD", "content": "Given a private real image dataset, we aim to generate an anonymized version that ensures patient privacy while preserving data utility. As shown in Fig. 1, we first project the real image into its latent space W through image reconstruction. Next, we initialize the anonymized latent code WA as W and optimize it using two loss functions: an identity loss $L_{id}$ to obscure identifiable features, and a utility loss $L_{ut}$ to retain critical diagnostic information."}, {"title": "2.1. Latent Code Projection", "content": "We formulate the latent code projection as an image reconstruction task using an AE-GAN (Autoencoder-Generative Adversarial Network) architecture (see top in Fig. 1), which combines a custom encoder $E$, a StyleGAN2 [5] generator $G$ and discriminator $D$. The encoder transforms an real image $X_R$ into its latent code $W = E(X_R)$, while the generator reconstructs an approximation of the real image, $X'_R = G(W)$ from the latent code. A discriminator $D(X_R)$ is also employed to distinguish between real and generated images.\nThe custom encoder $E$ (lower left of Fig. 1) mirrors the generator $G$, leveraging the inherent symmetry of the AE architecture. $E$ begins with an operation (fromIMG) that converts the input image into feature maps for subsequent convolutional processing. At each resolution, we implement a residual network architecture, consisting of two 3\u00d73 convolution layers followed by a bilinear downsampling operation to reduce the feature map size. The skip connection includes a bilinear downsampling operation and a 1\u00d71 convolution layer. After 6 operation groups, $E$ projects the input image into the W latent space of StyleGAN2 [5].\nTo learn a more accurate mapping from the input image to its W latent space, we propose a co-training scheme to optimize the AE-GAN network. In each training step, the encoder $E$ and generator $G$ are jointly optimized using a composite loss function $L_{E-G}$, which integrates three key components: pixel-wise similarity loss, perceptual similarity loss, and adversarial (generator) loss. This is followed by optimizing the discriminator $D$ using the discriminator loss $L_D$."}, {"title": "2.2. Latent Code Optimization", "content": "Latent code optimization (see bottom right in Fig. 1) drives the anonymization process, with $W_A$ as the only trainable parameter and initialized from $W$, while all other networks remain pre-trained and fixed. $W_A$ is optimized using two deep loss functions: $L_{id}$, which ensures that identifiable features are effectively obfuscated or removed, and $L_{ut}$, which preserves critical visual and diagnostic information.\nThe identity loss $L_{id}$ ensures that $X_A$ has a different identity from $X_R$, up to a desired margin. It is defined as follows:\n$L_{id}(X_R, X_A) = max(0, cos(E_{id}(X_R), E_{id}(X_A)) - m)$                                                            (1)\nwhere $cos(a, b) = \\frac{a \\cdot b}{max(||a||_2||b||_2, \\epsilon)}$ denotes the cosine similarity, and $\\epsilon$ is a small value to avoid division by zero. $E_{id}$ is the identity encoder, which is pre-trained for identity recognition [6]. $m$ is a hyperparameter that controls the dissimilarity between the real and the anonymized images, constrained to be equal to or greater than $arccos(m)$.\nThe utility loss $L_{ut}$ enforces that utility attributes of $X_R$ are preserved in $X_A$. It is defined as follows:\n$L_{ut}(X_R, X_A) = ||E_{ut}(X_R) - E_{ut}(X_A)||_2$                                                       (2)\nwhere $E_{ut}$ is the utility encoder, which is pre-trained to perform a downstream task (e.g. lung pathology classification)."}, {"title": "3. EXPERIMENTS", "content": "Dataset. We perform anonymization on MIMIC-CXR-JPG dataset [7], using the default dataset partition. To ensure sufficient data per patient, we apply a filtering strategy (\u2265 20 images per patient). This results in 50 875/522/1 641 images, corresponding to 1 538/14/47 patients in the training/validation/testing sets, respectively. The utility task focuses on classifying lung pathology labels, while the identity classifier is designed to predict patient IDs.\nLatent Code Projection. We evaluate the projection process using both the proposed \"Co-training\" scheme and the classic \"E-training\" approach, comparing their performance in terms of image reconstruction fidelity.\nUtility Preservation. To assess the preservation of utility attributes, we train utility classifiers on the training sets of real images $X_R$, reconstructed images $X'_R$, and anonymized images $X_A$, then evaluate them on the same unseen real test set.\nIdentity Anonymization. To measure the privacy-preserving properties of our approach, we first assess the singling-out risk\u00b9 on testing set with two metrics: LC (local cloaking) and HR (hidden rate). LC is defined as the median number of images between a real image and its anonymization. HR is defined as the percentage of individuals in the real dataset whose anonymized images is not the most similar to them.\nThen, we introduce a protocol to assess linkability risk\u00b2 from two perspectives: Inner risk: Verifying whether two anonymized images belong to the same patient. Outer risk: Verifying whether a real and its anonymized image belong to the same patient. Specifically, we frame the evaluation as a"}, {"title": "4. RESULTS", "content": "Image Reconstruction. Table 1 shows that the co-training scheme outperforms the E-training approach in reconstruction accuracy, as indicated by higher PSNR and IW_SSIM scores, highlighting the benefits of joint optimization for enhancing reconstruction quality. The results are further validated by the visual comparison in Fig. 2, where the co-training scheme recovers input images with finer details and higher fidelity. In contrast, the E-training scheme exhibits noticeable discrepancies when compared to the original images.\nUtility Preservation. As shown in Table 2, the performance of classifiers trained on anonymized datasets (row 4-6) exhibits minimal difference compared to the one trained on real dataset (row 1), indicating that the anonymized datasets maintain a similar level of data utility compared to their real counterparts. Moreover, incorporating $L_{ut}$ (row 4, 6) yields better results compared to those without it (row 2, 5), highlighting the effectiveness of the utility loss $L_{ut}$ in preserving utility-related information during optimization. Additionally, classifier trained on reconstructed datasets using E-training scheme (row 3) shows the weakest performance, highlighting the advantages of the proposed co-training scheme.\nIdentity Anonymization. Table 3 denotes that the anonymized images (row 3-5, 7-9) exhibit a lower linkability risk compared to their real counterparts (row 1). Additionally, the anonymized datasets exhibit high inner risk and a low outer risk, which is expected. The high inner risk indicates that the anonymized images retain relative likability relationships (e.g., images from the same patient remain associated with each other), while the low outer risk signifies that the linkability relationship between anonymized images and their real counterparts is effectively removed (e.g., anonymized images do not resemble their real counterparts in terms of identity).\nMoreover, incorporating $L_{id}$ increases the inner risk while reducing the outer risk. This suggests the loss $L_{id}$ helps push the anonymized images belonging to the same patient closer together while breaking the linkability to their real counterparts. Similar results are shown in Table 4, where $L_{id}$ plays a crucial role in reducing the singling out risk, as incorporating"}, {"title": "Qualitative Results", "content": "The visualization results are shown in Fig. 3. In this figure, the anonymized images optimized using only the utility loss $L_{ut}$ (column 3) exhibit greater visual similarity to their real counterparts (column 1), while those optimized using only the identity loss $L_{id}$ (column 4) appear more distinct from their originals. Additionally, the anonymized images optimized with both the $L_{ut}$ and the $L_{id}$ (column 5) strike a balance, appearing more realistic by simultaneously considering both identity removal and utility preservation."}, {"title": "5. CONCLUSIONS", "content": "In this paper, we introduce an innovative two-stage approach to address medical image anonymization. First, we precisely project the input image into its latent space using image reconstruction with a custom encoder and an effective co-training scheme. Then, we optimize the latent code to remove identifiable information while preserving utility using two deep loss functions. Our results demonstrate that the method effectively anonymizes the images while better preserving utility attributes, leading to improved de-identification and retention of critical clinical information."}]}