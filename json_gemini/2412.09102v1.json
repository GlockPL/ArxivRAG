{"title": "PolyIPA - Multilingual Phoneme-to-Grapheme Conversion Model", "authors": ["Davor Lauc"], "abstract": "This paper presents PolyIPA, a novel multilingual phoneme-to- grapheme conversion model designed for multilingual name transliteration, onomastic research, and information retrieval. The model leverages two helper models developed for data augmentation: IPA2vec for finding soundalikes across languages, and similarIPA for handling phonetic notation variations. Evaluated on a test set that spans multiple languages and writing systems, the model achieves a mean Character Error Rate of 0.055 and a character-level BLEU score of 0.914, with particularly strong performance on languages with shallow orthographies. The implementation of beam search further improves practical utility, with top-3 candidates reducing the effective error rate by 52.7% (to CER: 0.026), demonstrating the model's effectiveness for cross-linguistic applications.", "sections": [{"title": "Introduction", "content": "Although text-to-speech and speech-to-text models nowadays are mostly end- to-end, there are still many use cases for intermediate representations using phonetic alphabets such as IPA. This is particularly evident in multilingual"}, {"title": "Problem Statement and Contributions", "content": "The main focus of this paper is the development of the P2G model that is usable in the use cases of transliteration and information retrieval, as"}, {"title": "Data Collection and Preparation", "content": ""}, {"title": "Data Sources", "content": "The largest dataset available, WikiPron represents a foundational multilin- gual resource containing 1.7 million pronunciations in 165 languages (Lee et al., 2020). The data is provided in IPA format with clear transcription guidelines for contributors. CharsiuG2P dataset offers a transformer-based solution that supports 100 languages, built on the ByT5 architecture (Zhu et al., 2022). The Montreal Forced Aligner Dictionary Collection provides ex- tensive pronunciation data formatted specifically for speech alignment tasks (McAuliffe et al., 2017), but is useful for other tasks as well. PWESuite serves as an evaluation framework for phonetic word embeddings, offering tasks such as sound similarity correlation and cognate detection (Zouhar et al., 2023).\nBased on analysis of language representation versus language sizes, sev- eral language-specific sources were also included. KaamelDict stands as the largest Persian G2P dictionary with over 120,000 entries (Fetrat et al., 2024), that unifies multiple phonetic representation systems and provides detailed phoneme-to-IPA mapping. Thai G2P (Phatthiyaphaibun, 2020) focuses on"}, {"title": "Data Cleaning and Normalization", "content": "Data sources utilizing non-IPA transcription systems, such as X-SAMPA (Wells, 2016) and ARPABET (Klautau, 2001), were converted to standard International Phonetic Alphabet (IPA) notation. Particular attention was paid to the accurate conversion of extended and language-specific symbols, including tonal markers. The language names and codes from all sources were standardized using ISO-639-1 language codes when available or ISO-639-3 codes when necessary. Datapoints with unidentified languages, comprising 0.03% of the dataset, were excluded. Multiple phonetic transcriptions for a single grapheme within one language were retained.\nThe initial dataset comprised 20,987,451 unique language-grapheme-phoneme triples. All strings underwent NFC normalization, case lowering, and dedu- plication. To address invalid transliterations identified in the source data, we implemented a validation function to verify that the phonetic transcriptions contained only valid symbols of the extended IPA alphabet. This cleaning process resulted in 20,087,067 triples. Further refinement involved remov- ing entries where the detected script did not correspond to the official script of the respective language, eliminating both romanized versions of non-Latin languages and various noise elements. The final data set contained 19,648,870 data points."}, {"title": "Data Augmentation", "content": ""}, {"title": "Soundalikes by IPA2VEC model", "content": "To address the identified gaps in phonetic pattern coverage across languages, we implemented a data augmentation approach based on phonetic similarity mining using a Siamese neural network architecture.\nThe training data set was constructed using the large-scale cognate lex- ical database (Batsuren et al., 2019), filtering for entries that existed in our phonetic dictionary. For each positive pair in the database, we generated one random negative example, resulting in 2,364,433 word pairs. Each pair was annotated with a feature edit distance score following the methodology"}, {"title": "SimilarIPA model", "content": "The second data augmentation approach addressed the variations in IPA transcription practices between different sources and annotation traditions. These variations are particularly evident when combining multiple phonetic data sets with different transcription conventions.\nWe generated additional training data by leveraging cases where multi- ple IPA transcriptions existed for the same language-grapheme pair in our dataset. For each language-grapheme pair with multiple valid IPA transcrip- tions, we extracted all possible combinations to create IPA-to-IPA transfor- mation pairs. This process yielded 4.4 million pairs, which were split into training sets (98%), evaluation sets (1%) and test sets (1%).\nFor modelling these transformations, we employed the T5.1 architecture (Raffel et al., 2020), which has demonstrated strong performance in sequence- to-sequence tasks. We first trained a custom SentencePiece vocabulary of 32K tokens Kudo and Richardson (2018), on the training data to get vocab- ulary optimized for phonetic character sequences. The T5.1 small model was then trained from scratch for five epochs.\nThe model achieved an evaluation loss of 0.21 and a Character Error Rate (CER) of 0.06. These metrics are considered satisfactory for the pur-"}, {"title": "Accent and Tone Reduction", "content": "The final augmentation process included careful handling of the IPA tran- scriptions through multiple normalization steps. First, a validation function was implemented to ensure the quality of phonetic transcriptions. This func- tion performed several checks:\n\u2022 Basic validation of input type and format\n\u2022 Removal of diacritical marks and tone indicators using Unicode nor- malization"}, {"title": "Language and Script Handling", "content": "Data preparation included special handling for languages that use multiple scripts. Languages like Chinese (zh) and Serbian (sr), which can be written in different scripts, were encoded with script-specific language codes (e.g., zh_Hani for Chinese in Han characters, sr_Latn for romanized Serbian). This distinction was crucial for training the model to handle script-specific transcription patterns. Each IPA transcription was prefixed with a language- script code in the format <{lang_code}> or <{lang_code}_{script}> when necessary."}, {"title": "Dataset Splitting and Upsampling", "content": "The dataset was split into training and test sets using a stratified sampling approach to ensure representative coverage across languages. The key char- acteristics of the splitting process included:\n\u2022 A fixed test and evaluation set size of 5,000 examples\n\u2022 Stratification by ISO language code to maintain language distribution\n\u2022 Balanced sampling to prevent over-representation of high-resource lan- guages\nThe upsampling strategy was integrated directly into the training data generation process, with several key components working in concert. First, a length filter was applied to ensure that all examples remained under 40 tokens, maintaining computational efficiency and model stability. During generation, the system produced multiple variants of each training example:"}, {"title": "Experimental Setup", "content": "The model was trained using the Seq2SeqTrainer from the Hugging Face Transformers library, with optimized training configurations for the P2G task. The core configuration included:\n\u2022 Model Architecture: Two variants were tested - ByT5-small and MT5- small (Xue et al., 2022), with ByT5 showing superior performance for byte-level processing of multilingual text\n\u2022 Maximum Sequence Length: 64 tokens\n\u2022 Learning Rate: 4e-5 with a linear warm-up over 1000 steps\n\u2022 Weight Decay: 0.01 for regularization\n\u2022 Batch Size: 96 per device with gradient accumulation steps of 4\n\u2022 Training Duration: 3 epochs\n\u2022 Gradient Clipping: Maximum gradient norm of 1.0 to prevent explod- ing gradients"}, {"title": "Fine-tuning Model for Proper Names", "content": "The augmentation process began with a comprehensive phonetic analysis of common proper names across world languages. The initial data set consisted of the one million most frequent proper names from global language sources, as collected by Mondonomo Nomograph DB (Lauc, 2024). These names were processed through the trained phoneme-to-grapheme model, each token for"}, {"title": "Results and Discussion", "content": "The evaluation methodology employs multiple complementary metrics to as- sess the model's performance in phoneme-to-grapheme conversion across dif- ferent languages. The primary metrics include Character Error Rate (CER), Character Level BLEU Score, and Top N Word Error Rate (WER), providing a comprehensive assessment of the model's accuracy and generation quality.\nThe character error rate (CER), calculated using the Levenshtein dis- tance normalized by the reference length Levenshtein (1966), serves as our primary metric for measuring transcription accuracy. This metric is partic- ularly suitable for phoneme-to-grapheme conversion tasks, as it operates at the character level and captures insertion, deletion, and substitution errors Niu et al. (2019). Additionally, we compute character-level BLEU scores using SacreBLEU Post (2018), treating individual characters as tokens to evaluate the model's ability to preserve character sequences in the translit- eration process. This approach has been shown to be effective in previous transliteration studies Najafi et al. (2018).\nTo evaluate the performance of the model with beam search generation, we implement a top-N evaluation strategy similar to that used in machine translation studies Wu et al. (2016). For each input sequence, the model generates N candidate outputs (N=1,3,5), and we calculate the WER for each candidate, recording both the best score and its position on the beam. This approach helps assess the model's ability to generate multiple valid transliterations, which is particularly important for languages with multiple acceptable grapheme representations for the same phoneme sequence.\nThe evaluation is stratified by language to account for the varying com- plexity of phoneme-to-grapheme mapping across different writing systems. For each language, we calculate the mean performance metrics along with their standard deviations, weighted by the number of test samples. This stratification helps identify language-specific patterns and potential biases in"}, {"title": "Overall Performance", "content": "The model demonstrates strong performance in the majority languages, with:\n\u2022 Mean Character Error Rate (CER): 0.055 (\u00b10.167)\n\u2022 Mean Character-level BLEU: 0.914 (\u00b10.212)\n\u2022 Exact Match Accuracy: 0.830 (\u00b10.376)\n\u2022 Top-3 WER: 0.026 (\u00b10.115)\nThe high exact match rate and low CER indicate that the model success- fully learns phoneme-to-grapheme mappings for most languages."}, {"title": "Orthographic Depth Analysis", "content": "Performance correlates strongly with orthographic depth, a concept devel- oped by Katz and Frost (1992a) in their Orthographic Depth Hypothesis."}, {"title": "Shallow Orthographies (High Performance)", "content": "\u2022 Finnish (CER: 0.002): Known for nearly perfect grapheme-phoneme correspondence\n\u2022 Spanish (CER: 0.000): Highly regular orthography\n\u2022 Turkish (CER: 0.000): Consistent letter-sound relationships\n\u2022 Croatian (CER: 0.000): Transparent orthographic system"}, {"title": "Deep Orthographies (More Challenging)", "content": "\u2022 English (CER: 0.067): Complex historical influences (Venezky, 1970)\n\u2022 French (CER: 0.120): Multiple grapheme-phoneme mappings\n\u2022 Chinese (CER: 0.522): Morphosyllabic writing system"}, {"title": "Language Family Performance", "content": ""}, {"title": "High-Performing Language Families", "content": "1. Uralic Family:\n\u2022 Hungarian (CER: 0.000)\n\u2022 Finnish (CER: 0.002)\nReflects Abercrombie's (1967) observation about phonemic writing sys- tems\n2. Turkic Family:\n\u2022 Turkish (CER: 0.000)\n\u2022 Uzbek (CER: 0.019)\nDemonstrates success with agglutinative languages"}, {"title": "Challenging Language Families", "content": "1. Sino-Tibetan:\n\u2022 Chinese (CER: 0.522)\nConsistent with Share's (2008) analysis of non-alphabetic writing sys- tems\n2. Celtic:\n\u2022 Manx (CER: 0.296)\n\u2022 Scottish Gaelic (CER: 0.115)\nReflects historical orthographic complexity noted by Sproat (2000)"}, {"title": "Script Analysis", "content": "Performance patterns align with Perfetti and Liu (2005)'s Universal Writing System Constraint:\n1. Latin script languages: Strong performance\n2. Syllabic scripts (Thai, Khmer): Moderate performance\n3. Logographic scripts: Lower performance\n4. Alphabetic non-Latin: Good performance"}, {"title": "Beam Search Analysis", "content": "The beam search results demonstrate:\n1. Top-1 and Top-3 performance differences\n2. Language-specific benefits from larger beam sizes\n3. Correlation with orthographic depth"}, {"title": "Error Pattern Analysis", "content": "Common error patterns align with the Wiese (2004) typology of orthographic complexity:\n1. Character substitutions in phonetically similar sounds\n2. Diacritic mark variations\n3. Higher error rates in:\n(a) Non-phonemic orthographies\n(b) Complex writing systems\n(c) Limited training data case"}, {"title": "Discussion", "content": "The experimental results demonstrate both the capabilities and limitations of our multilingual phoneme-to-grapheme conversion approach. The model achieves strong performance across most languages, particularly those with"}, {"title": "Performance Analysis", "content": "The performance of the model exhibits clear patterns correlated with the linguistic characteristics of the target languages. Languages with shallow orthographies consistently show excellent results (CER \u00a1 0.005), support- ing the Orthographic Depth Hypothesis Katz and Frost (1992b). Finnish, Spanish, Turkish, and Croatian languages, all languages with highly regu- lar grapheme-phoneme correspondence, achieve near-perfect accuracy. This aligns with previous findings in cross-linguistic studies of writing systems Share (2008).\nHowever, significant challenges arise with deeper orthographies. English and French show moderate error rates (CER of 0.067 and 0.120 respec- tively), reflecting their complex historical influences on spelling conventions.\nThe most challenging cases appear in logographic writing systems, particu- larly Chinese (CER: 0.522), where the relationship between phonemes and graphemes is fundamentally different from alphabetic systems."}, {"title": "Error Analysis", "content": "Detailed error analysis reveals several systematic patterns:\n1. Phonetic Proximity Errors: The most common substitution er- rors occur between phonetically similar sounds, particularly within the same manner or place of articulation. This suggests that the model has learned meaningful phonetic relationships, but sometimes strug- gles with fine-grained distinctions.\n2. Script-Specific Challenges: Performance varies significantly between writing systems, with Latin-based scripts showing the highest accu- racy, followed by other alphabetic systems, syllabaries, and finally lo- gographic scripts. This hierarchy aligns with Perfetti and Liu's Perfetti and Liu (2005) Universal Writing System Constraint.\n3. Resource Effects: Languages with limited training data show a higher variance in performance, indicating the importance of quantity and quality of data in model training."}, {"title": "Beam Search Analysis", "content": "The implementation of beam search significantly improves the model's prac- tical utility. Although the accuracy of the top-1 provides strong results for many languages (mean CER: 0.055), including the top-3 candidates reduces the effective error rate by 52 7% (to CER: 0.026). This improvement is partic- ularly pronounced in languages with multiple valid grapheme representations for the same phoneme sequence."}, {"title": "Limitations", "content": "Several limitations warrant acknowledgment:\n1. The model's performance degrades significantly for languages with com- plex morphophonological rules that are not captured in the training data.\n2. The current approach does not explicitly handle tone languages, treat- ing tonal markers as diacritics rather than integral phonological fea- tures.\n3. The model occasionally produces phonologically valid but historically incorrect transliterations for proper names, particularly when crossing language families."}, {"title": "Future Work", "content": "Based on our findings and analysis, we identify several promising directions for future research."}, {"title": "Model Architecture Improvements", "content": "1. Phonetic Similarity Models: Development of a unified model that would, for a given IPA string and language, generate IPA rendering of similar sounding words for a typical speaker of a given language.\n2. Script-Specific Encoders: Developing specialized encoding layers for different writing systems could better capture script-specific features and improve performance across various orthographies.\n3. Morphological integration: Incorporating morphological analysis could help handle complex derivational and inflectional patterns that affect grapheme selection."}, {"title": "Data Enhancement", "content": "1. Targeted Data Collection: Expanding the training data for under- represented languages and scripts, particularly focusing on languages with complex orthographic systems.\n2. Generating synthetic data: Expanding the training data using well performing.\n3. Comprehensive Data Cleaning: Implementation of more thorough cleaning procedures to address errors primarily arising from Wiktionary parsing issues.\n4. Historical Pattern Mining: Incorporating historical linguistics data to better handle etymology-based spelling patterns, especially for proper names and borrowed words."}, {"title": "Feature Engineering", "content": "1. Phonological Feature Integration: Explicitly modelling phonolog- ical features could improve the handling of sound changes across lan- guage boundaries.\n2. Prosodic Modelling: Developing better representations for supraseg- mental features such as tone and stress.\n3. Enhanced Phonetic Similarity Metrics: Improving metrics for measuring phonetic similarity by incorporating language-specific per- ceptual factors, as suggested by recent research on cross-linguistic pho- netic perception (Antoniou et al., 2023)."}, {"title": "Evaluation Framework", "content": "1. Language-Specific Metrics: Developing evaluation metrics that ac- count for systematic differences in writing systems and acceptable vari- ation in transliteration.\n2. User Studies: Conducting human evaluation studies to assess the practical utility of the model's outputs in real-world applications.\n3. Cross-Linguistic Validation: Expanding evaluation to include more systematic testing of cross-linguistic name adaptation patterns."}]}