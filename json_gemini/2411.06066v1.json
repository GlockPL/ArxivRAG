{"title": "Diversity and Inclusion in AI for Recruitment: Lessons from Industry Workshop", "authors": ["Muneera Bano", "Didar Zowghi", "Fernando Mourao", "Sarah Kaur", "Tao Zhang"], "abstract": "Artificial Intelligence (AI) systems for online recruitment markets have the potential to significantly enhance the efficiency and effectiveness of job placements and even promote fairness or inclusive hiring practices. Neglecting Diversity and Inclusion (D&I) in these systems, however, can perpetuate biases, leading to unfair hiring practices and decreased workplace diversity, while exposing organisations to legal and reputational risks. Despite the acknowledged importance of D&I in AI, there is a gap in research on effectively implementing D&I guidelines in real-world recruitment systems. Challenges include a lack of awareness and framework for operationalising D&I in a cost-effective, context-sensitive manner. This study aims to investigate the practical application of D&I guidelines in AI-driven online job-seeking systems, specifically exploring how these principles can be operationalised to create more inclusive recruitment processes. We conducted a co-design workshop with a large multinational recruitment company focusing on two AI-driven recruitment use cases. User stories and personas were applied to evaluate the impacts of Al on diverse stakeholders. Follow-up interviews were conducted to assess the workshop's long-term effects on participants' awareness and application of D&I principles. The co-design workshop successfully increased participants' understanding of D&I in AI. However, translating awareness into operational practice posed challenges, particularly in balancing D&I with business goals. The results suggest developing tailored D&I guidelines and ongoing support to ensure the effective adoption of inclusive AI practices.", "sections": [{"title": "I. INTRODUCTION", "content": "Artificial Intelligence (AI) is increasingly transforming the landscape of online employment marketplaces, with significant potential benefits such as improved efficiency, reduced hiring time, and a broader reach in identifying candidates and job opportunities [1]. AI-powered recruitment systems can streamline resume screening, match candidates to jobs more effectively, and automate parts of the interview process [2]. However, while AI can introduce efficiency, it can also perpetuate harmful biases if not designed and deployed carefully [3]. Models trained on biased datasets may reinforce discrimination, particularly affecting underrepresented groups, resulting in unfair hiring practices and reduced workplace diversity [4]. The balance between leveraging Al's potential and mitigating its risks is a critical area of focus in online employment.\nProactive efforts to promote diversity and inclusion (D&I) are essential to ensure Al-powered hiring tools do not perpetuate or reinforce harmful biases. D&I in Al refers to the proactive incorporation of diverse human attributes and perspectives into all stages of Al development, including design, data, processes, systems, and governance [5]. As per the definition provided by [5], diversity encompasses the representation of individuals with varied attributes protected by law, such as race, gender, disability, and sexual orientation, among others. Inclusion involves ensuring that people with these diverse attributes, particularly those most impacted by Al systems, are meaningfully involved in the design, deployment, and governance of these technologies.\nTo guide the responsible development of Al systems, including those used in online recruitment markets, researchers at CSIRO's Data611 have developed D&I Guidelines for AI [6]. These guidelines focus on embedding D&I principles into the Al lifecycle, from data collection to deployment, ensuring that Al systems are equitable, transparent, and inclusive. The guidelines advocate human- centred design, diverse stakeholder involvement, and continuous monitoring to address bias and uphold ethical standards in Al applications.\nSEEK 2 a market leader in online employment marketplaces across Asia-Pacific (APAC), invests in safe and responsible AI to make employment markets more transparent, efficient and fairer for jobseekers and hirers. As an industry leader, SEEK is committed to promoting diversity and inclusion, recognising that Al systems must be fair and representative to ensure equitable hiring practices. This paper examines the integration of the D&I guidelines developed by researchers at CSIRO's Data61 within SEEK's Al-driven recruitment platform, focusing on how these guidelines can help transform business processes adopted by the industry to effectively deliver fair AI products in online employment markets.\nThis research investigates the challenge of operationalising D&I guidelines in AI recruitment systems. It aims to identify the challenges, requirements and practices for organisations to integrate D&I in the AI development lifecycle. While awareness of the need for ethical Al is growing, practical frameworks for integrating D&I principles into real-world applications are still lacking [7, 8]. Current approaches rely on theoretical frameworks focused on broad ethical principles and lack practical, industry-led initiatives to ensure the implementation of D&I principles [8]. To tackle this, we conducted a co-design workshop and follow-up reflection interviews in collaboration with SEEK, using A\u0399- generated personas and user stories to explore D&I principles in recruitment scenarios.\nThe results of this study indicate increased awareness among stakeholders regarding the importance of D&I in AI after the co-design workshop. Key lessons learned include the necessity of tailoring guidelines to specific use cases, the value of stakeholder engagement, and the effectiveness of using generative AI tools to illustrate potential impacts.\nThis research makes important contributions to the state- of-the-art and practical implementation of D&I in AI-driven recruitment systems. It provides practical and real-world insights into how D&I principles can be operationalised within AI technologies, moving beyond theoretical discussions to actionable, context-specific guidance. The use of co-design workshops with industry stakeholders demonstrated the importance of stakeholder engagement in tailoring D&I guidelines to specific use cases, revealing challenges like balancing business objectives with D&I goals. This study highlights the value of integrating D&I into SEEK's product development and governance workflows, offering a framework to improve inclusivity in their Al systems. Moreover, the results inform the refinement of D&I in Al guidelines and enhance the co-design workshop methodology by emphasising the need for ongoing support, follow-up sessions, and industry-specific adaptations. This work contributes to a broader understanding of how organisations can systematically embed D&I principles in AI systems, and the findings can serve as a model for other industries aiming to ensure inclusive AI-driven processes.\nSection II gives background and discuss existing literature on Al in Recruitment, Diversity and Inclusion in Al and Guidelines, and the intersection of these concepts. Section III provides motivation for the research, Section IV Methodology, and Section V describes the results. Section VI provides discussion, Section VII summarises the lessons learned, VIII discusses potential threats to validity, and Section IX draws the conclusion and puts forward the future directions."}, {"title": "II. BACKGROUND AND EXISTING LITERATURE", "content": "AI has the potential to significantly enhance the efficiency and effectiveness of online job seeking and matching processes by automating repetitive tasks, improving discoverability of job opportunities, and enabling data-driven hiring decisions [9, 10]. AI tools can analyse resumes, identify key skills, and match candidates to relevant job opportunities more quickly and accurately than traditional methods [9, 11]. It has been claimed that this results in better hiring outcomes, increased retention rates, and a more streamlined recruitment process [12, 13]. Additionally, AI-based systems can recommend talent lists to hirers, simplifying and accelerating the hiring process [11].\nHowever, significant challenges remain. One of the most pressing concerns is the potential for AI to perpetuate or reinforce harmful biases embedded in historical data, leading to discriminatory hiring practices. A notable example is Amazon's Al-powered hiring tool, which was abandoned after it was discovered to be biased against women [14, 15]. The tool had been trained on resumes submitted to the company over a ten-year period, many of which came from male candidates, leading the AI to penalise resumes from women. This incident illustrates how biased training data can reinforce gender and other discriminatory biases, undermining the fairness of AI-driven recruitment systems [15, 16].\nIn addition to biases, ethical concerns such as data privacy and transparency present further obstacles to the adoption of AI in recruitment at scale [17]. Moreover, organisational and technological barriers, such as integrating Al into existing hiring frameworks, complicate its widespread implementation [18]. While AI offers significant benefits, ensuring fairness, reducing harmful bias, and maintaining ethical governance are crucial to its effective use in recruitment. Robust guidelines and ongoing monitoring are essential to address these challenges and promote inclusion in Al-driven hiring processes [15]. Employment is considered a high-risk domain for AI in some jurisdictions, leading to proposed regulations that enforce mandatory safeguards to prevent large-scale harm [19].\nD&I in Al refers to the proactive and intentional integration of diverse attributes and perspectives across all stages of the Al lifecycle, including data collection, processes, system design, and governance [5]. Diversity encompasses attributes protected by law, such as race, gender, age, disability, and more, while inclusion ensures the proactive involvement and representation of diverse individuals impacted by AI systems [5]. Research consistently shows that neglecting D&I in AI development leads to biased algorithms, perpetuating existing societal inequalities and resulting in exclusionary or discriminatory outcomes [7, 20]. For example, Al systems trained on homogenous or biased datasets can disproportionately affect underrepresented groups, with significant implications for sectors like recruitment, healthcare, and law enforcement [21].\nThe consequences of neglecting D&I principles highlight the importance of understanding the interconnectedness between D&I, equity, and fairness. Equity ensures that everyone, regardless of their background, has equal access to opportunities, while fairness aims to eliminate harmful bias and provide consistent, objective evaluations for everyone. D&I lay the foundation for equitable and fair AI by promoting representation and active participation [7]. When D&I principles are ignored, Al systems can amplify biases, resulting in unfair decision-making processes that erode public confidence and expose organisations to legal and reputational risks [22, 23]. Embedding diverse perspectives throughout Al design helps prevent bias and creates more inclusive, equitable solutions [21].\nIntegrating D&I into Al systems, especially for online recruitment requires contextualising these efforts to the unique use cases of Al within specific tasks like candidate screening or job matching. We argue that requirements engineering (RE) processes can be tailored to identify and analyse AI-related risks, helping to navigate trade-offs and conflicts that may arise from neglecting D&I principles [24, 25]. For example, RE can support decision-making in situations where maximising inclusion may reduce performance or efficiency, or where ensuring data transparency for under-represented groups might compromise their privacy. By acknowledging diverse users and promoting inclusive system development, RE can help balance conflicting objectives and contribute to the creation of ethical AI systems [24]. Addressing these challenges through an RE lens and operationalising D&I requirements for AI ensures that AI systems are responsibly developed and deployed, promoting a more inclusive, equitable, and ethical AI landscape [25, 26]."}, {"title": "C. D&I Guidelines for AI", "content": "In our research, we utilise the D&I in Al guidelines developed by CSIRO's Data61 3 which are part of Australia's National AI Assurance Framework 4. The guidelines are structured around five key pillars: Humans, Data, Process, System, and Governance. These pillars provide a holistic approach to embedding D&I principles throughout the AI lifecycle. These guidelines address the critical need to minimise bias, promote fairness, and ensure transparency throughout the AI lifecycle. They provide actionable strategies to tackle challenges such as algorithmic bias, under- representation of diverse groups, and the risk of discrimination in Al decision-making. By incorporating these principles, the guidelines can help AI practitioners navigate the complexities of fairness, privacy, and inclusion, especially in sensitive domains like recruitment, healthcare, and media. To effectively implement these guidelines, co-design workshops with key stakeholders\u2014such as HR professionals, ethicists, legal experts, and underrepresented groups\u2014are vital. These workshops promote collaboration, allowing stakeholders to identify the operationalisable parts of the guidelines that best suit their domain's specific requirements and needs.\nIn Al systems for online recruitment markets, diversity attributes like gender, race, and names are often processed in ways that can either promote fairness or perpetuate harmful bias [27]. Inclusion means that AI fairly evaluates candidates from diverse backgrounds, ensuring equal opportunities for all, while exclusion occurs when Al reinforces existing biases, disadvantaging certain groups in hiring [28].\nSeveral studies highlight that Al in recruitment often exacerbates biases rather than mitigating them, especially when it relies on historical, biased data [28, 29]. Bias in Al algorithms can lead to discriminatory hiring outcomes, particularly against women, racial minorities, and people with disabilities [27, 30]. For instance, studies like [30] illustrate how Al systems, if not designed inclusively, may inadvertently exclude or misjudge applicants with disabilities. Key challenges include the opacity of AI algorithms, which often operate as \"black boxes,\" and the lack of transparency around how Al systems make decisions [27, 29].\nIn addressing these issues, AI ethics guidelines such as those proposed by IEEE and the European Union call for fairness, transparency, and accountability in Al systems. However, many of these guidelines, as seen in studies like [29], primarily focus on broad ethical principles without a dedicated emphasis on D&I. Furthermore, there is often little effort to engage in industrial co-design activities, where stakeholders, including those from underrepresented groups, collaborate to ensure D&I principles are actively integrated into Al development [31, 32]. Most studies, including those on Al recruitment strategies, rely on theoretical frameworks and literature reviews but lack practical, industry-led initiatives to ensure continuous implementation of D&I principles [33].\nThere is clear evidence that Al systems are not free from bias [5], and their unchecked use in job matching and recruitment can lead to discriminatory outcomes [29]. While the existing literature has made efforts to incorporate ethical AI standards, none have focused specifically on D&I in Al guidelines. This leaves a critical gap in ensuring fairness in Al-driven recruitment systems."}, {"title": "III. RESEARCH MOTIVATION", "content": "The lack of real-world validation and co-design activities remains a critical gap. Without involving industry stakeholders and ongoing collaboration, Al tools in recruitment will likely continue to reinforce existing biases, despite adherence to ethical Al guidelines. Addressing these gaps through practical engagement and industry validation is essential for building AI systems that are truly inclusive and capable of enhancing diversity in the workplace [34, 35].\nThere is a pressing need to explore how D&I guidelines can be applied in the context of Al for online recruitment markets. Doing so would help mitigate biases and promote inclusivity, ensuring that AI systems operate fairly for all candidates and hirers. To the best of our knowledge, none of the studies in the literature have involved industry partners in a co-design workshop to create contextualised guidelines for operationalising D&I principles.\nThis motivated us to explore and conduct a co-design workshop with SEEK, a leading online employment marketplace in APAC, serving millions of job seekers and hirers. SEEK is at the forefront of digital recruitment, making it an ideal partner to examine how D&I guidelines in AI can be operationalised in real-world scenarios. By collaborating with a large organisation like SEEK, which integrates Al into its recruitment processes, we aimed to ensure that AI-driven hiring is inclusive, and free from harmful bias.\nThis research investigates two research questions to identify the challenges, requirements and practices required for SEEK to integrate the D&I guidelines in the Al development lifecycle:\nCustomising D&I guidelines for specific sectors like recruitment is crucial because AI tools need to reflect the unique needs and dynamics of each industry. In recruitment, bias in AI can lead to discriminatory hiring practices, impacting underrepresented groups. By tailoring guidelines, we can ensure they address these sector-specific challenges and offer actionable insights for AI-driven recruitment.\nAl professionals often face challenges in applying ethical guidelines due to the complexity and variability of real-world scenarios. Providing sector-specific tools, processes, training, and support will enable them to embed D&I principles more effectively, ensuring Al systems operate fairly and inclusively."}, {"title": "IV. METHODOLOGY", "content": "At the outset of the workshop, the research team sought approval from human research ethics for industry collaboration, data collection, analysis, and publication of the results. The research design was divided into three phases: pre-workshop preparation, activities during the co-design workshop, and post-workshop reflection interviews. Besides detailing each phase, this section outlines the data collection and analysis processes used to assess the workshop's outcomes.\nIn the pre-workshop phase, extensive preparation was undertaken to ensure the workshop was focused and productive on identifying opportunities for systematic D&I in Al improvements in prioritised use cases. A preliminary meeting was held with SEEK's Head of Responsible AI (RAI) to identify key AI use cases where D&I guidelines could be integrated.\nTwo Al-driven recruitment use cases were identified for incorporating D&I guidelines. These use cases represent areas where Al plays a critical role in decision-making, and thus, integrating D&I principles would uplift existing mechanisms to ensure fairness and reduce bias. Below are descriptions of the use cases:\nThe \"Strong Applicant Badge\"5 use case is an Al-driven feature designed to inform jobseekers when they might be a strong fit for an advertised role. Predictions are based on matching criteria between each job advertisement description and factors extracted from the jobseeker's resume or profile at SEEK, such as skills and work experience. The badge is meant to help jobseekers gain confidence to apply for certain jobs. This use case presents potential D&I challenges, as the criteria used to assess compatibility might inadvertently favour certain groups while disadvantaging others if biased data or business decisions are used. Incorporating D&I guidelines into this feature would strengthen existing RAI guardrails that ensure the AI model fairly represents diverse candidates and avoids reinforcing harmful biases.\nThe \"Ads Summarisation\" use case involves the automatic generation of summaries for job advertisements. This AI tool aims to reduce the time and effort required by recruiters to create concise, effective job ads that attract the right candidates. D&I considerations are critical in this process, as the language and tone of job ads can subtly influence which demographics apply for a role. By applying D&I guidelines, we can better determine to what extent the AI Ads summarisation tool was designed to create summaries that are inclusive and free from biased language, ensuring that all potential candidates feel welcome to apply.\nOnce the use cases were defined, the research team utilised a tailored user story template. The research team generated user stories based on the confirmed use case descriptions. These user stories were then structured according to the five pillars of the D&I in AI guidelines. Additionally, the research team reviewed the D&I in Al guidelines and mapped the user stories against the specific guidelines (see Appendix B). The user stories reflected diverse roles representing various attributes, such as gender, ethnicity, and age, to help workshop participants imagine the potential D&I impacts of AI in job- seeking processes.\nThe co-design workshop was held at SEEK's Melbourne Head Office. The participants included product owners, data scientists, and RAI governance experts who have worked in at least one of the selected use cases. The following key activities were conducted during the workshop:\nEach session began with a detailed presentation of one of the selected use cases. These included descriptions of the Al models, workflows, and the ethical challenges related to D&I. The presentations aimed to provide participants with a clear understanding of how D&I issues might arise in these Al-driven recruitment processes.\nParticipants were guided through the process of generating their own user stories, using a structured template. These user stories were designed to identify potential D&I challenges and offer solutions. Pre-generated user stories by the research team were used as a starting point, helping participants consider how the D&I guidelines could be applied within each use case. In software development and product management, a user story is an informal, natural language description of one or more features of a software system. User stories are part of the Agile approach that helps shift the focus from writing about requirements to talking about them [36]. These stories typically follow a simple template:\nWe adopted the tailored user story template for eliciting and capturing D&I in Al requirements proposed by [25]. The template particularly focuses on roles embodied by persons with diverse attributes or that specify diverse system behaviours. The template we utilised for D&I- related user stories is the following:\nThis format helps to identify the key stakeholders, the desired action or outcome, and the underlying motivation behind the request. By employing this user story template, the development team can better address the needs of diverse stakeholders and align their Al systems with the overarching goals of diversity and inclusion.\nThroughout the workshop, participants worked with diverse roles representing various demographic attributes, including gender, ethnicity, and age. This approach enabled participants to explore how Al systems could impact individuals from different backgrounds, ensuring that the D&I guidelines were applied to a wide range of user scenarios.\nAfter generating the user stories (See Figure 1), participants engaged in a group voting process to prioritise which stories should be focused on first. This prioritisation helped determine which identified D&I features or concerns were most important to address in SEEK's AI systems, guiding future development efforts.\nFollowing the workshop, the user stories generated by participants were further analysed by the research team. These user stories were mapped back to the D&I in Al guidelines to ensure that the guidelines were effectively tailored to SEEK's specific recruitment context. This phase also included post- workshop discussions on how the guidelines could be practically integrated into SEEK's existing AI systems and governance processes.\nFinally, a post-workshop reflection was conducted with participants through follow-up interviews approximately after six months. These interviews evaluated the long-term impact of the co-design workshop, gathering feedback on the effectiveness and practical utility of the D&I guidelines. This reflection phase provided critical insights into how well the guidelines were received and considered for embedding into SEEK's AI system's development process and helped identify areas for improvement."}, {"title": "D. Data Collection and Analysis", "content": "Data collection for this study occurred during two key phases: during the co-design workshop and in the post- workshop evaluation. During the workshop, data were collected in the form of:\nIn the post-workshop phase, additional data was collected through interviews. Approximately six months after the workshop, semi-structured interviews were conducted with participants to gather feedback on the long-term effectiveness of the D&I guidelines and their consideration into SEEK's AI systems. The interviews were structured around four key themes: awareness, operationalisation ability, team dynamics, and real-world impact (see Appendix A for interview questions). For each theme, participants were first asked a closed-ended question to quantify their response, followed by an open-ended follow-up question to gather detailed insights. The interviews were conducted via video calls and recorded with participants' consent. A thematic analysis was performed on the qualitative responses, identifying common themes related to D&I awareness, operationalisation, and team dynamics. Quantitative data from the closed-ended questions were summarised to provide a general measure of the workshop's impact. Direct quotes from participants were extracted to illustrate key findings and provide personal perspectives on the workshop's outcomes.\nThe additional benefit of this analysis was that it was helpful in refining and improving the D&I in Al guidelines and ensuring they were aligned with the specific needs of SEEK's recruitment processes. The interviews conducted approximately six months after the workshop were analysed to assess the ongoing integration of D&I guidelines into SEEK's systems. This analysis provided insights into the effectiveness of the co-design approach and highlighted areas where further improvements were needed."}, {"title": "V. RESULTS", "content": "The workshop allowed participants to discuss the use cases, generate user stories, and elaborate the discussion around D&I concerns and improvements within SEEK's AI tools. These stories reflect various roles and highlight specific requirements for improving diversity and inclusion in AI-driven recruitment processes. By synthesising these stories, key requirements emerge for making recruitment more accessible and inclusive across a wide range of candidates. Key roles that emerged include hiring managers, job seekers with specific needs (such as non-native English speakers, people with disabilities, and those requiring visa sponsorship), as well as Al leaders responsible for shaping more inclusive recruitment systems.\nIn terms of the aspects of D&I, accessibility was a major concern, with stories from people with disabilities and non- native English speakers calling for job ads that clearly provide relevant information, ensuring these groups can engage meaningfully with job opportunities. Personalisation was another significant theme, as job seekers expressed the need for AI to tailor job summaries to their individual needs, streamlining their search process. Furthermore, bias mitigation was a recurring topic, with AI leaders emphasising the need for systems that reduce human biases in job ad creation, ensuring fairness across diverse candidates, including gender, race, language proficiency, and disability.\nThe Strong Applicant Badge, which flags job seekers as highly suitable for specific roles based on AI-driven analysis, was discussed in depth. Participants reinforced several key D&I concerns:\nParticipants highlighted the challenges of gathering representative training data for minority groups, as collecting protected attributes in the hiring process is legally sensitive. Although organisations can request jobseekers this data for specific research, small sample sizes and the bias of self- reporting remain significant obstacles.\nThe lack of access to protected attribute data limits organisations' ability to accurately measure diversity and promote inclusion. Participants also discussed the ethical use of inferred data and its limitations in fairness assessments.\nThe importance of both internal and external transparency around Al models and their driving factors was emphasised as another key consideration, especially given that latent variables may unknowingly influence the model's behaviour and outcomes.\nThe impact of seeing (or not seeing) a Strong Applicant Badge was briefly discussed, highlighting the psychological and cognitive bias influence this could have on a candidate's decision to apply for a job.\nAfter reflecting on the key D&I concerns and comparing them with existing guidelines, participants were asked to provide actionable recommendations for project leaders to enhance D&I efforts with specific goals in mind. Key recommendations included:\nConducted additional stakeholder engagement surveys to better understand how minority groups perceive job applications and their confidence in applying.\nThe second use case focused on the automation of job ad summaries. In this case, participants highlighted the following D&I concerns:\nAccuracy and false positive rates are crucial for scalability and efficient human resource allocation. Job ads flagged as sensitive by bias detection mechanisms can lead to high and inefficient manual efforts in curating summaries if not carefully managed.\nThe discussion highlighted that language models often struggle with gendered languages (e.g., French), making it more challenging to create neutral summaries for roles that may be linguistically gendered in some languages.\nThe AI system is evaluated based on how well it replicates human-generated ad summaries, which means it can unintentionally reinforce unconscious human biases.\nParticipants reflected on the identified D&I concerns and proposed the following key recommendations for project leaders:\nLeaveraging synthetic training data that includes both \"good\" and \"bad\" examples to help mitigate human bias."}, {"title": "B. Post Workshop Reflection Interviews", "content": "This section synthesises feedback from eight SEEK participants who attended the workshop (and consented to being interviewed) aimed at enhancing their awareness and ability to implement D&I in AI within their product design and governance workflows. The workshop took place approximately six months prior to these interviews, and the purpose of these interviews is to evaluate its long-term impact based on four key themes as follows:\nSix out of the eight participants reported an increase in their awareness of D&I in Al principles because of the workshop. Participants generally attributed this increase to the dedicated time spent reflecting on these issues and engaging in facilitated discussions. Several noted that the workshop allowed them to think more deeply about the impacts of AI on different stakeholders.\nFor example, one participant noted that the workshop provided valuable time to reflect on D&I, which they rarely do in their regular work. Another participant mentioned how their team expanded the concept of fairness to incorporate D&I principles in their service evaluations after the workshop. Additionally, one participant appreciated the diverse perspectives offered by external facilitators (i.e. researchers), which deepened their understanding of D&I considerations.\nHowever, some participants had difficulty recalling specific details of the workshop. One participant mentioned that they had an \u201caha\u201d moment during the workshop but could not recall the exact insight that increased their awareness. Another participant pointed out that, although they already had a high level of awareness of Responsible Al prior to the workshop, the session further reinforced their understanding of D&I by highlighting new perspectives.\nWhile individual awareness increased for most participants, a few noted that prioritising D&I in their daily activities is challenging. One participant mentioned that while their awareness had increased, the practical application of D&I principles within their team remained limited, as satisfying other functional requirements took precedence.\nWhile six participants reported increased awareness, only three felt that their ability to operationalise D&I principles had improved. Several participants expressed challenges in translating the workshop's concepts into actionable steps within their workflows. For instance, one participant stated that while they were aware of the discussions around mitigating D&I risks, they were unclear on how to enforce these strategies in practice. Another participant highlighted that their team struggled to balance the operationalisation of D&I principles with business priorities, especially when these principles did not directly translate to revenue generation.\nThere were a few instances where operationalisation was successful, for example one participant mentioned that their team had begun to frame user questions around D&I in ways they wouldn't have considered prior to the workshop, though broader operationalisation challenges remained.\nSeveral barriers to operationalising D&I principles were identified. A common issue was the lack of demographic data needed to measure D&I impacts on minorities. Time and business pressures usually emerge as significant barriers in practice. One participant mentioned that while their team had identified potential D&I concerns, determining prioritisation to better understand these concerns was a challenge.\nAdditionally, none of the participants could recall seeing the workshop output notes and recommendations after the workshop, this may have contributed to the challenge of lack of sustained support or follow up to take action, after gaining awareness and insights for increasing D&I considerations.\nMost participants (seven out of eight) indicated that they would endorse the introduction of a clear, guided business process for D&I guidelines at SEEK. One participant explained that their team already applied fairness principles that aligned with D&I, and they would support formalising these efforts into a broader process. Another participant emphasised the importance of upskilling SEEK's RAI champion within each team on D&I guidelines to initiate regular reviews of projects, ensuring that D&I principles are consistently considered. This aligns with the D&I in Al guidelines, which emphasise the crucial role of Al stewards in maintaining accountability and promoting ethical AI practices across teams.\nDespite this endorsement, actual changes in team dynamics post-workshop were limited. Many participants indicated that they had not observed significant shifts in their teams' approach to operationalising D&I. One participant mentioned that, although they valued the workshop, they hadn't seen practical changes within their team. Another participant noted that while they would support the introduction of formal D&I processes, the perception that such processes are time- consuming could be a barrier to widespread adoption. A speculative reason for these challenges could be that implementing practical changes to existing business processes, or altering team structures, requires strong enforcement and clear direction from leadership. Without explicit management endorsement, such as incorporating D&I practices into standard business processes or mandating compliance as part of Responsible AI governance, teams may not feel the urgency or authority to prioritise these changes\nSome participants observed a lack of engagement from their teams. One participant noted that while they and another colleague were keen to adopt D&I principles, some of their team members viewed RAI training as a burden and were less enthusiastic about engaging with D&I concepts. This highlights the need for continued RAI and D&I culture strengthening among technical teams. This feedback also entails the necessity of broader team involvement and possibly more engaging formats to encourage participation in D&I rituals.\nDespite having a mature RAI framework, RAI training and processes to assess and monitor AI systems along AI principles, including fairness, the workshop results highlighted D&I operationalisation challenges for:\nWhile participants (five out of eight) felt that the workshop contributed positively to D&I discussions within SEEK, specific, tangible, and long-term improvements require continuous engagement. One participant mentioned that the workshop helped to provide a systematic view of how D&I could be incorporated into the AI lifecycle, allowing their team to think more comprehensively about these issues. Several participants suggested that ongoing workshops or follow-up sessions could help maintain the momentum from the initial workshop. One participant proposed having more explicit follow-up sessions to ensure that discussions lead to concrete actions. Another participant mentioned the importance of involving more people across teams, especially those less familiar with D&I, to broaden the workshop's impact.\nDespite the positive reflections on the workshop's impact, many participants did not see significant tangible outcomes. One participant noted that they could not recall specific actions taken as a result of the workshop. Another participant mentioned that while D&I principles were being discussed within SEEK, they could not remember any direct outcomes or improvements stemming from the workshop itself."}, {"title": "C. Insights from SEEK's RAI Leadership", "content": "In addition to conducting post-workshop reflection interviews, we also sought insights from SEEK's Responsible Al leadership to gather their thoughts on the effectiveness of the workshop and how D&I principles are being integrated into ongoing AI practices within the organisation.\nSEEK'S RAI Leadership highlights that the sustainable integration of D&I guidelines into Al governance is a critical milestone for organisations aiming to enhance D&I maturity. This requires a systematic approach, ensuring that D&I principles are embedded in business processes and RAI frameworks rather than being treated as isolated initiatives. A key insight is that D&I workshops alone are insufficient for cultural transformation; the change must permeate organisational culture to be sustainable.\nMoreover, RAI leadership emphasises the challenge of balancing multiple AI ethics guidelines, noting that it is impractical to apply all guidelines in every use case. Organisations should focus on quickly identifying high impact use cases that require deeper D&I considerations. By doing so, they can prioritise D&I efforts where they will have the most significant effect, ensuring that Al systems are not only fair but also human-centric. Additionally, organisations should go beyond risk management and unlock the potential benefits that D&I for AI can bring.\nTo operationalise these insights, actionable recommendations include consolidating a database of context-specific user stories to guide D&I discussions, updating AI Impact Assessment processes to integrate D&I, and institutionalising co-design workshops. Engaging external D&I experts can also bring fresh perspectives and ensure continuous improvement. These steps will help organisations foster a more inclusive, ethical AI landscape while maximising the potential benefits of D&I in AI."}, {"title": "VI. DISCUSSION", "content": "The results from the co-design workshop and post- workshop reflection interviews provide valuable insights into the operationalisation of D&I in Al systems within the online employment context, particularly in SEEK's Al-powered platform. The key takeaway is an increased awareness among participants about the challenges of embedding D&I principles into Al workflows, but the results also highlight significant obstacles in translating this awareness into actionable change. These findings offer both confirmations of existing literature and new insights into how D&I principles can be more effectively implemented in real-world scenarios.\nThe workshop and subsequent interviews demonstrate that participants gained a clearer understanding of the complexity of D&I issues in AI-driven recruitment, particularly in terms of bias detection, data limitations, and the ethical considerations around transparency and explainability. This increased awareness reflects findings in the broader literature that highlight Al's potential to exacerbate biases if not carefully managed [27", "30": ".", "28": ".", "37": ".", "29": ".", "black boxes,\" can perpetuate historical biases present in the training data. Participants also emphasised the need to move beyond the typical focus on bias detection and algorithmic fairness, advocating for the use of D&I guidelines to actively promote greater inclusion.\nThe workshop's use of diverse roles in user stories to simulate the impact of AI on different user groups also aligns with literature advocating for human-centred design in Al systems [38": ".", "26": "."}]}