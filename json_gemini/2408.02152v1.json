{"title": "Generative Retrieval with Few-shot Indexing", "authors": ["Arian Askari", "Chuan Meng", "Mohammad Aliannejadi", "Zhaochun Ren", "Evangelos Kanoulas", "Suzan Verberne"], "abstract": "Existing generative retrieval (GR) approaches\nrely on training-based indexing, i.e., fine-\ntuning a model to memorise the associations\nbetween a query and the document identifier\n(docid) of a relevant document. Training-based\nindexing has three limitations: high training\noverhead, under-utilisation of the pre-trained\nknowledge of large language models (LLMs),\nand challenges in adapting to a dynamic docu-\nment corpus. To address the above issues, we\npropose a novel few-shot indexing-based GR\nframework (Few-Shot GR). It has a novel few-\nshot indexing process, where we prompt an\nLLM to generate docids for all documents in a\ncorpus, ultimately creating a docid bank for the\nentire corpus. During retrieval, we feed a query\nto the same LLM and constrain it to generate\na docid within the docid bank created during\nindexing, and then map the generated docid\nback to its corresponding document. Few-Shot\nGR relies solely on prompting an LLM without\nrequiring any training, making it more efficient.\nMoreover, we devise few-shot indexing with\none-to-many mapping to further enhance Few-\nShot GR. Experiments show that Few-Shot GR\nachieves superior performance to state-of-the-\nart GR methods that require heavy training.", "sections": [{"title": "1 Introduction", "content": "Generative retrieval (GR) has emerged as a novel\nparadigm in information retrieval (IR). Unlike the traditional IR paradigm, decoupling\nindexing and retrieval processes, the paradigm\nof GR consolidates both processes into a single\nmodel. Studies in GR typically\nregard indexing and retrieval as training and infer-\nence processes, respectively. The indexing (train-\ning) process typically trains a seq2seq model to map queries to the docids cor-\nresponding to relevant documents, using extensive\ntraining data of query-docid pairs. In the retrieval (inference) process, the\ntrained model takes a query text as input and di-\nrectly generates potentially relevant docids.\nLimitations. Existing studies typically rely on\ntraining-based indexing to memorise the associa-\ntions between a query and its docid. The nature\nof training-based indexing results in three limita-\ntions: (i) The approach has a high training over-\nhead . Existing studies typically\nuse an LLM (or a pre-trained language model) as the backbone\nand then fine-tune it with a new learning objec-\ntive: mapping query text to docids. Fine-tuning\nan LLM with a new objective demands large-scale\nquery-docid pairs, considerable time, and numer-\nous GPUs. (ii) The approach does not make effec-\ntive use of LLMs' pre-trained knowledge. Because\nthere is a gap between the learning objectives of\nLLMs pre-training (natural language generation)\nand GR fine-tuning (query-docid mapping), fine-\ntuning an LLM with GR's objective may cause the\nLLM to forget its pre-trained knowledge . Little research has explored mainly using\nLLMs' pre-trained knowledge for GR indexing,\nwithout heavy training. (iii) It\nis challenging to handle a dynamic corpus. Train-\ning a model to memorise new documents inevitably\nleads to forgetting old ones. While\nexisting studies propose solutions to mitigate this\nissue, the problem persists\ndue to the inherent nature of training.\nA new perspective on GR. To address the above\nlimitations, we propose a few-shot indexing-based\nGR framework (Few-Shot GR). Unlike previous\nGR approaches based on training-based indexing,\nFew-Shot GR has a few-shot indexing process,\nwhere we index a document corpus without requir-\ning any training. Specifically, in the few-shot index-"}, {"title": "2 Methodology", "content": "Few-Shot GR has two essential steps: (i) few-shot\nindexing with one-to-many mapping, and (ii) re-\ntrieval with constrained beam search.\nFew-shot indexing with one-to-many mapping.\nGiven a corpus $C = \\{d_1,\\ldots,d_i,\\ldots,d_{|C|}\\}$\nwith\n$|C|$ documents, this step uses an LLM to generate\n$n$ distinct free-text docids $\\{id_1,\\cdots,id_j,\\ldots,id_n\\}$\nfor each document $d$ in the corpus $C$. Ultimately,\nwe create a docid bank $B$ that contains docids for\nall documents ($n$ docids for each document) in $C$.\nFollowing the GR literature which shows that replac-\ning documents with their corresponding pseudo\nqueries during indexing results in better retrieval"}, {"title": "3 Experimental setup", "content": "Datasets. We use NQ320K, a version of Natural\nQuestions (NQ), has\nbeen widely used for GR evaluation. NQ320K\nconsists of 320k relevant query-document pairs,\n100k documents, and 7,830 test queries. Following\nrecent studies, we fetch and process NQ320K using the script re-\nleased by Wang et al. (2022),\u00b9 to ensure our results\nare comparable with previous work.\nBaselines. We use non-GR and GR baselines. Fol-\nlowing Lee et al. (2023), we use the following\nnon-GR baselines: BM25, DPR, ANCE and SentenceT5 and GTR-base. We use the\nfollowing GR baselines (training-based indexing):\n(i) SEAL  learns to gen-\nerate n-grams-based docids and applies FM-in- (ii) DSI learns to generate numeric identifiers.\n(iii) DSI-QG augments DSI\ntraining by using pseudo queries; we replicate\nDSI-QG using the pseudo query generator provided\nby the original paper. (iv) DSI-QG uses\nthe pseudo query generator from InPars. (v) GenRET learns\nto assign numeric docids based on an auto-encod-\ning scheme. (vi) TOME  learns to\ngenerate document URLs. (vii) GLEN learns dynamic lexical docids.\nEvaluation metrics. In line with recent GR re-\nsearch , we adopt\nRecall@1, Recall@10 and MRR@100.\nImplementation details. We equip Few-Shot GR\nwith llama-3-8B-Instruct for indexing and retrieval.\nWe generate 10 docids per document during few-\nshot indexing. We set the maximum and minimum\nlengths for docid generation to 15 and 3 tokens, re-\nspectively. We employ the query generator from In-\nPars for generating pseudo\nqueries in Equation 1. We conduct parameter tun-\ning on the training set of NQ320K."}, {"title": "4 Result & analysis", "content": "Comparison with baselines. Table 1 shows the\nretrieval quality of Few-Shot GR and all baselines\non NQ320K. The leading observation is that Few-\nShot GR outperforms all state-of-the-art baselines\nacross all metrics, except for GenRET in terms\nof Recall@10. This indicates that our proposed\nfew-shot indexing is a highly effective new GR\nparadigm compared to training-based indexing.\nIt suggests that\nselecting an effective LLM is another critical factor\ncontributing to the success of Few-Shot GR.\nEfficiency of indexing and retrieval. Table 3 presents the indexing time and retrieval latency\nfor Few-Shot GR compared to two training-based\nGR methods, DSI-QG and GenRET. The time cost of in-\ndexing is measured in hours (hr) on the training\nset of NQ320K, while the retrieval query latency\nis measured in milliseconds (ms) on the test set\nof NQ320K. We perform all measurements on a\nsingle A100 GPU (80GB) with a batch size of 16,\nexcept for the indexing (training) of GenRET. We\ninquired with the authors of GenRET  about GenRET's indexing (training) time,\nand they indicated it took 7 days on 100 A100\nGPUs. This implies it may take approximately\n16,800 hours on a single A100 GPU. We found\nthat Few-Shot GR is significantly more efficient\nin indexing than existing GR methods. Also, Few-\nShot GR achieves similar retrieval query latency\ncompared to existing GR methods."}, {"title": "5 Conclusions", "content": "We have proposed a new, efficient, and effective\nGR paradigm, Few-Shot GR, featuring a novel few-\nshot indexing process that solely relies on prompt-\ning an LLM to record associations between queries\nand their docids, eliminating the need for any train-\ning steps. Given a query, Few-Shot GR conducts\nretrieval by promoting the LLM used for index-\ning and constraining it to generate a docid within\nthe recorded docid created in indexing. We have\ndesigned few-shot indexing with one-to-many map-\nping to further enhance Few-Shot GR's indexing.\nExperimental results demonstrate that GR achieves\nsuperior performance to state-of-the-art GR meth-\nods that require heavy training."}, {"title": "Limitations", "content": "We acknowledge the limitations of our work and\noutline avenues for future research. First, we only\nverify Few-Shot GR's effectiveness on one dataset,\nNQ320k. It is valuable to investigate Few-Shot GR\n's performance on other ranking datasets, such as\nMS MARCO and BEIR . Second, existing work has shown\nthat GR methods using training-based indexing per-\nform worse as the corpus size increases. Since the dataset we used in our pa-\nper (NQ320K) has a document corpus with only\n100k documents, we have yet to validate the effec-\ntiveness of Few-Shot GR on a document corpus\nwith millions of documents. It is worthwhile to\ninvestigate whether Few-Shot GR's effectiveness\nwould generalise to a large-scale document corpus.\nThird, we claim that Few-Shot GR can potentially\ndeal with a dynamic document corpus better than\ntraining-based indexing, because of Few-Shot GR's\nnon-training nature. This is because Few-Shot GR\ncan easily add or remove docids in the docid bank\ncreated during few-shot indexing, and it does not\nsuffer from the issue of forgetting. Several exist-\ning GR methods that use training-based indexing\nattempt to address this issue. It would be valuable to design experiments\nin the future to compare Few-Shot GR with these\nmethods."}]}