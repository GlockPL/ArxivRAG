{"title": "Generative Retrieval with Few-shot Indexing", "authors": ["Arian Askari", "Chuan Meng", "Mohammad Aliannejadi", "Zhaochun Ren", "Evangelos Kanoulas", "Suzan Verberne"], "abstract": "Existing generative retrieval (GR) approaches\nrely on training-based indexing, i.e., fine-\ntuning a model to memorise the associations\nbetween a query and the document identifier\n(docid) of a relevant document. Training-based\nindexing has three limitations: high training\noverhead, under-utilisation of the pre-trained\nknowledge of large language models (LLMs),\nand challenges in adapting to a dynamic docu-\nment corpus. To address the above issues, we\npropose a novel few-shot indexing-based GR\nframework (Few-Shot GR). It has a novel few-\nshot indexing process, where we prompt an\nLLM to generate docids for all documents in a\ncorpus, ultimately creating a docid bank for the\nentire corpus. During retrieval, we feed a query\nto the same LLM and constrain it to generate\na docid within the docid bank created during\nindexing, and then map the generated docid\nback to its corresponding document. Few-Shot\nGR relies solely on prompting an LLM without\nrequiring any training, making it more efficient.\nMoreover, we devise few-shot indexing with\none-to-many mapping to further enhance Few-\nShot GR. Experiments show that Few-Shot GR\nachieves superior performance to state-of-the-\nart GR methods that require heavy training.", "sections": [{"title": "1 Introduction", "content": "Generative retrieval (GR) has emerged as a novel\nparadigm in information retrieval (IR) (Zeng et al.,\n2024b,a; Kuo et al., 2024; Li et al., 2024c,b).\nUnlike the traditional IR paradigm, decoupling\nindexing and retrieval processes, the paradigm\nof GR consolidates both processes into a single\nmodel (Tay et al., 2022). Studies in GR typically\nregard indexing and retrieval as training and infer-\nence processes, respectively. The indexing (train-\ning) process typically trains a seq2seq model (Raf-\nfel et al., 2020) to map queries to the docids cor-\nresponding to relevant documents, using extensive\ntraining data of query-docid pairs (Zhuang et al.,\n2022). In the retrieval (inference) process, the\ntrained model takes a query text as input and di-\nrectly generates potentially relevant docids.\nLimitations. Existing studies typically rely on\ntraining-based indexing to memorise the associa-\ntions between a query and its docid. The nature\nof training-based indexing results in three limita-\ntions: (i) The approach has a high training over-\nhead (Li et al., 2024c). Existing studies typically\nuse an LLM (or a pre-trained language model) (Lee\net al., 2023; Li et al., 2024a) as the backbone\nand then fine-tune it with a new learning objec-\ntive: mapping query text to docids. Fine-tuning\nan LLM with a new objective demands large-scale\nquery-docid pairs, considerable time, and numer-\nous GPUs. (ii) The approach does not make effec-\ntive use of LLMs' pre-trained knowledge. Because\nthere is a gap between the learning objectives of\nLLMs pre-training (natural language generation)\nand GR fine-tuning (query-docid mapping), fine-\ntuning an LLM with GR's objective may cause the\nLLM to forget its pre-trained knowledge (Li et al.,\n2024c). Little research has explored mainly using\nLLMs' pre-trained knowledge for GR indexing,\nwithout heavy training (Li et al., 2024c). (iii) It\nis challenging to handle a dynamic corpus. Train-\ning a model to memorise new documents inevitably\nleads to forgetting old ones (Li et al., 2024b). While\nexisting studies propose solutions to mitigate this\nissue (Mehta et al., 2022; Kishore et al., 2023; Chen\net al., 2023; Guo et al., 2024), the problem persists\ndue to the inherent nature of training.\nA new perspective on GR. To address the above\nlimitations, we propose a few-shot indexing-based\nGR framework (Few-Shot GR). Unlike previous\nGR approaches based on training-based indexing,\nFew-Shot GR has a few-shot indexing process,\nwhere we index a document corpus without requir-\ning any training. Specifically, in the few-shot index-"}, {"title": "2 Methodology", "content": "Few-Shot GR has two essential steps: (i) few-shot\nindexing with one-to-many mapping, and (ii) re-\ntrieval with constrained beam search.\nFew-shot indexing with one-to-many mapping.\nGiven a corpus $C = \\{d_1,\\ldots,d_i,\\ldots,d_{|C|}\\}$\nwith |C| documents, this step uses an LLM to generate\nn distinct free-text docids $\\{id_1,\\ldots,id_j,\\ldots,id_n\\}$\nfor each document d in the corpus C. Ultimately,\nwe create a docid bank B that contains docids for\nall documents (n docids for each document) in C.\nFollowing the GR literature (Zhuang et al., 2022;\nPradeep et al., 2023), which shows that replac-\ning documents with their corresponding pseudo"}, {"title": "3 Experimental setup", "content": "Datasets. We use NQ320K, a version of Natural\nQuestions (NQ) (Kwiatkowski et al., 2019), has\nbeen widely used for GR evaluation (Lee et al.,\n2023; Sun et al., 2024; Tay et al., 2022). NQ320K\nconsists of 320k relevant query-document pairs,\n100k documents, and 7,830 test queries. Following\nrecent studies (Lee et al., 2023; Sun et al., 2024),\nwe fetch and process NQ320K using the script re-\nleased by Wang et al. (2022),\u00b9 to ensure our results\nare comparable with previous work.\nBaselines. We use non-GR and GR baselines. Fol-\nlowing Lee et al. (2023), we use the following\nnon-GR baselines: BM25 (Robertson et al., 2009),\nDPR (Karpukhin et al., 2020), ANCE (Xiong\net al., 2021) and SentenceT5 (Ni et al., 2022a),\nand GTR-base (Ni et al., 2022b). We use the"}, {"title": "4 Result & analysis", "content": "Comparison with baselines. Table 1 shows the\nretrieval quality of Few-Shot GR and all baselines\non NQ320K. The leading observation is that Few-\nShot GR outperforms all state-of-the-art baselines\nacross all metrics, except for GenRET in terms\nof Recall@10. This indicates that our proposed\nfew-shot indexing is a highly effective new GR\nparadigm compared to training-based indexing.\nThe impact of # docids generated per document.\nFigure 2 shows Few-Shot GR's performance w.r.t.\n# generated docids per document during few-shot\nindexing; we equip Few-Shot GR with llama-3-8B-\nInstruct or Zephyr-7B-B (Tunstall et al., 2023). We\nfound that Few-Shot GR's performance improves\nas it generates more docids per document during\nindexing, reaching saturation when generating 10\ndocids per document. E.g., when using Llama-3,\nincreasing the number of generated docids from\n1 to 10 leads to an improvement of 27.2% in Re-\ncall@10. It suggests that our devised \u201cone-to-many\nmapping\u201d is a key factor in the success of few-shot\nindexing. Table 4 in the appendix gives an example\nof 10 distinct docids generated by Few-Shot GR\nfor a specific document.\nThe impact of LLMs choices. Table 2 shows Few-\nShot GR's performance using different LLMs; here\nwe compare T5-base, Zephyr-7B-\u00df, and llama-3-\n8B-Instruct. We found that Llama-3-8B-Instruct"}, {"title": "5 Conclusions", "content": "We have proposed a new, efficient, and effective\nGR paradigm, Few-Shot GR, featuring a novel few-\nshot indexing process that solely relies on prompt-\ning an LLM to record associations between queries\nand their docids, eliminating the need for any train-\ning steps. Given a query, Few-Shot GR conducts\nretrieval by promoting the LLM used for index-\ning and constraining it to generate a docid within\nthe recorded docid created in indexing. We have\ndesigned few-shot indexing with one-to-many \u0442\u0430\u0440-\nping to further enhance Few-Shot GR's indexing.\nExperimental results demonstrate that GR achieves\nsuperior performance to state-of-the-art GR meth-\nods that require heavy training."}, {"title": "Limitations", "content": "We acknowledge the limitations of our work and\noutline avenues for future research. First, we only\nverify Few-Shot GR's effectiveness on one dataset,\nNQ320k. It is valuable to investigate Few-Shot GR\n's performance on other ranking datasets, such as\nMS MARCO (Bajaj et al., 2016) and BEIR (Thakur\net al., 2021). Second, existing work has shown\nthat GR methods using training-based indexing per-\nform worse as the corpus size increases (Pradeep\net al., 2023). Since the dataset we used in our pa-\nper (NQ320K) has a document corpus with only\n100k documents, we have yet to validate the effec-\ntiveness of Few-Shot GR on a document corpus\nwith millions of documents. It is worthwhile to\ninvestigate whether Few-Shot GR's effectiveness\nwould generalise to a large-scale document corpus.\nThird, we claim that Few-Shot GR can potentially\ndeal with a dynamic document corpus better than\ntraining-based indexing, because of Few-Shot GR's\nnon-training nature. This is because Few-Shot GR\ncan easily add or remove docids in the docid bank\ncreated during few-shot indexing, and it does not\nsuffer from the issue of forgetting. Several exist-\ning GR methods that use training-based indexing\nattempt to address this issue (Mehta et al., 2022;\nKishore et al., 2023; Chen et al., 2023; Guo et al.,\n2024). It would be valuable to design experiments\nin the future to compare Few-Shot GR with these\nmethods."}, {"title": "A Appendix", "content": "Case study of docids generated by Few-Shot GR.\nTable 4 gives an example of 10 distinct docids gen-\nerated by Few-Shot GR for a specific document in\nNQ320K. It shows that docids generated by Few-\nShot GR are various."}]}