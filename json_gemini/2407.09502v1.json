{"title": "From Text to Life: On the Reciprocal Relationship between Artificial Life and\nLarge Language Models", "authors": ["Eleni Nisioti", "Claire Glanois", "Elias Najarro", "Andrew Dai", "Elliot Meyerson", "Joachim Winther Pedersen", "Laetitia Teodorescu", "Conor F. Hayes", "Shyam Sudhakaran", "Sebastian Risi"], "abstract": "Large Language Models (LLMs) have taken the field of AI by\nstorm, but their adoption in the field of Artificial Life (ALife)\nhas been, so far, relatively reserved. In this work we investi-\ngate the potential synergies between LLMs and ALife, draw-\ning on a large body of research in the two fields. We explore\nthe potential of LLMs as tools for ALife research, for exam-\nple, as operators for evolutionary computation or the genera-\ntion of open-ended environments. Reciprocally, principles of\nALife, such as self-organization, collective intelligence and\nevolvability can provide an opportunity for shaping the devel-\nopment and functionalities of LLMs, leading to more adap-\ntive and responsive models. By investigating this dynamic\ninterplay, the paper aims to inspire innovative crossover ap-\nproaches for both ALife and LLM research. Along the way,\nwe examine the extent to which LLMs appear to increas-\ningly exhibit properties such as emergence or collective in-\ntelligence, expanding beyond their original goal of generat-\ning text, and potentially redefining our perception of lifelike\nintelligence in artificial systems.", "sections": [{"title": "Introduction", "content": "Artificial life (ALife) refers to the study and creation of life-\nlike systems using computer models, algorithms, and, some-\ntimes, physical hardware. Its goal is to understand the fun-\ndamental principles of living systems, to explore the pro-\ncesses underlying life, and to develop new forms of life that\nmay exhibit lifelike behaviours. ALife research typically in-\nvolves simulating and studying various aspects of biological\nlife, such as evolution, self-organization, adaptation, repro-\nduction, and emergence. These simulations may range from\nsimple models of individual organisms to complex ecosys-\ntems with multiple interacting species [60, 109, 4]. Re-\ncently, the Artificial Intelligence (AI) community has started\nto increasingly embrace such ALife concepts (see Fig. 1).\nMuch of the current focus in Al research has shifted to\nLarge language models (LLMs). Beyond their impressive\nability to generate text in natural language, LLMs are part\nof an emerging debate on their ability to act as agents that\nemulate aspects of human behaviour. Computationally, both\nALife forms and LLMs can be seen as autoregressive models\ncapable of processing information and producing complex\nsequences of patterns. However, modern neural network\narchitectures such as the Transformer [225]-the architec-\nture underpinning LLMs- have been shown to have suf-\nficient computational expressivity to, not only model com-\nplex sequences, but also to serve as general-purpose comput-\ners [76, 128]. This parallelism between the information pro-\ncessing mechanisms of artificial life-forms and transform-\ners, particularly their concurrent processing capabilities, has\nbeen underexplored in the ALife literature 1.\nThis paper takes a deeper look into the current and po-\ntential\ninterplay between these two fields of research, in-\nvestigating the mutual benefits and potential advancements\narising from their intersection. First, we aim to uncover\nhow LLMs can be harnessed as potent tools within ALife\nresearch, for example by enacting powerful new mutation\noperators for evolutionary computation. Second, we believe\nthat the principles of ALife can reciprocally illuminate and\nhelp to expand the functionalities of LLMs. Finally, the\nrecent emergence of agents powered by LLMs with di-\nverse architectures, sensory modalities, or even social struc-\ntures known as LLM Agents- raises a provocative ques-\ntion: could LLM agents themselves be considered a form\nof ALife? While the view of LLMs as stochastic parrots\nis a sensible and important critique [21], considering LLM"}, {"title": "Background", "content": "Artificial Life\nWhile a review of ALife is beyond our scope (cf. [60, 109,\n4]), we aim here to provide relevant background on funda-\nmental questions in this field. The study of biological life\nhas been dominated by two distinct perspectives: (a) The\nevolutionary perspective, exemplified by Neo-Darwinism,\nstates that a system implements life as long as it exhibits\nthe properties of multiplication, variation, and heredity and\ncan be extended to consider other processes, such as de-\nvelopment and symbiogenesis [105]. This paradigm fo-\ncuses on the evolution of open-endedness and/or complex-\nity, given basic evolutionary operators [205, 17]. Exam-\nples include systems of self-replicating, evolving individu-\nals such as Terraria [182] and Avida [154]. (b) The eco-\nlogical perspective, exemplified by the autopoietic systems\npopularized by Varela [224, 223], focusing on the ability\nof individuals, viewed as structures engaged in energy and\nmatter exchange with their environment, to maintain them-\nselves in the face of environmental perturbations. Examples\nsystems here include Cellular Automata [46] and Artificial\nChemistries [69], which examine how self-replication mech-\nanisms emerge from interactions among non-living compo-\nnents. What is the objective of ALife as a scientific disci-\npline? The answer is two-fold: (a) understanding the essen-\ntials of life by simulating bottom-up processes that imitate\nthe biological ones, i.e. ALife as the study of life-as-it-is.\n(b): building systems that have lifelike properties and can\nbe viewed as life, independently of their substrate, i.e. AL-\nife as the study of life-as-it-could-be [116, 165, 183].\nLarge Language Models\nLanguage models (LMs) can be understood as probabil-\nity distributions over sequences of text elements [231, 22].\nCommonly, LMs aim to predict the next text element, called\na token, conditioned on the previous ones [30]. This training\napproach yields generative models of language: tokens are\nsampled one after the other \u2014i.e. autoregressively- based\non the learned distribution. The tipping point in Language\nModelling research occurred with the arrival of the mas-\nsively parallel Transformer architecture[225]\u00b2, whose self-\nattention mechanism allowed both larger-scale training and\nlong-range dependency modelling, and offered compelling\nperformance. The recent discovery of empirical scaling\nlaws [108, 90] -predicting test perplexity [101] as a power\nlaw of a model's and dataset's size, and correlating perplex-\nity with downstream task performance-, spurred researchers\nto train large LMs (LLMs)\u00b3 to the 100s of billion parame-\nters and to the trillion tokens [30, 180], requiring massive\ncompute and internet-scale data. Some emergent capabili-\nties have been discussed [239, 194], reminiscent of complex\nsystems [241], such as zero- or few-shot learning [30],4\nSteering LMs towards human-preferred responses solely\nthrough next-token prediction proved challenging, so ad-"}, {"title": "LLMS AS TOOLS FOR ALIFE", "content": "LLMs can find diverse applications that stretch far beyond\ntheir obvious use in text generation. Here we review existing\nworks that incorporate LLMs in ALife studies, organizing\nthem into five main threads of research.\nArtificial Evolution and LLMs\nArtificial evolution is a powerful optimization algorithm for\nexploring arbitrary search spaces but comes with the down-\nside of slow exploration due to random mutations and un-\ninformed cross-over. This has so far limited the appli-\ncation domains of techniques such as Genetic Program-\nming [111, 121]. Here we highlight different ways in which\nthe ALife community incorporated LLMs in evolution.\nEvolution through Large Models (ELM) employed an\nLLM as an intelligent mutation operator for evolving pro-\ngrams that control robotic morphologies [121]. The LLM\nembodies the ability of humans to intentionally modify pro-\ngrams to achieve a desired functionality. This is achieved\nby fine-tuning the LLM on data available in online code\nrepositories, where humans employ version control to log\ncode modifications, accompanying each modification with\nan explanation in natural language. By replacing ran-\ndom mutations with intelligent ones, ELMs can explore\nrobotic morphologies much quicker than genetic program-\nming and can zero-shot produce functional morphologies\nfor a user-defined terrain. Another example is the LMX ap-\nproach [139], which employs LLMs as intelligent, domain-\nindependent cross-over operators by leveraging their in-\ncontext learning abilities. The LLM is prompted with ex-\namples of genotypes and, due to its pattern-completion abil-\nity, acts as a probabilistic model for generating offspring,\nakin to models employed in classical evolutionary strategies,\nsuch as CMA-ES [87]. EvoPrompting [42] and Prompt-\nBreeder [68] employ LLMs as both mutation and cross-\nover operators and showcase that evolving the prompts for\nin-context learning can further improve performance. In\na more holistic approach, EvoLLM models the LLM as a\nblack box that embodies an end-to-end evolutionary algo-"}, {"title": "Environment generation through LLMs", "content": "Environments play a central role in open-ended evolution,\nas they set the limit for the phenotypic complexity a sys-\ntem can exhibit [207, 235]. Generating useful environments\nfor studying ALife is as challenging a problem as creating\nagents that solve them [49]. Techniques such as Procedu-\nral Content Generation [198] can automate this process, but\nface a long-standing challenge; balancing the diversity and\noriginality of environments with controllability.\nRecent works in ALife started exploring the automated\ngeneration of environments through LLMs [112], by en-\ncoding pixels as text. Todd et al. [220] explored the po-\ntential of LLMs in PCG by fine-tuning an LLM on a two-\ndimensional puzzle game and showcased that, despite lack-\ning biases for spatial arrangements that previous PCG mod-\nels such as CNNs and CA exploited, LLMs can create di-\nverse and playable games levels Sudhakaran et al. [214] in-\ntroduced MarioGPT for generating diverse and controllable\nlevels for Super Mario by employing Novelty Search and\nconditioning the LLM's output on a textual description of\nthe level. Zala et al. [262] incorporated LLMS into the cur-\nriculum learning paradigm, where the performance of agents\nis fed back to the environment generation process to avoid its\nhalt. Generative Interactive Environments (Genie) is a train-\ning paradigm that extended the paradigm of foundational\nmodels to the generation of Platformer games [31]. Genie\ntrained a Transformer on a large corpus of virtual worlds de-\nscribed through text, images, and sketches and showcased\nthe potential of this line of research for the large-scale gen-\neration of environments. Code-generating LLMs [121] can\nbe seen as universal environment generators and, when em-\nbedded within an optimization process that encourages di-\nversity [121] and self-improvement [68], can hold great po-\ntential for the generation of open-ended environments [121]."}, {"title": "Exploration through LLMs", "content": "Play or intrinsic motivation is a vital component of ex-\nploration in open-ended spaces, facilitating, among oth-\ners, the discovery of emergent patterns in self-organized\nsystems [184, 85, 83, 56] and skill-acquisition with RL\nagents [70, 170]. Similarly to evolution, intrinsically mo-\ntivated exploration faces the challenge of quickly discover-\ning interesting information in large search spaces. Here, we\nhighlight works leveraging LLMs for guiding exploration.\nLin et al. [130] recommend interpreting the auto-\nregressive ability of LLMs as a powerful form of self-\nprediction that can be useful for predicting next states in\nembodied environments. LLMs have been found particu-\nlarly useful for improving the exploration abilities of agents\nin open-ended tasks. For example, they can help assess\nthe achievability of goals based on the agent's abilities,\nmaintain libraries of skills, as well as plan by generating\ngoals [62, 51] and decomposing tasks into achievable sub-\ngoals [153, 237, 233],"}, {"title": "LLMs as models of human behaviour", "content": "ALife has long been concerned with understanding and\nreplicating the emergence of collective and individual phe-\nnomena in human populations. Studies are, however, often\nlimited in their complexity and controllability. At the same\ntime, human notions such as interestingness, surprise, and\ncreativity are elusive to define in a computational way that\nwill enable optimizing ALife systems. Here, we highlight\nworks showcasing that LLMs have captured biases that ex-\ntend beyond language to behaviours and notions related to\nsocial interactions, economic decision-making, innovation\nand interestingness.\nWhen prompted to impersonate different characters, a\ngroup of LLM agents in a game inspired by The Sims,\nemerged convincing social interactions [163]. When eval-\nuated for their decision-making in economic studies, LLMs\nwere found to exhibit human-like biases such as fairness and\nstatus quo [2]. LLMs may also hold promise as tools for cul-\ntural evolution studies as they exhibit human-like biases in\ninformation transmission [2, 171]. By capturing the human\nnotion of interestingness, LLMs can be leveraged in open-\nendedness research [266].\nDespite being able to model certain aspects of human be-\nhaviour, LLMs' ability to model human cognition and psy-\nchology is heavily debated [126, 142, 199, 144]. Criticism\nquestions their ability to use symbolic and complex abstrac-\ntion and reasoning [143], utilize cognitive maps for plan-\nning [144], their \"understanding\" of language and if they\nhave a Theory of Mind [222]. Yet, despite being in some\nways fundamentally distinct, they provide an opportunity for\ncognitive science as they allow for the manipulation and ob-\nservation of input data in ways not possible with human sub-\njects [247, 86], and open up interesting questions on whether\ncertain behaviors can emerge purely from textual data."}, {"title": "LLMs as scientific collaborators", "content": "AI holds the promise of changing the way we do sci-\nence [209, 110, 138, 1], including ALife research [65],\nLLMs trained on large scientific corpora putatively capture\nknowledge about the natural world in the form of language\ncorrelations [172]. While we acknowledge the debate on\nwhether these correlations can be considered a strong form\nof knowledge in an epistemological sense, recent research\nsuggests that LLMs hold potential as scientific collabora-\ntors [113, 91, 132, 163, 178, 270]."}, {"title": "ALIFE FOR LLMS", "content": "Reflecting on the potential of LLMs as instruments for AL-\nife naturally leads us to the reciprocal inquiry: how can in-\nsights from ALife research enhance LLMs? We review some\nfundamental characteristics defining (a)life [4, 60, 109], and\nsketch possible parallels with LLM agents 5 (see Fig. 2 for\nan illustration of these parallels).\nOn Internal States Internal states of organisms, emerg-\ning from the dynamic interactions with their environment,\nand their broader developmental and evolutionary history,\nguide their behaviour and decision-making [25, 260, 140].\nDifferently from living organisms, LLMs lack of self-\nsustained activity [134, 73, 226, 228, 34, 193] The internal\nstate of an LLM is entirely a function of the current con-\ntents of its context window. A main bottleneck when scal-\ning up Transformer architectures is the fact that the compu-\ntational requirements of the standard self-attention mecha-\nnism scale quadratically with the length of the context [217].\nThe limited context window can lead to temporal incon-\nsistencies and erratic behaviour when exceeded due to the\ndiscrete capacity7. Some efforts in LLM research are cur-\nrently directed towards addressing these constraints by aug-\nmenting them with external memory (e.g. with Retrieval-\naugmented generation) [81, 125, 72], sometimes including\nabstractions of the raw observations [163, 201], or towards\nmore self-sustained activity (via incorporating internal feed-\nback mechanisms, or recurrent LLM streams) [265, 269].\nFurther, a wealth of research aims at mitigating the limita-\ntions set by the quadratic requirements of the self-attention\nmechanism [196, 261, 168, 167, 43, 131, 58, 253, 104].\nAutonomy\nDefinition 1. Autonomy refers to the degree to which a sys-\ntem can 'govern' itself (i.e. make decisions, take actions)\nWe deliberately avoid discussing the metaphysics of these\nproperties, such as emergence or autonomy, assuming they are\nepistemological not ontological and hence solely exist in the\neyes of the observer and not in the systems themselves.\nLLMs remain dormant, waiting for a function call, without\ncognitive processes running in the background."}, {"title": "Self-Replication", "content": "Definition 3. Self-Replication can manifest in two ways:\n(a) system-level self-replication is the process by which a\nsystem makes a copy of itself or its components (b) pattern-\nlevel self-replication is when a system makes copies of cer-\ntain outputs/behaviors it produces.\nBy enabling the transmission of information across gen-\nerations when coupled with evolution, Self-Replication is\na pivotal feature of Life. In ALife, self-replication has\nbeen an historical quest [218, 204, 169], from von Neu-\nmann's automata [229], Wolfram's [246] or Langton's cel-\nlular automata [116], to Kauffman's work on autocatalytic\nnetworks [95] and recent works such as Lenia [39]. These\nsystems exhibit pattern-level self-replication. In contrast,\nartificial systems such as computer viruses exhibit system-\nlevel self-replication.\nPattern-level self-replication in LLMs can be seen\nthrough the memes that LLMs create and spread across our\nsocial networks [28] LLMs Agents show early forms of\nsystem-level self-replication, as they offload parts of their\ncognitive processes by instantiating \u201csiblings\u201d to divide and\nconquer a given task [254, 93, 269]. This emergent ability\nto self-replicate beyond their intended environments, can be\nseen as a source of risk and is under scrutiny (e.g. see ASL-3\nCommitments in [9])."}, {"title": "Self-Organisation", "content": "Definition 4. Self-organisation refers to the spontaneous\nemergence of global order or coordination in a system from\nlocal interactions of its parts. That is, self-organisation can\nbe understood in terms of the presence of an attractor driv-\ning the dynamics.\nSelf-organisation has been observed in physical, biologi-\ncal, chemical, and social systems, from bird flocks to animal\nfur patterns formation, and crystal growth, via morphogene-\nsis, where cells in a living body divide and specialize to de-\nvelop into a complex body plan. While its mechanisms are\nstill being investigated, this ability is foundational to enable\nsystems with self-regulating, self-repairing, self-optimizing,\nand self-assembling capabilities (discussed below), adap-\ntivity and resilience. Self-organisation is an essential in-\nspiration both for ALife systems [74], and beyond [94],\nfrom the early autopoietic models [223], snowflake forma-\ntion [159] or Conway's Game of Life [11] to neural cellular\nautomata [145, 215, 38, 152] or information theoretic ap-\nproaches [176, 174, 244]. Self-assembling, as a path to-wards more adaptability, has been studied in ALife or AI\nsystems [147, 191, 149, 164].\nRegarding LLM agents, although recent research hints in\nthat direction investigating locally-interacting agents [98], it\ndoes not seem to exhibit self-organised properties.\nEmergence Both the notion of self-organisation and au-\ntonomy is tied to the concept of emergence, which is a\ncentral topic both in ALife and biological life. In ALife,\nworks have studied the emergence of structure out of chaos,\nof self-repair properties, of cooperation [186], of division of\nlabor [221], of language [52], etc.\nWhile downstream task performance of LLMs has often\nimpressed, the emergent behaviors of LLMs from scaling\n(reminiscent of complex systems [241]) are part of a hot de-\nbate [239, 194]). LLMs research significantly diverges from\nthe bottom-up approach characteristic of ALife. As of now,\nmany of the properties attributed to LLM Agents in this sec-\ntion, such as self-repair, self-improvement, self-replication,\netc. are hard-coded instead of emergent."}, {"title": "Self-Regulation", "content": "Definition 5. Self-regulation refers to the ability of organ-\nisms to manage and adjust their internal state and functions\nin response to internal and external changes.\nSuch ability typically involves various regulatory mech-\nanisms (feedback loops), concepts at the core of cybernet-\nics [19]. ALife systems, like Xenobots [23] and (neural) cel-\nlular automata [145, 215, 38], often display self-regulation\nproperties, such as the ability to recover from damage.\nUnder Reflexion [201], an LLM maintains its own re-\nflective text (from self-assessed experiences) in an episodic\nmemory buffer to induce better decision-making in sub-\nsequent trials. Recent studies have also explored the ex-\ntent to which LLMs may exhibit self-repair innate capabili-\nties, specifically examining whether and how components of\nLLMs compensate upon ablation of certain elements (e.g. at-\ntention heads [190]). Future research could aim at develop-\ning self-repairing LLMs upon damage to some of their com-\nponents. Advancing the development of additional mecha-\nnisms that enhance the adaptability of both the morpholo-\ngies (architecture) and the code (weights) of LLM Agents in\nresponse to internal or external change seems also crucial 9."}, {"title": "Embedded, Embodied, Enacted, Extended", "content": "Definition 6. The 4E cognition framework [151] posits that\ncognitive processes in agents are deeply influenced by: (1)\nthe immediate physical and social environment in which an\norganism exists (embedded), (2) the body's interactions with\nthe world (embodied), (3) the dynamic interactions between\nan organism and its world (enacted), and (4) can extend be-\nyond the brain to include tools, technologies, and other en-\nvironmental elements (extended).\nThe 4E framework is widely investigated in ALife [48,\n213]. Agents may rely on environmental cues to perform\ntasks, and learn representations or behaviors which emerge\nfrom their actions and interactions with the environment and\nthrough sensory-motor couplings. Occasionally ALife sys-\ntems may also have a physical body [23, 37, 55].\nRegarding embeddedness, LLMs are situated in the sense\nthat their response is highly sensitive to its context, fed as\nthe prompt. Although by default very limited, their envi-\nronment can be -and has been- drastically extended for in-\nstance through external and real-time information via Web\naccess and navigation [82], computer access, API exten-\nsions [195], etc. Regarding embodiment, although LLMs\nor LLM agents often lack a 'tangible body', they may be\nphysically situated as pointed out in [137], which seems the\nmost critical component for 4E. By dynamically focusing on\ncertain parts of its sensory input and adjusting its focus with\nfeedback mechanisms, the attention mechanism in Trans-\nformers loosely echoes some form of sensorimotor coupling.\nTo which extent such purely textual sensorimotor contingen-\ncies in the case of LLMs do impose certain cognitive dis-\ntinctions or limitations compared to other forms of cogni-\ntion remains to be investigated. Tangentially, recent works\nhave grounded LLM agents further in our physical tangible\nenvironment, extending some of their sensorial abilities, as\nmulti-modal LLMs [250], API-extended LLM agents [195],\nor even robotic-bodied LLM agents [6, 97, 29, 257]. LLM\nAgents can be seen enacted when their cognitive processes\nand representations still develop through training from their\ninteractions with the environment, as when paired with con-\ntinual learning (or weakly, with in-context learning). Yet ad-\nditional plasticity mechanisms could be explored for LLM\nAgents. Lastly, as extended agents, some LLM Agents\ncan outsource some cognitive tasks beyond their own skills,\nby leveraging existing tools [32, 177, 195], or even learn-\ning how to create their own tools [233]. Their tool use of-\nten stems from existing knowledge of the world rather than\nemergent and extrapolative innovation."}, {"title": "Collective Intelligence", "content": "Definition 7. Collective intelligence refers to the phenom-\nena of simple local interactions between agents leading to\nthe emergence of complex behaviors.\nThe diverse forms of interactions within and between\ngroups of individuals -sometimes resulting in collective\nintelligence- play a crucial role in the development of\nboth natural and ALife systems. Multi-Agent ecosystems\nhave been highlighted as sources of emergent innovation,\nwithin ALife research and beyond [100], both in collabora-\ntive [161] and competitive setups [13, 12, 203]. Collective\nIntelligence has raised particular attention in ALife, from\nflocking agents models [185] to swarm bots [59, 188, 84],\nalso investigating the role of diverse relationships, such as\nsymbiosis [230, 216], parasitism [88] and mutualism [54].\nTo enhance LLM abilities, many recent works [127, 129,\n40, 148, 269, 93, 66, 238, 264, 98, 268] exploit multi-agents\ncollaborations, for instance multi-agent debate [129, 40],\neven across modalities [268]. These works may involve role\nspecialisations [93, 35] (sometimes dynamically assigned\nroles [127]), diverse ecological niches (e.g. different senso-\nrial modalities [264]) and diverse social structures (some-\ntimes even optimized alongside prompts [269]). However,\nthese multi-LLM-agent frameworks 10, mostly focus on per-\nforming short-horizons tasks, with simple in-context social\nlearning (e.g. zero/few-shot learning). Further exploration\ncould harness enhanced social learning mechanisms, such\nas reinforcement learning (as in the Economy of Minds en-\nvisioned in [268]), and adaptive social organization with the\naspiration of fostering collective behaviors that are not just\nmarginally superior but qualitatively distinct from both indi-\nvidual behaviors and their aggregation."}, {"title": "Evolution", "content": "Evolutionary processes, driven by an interplay of selection,\nvariation (mutation, cross-over), and transmission (hered-\nity) processes, across both temporal and spatial scales, have\nplayed a pivotal role in the emergence, adaptation, and diver-\nsification of life forms, both biological and artificial [206].\nThe importance of historicity for behavior, and the interplay\nof different time scales -ontogenetic, phylogenetic- should\nalso be noted [77].\nDefinition 8. Open-endedness refers to the capacity of a\nsystem to continuously produce novel, and increasingly so-\nphisticated and diverse behaviors, without predefined limit.\nIn ALife -and beyond [219]-, open-endedness is an active\narea of research [212, 158, 14, 236, 219, 79, 124, 123, 208].\nFactors like the open-endedness of environment and com-\nplexity of phenotypes still hinders progress of weak ALife\ntowards more open-ended systems [207, 16].\nAkin to genetic operators such as crossover, model merg-\ning aims to encapsulate the knowledge of multiple models\ninto a single one [249], by 'merging' them at the parame-\nter level or at the data flow level (e.g. transformer blocks).\nMany approaches utilize a weighted average to combine the\nmodel weights into a single model, with hand-tuned opera-\ntions to find the best model. Yet, when combined with evolu-\ntionary algorithms [7], it may enable the automated creation\nand improvement of LLMs across generations, and has led\nto state-of-the-art LLMs. Analysing the phylogeny of LLMs\n(how models are combined/fine-tuned to form new models)\ncan be useful towards better understanding them and pre-\ndicting their performance [256].The evolvability of agents\nco-evolving with their environment, alongside with open-\nended evolution and the interplay of different time scales of"}, {"title": "On LLM Ecologies", "content": "The proliferation of distinct LLMs\nacross dimensions such as size, speciality, and architecture\nsuggests that we are already experiencing a certain LLM\necology [141, 267, 36], sometimes referred to as a \"Model\nGarden\" 11. 'Successful' models, where success denotes\neconomic utility) influence the creation of future genera-\ntions of models through fine-tuning or design inspiration, at\na pace which gives us a visceral picture of variation, death,\nand growth. The array of model scales, from the thou-\nsands to trillions of parameters, is akin to scales observed\nin natural ecologies [242], or ALife ecologies [41, 63, 122].\nSmaller LLMs are currently more plentiful, mirroring natu-\nral ecosystems [248], and have a generally shorter lifespan,\nakin to the natural \"thermodynamic law\" [210].\nCompared to other technologies, what makes LLM ecolo-\ngies particularly suitable for study from an ALife perspec-\ntive? First, LLM agents operate through a common inter-\nface -e.g. text in, text out-, enabling them to function non-\ntrivially across many environments, akin to the universal-\nity of physical embodiment in biology. Second, both LLMs\nand ecosystems are grounded in energy, which is becom-\ning a critical factor in their development and use [36, 67].\nThis may lead to the stratification of LLMs across diverse\nthermodynamic regimes akin to natural and ALife ecosys-\ntems [210, 63, 136] and task offloading between larger and\nsmaller models [57, 259, 232, 35]. Third, LLMs are all\nmade out of the same stuff on which they can operate (e.g.\ncode, Transformer blocks [267])\u2013 as all organisms are made\nof DNA, proteins, etc, which grants them the capability to\nself-improve, self-variate and and self-generate."}, {"title": "Cultural Evolution", "content": "Both human and non-human entities have the capacity to\nact and influence their respective ecosystem. LLMs -as\nother AI [200, 243] or technological objects- can be seen\nas actors that participate in and co-construct human socio-\ncultural reality, as advocated by Gilbert Simondon [202],\nand Actor-Network Theory [118] among others. This was\nalso witnessed with AI systems, e.g. reinforcement learn-\ning algorithms integrated within the society effects on hu-\nman behavior, such as AlphaGo changing the way hu-\nmans play Go [200], or Recommender Systems affecting\npolarisation and radicalisation [243]. Increasingly LLMs\nare mediating our decisions, our ways to consume and\nshare information (e.g. as search engines, recommenders,\ncontent generators), our relationships (e.g. as writer assis-\nstants), and our very cognitive processes (e.g. as collabora-\ntors [227]) -at a scale rarely matched by other technologi-\ncal objects. They could have a considerable influence on our"}, {"title": "Discussion", "content": "In this paper, we highlight the potential reciprocal relation-\nship between ALife and LLMs. On the one hand, our re-\nview of works employing LLMs as tools for ALife shows\nthat the emergence of LLMs has opened new avenues for\naddressing many open questions in ALife [16]. On the other\nhand, the methodologies and perspectives from ALife re-\nsearch offer valuable insights for framing the development\nand functionality of LLMs. The principles of evolvability,\nself-organisation, and emergence that underpin ALife can\ninform strategies for designing LLM architectures and train-\ning processes, towards models more adaptive in response to\nshifting environments.\nAre LLMs a form of ALife? Some LLM Agents be-\ngin to exhibit behaviors akin to artificial life, e.g. self-\nreplication, self-repair, collective interaction, tool use, divi-\nsion of labour, planning, goal generation, and being embed-\nded in complex open-ended environments (e.g. web). Yet,\ntheir capabilities are currently mostly designed top-down in-\nstead of being evolvable and emerging, driven by intrinsic\nmotivation, and complex couplings with their ecosystem,\nwhile accounting for developmental and evolutionary his-\ntories. Beyond providing a definite answer, the exercise of\ndrawing this analogy may provide new stepping stones for\nadvancing both LLM agents and ALife systems [211].\nHowever, the relationship between ALife and LLMs is\nnot without challenges, including those arising from LLMs\nalone [106]. The complexity of LLMs, their dependence\non vast and sometimes dubious datasets [133, 53], and their\nenergy consumption raises questions about their ecological\nand ethical implications [21, 173]. The rapid -and thus\nimmature- profit-driven deployment of LLMs may have a\nconcerning impact on human socio-cultural evolution. The\nmoral implications of such rapid technological progress\nhave been contemplated by both in AI and ALife. On one\nhand, the AI alignment movement is concerned with the con-\ntrollability and interpretability of the AI ecosystem [102].\nOn the other hand, ALife researchers ponder the moral re-\nsponsibility of creating artificial systems that participate in\nhuman societies as autonomous agents [245, 92]. Under-\nstanding these implications may benefit from a dialogue be-\ntween the two communities."}]}