{"title": "PEDIATRIC BRAIN TUMOR CLASSIFICATION USING DIGITAL\nHISTOPATHOLOGY AND DEEP LEARNING: EVALUATION OF SOTA\nMETHODS ON A MULTI-CENTER SWEDISH COHORT", "authors": ["Iulian Emil Tampu", "Per Nyman", "Christoforos Spyretos", "Ida Blystad", "Alia Shamikh", "Gabriela\nProchazka", "Teresita D\u00edaz de St\u00e5hl", "Johanna Sandgren", "Peter Lundberg", "Neda Haj-Hosseini"], "abstract": "Brain tumors are the most common solid tumors in children and young adults, but the scarcity of\nlarge histopathology datasets has limited the application of computational pathology in this group.\nThis study implements two weakly supervised multiple-instance learning (MIL) approaches on patch-\nfeatures obtained from state-of-the-art histology-specific foundation models to classify pediatric\nbrain tumors in hematoxylin and eosin whole slide images (WSIs) from a multi-center Swedish\ncohort. WSIs from 540 subjects (age 8.5\u00b14.9 years) diagnosed with brain tumor were gathered\nfrom the six Swedish university hospitals. Instance (patch)-level features were obtained from WSIs\nusing three pre-trained feature extractors: ResNet50, UNI and CONCH. Instances were aggregated\nusing attention-based MIL (ABMIL) or clustering-constrained attention MIL (CLAM) for patient-\nlevel classification. Models were evaluated on three classification tasks based on the hierarchical\nclassification of pediatric brain tumors: tumor category, family and type. Model generalization was\nassessed by training on data from two of the centers and testing on data from four other centers. Model\ninterpretability was evaluated through attention-mapping. The highest classification performance\nwas achieved using UNI features and AMBIL aggregation, with Matthew's correlation coefficient of\n0.86\u00b10.04, 0.63\u00b10.04, and 0.53\u00b10.05, for tumor category, family and type classification, respectively.\nWhen evaluating generalization, models utilizing UNI and CONCH features outperformed those\nusing ResNet50. However, the drop in performance from the in-site to out-of-site testing was similar\nacross feature extractors. These results show the potential of state-of-the-art computational pathology\nmethods in diagnosing pediatric brain tumors at different hierarchical levels with fair generalizability\non a multi-center national dataset.", "sections": [{"title": "Introduction", "content": "Tumors of the central nervous system (CNS) are the most common solid neoplasms occurring in children and young\nadults (age <20 years), and account for 20% of all pediatric tumors [1] with a global incidence of 1.2 per 100.000\nchildren in 2022 [2]. The prognosis of pediatric CNS tumors depends on several factors including tumor location,\nhistology, age, and sex, with a ten-year survival of 72% in western countries [1]. Timely and accurate diagnosis of\npediatric brain tumors is essential to improve prognosis and reduce the collateral and long-term effects of treatment\n[2]. Non-invasive imaging modalities, such as computed tomography (CT) and magnetic resonance imaging (MRI),\nare used for the initial diagnosis and to guide biopsies for histological and molecular analysis. A final diagnosis is\nattained by integrating radiological findings, histological examination, and molecular profiling, with the latter playing\nan increasingly larger role as genetic and epigenetic traits drive disease progression [3, 4]. Advancements in molecular\nanalysis have enabled a refined diagnosis of pediatric brain tumors, identifying 22 distinct types [5, 6]. However,\nmolecular profiling is costly, time-consuming, and not widely available today. Consequently, treatment sometimes\nbegins after the preliminary diagnosis based on radiological and histological features. Histological examinations are\nlabor intensive, and in the case of pediatric brain tumors, the lack of expert pediatric neuropathologists (as low as\none expert per 173.000 children [7] in Europe), emphasises the need for decision-support tools to aid diagnosis. The\ndigitization of histology glass slides into whole slide images (WSIs) has enabled the development of computational\npathology (CPath) methods that automatically analyze the image data (with or without the combination of clinical\nmetadata) for tissue sub-region segmentation, prognostication, cancer subtyping, and gene mutation prediction [8].\nCurrently, CPath takes advantage of artificial intelligence (AI) and deep learning algorithms (DL), with several studies\nshowing the successful implementation of these methods for cell and gland detection/segmentation and classification\n[9, 10, 11] and more recently for molecular biomarker detection from the image data [12]. In the context of slide\nand patient-level prediction tasks (tumor grading, subtyping, and prognostication), the state-of-the-art (SOTA) DL\nmethods use variants of the multiple instance learning (MIL) framework [13, 14] to address the unavailability of\npixel-level annotations and the computational challenges that originate from the large size of the WSIs. This framework\nis composed of several customizable steps including segmentation of the tissue regions from the glass background,\nsubdivision of the tissue region into non-overlapping patches, projection of each patch using pre-trained patch-encoders\ninto a low-dimensional space and aggregation of the patch representations into a slide-level representation which can\nbe used for the downstream task. A large corpus of research has been focused on obtaining histology-specific patch\nencoders that provide strong feature representations, that are task-agnostic and can be applied in low-data regime\nsettings [15, 16, 17, 18]. Moreover, several aggregation methods have been developed [19], with attention-based MIL\n(ABMIL) [20] and its variants becoming the method of choice for CPath.\nCPath methods for brain tumors have primarily focused on the adult population [21], with few studies exclusively\ninvestigating pediatric tumors for diagnosis or survival prediction [22, 23, 24, 25] mainly due to the unavailability of\nlarge datasets. Among these, Steyaer et at., proposed a deep learning-based approach for survival prediction of pediatric\nbrain tumors (low-grade glioma, high-grade astrocytoma, high-grade ependymoma, and high-grade medulloblastoma)\nand adult (low-grade glioma, glioblastoma) using H&E WSIs and genetic data [25]. The authors obtained a slide-level\nrepresentation by averaging the patch features extracted using an ImageNet pre-trained ResNet50 [26] model. Results\nshow that H&E WSIs alone could predict the survival of pediatric brain tumors with a composite score of (0.67\u00b10.16)\nwhich improved by 6.5% when fused with RNA data. The subtyping of medulloblastoma, the most common malignant\nbrain tumor in the pediatric population, has also been investigated [22, 24]. By using a pre-trained EfficientNet model\nfine-tuned on squared crops of medulloblastoma WSIs, Bengs et al., showed a classification F1 score of 80.1% between\nclassic and nodular-type medulloblastoma [22]. In another work, Whitney and colleagues first segmented the cells in\nsquared WSI patches and then extracted nuclear and histomorphometric features describing the shape, architecture,\nand texture of the cell population [23]. A machine learning model was then trained on the extracted features for\nthe classification between SHH-activated, WNT-activated, and Group 3, 4 medulloblastoma subtypes obtaining a\npatient-level area under the receiver operator curve (AUC) of 0.7. Additionally, survival prediction within each tumor\nsubtype was performed, with the highest AUC of 0.92 obtained for medulloblastoma Group 3 survival prediction. Of\nnotice, both [22, 23] extracted patches manually from the WSI to ensure that only tumor regions were available for\nfeature extraction and training. Thus, both methods suffer from the need for fine detailed annotations and cannot be\ntrained in an end-to-end fashion.\nIn this work, we aim to implement and evaluate state-of-the-art weakly supervised deep learning methods on WSIs\nof pediatric brain tumors for the classification of tumor category, family, and type on a unique multi-center dataset\nthat represents a population-based range of diagnosis. The contributions of this work are: (1) implement and evaluate\ntwo histopathology-specific feature extractors (UNI and CONCH) for the classification of pediatric brain tumors\nat patient-level, and compare them with a baseline ImageNet pre-trained ResNet50, (2) evaluate and compare two\nestablished attention-based approaches (ABMIL) and clustering-constrained-attention MIL (CLAM) for the aggregation\nof the patch-level features into a patient level classification and (3) evaluate model generalization by training on data\nfrom two centers and testing on data from four other centers"}, {"title": "Material and Methods", "content": "The dataset used in this study was made available from the Swedish Childhood Tumor Biobank (BTB), and is part of\na national effort to generate and maintain multi-modal data on pediatric brain tumors (among other childhood solid\nmalignancies) from the six Swedish university hospitals where tissue samples and linked sample information are\ncollected to BTB after informed consent. Ethical approval was obtained from the Swedish Ethical Review Authority\n(Dnr 2021-03985 and Dnr 2022-00065-02). The study was additionally approved by BTB, as well as Karolinska\nUniversity Hospital and Stockholm Medical Biobank, the medico-legal authority for BTB's personal data and tissue\nsamples, respectively.\nData included subjects from 2013 to 2023, and although it does not include all pediatric brain tumor patients, the\nselection is random and representative of the prevalent diagnoses in the country. Data from three centers (Link\u00f6ping,\nUppsala, and Ume\u00e5) were obtained as H&E stained WSIs, while from the remaining centers (Stockholm, Gothenburg,\nand Lund) glass slides were retrieved and scanned using digital scanners (Hamamatsu-Nanozoomer-XR & S360). In\ntotal, 1460 WSIs from 540 subjects (284 males, 253 females, 3 not specified, age in years 8.29\u00b15.03, range [0.00,\n19.00]) were available representing primary, metastatic, and recurrent tumors. Patient diagnoses were retrieved from\nthe clinical health records, specifying tumor category, family, and type. Twenty-one subjects had multiple diagnosis\ncorresponding to analysis of samples from metastatic and/or recurrent tumor regions (18 subjects with double diagnosis,\n3 subjects with triple diagnosis). Thus, 564 unique subject-diagnosis pairs, hereafter called cases, were identified and\nused for the analysis. Overall, the WSIs were scanned with 5 different scanners at magnifications of \u00d720 or \u00d740\nresulting in a variability in image quality and color accuracy, among others. Of these, 170 WSIs (from 65 cases, 35\nmales, 29 females, and 1 not specified) were excluded due to unclear diagnoses, or diagnoses not matching the latest\n2021 WHO classification of brain tumors [6]. Additional 66 WSIs (from 20 cases, 7 males, 13 females) were removed\ndue to severe scanning artifacts (e.g., out-of-focus scan), and 3 WSIs (1 case, 1 male) were excluded due to failed\ntissue segmentation and patching. To ensure a sufficient number of cases for training and testing, only tumor diagnosis\nrepresented by at least 10 cases were included in the analysis, with the threshold of 10 set according to the few-shot\nresults presented in [17].\nIn this work, the weakly-supervised MIL framework was utilized to train models for patient-level prediction (Figure 1).\nInitially, non-overlapping patches of size 224\u00d7224 pixels at \u00d720 magnification were obtained from tissue-segmented\nregions of each WSI using the CLAM framework [27]. Features from each patch (or instance) were then extracted using\none of three pre-trained image encoders: ResNet50, UNI, and CONCH (see Instance-level feature extraction section).\nThe instance-level features of all the WSIs of each patient were then aggregated into a single representation using two\ndifferent MIL-based methods: ABMIL [20] and clustering-constrained-attention MIL (CLAM) [27] (see Attention-\nbased aggregation methods section). The aggregated representation was then utilized for patient-level diagnosis via a\nfully connected layer with softmax activation."}, {"title": "Instance-level feature extraction", "content": "Tumors often exhibit heterogeneous patterns, meaning different regions of the tumor can have varying characteristics.\nPatch-level (or instance-level) feature extraction allows for a detailed analysis of these diverse regions, which can\nprovide critical insights for accurate diagnosis and prognosis. Instance-level feature extraction was performed to obtain\na compact representation of each 224\u00d7224 pixel patch. This approach is advantageous in computational pathology"}, {"title": "Attention-based aggregation methods", "content": "In tumor slides, not all regions are equally important. For example, some patches may contain benign tissue, while\nothers may show aggressive cancer. Attention-based aggregation allows the model to focus more on the most relevant\nparts of the image, possibly leading to more accurate and clinically useful predictions. In this work, two attention-based\naggregation methods were investigated to derive a case-level representation from the patch-level features: the well-\nestablished ABMIL and its variation, CLAM. ABMIL [20] was introduced as a learnable pooling method, in contrast to\nmax or average pooling, which borrows from the attention mechanism but is invariant to the number and order of the\ninstances in a bag. It employs two fully connected layers to learn a weight for each of the instances in the bag, which is\nthen used to compute the bag representation as the weighted average of the instances. The gated version of the attention\nmechanism [20] was used in this work which is described by\n$a_k = \\frac{\\exp \\left(w^{\\mathsf{T}} \\left(\\left(\\tanh V h_j\\right) \\odot \\operatorname{sign}\\left(U h_j\\right)\\right)\\right)}{\\sum_{l=1}^K \\exp \\left(w^{\\mathsf{T}} \\left(\\left(\\tanh V h_l\\right) \\odot \\operatorname{sign}\\left(U h_l\\right)\\right)\\right)}$\nwhere $h_j$ is the projected instance feature vector $\\in \\mathbb{R}^{1\\times 255}$, and $w \\in \\mathbb{R}^{384\\times 1}, V \\in \\mathbb{R}^{381\\times 512}, U \\in [\\mathbb{R}^{381\\times 512}$ are model\nparameters updated during training. The aggregated representation is then computed by\n$z = \\sum_{j=1}^K a_j h_j$\nThe second aggregation method, clustering-constrained attention multiple-instance learning (CLAM) [27], is one of\nseveral attention MIL approaches available in the literature [30] and used in several CPath implementations. CLAM\nbuilds upon ABMIL by adding a clustering layer parallel to the attention mechanism that is trained to differentiate\nbetween instances that are positive and negative evidence for the ground truth label. Namely, the instance-level\nclustering loss guides the model to attend more to instances that are positive evidence exclusively for the ground truth\nand not for the other labels. In this work, the k=8 instances with the highest and lowest attention scores were used for\nclustering [27]. The single branch and small-size version of CLAM was used in this work."}, {"title": "Experimental setup", "content": ""}, {"title": "Classification tasks", "content": "Utilizing the hierarchical classification system of CNS tumors, three classification tasks were designed to assess the\nmodel's performance at varying levels of classification granularity. In particular, at a coarse-level, models were tasked to\nclassify between 5 tumor categories (choroid plexus tumors, embryonal tumors, gliomas/glioneuronal/neuronal tumors,\nmeningiomas, and sellar region tumors). At a medium-level, models were trained to distinguish between 10 tumor\nfamilies (choroid plexus tumors, circumscribed astrocytic glioma, craniopharyngiomas, ependymal tumors, glioneu-\nronal/neuronal tumors, medulloblastoma histologically defined, medulloblastoma molecularly defined, meningioma,\nother CNS embryonal tumors, pediatric diffuse high-grade glioma). Finally, at the fine-level, models were tasked\nto classify between 13 classes (adamantinomatous craniopharyngioma, AT/RT, diffuse high-grade glioma, diffuse\nmidline glioma, dysembryoplastic neuroepithelial tumor (DNET), ependymoma, ependymoma grade 3, ganglioglioma,\nmedulloblastoma, medulloblastoma non-WNT/non-SHH, medulloblastoma TP53 wild type, medulloblastoma WNT\nactivated, pilocytic astrocytoma)."}, {"title": "Model generalization", "content": "To evaluate the generalization of the classification models, data from two of the six sites (Stockholm and Uppsala,\nreferred to as in-site data) were used for training, while the data from the remaining sites were used for testing (referred\nto as out-of-site data). The selection for the training and testing sites was guided by the number of cases, trying to obtain\nan equal number of cumulative cases in the training and testing sites. However, due to the smaller number of cases in the\ntraining set and the minimum requirement of 10 samples per class, the number of classes for each of the classification\ntasks was adjusted as follows: three classes for tumor category (CNS embryonal tumors, gliomas/glioneuronal/neuronal\ntumors, tumors of the sellar region), eight classes for tumor family (circumscribed astrocytic gliomas, craniopharyn-\ngiomas, ependymal tumors, glioneuronal/neuronal tumors, medulloblastomas histologically defined, medulloblastomas\nmolecularly defined, other CNS embryonal tumors, pediatric type diffuse high-grade gliomas), and five classes for tumor\ntype (ependymoma, ganglioglioma, medulloblastoma, medulloblastoma non-WNT/non-SHH, pilocytic astrocytoma)."}, {"title": "Training routine", "content": "The weights and biases of the attention-based aggregation layers and classification layer were randomly initialized and\nwere trained end-to-end using a batch size of one. For ABMIL, training was supervised using the cross-entropy loss\ncomputed between the model prediction and the case-level ground truth. In the case of CLAM, training was supervised\nby both the cross-entropy loss and the smooth-SVM loss obtained from the instance clustering. To account for class\nimbalance, a batch weighted sampling strategy was employed, where the probability of a sample to be drawn is inversely\nproportional to the frequency of the number of samples in its class. For regularization, dropout was used on the input\nembeddings and after each intermediate layer in the model, with P=0.1 and P=0.25, respectively. Models were trained\nusing the AdamW optimizer [31] with a starting learning rate of 0.0001 and decreased during training using a cosine\nannealing scheduler. Training ran for a minimum of 10 and a maximum of 20 epochs along with early stopping on the\nvalidation loss with patience set to 5 epochs. Model training and evaluation ran on a workstation equipped with 24 GB\n4090 Nvidia GPU and a 24-core CPU. We adapted the CLAM framework to allow for additional feature extractors and\naggregation methods."}, {"title": "Evaluation and statistical analysis", "content": "Classification performance is reported in terms of Matthews Correlation Coefficient (MCC), balanced accuracy, weighted\nF1 score, and area under the receiver operator curve (AUROC). MCC, balanced accuracy, and weighted F1 score were\nused to account for the class imbalance in the test set. Balanced accuracy was computed as the average recall across all\nclasses. The weighted F1 score was calculated as the average of the F1 score for each class, weighted by the number of\nground truth samples in each class. For the experiments investigating the classification performance using data from\nall the sites, metrics are reported as mean and standard deviation over 150 replicates obtained from a nonparametric\nbootstrapping. The number of replicates was obtained through a power calculation using statistics from a preliminary\ninvestigation. The split between training/validation/test to obtain each of the replicas was performed on a subject level\nand was class-stratified, with 30% of samples set for testing, 20% for validation, and 50% for training. Statistical\ncomparison was performed through a two-sided paired permutation test with 10000 permutations using test values from\nthe nonparametric bootstrapping replicates, for which the significance level was set to p=0.05. Bonferroni correction\nwas additionally utilized in the case of multiple comparisons. For the model generalization evaluation, metrics are\nreported as mean and standard deviation over 5 replicates obtained from a nonparametric bootstrapping, with replicates\nobtained using the same split strategy as before. No statistical analysis was performed between the performances\nobtained on the in-site and out-of-site testing."}, {"title": "Attention mapping", "content": "The attention scores for each instance in a bag can be used to highlight regions in the WSIs that contributed more\nto the class predicted by the model. In particular, attention score heatmaps can be overlaid on the WSIs to highlight\nthe salient histological morphologies used for classification. In this work, attention maps were computed from the\nmodels whose MCC performance was closest to the median value across the 150 replications. For a few selected WSIs,\nan expert pediatric neuropathologist identified regions relevant for the diagnosis, describing the characteristics of the\ncell population (normal, tumor, and tumor grade) and stroma. A qualitative comparison was performed between the\nattention maps and these regions."}, {"title": "Results", "content": ""}, {"title": "Classification performance", "content": ""}, {"title": "Discussion", "content": "In this study, we investigated the classification of pediatric brain tumors on a national multi-center digital histopathology\ncohort with a wide range of diagnoses using an attention-based MIL approach on WSI features extracted by histology\npre-trained foundation models to obtain a per-case classification. Our findings demonstrate the potential of leveraging\ndeep learning for the classification of pediatric brain tumors at different levels of granularity."}, {"title": "Feature extractors and aggregation methods", "content": "Our results show that, regardless of the MIL aggregation method, there is a significant improvement in classification\nperformance when training models on instance-level features obtained from in-domain pretrained feature extractors\n(CONCH and UNI) compared to when using features from an out-of-domain pre-trained feature extractor (ResNet50).\nThe impact of feature extractors in CPath has been investigated in several studies [16, 17, 33], demonstrating that\nself-supervised pretraining on in-domain histopathology data consistently results in performance improvements across\na variety of tasks compared to ImageNet pretraining. The possibility of pretraining histology-specific and task-agnostic\nfeature extractors has been facilitated by the curation of large histopathology datasets as well as methodological\nadvancements in self-supervised pretraining. When considering models using CONCH and UNI features, a small but\nstatistically significant difference in performance is observed between the two feature extractors when considering\ntumor family and type classification. Additionally, there is a difference in the performance drop when increasing\ntumor classification granularity. The difference in the sourcing and quality of the pretraining datasets can be used\nas an explanation for the higher classification performance and lower performance drop observed in models trained\nusing UNI features. UNI was pretrained on a larger corpus of patches (100M vs 1.17M) obtained from WSIs of\nmostly cancer tissues, whereas CONCH pretraining dataset was obtained by extracting histology images from publicly\navailable research articles. Another possible reason can be found in the dimension of the feature space used for instance\nrepresentations, with UNI outputting 1024 feature vectors while CONCH outputs 512.\nThe difference in classification performance observed between aggregation methods partially agrees with the literature.\nIn particular, the performance improvement of CLAM over ABMIL aggregation for models using ResNet50 aligns\nwith the reported results [16, 30, 34, 35]. For example, Zhang et al., reported an average improvement of 1.3% in\nclassification performance across three classification tasks when using CLAM over ABMIL [34]. Moreover, results\npresented here show no improvements or marginally worse performance when using UNI or CONCH features with\nCLAM aggregation. This was unexpected considering that CLAM is an extension of ABMIL. However, as shown\nby Chen et al., [30] in the comparison of several foundation models and instance aggregation methods on nine CPath\ntasks, advanced aggregation approaches did not always outperform ABMIL, and a case-by-case evaluation should be\nperformed.\nOverall, several instance-level feature extractors and aggregation methods are available in the literature [15, 30, 36].\nUNI and CONCH are among the recent and best-performing foundation models, designed for digital histopathology,\nbut other feature extractors such as Virchow [36] could be evaluated given the comparable performance on adult\nbrain tumors. Feature encoders such as HIPT [15] which uses the hierarchical structure of WSIs to learn a slide-level\nrepresentation could also be considered\nClassification performance reported in this study, even though not directly comparable given the differences in sample\nsize and classes, shows similar trends to the available literature on brain tumor classification using WSI data when\nconsidering coarse and fine-grained classification. Using data from EBRAINS [37] which is one of the few datasets\navailable with a wide range of diagnoses from adult and pediatric brain tumors, Liu et al., evaluated tumor type\nclassification when using UNI features and ABMIL aggregation [17]. The authors reported a balanced accuracy of\n0.88 for the coarse-grained classification (12 classes) and 0.67 on the fine-grained classification (30 classes). The\nperformance drop going from coarse to fine-grained classification is comparable to ours when going from tumor\ncategory to family classification, however, in each case only a few classes have overlap with ours."}, {"title": "Miss-classifications", "content": "When looking at the class-wise performance across classification tasks, no obvious patterns in misclassification\nwere observed for the tumor category. In the case of tumor family classifications, medulloblastomas histologically\ndefined were misclassified as medulloblastomas molecularly defined. This is not unexpected since histologically\ndefined medulloblastomas have morphological characteristics that are highly related to molecularly defined subgroups\n[6]. Additionally, in the tumor type classification, different medulloblastoma types (histologically and molecularly\ndefined) are misclassified among each other. This indicated that while the features learned by the models from\nthe image data could help distinguish medulloblastomas from different tumor types, they were not able to capture\ndifferences in molecular characteristics. Tumor family classes of pediatric-type diffuse high-grade gliomas and\nglioneuronal/neuronal tumors were primarily misclassified as circumscribed astrocytic gliomas, which belong to the\nsame tumor category of gliomas/glioneuronal and neuronal tumors. For pediatric-type diffuse high-grade gliomas,\nthe differential diagnosis includes glioneuronal tumors (e.g. gangliogliomas) and circumscribed astrocytic gliomas\n(e.g. pilocytic astrocytomas), and differentiation is challenging requiring both histomorphological and molecular"}, {"title": "Model generalization", "content": "The generalization of deep learning-based CPath methods to out-of-distribution data has been investigated in a range of\napplications [40, 41, 42]. Overall, these methods perform worse on out-of-distribution data compared to in-domain\ndata due to domain shift, with research efforts focused on reducing the performance gap through domain adaptation\nand domain generalization methods [41]. Among the domain generalization methods, self-supervised pre-training of\nfeature encoders on a large and diverse dataset has been shown to improve the generalization of learned representations\n[17]. The results on the out-of-site data in this study show that models trained using instance-level features from UNI\nand CONCH outperform those using ImageNet across all classification tasks. However, these results indicate only that\nthe instance-level representations obtained from the histology pre-trained feature encoders are less affected by domain\nshift than those obtained when using a general ImageNet pre-trained model. Regardless of the feature extractor, no\nconsistent benefit was observed in using CLAM over ABMIL when comparing classification performance between\nin-site and out-of-site testing."}, {"title": "Attention mapping", "content": "The qualitative analysis of model attention maps demonstrated that there is an overlap between the regions the models\nlearn to be relevant for classification and those deemed as important for diagnosis by the pathologist. Models attended\nto the tumor regions as well as other relevant features such as necrosis and abnormal stroma. Additionally, depending\non the classification task granularity, models selectively focused on different diagnostic regions. This was particularly\nvisible in the case of the ependymoma grade 3 sample, where the high-grade tumor regions were the most relevant for\ntumor type classification, whereas both high and low grade tumor areas were utilized for tumor category classification.\nThe importance of the necrotic area also changes from being ignored for tumor category, to being relevant for tumor\nfamily and partially considered for tumor type classification. Thus, while the features of the relevant diagnostic regions\nare the same across classification tasks (when using the same feature extractor), models learn to selectively focus on\nthose that are relevant based on the classification granularity."}, {"title": "Limitations", "content": "Despite the promising results, this study has some limitations. First, to allow for a larger training set and include more\ntumor classes providing a more comprehensive evaluation of models' generalization, cases with unclear diagnoses in\nthe current dataset should be re-evaluated incorporating molecular information and datasets from multinational centers\nshould be included. Another aspect of the dataset that influences the evaluation of model generalization presented here,\nis that glass slides from one of the training sites and two of the out-of-site testing sites were scanned at the same location\nwith the same scanner. Digitizing slides using the same scanner reduces domain shift and can lead to models performing\nwell on the in-site data, but limits the generalization on out-of-site data. Consequently, the results presented reflect the\ndomain shift caused by the slide preparation protocol and not the differences between scanners. Moreover, the results\nalso reflect only variability in slide preparation in Sweden, not across different countries. Testing on additional datasets\nshould be considered. Additionally, the generalization analysis presented does not show each out-off-site individually,\nand class distribution shift was not accounted for.\nInterpretability of the attention maps is limited by the lack of detailed (pixel or region-level) annotations in the dataset.\nWhile single-case evaluations are beneficial, the alignment between the histomorphological features pathologists use for\ndiagnosis should be comprehensively and quantitatively compared to regions utilized by the model for classification.\nFinally, this study focused only on the classification of tumor category, families, and types, while analysis such as\nsurvival rate prediction and molecular biomarker identification (e.g. BRAF mutation) would additionally provide a\nmore comprehensive description of the potential of the unique dataset used in the study. Furthermore, only H&E WSIs\nwere used for model training, while multimodal approaches such as fusion of age [43] or other healthcare record data,\nimmunohistochemistry WSIs [44], and molecular data [25, 45] could potentially improve the performance of the models\nand open possibilities for predicting the diagnosis independent of the molecular testing."}, {"title": "Conclusion", "content": "In this work, we implemented attention-based multiple-instance learning on WSI features extracted by histology\nfoundation models to diagnose pediatric brain tumors on a multicenter Swedish cohort. Classification and model\ngeneralization results demonstrate the flexibility of histology-specific encoders over generic models to transfer to new\ntasks and datasets. In all the experiments, UNI-derived features, aggregated through ABMIL, resulted in the highest\nclassification performance. On model generalization, performance was maintained for tumor category classification\nbut decreased for fine-grained classification, with a similar drop across models. Overall, these findings expand the\nadvancement of computational pathology in pediatric brain cancer diagnosis."}, {"title": "Code and data availability", "content": "The minimal data and codes for result interpretation can be made available on reasonable request to the corresponding\nauthors. Weights for UNI and CONCH pre-trained models are available at https://github.com/mahmoodlab/UNI\nand https://github.com/mahmoodlab/CONCH, respectively. The original code for CLAM is available at https:\n//github.com/mahmoodlab/CLAM."}]}