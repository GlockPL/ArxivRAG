{"title": "AdverX-Ray: Ensuring X-Ray Integrity Through\nFrequency-Sensitive Adversarial VAEs", "authors": ["Francisco Caetano", "Christiaan Viviers", "Lena Filatova", "Peter H.N. de With", "Fons van der Sommen"], "abstract": "Ensuring the quality and integrity of medical images is crucial for maintaining diagnostic accuracy in deep\nlearning-based Computer-Aided Diagnosis and Computer-Aided Detection (CAD) systems. Covariate shifts are\nsubtle variations in the data distribution caused by different imaging devices or settings and can severely degrade\nmodel performance, similar to the effects of adversarial attacks. Therefore, it is vital to have a lightweight and\nfast method to assess the quality of these images prior to using CAD models. AdverX-Ray addresses this need\nby serving as an image-quality assessment layer, designed to detect covariate shifts effectively. This Adversarial\nVariational Autoencoder prioritizes the discriminator's role, using the suboptimal outputs of the generator as\nnegative samples to fine-tune the discriminator's ability to identify high-frequency artifacts. Images generated by\nadversarial networks often exhibit severe high-frequency artifacts, guiding the discriminator to focus excessively\non these components. This makes the discriminator ideal for this approach. Trained on patches from X-ray\nimages of specific machine models, AdverX-Ray can evaluate whether a scan matches the training distribution,\nor if a scan from the same machine is captured under different settings. Extensive comparisons with various\nOOD detection methods show that AdverX-Ray significantly outperforms existing techniques, achieving a 96.2-%\naverage AUROC using only 64 random patches from an X-ray. Its lightweight and fast architecture makes it\nsuitable for real-time applications, enhancing the reliability of medical imaging systems. The code and pretrained\nmodels are publicly available*.\nKeywords: Covariate Shift, Generative Adversarial Networks, Generative Modelling, Out-of-distribution De-\ntection, Variational Autoencoders, X-Ray Imaging", "sections": [{"title": "1. INTRODUCTION", "content": "The accurate and reliable detection of out-of-distribution (OOD) data is paramount to diagnostic accuracy and\noverall reliability of medical imaging systems, ultimately ensuring patient safety. Faulty systems processing\nincorrect imaging statistics can adversely affect diagnostics. It is well established that modern deep learning-\nbased Computer-Aided Diagnosis and Computer-Aided Detection (CAD) systems are vulnerable to distribution\nshifts, which can lead to erroneous predictions.\nConventional anomaly detection techniques often rely on identifying deviations from a learned statistical\nrepresentation of the in-distribution (ID) data and typically focus on semantic anomalies in images.1 Medical\nimages can exhibit complex noise patterns and variability due to equipment variations, imaging conditions, and\nphysiological differences between patients.2 Previous research on the impact of covariate shifts on X-ray chest\nimages has demonstrated that factors such as acquisition parameters, device manufacturers, and geographical\nvariations can degrade the F\u2081 score by up to 6%.3 Identifying these covariate factors, i.e. the change in the\ndistribution of high-level image statistics (covariates) subject to consistent low-level semantics, 4 will enable safer\ndeployment and continuous exploitation of modern medical imaging systems, while ensuring that CAD methods\nremain applied within their ID range."}, {"title": "2. METHODOLOGY", "content": "Medical X-ray images, pivotal for diagnostic purposes, contain covariate factors that can compromise image\nquality and diagnostic accuracy.11 We aim to develop a method to detect changes in the imaging system (or\nfaulty behavior), representing themselves as OOD covariate shifts in the images."}, {"title": "A. Philips X-ray Dataset", "content": "Since we do not have access to such OOD artifacts or faulty images, we capture\nreal covariate shifts in the data by altering the imaging settings. If we can discern the subtle variations caused\nby changed imaging settings, we hypothesize that the proposed models can measure faulty OOD covariate shifts\nas an effect of system errors. To this end, we acquire a new dataset of X-ray images containing a standard test\nobject (clock), using an Azurion Image-Guided Therapy (IGT) system. We capture images in Dicom format\nat 12 bits/pixel for different imaging settings, encompassing distinct dose levels using both pulsed fluoroscopy\nand full radiation modes. These dose variations are operated at varying source-image distances (SIDs). We\norganize the dataset in 6 different modes, as follows: Mode 0 (exposure with a normal dose at 110-cm SID),\nMode 1 (exposure with a low dose at 110-cm SID), Mode 2 (exposure with a normal dose at 90-cm SID),\nMode 3 (exposure with a low dose at 90-cm SID), Mode 4 (fluoroscopy with a normal dose at 110-cm SID), and\nMode 5 (fluoroscopy with a low dose at 90-cm SID). Assuming Mode 0 as ID, a progressive covariate shift is\nexpected from Mode 0 to Mode 5 in orders of magnitude, with Mode 5 being the most OOD. On the left side\nof Figure 1, we can observe how different fluoroscopy and exposure doses affect the high-frequency components\nof the scans. The full dataset consists of 18 Modes and two environments. This dataset will be made publicly\navailable alongside this paper\u2020."}, {"title": "B. BIMCV-COVID19+ Dataset", "content": "This is a large dataset that includes CR, DX, and CT images of\nCOVID-19 patients, as well as their radiographic findings, pathologies, polymerase (PCR), antibody tests, and\nradiographic reports from the Medical Image Data Bank of the Valencian Community (BIMCV). The first\niteration of the database includes 1,380 CX, 885 DX, and 163 CT studies from 1,311 COVID-19+ patients,\nresulting in 3,141 X-ray images and 2,239 CT images. The conducted study concentrates solely on the X-ray\nscans, clustered into 29 machine models. This grouping simulates real-world scenarios where machine learning\nmodels, trained on images from one specific X-ray machine, may need to process images from different machines,\npotentially leading to performance degradation. Figure 1 illustrates the differences between scans from different\nmachines. For our experiments, we define five distinct ID sets, each consisting of images from the five machines\nwith the most scans. The details of the ID sets are provided in Table 1. Each set is divided into 70% for training\nand 30% for testing."}, {"title": "2.2 AdverX-Ray", "content": "A common generative-based approach to OOD detection involves using a trained model to identify new unseen\nsamples. Similarly, an adversarially trained discriminator can provide a boundary for the ID set by assessing the\nprobability of a sample being real (ID) or synthetic (OOD). We can detect OOD samples by adjusting where\nthe discriminator learns to draw its boundary. It is on this premise that we propose AdverX-Ray, shown in\nFigure 2, an X-ray-tailored Adversarial VAE framework that, when fed with a batch of patches from an X-ray\nscan, can detect covariate shifts effectively. The model is a modified version of the Discriminative Covariate Shift\nPatch-based Network (DisCoPatch).10"}, {"title": "A. Overview", "content": "The AdverX-Ray approach integrates generative and reconstruction-based strategies to distill\ninformation in an unsupervised manner about the ID set and the OOD set boundaries for the discriminator."}, {"title": "B. Patching Strategy", "content": "The proposed patching strategy addresses the issue of black margins in chest X-\nrays, especially above the shoulders and in areas where black bars are used to maintain the aspect ratio. To\naddress this, we define a fixed region of interest that excludes the top and bottom 20% of the image, as well as\nthe outermost 20% both at the left and right sides. The extracted patches have a resolution of 128\u00d7128. The\nimage-level score during inference is calculated as the mean of the scores from all patches in that image."}, {"title": "2.3 Benchmark", "content": "For evaluating the Philips dataset, we utilize the entire test set to measure the performance of the\nmodels. However, the BIMCV-COVID19+ dataset involves a more nuanced approach. For each subset within\nthis dataset, the test set comprises the ID test split, as defined in Section 2.1, and OOD images. The OOD\nimages include the test splits of all other potential ID machines and the images from the remaining 24 machines.\nTo ensure a balanced comparison between ID and OOD images, we perform random image sampling from the\nOOD set 10 times. The final performance metrics for each model are averaged across these 10 iterations."}, {"title": "B. Models", "content": "For the initial evaluation on the internal Philips X-Ray Dataset, we select a state-of-the-\nart reconstruction-based method, DDPM-OOD,14 and an explicit density model known for its high-frequency\ndetection capabilities, GLOW.15 Additionally, we evaluate a conventional VAE,16 the proposed AdverX-Ray, and\nthe Adversarial VAE, which serves as the generator component of AdverX-Ray. Following this, we identify the\ntop three approaches and retrain them on the BIMCV-COVID19+ dataset to further validate their performance."}, {"title": "C. Performance metrics", "content": "Two metrics are used to evaluate the models, the Area Under the Receiver\nOperating Characteristic curve (AUROC) and the False Positive Rate at 95% True Positive Rate (FPR95)."}, {"title": "3. RESULTS AND DISCUSSION", "content": "This section presents a comprehensive analysis of the performance achieved by AdverX-Ray across both datasets.\nWe further investigate the influence of varying patch counts on AdverX-Rays's effectiveness, and we evaluate the\ncomputational demands associated with the proposed approach."}, {"title": "3.1 Philips X-ray Dataset", "content": "The results in Table 2 showcase the performance of the OOD detection methods in the X-ray setting with\nvarying acquisition parameters, which can influence heteroscedastic noise in the signal. Covariate shifts in the\nX-ray setting are intractable and usually not visible to the non-specialist. Regardless of this and except for the\nGLOW model trained on typicality, 17 all methods can detect a shift in the high-level image statistics."}, {"title": "3.2 BIMCV-COVID19+ Dataset", "content": "demonstrates the AdverX-Ray model prediction quality for all ID sets, compared to the VAE and\nGLOW. GLOW achieves poor results because of a known phenomenon in which it attributes higher likelihoods\nto OOD images.19 Interestingly, this limitation is inconsistent, occurring only for certain machines. AdverX-Ray\nconvincingly surpasses the VAE and GLOW in all test sets, except for the GE machine, which achieves close\nperformance to the VAE."}, {"title": "3.3 Impact of the number of patches", "content": "The results in Table 4 validate the prior choice of using 64 patches per image, as this configuration achieves\na strong balance between performance and computational efficiency. Although increasing the patch count per\nimage does yield incremental improvements, particularly in FPR95, the gains are marginal beyond 64 patches.\nThis effect is more noticeable in Figure 4, in which it is possible to observe that the major improvements for a\nlarger number of patches occur when using the GE machine, in which the model achieves its lowest performance."}, {"title": "3.4 Computational Requirements", "content": "To assess the computational requirements, Table 5 provides the model size, total number of parameters, average\ntraining time for all BIMCV-COVID19+ ID sets, and average inference time to obtain the score for a single\nimage. All models are evaluated with 64 patches per image. AdverX-Ray is the smallest and fastest model and\nrequires significantly less time than GLOW for training."}, {"title": "4. CONCLUSION", "content": "This paper introduces a novel image quality evaluation model, AdverX-Ray, an Adversarial VAE framework\ntailored to detecting OOD covariate shift in X-ray imaging. AdverX-Ray combines reconstructed and gener-\nated image patches in its training process to carefully distinguish various frequency-spectrum perturbations. By\nshowcasing its superior performance in detecting changes in imaging settings (Philips X-ray) and images from\ndifferent scanners (BIMCV-COVID19+), the model ensures the integrity of medical imaging systems and the po-\ntential CAD methods applied to the resulting images. AdverX-Ray's efficient and lightweight architecture makes\nit suitable for real-world applications requiring minimal computation resources and offers reliable deployment in\nclinical settings."}]}