{"title": "Inference of Abstraction for Grounded Predicate Logic", "authors": ["Hiroyuki Kido"], "abstract": "An important open question in AI is what simple and natural principle enables a machine to reason logically for meaningful abstraction with grounded symbols. This paper explores a conceptually new approach to combining probabilistic reasoning and predicative symbolic reasoning over data. We return to the era of reasoning with a full joint distribution before the advent of Bayesian networks. We then discuss that a full joint distribution over models of exponential size in propositional logic and of infinite size in predicate logic should be simply derived from a full joint distribution over data of linear size. We show that the same process is not only enough to generalise the logical consequence relation of predicate logic but also to provide a new perspective to rethink well-known limitations such as the undecidability of predicate logic, the symbol grounding problem and the principle of explosion. The reproducibility of this theoretical work is fully demonstrated by the included proofs.", "sections": [{"title": "Introduction", "content": "The current artificial intelligence (AI) systems such as large language models (LLMs) [1, 7] demonstrate a surprising linguistic ability in both what they know and how they articulate it. However, the common view is that they are still not as capable as ordinary people in several areas such as logical reasoning and abstract reasoning. For logical reasoning, it is unlikely to believe that the statistical patterns an AI algorithm extracts from finite training data can capture the infinite set of rules of valid inference studied in formal logic. For abstract reasoning, it is still unclear how a machine should explore and discover abstract concepts and principles from the real world in its own way. Consider the following problems requiring both abstract reasoning and logical reasoning skills.\nExample 1. Carol remembers the following three scenes.\nAlice and Bob did not blame each other.\nOne day Alice blamed Bob, and she blamed herself afterwards.\nAlice and Bob blamed each other on another day.\nOne day Carol wants to blame Bob. She hesitated it because she learnt that someone will blame those who blame anyone, which can be expressed in a predicate language as follows.\n$\\forall xy Blames(x,y) \\rightarrow \\exists z Blames(z, x)$\nExample 2. Consider the following three data. What number fits in the blank?\nThe correct number could be 18 as the following predicate knowledge can be extracted.\ntop \u00d7 left + right = bottom"}, {"title": "Inference of Abstraction for Grounded Predicate Logic", "content": "Interestingly, the current AI systems such as ChatGPT [1] and DeepSeek [7] often answer them incorrectly. Their failure is mainly due to a lack of abstract or logical reasoning skills, but not a lack of arithmetic skills. Abstraction and Reasoning Corpus (ARC) [6] is a benchmark test designed to test machine's ability to extract graphical patterns from images, but not the intellectual ones shown above.\nIn this paper, we ask how logical reasoning in predicate logic emerges from reasoning based on data. The underlying idea discussed in this paper is abstraction. Roughly speaking, it is about an inferential process of deriving intrinsically abstract symbols from intrinsically concrete data through selective ignorance. It is not about generalisation where typical inferential processes, e.g., deductive reasoning, is used backward for general rules from specific examples or facts. This type of reasoning is intensively studied as inverse resolution [18, 19], inverse deduction [22] and inverse entailment [17] mainly in inductive logic programming (ILP) [19]. It is either not about parametric learning where intrinsically concrete data are assumed to be generated from parameters of a probability distribution. This idea is prevalent in various applications of machine learning and statistics, e.g., [2, 23, 4, 14, 15]. Abstraction is rather relevant to top-down (memory/experience-driven) and bottom-up (sensory-driven) information processing used by neuroscientists and AI researchers as a metaphor for the cognitive process of biological brains, e.g., [20, 10, 16, 11, 9, 21, 8].\nIn this paper, we extend the inference of propositional abstraction [12, 13] to the inference of predicative abstraction towards enhanced human-like machine intelligence. The key idea is to use the property of predicate logic and expand the joint probability distribution over data, models of predicate logic and predicate formula, denoted by D, M and a, respectively, as follows.\n$p(D, M, \\alpha) = p(a|M)p(M|D)p(D).$\nThe right-hand side realises the idea that a formula is an abstraction, or selective ignorance, of models and each of the models is an abstraction of data.\nWe show that the inference of predicative abstraction serves as a solution to simple yet important problems such as Examples 1 and 2. The research is not as straightforward as we think because the semantics of predicate logic needs a reformulation in accordance with abstraction. Our theory assumes only closed formulas, i.e., predicate formulas without free variables, to balance the expressiveness and simplicity of the theory. The contributions of this paper are summarised as follows.\nWe introduce a simple theory of inference that opens up the possibility of combining probability theory and predicate logic in a data-driven manner. Predicate reasoning in our theory always proceeds between data and predicate formulas. This suggests a shift in the traditional view that predicate reasoning proceeds between predicate formulas via rules of inference (see Section 2).\nThe theory allows us to see the traditional model-based predicate reasoning as a special case of data-based predicate reasoning studied in this paper. The data-based perspective provides a new opportunity to rethink some existing limitations such as the undecidability of predicate logic, the symbol grounding problem [10, 22] and commonsense reasoning [3, 5] (see Sections 3.1, 3.2 and 3.3).\nWe demonstrate a solution to simple yet essential problems that are often difficult to solve by existing established approaches (see Section 3.4)."}, {"title": "Proposals", "content": "The inference of abstraction for propositional logic [12, 13] is insufficient to handle problems like Examples 1 and 2. We thus propose the inference of abstraction for predicate logic in this section. Let {d1,d2, ...,dk} be a multiset of K data and D be a random variable for data taking values from {d1, d2, ..., dk }.\nDefinition 3. Let dk \u2208 {d1,d2,...,dk}. Th probability of dk, denoted by p(D = dk), is defined as follows.\n$p(D = d_k) = \\frac{1}{K}$ (1)\nNamely, p(D) is a uniform distribution. Let C, V, F and P be the sets of constants, variables, function symbols and predicate symbols, respectively, and L be the predicate language built with these vocabularies.\nExample 4. Consider the following vocabularies of a predicate language.\nConstants: C = {alice, bob}\nVariables: V = {x,y}\nFunction symbols: F = {mentor}\nPredicate symbols: P = {Blames}\nThe following is a predicate formula meaning that Alice's mentor blames everyone who blames someone.\n$\\forall x(\\exists y(Blames(x,y)) \\rightarrow Blames(mentor(alice), x))$\nIn this paper, we assume that the predicate language includes only formulas without free variables, i.e., closed formulas.1 We exclude open formulas for the following reasons. First,"}, {"title": "Inference of Abstraction for Grounded Predicate Logic", "content": "it is inappropriate to view an assignment in predicate logic as an abstraction, or selective ignorance, of data or observations. Its inclusion thus does not fit the underlying idea of the inference of abstraction. Second, a lot of cases such as Examples 1 and 2 do not need open formulas. Its inclusion thus makes our formalism unnecessary complicated.\nAs usual, a model in predicate logic is a pair of a domain of discourse and valuation function. The domain of discourse, denoted by u, is a non-empty set of a finite or countably infinite number of entities. The valuation function, denoted by v, is a function that associates constants, function symbols and predicate symbols with u. We use the symbol ar(x) to denote the arity of the function or predicate symbol x. Specifically,\nv maps each constant c\u2208 C to an entity of u, i.e., v(c) \u2208 u.2\nv maps each function symbol f \u2208 F to an ar(f)-ary function from u to $u^{ar(f)}$, i.e., v(f) : $u^{ar(f)}$ \u2192 u.\nv maps each predicate symbol P\u2208P to a subset of $u^{ar(P)}$, i.e., v(P) \u2286 $u^{ar(P)}$.\nFrom the viewpoint of the inference of abstraction, it is important to adopt the perspective that each model represents a different state of the world. For any function symbol f \u2208 F, we write v(f)(v(t\u2081), ..., v(tar(f))) as v(f(t1, ...,tar(f))), where t1, t2, ...tar(f) are the arguments of f called terms referring to constants, variables or functions.\nLet {m1, m2,..., mv} be the set of models of the predicate language L. This set is finite or countably infinite. Let M be a random variable for the models taking values from {m1, m2, ..., mv}. We assume that each data point supports a single model. We thus assume a function m: {d1,d2,...,dk} \u2192 {M1, M2, ..., MN} such that m(dk) denotes the model supported by data dk.\nDefinition 5. Let dk \u2208 {d1,d2, ..., dk} and mn \u2208 {m1, m2, ..., MN}. The probability of mn given dk, denoted by p(M = mn|D = dk), is defined as follows.\n$p(M = m_n|D = d_k) =\\begin{cases}1 & \\text{if } m_n = m(d_k) \\\\ 0 & \\text{otherwise}\\end{cases}$ (2)\nWe use the symbols u(mn) and v(mn) to denote the domain of discourse and the valuation function of the model mn, i.e., mn = (u(mn), v(mn)). Thus, the model supported by data dk can be written as m(dk) = (u(m(dk)), v(m(dk))).\nExample 6. Consider the predicate language L built with the following vocabularies.\nConstants: C = {alice, bob}\nVariables: V = {x,y}\nFunction symbols: F = {0}\nPredicate symbols: P = {Blames}\nThe top layer of the hierarchy shown on the right in Figure 1 shows twenty data. Given u = {\u2299,\u2295}, the middle layer shows all the thirty two models (u, v) of the language L. The depth of the middle layer shows how the valuation function v associates the constants alice and bob with u. Its width shows how v associates the predicate symbol Blames to u, where an arrow from x to y represents that x blames y. Each blank cell in the middle layer is not a model due to the assumption we made in Footnote 2. The arrow from the top to middle layers represent a function m. The twenty data dk commonly say that there are two people \u2299 and named Alice and Bob, respectively, i.e., u(m(dk)) = {\u2299, \u2295}, v(m(dk))(alice) = \u2299 and"}, {"title": "Models support formulas", "content": "We are interested in the probability of predicate formula a \u2208 L being true or false. We thus assume that each formula is a random variable taking values from {0,1}. For any truth values v \u2208 {0,1}, we use the symbol [a = v] to denote the set of models where a has the truth value v. We often write [a = v]mn = 1 if mn \u2208 [a = v] and [a = v]mn = 0 otherwise for the membership of the model. We call formulas with neither logical connectives, such as \u00ac, V, \u2227 and \u2192, nor quantifiers, such as \u2200 and \u2203, atomic formulas. Let mn = (u, v) be a model. As usual, the truth value of an atomic formula without variables is defined as follows.\n$[P(t_1,...,t_{ar(P)})]_{m_n}=\\begin{cases}1 & \\text{if } (v(t_1), ..., v(t_{ar(P)})) \\in v(P)\\\\ 0 & \\text{otherwise}\\end{cases}$\nLet \u03b1, \u03b2 \u2208 L be formulas and mn = (u, v) be a model. As usual, the truth values of compound formulas with logical connectives are defined as follows.\n$[\\neg a]_{m_n} = 1 \\Leftrightarrow [a]_{m_n} = 0$\n$[\\alpha \\wedge \\beta]_{m_n} = 1 \\Leftrightarrow [a]_{m_n} = 1 \\text{ and } [\\beta]_{m_n} = 1 \\Leftrightarrow min\\{[a]_{m_n}, [\\beta]_{m_n}\\}$\n$[a \\vee \\beta]_{m_n} = 1 \\Leftrightarrow [a]_{m_n} = 1 \\text{ or } [\\beta]_{m_n} = 1 \\Leftrightarrow max\\{[a]_{m_n}, [\\beta]_{m_n}\\}$\n$[a \\rightarrow \\beta]_{m_n} = 1 \\Leftrightarrow [a]_{m_n} = 0 \\text{ or } [\\beta]_{m_n} = 1 \\Leftrightarrow max\\{1 - [a]_{m_n}, [\\beta]_{m_n}\\}$\nLet us use the symbol a[c/x] to denote the formula replacing all the free variables x \u2208 \u03bd in the formula a by the constant c\u2208 C. Here, a variable x is free if there is no quantifier bounding x or x is outside the scope of such quantifiers. As usual, the truth values of compound formulas with quantifiers are defined as follows.3\n$[\\forall x a]_{m_n} = 1 \\leftrightarrow [a[c/x]]_{m_n} = 1, \\text{ for all } c \\in C \\leftrightarrow min\\{[a[c/x]]_{m_n}\\}_{c \\in C}$\n$[\\exists x a]_{m_n} = 1 \\leftrightarrow [a[c/x]]_{m_n} = 1, \\text{ for some } c \\in C \\rightarrow max\\{[a[c/x]]_{m_n}\\}_{c \\in C}$\nWe say that a formula a \u2208 L is true in a model mn or mn satisfies, or supports, a if [a]mn = 1. We also write [a]mn = 1 as mn \u2208 [\u03b1].\nExample 7 (Continued). Let us find the models where everyone blames someone, i.e., \u2200x\u2203y Blames(x, y), is true. Each atomic formula has the following truth value (see Figure 1).\n[Blames(alice, alice)] = {mn|n \u2208 {5-8, 13-16, 25-32}}\n[Blames(alice, bob)] = {mn|n \u2208 {3, 4, 7, 8, 11, 12, 15, 16, 18, 20, 22, 24, 26, 28, 30, 32}}\n[Blames(bob, alice)] = {mn|n \u2208 {2, 4, 6, 8, 10, 12, 14, 16, 19, 20, 23, 24, 27, 28, 31, 32}}\n[Blames(bob, bob)] = {mn|n\u2208 {9-16, 21-24, 29-32}}"}, {"title": "Inference of Abstraction for Grounded Predicate Logic", "content": "The compound formula, \u2200x\u2203y Blames(x,y), thus has the following truth value.\n$[\\forall xy Blames(x,y)]_{m_n} = min \\{\\exists y Blames(C_1, y)]_{m_n}\\}_{C_1 \\in C}$\n$= min \\{ max \\{[Blames(C_1, C_2)]_{m_n}\\}_{C_2 \\in C}\\}_{C_1 \\in C}$\n$= min\\begin{cases}max \\{\\[Blames(alice, alice)]_{m_n}, \\[Blames(alice, bob)]_{m_n}\\}, \\\\max \\{\\[Blames(bob, alice)]_{m_n}, \\[Blames(bob, bob)]_{m_n}\\}\\end{cases}$=\n$\\begin{cases}1 & \\text{if } n \\in \\{3-8, 11-16, 18, 20, 22, 24-32\\} \\cap \\{2, 4, 6, 8-16, 19-24, 27-32\\}, \\text{ i.e.,}\\\\ & \\text{if } n \\in \\{4, 6, 8, 11-16, 20, 22, 24, 27-32\\} \\\\0 & \\text{otherwise}\\end{cases}$\nThe probability of the truth of a formula is defined using the semantics of predicate logic.\nDefinition 8. Let \u03bc\u2208 [0.5, 1], dk \u2208 {d1, d2, ..., dk}, mn \u2208 {m1, m2, \u2026, MN }, A1, A2, ..., \u03b1\u0399 \u2208 Land v1, v2, ..., v\u2081 \u2208 {0,1}. The probability of a1 = v1 given a2 = U2, ..., A1 = V1, M = Mn and D = dk, denoted by p(\u03b11 = V1|X2 = U2, ..., \u03b1\u2081 = v1, M = mn, D = dk), is defined as follows.\n$p(\\alpha_1 = v_1 | \\alpha_2 = v_2, ..., \\alpha_l = v_l, M = m_n, D = d_k) =\\begin{cases}\\mu & \\text{if } m_n \\in [\\alpha_1 = v_1] \\\\1- \\mu & \\text{otherwise}\\end{cases}$\nIf we adopt the convention that 00 1 then Definition 8 can be expressed as a Bernoulli distribution with parameter \u03bc.\n$p(\\alpha_1 = v_1 | \\alpha_2 = v_2, ..., \\alpha_l = v_l, M = m_n, D = d_k) = \\mu^{[a_1=v_1]_{mn}}(1 - \\mu)^{1-[a_1=v_1]_{mn}}$\nIn Figure 1, the arrows from the middle to the bottom layer of the hierarchy shown on the right indicate that the predicate formula is true in these models. The following probabilistic property of conditional independence comes directly from the property of predicate logic.\nProposition 9. Let a1, a2 \u2208 L. a1 is conditionally independent of a2 and D given M, i.e., p(\u03b11 \u03b12, M, D) = p(\u03b1\u2081|\u041c).\nProof. Using the definition of conditional probability, the right-hand side can be written as\n$p(\\alpha_1 | M) = \\frac{p(\\alpha_1, M)}{p(M)}$\nUsing the sum rule [2] and the product rule [2] of probability theory, its numerator can be expanded as\n$p(\\alpha_1, M) = \\sum_{v_2} \\sum_{d_k} p(\\alpha_1, \\alpha_2 = v_2, M, D = d_k)$\n$= \\sum_{v_2} \\sum_{d_k} p(\\alpha_1|\\alpha_2 = v_2, M, D = d_k)p(\\alpha_2 = v_2, M, D = d_k)$.\nNow, it is obvious from Definition 8 that neither a2 nor D affects the value of p(\u03b11 a2 = 02, M, D = dk). We can thus move it outward. Using the sum rule, we have\n$p(\\alpha_1, M) = p(\\alpha_1|\\alpha_2, M, D) \\sum_{v_2} \\sum_{d_k} p(\\alpha_2 = v_2, M, D = d_k) = p(&_1|4_2, M, D)p(M).$"}, {"title": "Hiroyuki Kido", "content": "Taking into accout the denominator, the original expression can be written as\n$p(\\alpha_1 | M) = \\frac{p(\\alpha_1 | \\alpha_2, M, D)p(M)}{p(M)} = p(\\alpha_1 | \\alpha_2, M, D).$\nFrom the equation in Proposition 9, we can simplify Definition 8 as follows.\n$p(a_1 = v_1|M = m_n) = \\mu^{[a_1=v_1]} (1 - \\mu)^{1-[\\alpha_1=v_1]}$ (3)\nThe following example shows why we need to assume \u03bc\u2208 [0.5, 1], rather than simply \u03bc = 1.\nExample 10 (Continued.). Let \u03bc = 1 and a = Blames(alice, bob) ^ \u00abBlames(alice, bob). Using the definition of conditional probability, the sum rule, the product rule and Proposition 9, we have\n$p(M = m_4|a) = \\frac{p(M = m_4, a)}{p(\u03b1)} = \\frac{p(M = m_4, a)}{\\sum_{n=1}^{32} p(M = m_n, a)} =\\frac{p(a|M = m_4)p(M = m_4)}{\\sum_{n=1}^{32} p(\u03b1|M = m_n)p(M = m_n)} =\\frac{(1 - \\mu)p(M = m_4)}{\\sum_{n=1}^{32} (1 - \\mu)p(M = m_n)} =\\frac{0}{0} =1$\nNamely, the value is undefined due to division by zero. However, given \u00b5 \u2260 1 such as \u03bc approaches one, denoted by \u00b5 \u2192 1, the undefined value can be replaced by a reasonable one.\n$p(M = m_4|a) = lim_{\\mu \\rightarrow 1} \\frac{(1 - \\mu)p(M = m_4)}{\\sum_{n=1}^{32} (1 - \\mu)p(M = m_n)} = \\frac{p(M = m_4)}{\\sum_{n=1}^{32} p(M = m_n)} = p(M = m_4)$\nHere, $\\sum_{n=1}^{32} p(M = m_n) = 1$ as p(M) is the probability distribution over all the models.\nIn Section 3, we will discuss that \u03bc = 1 corresponds to the logical consequence relation and \u03bc \u2192 1 corresponds to its natural generalisations. In Figure 1, each arrow between the middle and bottom layers of the hierarchy shown on the right shows that the model satisfies or supports the formula, \u2200x(\u2203y(Blames(x, y)) \u2192 Blames(alice, x))."}, {"title": "Predicate reasoning", "content": "We can now discuss probabilistic reasoning with predicate language. The following property is useful to simply our notation.\nProposition 11. Let a \u2208 L. p(a = 1) = p(\u00ab\u03b1 = 0).\nProof. a is true in a model iff \u00aca is false in the model. Thus, [a = 1] = [\u00ab\u03b1 = 0]. Using the sum rule, the product rule and Proposition 9, we have\n$p(\\alpha = 1) = \\sum_{m_n} p(\\alpha = 1|M = m_n)p(M = M_n) = \\sum_{m_n} \\mu^{[a=1]_{m_n}} (1 - \\mu)^{1-[a=1]_{m_n}}p(M = m_n)$\n$= \\sum_{m_n} \\mu^{[a=0]_{m_n}} (1 - \\mu)^{1-[a=0]_{m_n}}p(M = m_n)$\n$= \\sum_{m_n} p(\\llcorner \\alpha = 0|M = m_n)p(M = m_n) = p(\\llcorner \\alpha = 0).$\nThis holds regardless of the value of \u03bc."}, {"title": "Inference of Abstraction for Grounded Predicate Logic", "content": "Therefore, we can write \u03b1 0 as a = 1 and abbreviate a = 1 as a, for all a \u2208 L. We also abbreviate M = mn and D = dk as mn and dk, respectively.\nNow, using the sum rule, the product rule and the conditional independence, i.e., Proposition 9, the probability of \u03b1, \u03b2\u2208 L can be expressed as follows.\n$p(\\alpha, \\beta) = \\sum_k \\sum_n p(\\alpha, \\beta, m_n, d_k) = \\sum_k \\sum_n p(a|\\beta, m_n, d_k)p(\\beta|m_n, d_k)p(m_n|d_k)p(d_k)$\n$= \\sum_k \\sum_n p(a|m_n)p(\\beta|m_n)p(m_n|d_k)p(d_k)$\nSince p(dk) = 1/K, i.e., Definition 3, and our assumption that each data point supports a single model, we finally have\n$p(\\alpha, \\beta) = \\frac{1}{K} \\sum_k \\sum_n p(\\alpha|m_n)p(\\beta|m_n)p(m_n|d_k) = \\frac{1}{K} \\sum_k p(a|m(d_k))p(\\beta|m(d_k)).$ (4)\nWe here used $\\sum_n p(a|m_n)p(\\beta|m_n)p(m_n|d_k) = p(a|m(d_k))p(\\beta|m(d_k))$. This fact is crucially important in terms of decidability and computational complexity since N can be countably infinite.\nExample 12. Let a be \u2200x(\u2203y(Blames(x,y)) \u2192 Blames(alice,x)) shown in Figure 1. The probability of the formula being true can be evaluated using Equation (4).\n$p(\\alpha) = \\frac{1}{20} \\sum_{k=1}^{20} p(a|m(d_k)) = \\frac{1}{20} \\sum_{k=1}^{20} \\mu^{[a]_{m(d_k)}} (1 - \\mu)^{1-[a]_{m(d_k)}}$\n$= \\frac{1}{20} \\{\\sum_{k \\in \\{1-17\\}} \\mu^{1}(1 - \\mu)^{0} + \\sum_{k \\in \\{18-20\\}} \\mu^{0}(1 - \\mu)^{1}\\}$\n$= \\frac{1}{20} \\{\\sum_{k \\in \\{1-17\\}} \\mu + \\sum_{k \\in \\{18-20\\}} (1 - \\mu)\\} = \\frac{17\\mu + 3(1 - \\mu)}{20}$\nTherefore, p(a) = 17/20 when \u03bc = 1. This result is intuitive as it is the number of data supporting models where a is true, out of all the twenty data."}, {"title": "Evaluations", "content": "The common view in statistics is that observed data are generated from unobserved parameters of a probability distribution. Maximum likelihood estimation (MLE) is the most commonly used statistical method to estimate the values of unobserved parameters only from observed data. MLE is defined as $\\Theta = arg \\underset{\\Theta}{max} p(d_1, d_2, ..., d_k|\\Theta)$, where each dk is an observed data point and is the set of parameters of a probability distribution.\nProposition 13. Let {d1,d2, ...,dx} be a multiset of K data and O be the parameters of a categorical distribution. p(M) = \u00db if and only if \u00db maximises the likelihood of data, i.e., $\\hat{\\Theta} = arg \\underset{\\Theta}{max} p(d_1, d_2, ..., d_k|\\Theta)$.\nProof. Let K be the total number of data, and Kn be the number of data in the nth category or model. The maximum likelihood estimate of the parameter on for a categorical distribution is simply known as the relative frequency of data, i.e.,\n$\\theta_n = \\frac{\\text{The number of data in the nth category}}{\\text{The total number of data}} = \\frac{K_n}{K}$"}, {"title": "Hiroyuki Kido", "content": "Therefore, the maximum likelihood estimate is given by\n$\\hat{\\Theta} = (\\frac{K_1}{K}, \\frac{K_2}{K}, ..., \\frac{K_N}{K})$\nLet mn be a model of predicate logic. Using the sum and product rules, we have\n$p(m_n) = \\sum_k p(m_n, d_k) = \\sum_k p(m_n|d_k)p(d_k) = \\frac{1}{K} \\sum_k p(m_n, d_k) = \\frac{K_n}{K}$\nTherefore, we have p(M) = \u00d4."}, {"title": "Reasoning from possible information", "content": "This section aims to logically characterise the inference of predicative abstraction with \u03bc = 1. We focus on the relation between models and formulas by marginalising out data, i.e., $p(a, M) = \\sum_k p(a, M, D = d_k)$. As usual, we use the symbol [A] to denote the set of models where all the formulas in \u2206 \u2286 L are true, i.e., $[\\Delta] = \\bigcap_{a \\in \\Delta}[a]$. A model with a non-zero probability is called possible. We use the symbol [[\u25b3] to denote the set of possible models where all the formulas in \u2206 C L are true, i.e., $[[\\Delta] = \\{m_n \\in [\\Delta]|p(m_n) \\neq 0\\}$. We write $m_n \\in [\\Delta]$ and $m_n \\in [[\\Delta]$ as $[\\Delta]_{m_n} = 1$ and $[[\\Delta]_{m_n} = 1$, respectively. We use the empirical consequence relation originally defined for propositional logic.\nDefinition 15 ([12]). Let a \u2208 L and \u2206 \u2286 L. a is an empirical consequence of \u2206, denoted by \u2261\u2206 a, if [[\u0394]\u2286 [\u03b1].\nAs usual, a is a logical consequence of \u2206, denoted by \u2206 \u255e a, if [\u0394] \u2286 [a]. The empirical consequence relation is thus a probabilistic generalisation of the logical consequence relation \u255e.\nWe write p\u03bc=1(a) and p\u03bc\u21921(a) when we want to specify the value of u used in the evaluation. We often omit it when the value of u is obvious from the context. We can now logically characterise the inference of predicative abstraction with \u03bc = 1.\nTheorem 16. Let a \u2208 L and \u2206 \u2286 L such that [[\u25b3] \u2260 0.\n$P_{\\mu=1}(\\alpha|\\Delta) = \\frac{\\sum_n[\\alpha]_{m_n}[\\Delta]_{m_n}p(m_n)}{\\sum_n[\\Delta]_{m_n}p(m_n)}$\nProof. Using the definition of conditional probability and the conditional independence we showed in the previous section, we have\n$p(\\alpha | \\Delta) = \\frac{p(\\alpha, \\Delta)}{p(\\Delta)} = \\frac{\\sum_n p(\\alpha, \\Delta, m_n)}{\\sum_n p(\\Delta, m_n)} = \\frac{\\sum_n p(\\alpha|m_n)p(\\Delta|m_n)p(m_n)}{\\sum_n p(\\Delta|m_n)p(m_n)}.$\nDividing models into possible ones, i.e., [[A], and the others, we have\n$p(\\alpha | \\Delta) = \\frac{\\sum_{m_n \\in [[\\Delta]} p(\\alpha|m_n)p(\\Delta|m_n)p(m_n) + \\sum_{m_n \\notin [[\\Delta]} p(\\alpha|m_n)p(\\Delta|m_n)p(m_n)}{\\sum_{m_n \\in [[\\Delta]} p(\\Delta|m_n)p(m_n) + \\sum_{m_n \\notin [[\\Delta]} p(\\Delta|m_n)p(m_n)}$"}, {"title": "Inference of Abstraction for Grounded Predicate Logic", "content": "Since \u03bc = 1, p(\u2206|mn) can be expanded as follows.\n$p(\\Delta|m_n) = \\prod_{\\beta \\in \\Delta} p(\\beta|m_n) = \\prod_{\\beta \\in \\Delta} 1^{[\\beta", "0^{1-[\\beta": {"Delta": 0, "\u0394": "."}, "\u0394": ".", "Delta": ""}, "p(\\Delta|m_n)p(m_n) = 0$. Since p(\u2206|mn) = 1, for all mn \u2208 [[\u2206"]}