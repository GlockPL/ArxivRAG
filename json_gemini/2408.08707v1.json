{"title": "Beam Prediction based on Large Language Models", "authors": ["Yucheng Sheng", "Kai Huang", "Le Liang", "Peng Liu", "Shi Jin", "Geoffrey Ye Li"], "abstract": "Millimeter-wave (mmWave) communication is promising for next-generation wireless networks but suffers from significant path loss, requiring extensive antenna arrays and frequent beam training. Traditional deep learning models, such as long short-term memory (LSTM), enhance beam tracking accuracy however are limited by poor robustness and generalization. In this letter, we use large language models (LLMs) to improve the robustness of beam prediction. By converting time series data into text-based representations and employing the Prompt-as-Prefix (PaP) technique for contextual enrichment, our approach unleashes the strength of LLMs for time series forecasting. Simulation results demonstrate that our LLM-based method offers superior robustness and generalization compared to LSTM-based models, showcasing the potential of LLMs in wireless communications.", "sections": [{"title": "I. INTRODUCTION", "content": "ILLIMETER wave (mmWave) communication is widely acknowledged as a key technology for next- generation wireless networks due to its huge bandwidth. To address the significant path loss inherent to mmWave sig- nals, huge antenna arrays are often deployed in both base stations (BSs) and user terminals (UTs), facilitating directional transmissions. This directional transmission requires beam training to maximize received power. However, the optimal beam direction changes rapidly in high mobility environments, necessitating frequent beam training and accuracy beam pre- diction.\nDeep learning (DL) has recently gained significant research interest in wireless communications due to its strong ability to extract nonlinear features. To improve beam tracking per- formance, DL is commonly employed to extract UT move- ment features from received signals, thereby predicting future beam variations. Long short-term memory (LSTM) models, in particular, are typically used to periodically predict the next optimal beam based on signals from previous beam tracking, with the prediction period matching the beam measurement period [1][2][3]. However, due to the relatively small number of parameters in LSTM-based models, these models are often sensitive to different wireless environments, and result in poor robustness and generalization, which is a critical issue for the practical applications of learning-based models. This stands in stark contrast to foundation language models, such as GPT-2 [4], GPT-4, and LLaMa [5], which exhibit remarkable robustness.\nPre-trained foundation models, such as large language models (LLMs), have revolutionized computer vision (CV) and natural language processing (NLP). Despite some studies suggesting the potential transformative impact of large models on wireless communications [6][7][8], specific applications of these models in beam prediction have yet to be realized. To bridge this gap, we propose a beam prediction model leverag- ing LLMs, framing the problem as a time series forecasting task. The robustness of our approach depends on effectively aligning the modalities of wireless data and natural language. This alignment is challenging because LLMs process discrete tokens, whereas wireless data is analog. Additionally, the ability to interpret wireless data patterns is not inherently included in the pre-training of LLMs [9]. Therefore, it remains an open issue to combine LLM with wireless data.\nIn this letter, we introduce a framework designed to leverage large language models for beam prediction without alter- ing the underlying model architecture. Our primary strategy involves aggregating messages from diverse variables and then transforming the aggregated information into text-based prototype representations that align better with the capabilities of language models. To enhance the model's understanding and reasoning abilities of wireless data, we utilize a novel technique, called Prompt-as-Prefix (PaP). Simulation results demonstrate that our LLM-based method exhibits superior robustness and generality compared to LSTM-based prediction schemes. Our initial research indicates that LLM hold promise for diverse applications in wireless communication, shedding lights on the research of LLM-assisted wireless communica- tion."}, {"title": "II. SYSTEM MODEL", "content": "Consider the downlink mmWave transmission for a single user, where the BS and UTs are equipped with M antennas and a single antenna, respectively. Notably, our proposed scheme can be directly extended to the multiuser scenario with multiple UT antennas.\nTo accurately model the beam variations resulting from UT mobility, we adopt the well-known Saleh-Valenzuela (SV) channel model [10] [11]. In this model, the channel vector corresponding to the n-th time slot can be expressed as\n$h_n = \\sum_{l=1}^{L_n} \\sqrt{p_{n,l}} a(\\varphi_{n,l}) a^*(\\theta_{n,l}),$ (1)"}, {"title": null, "content": "where $L_n$ denotes the number of paths at the n-th time slot, while the l-th path is with path loss $p_{n,l}$, complex gain $a_{n,l}$, and angle of departure (AoD) $\\varphi_{n,l}$. It should be noted that in this model, the line-of-sight (LOS) path is dominant. Additionally, $a \\in C^{M \\times 1}$ represents the antenna response vector. Assuming the BS is equipped with a uniform linear array (ULA), the antenna response vector can be expressed as\n$a(\\varphi) = [1 \\quad e^{j2\\pi d \\sin \\varphi/\\lambda} \\quad ... \\quad e^{j\\pi (M-1)d \\sin \\varphi/\\lambda}],$ (2)\nwhere is the AoD, d and $\\lambda$ denote the antenna spacing and wavelength, respectively. For simplicity, we set d = $\\lambda$/2.\nWe assume that a single radio frequency (RF) chain and phase shifter based analog beamformer are employed at the BS. The discrete Fourier transform (DFT) codebook F, com- prising Q candidate beams, is considered. Specifically, the BS selects one transmit beam $f_n \\in F$ at the n-th time slot. The q-th candidate transmit beam $f^{(q)} \\in C^{M \\times 1}$, where q \u2208 {0, 1, 2, ..., Q \u2212 1}, can be expressed as\n$f^{(q)} = \\frac{1}{\\sqrt{M}} [1 \\quad e^{j2\\pi q/Q} \\quad ... \\quad e^{j2\\pi (M-1)q/Q}]^T.$ (3)\nBeam prediction aims to forecast the transmit beam $f^{(q*)}$ with the largest gain from all candidates, which can be formulated as\n$q^* = \\arg \\max_{q \\in \\{0,1,2,...,Q-1\\}} |h_n^Tf^{(q)}|^2,$ (4)\nIn this letter, we predict the optimal beam for the next H time steps based on the information from the past T time steps, including the optimal beam and AoD. Our goal is to achieve the maximum normalized beamforming gain for the future H time steps, which can be expressed as\n$max\\quad G_N = \\frac{|h^Tf^{(q*)}|^2}{|h^Tf^{(q*)}|^2},$ (5)\nwhere $q^*$ represents the predicted optimal beam index."}, {"title": "III. PREDICTION MODEL BASED ON LLM", "content": "In this letter, we propose reprogramming an embedding- visible large language model, such as Llama and GPT-2, to perform optimal beam forecasting without the need for fine- tuning the backbone model. Specifically, for the i-th sequence of historical observations $X^{(i)} \\in R^{C \\times T}$, where C denotes the number of variables, we aim to adapt a large language model f(\u00b7) to interpret the input time series and accurately predict the values at H future time steps, represented by $\\hat{Y}^{(i)} \\in R^{1 \\times H}$.\nInput Preprocessing We use past optimal beam indexes $q_t \\in R^{1xT}$ and AoD $\\varphi_s \\in R^{1\\times T}$ as historical observations. Different numbers of antennas cause different ranges of beam indexes, which reduces generalization. Therefore, we first map the sequence of past optimal beam indexes $q_t$ into the angular domain, represented by\n$q_a = \\frac{q_t}{Q}.$ (6)\nMoreover, by using $\\frac{q_t}{+Q}$ or $\\frac{q_t}{-Q}$, we achieve continuity between values at consecutive time steps, thereby avoiding sudden jumps in the input values between successive time steps."}, {"title": null, "content": "Finally, we can get the input $X^{(i)}$ by combining the $q_a$ and $\\varphi_s$.\nInput Embedding Each input sample $X^{(i)} \\in R^{C \\times T}$ is initially normalized to have zero mean and unit standard deviation using reversible instance normalization (RevIN) to mitigate time series distribution shifts. Subsequently, $X^{(i)}$ is segmented into several consecutive, overlapped or non- overlapped patches $X_p^{(i)}$ with a length of $L_p$. The total number of input patches is determined by:\n$P = \\lfloor \\frac{T-L_p}{S} \\rfloor+2,$ (7)\nwhere S denotes the horizontal sliding stride. This process serves two primary purposes: (1) preserving local semantic information by aggregating it into each patch, and (2) function- ing as tokenization and forming a compact sequence of input tokens that reduces computational complexity. These patches $X_p^{(i)} \\in R^{P \\times C \\times L_p}$ are then embedded as $A_p^{(i)} \\in R^{P \\times C \\times d_m}$ using a straightforward linear layer as the patch embedding.\nCross-Variable Attention In this letter, a learnable vector is used as a router to aggregate messages from all variables. This is achieved by using $R^{(i)}$ as query and vectors of all variables $A_p^{(i)}$ as both key and value, denoted by\n$B^{(i)} = ATTENTION(R^{(i)}, A_p^{(i)}, A_p^{(i)}),$ (8)\nwhere $R^{(i)} \\in R^{P \\times 1 \\times d_m}$ serves as a router. Cross-variable attention is applied to analyze the relationship between the $q_a$ and $\\varphi_s$ and to aggregate messages into $B^{(i)} \\in R^{P \\times 1 \\times d_m}$, which is then passed to patch reprogramming.\nPatch Reprogramming We reprogram patch embedding into the source data representation space to align the modal- ities of time series and natural language, thereby activating the ability of LLMs to understand and reason about time series data. However, time series cannot be directly edited or described losslessly in natural language, which presents significant challenges for LLMs to understand time series without resource-intensive fine-tuning.\nTo address this challenge, we propose reprogramming $B^{(i)}$ using pre-trained word embeddings $E \\in R^{V \\times D}$ within the backbone, where V is the vocabulary size. However, there is no prior knowledge indicating which source tokens are directly relevant, making direct use of E impractical due to the large and potentially dense reprogramming space. A practical solution is to maintain a small collection of text prototypes by linearly probing E, denoted as $E' \\in R^{V' \\times D}$, where $V' \\ll V$. To identify a small set of text prototypes E' from E, we learn a matrix $W \\in R^{V' \\times V}$ as the intermediary. These text prototypes learn connecting language cues (e.g., \"short up\" for an upward trend and \u201csteady down\" for a downward trend) that can be combined to represent local patch information (e.g., \"short up then down steadily\" to describe a specific patch) without leaving the pre-trained space of the language model. This approach is efficient and enables the adaptive selection of relevant source information.\nTo implement this, we employ a multi-head cross-attention layer. Specifically, for each head k = {1,\u2026\u2026, K}, we define query matrices $Q_k^{(i)} = B^{(i)} W_Q^k$, key matrices $K_k^{(i)} = E'W_K^k$,"}, {"title": null, "content": "and value matrices $V_k^{(i)} = E'W_V^k$, where $W_Q^k \\in R^{d_m \\times d}$, $W_K^k \\in R^{D \\times d}$, and $W_V^k \\in R^{D \\times d}$. The reprogramming operation for time series patches in each attention head is then defined as\n$Z_k^{(i)} = ATTENTION(Q_k^{(i)}, K_k^{(i)}, V_k^{(i)}).$ (9)\nBy aggregating each $Z_k^{(i)} \\in R^{P \\times d}$ in every head, we obtain $Z^{(i)} \\in R^{P \\times d_m}$, which is then linearly projected to align the hidden dimensions with the backbone model, yielding $O^{(i)} \\in R^{P \\times D}$.\nPrompt-as-Prefix Prompting is a simple yet useful method for task-specific activation of LLMs. However, directly con- verting time series data into natural language is challenging, making it difficult to create instruction-following datasets and use on-the-fly prompting effectively without sacrificing performance. Recent research shows that other data modalities, such as images, can be seamlessly incorporated as prefixes in prompts, enabling effective reasoning with these inputs. We refer to this approach as Prompt-as-Prefix (PaP) and find that it significantly improves the LLM's adaptability to downstream tasks while complementing patch reprogramming.\nAs illustrated in Fig. 1, we use three different types of prompts as prefixes, including domain knowledge, instruction, and statistics. As for statistics, we adopt the sum of difference between successive time steps to express the overall trend of the time series in natural language. If the sum is positive, it signifies an upward trend; otherwise, a downward trend. Additionally, we identify the top 5 lags of the time series by computing the autocorrelation function using fast Fourier transformation (FFT) and selecting the five lags with the largest correlation values.\nOutput Projection After packing and feeding the prompt and patch embeddings $O^{(i)}$ through the frozen LLM, as shown in Fig. 1, we discard the prefix portion and obtain the output representations. These representations are then flattened and linearly projected to derive the final forecasts $\\hat{Y}^{(i)}$. The loss function aims to minimize the mean-squared errors between the ground truths Y and the predictions $\\hat{Y}$ of the optimal beam indexes over future time steps, which can be expressed as\n$L=\\frac{1}{H} \\sum_{h=1}^{H} |Y_h - \\hat{Y}_h|^2$ (10)"}, {"title": "IV. SIMULATION", "content": "We select GPT-2 [4] as our backbone model, which achieves a trade-off between inference speed and prediction accuracy. Note that our method is also theoretically applicable to other LLMs, such as the Qwen series and Llama series [5]. As for baselines, we compared our proposed method with two LSTM- based methods, labeled as ODE [1] and CascadedLSTM [2].\nWe adopt the DeepMIMO dataset [12], which uses precise ray-tracing method, to accurately simulate the nonlinear rela- tionships between the user movement and beam variation.\nA training dataset comprising 73,728 samples and a valida- tion dataset comprising 9,216 samples are constructed, respec- tively. In these datasets, we focus on an outdoor environment labeled \"Outdoor 1\", to reflect real-world implementation in natural settings. BSs are indexed as 1-2, covering the range of the simulated area. The UT velocity ranges from 5 ~ 20 m/s, introducing dynamic movement to access the model's adaptability. BSs are configured with 32, 64, or 128 antennas, offering diverse setups for testing coverage and capacity. The number of beams matches the antenna numbers at 32, 64, or 128, facilitating testing of different communication patterns. Lastly, the beam prediction period is set as 16 ms while T is set as 40 and H is set as 10. The optimal beams within the neighborhood of the prediction results will be collected at regular intervals and used as inputs for the next prediction. Note that our model is trained under the assumption that the BS index is set to one and the center frequency is set to 28 GHz."}, {"title": "B. Simulation Results", "content": "The robustness of these schemes is tested at various speeds. Fig. 2 illustrates the performance of a single model across different speeds. In these figures, two LSTM-based methods are trained at distinct speeds and then tested at four different speeds, with the results averaged. Our model's performance, averaged across these different speeds, surpasses both base- lines, particularly outperforming the CascadedLSTM. This is primarily because the performance of small models signif- icantly deteriorates when tested at mismatched speeds. As shown in Fig. 2(c), testing has been conducted solely at 20 m/s. The results indicate that training at 5 m/s and testing at 20 m/s results in a substantial performance degradation, whereas training at 10 m/s and testing at 20 m/s leads to a less pronounced decline. This highlights an inherent limitation of small models: training at low-mobility hampers their ability to generalize to high-mobility scenarios. Therefore, by leveraging the capabilities of large models and training them at various speeds, improved robustness can be achieved.\nSimilarly, we evaluate robustness across different BSs, as shown in Fig. 3. We train our model on one BS and test on another. Fig. 3 indicates that regardless of the test speed, the performance of LSTM-based models significantly deteriorates. The decline is because small models fail to acquire diverse knowledge, which is unacceptable from a practical deployment perspective. In contrast, our LLM-based solution exhibits strong robustness, with no performance drop across different base stations. This demonstrates that our solution leverages the powerful zero-shot learning capabilities of LLMs, enabling them to learn more general domain knowledge even when trained on a single BS.\nWe also evaluate robustness across different center frequen- cies in Fig. 4. The model is trained at 28 GHz and tested at 60 GHz. Our LLM-based solution demonstrates remarkable robustness compared to the LSTM-based models. It is worthy noting that our robustness stems not only from the large model but also from our input setup. Previous LSTM methods primarily takes received signals as input, making them heavily dependent on channel characteristics. Our solution, based on past optimal beam indexes and AoDs, is more robust to channel characteristics.\nWe also conducted tests with different antenna configura- tions in Fig. 5. For previous LSTM-based solutions, their lack of scalability is a significant drawback due to their reliance on received signals as input. This means that different antenna codebooks necessitate redesign and retraining of previous models. Our solution partially resolves this issue. As shown in Fig. 5, our solution still functions across different antennas, which is challenging for small models. We also find that as the number of antennas decreases, the overall normalized gain increases. This phenomenon can be attribute to the narrowing beamwidth with more antennas, leading to a significant per- formance difference between the best beam and other beams.\nLastly, we conduct an ablation experiment to demonstrate the necessity of including external variables in Fig. 6. We com- pare the scheme of using only the optimal beam as input versus using the optimal beam plus AoD. We find that including the external variable significantly improves performance."}, {"title": "V. CONCLUSION", "content": "In this paper, we have presented a novel framework that adapts LLM for beam prediction. By aggregating optimal beam indexes and AoD, and subsequently converting them into text-based prototype representations, we align the data format with LLM capabilities. Our innovative PaP technique further enhances the model's understanding and reasoning of wireless data. This work marks the first integration of LLMs with wireless transmission. Our findings suggest that LLMs have significant potential for diverse applications in wireless communications."}]}