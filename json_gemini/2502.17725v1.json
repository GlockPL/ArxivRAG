{"title": "Solving the Traveling Salesman Problem via Different Quantum Computing Architectures", "authors": ["Venkat Padmasola", "Zhaotong Li", "Rupak Chatterjee", "Wesley Dyk"], "abstract": "We study the application of emerging photonic and quantum computing architectures to solving the Traveling Salesman Problem (TSP), a well-known NP-hard optimization problem. We investigate several approaches: Simulated Annealing (SA), Quadratic Unconstrained Binary Optimization (QUBO-Ising) methods implemented on quantum annealers and Optical Coherent Ising Machines, as well as the Quantum Approximate Optimization Algorithm (QAOA) and the Quantum Phase Estimation (QPE) algorithm on gate-based quantum computers.\nQAOA and QPE were tested on the IBM Quantum platform. The QUBO-Ising method was explored using the D-Wave quantum annealer, which operates on superconducting Josephson junctions, and the QCI Dirac machine, a nonlinear optoelectronic Ising machine. Gate-based quantum computers demonstrated accurate results for small TSP instances in simulation. However, real quantum devices are hindered by noise and limited scalability. Circuit complexity grows with problem size, restricting performance to TSP instances with a maximum of 6 nodes.\nIn contrast, Ising-based architectures show improved scalability for larger problem sizes. SQUID-based Ising machines can handle TSP instances with up to 12 nodes, while nonlinear optoelectronic Ising machines extend this capability to 18 nodes. Nevertheless, the solutions tend to be suboptimal due to hardware limitations and challenges in achieving ground state convergence as the problem size increases. Despite these limitations, Ising machines demonstrate significant time advantages over classical methods, making them a promising candidate for solving larger-scale TSPs efficiently.", "sections": [{"title": "I. INTRODUCTION", "content": "The Traveling Salesman Problem (TSP) is an NP-hard optimization problem with a wide range of real-world applications, from optimizing delivery routes in supply chains to DNA sequencing [11]. The primary objective of the TSP is to determine a path starting from a given location, visiting every location in a specified list exactly once, and returning to the starting point while minimizing the total distance traveled. This problem involves strict, non-violable constraints, making it challenging to solve efficiently.\nWhile the TSP is conceptually simple and can be solved for small graphs with well-defined edge connectivity, it becomes computationally intractable as the problem size increases."}, {"title": "II. THE TSP FORMULATION FOR GATE BASED QUANTUM COMPUTING", "content": null}, {"title": "A. QAOA Formulation", "content": "1) Theoretical formulation for the QAOA: The quantum approximate optimization algorithm is a hybrid quantum-classical variational algorithm designed to tackle combinatorial optimization problems. An essential ingredient for understanding and deploying the QAOA is a constructive approach to carry out the outer-loop classical optimization. The performance of the QAOA on MaxCut problems has revealed its ability to exploit non-adiabatic operations [2]. For instance, the QAOA method compared to quantum annealing can succeed especially in scenarios adiabatic quantum annealing fail due to a small spectral gap between the ground state and excited states. The comparison reveals that the QAOA can learn via optimization to utilize nonadiabatic mechanisms to circumvent the challenges associated with vanishing spectral gaps [2]. Finally, we provide a realistic resource analysis on the experimental implementation of the QAOA. When quantum fluctuations in measurements are accounted for, we illustrate that optimization is important only for problem sizes beyond numerical simulations but accessible on near-term devices.\nFor combinatorial optimization, the quantum approximate optimization algorithm briefly had a better approximation ratio than any known polynomial time classical algorithm until a more effective classical algorithm was proposed. The relative speed-up of the quantum algorithm is an open research question.\nThe heart of QAOA relies on the use of unitary operators dependent on 2p angles, where p > 1 is an input integer. These operators are iteratively applied on a state that is an equal weighted quantum superposition of all the possible states in the computational basis. In each iteration, the state is measured in the computational basis and the cost function f_0 is calculated. After a sufficient number of repetitions, the value of f_0 is almost optimal, and the state being measured is close to being optimal as well.\nIt was also shown that QAOA exhibits a strong dependence on the ratio of a problem's constraint to variables (problem density) [17] placing a limiting restriction on the algorithm's capacity to minimize a corresponding objective function.\nIt was soon recognized that a generalization of the QAOA process is essentially an alternating application of a continuous-time quantum walk on an underlying graph followed by a quality-dependent phase shift applied to each solution state. This generalized QAOA was termed the QWOA (Quantum Walk-Based Optimization Algorithm) [18].\nIn the paper [3] the authors conclude that a QAOA circuit with 420 qubits and 500 constraints would require at least one century to be simulated using a classical simulation algorithm running on state-of-the-art supercomputers so that would be sufficient for quantum computational supremacy.\nTo demonstrate solutions to the TSP using Universal gate based processors, we have explored known formulations of the QAOA, some of which are discussed below with specific processors as the quantum back-ends. Most known ways to formulate the TSP rely on defining the problem as a QUBO problem and then converting to a QAOA [30].\nFor a given classical \u201ccost\u201d function f_c(x) : B^n \u2192 R, an approximate algorithm (for maximization) attempts to find a string x that achieves a desired approximation ratio r,\n\\frac{f_c(x)}{f_{max}} > r\nwhere f_max is the true maximum.\nConsider the operator\nH_c = f_c(\\sigma_1^z, \\sigma_2^z, ..., \\sigma_n^z)\nand the Hadamard basis\nH |0> = |+> = \\frac{|0> + |1>}{\\sqrt{2}} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\nH |1> = |-> = \\frac{|0> - |1>}{\\sqrt{2}} = \\frac{1}{\\sqrt{2}}\\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}\nConsider an equally weighted superposition of all 2^n computational basis states by applying a direct product of Hadamard operators to |0>,\nH^{\\otimes n} |0> = \\frac{1}{2^{n-1}} \\Sigma_{z=0}^{2^n - 1} |z>\nwhere |z> = |z_{n-1} z_{n-2} z_{n-3} \u00b7\u00b7\u00b7 z_{2} z_{1} z_{0}> represents the bit string corresponding to any integer as z = 2^0 z_0 + 2^1 z_1 + ... 2^{n-1} z_{n-1}. Each basis state is a eigenvector of H_c\nH_c|z> = f_c(\\sigma_1^z, \\sigma_2^z, ..., \\sigma_n^z) |z> = f_c(z) |z>\nLet the maximum value f_{max}, being the largest eigenvalue of H_c, correspond to the eigenvector |z_{max}> such that\n<z_{max}|H_c|z_{max}> = f_{max}\nOne cannot in general find the state |z_{max}> but one can search for a state\n|\\psi> = \\Sigma_{z \\in {0,1}^n} a_z |z>\nwhich is close as possible to |z_{max}>.\n2) The QAOA algorithm step sequence:\n1) Prepare the Initial State: Begin with a uniform superposition of all possible computational basis states. For a system of n qubits, this state is prepared using Hadamard gates applied to each qubit:\n|\\psi_0> = H^{\\otimes n} |0> = \\frac{1}{2^{n-1}} \\Sigma_{z=0}^{2^n - 1} |z>\n2) Construct the Problem Hamiltonian: Define a Hamiltonian H_c that encodes the optimization problem's objective function. For example, if the goal is to minimize a cost function C'(z), then:\nH_c|z> = f_c(\\sigma_1^z, \\sigma_2^z, ..., \\sigma_n^z) |z> = f_c(z) |z>\nwhere f_c(z) is the cost associated with the computational basis state |z>.\n3) Construct the Mixer Hamiltonian: Define a mixer Hamiltonian H_B that facilitates transitions between basis states. The typical choice is:\nH_B = \\Sigma_{i=1}^n X_i\nwhere X_i is the Pauli-X operator acting on the i-th qubit. This Hamiltonian helps explore the solution space by driving transitions between states.\n4) Exponentiate and Parameterize: Apply the problem Hamiltonian and mixer Hamiltonian alternately in p layers (referred to as the 'p-level' algorithm). Each layer is parameterized by angles \u03b3 and \u03b2, which control the evolution times. The resulting state after p steps is:\n|(\\gamma, \\beta)> = \\Pi_{j=1}^P e^{-i \\beta_j H_B} e^{-i \\gamma_j H_c} |\\Psi_0>\n5) Optimize Parameters: Use a classical optimization algorithm to adjust the 2p parameters \u03b3 = (\u03b3_1, ..., \u03b3_p) and \u03b2 = (\u03b2_1, ..., \u03b2_p) to maximize the expectation value of the problem Hamiltonian:\n<H_c> = <\\psi_p(\\gamma, \\beta)| H_c |\\psi_p(\\gamma, \\beta)>\nThe classical optimizer iteratively improves these parameters to find the optimal solution.\n3) Simulation Results on the IBMQ Platform for the QAOA Algorithm: We initialize an arbitrary set of angles between 0 and 2\u03c0, which are passed through a classical COBYLA optimizer to determine the optimal set of angles. For a 4-node TSP, a 16-qubit circuit is initialized, as the qubit requirement scales as N^2. The values pass through a quantum circuit with a depth of 6 layers. Therefore, there are 96 angles serving as hyperparameters for optimization. The output is then measured."}, {"title": "B. The QPE Formulation", "content": "1) Overview of the Quantum Phase Estimation Algorithm: The Quantum Phase Estimation (QPE) algorithm extracts the phase \u03b8 associated with an eigenvalue of a unitary operator U [10]. Specifically, if U|\u03c8> = e^{2\\pi i\\theta}|\u03c8>, QPE estimates the phase \u03b8 with n-bit precision. The QPE circuit operates on two registers: the upper register of n qubits, initialized in |0>^n, is used for phase estimation, and the lower register is initialized in the eigenstate |\u03c8> of U, such that U|\u03c8> = e^{2\\pi i\\theta} |\u03c8>. The key steps of QPE are as follows:\n1) Apply Hadamard gates on all qubits of the upper register to create a superposition state.\n2) Apply controlled-U^{2^j} operations, where j corresponds to each qubit in the upper register.\n3) Apply the inverse Quantum Fourier Transform (QFT) on the upper register to extract the phase \u03b8. The final state of the upper register encodes the binary representation of \u03b8.\n2) Constructing the Unitary Operator U: The unitary matrix U operates on a Hilbert space of dimension 2^m, where m is the number of qubits in the lower register. The action of U on an eigenstate |\u03c8> is:\nU|\u03c8> = e^{2\\pi i\\theta}|\u03c8>.\nThe QPE algorithm requires the controlled-U operator, defined as:\nC-U = |0><0| \\otimes I + |1><1| \\otimes U.\nHere, |0> and |1> correspond to the control qubit states, and I is the identity matrix. The controlled-U^{2^j} operator generalizes this to:\nC-U^{2^j} = |0><0| \\otimes I + |1><1| \\otimes U^{2^j}.\n3) Phase Kickback and Superposition State: The Hadamard gate applied to the n-qubit upper register produces a superposition state:\n|0>^n H^{\\otimes n} = \\frac{1}{2^{n/2}} \\Sigma_{k=0}^{2^n - 1} |k>.\nwhere k> represents the computational basis states. The controlled-U^{2^j} gates apply phase shifts based on the eigenvalue e^{2\\pi i\\theta}. For the j-th control qubit, the operation introduces a phase factor e^{2\\pi i\u00b72^j \u03b8}, resulting in the following state:\n\\frac{1}{2^{n/2}} \\Sigma_{k=0}^{2^n - 1} e^{2\\pi i k \\theta} |k> \\otimes |\\psi>.\nBy leveraging the eigenvalue relationship U|\u03c8> = e^{2\\pi i\\theta}|\u03c8>, the lower register accumulates phase factors:\n\\frac{1}{2^{n/2}} \\Sigma_{k=0}^{2^n - 1} e^{2\\pi i k \\theta} |k> \\otimes |\\psi>.\nThe upper register now contains the phase information encoded in the amplitudes of the basis states |k>.\n4) Applying the Inverse QFT: To extract the phase \u03b8, we apply the inverse Quantum Fourier Transform (QFT) on the upper register. The QFT\u2020 maps the amplitudes e^{\u03c0ike} into the binary representation of \u03b8 with high probability. The inverse QFT is defined as:\nQFT^{\\dagger} |k> = \\frac{1}{2^{n/2}} \\Sigma_{j=0}^{2^n - 1} e^{-2\\pi i k j /2^n} |j>.\nAfter applying QFT\u2020, the upper register collapses to a computational basis state |j>, where j represents the binary approximation of 2^n \u03b8. That is, the output of the QPE algorithm is the n-bit approximation of the phase \u03b8, such that:\n\\theta \\approx \\frac{j}{2^n}, j \\in \\{0, 1, ..., 2^n - 1\\}.\n5) Encoding Hamiltonian Cycles: If QPE is applied to a system where the unitary U encodes Hamiltonian cycles as needed for the TSP problem, the eigenstates |\u03c8> are expressed as:\n|\\Psi> = |i(j) - 1>_2\nwhere i(j) represents the index of the city visited at step j. For example, for the sequence 1-2-4-3:\n|i(1) - 1> = |2> = |10>_2,\n|i(2) - 1> = |0> = |00>_2,\n|i(4) - 1> = |1> = |01>_2,\n|i(3) - 1> = |3> = |11>_2.\nThe complete encoded state is:\n|\\Psi> = |10> |00> |01> |11> = |10000111>.\nIn its simplest form, the quantum phase estimation (QPE) circuit operates on two registers of qubits. The lower register is repeatedly acted on by a controlled-U operator, where the control qubits are in the upper register. An inverse quantum Fourier transform (QFT) is then applied to the upper register, which serves as the estimator for an n-bit estimate of the phase \u03b8. Applying this circuit block to a 16-qubit case, we obtain the following quantum circuit.\nTo encode any arbitrary distance matrix to a format suitable for the QPE algorithm, we first normalize the values in raw distance matrix such that all the values are in between 0 and 1. We do this so that any such value can be represented by euler phase angles(the exponents are the phase angles which lie between 0 and 2\u03c0 ).\nThe matrix B is a representation of the normalized distance matrix encodes as euler phases.\nB = \\begin{bmatrix} e^{i \\phi_{1 \\rightarrow 1}} & e^{i \\phi_{1 \\rightarrow 2}} & e^{i \\phi_{1 \\rightarrow 3}} & e^{i \\phi_{1 \\rightarrow 4}} \\\\ e^{i \\phi_{2 \\rightarrow 1}} & e^{i \\phi_{2 \\rightarrow 2}} & e^{i \\phi_{2 \\rightarrow 3}} & e^{i \\phi_{2 \\rightarrow 4}} \\\\ e^{i \\phi_{3 \\rightarrow 1}} & e^{i \\phi_{3 \\rightarrow 2}} & e^{i \\phi_{3 \\rightarrow 3}} & e^{i \\phi_{3 \\rightarrow 4}} \\\\ e^{i \\phi_{4 \\rightarrow 1}} & e^{i \\phi_{4 \\rightarrow 2}} & e^{i \\phi_{4 \\rightarrow 3}} & e^{i \\phi_{4 \\rightarrow 4}} \\end{bmatrix}\nSince we have a 4 node distance matrix, we then construct 4 unitary operators Uj from B such that (U_j)_{k,k} = [B]_{j,k}:\nU_j = diag (B_{j,1}, B_{j,2}, B_{j,3}, B_{j,4})\nFinally, the tensor product of the 4 U_j operators U = U_1 \\otimes U_2 \\otimes U_3 \\otimes U_4 will also be a unitary matrix. We define U_j generally as\nU_j = \\Sigma_{k=1}^{n} B[j][k] \\times outer product of basis vectors\nThat is,\nU_1 = \\begin{bmatrix} e^{i \\phi_{1 - 1}} & 0 & 0 & 0 \\\\ 0 & e^{i \\phi_{2 - 1}} & 0 & 0 \\\\ 0 & 0 & e^{i \\phi_{3 - 1}} & 0 \\\\ 0 & 0 & 0 & e^{i \\phi_{4 - 1}} \\end{bmatrix}\nU_2 = \\begin{bmatrix} e^{i \\phi_{1 - 2}} & 0 & 0 & 0 \\\\ 0 & e^{i \\phi_{2 - 2}} & 0 & 0 \\\\ 0 & 0 & e^{i \\phi_{3 - 2}} & 0 \\\\ 0 & 0 & 0 & e^{i \\phi_{4 - 2}} \\end{bmatrix}\nU_3 = \\begin{bmatrix} e^{i \\phi_{1 - 3}} & 0 & 0 & 0 \\\\ 0 & e^{i \\phi_{2 - 3}} & 0 & 0 \\\\ 0 & 0 & e^{i \\phi_{3 - 3}} & 0 \\\\ 0 & 0 & 0 & e^{i \\phi_{4 - 3}} \\end{bmatrix}\nU_4 = \\begin{bmatrix} e^{i \\phi_{1 - 4}} & 0 & 0 & 0 \\\\ 0 & e^{i \\phi_{2 - 4}} & 0 & 0 \\\\ 0 & 0 & e^{i \\phi_{3 - 4}} & 0 \\\\ 0 & 0 & 0 & e^{i \\phi_{4 - 4}} \\end{bmatrix}\nCreating the final unitary matrix U from the series of submatrices U_i The way U defined is:\nU = U_1 \\otimes U_2 \\otimes U_3 \\otimes U_4\n6) Simulation and experimental results for the QPE algorithm on IBMQ platform: The QPE method has certain advantages over the QAOA approach significantly due to the fact that for a problem of size n, the qubit requirement in the case of QPE being nlogn as opposed to the n^2 qubit requirement in the case of QAOA.\nIt is evident that real quantum computers are prone to errors due to noise, as illustrated in Figure 7, while the simulation results yield more accurate results, as shown in Figure 6. Previous studies have demonstrated that NISQ gate-based quantum computers are not yet sufficiently advanced for fault tolerance or large enough to achieve quantum advantage [23]."}, {"title": "III. THE TSP FORMULATION FOR ISING TYPE SIMULATORS AND HARDWARE", "content": null}, {"title": "A. Ising and QUBO Models", "content": "The Ising model and its equivalent Quadratic Unconstrained Binary Optimization (QUBO) formulation constitute a central problem class for adiabatic quantum computation (AQC), where they are solved through a physical process known as quantum annealing.\nIn this model, we consider a set A of lattice sites, each with a set of adjacent sites forming a lattice or graph structure. For each lattice site k \u2208 A, there is a discrete variable \u03c3_k such that \u03c3_k \u2208 {+1, \u22121}, representing the spin states of a system. Any two adjacent sites, or \u201cnearest neighbors,\u201d i, j\u2208 A interact with an exchange coefficient J_{ij}. Additionally, each site j \u2208 A may experience an external magnetic field h_j. The energy of a spin configuration \u03c3 = (\u03c3_1, \u03c3_2, ...) is given by the following Hamiltonian:\nH(\\sigma) = - \\Sigma_{(i,j)} J_{i,j} \\sigma_i \\sigma_j - \\mu \\Sigma_{j} h_j \\sigma_j,\nwhere \u03bc represents the magnetic moment.\nA specific spin configuration \u03c3 follows a probability distribution given by the Boltzmann distribution with inverse temperature \u03b2 \u2265 0:\nP_{\\beta}(\\sigma) = \\frac{e^{-\\beta H(\\sigma)}}{Z_{\\beta}},\nwhere the partition function Z\u03b2 is defined as:\nZ_{\\beta} = \\Sigma_{\\sigma} e^{-\\beta H(\\sigma)}.\nThe expectation value of a function f over spin configurations is given by:\n<f>_{\\beta} = \\Sigma_{\\sigma} f(\\sigma) P_{\\beta}(\\sigma).\nThe QUBO model is an alternative formulation of the Ising model that replaces spin variables (\u00b11) with binary variables {0, 1}. This model is widely used in combinatorial optimization, including applications in finance, machine learning, and logistics. The QUBO formulation is NP-hard and often serves as a bridge between classical and quantum approaches to optimization [5]. For many classical problems such as the maximum cut graph problem, embeddings into a QUBO formulation are well known [4]. Embeddings for machine learning models include support vector machines [32], clustering, and probabilistic graphical models [31]. An almost equivalent physical model, the Ising model, has a well known QUBO formulation.\nThe transformation from the Ising model to QUBO is straightforward and is achieved using the following linear transformation:\nX_i = \\frac{1 + \\sigma_i}{2}, X_j = \\frac{1 + \\sigma_j}{2}\nThis ensures that for any \u03c3_i, \u03c3_j \u2208 {+1, \u22121}, we obtain binary variables x_i, x_j \u2208 {0, 1}.\nConsider a quadratic function f : B^n \u2192 R, defined over an n-dimensional binary space:\nf_Q(x) = \\Sigma_{i=1}^{n} \\Sigma_{j=1}^{n} q_{ij} X_i X_j,\nwhere q_{ij} \u2208 R, 1 \u2264 j \u2264 i \u2264 n, and x_i \u2208 B = {0, 1}. The goal of QUBO is to find an n-dimensional binary vector x that minimizes this function:\nx = arg min_{x \\in B^n} f_Q(x).\nThe QUBO function f_Q can be rewritten using a symmetric QUBO matrix Q \u2208 R^{n\u00d7n}, Q = [q_{ij}]:\nf_Q(x) = x^T Q x.\nThis matrix representation allows QUBO problems to be efficiently mapped onto quantum annealers or specialized quantum hardware for solving large-scale optimization problems."}, {"title": "B. The TSP Formulation for Simulated Annealing", "content": "Simulated Annealing (SA) is a classical optimization algorithm inspired by the annealing process in metallurgy, where a material is gradually cooled to remove defects and reach a stable low-energy state. SA applies this concept to optimization problems by slowly decreasing the system's temperature, allowing it to explore the solution space and settle into a low-energy configuration. However, SA can be computationally expensive due to its reliance on sequential updates of spin states. Nonetheless, it provides a unique approach to solving the Traveling Salesman Problem (TSP) by leveraging principles that differ fundamentally from universal gate-based quantum machines.\nMathematically, SA closely resembles the formulation of an Ising-type quantum computer. It explores the entire solution space, enabling it to escape local optima. Unlike gradient-based methods, SA does not get trapped in suboptimal solutions since it incorporates randomness to explore neighboring states. This stochastic nature helps the algorithm bypass local minima. However, in highly complex landscapes with numerous local minima, especially for large problem sizes, SA may fail to reach the true ground state solution.\nThe annealing process involves gradually lowering the \u201ctemperature,\u201d allowing the algorithm to initially explore a broad set of solutions, including suboptimal ones, before progressively converging toward an optimal or near-optimal solution. This approach enables SA to handle complex, non-convex objective functions without requiring derivatives or assumptions about the function's structure. It performs effectively even in noisy or irregular problem spaces.\nDespite its advantages, SA is not always the fastest or most precise optimization method. Depending on the problem, alternative approaches such as genetic algorithms, particle swarm optimization, or gradient-based techniques may yield better results. Additionally, selecting appropriate coefficients and tuning parameters for SA is critical, as improper settings can significantly affect its performance. A systematic strategy for parameter optimization is necessary to enhance the algorithm's efficiency and effectiveness in solving large-scale optimization problems.\n1) Hamiltonian formulation for Simulated Annealing: One of the most straightforward ways to solve the TSP is to convert it into a Quadratic Unconstrained Binary Optimization (QUBO) problem. For an unconstrained TSP problem, we can use a binary variable a_{ik} to represent whether the city k is visited (a_{ik} = 1) or not (a_{ik} = 0) at the i-th step, shown in figure 8. The objective function can therefore be defined in a quadratic form:\nH_{obj} = \\Sigma_{k \\neq l} \\Sigma_{i} W_{kl} a_{ik} a_{(i+1)l}\nWhere W_{kl} is the element of the distance matrix for distance between city k and city 1. Since each city should only be visited once, and only a single city can be visited simultaneously, we introduce the two constrains:\nH_{cons} = \\Sigma_i (\\Sigma_k a_{ik} - 1)^2 + \\Sigma_k (\\Sigma_i a_{ik} - 1)^2\nIf we replace a_{ik} = (\u03c3_{ik}+1)/2 where \u03c3_{ik} = \u00b11 represents an Ising spin, the QUBO formulation is mathematically equivalent to an Ising Hamiltonian:\nH = H_{obj} + H_{cons}\n= \\frac{1}{4} \\Sigma_{k \\neq l} \\Sigma_{i} W_{kl} \u03c3_{ik} \u03c3_{(i+1)l} + \\frac{1}{4} \\Sigma_{k \\neq l} \\Sigma_{i} W_{kl} \u03c3_{ik}\n+\\Sigma_{k} \\Sigma_{i} \\Sigma_{j} \u03c3_{ik} \u03c3_{jl} + (n-2) \\Sigma_{k} \\Sigma_{i} \u03c3_{ik}\n+\\Sigma_{k} \\Sigma_{i} \\Sigma_{j} \u03c3_{ik} \u03c3_{jk} + (n-2) \\Sigma_{k} \\Sigma_{k}\n+const.\nFor a randomly generated distance matrix W, figure 9 shows the interaction matrix J reshaped into 2D when \u03b3 = 5.\nTo demonstrate how the Hamiltonian appears after the adjacency matrix transforms under the equations described above, a heat map of the Hamiltonian for a 6 city TSP is plotted as shown in figure 9.\n2) Solution for a 6 city TSP using Simulated Annealing:\nThe solution obtained from this Hamiltonian is initially represented as a linear array of 36 spins, which is then reshaped into a 6 \u00d7 6 square matrix encoding the solution path, ensuring that each row and column contains exactly one +1 spin value."}, {"title": "C. Experimental Observations for Adiabatic Quantum computers", "content": "1) Hamiltonian formulation for the D-Wave platforms: Consider N \"cities\" (vertices in a graph) indexed as {0,1,..., N \u22121}. Consider the case of a round trip returning to the original city (Hamilton cycle). As each city maybe visited only once, there will be N time steps indexed as {1, ..., N} where we start at t = 0. Consider N + 1 sets of N + 1 binary variables\nX_{i,t} \u2208 B, i\u2208 {0,1,..., N}, t\u2208 {0, 1, ..., N}\nX_{i,t} = 1 denotes that the ith city was reached in the tth time. Let us start at the Oth city such that we have a boundary condition of x_{0,0} = 1. The last city visited at t = N must be the original city, so we have another boundary condition x_{N,N} = 1 where city N is required to be equal to city 0 (recall that the unique cities are indexed as {0,1, ..., N \u2013 1}).\nLet d_{ij} denote a distance (directed graph edge) between the ith and jth cities. The tour length is given by\nH_{tour} = \\Sigma_{i,j=0}^{N} \\Sigma_{t=0}^{N-1} d_{ij} x_{i,t} X_{j,t+1}\nThere exist two main constraints. First, one may travel to each city (vertex) only once. Consider the ith city. If one looks at a whole time cycle summing over all times one needs\n\\Sigma_{t=0}^{N} x_{i,t} = 1, \u2200i \u2208 {0, 1, ..., N}\nFor instance, if the ith city was never visited, this sum would be 0. If a city was visited more than once, this sum would be > 1. Second, one must travel to every city once (each time step contains only one city) producing the condition that\n\\Sigma_{i=0}^{N} xi,t = 1, \u2200t \u2208 {0, 1, ..., N}\nSuch a round trip tour is called a Hamilton cycle.\nBoth these constraints must be added to the tour Hamiltonian Htour to give the TSP minimization function\nH_{TSP} = H_{tour} + constraint terms\nN-1\n= \\Sigma_{i,j=0} d_{ij} x_{i,t}x_{j,t+1} + \\lambda(\\Sigma_{t=0}^{N} (\\Sigma_{i=0}^{N} xi,t - 1)^2 + (\\Sigma_{i=0}^{N} xit - 1)^2 )\nThe ground state of this Hamiltonian is the solution of the TSP problem.\n2) Constraints: For a problem of size N, there are \\binom{N}{2} constraints. The constraint matrices corresponding to these constraint terms must match the number of constraints [6]. In the AQC formulation of the problem, enforcing hard constraints presents a challenge, as introducing high penalty terms often eliminates the feasibility of solutions. Therefore, it is crucial to establish bounded values for the Lagrange parameter to obtain the most optimal solutions. Additionally, chain strength plays a significant role in determining the feasibility and quality of returned solutions, ensuring that constraints are not violated.\nAlthough D-Wave processors continue to improve, enabling the embedding of larger graphs, the majority of returned solutions remain suboptimal. Further research is necessary to identify the key parameters that significantly influence solution quality. Refining these parameters could enhance the likelihood of achieving optimal solutions with the highest number of valid samples.\n3) Normalization: Since the AQC formulation is sensitive to variations in the Lagrange parameter, making it challenging to enforce constraints effectively, additional steps are necessary to carefully select an appropriate Lagrange parameter. A plot of constraint violation probability is shown in Figure 11 for test graphs with random weights.\nFrom recent efforts to enforce constraints rigorously before sampling energies and constructing solutions, we have observed that normalizing or scaling the matrix of weights significantly increases the likelihood of finding a feasible solution.\nWe conducted 10 test runs of the TSP code on each test graph for two cases: one without normalization and the other with normalization applied. As shown in Table II, normalizing the weight matrix enhances the probability of obtaining a feasible solution."}, {"title": "D. Experimental Observations for Optical Ising computers", "content": "The large-scale optical Ising machine represents a significant advance in photonic computing. This system utilizes a spatial light modulator (SLM), a device that imposes spatially varying modulation on a beam of light. In this configuration, the spin variables of the Ising problem are encoded through binary phase modulation of the light field [7]. Essentially, the phase of the light field corresponding to the position of the wave at a given point in space is modified in a binary manner to represent the spin variables.\nA key challenge facing optical Ising machines is the difficulty in encoding the coupling coefficients J_{ij} onto the SLM for a spatial optical Ising machine. One potential solution to this issue is the application of gauge transformations [25], which provides an alternative approach to improve the efficiency and accuracy of encoding.\n1) Hamiltonian formulation on the QCI Dirac platforms: The QCI dirac machines are photonic quantum computers that can solve BQM, QCBO and QUBO problems in a similar way that the D-wave quantum annealers can solve the problems. The have been shown to additionaly solve integer linear programming models and mixed integer linear programming models with a solution space spanning a range of integers without explicitly converting such a problem to binary. This allows us to use ILP formulations directly without any conversions to define the TSP to be solved on the QCI platforms. Two most popular ILP formulations that are being tested here are the Miller-Tucker-Zemlin [26] formulation and the Dantzig-Fulkerson-Johnson formulation[27].\nmin \\Sigma_{i=1}^{n} \\Sigma_{j=1}^{n} C_{ij} X_{ij}\nwhere C_{ij} is the cost of traveling from city i to city j, and X_{ij} is a binary variable indicating whether the path from i to j is included in the tour.\n2) Subtour Elimination Constraints: Introduce variables u_i to represent the order in which cities are visited:\nU_j-u_\u017c \u2265 1-(n-1)(1-x_{ij}) Vi, j \u2208 {2, ..., n}, i \u2260 j\nThese constraints ensure that no subtours are formed.\n3) Additional Constraints: Each city must be visited exactly once:\n\\Sigma_{j=1}^{n} X_{ij} = 1 Vi\n\\Sigma_{i=1}^{n} X_{ij} = 1 \u2200j\nThe order variables must be within a valid range:\n2\u2264u_i\u2264n Vi\u2208 {2,..., n}\n4) Hardware architecture: The Dirac1 machine is an FPGA based Optical Parametric Oscillator (OPO), that uses a non-linear crystal such as Periodically Poled Lithium Niobate (PPLN). Optical Parametric Oscillators (OPOs) are devices that generate new frequencies by mixing two light waves in a nonlinear crystal. The PPLN is a highly efficient medium for these nonlinear wavelength conversion processes. It is used for frequency doubling, difference frequency generation, sum frequency generation, optical parametric oscillation, and other nonlinear processes [29].\nResearchers have shown that by doing this, the propagation of light can be tailored or adjusted to minimize an Ising Hamiltonian. Using Min-Max normalization to ensure a successful Hamilton cycle, the photonic Ising machine Can solve the TSP for a problem upto 18 nodes for any linear constraints of the type Ax = b.\nSince no explicit embedding step is required as opposed to the D-wave platform [22], the QCI Dirac machines are able to solve TSP instances of sizes beyond 12 nodes.\n5) Solution for an 18 node TSP: The maximum size of the TSP that can be solved reliably without violating the constraints is currently 18 nodes. is a demonstration of the QCI dirac machine solving a TSP instance of 18 nodes."}, {"title": "IV. RESULTS", "content": "We can clearly see that the Traveling Salesman Problem (TSP) is well-suited for direct Ising-type processors, as the cost"}]}