{"title": "Ontological Relations from Word Embeddings", "authors": ["Mathieu d'Aquin", "Emmanuel Nauer"], "abstract": "It has been reliably shown that the similarity of word embeddings obtained from popular neural models such as BERT approximates effectively a form of semantic similarity of the meaning of those words. It is therefore natural to wonder if those embeddings contain enough information to be able to connect those meanings through ontological relationships such as the one of subsumption. If so, large knowledge models could be built that are capable of semantically relating terms based on the information encapsulated in word embeddings produced by pre-trained models, with implications not only for ontologies (ontology matching, ontology evolution, etc.) but also on the ability to integrate ontological knowledge in neural models. In this paper, we test how embeddings produced by several pre-trained models can be used to predict relations existing between classes and properties of popular upper-level and general ontologies. We show that even a simple feed-forward architecture on top of those embeddings can achieve promising accuracies, with varying generalisation abilities depending on the input data. To achieve that, we produce a dataset that can be used to further enhance those models, opening new possibilities for applications integrating knowledge from web ontologies.", "sections": [{"title": "1 Introduction", "content": "Word embeddings [4] are vector representations of words in a text, used, in particular, to perform learning tasks in natural language processing. Many of the embeddings used today are produced by neural (large) language models such as BERT [2]. These are neural network models trained on particular tasks (such as masked-language modelling, i.e. predicting masked tokens in a given text) and from which selected hidden layers can be used as embeddings. Interesting properties have been demonstrated for embeddings produced by different models, in particular, in representing the meaning of the words within the embedding space. For example, words that are semantically similar have been shown to generally have similar embeddings [12]. The main question that is asked in this paper is whether they encapsulate enough information to cover relations"}, {"title": "2 Related work", "content": "A lot of attention has been given recently to the whole area of knowledge graph embeddings (see, for example, [13]) in particular for their use in link prediction tasks (see, for example, [21]). Knowledge graph embeddings are methods (often based on neural models) to project the graph representation available in knowledge graphs onto a vector space in a way that should align with the structure and meaning of the graph. They are often used for link prediction, i.e. the task of predicting which entity might be related to which other in a graph since, by encapsulating patterns in the existing graph, they should be able to discover where missing relations might exist. These two categories of work are closely related to the work presented in this paper since they relate to the prediction of relations between entities in knowledge structures through the use of embeddings. Here, however, we focus on ontological relations as predictable from word embeddings applied to the textual representation of the entities. In other words, while knowledge graph embeddings, in a sense, distill the content of a graph to find ways to complete it, we aim to exploit knowledge already captured by pre-trained language models through word embeddings to predict ontological relations between classes and properties of web ontologies.\nFollowing the work on knowledge graph embeddings, ontology embeddings have been proposed that focus on the OWL language [1] or on particular description logics [8]. While ontological relations are considered, those works aim to create representations similar to knowledge graph embeddings but that are capable of capturing the semantics of higher-level formalisms used for ontologies. They therefore also accomplish a different task from the one endeavoured"}, {"title": "3 Overview", "content": "Figure 1 provides an overview of the approach taken to predict ontological relations that might exist between two entities, represented as texts by their short name (the last part of their IRI) and comments in English (if they have one). The texts of the short name and of the comment of each entity are first run through a language model (in Section 4.3, we describe the four we tested) to obtain word embedding vectors for each of them, i.e. a word embedding is com-"}, {"title": "4 Dataset generation", "content": "In this section, we detail how datasets are created for the training and validation of relation prediction models. We start by describing the ontologies used and the process of extracting relations from those ontologies. We then briefly introduce the language models used to extract embeddings of the textual representation of entities, and finally what is included in the generated datasets. The generated datasets and intermediary structures computed to construct them are available on FigShare\u00b9 and the code to generate them from an N-Triples file containing an ontology is available on github.2"}, {"title": "4.1 Ontologies", "content": "As a basis for training and validation, we selected five ontologies. The reason for using those five is that, considering that the language models used were trained on open-domain texts, they should be better able to predict the relations existing in ontologies that are not specific to a particular domain. In other words, they rely, in the textual representation of the included entities, on a general"}, {"title": "4.2 Extracting relations from ontologies", "content": "The first part of the process of creating a dataset of relations between entities contained in the considered ontologies is to extract such relations, as well as those that can be derived from them. Some of the ontologies considered are relatively large (including a few thousand classes and properties), and relations between potentially every pair of entities had to be considered. To minimise the time to search the relations between two entities, each ontology is represented by a large nxn matrix where n is the number of entities, and each cell of the matrix"}, {"title": "4.3 Pre-trained Language Models for Word Embedding", "content": "In the process presented in Section 3, we rely on a selection of popular language models to test which are more efficient in re-creating ontological relations. All those language models are pre-trained by their original authors and built on different architectures, although they are all neural models based on transformers, as summarised below. There are a number of other language models that could have been used and could be added in the future, but those represent a reasonable selection of what is openly available today.\nTo extract embedding vectors for textual representations of classes and properties of ontologies with these models, we used the huggingface transformers library in Python. In more detail, for every entity included in an index for an ontology, we first run the tokenized shortname of the entity through the model, obtaining an \"in context\" embedding vector for each of the words in the shortname by extracting the activations of the last layer before output (last hidden states). We reduce this set of vectors to one by averaging them (the meanpooling step in Figure 1). We apply the same process to the rdfs:comment of the entity if it has one, and average the name and comment vectors to obtain a final embedding vector of the textual representation of the entity. As a result, our process leads to a dataset including an embedding vector from each of the four language models for every class and property in each of the five ontologies considered here.\nBERT: BERT [2] (Bidirectional Encoder Representations from Transformers) was introduced by Google in 2018 and quickly became a reference language model for many tasks. It has the particularity of considering textual contexts in both directions (forward and backward). It was mostly trained on"}, {"title": "4.4 Structure of the generated datasets", "content": "We created 20 training and validation datasets: one for each of the five ontologies together with one of the four language models considered. Each of these datasets includes the concatenation of the embedding vectors from the given language model of pairs of entities of the given ontology, associated with the binary vectors representing the presence or absence of ontological relations between those pairs. To separate the training set from the validation set, we first set aside 30% or 40% of the entities (depending on the ontology, to ensure that different types of relations are reasonably represented in the validation set) to create pairs for the validation set and use the remaining entities to form pairs for the training set. In the next section, we will, therefore, assess the performance of models having learnt from a training set, based on measuring precision, recall, and F-score on the corresponding validation set. Note that we only include in the datasets pairs of entities between which there exists at least one relation. Also, as mentioned in Section 4.2, some relations in the datasets for the DBpedia ontology were randomly removed to reduce the imbalance between the different types of relation in that ontology."}, {"title": "5 Results", "content": "In this section, we present the results of training a number of models on the task of predicting the relations existing between pairs of entities, represented by the text of their names and, optionally, their descriptions as present in the rdfs:comment attribute. We first briefly describe the training process, show the results in terms of precision, recall, and F-score for the 20 combinations of ontologies and language models, and discuss those results. We then also show the results of cross-validating models trained on each of the ontologies against the validation set of the other ontologies on the best embeddings obtained in the previous step (Llama2). The goal here is to obtain results that enable us to gain an understanding of the generalisation capabilities of the models created. Finally, we also show the results of training one model from a combination of all the training sets from the five ontologies, to assess whether including relations from a larger, more varied set could lead to a globally more effective model not only of one ontology but of knowledge on the Web generally."}, {"title": "5.1 Training", "content": "As shown in Figure 1, each model adds to the concatenation of the embedding vectors produced for a pair of entities a few (one to three) fully connected hidden layers with reLU activation and an output layer (of size 20) with sigmoid activation. The decision on the number of hidden layers and their sizes is made for each model empirically: Several values have been tried to identify some that seem to consistently perform better than others. Other parameters, such as the number of epochs of training, the learning rate, or the batch size, are established by following the same approach. All the parameters used for training are recorded in our code repository on github. The results below were obtained using relatively small models on top of the embeddings used, the largest (Schema.org/Llama2) containing three hidden layers of sizes 100 each, and the smallest (DBpedia/ROBERTA) containing only one layer of size 15.\nAll models were trained using the PyTorch Library with the Adam optimiser and the cross-entropy loss function applied to the 20-sized vector in output of the sigmoid layer, against the binary vector representing the actual relations between the input pair of entities."}, {"title": "5.2 Learning individual ontologies", "content": "Table 2 provides the results in terms of overall precision, recall, and F-score for each of the 20 trained models. To clarify here, those measures are considered on a per-relation basis, that is, if a relation exists in the ontology between a pair of entities and the model produces a number over 0.5 for the dimension of the output vector corresponding to that relation, then a true positive will be counted. If, however, the model outputs a number below the threshold of 0.5 for that relation, then a false negative is counted (similarly for true negatives and false positives).\nPre-trained language models capture ontological relations. The first conclusion which can be drawn is that the results confirm that, to an extent, the tested pre-trained language models include sufficient information in their representation of texts to be able to recognise ontological relations between classes and properties, the best results obtained being Llama2 on DUL for an F-score of more than 88%. This is an interesting result in itself, as it shows that, even without much effort in training, using only a few, small additional layers on top of the produced embeddings, a fairly accurate reconstruction of a significant part of some of the ontologies can be achieved.\nLlama2 performs significantly better than other language models. Another straightforward conclusion from Table 2 is that Llama2 performs significantly better than other language models on this task, for all measures. This is not surprising considering that even the small version of Llama2 we used is much larger than the other models. This could indicate that using a larger version of Llama2 or other larger models could potentially lead to better results, although"}, {"title": "5.3 Cross testing ontology models", "content": "In Figure 2, we present the results, in terms of precision, recall, and F-score, of cross-validating models built on the training sets of each of the ontologies, on the validation sets of each of the ontologies. Here, we rely on the five models built using Llama2, as the best performing language model for our task. The diagonals in the three matrices of Figure 2 therefore correspond to the results already presented in the last column of Table 2.\nThe first conclusion here is that, once again without surprise, a model trained on a part of an ontology is better able to predict another part of the same ontology, rather than a part of another ontology. Beyond this obvious statement, however, we can also see that the models based on the two upper-level ontologies are not only the ones obtaining the best results on their ontology, they also generalise fairly well to predicting each other. A more surprising result is that, however, even though it generally reaches very low performances, the model trained on OpenVocab is not much worse at predicting gUFO and DUL than it is at predicting OpenVocab itself. A possible explanation for this is that the low quality of OpenVocab might not be as much the incorrectness of the relations it expresses as its incompleteness. Finally, another interesting aspect of these results is the observation that even though it achieves good performance on schema.org itself, the model trained on this ontology performs extremely"}, {"title": "5.4 Building and testing a global model", "content": "As a last experiment, we trained a \"global\" model on a combined training set from the five ontologies and tested it using the five validation sets, again relying here on the Llama2 language model. The goal is to compare the performance of such a general model, trained on a larger and more diverse set of relations, with the results obtained above for more specific models, trained on smaller amounts of data.\nAs can be seen, increasing in this way the size of the training set did not lead, as could have been expected, to major improvements (the global validation measures appear close to the average scores for the previous ontology-specific models). However, it does highlight the importance of selecting the ontologies"}, {"title": "6 Discussion: possible applications", "content": "The results presented in the previous section show a promising new way in which semantic web tools and applications could effectively exploit web knowl-"}, {"title": "7 Conclusion", "content": "In this paper, we report on experiments to build neural models to predict ontological relations (direct or inferred) between classes and properties from word embeddings. We showed that even very simple models built on top of such embeddings for the textual representation of those entities obtained promising results. We also showed that even if the results were often similar, the larger Llama2 model was consistently better as a source of embeddings in this task than other smaller models. We also discussed how the results were largely dependent on the quality of the ontology(ies) on which the model was trained, with carefully designed, upper-level ontologies leading to excellent results where unvalidated, community built ontologies led to disappointing model performances. Based on the promising results obtained, we discussed possible applications"}, {"title": "Supplementary material", "content": "At\nhttps://figshare.com/articles/dataset/Data_and_models_for_\nOntological_relations_from_word_embeddings_/25601010?file=\n45645084 is the FigShare data repository that includes the built models and the measures obtained from their validation. It also includes the generated datasets used as input to the training and validation steps and the intermediary structures built as part of constituting those datasets (indexes and matrices). The ontologies themselves are not included, but a metadata file indicates from where they were downloaded, at what time."}]}