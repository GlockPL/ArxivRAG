{"title": "Learning Lifted STRIPS Models from Action Traces Alone: A Simple, General, and Scalable Solution", "authors": ["Jonas G\u00f6sgens", "Niklas Jansen", "Hector Geffner"], "abstract": "Learning STRIPS action models from action traces alone is a challenging problem as it involves learning the domain predicates as well. In this work, a novel approach is introduced which, like the well-known LOCM systems, is scalable, but like SAT approaches, is sound and complete. Furthermore, the approach is general and imposes no restrictions on the hidden domain or the number or arity of the predicates. The new learning method is based on an efficient, novel test that checks whether the assumption that a predicate is affected by a set of action patterns, namely, actions with specific argument positions, is consistent with the traces. The predicates and action patterns that pass the test provide the basis for the learned domain that is then easily completed with preconditions and static predicates. The new method is studied theoretically and experimentally. For the latter, the method is evaluated on traces and graphs obtained from standard classical domains like the 8-puzzle, which involve hundreds of thousands of states and transitions. The learned representations are then verified on larger instances.", "sections": [{"title": "Introduction", "content": "The problem of learning lifted STRIPS action models from action traces alone is challenging because it requires learning the domain predicates which are not given. The problem has been addressed by the LOCM systems (Cresswell and Gregory 2011; Cresswell, McCluskey, and West 2013), and more recently, through SAT and deep learning approaches (Bonet and Geffner 2020; Rodriguez et al. 2021; Asai and Fukunaga 2018; Asai et al. 2022). Still all these approaches have severe limitations. The LOCM systems are scalable but heuristic, and their scope is not clear and can fail even in simple domains. The SAT approaches are sound and complete, but they work on graphs, not traces, and more importantly, they do not scale up. Deep learning approaches can deal with traces combining state images and actions, but do not yet produce meaningful lifted representations.\nIn this work, we address the problem using a different approach that combines the benefits of some of these methods while avoiding their pitfalls. Like LOCM, the new method is scalable, and like SAT approaches, it is sound and complete, while learning from either action traces or graphs, without making any assumptions on the \"hidden\" STRIPS domains except that they are \"well formed\", so that action effects must change the state.\nThe new method, named SIFT, utilizes an efficient, novel test that checks whether it is consistent with the inputs (traces or graphs) to assume that a predicate can be affected by a set of action patterns; namely, actions with specific argument positions. The predicates and action patterns that pass the test provide the basis for the learned domain that is then easily completed with preconditions and static predicates. The approach is evaluated on traces and graphs obtained from standard domains like the 8-puzzle, which involves hundreds of thousands of states and transitions, and the learned domains are verified on larger instances.\nThe rest of the paper is organized as follows: We preview the new ideas through an example, discuss related work, review background notions, and introduce the new learning formulation. Then we present details of the implementation, experimental results, and a summary and discussion."}, {"title": "Preview", "content": "The intuition for the approach is simple. Consider for example the following action trace T for the Delivery domain:\npick(01, c), move(c, c'), drop(01, c'), pick(01, c') .\nThis is an applicable sequence of actions in an instance of the domain where an object 01 is picked from a cell c, a move is done from c to cell c', the object is dropped, and picked up again. The task is to learn the hidden domain from traces such as this, and this involves learning some predicates, and learning the action schemas for the three domain actions pick, drop, and move, including their effects and preconditions.\nGiven traces like T drawn from a hidden domain D, the new method will address the learning task by considering questions like the following, where the symbol \"-\" stands for any values (\"don't cares\"):\n1. Is the assumption that D involves a unary atom p(x) affected only by actions of the form pick(x, -) and drop(x, -), consistent with \u03c4?\n2. Is the assumption that D involves a unary atom q(x) affected only by actions pick(x, -), consistent with \u03c4?\nWe will show that these questions can be answered in a crisp and efficient manner, and moreover, that a domain equivalent to the one generating the traces can be obtained from the answers to such questions."}, {"title": "Related Work", "content": "The problem of learning lifted STRIPS models has a long history in planning. Most works however have been focused on learning lifted action models from traces that combine actions and states where the domain predicates are given. Observability of these traces can be partial, complete, or noisy (Yang, Wu, and Jiang 2007; Mour\u00e3o et al. 2012; Zhuo and Kambhampati 2013; Arora et al. 2018; Aineto, Celorrio, and Onaindia 2019; Lamanna et al. 2021; Verma, Marpally, and Srivastava 2021; Le, Juba, and Stern 2024; Balyo et al. 2024; Bachor and Behnke 2024; Xi, Gould, and Thi\u00e9baux 2024; Aineto and Scala 2024). Fewer works have considered inputs that are pure action traces.\nLOCM: The work that is closest to ours is the one on the LOCM system (Cresswell, McCluskey, and West 2013; Cresswell and Gregory 2011; Gregory and Cresswell 2015; Lindsay 2021), which also accepts action traces as inputs, and outputs lifted domain descriptions. Moreover, there is a common intuition guiding both works, namely, that the information to be extracted from the action traces is about the action that are \"consecutive\" in a trace. In LOCM, this happens when two ground actions in a trace share a common object as argument, and no ground action between them does. In our setting, this basic intuition is formulated in a different way. The notions of action patterns and features provide the basis of SIFT, which is scalable like LOCM but with the right theoretical properties and with no domain restriction. The LOCM approach, on the other hand, is heuristic and does not have a clear scope where it is sound and complete.\nSAT: A very different approach has been aimed at learning domains from labeled state graphs G of hidden domain instances. For this, the simplest instance that produces the structure of graph G is sought. The problem is addressed with weighted Max-SAT solvers (Bonet and Geffner 2020) and ASP solvers (Rodriguez et al. 2021). The limitations of the approach is that it does not learn from traces and does not scale up to graphs with more than a few hundred states.\nDeep learning: LATPLAN learns STRIPS models without supervision from traces where states are represented by images (Asai and Fukunaga 2018; Asai et al. 2022). For this, an encoder mapping states into latent representations is learned along with a model that predicts the next latent representation given the action. This enables planning in latent space from new initial states encoded by images. The approach,"}, {"title": "Background", "content": "A classical STRIPS problem is a pair P = (D, I) where D is a first-order domain and I contains information about the instance (Geffner and Bonet 2013; Ghallab, Nau, and Traverso 2016). The domain D has a set of predicate symbols p and a set of action schemas with preconditions and effects given in terms of atoms p(x1,...,xk), where p is a predicate symbol of arity k, and each xi is an argument of the schema. The instance information is a tuple I = (O, Init, G) where O is a set of object names ci, and Init and G are sets of ground atoms p(c1,...,ck) denoting the initial and goal situations. A STRIPS problem P = (D, I) defines a state graph G(P) whose nodes are the reachable states in P, the root node is the initial state, and edges stand for state transitions labeled with the actions causing them. A path in this graph starting in a node represents an action sequence that is applicable in the state represented by the node.\nCurrent PDDL standards support a number of STRIPS extensions (Haslum et al. 2019), and SIFT learns domains expressed in STRIPS with negation where negative literals can be used in the initial situation, action preconditions, and goals. The states in such a case are not sets of ground atoms but sets of ground literals. Since the goals of an instance P = (D, I) play no role in learning, we will regard I as just representing the initial situation through a set of signed ground atoms (literals)."}, {"title": "Traces, Extended Traces, and Graphs", "content": "An action trace or simply a trace from a domain instance P = (D, I) is an action sequence that is applicable from a reachable state in P. An action trace from a domain is a trace from a domain instance. For each action trace, there is a hidden initial state s\u2081 and hidden states si+1 generated by the actions in the trace. When learning from action traces alone, these states are not known, and moreover, there is no assumption about whether any pair of hidden states si and s; represent the same state or not. In certain cases, however, the information that two states in a trace or in different traces represent the same state is available (e.g., traces drawn from the same state) and can be used. We will refer to sets of traces extended with such state equalities as extended traces. Extended traces generalize plain traces, where no state equalities are revealed, and can provide a good approximation of labeled state graphs G(P) considered in (Bonet and Geffner 2020; Rodriguez et al. 2021), that represent all possible traces in P and all state equalities (more about this below). We refer to both plain traces and extended traces as traces, and make their difference explicit when relevant."}, {"title": "Formulation", "content": "We aim to learn classical planning domains from traces assuming that the traces come from a hidden STRIPS domain with negation that is well-formed:"}, {"title": "Dual Representation of Action Effects", "content": "A planning domain D is described normally in terms of a set of actions schemas that involve a set of lifted atoms in action preconditions and effects. There is, however, an alternative way of describing action effects that will be convenient in our setting, leaving aside for now the signs of these effects. For example, a domain D with two actions with effects:\nAction a(x1, x2): Effects p(x1, x2),\nAction b(x1, x2, x3): Effects q(x1, x2), q(x3,x2)\ncan also be expressed in \"dual form\" in term of the two atoms affected by the actions as:\nAtom p(x1, x2): Affected by a(x1,x2)\nAtom q(x1,x2): Affected by b(x1, x2, \u2212), b(\u2212, x2, X1),\nwhere the missing arguments \"-\" are don't cares that can take any value. We will refer to lifted actions of the form b(y1, y2, -) and b(\u2212, y1, y2), as action patterns.\nIn the normal representation of action effects, each action schema occurs once and may involve many atoms with the same predicate; in this alternative, dual representation, each lifted atom occurs once and may involve multiple action patterns. The two representations are equivalent."}, {"title": "Action Patterns and Features", "content": "We will say that an action b(x1,x2,x3) has the atom q(x3,x2) as an effect, by saying that the predicate q is affected by the action pattern b[3, 2]. This means that the arguments of q bind to the third and second arguments of b respectively. Formally, an action pattern is:\nDefinition 1 (Action patterns). An action pattern a[t] of arity k is an action name a of arity k' > k followed by a tuple t of k different indexes t = (t1,..., tk), 1 \u2264 t \u2264 k', i =\n1,..., k.\nA lifted atom in a domain is not affected by actions a but by action patterns a[t] that bind the arguments of the atom to the action arguments. For learning a domain, leaving preconditions and the sign of effects aside, it will be sufficient to learn the predicates p involved in the domain and the action patterns a[t] that affect them. We will refer to the predicates that are possible given a set of action patterns, as features:\nDefinition 2 (Features). A feature f of arity k is a pair f = (k, B), where B is a non-empty set of action patterns of arity k. B is called the feature support, also referred to as Bf.\nA feature f = (k, B) represents an assumption about the hidden domain; namely, that it contains atoms f (x1,...,xk) of arity k which are affected by all and only the action patterns a[t] in B which must have the same arity k. The actions a in these patterns, however, can have any arity k' greater than or equal to k, as the indexes in the pattern t select the k relevant action arguments of a in order. For example, if k' = 3, the action pattern a[3, 2] in B says that f(x3, x2) is an effect of the action a(x1, x2, x3).\nA finite set of inputs in the form of traces determines a finite set of action names a with their arities, and these determine a finite set of action patterns a[t] and a finite set of features. The learning task will reduce to a large extent to finding the features that are consistent with the given traces."}, {"title": "Action Groundings Af(o)", "content": "By the action grounding Af(o) of a feature f in a given set T of traces, we will refer to the set of ground actions a(o') in T that are assumed to affect the truth of the hypothetical ground atom f(o). For making this precise, for an action pattern a[t], t = (t1, ..., tk), and a ground action a(o), o = (01,..., Ok'), k' \u2265 k, let ti[0] refer to oj if t\u2081 = j, and let t[o] refer to the tuple of objects t\u2081 [0], . . ., tk [0]. Then the action grounding Af (o) can be defined as follows:\nDefinition 3 (Action groundings). The action grounding Af(o) of a feature f in a set of traces T refers to the set of ground actions a(o') in T such that a[t] is a pattern in B f and o = t[o'].\nFor example, if o = (01, 02) and a[4, 1] is a pattern in Bf, Af(o) will include all the ground actions in T of the form a(02, -, -, 01), as o = t[o'] is true for t = [4, 1] if the two elements of o are the fourth and first elements of o'.\nThe action grounding Af(o) contains all and only the ground actions appearing in T that affect the truth of the hypothetical atom f(o). Interestingly, by just \u201clooking\u201d at the traces in T, we will be able to tell in time that is linear in the length of the traces, whether the assumption expressed by a feature is consistent with the traces."}, {"title": "Pattern Constraints", "content": "Each pattern a[t] in Bf represents an effect on the hypothetical atom f (x), and hence must have a sign: positive (1) when the atom becomes true, and negative (0) when the atom becomes false.\nDefinition 4 (Signs). Each pattern a[t] in Bf must have a unique sign, sign(a[t]) that can be 0 or 1.\nA feature f = (k, B) is consistent with the input traces if it's possible to assign a sign to each action pattern a[t] in B in a way that is compatible with the traces. For this, we extract two types of pattern constraints from sets of traces T: those that follow from patterns appearing sequentially in some grounding of T, and those that follow from patterns appearing in parallel in some grounding of T:\nDefinition 5 (Consecutive patterns). Two action patterns a[t] and b[t'] in Bf are consecutive in T, if some trace \u03c4 in T contains two actions a(01) and b(02) that appear in some action grounding Af(o), such that no other action from Af (o) appears between them.\nIf a[t] and b[t'] affect f and are consecutive in T, the two patterns must have different signs. Indeed if a(01) adds the atom f(o), b(02) must delete f(o), and vice versa, if b(02) adds it, a(01) must delete it. A different type of constraint on action patterns arises from extended traces that start at or reach the same state:"}, {"title": "Feature consistency", "content": "The constraints Cf (T) for the feature f are extracted from the given traces T, and the solution to these constraints is a sign assignment to the patterns a[t] in Bf; namely, a 0/1 valuation over the expressions sign(a[t]), such that all the constraints in Cf (T) are satisfied. If there is one such valuation, the set of constraints Cf (T) and the feature f are said to be consistent, and the sign of the patterns a[t] in Bf is given by such a valuation.\nDefinition 8 (Feature consistency). The feature f is consistent with a set of (extended) traces T if the set of pattern contraints C f (T) is consistent.\nThe good news is that both the extraction of the pattern constraints from traces, and the consistency test are easy computational problems. The latter can indeed be reduced to 2-CNF satisfiability:\nTheorem 9. The problem of determining if a feature f is consistent with a set of (extended) traces T is in P and reduces to the problem of checking 2-CNF satisfiability.\nThe reduction is direct: if the propositional symbol $P_{a[t]}$ stands for $sign(a[t]) = 1$, then the equalities $sign(a[t]) = sign(b[t'])$ map into implications $P_{a[t]} \\rightarrow P_{b[t']}$ and $\\neg P_{a[t]} \\rightarrow \\neg P_{b[t']}$, and inequalities $sign(a[t]) \\neq sign(b[t'])$ into implications $P_{a[t]} \\rightarrow \\neg P_{b[t']}$ and $\\neg P_{a[t]} \\rightarrow P_{b[t']}$, all of which define clauses with two literals. A 2-CNF formula is unsatisfiable iff implication chains $p \\rightarrow l_1 \\rightarrow l_2\u2026 \\rightarrow \\neg p$ and $\\neg p \\rightarrow l_1 \\rightarrow l_2\u2026 \\rightarrow p$ can be constructed for one of the symbols p. For our constraints, the first chain implies the second, and vice versa, so that the satisfiability algorithm required is even simpler. For checking the consistency of a feature f given the traces T, an arbitrary pattern a[t] in Bf is chosen and given the arbitrary value 1. Then, all patterns b[t'] in Bf that are directly related to a[t] through a constraint in Cf (T) and which have no value, get the same value as a[t], if the relation is equality, and the inverse value if the relation is inequality. If there are then patterns in Bf that did not get a value, one such pattern a[t] is chosen and given value 1, and the whole process is repeated over such patterns. The iterations continue til an inconsistency is detected or all patterns get a sign. The algorithm runs in time that is linear in the number of patterns in Bf."}, {"title": "Feature consistency", "content": "The constraints Cf (T) for the feature f are extracted from the given traces T, and the solution to these constraints is a sign assignment to the patterns a[t] in Bf; namely, a 0/1 valuation over the expressions sign(a[t]), such that all the constraints in Cf (T) are satisfied. If there is one such valuation, the set of constraints Cf (T) and the feature f are said to be consistent, and the sign of the patterns a[t] in Bf is given by such a valuation.\nDefinition 8 (Feature consistency). The feature f is consistent with a set of (extended) traces T if the set of pattern contraints C f (T) is consistent.\nThe good news is that both the extraction of the pattern constraints from traces, and the consistency test are easy computational problems. The latter can indeed be reduced to 2-CNF satisfiability:\nTheorem 9. The problem of determining if a feature f is consistent with a set of (extended) traces T is in P and reduces to the problem of checking 2-CNF satisfiability.\nThe reduction is direct: if the propositional symbol $P_{a[t]}$ stands for $sign(a[t]) = 1$, then the equalities $sign(a[t]) = sign(b[t'])$ map into implications $P_{a[t]} \\rightarrow P_{b[t']}$ and $\\neg P_{a[t]} \\rightarrow \\neg P_{b[t']}$, and inequalities $sign(a[t]) \\neq sign(b[t'])$ into implications $P_{a[t]} \\rightarrow \\neg P_{b[t']}$ and $\\neg P_{a[t]} \\rightarrow P_{b[t']}$, all of which define clauses with two literals. A 2-CNF formula is unsatisfiable iff implication chains $p \\rightarrow l_1 \\rightarrow l_2\u2026 \\rightarrow \\neg p$ and $\\neg p \\rightarrow l_1 \\rightarrow l_2\u2026 \\rightarrow p$ can be constructed for one of the symbols p. For our constraints, the first chain implies the second, and vice versa, so that the satisfiability algorithm required is even simpler. For checking the consistency of a feature f given the traces T, an arbitrary pattern a[t] in Bf is chosen and given the arbitrary value 1. Then, all patterns b[t'] in Bf that are directly related to a[t] through a constraint in Cf (T) and which have no value, get the same value as a[t], if the relation is equality, and the inverse value if the relation is inequality. If there are then patterns in Bf that did not get a value, one such pattern a[t] is chosen and given value 1, and the whole process is repeated over such patterns. The iterations continue til an inconsistency is detected or all patterns get a sign. The algorithm runs in time that is linear in the number of patterns in Bf."}, {"title": "From Features to Domains", "content": "We will refer to features that are consistent with the given traces T as admissible, and to the collection of admissible features, as F(T). We show first how to use these features to define the learned domains DT and the learned instances \u0420\u0442 = (D\u0442, \u0406\u0442\u3009 from T. For this, notice that a trace in T with a non-empty action grounding Af (o), defines a unique truth value for the atom f(o) in every state of the trace, while in a set of connected (extended) traces, where each pair of traces shares a common state, a non-empty grounding Af (o) in one of the traces, determines the truth value of the atom f (o) in every state of each of the connected traces.\nThese truth values are used to infer the action preconditions in the learned domain DT:\nDefinition 10 (Learned domain). The domain Dr learned from a set of action traces T is defined as follows:\n\u2022 Lifted actions a(x) with arities as appearing in T\n\u2022 Predicates f(x) of arity k if f = (k, B) is in F(T)\n\u2022 Effects f (t[x]) of a(x) with sign(a[t]) if a[t] \u2208 B"}, {"title": "From Features to Domains", "content": "We will refer to features that are consistent with the given traces T as admissible, and to the collection of admissible features, as F(T). We show first how to use these features to define the learned domains DT and the learned instances \u0420\u0442 = (D\u0442, \u0406\u0442\u3009 from T. For this, notice that a trace in T with a non-empty action grounding Af (o), defines a unique truth value for the atom f(o) in every state of the trace, while in a set of connected (extended) traces, where each pair of traces shares a common state, a non-empty grounding Af (o) in one of the traces, determines the truth value of the atom f (o) in every state of each of the connected traces.\nThese truth values are used to infer the action preconditions in the learned domain DT:\nDefinition 10 (Learned domain). The domain Dr learned from a set of action traces T is defined as follows:\n\u2022 Lifted actions a(x) with arities as appearing in T\n\u2022 Predicates f(x) of arity k if f = (k, B) is in F(T)\n\u2022 Effects f (t[x]) of a(x) with sign(a[t]) if a[t] \u2208 B\n\u2022 Preconditions f(t[x]) (resp. \u00acf(t[x])) of a(x) for f \u2208 F(T), if in all traces where an action a(o') is applied and the truth of the literal f(o) is defined, f(o) is true (resp. false) right before a(o') for o = t[o'].\nThe expression t[x] selects elements of x according to the indices in t, and while t in effects comes from the action pattern a[t] \u2208 B; t in preconditions ranges over the possible precondition patterns of a. That is, if the arities of f and a are k and k' \u2264 k, then t ranges over all tuples (t1,...,tk) where the indexes ti are different and 1 \u2264 t \u2264 k. The reason that action preconditions can be learned by just taking the \u201cintersection\u201d of the f(t[x])-literals that are true when the action a is applied, is that such literals include the true, hidden, domain literals, as we will see in the next section.\nThe instance P\u0442 = (D\u0442, \u0406\u0442) learned from a set of connected traces T is defined in terms of the set A(D,T) of ground atoms f(o) whose truth values over all states along the traces in T are determined by the domain D and the traces T. These are:\nDefinition 11 (Relevant ground atoms). A(D, T) stands for the set of ground atoms p(o) such that p is a predicate in D, and some action a(o') in a trace in T has an effect or precondition p(o) in D with any sign.\nIndeed, the truth values of the atoms p(o) in A(D, T) in each of the states over the traces in T, follow from D and T by simple constraint propagation:\nTheorem 12 (Truth values). The truth values of each ground atom p(o) in A(D,T) in each of the states s underlying a set of connected traces in T are fully determined by D and T.\nThe truth values are determined because the signs of the action preconditions and effects in D are known, and every atom p(o) in A(D, T) is the precondition or effect of an action in a trace from T. The instance Pr = \u3008D\u0442, \u0406\u0442\u3009 learned from T assumes that at least one trace from T is drawn from the initial state of P = (D, I). We call the initial state of this trace, the initial state of T:\nDefinition 13 (Learned instance). For a set of connected traces T drawn from a hidden instance P = (D, I), the learned instance is PT = (DT, IT) where Dr is the domain learned from T, and It is A(DT,T) with the truth values of the atoms f (o) in Ir as derived at the initial state of T.\nWe can now express a soundness and completeness result for the instances Pr learned from a hidden instance P = (D, I) with no static predicates, as static predicates can be treated separately (see below). For stating the conditions, we ask the traces to be complete in the following sense:\nDefinition 14. A set of traces T is complete for an instance P = (D, I) if the traces in T are all drawn from the initial state of P and hence are connected, they affect each predicate p in D, and I contains the same atoms as I(D,T), ignoring the signs."}, {"title": "Implementation", "content": "We explain next some relevant details about the implementation of the domain learning algorithm called SIFT. The algorithms accepts a set of traces or extended traces T in the form of graphs with nodes that are hidden states and edge labels that are actions. For plain traces, these graphs are labeled chains. SIFT then performs three steps: 1) generation of the features f, 2) pruning the inconsistent features, and 3) construction of the learned domain D and of the set of ground atoms f(o) \u2208 A(D,T) with the truth values over each input node. We explained these three steps above. Here we provide details about the implementation of 1 and 2.\nFeatures. The key idea to make the learning approach computationally feasible and to avoid the enumeration of features is the extraction of type information about the action arguments from the traces, as done in LOCM (Cresswell, McCluskey, and West 2013), and its use for making the features typed. The types are constructed as follows. Initially, there is a type wa,i for each action a of arity ka > 0 in the traces, and each argument index i, 1 \u2264 i \u2264 ka. Then two types wa,i and wb,j are merged into one if there is an object o in the traces that appears both as the i-th argument of an a-action and as the j-th argument of a b-action. This merging of types is iterated until a fixed point is reached, where the objects mentioned in the traces are partitioned into a set of disjoint types. The following step is to use such types to enumerate the possible feature types, and for each feature type, the possible features. This massively reduces the number of features f = (k, B) that are generated and checked for consistency. We explain this through an example. In Gripper, the actions pick(b, g,r) and drop(b, g,r) take three arguments of types ball, gripper, and room, while the other action, move (r1, r2), takes two arguments of type room. Simple calculations that follow from the arities of these actions, show that 14 action patterns a[t] of arity two can be formed from these actions, and thus $2^{14} - 1 = 16,383$ features. If types are taken into account and read from the traces, 7 possible binary feature types are found (namely, ball and gripper, ball and room, etc), each of which accommodates 2 action patterns at most (e.g., pick[1, 2] and drop[1, 2] for ball and gripper). Hence, the number of (typed) binary features f becomes 7 \u00d7 ($2^2$ \u2212 1) = 21, which is much smaller than 16, 383. A further reduction is obtained by ordering the types and using the types in the feature arguments in an ordering that is compatible with such a fixed, global ordering, avoiding the generation of symmetrical features. This reduction leaves the number of binary features to be tested in Gripper down to 4 \u00d7 ($2^2$ \u2212 1) = 12. The number of ternary (typed and ordered) action patterns in Gripper is 2, and hence, there are ($2^2$ \u22121) = 3 ternary features to check, while the number of nullary action patterns is 3, and hence the number of nullary features is $2^3$ \u2013 1 = 7.\nPattern constraints Cf (T). This optimization is critical for processing very large state graphs, not plain traces. We will show for example that SIFT can learn the n-puzzle domain by processing the full state graph for n = 8, which involves almost 200,000 states and 500,000 state transitions. For this, the pattern constraints Cf (T) are obtained by traversing reduced graphs where edges (n, n') labeled with actions a with no pattern in Bf are eliminated by merging the nodes n and n'. This simplification, that applies to plain traces as well, is carried out at the level of feature types, because there are actions that due to their argument types, cannot be part of any feature of a given type. In our current implementation, the process of collecting the pattern constraints in Cf (T) for a given action grounding Af (o) is actually done by a simple 0-1 coloring algorithm that runs in time that is linear in the size of such reduced graphs."}, {"title": "Experiments", "content": "We have tested the SIFT algorithm over a number of benchmarks in classical planning. For this, a set of traces T is"}, {"title": "Discussion", "content": "We have presented the first general, and scalable solution to the problem of learning lifted STRIPS models from traces alone. The approach makes use of the intuitions that underlie the LOCM systems (Cresswell and Gregory 2011; Cresswell, McCluskey, and West 2013) but the formulation, the scope, and the theoretical guarantees are different. The learning task is challenging because there is no information about the structure of states, which must be fully inferred from the traces. The new approach is based on the notion of features f = <k, B) that represent assumptions: the possibility of an atom f(x) in the hidden domain of arity k, being affected by the action patterns in B only. The consistency of these assumptions can be tested efficiently over the input traces T by collecting a set Cf (T) of tractable, 2-CNF-like equality and inequality pattern constraints. The consistent features define the learned domain in a simple manner which is guaranteed to generalize correctly for a suitable finite set of traces. The experiments show the generality and scalability of the learning method and its implementation in SIFT.\nThree direct extensions that we have not addressed in the paper are: the elimination of \u201credundant\u201d features and predicates, the derivation of static predicates of lower arity, and the variations needed to make the learning approach robust to noisy inputs. For this, notice that rather than \u201cpruning\u201d a feature f when found to be inconsistent with a trace, f can be pruned when inconsistent with k traces. A more challenging extension involves learning models over languages that are more expressive than STRIPS with negation. For example, the n-puzzle domain can be represented in terms of four actions, up, down, left, and right, with no arguments, but not in STRIPS. Such an extension would be needed for learning lifted models from traces obtained from simulators or real settings. Indeed, the proposed approach can't learn Blocksworld from traces that just involve a single type of move actions, because there is simply not such a STRIPS model."}]}