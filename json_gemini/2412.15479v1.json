{"title": "Continual Learning Using Only Large Language Model Prompting", "authors": ["Jiabao Qiu", "Zixuan Ke", "Bing Liu"], "abstract": "We introduce CLOB, a novel continual learning (CL) paradigm wherein a large language model (LLM) is regarded as a black box. Learning is done incrementally via only verbal prompting. CLOB does not fine-tune any part of the LLM or add any trainable parameters to it. It is particularly suitable for LLMs that are accessible via APIs. We also propose a new CL technique, called CIS, based on incremental summarization that also overcomes the LLM's input length limit. Experiments show CIS outperforms baselines by a very large margin.", "sections": [{"title": "1 Introduction", "content": "Continual learning (CL) learns a sequence of tasks incrementally (Chen and Liu, 2018). Once a task is learned, its training data is discarded. Existing CL work in NLP mainly fine-tunes language model (LM) parameters or uses adapters or variants to adapt the LM (Ke and Liu, 2022). In learning a new task, the system must update the network parameters without seeing the old task data. This may corrupt the knowledge learned from old tasks, causing catastrophic forgetting (CF). Further, since a large number of training samples, expensive training, and access to the LM parameters are needed, it is limited to \"small\" LMs.\nRecently, large language models (LLMs) such as GPT4 (OpenAI, 2023) and Gemini (Google, 2024) have revolutionized NLP, but they are typically accessed only through APIs. In these \u201cblack-boxes\u201d1 LLMs, the users typically use prompts that include few-shot in-context examples and instructions to ask the LLMs to perform their tasks.\nCL with black-box LLMs is clearly important. However, to our knowledge, CL has not been explored in this context. Our first contribution is thus to propose a new CL paradigm for this context, called CLOB (Continual Learning Over Black-box LLMs). The user works with the LLM using only verb prompts with few-shot in-context examples and instructions. The traditional parameter-based CF caused by parameter updating disappears, but a new prompt-based CF appears.\nThis paper works in the class-incremental learning (CIL) setting of CL. In CIL, each task consists of one or more classes to be learned. In testing, no task identification information is given. To make CIL more realistic, we allow the arrivals of the training data from different tasks to intertwine, called blurry task boundaries. That is, when a new task arrives, only a portion of its training data is available and the rest of the labeled samples of the task may come at any time later (Koh et al., 2022). This is referred to as online or streaming CIL, where the training data arrives as a continuous stream, and each training example is seen only once by the system (Guo et al., 2022).\nSince an LLM has a maximum input length or token limit, it restricts the number of in-context examples that can be used in a prompt. This poses a major challenge for CIL because it needs to learn more and more tasks/classes. Thus, the ability to learn and store a minimum amount of knowledge for each class and to incrementally update the knowledge on the fly when additional data of old tasks becomes available is critical. This update also needs to ensure that the knowledge learned previously is not forgotten. Unlike existing approaches, in CLOB, we must do all these by using verbal prompts without touching any network parameters.\nOur second contribution is to propose a simple and novel CIL method for CLOB, called CIS (in-context CL via Incremental Summarization). CIS leverages the summarization capabilities of LLMs to encapsulate the knowledge about each class in a summary and incrementally learn and update the summary when some data from some old tasks come. CIS can also deal with the token limit issue for LLMs. Experimental results show significant accuracy gains compared to baselines."}, {"title": "Related Work", "content": "Overcoming CF is a key goal of CL. There are many existing approaches, e.g., regularization-based approaches (Kirkpatrick et al., 2016; Li et al., 2022; Liu et al., 2019), replay-based approaches (Rebuffi et al., 2017; Liu et al., 2021; Scialom et al., 2022; Qin et al., 2022; Huang et al., 2021) and parameter isolation based approaches (Ke et al., 2021, 2023; Serr\u00e0 et al., 2018; Gururangan et al., 2022; Qin et al., 2022; Zhu et al., 2022; Geng et al., 2021; Madotto et al., 2021). Recent research in NLP also used parameter-tuning (Zhao et al., 2024) or a rehearsal-free modular (Wang et al., 2024b) to help knowledge transfer among tasks. A data-efficient CL paradigm for fine-tuning LLMs (Guo et al., 2024) and a prompt tuning-based CL method (Wang et al., 2024c) are also proposed. Reflexion (Shinn et al., 2023) and LLM as optimizer (Yang et al., 2024) update previous knowledge without knowledge retention. Voyager (Wang et al., 2024a) adds new skills to a library and retrieves it for each new task. We are different as we treat LLMs as black boxes and use only verb prompting for CL.\nMany few-shot and instruction prompting techniques are proposed in (Wei et al., 2022; Zhou et al., 2023; Khot et al., 2022; Yao et al., 2023; Hao et al., 2023). However, they do not do prompting for CL."}, {"title": "2 Proposed CIS Method for CLOB", "content": "CIS learns a sequence of tasks $T_1, \\dots, T_n$ in CIL. Each task t has an input space $X^{(t)}$, a class label space $Y^{(t)}$ ($Y^{(t)} \\cap Y^{(i)} = \\emptyset$ for all $i \\neq t$), and a training set $D^{(t)} = \\{(x, y)\\}$ drawn i.i.d. from $P_{X^{(t)}Y^{(t)}}$. When task t arrives, only a subset $D_{sub}^{(t)}$ of $D^{(t)}$ is available for learning. The rest of the training samples $D_{rest}^{(t)} = D^{(t)}\\D_{sub}^{(t)}$, may arrive at any time later. That is why we say that the arrivals of the data from different tasks intertwine, or the task boundaries are blurry. Our goal is to learn a function $f : \\bigcup_{t=1}^{n}X^{(t)} \\rightarrow \\bigcup_{t=1}^{n}Y^{(t)}$ to predict the class label of each test sample x. No task identifier is given for a test sample in testing.\nCIS works in online CIL (Guo et al., 2022; de Masson d'Autume et al., 2019; Wang et al., 2020) with no training sample saved after being seen. Learning is done incrementally via verbal prompts over a black-box LLM whenever some training samples arrive."}, {"title": "2.1 CIS System", "content": "Due to the blurry task boundary and stream data, the following three scenarios may occur during training and the system needs to learn from any arrival data immediately and incrementally: (1) a new task t arrives with only a subset of the training data $D_{sub}^{(t)}$. The system generates a summary of the data in each class and saves the summary. (2) Only a set S of new samples from the remaining samples of the old tasks arrives. CIS updates the summary of each class in S using samples of the class in S. (3) Both (1) and (2) occur. CIS performs the corresponding actions of (1) and (2). Below, we present the summary generator and the summary updator. An overview of CIS is given in Figure 1.\nSummary generator ($M_r$): We also call this system the reflector. It is used only when a new task arrives. Since the data is discarded after it is learned, we propose to use the verbal summary to represent each class. Specifically, given the data from a task t, $D_{sub}^{(t)}$, the LLM is prompted to generate a summary $s_i^{(t)}$ for each new class i in the task using the data of the class $D_{sub,i}^{(t)}$, which is expected to represent the knowledge of the class,\n$s_i^{(t)} = M_r(D_{sub,i}^{(t)}) \\qquad (1)$\nThe resulting summary $s^{(t)}$ is saved. We call all saved summaries the summary base.\nSummary Updator ($M_u$). As new data $D_{new}^{(pre)}$ from previous tasks may come later at any time. The summaries of the classes involved in the new data need to be updated. This is done by the Updator. This update can potentially cause forgetting of existing knowledge in the summaries. We call this prompt-based forgetting. Specifically, for each class j (from a previous task p) involved in the new data $D_{new,j}^{(pre)}$, its summary $s_j^{(p)}$ is updated with the new data of class j, $D_{new,j}^{(pre)}$. This incremental summarization is also done via prompts.\n$s_j^{(p)} = M_u(s_j^{(p)}, D_{new,j}^{(pre)}). \\qquad (2)$\nwhere $p \\in pre$. The updated summary, $s_j^{(p)}$, replaces the original summary $s_j^{(p)}$ in the summary base.\nSolver ($M_s$) for Testing. Due to the prompt length/token limit of LLMs and the fact that a test"}, {"title": "3 Experiments", "content": "Datasets. We use four datasets. (1) Banking-77 with 77 classes (Casanueva et al., 2020), (2) CLINC-80 (Larson et al., 2019) with 80 classes from 10 domains, (3) DPpedia-14 (Lehmann et al., 2014) with 14 classes, and (4) Reuters-14 (Lewis, 1997) with the top-14 most frequent classes. Due to budget constraints and the use of OpenAI's paid GPT-3.5 API, we limited our study to 80 of the 150 classes in the CLINC dataset. However, CIS is capable of handling all 150 classes. Additionally, we focus on classification datasets since CIL is not well-suited for various NLP tasks like summarization, question-answering, and sentiment analysis.\nFor training, we select 7 random samples per class for all datasets. 7 was chosen to balance the need for variability in our settings with cost considerations. Tasks are ordered randomly, and the arrival times of new samples are also randomized in the Blurry setting. We perform 3 random runs for each experiment and report the average accuracy.\nBlurry Setting. It is denoted by \u2018M / N Blurry', where M + N = 7, M is the number of training samples per class used when a task first appeared and N is the number of additional training samples per class that randomly appear later. Note that although the total number of training samples per class is 7 in this paper due to the budgetary constraint, this blurry setting allows CIS to handle any number of training samples per class and any possible M and N values.\nBaselines. We compare CIS with several base-lines: (1) EWC, a regularization-based algorithm to"}, {"title": "3.1 Evaluation Results and Analysis", "content": "Ablation results. We report ablation results first as they are more interesting. We use the test accuracy after all tasks are learned in Table 1, called the Last Accuracy. Average Incremental Accuracy and Forgetting Rate are also commonly used, but they require accuracy after each task is learned. In the blurry setting, where task boundaries are not clearly defined, these metrics are hard to apply.\nCIS is effective. In the 3/4-blurry, 4/3-blurry, and 5/2-blurry settings, the accuracy results are comparable to or even exceed (as seen with DBpedia) those obtained when all 7 training samples per class are presented simultaneously (7 Non-blurry).\nForgetting. Comparing the accuracy results of CIS with those of 7-Non-blurry helps quantify the amount of prompt-based forgetting resulting from incremental summarization. We observe minimal forgetting."}, {"title": "4 Conclusion", "content": "This paper made two contributions: (1) proposing a new CL paradigm, called CLOB, which works with black-box LLMs using only verbal prompts. (2) proposing a novel CL method CIS based on incremental summarization. Evaluations show that CIS not only has almost no CF but also outperforms baselines by a large margin.\nWe believe that there are two main reasons for the strong results. First, there is zero model parameter-based catastrophic forgetting, which the baselines have, because they require training or fine-tuning the full or part of the network for each new task. This is a significant advantage of LLMs. By aiming to cover comprehensive knowledge, LLMs can ensure that no essential information is overlooked during summary updates, effectively mitigating the risk of forgetting caused by updating summaries. Second, by using very compact summaries, our classification process can access summaries of all classes or in chunks simultaneously, but the baselines do not have access to the representations of all tasks at the same time as they cannot use summaries. Note that the summary of each class can be seen as its representation. Although replay-based baselines have access to some raw data of earlier classes/tasks, the amount of the raw data is too small for the system to handle parameter-based forgetting.\nThe experiments conducted in this paper stay within the scope of category-based text classification, as our work focuses on the CIL setting, which requires learning an increasing number of new classes over time. Relation classification is also appropriate for the proposed setting and, thus, a potential future extension of this work."}, {"title": "5 Limitations", "content": "There exists a concern that if each document is too long to fit in the token limit of the LLM, it will be difficult to produce a summary for the document. In such a case, we may need to break the document into multiple chunks and summarize each chunk first. After that, we summarize the chunks of summaries. However, it is unclear whether the approach will be effective. To address this problem, we could also use long-context LLMs. However, at this point, we cannot draw any conclusion about using very long documents as we do not have such documents. New experiments will be needed to test using very long documents to find the most appropriate solution, leading to future work.\nAnother limitation is that the proposed method may be hard to apply to computer vision applications due to the use of summaries. It is unclear how to replace the text summary with some form of image summary. These all form interesting future research directions, which are worthy of exploration because the proposed approach is highly effective and has almost no forgetting, which has plagued the existing fine-tuning or adaptation-based CL."}, {"title": "6 Ethics Statement", "content": "We believe that our work has no ethical issues or risks as we are using public-domain datasets and our task is simply classification based on the class labels already provided in the datasets."}, {"title": "A Prompts Used in CIS", "content": "A.1 Reflector\nI will present you with several examples from the same class. Based on these examples, please provide a summary of the class in no more than 3 sentences. Note that your summary should not include any of the examples.\nA.2 Updator\nBelow is the original summary of a class. I will now provide m additional examples within this class. Based on these, please update the summary accordingly. Ensure that the updated summary does not exceed 3 sentences.\nA.3 Solver - Classification\nPlease classify the provided test sample into one of the listed classes based on the summaries provided for these classes. The summaries are formatted as '<class name>: [summary].' Your response should include only one class name as the answer. This name must exactly match one of the classes given. Do not include the original test sample in your response.\nA.4 Solver - Confidence\nPlease tell me your confidence scores for the test sample belonging to each class I provided. I will present you a list of summaries for these classes as your reference. The summaries are formatted as '<class name>: [summary].' Your response should include only the class names and the corresponding confidence scores in decimal as the answer. The name must exactly match one of the classes given. Do not include the original test sample in your response."}, {"title": "B Summary Examples", "content": "Routing: \"The category is requesting routing numbers for various banks and accounts. These numbers are used to identify the specific bank and account when making transactions. Customers can find their routing numbers through their bank's website or by contacting their bank directly.\"\nTransactions: \"The category is about requesting information on past transactions, including the ability to list recent transactions, check on a specific transaction, and view transaction history within a certain time frame.\"\nMin_payment: \"The category is about minimum payments for various bills, such as truck payments, M&T bills, power bills, credit card bills, and phone bills. Customers are seeking information on the minimum amount they need to pay for each bill.\""}, {"title": "C Random Order Issue", "content": "As discussed, the order of classes provided to the LLMs affects the results. The top-k confidence scores are no exceptions.\nTo investigate this issue, we conducted experiments using DBpedia-14 dataset with our CIS system.\nThe experiments using Llama-3.1-8B show the following results:\n3/4-blurry: 90.32 \u00b10.76\n4/3-blurry: 90.18 \u00b13.89\n5/2-blurry: 90.18 \u00b11.57\nNon-blurry: 90.57 \u00b11.41\nThe results show a slight decline compared to the original results with Llama, with higher standard deviations. We also ran similar experiments with 3/4-blurry and 4/3-blurry using GPT-3.5, which are reported below:\n3/4-blurry: 92.41 \u00b10.56\n4/3-blurry: 93.56 \u00b10.81\nIn this case, the standard deviations are low, indicating that the class order has a minimal effect on the final classification results. We also notice that these new results are better than those reported in the paper, but this is possibly due to the update of OpenAI's system."}]}