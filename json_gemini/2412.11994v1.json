{"title": "Fairness Shields: Safeguarding against Biased Decision Makers", "authors": ["Filip Cano", "Thomas A. Henzinger", "Bettina K\u00f6nighofer", "Konstantin Kueffner", "Kaushik Mallik"], "abstract": "As AI-based decision-makers increasingly influence human lives, it is a growing concern that their decisions are often unfair or biased with respect to people's sensitive attributes, such as gender and race. Most existing bias prevention measures provide probabilistic fairness guarantees in the long run, and it is possible that the decisions are biased on specific instances of short decision sequences. We introduce fairness shielding, where a symbolic decision-maker\u2014the fairness shield-continuously monitors the sequence of decisions of another deployed black-box decision-maker, and makes interventions so that a given fairness criterion is met while the total intervention costs are minimized. We present four different algorithms for computing fairness shields, among which one guarantees fairness over fixed horizons, and three guarantee fairness periodically after fixed intervals. Given a distribution over future decisions and their intervention costs, our algorithms solve different instances of bounded-horizon optimal control problems with different levels of computational costs and optimality guarantees. Our empirical evaluation demonstrates the effectiveness of these shields in ensuring fairness while maintaining cost efficiency across various scenarios.", "sections": [{"title": "Introduction", "content": "With the increasing popularity of machine learning (ML) in human-centric decision-making tasks, including banking (Liu et al. 2018) and college admissions (Oneto et al. 2020), it is a growing concern that the decision-makers often show biases based on sensitive attributes of individuals, like gender and race (Dressel et al. 2018; Obermeyer et al. 2019; Scheuerman et al. 2019). Therefore, mitigating biases in ML decision-makers is an important problem and an active area of research in AI.\nA majority of existing bias prevention techniques use design-time interventions, like pre-processing the training dataset (Kamiran et al. 2012; Calders et al. 2013) or tailoring the loss function used for training (Agarwal et al. 2018; Berk et al. 2017). We propose fairness shielding, the first run-time intervention procedure for safeguarding fairness of already deployed decision-makers.\nFairness shields consider fairness from the sequential decision-making standpoint, where decisions are made on individuals appearing sequentially over a period of time, and each decision may be influenced by those made in the past. While the classical fairness literature typically evaluated fairness in a single round of decision, the sequential setting has been shown to better captures real-world decision making problems (Zhang et al. 2021). Among the works on fairness in the sequential setting, most prior works aimed at achieving fairness in the long run (Hu et al. 2022). Recently, the bounded-horizon and the periodic variants have been proposed, which are often more realistic as regulatory bodies usually assess fairness after bounded time or at regular intervals, such as yearly or quarterly (Oneto et al. 2020).\nOur fairness shields guarantee bounded-horizon and periodic fairness of deployed unknown decision-makers by monitoring each decision and minimally intervening if necessary. Fairness is guaranteed on all runs of the system, whereas existing algorithms guarantee fairness only on average over all runs, leaving individual runs prone to exhibit biases (Alamdari et al. 2024).\nThe basic functionality of fairness shields is depicted in Fig. 1. We assume a bounded-horizon or periodic fairness property is given, with a known time horizon or period, respectively. For each individual appearing in sequence, the fairness shield observes the sensitive attribute, the classifier's recommendation, and the cost of changing that recommendation to a different value, where the cost is assumed to be either provided by the decision-maker or pre-specified as constants. The shield then makes the final decision, en-"}, {"title": "2 Shielding Fairness", "content": "Data-driven classifier. Suppose we are given a population of individuals partitioned into groups a and b, where G = {a,b} are the sensitive features, like race, gender, or language, for example. Consider a data-driven classifier that at each step samples one individual from the population, and outputs a recommended decision from the set B = {1,0} along with an intervention cost from the finite set C \\subset R\u22650. As convention, decisions \u201c1\u201d and \u201c0\u201d will correspond to \u201caccept\u201d and \u201creject,\u201d respectively. We assume that the sampling and classification process gives rise to a given input distribution \u03b8 \u2208 \u0394(X), where the set X := (G \u00d7 B x C) is called the input space. The non-sensitive features of individuals are hidden from the input space because they are irrelevant for shielding. We will assume that \u03b8 is given; in App. C.5, we discuss extensions to cases when \u03b8 is to be estimated from data.\nShields. A shield is a symbolic decision-maker\u2014independent from the classifier and selects the final decision from the output space y := B after observing a given input from X, and possibly accounting for past inputs and outputs. Formally, a shield is a function \u03c0: (X \u00d7 V)* \u00d7 X \u2192 Y, and its bounded-horizon variants are functions of the form (X \u00d7 y)\u2264t \u00d7 X \u2192 Y, for a given t. We will write \u03a0 and \u03a0t to respectively denote the set of all shields and the set of bounded-horizon shields with horizon t. The concatenation of a sequence of shields"}, {"title": "3 Algorithm for FinHzn Shield Synthesis", "content": "We present our algorithm for synthesizing FinHzn shields as defined in Def. 1. A FinHzn shield \u03c0* computes an output y = \u03c0*(\u03c4,x) for every trace \u03c4 and every input x. Our synthesis algorithm builds \u03c0* recursively for traces of increasing length, using an auxiliary value function v(\u03c4) that represents the minimal expected cost conditioned on traces with prefix \u03c4. To define v(\u03c4), we generalize fairness shields with the condition that a certain trace has already occurred. Given a time horizon t and a trace \u03c4 (length can differ from t), the set of fairness shields over time t after \u03c4 is defined as:\n\u03a0_{fair}^{\\theta,\\phi,t} := {\\pi \\in \\Pi | \\forall \\tau' \\in (X \\times Y)^t . \\tau\\tau' \\in F_{\\mathcal{T}/\\tau+\\tau'} \\Rightarrow \\phi(\\tau\\tau') \\leq \\kappa}.\nThen v(\u03c4) is given by:\n\\upsilon(\\tau) := \\min_{\\pi \\in \\Pi_{fair}^{(\\theta, \\phi, T-|\\tau|)}} E[cost | \\tau; \\theta, \\pi, T - |\\tau|].\nFor every trace \u03c4 and every input x \u2208 X, the optimal value of the shield is \u03c0*(\u03c4, x) = arg min_{y\u2208y} v(\u03c4, (x, y)).\nIn Sec. 3.1, we present a recursive dynamic programming for computing v(\u03c4), whose complexity grows exponentially with the length of T. In Sec. 3.2, we present an efficient solution using only the p counters defining the fairness property, thus solving the synthesis problem in O(TP \u2022|X|)-time. From now on, we present the main ideas in the text, and refer the reader to App. B for detailed proofs of all results."}, {"content": "We present our algorithm for synthesizing FinHzn shields as defined in Def. 1. A FinHzn shield $\\pi^*$ computes an output $y = \\pi^*(\\tau,x)$ for every trace $\\tau$ and every input $x$. Our synthesis algorithm builds $\\pi^*$ recursively for traces of increasing length, using an auxiliary value function $v(\\tau)$ that represents the minimal expected cost conditioned on traces with prefix $\\tau$. To define $v(\\tau)$, we generalize fairness shields with the condition that a certain trace has already occurred. Given a time horizon $t$ and a trace $\\tau$ (length can differ from $t$), the set of fairness shields over time $t$ after $\\tau$ is defined as:\n$$\\Pi_{fair}^{\\theta,\\phi,t} := {\\pi \\in \\Pi | \\forall \\tau' \\in (X \\times Y)^t . \\tau\\tau' \\in F_{\\mathcal{T}/\\tau+\\tau'} \\Rightarrow \\phi(\\tau\\tau') \\leq \\kappa}.$$\nThen $v(\\tau)$ is given by:\n$$\\upsilon(\\tau) := \\min_{\\pi \\in \\Pi_{fair}^{(\\theta, \\phi, T-|\\tau|)}} E[cost | \\tau; \\theta, \\pi, T - |\\tau|].$$\nFor every trace $\\tau$ and every input $x \\in X$, the optimal value of the shield is $\\pi^* (\\tau, x) = arg \\min_{y\\in y} v(\\tau, (x, y))$.\nIn Sec. 3.1, we present a recursive dynamic programming for computing $v(\\tau)$, whose complexity grows exponentially with the length of $T$. In Sec. 3.2, we present an efficient solution using only the $p$ counters defining the fairness property, thus solving the synthesis problem in $O(TP \\cdot|X|)$-time. From now on, we present the main ideas in the text, and refer the reader to App. B for detailed proofs of all results."}, {"title": "3.1 Recursive Computation of v(\u03c4)", "content": "Base case. Let T be the time horizon and \u03c4 be a trace of length T. Since the horizon is reached if \u03c6(\u03c4) < \u043a then the expected cost is zero because fairness is already satisfied and no more cost needs to be incurred, whereas if \u03c6(\u03c4) > \u043a, the expected cost is infinite, because no matter what cost is paid fairness can no longer be achieved. Formally,\n\u03c5(\u03c4) = { 0 \u03c6(\u03c4) \u2264 \u043a,\n\u221e otherwise.\n(3)\nRecursive case. Let \u03c4 be a trace of length smaller than T. The probability of the next input being x = (g, r, c) is \u03b8(x), and the shield decides to output y that either agrees with the recommendation r (the case y = r) or differs from it (the case y \u2260 r)\u2014whichever minimizes the expected cost. When y = r, then the trace becomes (\u03c4, (x,y = r)). Therefore, no cost is incurred and the total cost remains the same as v(\u03c4, (x,y = r)). When y \u2260 r, the trace becomes (\u03c4, (x, y \u2260 r)). Thus, the incurred cost is c and the new total cost becomes c + v(\u03c4, (x, y = r)). Therefore\n\u03c5(\u03c4) = \u03a3x=(g,r,c)\u2208X \u03b8(x) min { (v(\u03c4, (x, y \u2260r)) + c)  v(\u03c4, (x, y = r)),}. (4)\nEqs. (3) and (4) can be used to recursively compute v(\u03c4) for every \u03c4 of length up to T, and the time and space complexity of this procedure is O(|X \u00d7 Y|T). The correctness of Eq. (4) is formally proven in App. B, Lem. 7."}, {"content": "Base case. Let $T$ be the time horizon and $\\tau$ be a trace of length $T$. Since the horizon is reached if $\\phi(\\tau) < \\kappa$ then the expected cost is zero because fairness is already satisfied and no more cost needs to be incurred, whereas if $\\phi(\\tau) > \\kappa$, the expected cost is infinite, because no matter what cost is paid fairness can no longer be achieved. Formally,\n$$\\upsilon(\\tau) = {\\begin{cases} 0 & \\phi(\\tau) \\leq \\kappa, \\\\ \\infty & \\text{otherwise}. \\end{cases}}$$\n(3)\nRecursive case. Let $\\tau$ be a trace of length smaller than $T$. The probability of the next input being $x = (g, r, c)$ is $\\theta(x)$, and the shield decides to output $y$ that either agrees with the recommendation $r$ (the case $y = r$) or differs from it (the case $y \\neq r$)\u2014whichever minimizes the expected cost. When $y = r$, then the trace becomes $(\\tau, (x,y = r))$. Therefore, no cost is incurred and the total cost remains the same as $v(\\tau, (x,y = r))$. When $y \\neq r$, the trace becomes $(\\tau, (x, y \\neq r))$. Thus, the incurred cost is $c$ and the new total cost becomes $c + v(\\tau, (x, y = r))$. Therefore\n$$\\upsilon(\\tau) = \\sum_{x=(g,r,c)\\in X} \\theta(x) \\min { (\\upsilon(\\tau, (x, y \\neq r)) + c)  \\upsilon(\\tau, (x, y = r)),}.$$\n(4)\nEqs. (3) and (4) can be used to recursively compute $v(\\tau)$ for every $\\tau$ of length up to $T$, and the time and space complexity of this procedure is $O(|X \\times Y|^T)$. The correctness of Eq. (4) is formally proven in App. B, Lem. 7."}, {"title": "3.2 Efficient Recursive Computation of v(\u03c4)", "content": "We now present an efficient recursive procedure for computing FinHzn shields that runs in polynomial time and space. The key observation is that is a fairness property that depends on through a statistic that uses p counters. Consequently, \u03c5(\u03c4) in Eq. (3) and Eq. (4) depend only on counter values, not on exact traces. This allows us to define our dynamic programming algorithm over the set of counter values taken by the statistic \u03bc. Let R\u03bc,T \u2286 N\u00ba be the set of values the statistic \u03bc can take from traces of length at most T. We have the following complexity result.\nTheorem 1. The bounded-horizon shield-synthesis problem can be solved in O(|R\u03bc,\u03c4|\u00b7|X|)-time and O(|R\u03bc,\u03c4|\u00b7 |X|)-space.\nIn most fairness properties like DP and EqOpp, the range of values they can take is R\u00b5,T = [0,T]p, where p is the number of counters (p = 4 for DP, and p = 5 for EqOpp), making the complexity polynomial in the length of the time horizon."}, {"content": "We now present an efficient recursive procedure for computing FinHzn shields that runs in polynomial time and space. The key observation is that is a fairness property that depends on through a statistic that uses $p$ counters. Consequently, $\\upsilon(\\tau)$ in Eq. (3) and Eq. (4) depend only on counter values, not on exact traces. This allows us to define our dynamic programming algorithm over the set of counter values taken by the statistic $\\mu$. Let $R_{\\mu,T} \\subseteq N^p$ be the set of values the statistic $\\mu$ can take from traces of length at most $T$. We have the following complexity result.\nTheorem 1. The bounded-horizon shield-synthesis problem can be solved in $O(|R_{\\mu,T}|\\cdot|X|)$-time and $O(|R_{\\mu,T}|\\cdot |X|)$-space.\nIn most fairness properties like DP and EqOpp, the range of values they can take is $R_{\\mu,T} = [0,T]^p$, where $p$ is the number of counters ($p = 4$ for DP, and $p = 5$ for EqOpp), making the complexity polynomial in the length of the time horizon."}, {"title": "4 Algorithms for Periodic Shield Synthesis", "content": "We present algorithms for computing periodic fairness shields for a broad subclass of group fairness properties, termed difference of ratios (DoR) properties. A statistic \u03bc is single-counter if it maps every trace \u03c4 to a single counter value, i.e., \u03bc(\u03c4) \u2208 N, and additive if \u03bc(\u03c4\u03c4') = \u03bc(\u03c4) + \u03bc(\u03c4') for any traces \u03c4 and \u03c4'. A group fairness property \u03c6 is DoR if (a) for each group g, WF9(t) = num\u2079(T)/den\u2079(T), where num9 (T) and deng (T) are additive single-counter statistics, and (b) \u03c6(T) = |WF(T)-WF\u266d(t)|. Many fairness properties, including DP and EqOpp, are DoR, though DI is not because it violates the condition (b). For DoR fairness properties, we propose two approaches for constructing periodic fairness shields: static and dynamic, and we explore their respective strengths and weaknesses."}, {"content": "We present algorithms for computing periodic fairness shields for a broad subclass of group fairness properties, termed difference of ratios (DoR) properties. A statistic $\\mu$ is single-counter if it maps every trace $\\tau$ to a single counter value, i.e., $\\mu(\\tau) \\in N$, and additive if $\\mu(\\tau\\tau') = \\mu(\\tau) + \\mu(\\tau')$ for any traces $\\tau$ and $\\tau'$. A group fairness property $\\phi$ is DoR if (a) for each group $g$, $WF^g(t) = num^g(T)/den^g(T)$, where $num^g (T)$ and $den^g (T)$ are additive single-counter statistics, and (b) $\\phi(T) = |WF(T)-WF^{\\flat}(t)|$. Many fairness properties, including DP and EqOpp, are DoR, though DI is not because it violates the condition (b). For DoR fairness properties, we propose two approaches for constructing periodic fairness shields: static and dynamic, and we explore their respective strengths and weaknesses."}, {"title": "4.1 Periodic Shielding: The Static Approach", "content": "In the static approach, a periodic shield is obtained by concatenating infinitely many identical copies of a statically"}, {"title": "5 Experiments", "content": "Experimental setup. We performed our experiments on the datasets Adult (Becker et al. 1996), COMPAS (Kirchner et al. 2016), German Credit (Hofmann 1994), and Bank Marketing (Moro et al. 2012). The protected attributes include race, gender, and age. We synthesized shields to ensure DP and EqOpp with thresholds \u03ba\u2208 {0.05, 0.1, 0.15, 0.2}. We give further details on our experimental setup in App. C.\n5.1 FinHzn Shields\nThe ML models were trained with DiffDP (Chuang et al. 2021), HSIC (P\u00e9rez-Suay et al. 2017), LAFTR (Madras et al. 2018), and PRemover (Kamishima et al. 2012). As a baseline, we also trained a classifier using empirical risk minimization (ERM). For all models and datasets, FinHzn shields were synthesized with T = 100 for DP and T = 75 for EqOpp. Shield synthesis took about 1 second and 30 MB for DP, and 1.5 seconds and 1.3 GB for EqOpp. We present the detailed resource usage in App. D.1. We compared model performances\u2014with and without shielding-across 30 simulated runs. The analysis follows.\nFairness. Unshielded ML models violated bounded-horizon fairness in 44% of the cases for DP and in 65% for EqOpp, while shielded models were always fair at the horizons. Detailed results are in Fig. 5 and Tab. 9 in App. D. This empirically validates the effectiveness of FinHzn shields."}, {"title": "7 Discussion and Future Work", "content": "Static vs. dynamic shielding in the periodic setting. Static shields are computationally cheaper than Dynamic shields and have no runtime overhead, making them ideal for fast decision-making applications like online ad-delivery (Ali et al. 2019). However, they can't adjust decisions based on the actual history, leading to overly restrictive and frequent interventions\u2014particularly in the long run. In contrast, Dynamic shields adapt to historical data, resulting in fewer interventions over time, making them suitable for applications like banking where decision-making can afford longer computation times (Liu et al. 2018).\nOn the feedback effect in sequential decision-making. Decisions that seem fair individually can introduce biases over time as the input distribution @ changes based on past actions (D'Amour et al. 2020; Sun 2023). Although we assumed a constant @ in this paper, our recursive synthesis algorithm from Sec. 3 could be adapted to handle trace-dependent @ by simply modifying Eq. 4. A detailed study of this adaptation is left for future work.\nFairness shields with humans in the loop. In applications where human experts make decisions with AI assistance, shields may not have final decision authority but can act as a runtime \"fairness filter\" to modify and de-bias the Al's outputs before presenting them to the human expert."}, {"title": "A Additional Insights", "content": "In this appendix, we discuss additional insights into the assumptions that we have throughout the paper.\nA.1 Existence of FinHzn\nThe set of feasible solutions of the optimization problem in Eq. 1 is nonempty for DoR properties, because the fairness-shield that always accepts or always rejects each candidate from each group is a solution that trivially fulfills \u03c6(\u03c4) \u2264 \u043a. Even nontrivial optimal fairness-shields may exhibit such degenerate behaviors at runtime, when the order of appearances of individuals from the two groups is excessively skewed. Consider the following example for demographic parity (DP). Let \u043a <7. Suppose at time T \u2013 1, all the individuals seen so far were from group a (i.e., na = T \u2013 1 and n\u044c = 0). If some of the individuals were accepted and the rest rejected, then 0 < na1 < na, implying \u043a < na1/na < 1 \u2013 K. Now if the T-th individual x is from group b, n\u044c becomes 1, and no matter which action the shield picks, DP will be violated: If x is accepted, then n\u044c/T = 1/T, and if x is rejected, then n\u044c = 0. In both cases, DP ((na1)/(na) (\u043f\u044c1)/(\u043f\u044c)) > \u043a. Therefore, the shield must have made sure that each individual until time T \u2013 1, all of whom were from group a, were either accepted or rejected. Luckily, the chances of such skewness of appearance orders is rare in most applications, so that FinHzn as in Def. 1 exhibit effective, non-trivial behaviors in most cases as seen from our experiments."}, {"content": "In this appendix, we discuss additional insights into the assumptions that we have throughout the paper.\nA.1 Existence of FinHzn\nThe set of feasible solutions of the optimization problem in Eq. 1 is nonempty for DoR properties, because the fairness-shield that always accepts or always rejects each candidate from each group is a solution that trivially fulfills $\\phi(\\tau) \\leq \\kappa$. Even nontrivial optimal fairness-shields may exhibit such degenerate behaviors at runtime, when the order of appearances of individuals from the two groups is excessively skewed. Consider the following example for demographic parity (DP). Let $\\kappa < \\frac{1}{T}$. Suppose at time $T \u2013 1$, all the individuals seen so far were from group $a$ (i.e., $n_a = T \u2013 1$ and $n_b = 0$). If some of the individuals were accepted and the rest rejected, then $0 < n_{a1} < n_a$, implying $\\kappa < \\frac{n_{a1}}{n_a} < 1 \u2013 \\kappa$. Now if the $T$-th individual $x$ is from group $b$, $n_b$ becomes $1$, and no matter which action the shield picks, DP will be violated: If $x$ is accepted, then $\\frac{n_{b1}}{n_b} = \\frac{1}{T}$, and if $x$ is rejected, then $\\frac{n_{b1}}{n_b} = 0$. In both cases,\n$$DP(\\frac{n_{a1}}{n_a} - \\frac{n_{b1}}{n_b}) > \\kappa.$$\nTherefore, the shield must have made sure that each individual until time $T \u2013 1$, all of whom were from group $a$, were either accepted or rejected. Luckily, the chances of such skewness of appearance orders is rare in most applications, so that FinHzn as in Def. 1 exhibit effective, non-trivial behaviors in most cases as seen from our experiments."}, {"title": "A.2 Counterexample families for Static-Fair shields being not composable", "content": "We have already shown in Example 5 that traces can have zero bias in terms of DP, and when composed have arbitrarily close to 1.\nWhile the family of counterexamples presented in Example 5 is quite degenerate in the sense that acceptance rates are always either 0 or 1, we present here another family of counterexamples that is less degenerate. We write these examples for demographic parity, but the same ideas can be applied to build counterexamples for any DoR property.\nLet T > 0 and 0 < K < T/2. The family of counterexamples will be parametrized by (T, K).\nFor a pair (T, K) consider traces T1, T2 such that (na1, \u041f\u0430, \u043f\u044c\u044b, \u043f\u044c) (71) = (1, K, 1, T - K), and (\u041f\u04301, \u041f\u0430, \u043f\u044c\u044b, \u043f\u044c)(\u04422) = (T \u2013 K \u2013 1,T \u2013 K, K \u2212 1, \u041a). In the trace 71, exactly one element of each group was accepted, while in the trace T2, all but one element of each group were accepted. The values of demographic parity are:\nDP(T1)T,K = |(1/K) - (1/(T-K))| = |(T-2K)/((T-K)K)|\n(7)\nDP(T2)T,K = |((T-K-1)/(T-K)) - ((K-1)/K)| = |(T-2K)/(K(T-K))|\n(8)\nDP(T1T2)T,K = |(T-K)/T - K/T| = |(T-2K)/T|\n(9)\nThese pair of traces are not a counterexample for every pair (T, K). However, we can observe that, once fixed K, the limit when T \u2192 \u221e of Eq. 7 and Eq. 8 is 1/K, but the limit when T\u2192\u221e of Eq. 9 is 1. Therefore, for every \u0454, we can find K large enough such that 1/\u039a < \u03b5/2, and then find T large enough such that the corresponding DP values are close enough to the limit.\nWe now build a different family of counterexamples that show that the condition for correctness of Static-Fair shields given in Thm. 2 is as tight as can be.\nTheorem 6. For all \u043a > 0, there exists \u043a\u2081 and K2 K1 \u2264\u043a\u2264 K2, such that for i \u2208 {1,2}, there exists ti and traces Ti, Ti that are []-balanced such that DP(Ti) \u2264 ki, DP(T) \u2264 \u043a\u0456, and DP(TiT) > \u043a\u0456."}, {"content": "We have already shown in Example 5 that traces can have zero bias in terms of DP, and when composed have arbitrarily close to 1.\nWhile the family of counterexamples presented in Example 5 is quite degenerate in the sense that acceptance rates are always either 0 or 1, we present here another family of counterexamples that is less degenerate. We write these examples for demographic parity, but the same ideas can be applied to build counterexamples for any DoR property.\nLet $T > 0$ and $0 < K < \\frac{T}{2}$. The family of counterexamples will be parametrized by $(T, K)$.\nFor a pair $(T, K)$ consider traces $\\tau_1, \\tau_2$ such that $(n_{a1}, n_a, n_{b1}, n_b) (\\tau_1) = (1, K, 1, T - K)$, and $(n_{a1}, n_a, n_{b1}, n_b)(\\tau_2) = (T \u2013 K \u2013 1,T \u2013 K, K \u2212 1, K)$. In the trace $\\tau_1$, exactly one element of each group was accepted, while in the trace $\\tau_2$, all but one element of each group were accepted. The values of demographic parity are:\n$$DP(\\tau_1)_{T,K} = |(\\frac{1}{K}) - (\\frac{1}{T-K})| = |\\frac{T-2K}{(T-K)K}|$$\n(7)\n$$DP(\\tau_2)_{T,K} = |(\\frac{T-K-1}{T-K}) - (\\frac{K-1}{K})| = |\\frac{T-2K}{K(T-K)}|$$\n(8)\n$$DP(\\tau_1\\tau_2)_{T,K} = |(\\frac{T-K}{T}) - (\\frac{K}{T})| = |\\frac{T-2K}{T}|$$\n(9)\nThese pair of traces are not a counterexample for every pair $(T, K)$. However, we can observe that, once fixed $K$, the limit when $T \\rightarrow \\infty$ of Eq. 7 and Eq. 8 is $\\frac{1}{K}$, but the limit when $T\\rightarrow\\infty$ of Eq. 9 is 1. Therefore, for every $\\epsilon$, we can find $K$ large enough such that $\\frac{1}{K} < \\epsilon/2$, and then find $T$ large enough such that the corresponding DP values are close enough to the limit.\nWe now build a different family of counterexamples that show that the condition for correctness of Static-Fair shields given in Thm. 2 is as tight as can be.\nTheorem 6. For all $\\kappa > 0$, there exists $\\kappa_1$ and $\\kappa_2$ $\\kappa_1 \\leq\\kappa\\leq \\kappa_2$, such that for $i \\in {1,2}$, there exists $t_i$ and traces $T_i, \\acute{T_i}$ that are [$\\frac{T}{2}$]-balanced such that $DP(T_i) \\leq \\kappa_i$, $DP(\\acute{T_i}) \\leq \\kappa_i$, and $DP(T_i\\acute{T_i}) > \\kappa_i$."}, {"title": "B.3 Dynamic Shielding", "content": "Lemma 10. Let o be a DoR fairness property with \u03c6(\u03c4) = |WF\u00ba(\u0442) \u2014 WF\u266d(\u03c4)|, and WF9 (t) = num\u00ba(T)/deng(t). Let T1 be a trace and \u043a \u2265 0. There exists a shield \u03c0\u2208 II such that every trace T2 \u2208 FTT N S satisfies DP(T1T2) \u2264 \u043a, where\nS = {T2 \u2208 (X \u00d7 V)T :\n+ \u2264 \u043a + \u03c6(11)}\ndena (T172) den (T172)\nProof. The proof of this result is analogous to that of Lemma 9, with a slightly more convoluted argument.\nLet n = den\u00ba(71), na\u2081 = num\u00ba(T1), n = den\u266d(T1), and n\u2081 = num (71). Without loss of generality, we can assume that na1/n/a - 11/\u2265 0. The alternative case is analogous.\nFor a shield to exist that can enforce 4(T1T2) \u2264 \u043a there must exist, for every value of den\u00ba (7172) (in demographic parity, the amount of individuals of a group), at least one way of deciding acceptance and rejection (value of num\u00ba (T1T2)) that maintains the fairness property in the target bound. Since we do not know a priori how many individuals of each group will appear, this decision must be incremental, and be such that the fairness property is maintained for any number of individuals.\n=\nTo express this, a new trace 72 is enforceable if na den\u00ba (72) > Na and n\u044c = den\u266d(T2) > N\u266d if there exist two sequences (xna), (Yn\u2081) \u2286 N such that for all n\u00ba > Na and nb \u2265 No\n1 + \u2264\u043a + \u03c6(11) (28)\nand for both sequences Xna+1 - Xna \u2208 {0,1} and Yna+1 - Yna \u2208 {0,1}.\nWith the spirit of maintaining the welfare bounds as a proxy to maintaining fairness, we try"}, {"title": "C.1 Computing infrastructure", "content": "All experiments were performed with a workstation with AMD Ryzen 9 5900x CPU, Nvidia GeForce RTX 3070Ti GPU, 32GB of RAM, running Ubuntu 20.04. The code to reproduce our experiments is included as part of the supplementary material."}, {"title": "C.2 Datasets", "content": "We used four tabular datasets in our experiments, all common benchmarks in the fairness community: Adult (Becker et al. 1996), COMPAS (Kirchner et al. 2016), German Credit (Hofmann 1994) and Bank Marketing (Moro et al. 2012). Details on the task, sensitive attributes, size of the dataset, number of numerical and categorical features, as well as existing bias can be found in Table 4."}, {"title": "C.3 Training ML classifiers", "content": "To train our ML models, we adapted the implementation provided by (Han et al. 2024), using the same neural network, train-test splits, and most training hyper-parameters set as default in their implementation, tuning only the hyper-parameters related to fairness.\nWe use fixed architecture multi-layer perception (MLP) with three hidden layers with sizes 512, 256, and 64 in all our experiments. In each case, the model is trained for 150 epochs with batches of 1024 instances, with the exception of the German dataset, which we trained with batches of 128, as the dataset has only 1000 instances. We use the Adam optimizer (Kingma et al. 2015), with a learning rate of 0.01."}, {"title": "C.4 Learning Algorithms", "content": "To train our classifiers", "literature": "n\u2022 Differential Demographic Parity (DiffDP) is a gap regularization method for demographic parity. DiffDP introduces a term in the loss function that penalizes differences in the prediction rates between different demographic groups.\n\u2022 The Hilbert-Schmidt Independence Criterion (HSIC) is a statistical test used to measure the independence of two random variables. Adding an HSIC term measuring the independence between prediction accuracy and sensitive attributes to the loss has been used as a fair learning method (P\u00e9rez-Suay et al. 2017).\n\u2022 Learning adversarially fair and transferable representations (LAFTR) is a method proposed by (Madras et al. 2018), where the classifier learns an intermediate representation of the data that minimizes classification error while simultaneously minimizing the ability of an adversary to predict sensitive features from the representation.\n\u2022 Prejudice Remover (PR) (Kamishima et al. 2012) adds a term to the loss that penalizes mutual information between the prediction accuracy and the"}]}