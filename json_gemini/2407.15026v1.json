{"title": "BENCHMARKING END-TO-END PERFORMANCE OF AI-BASED CHIP PLACEMENT ALGORITHMS", "authors": ["Zhihai Wang", "Zijie Geng", "Zhaojie Tu", "Jie Wang", "Yuxi Qian", "Zhexuan Xu", "Ziyan Liu", "Siyuan Xu", "Zhentao Tang", "Shixiong Kai", "Mingxuan Yuan", "Jianye Hao", "Bin Li", "Yongdong Zhang", "Feng Wu"], "abstract": "The increasing complexity of modern very-large-scale integration (VLSI) design highlights the significance of Electronic Design Automation (EDA) technologies. Chip placement is a critical step in the EDA workflow, which positions chip modules on the canvas with the goal of optimizing performance, power, and area (PPA) metrics of final chip designs. Recent advances have demonstrated the great potential of AI-based algorithms in enhancing chip placement. However, due to the lengthy workflow of chip design, the evaluations of these algorithms often focus on intermediate surrogate metrics, which are easy to compute but frequently reveal a substantial misalignment with the end-to-end performance (i.e., the final design PPA). To address this challenge, we introduce ChiPBench, which can effectively facilitate research in chip placement within the AI community. ChiPBench is a comprehensive benchmark specifically designed to evaluate the effectiveness of existing AI-based chip placement algorithms in improving final design PPA metrics. Specifically, we have gathered 20 circuits from various domains (e.g., CPU, GPU, and microcontrollers). These designs are compiled by executing the workflow from the verilog source code, which preserves necessary physical implementation kits, enabling evaluations for the placement algorithms on their impacts on the final design PPA. We executed six state-of-the-art AI-based chip placement algorithms on these designs and plugged the results of each single-point algorithm into the physical implementation workflow to obtain the final PPA results. Experimental results show that even if intermediate metric of a single-point algorithm is dominant, while the final PPA results are unsatisfactory. This suggests that the AI community should concentrate more on enhancing end-to-end performance rather than those intermediate surrogates. We believe that our benchmark will serve as an effective evaluation framework to bridge the gap between academia and industry.", "sections": [{"title": "1 INTRODUCTION", "content": "The exponential growth in the scale of integrated circuits (ICs), in accordance with Moore's law, has posed significant challenges to chip design (Huang et al., 2021; Lopera et al., 2021). To handle the increasing complexity, many electronic design automation (EDA) tools have been developed to assist hardware engineers. As shown in Figure 1, EDA tools automate various steps in the chip design workflow, including high-level synthesis, logic synthesis, physical design, testing and verification (Huang et al., 2021; S\u00e1nchez et al., 2023).\nChip placement is a critical step in the chip design workflow, which aims to position chip modules on the canvas, with the goal of optimizing the performance, power, and area (PPA) metrics of final chip designs (Cheng et al., 2023; Shi et al., 2023; Lin et al., 2019). Traditionally, this is done manually by human expert designers, which costs much labor and necessitates much expert prior knowledge. Therefore, a lot of design automation methods, especially those AI-based algorithms, have been developed to automate this process. These methods mainly fall into two categories: optimization-based"}, {"title": "2 RELATED WORK", "content": "Datasets Some well-known EDA conferences, such as ISPD and ICCAD, host contests addressing EDA challenges and offer benchmarks with processed data for researchers. However, in the early years (e.g., ISPD2005 (Nam et al., 2005) and ICCAD2004 (Adya et al., 2009)), the provided datasets used overly simplified Bookshelf formats, which are abstracted versions of the actual design kits. Therefore, we cannot evaluate the final PPA of the placement results on those datasets. Recently, ISPD2015 (Bustany et al., 2015) and ICCAD2015 (Kim et al., 2015) have offered benchmarks and datasets closer to real-world applications, including necessary netlist, library, and design exchange files, broadening their utility slightly. Nevertheless, they still lack the essential information (e.g., necessary design kits) to run the open-source EDA tools such as OpenROAD (Kahng & Spyrou, 2021). Beyond these conferences, some other datasets have been developed in various directions. For example, the EPFL (Amar\u00fa et al., 2015) benchmarks and the larger OpenABC-D Chowdhury et al. (2021) dataset concentrated on synthetic netlists, primarily for testing modern logic optimization tools with a focus on logic synthesis. CircuitNet 2.0 Jiang et al. (2023), on the other hand, shifted the focus towards providing multi-modal data for prediction tasks, enhancing the capability for various prediction tasks through the use of diverse data modalities. Compared with previous efforts, our proposed dataset focuses on the entire EDA workflow. It provides complete files for each case and necessary design kits, such as timing constraints, library files, and LEF files, offering a comprehensive dataset that supports all stages of design and fosters a more integrated approach to chip design and evaluation.\nPlacement Algorithms Recent advancements in AI technology within the EDA field have led to a variety of AI-based chip placement algorithms. (1) Black-Box Optimization methods. Simulated Annealing (Cheng et al., 2023) provides a probabilistic method for finding a good approximation of the global optimum. Wire-Mask-Guided Black-Box Optimization (Shi et al., 2023) uses a wire-mask-guided greedy procedure to optimize macro placement efficiently. (2) Analytical methods. DREAMPlace (Lin et al., 2019) uses deep learning toolkits to achieve over a 30x speedup in placement tasks. AutoDMP (Agnesina et al., 2023) leverages DREAMPlace for the concurrent placement of macros and standard cells, enhancing macro placement quality. (3) Reinforcement Learning methods. MaskPlace (Lai et al., 2022) treats chip placement as a visual representation learning problem, reducing wirelength and ensuring zero overlaps. ChiPFormer (Lai et al., 2023) employs offline reinforcement learning, fine-tuning on unseen chips for better efficiency. The evaluation of these algorithms mainly focuses on intermediate metrics. In contrast, we utilized the end-to-end performance to evaluate six existing AI-based chip placement algorithms, encompassing a significant portion of mainstream AI-based placement algorithms."}, {"title": "3 BACKGROUND ON ELECTRONIC DESIGN AUTOMATION", "content": "Electronic Design Automation (EDA) is a suite of software tools vital for designing and developing electronic systems, primarily integrated circuits (ICs). These tools enable electrical engineers to efficiently transform innovative concepts into functional products, addressing the increasing complexity and demands of modern chip design. EDA optimizes the entire design process from schematic cap-"}, {"title": "Chip Placement", "content": "The placement stage is crucially divided into two distinct phases: macro placement and cell placement. (1) Macro placement is a critical very large-scale integration (VLSI) physical design problem that targets the arrangement of larger components, such as SRAMs and clock generators often called macros. This phase significantly impacts the chip's overall floorplan and essential design parameters like wirelength, power, and area. (2) Following this, the standard cell placement phase addresses the arrangement of the more numerous and smaller standard cells, which serve as the fundamental building blocks of digital designs. This phase typically utilizes analytical solvers to secure an optimized configuration that not only minimizes wirelength but also enhances the electrical performance of the chip."}, {"title": "4 DATASET", "content": ""}, {"title": "4.1 DESCRIPTION OF DESIGNS", "content": "Due to the oversimplification of datasets in early years, there exists a significant gap between these datasets and real-world applications. For instance, the usually used Bookshelf format (Nam et al., 2005; Adya et al., 2009) is overly simplified so that placement results given in such format are inapplicable for the subsequent stages to obtain a valid final design. Some later datasets (Kim et al., 2015) provide the LEF/DEF and necessary files for running these stages, but the contained circuits are still limited and they still lack some information for open-source tools like OpenROAD to work. For instance, the library file lacks buffer definitions, which is necessary for the clock tree synthesis phase, and the LEF file has incomplete layer definitions, which hinders the routing phase. To address this issue, we construct a dataset with comprehensive physical implementation information across the entire flow. Our dataset involves collecting a series of designs spanning various domains, including components such as CPUs, GPUs, network interfaces, image processing technologies, IoT devices, cryptographic units, and microcontrollers. Additionally, the dataset features a diverse array of sizes, with cell ranges from thousands to nearly a million. The statistics for each case is detailed in Table 1, and we defer more details to Table 4 in Appendix C."}, {"title": "4.2 DATASET GENERATION PIPELINE", "content": "We use OpenROAD (Kahng & Spyrou, 2021), an open-source EDA tool, for generating our dataset. OpenROAD integrates various tools, such as Yosys (Wolf, 2016) for logic synthesis, TritonMacroPlacer for macro placement, RePlAce (Cheng et al., 2018) for cell placement, TritonCTS for clock tree synthesis, and TritonRoute for detailed routing. The choice of open-source tool allows for full reproducibility of our results and supports the promotion of the open-source community, ensuring that all generated data and methodologies are open-source. The initial dataset generation starts with Verilog files as raw data. OpenROAD performs logical synthesis to convert these high-level descriptions into a netlist, detailing the electrical connections among circuit components. This netlist is then used by OpenROAD's integrated floorplanning tool to configure the physical layout of the circuit on silicon. The resulting design from the floorplanning stage is converted into LEF/DEF files by OpenROAD, facilitating the application of subsequent placement algorithms. Simultaneously, we complete the EDA design flow through OpenROAD, generating data at subsequent stages, including placement, CTS, and routing."}, {"title": "5 ALGORITHMS", "content": "AI-based chip placement algorithms can be roughly grouped into three categories: black-box optimization (BBO) methods, analytical methods (gradient-based methods), and reinforcement learning (RL) methods. Each category frames the placement task as an optimization problem but adopts distinct objectives and methodologies. We present details as follows."}, {"title": "5.1 BLACK-BOX-OPTIMIZATION (BBO) METHODS", "content": "A straightforward intuition is to view the chip placement task as a black-box-optimization (BBO) problem, where the inner workings of the objective functions are inaccessible, and solutions are evaluated only based on the output metrics.\nSimulated Annealing (SA) is a heuristic BBO optimization algorithm favored for its simplicity in implementation. Specifically, the SA algorithm generates solutions by perturbing the solution space and then assessing the resulting representation. Different methods have been developed to effectively map representations to placement solutions (Kirkpatrick et al., 1983; Sherwani, 2012; Ho et al., 2004; Shunmugathammal et al., 2020; Vashisht et al., 2020), such as sequence pair (Murata et al., 1996) and B*-tree (Chang et al., 2000). Solutions are probabilistically accepted based on an annealing temperature to escape local optima in pursuit of a global optimum. Due to its simplicity in implementation, the SA algorithm often serves as a strong baseline in previous studies. In this work, we incorporate a specific SA implementation (Cheng et al., 2023) utilizing operations like swaps, shifts, and shuffles, and a cost function that balances wirelength, density, and congestion.\nWireMask-EA (Shi et al., 2023) is a BBO framework recently appearing on the AI conference NeurIPS'2023. It leverages wiremask to greedily guide the mapping from genotypes to phenotypes. Here the concept of wiremask was first proposed by Lai et al. (2022), and it is a matrix representing the potential increases in HPWL when placing the next macro on the canvas. Building on this, Shi"}, {"title": "5.2 ANALYTICAL (GRADIENT-BASED) METHODS", "content": "Analytical methods formulate the optimization objective as an analytical function of module co-ordinates. This formulation enables efficient solutions through techniques like quadratic programming (Kahng et al., 2005; Viswanathan et al., 2007a;b; Spindler et al., 2008; Chen et al., 2008; Kim et al., 2012; Kim & Markov, 2012) and direct gradient descent (Lu et al., 2014; Cheng et al., 2018; Lin et al., 2019; 2020; Gu et al., 2020; Liao et al., 2022). This work focuses on the gradient-based algorithms, which are by far the more mainstream algorithms.\nDREAMPlace (Liao et al., 2022) is a GPU-accelerated framework that leverages differentiable proxies, such as approximate HPWL, as optimization objectives. It was built upon the previous analytical placement algorithms, ePlace (Lu et al., 2014) and RePlAce (Cheng et al., 2018), yet significantly speeding up the placement process by using GPUs for acceleration. The series of versions of DREAMPlace introduces diverse differentiable proxies to better align the PPA improvement.\nAutoDMP (Agnesina et al., 2023) extends DREAMPlace by automating hyperparameter tuning through multi-objective Bayesian optimization. It further speeds up the optimization process and reduces the heavy manual tuning efforts. At that time, this work showcased the promising potential of integrating GPU-accelerated algorithms with machine learning techniques for the automation of VLSI design."}, {"title": "5.3 REINFORCEMENT LEARNING (RL) METHODS", "content": "As VLSI systems grow in complexity, RL methods are being explored to enhance placement quality. GraphPlace (Mirhoseini et al., 2021) first models macro placement as a RL problem. Subsequently, DeepPR (Cheng & Yan, 2021) and PRNet (Cheng et al., 2022) establish a streamlined pipeline encompassing macro placement, cell placement, and routing. However, they treat density as a soft constraint, which may violate non-overlap constraint during training. Therefore, in this work, we mainly focus on MaskPlace and ChiPFormer, which are recent SOTA algorithms with hard non-overlapping constraints.\nMaskPlace (Lai et al., 2022) represents the chip states as pixel-level visual inputs, including a wiremask (recording the HPWL increment for each grid), the viewmask (a global observation of the canvas), and the positionmask (to ensure non-overlapping constraint). Furthermore, it uses dense reward to boost the sample efficiency.\nChiPFormer (Lai et al., 2023) represents the first offline RL method. It is pretrained on various chips via offline RL and then fine-tuned on unseen chips for better efficiency. As a result, the time for placement is significantly reduced."}, {"title": "6 EVALUATION", "content": ""}, {"title": "6.1 EVALUATION METRICS", "content": ""}, {"title": "6.1.1 FINAL DESIGN PPA METRICS", "content": "The primary goal of the entire Electronic Design Automation (EDA) workflow is to optimize the final PPA metrics. PPA stands for performance, power, and area-three crucial dimensions used to evaluate the quality of a chip product. These dimensions are assessed using several critical metrics, including worst negative slack (WNS), total negative slack (TNS), number of violating paths (NVP), power, and area. Optimizing these PPA metrics has been a major focus in the industry, approached through expert-designed heuristics. However, the challenge of PPA optimization has not been fully recognized within the AI community. Bridging this gap and improving the incorporation of AI strategies into PPA optimization are key goals of this benchmark.\nIn terms of specific metrics, Worst Negative Slack (WNS) and Total Negative Slack (TNS) are essential for assessing the timing performance of a chip circuit. Slack is the discrepancy between the expected and required arrival times of a signal, with negative slack indicating a timing violation."}, {"title": "6.1.2 INTERMEDIATE METRICS", "content": "Commonly used intermediate surrogate metrics include Congestion, Wire Length (WL), Half Perimeter Wire Length (HPWL), and Macro HPWL (mHPWL). Congestion evaluates the density of wires in different chip regions. High congestion in certain areas can pose substantial challenges during the routing stage. While not a direct component of the PPA metrics, managing congestion effectively is essential to ensure that the chip can be successfully manufactured. Therefore, it is also considered as an evaluation metric in this paper. Congestion is typically estimated after the Clock Tree Synthesis (CTS) stages but before the detailed routing stage, allowing for adjusting macro placement and routing strategies to mitigate potential issues.\nWire Length (WL) is the total length of all wires connecting all modules in a chip. Half Perimeter Wire Length (HPWL) is the sum of half perimeters of bounding boxes that encompass all pins in each net. It is widely used as an estimation of WL and is obtained after cell placement. Macro HPWL (mHPWL) further simplifies HPWL by only considering the macros. It is favored in recent studies as it can be immediately obtained after macro placement. These metrics are thought to correlate with the final PPA, but they do not directly reflect the chip quality."}, {"title": "6.2 END-TO-END EVALUATION WORKFLOW", "content": "We present an end-to-end evaluation workflow utilizing OpenROAD-flow-scripts (Kahng & Spyrou, 2021) for the various stages of the EDA design flow, as illustrated in Figure 2. All tools used in this workflow are open-source, providing a significant advantage over other workflows that rely on commercial software. This workflow is designed to offer a comprehensive assessment of optimization algorithms at any stage of the design flow.\nOur dataset comprises design kits needed for each stage of the physical design flow. For evaluating any stage-specific algorithm, the output file from the preceding stage serves as the input for the algorithm under evaluation. The algorithm processes this input to generate its output, which is subsequently plugged into the Open-ROAD design flow. Ultimately, final performance metrics such as TNS, WNS, Area, and Power are reported, providing a comprehensive end-to-end performance assessment. This method offers a holistic set of metrics that can evaluate the optimization effects of any stage-specific algorithm on the final chip design, providing consistency of metrics and avoiding the limitations of overly simplified metrics confined to a single stage.It is particularly beneficial for the optimization and development of various algorithms, ensuring their improvements translate to practical enhancements in chip design and foster the development of more efficient and effective open-source EDA tools through a robust framework for testing and improvement."}, {"title": "6.3 EXPERIMENTAL SETUP", "content": "We apply the aforementioned workflow to evaluate six macro placement algorithms: SA, WireMask-EA, MaskPlace, ChiPFormer, and the default algorithm in OpenROAD. As most of these methods only support the circuit data in a BookShelf format, while the circuits in our used dataset are in a standard LEF/DEF, we start by converting the LEF/DEF files from the floorplan stage of our dataset to BookShelf format to serve as the input for the placement algorithms. After finishing the macro placement stage, we use DREAMPlace to finish the placement of the standard cells. In this stage it conduct two different operations, coarse placement and legalization, with the coarse placement splitting the cells simultaneously using gradient descent algorithms and the legalization stage correct"}, {"title": "7 RESULTS AND DISCUSSIONS", "content": ""}, {"title": "7.1 MAIN RESULTS", "content": "We evaluate the AI-based chip placement algorithms, including SA, WireMask-EA, DREAMPlace, AutoDMP, MaskPlace, and ChiPFormer, using both intermediate metrics and end-to-end performance. The results for macro placement are in Table 2. ChiPFormer and WireMask-EA demonstrated a significant reduction in MacroHPWL compared to OpenROAD using TritonMacroPlacer. WireMask-EA achieved the best performance in terms of MacroHPWL. While these AI-based placement algorithms showed good performance on several intermediate metrics, they perform poorly in terms of the end-to-end metrics compared to OpenRoad, particularly in Power, TNS, and Area. This outcome revealed a significant gap between the originally optimized MacroHPWL intermediate metrics and the final design PPA.\nCell Placement As shown in Table 3, DREAMPlace achieved the best results in the intermediate metrics of HPWL, and performed well in terms of Power. However, OpenROAD achieved the best results in WNS, TNS, NVP, and area, further demonstrating the inconsistency between intermediate metrics and final PPA results."}, {"title": "7.2 CORRELATION ANALYSIS", "content": "In this section, we conduct compute and discuss the correlation between the core optimization indicator MacroHPWL, used in existing placement algorithms, and the final chip performance metrics such as WNS, TNS, and wirelength, obtained through the OpenROAD process.\nWe use the Pearson correlation coefficient (Cohen et al., 2009) to evaluate the strength of linear correlation between pairs of metrics. The formula for calculating the Pearson correlation coefficient takes the form of\n$$r=\\frac{\\sum (X_i - \\overline{X})(Y_i - \\overline{Y})}{\\sqrt{\\sum (X_i - \\overline{X})^2 \\sum (Y_i - \\overline{Y})^2}}$$\nwhere $X_i$ and $Y_i$ are the observations, and $\\overline{X}$ and $\\overline{Y}$ are the respective means.\nThe results are shown in Figure 3. To calculate the correlation, the signs of all values are adjusted so that for all metrics the lower indicates the better. The results show that MacroHPWL only has a weak correlation with the Wirelength, which indicates that existing algorithms that optimize MacroHPWL do not lead to an optimization on the Wirelength. In contrast, HPWL shows a very strong positive correlation with actual Wirelength, indicating that HPWL works as an effective surrogate for approximating the Wirelength.\nIn addition to Wirelength, the final PPA metrics of the chip are associated with WNS/TNS, congestion, area, and power. The analyses shows that the correlation between MacroHPWL and these metrics is weak, indicating that optimization of MacroHPWL has minimal impact on these performance indicators. Moreover, the results in Figure 4 show that Wirelength exhibits weak correlations with WNS and TNS as well. This implies that even if a single-point algorithm successfully optimizes metrics such as Wirelength, the ultimate physical implementation might only enhance one aspect of the PPA metrics and may not effectively optimize the other dimensions. Therefore, more appropriate intermediate metrics are needed to better correlate with the actual PPA objectives."}, {"title": "7.3 DISCUSSION", "content": "Our benchmark comprises design kits essential for each stage of the physical design flow, including netlists, libraries, rules, and constraints needed during the physical implementation stage. This thorough inclusion allows for a convenient and detailed evaluation of algorithms at any specific stage of the physical design flow, enabling researchers and practitioners to test and compare the effectiveness of their solutions in a realistic, end-to-end environment. We call on the AI researchers to pay more attention on the \"shift-left\u201d challenge from the real-world industrial scenarios, keeping towards the mission of bridging the huge gap between academic research and industrial applications."}, {"title": "8 CONCLUSION", "content": "This paper presents a comprehensive dataset that spans the entire spectrum of the EDA design process and an end-to-end evaluation method, which we used to assess several placement algorithms: DREAMPlace, AutoDMP, MaskPlace, ChipFormer, Wiremask-EA, and SA. Our evaluation revealed inconsistencies between the metrics currently emphasized by mainstream placement algorithms and the final performance outcomes. These findings highlight the need for a new perspective in the development of placement algorithms."}, {"title": "A TECHNICAL DETAILS", "content": ""}, {"title": "A.1 EXPERIMENTAL DETAILS", "content": "In our workflow, it starts with OpenROAD. The file format for physical design in OpenROAD is OpenDB database (.odb), which contains LEF/DEF information. OpenROAD can be used to convert ODB to LEF/DEF, or LEF/DEF to ODB. Initially, the ODB after macro placement in the OpenROAD flow is converted to LEF/DEF files, serving as inputs for other macro placement algorithms. Since most existing macro placement algorithms only support bookshelf format input, DREAMPlace's code is used to convert LEF/DEF to bookshelf (.nodes, .pl, .nets) format. It is important to note that when DREAMPlace reads the DEF file, it treats the blockages in the BLOCK-AGES part as virtual macros, so when using DREAMPlace's PlaceDB in Python to read macro information, the virtual macros must be excluded.\nFor ChiPFormer, use the default model and perform 100 online iterations to fine-tune the macro layout.For MaskPlace, run 3000 epochs. Other settings use the defaults.\nIn the method of ChipFormer and MaskPlace, the experiments were run on an NVIDIA GeForce RTX 2080 Ti, taking one day for all cases. For the other algorithms, we used 32 CPUs (Intel(R) Xeon(R) CPU E5-2667 v4 @ 3.20GHz), with a total time expenditure of two days.\nNext, the macro layout (.pl) files are obtained after running ChiPFormer, MaskPlace, WireMask-EA, and SA, and then DREAMPlace is used to write the macro layout into DEF files. Since DREAM-Place does not modify the blockages in the DEF file, if blockages are defined in the DEF file, additional script modifications may be required.\nAfter obtaining the macro-placed DEF files, they are converted to ODB using OpenROAD, followed by Tapcell and Welltie insertion, PDN generation, IO place, global place, detail place, and subsequent CTS and routing.\nThe performance of OpenROAD is limited; in the future, other global placement tools and detailed placement tools can be used to run the entire workflow."}, {"title": "A.2 ENCOUNTERED ERRORS", "content": "Due to certain parsing bugs in OpenROAD, when converting DEF files to ODB files, it is necessary to ensure that no object names in the DEF file contain \"/\", otherwise, there will be issues during timing tests (issues will occur when writing and reading SPEF file).\nSince various algorithms are academic and cannot directly set the minimum spacing between macros (which can be set in OpenROAD), the optimization of macro positions by these algorithms may result in macros being placed too closely. When integrating back into OpenROAD, the following errors might occur:\nOpenROAD's limited capabilities in various stages also contribute to these errors. During PDN, \u201cUnable to repair all channels.\u201d might be encountered. During the global place stage, global placement might diverge. During the detail place stage, detailed placement might fail (because the surrounding space of certain cells makes it impossible for OpenROAD to find space for adjustments).\nThe code of ChiPFormer has certain issues and needs modifications to be applied to other cases. DREAMPlace directly uses the mix-size method with LEF/DEF for running macros.\nFor the ICCAD 2015 dataset, it includes the lib file, LEF/DEF files, netlist file, and sdc file. However, the lib file lacks buffer definitions, preventing CTS. The lef files have incomplete layer definitions, hindering routing.Additionaly, OpenRoad does not support the syntax of the ICCAD 2015 sdc file."}, {"title": "B LIMITATION", "content": "Our dataset currently has limitations in terms of data volume. In the future, we aim to increase the dataset's size and include more cases from various domains. This will enhance its generalizability and robustness, making it a more comprehensive and valuable resource for researchers . By ex-"}, {"title": "C MORE RESULTS", "content": "The detailed descriptions of each design are in Table 4. All the raw data from the experiment are in Tables 5-22. Methods or designs not shown in the table failed to complete the entire process due to the errors discussed earlier."}]}