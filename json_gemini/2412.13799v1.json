{"title": "Enhancing Rhetorical Figure Annotation: An Ontology-Based Web Application with RAG Integration", "authors": ["Ramona K\u00fchn", "Jelena Mitrovi\u0107", "Michael Granitzer"], "abstract": "Rhetorical figures play an important role in our communication. They are used to convey subtle, implicit meaning, or to emphasize statements. We notice them in hate speech, fake news, and propaganda. By improving the systems for computational detection of rhetorical figures, we can also improve tasks such as hate speech and fake news detection, sentiment analysis, opinion mining, or argument mining. Unfortunately, there is a lack of annotated data, as well as qualified annotators that would help us build large corpora to train machine learning models for the detection of rhetorical figures. The situation is particularly difficult in languages other than English, and for rhetorical figures other than metaphor, sarcasm, and irony. To overcome this issue, we develop a web application called \"Find your Figure\" that facilitates the identification and annotation of German rhetorical figures. The application is based on the German Rhetorical ontology GRhOOT which we have specially adapted for this purpose. In addition, we improve the user experience with Retrieval Augmented Generation (RAG). In this paper, we present the restructuring of the ontology, the development of the web application, and the built-in RAG pipeline. We also identify the optimal RAG settings for our application. Our approach is one of the first to practically use rhetorical ontologies in combination with RAG and shows promising results.", "sections": [{"title": "1 Introduction", "content": "The consideration of rhetorical figures from a computational perspective is important, as they can convey subtle, implicit meanings (e.g., metaphors), make texts more memorable, or add emphasis to the message (e.g., through the repetition of words). Their detection in text regularly leads to improved performance of various NLP applications, such as hate speech (Lemmens et al., 2021) or fake news detection (Dwivedi and Wankhade, 2021; Fang et al., 2019; Rubin et al., 2016; Troiano et al., 2018), sentiment analysis (Ranganath et al., 2018), or persuasive communication in general (Anzilotti, 1982; Gass and Seiter, 2022; Ranganath et al., 2018).\nUnfortunately, most computational approaches for the detection of rhetorical figures struggle with lower performance than they could actually achieve, e.g., Bhattasali et al. (2015); Dubremetz and Nivre (2015); Zhu et al. (2022). K\u00fchn and Mitrovi\u0107 (2024a) identify the major challenges for researchers in this domain and point out why their approaches often suffer from lower performance. One of the main reasons is the lack of data or unbalanced datasets. In these datasets, the number of instances without rhetorical figures is higher than those containing them, as shown in Adewumi et al. (2021); Bhattasali et al. (2015); Dubremetz and Nivre (2017); K\u00fchn et al. (2023); K\u00fchn et al. (2024b); Ranganath et al. (2018).\nAnother major problem is that most detection approaches focus on English. This means that (annotated) data in other languages are even scarcer. In addition, annotators qualified in this research field are not easy to find, and the quality of their annotations varies greatly due to the ambiguous nature of rhetorical figures (Strommer, 2011; Gavidia et al., 2022).\nWe overcome those two major challenges in the domain of rhetorical figure detection by developing an interactive web application for the collection of rhetorical figures in German. Users without linguistic knowledge are guided through an interactive process in which they can determine the name of a rhetorical figure in a text and annotate it. In addition to the guided input, we offer a chat-like feature, so users can interact with a large language model (LLM). The LLM obtains domain-specific knowledge about rhetorical figures through retrieval augmented generation (RAG) (Lewis et al., 2020). Although current LLMs are powerful, they often struggle even in English with generating and"}, {"title": "2 Related Work", "content": "The scarcity of annotated data and the high imbalance between classes with or without rhetorical figures is a well-known issue in the domain of computational detection of rhetorical figures (Dubremetz and Nivre, 2015; Bhattasali et al., 2015; Dubremetz and Nivre, 2017; Ranganath et al., 2018; Adewumi et al., 2021; K\u00fchn et al., 2023; K\u00fchn and Mitrovi\u0107, 2024a). Unfortunately, efforts to overcome the problem are limited. Chakrabarty et al. (2022) use OpenAI's gpt-3 to generate text containing a rhetorical figure, but their method still requires three human annotators to oversee the output. Additionally, annotations of rhetorical figures often have a high variability, because annotators cannot agree on the existence of a figure in particular cases (Strommer, 2011; Dubremetz and Nivre, 2015; Troiano et al., 2018). This problem can be directly linked to the lack of consensus and multiple varying definitions, inconsistent names, and spellings of rhetorical figures, which is a well-known problem (Harris et al., 2018; Gavidia et al., 2022; K\u00fchn and Mitrovi\u0107, 2024b)."}, {"title": "3 Reification of the GRhOOT ontology", "content": "The German GRhOOT ontology was developed by (K\u00fchn et al., 2022). It contains the formal description of 110 common German rhetorical figures. Each figure is specified based on the way it is constructed. The figure epiphora shall serve as an example here. In an epiphora, the last word of each sentence is repeated at the end of the next sentence. In the ontology, these properties are expressed by the relations\n: Epiphora :isInPosition : Beginning\n: Epiphora : isInArea : Sentence\n: Epiphora :isRepeatableElementOfSameForm : Word\nRhetorical figures in the ontology also contain relations to express a textual definition, example sentences, and names of the figure in other languages. An example of the complete formal model of epiphora is shown in Fig. 6 in the Appendix in Section A. While building the web application and specifying user needs, we identify opportunities for further enhancement, particularly in simplifying the relations within the ontology. For this reason, we create an adapted version of the GRhOOT ontology. The main changes are the reification of relations and a more fine-grained description of definitions, authors, example sentences, and their sources. In addition, we model rhetorical figures as classes instead of individuals. Reification involves breaking down properties and relationships into more fine-grained components while offering a more detailed and flexible representation of the ontology. Although this approach increases complexity (Stevens and Lord, 2010), it allows for more precise querying and filtering of attributes. Consider for example the construction relationship\n:isRepeatableElementOfSameForm :Word\nWhen a user wants to list all figures that contain a repetition of a word, it would be a cumbersome operation to filter the relation names for the isRepeatable substring. We want to make the search more intuitive by breaking compound relations into smaller, fine-grained ones. For example, we split the repetition relation into three relations (RF denotes Rhetorical Figure):\n: RF : hasOperation : Repetition\n: RF : affectedElement : Word\n: RF : operationalForm : SameForm\nA comparison between old and new relations is shown in Table 1 in Example (a). There were several relations of this form that we adapted accordingly.\nThis change allows users of the web application to generally filter for figures with the same operations, the same affected elements, or the same operational forms. Reification often makes relations more implicit, requiring an understanding of which relations belong together. However, users are guided through our web interface, so we do not see any drawbacks.\nMoreover, we adapt the ontology to reflect the hierarchical structure of rhetorical figures. In the original GRhOOT, rhetorical figures are modeled as individuals, similar to the Serbian RetFig ontology (Mladenovi\u0107 and Mitrovi\u0107, 2013). However, the English RhetFig (Kelly et al., 2010) and the English Ploke ontology (Wang et al., 2021) model figures as classes. We also decided to convert the rhetorical figures from individuals to classes to better align with established hierarchies in rhetorical theory (Harris and Di Marco, 2017; O'Reilly et al., 2018). This adjustment is particularly useful in annotation tasks, where it is important to recognize that one figure may be a more specific form of another figure, and both annotations can be valid. For example, the figure antimetabole is a more specific form of the figure chiasmus and can therefore be modeled as a subclass of chiasmus.\nAnother major change is the adaption of textual definitions and example sentences that are no longer modeled as property relations. We convert"}, {"title": "4 Ontology-Based Web Application for Rhetorical Figure Annotation", "content": "Our overall goal is to improve the computational detection of rhetorical figures by collecting more annotated instances of rhetorical figures. We demonstrated the important role of rhetorical figures and how their detection can improve many NLP systems in Section 1. The interaction with the ontology through the web application is as natural and intuitive as possible without the need for linguistic knowledge or knowledge about ontological details. When users encounter a sentence in which they suspect a rhetorical figure, they can use our web application to determine its name and function. The application is based on the Python Flask\u00b2 framework and uses an SQLite 3 database. The Flask framework is suited for lightweight web applications such as ours.\n4.1 Pages of the Web Application\nThe application encompasses the following five pages.\n\u2022 create.html: On this page, users have the possibility to enter a sentence with a rhetorical figure without annotating it. Users submit a text or sentences, context (e.g., preceding sentences, description of the situation), author, and source of the text. The example is stored\nin the database for later annotation by other users who do not have an own example but choose a random one from the database.\n\u2022 FyF.html: This is the main page of our \"Find your Figure\" application. It is shown in Fig. 3. Users choose to submit their text/sentence or choose a random one from the database previously submitted by users on the create.html page. The option to enter an own text also includes specifying context, author, and source. The users then select the properties of the text from a dropdown list that best describes the pattern in the submitted text. Properties are extracted relations from the ontology, such as operation (e.g., repetition), affected element (e.g., word). Users always have the possibility to choose No idea (Keines davon/Wei\u00df nicht) if they are not sure about the property. After the users submit the information, the properties are translated into a SPARQL query in the backend and executed on the ontology. If matching figures are found, they are presented along with a definition and examples of the figure in the frontend. The users can choose one or more figures they consider appropriate as shown in Fig. 4. The text, context, author, source, and annotated figure are then written to the SQLite database. The database scheme is shown in Fig. 2.\n\u2022 1lm.html: As the annotation process in FyF.html still requires basic knowledge of linguistic concepts, we integrate a chatbot-like feature for a more natural interaction between users and ontology. Users simply submit the example text they want to annotate and describe its properties to the LLM. It offers a field for text, context, author, and source, or the possibility to load an example from the database. Instead of the drop-down list, a text field is presented for the LLM prompt. The answers are generated by the LLM with RAG extended context. The different setups to find the best RAG parameters are described in Section 5.\n\u2022 figure_info.html: This page provides an informative overview of rhetorical figures. Users can select the name of a rhetorical figure from a dropdown list. The application then presents definitions of the figure and example sentences. As the elements of the list and"}, {"title": "4.2 Verification of User Input", "content": "We need to verify that\n1. users do not violate intellectual property rights when uploading examples,\n2. the submitted text is valid and not \"gibberish\",\n3. the assigned rhetorical figures is correct,\n4. the submitted text is not harmful or violating, especially when presented to other people for annotation.\nIt is important to verify that no intellectual property rights are infringed, especially when we later train models on the obtained data. Researchers are aware of those challenges regarding intellectual property rights when training LLMs with large amounts of text (Smits and Borghuis, 2022). However, identifying unauthorized material or a violation of intellectual property is \u201cnotoriously difficult to prove\" (Chesterman, 2024). To overcome the first challenge (1.), users must indicate at least an author or source of their submitted text. In addition, we raise awareness of the problem by displaying an informational text next to the author and source fields in the create.html and FyF.html pages. The LLM we are using in the 11m.html page is used in a generative way, but we prompt it with information from the ontology in a RAG setting to ensure that it is more likely to only present examples from the ontology. Another possibility to make potential copyright infringements tractable is user authentication via login. However, this would increase the threshold to use the app, especially for younger users, e.g., school children.\nFurthermore, we want to verify that users only submit valid text which is then written to the database (2.). We cannot rely (solely) on common grammar or spell checks, as odd grammatical constructs or omitted letters can be a feature of rhetorical figures. We use a combination of a language detector (langdetect) to identify if the submitted example is German, a measure of the text length (10 < text_length < 1000, and a grammar checker that supports German (language-tool-python\u2074). If one of those three checks fails, we ask gpt-3.5-turbo to evaluate if the text is \"gibberish\". If the answer is positive, we show a notification to the users if they really want to submit the example, making them aware of potential problems. If they submit the example anyhow, we will flag the example in the database in the column is_invalid, such that an administrator can later check the validity.\nEnsuring that the rhetorical figures assigned by the users are correct (3.) is a highly challenging"}, {"title": "5 RAG Integration: Parameter Testing and Evaluation", "content": "RAG uses an external knowledge source to enhance the context of an LLM. LLMs still struggle to generate rhetorical figures as we showed in Fig. 1. Another challenge in this domain are the many different and varying definitions of rhetorical figures. Though, we want the integrated LLM to respond to the web application users with the specific definitions we use in our ontology to ensure consistent annotation guidelines.\nFig. 5 illustrates the RAG pipeline with its individual steps. It also shows the different parameters used in our experiment to determine the optimal settings for the web application. The input is the reified GRhOOT ontology which is also the basis of the web application. After chunking and embedding the information (steps 1 and 2), it is stored in a vector store (step 3). When a user asks the system a question about rhetorical figures in step 4 (e.g., \"What is an alliteration?\u201d), the question is embedded and compared to the content in the vector store. The top-k relevant chunks are retrieved in step 5, often in combination with a reranker, and added as context to the query, e.g., actual examples of an alliteration. The LLM receives the context along with the original question. In step 6, the LLM answers the users' questions with a reduced probability of hallucinations and knowledge of the domain, which are rhetorical figures in our case.\nTo find the best setting, we experiment with different chunk sizes ([2048],[2048, 512, 128], and [512, 256, 128]). It is a known phenomenon called \"lost in the middle\" that content stored in the middle of a chunk is more difficult for the LLM to recall (Liu et al., 2024). Therefore, we test different sizes to avoid this problem. As chunking technique, we investigate basic chunking (i) and auto-merging retrieval chunking (ii) with the HierarchicalNodeParser by LlamaIndex. It is an advanced chunking technique, where a smaller chunk that contains relevant information is merged into the parent chunk and provided as context.\nWe use the multilingual model bge-m36 for the embeddings.\nUsually, the vectorized index is stored in a suitable vector database, which offers additional benefits, especially when working with multiple documents. However, as we only focus on a compact and relatively small ontology, we do not need a vector database. Instead, we store the index in a file. This approach reduces the number of variables that could affect the output, as we are not relying on optimization strategies of database vendors.\nFurthermore, we use a reranker (BAAI/bge-reranker-large) in all settings to improve the results. In setting (a), we first retrieve the top-12 chunks, while the reranker selects the top-6 chunks. In setting (3), we retrieve the top-6 chunks, while the reranker selects the top-3 chunks (\u03b2).\nWe are using OpenAI's gpt-3.5-turbo as LLM, as it shows good results in German. We set the temperature to 0.1 to obtain stable responses."}, {"title": "5.1 Evaluation Setup for the RAG pipeline", "content": "RAG evaluation still poses a challenge. We use the Ragas framework for evaluation. It requires a file of questions, answers generated by the LLM in the last step of the RAG pipeline, context information from the original document, and ground truth answers. Most approaches rely on LLM-generated ground truths that are then again evaluated by an LLM.\nOntologies in general and especially the GRhOOT ontology have a big advantage here. We can use ontological competency questions (CQ) (Gr\u00fcninger and Fox, 1995; Noy et al., 2001; Hristozova and Sterling, 2002; Allemang and Hendler, 2011) their respective answers extracted from the ontology to generate the ground truth file for the Ragas evaluation. Unfortunately, the GRhOOT ontology comes only with five CQs. However, Alharbi et al. (2023) and Ciroku et al. (2024) demonstrate that OpenAI gpt-4 can generate competency questions after the ontology has been created. Therefore, we also use gpt-4 to generate further CQs for the reified GRhOOT ontology. In contrast to Alharbi et al. (2023), we skip the triple extraction and provide only the formalization of one rhetorical figure as context to the LLM. The LLM is then able to formulate appropriate questions. Additionally, we create template questions asking for properties of rhetorical figures, i.e., \"What is <property> of the rhetorical figure <figure_name>\u201d, e.g., \u201cWhat is an example of the rhetorical figure anaphora?\". With those methods, we obtain 70 CQs. We formulate matching SPARQL queries to retrieve the answers from the ontology. The context is manually extracted from the ontology. From this information, we construct our ground truth file in the required format for the Ragas framework. The answers of the LLM still require post-processing before we can use them in the Ragas framework as the LLM tends to add additional quotation marks around figure names or examples but often does not close them. The post-processing step is only necessary for the evaluation. It is not required in the production mode of our web application.\nFor the evaluation, we use the pre-defined metrics from the Ragas framework. A detailed description can be found online, 8 but we describe them shortly here for clarification. We choose the following Ragas metrics:\n\u2022 Faithfulness: Describes the extent to which the answer is grounded in the context.\n\u2022 Context precision: Measures if relevant\""}, {"title": "5.2 Evaluation Results", "content": "In the first review of the answers, we notice that the LLM sometimes responds in English instead of German. For this reason, we add to the prompt the request to only answer in German (step 4 in Fig. 5): \"Bitte antworte nur auf Deutsch!\" (\"Please answer only in German!\").\nTable 2 shows the result for the different settings. Surprisingly, advanced chunking techniques do not increase the performance. As best setting, we identify basic chunking with a chunk size of 2048, where the top-12 chunks are selected first and then filtered for the top-6 by the reranker. Only the context precision is low in this setting. However, as we mentioned, we focus more on answer metrics. When reviewing the results, we notice deviations in answer correctness and answer similarity, even when the LLM's answer is correct and semantically similar to the ground truth. We identify the LLM's circumscription of the answer as the problem. For example, consider the following case:\nQuestion: \"What is the name of the figure where the first letter of each word sounds the same?\"\nGround truth: \"Alliteration\"\nLLM's answer (translated from German): \u201cThe name of the figure where the first letters of each word sounds the same is 'Alliteration\"\nThis answer leads to a reduced answer correctness and answer similarity because of the wordiness of the LLM's answer. However, we do not consider this as an issue since the answer is correct and users would probably prefer a complete sentence over a single-word-response.\nOther examples where the LLM is correct but creates reduced answer correctness and answer similarity are a different choice of words. For example, the LLM answers with this definition for a rhetorical figure\nLLM's answer: \"Eine Wiederholung des Anfangslautes benachbarter oder nah beieinander-stehender Worte in einem Satz oder Vers\"\nGround truth: \u201cGleichklingender Anlaut der betonten Silben innerhalb einer Wortgruppe\",\nwhere \"Gleichklingender Anlaut\" means the same as \"Wiederholung des Anfangslauts\". We assume that it is caused by the definitions in the ontology taken from dictionaries and books, while the LLM uses more \u201cmodern\" language and simpler expressions.\nWe see problems when the LLM is asked to answer questions that require aggregation of information (e.g., \"What are the linguistic groups defined in the ontology?\u201d\u201d), which requires reasoning over multiple chunks. This finding is in line with the experience of Alharbi et al. (2023) that LLMs generally tend to fail in such tasks. Unfortunately, RAG can do little to change this. Nevertheless, the high values of the metrics show the efficiency of RAG on ontologies. Even without special adaptions to the ontological structure, we achieve satisfying results.\""}, {"title": "6 Conclusion", "content": "The development of the web application to collect rhetorical figures is an important step to overcome the scarcity of annotated data in the field of the computational detection of rhetorical figures, especially in German. The web application allows users to specify the properties of a text and assists them to name and annotate the rhetorical figure hidden in it. Furthermore, the web application serves as an information collection about rhetorical figures, where users can learn the definitions and see examples. The web application, which is built on top of the GRhOOT ontology, is one of the first approaches to practically use a rhetorical figure ontology for figure annotation. It also contains verification functions for the user input. The integrated RAG pipeline allows users to use an LLM-powered chat for the interaction with the GRhOOT ontology. One of our main objectives for the future is to publish the web application and promote it to potential users. We can then evaluate the features of the application that are most beneficial to users and learn about their behavior, for example, if they prefer the chat function with the integrated RAG model or the structured drop-down fields.\nIn addition, we will observe the performance of the RAG pipeline. When we collect more examples from users through the web application, it is possible to add them to the ontology and update the vector store to improve the performance of the RAG pipeline. We also envision gamification elements and user sessions to store their achievements to keep them engaged. In addition, we will extend our verification methods for the user input. We also plan to show retrieved chunks to the users so they can compare the information from the ontology with the LLM's answer.\nNevertheless, the current version that combines annotation capabilities and educational resources makes our application a valuable tool in the domain of computational detection of rhetorical figures, as well as a possible interactive resource in education."}, {"title": "7 Limitations", "content": "Our web application for identifying rhetorical figures has some limitations. It is better suited to identify figures with obvious rhetorical features, e.g., figures with repeating elements, than for figures relying on transferred meanings, such as metaphors. However, we see this rather as a limitation on the side of the users. For most persons without linguistic knowledge of rhetorical figures, it is easier to spot and describe obvious lexical patterns than figures with implicit, transferred meaning. Additionally, this app represents only the initial implementation of our envisioned tool. There are many possible features that can be implemented, enhanced, and improved in the future."}, {"title": "8 Ethical Considerations", "content": "Regarding the web application, the main concern is the violation of intellectual property rights. Users may submit text from sources they do not have the right to use. Furthermore, the text is then stored in the database and used to train models, even if the original authors did not agree on the distribution of their text. This is not an easy task to solve both from a computational and legal perspective. However, we established methods to encourage users to indicate an author or source of the examples.\nRegarding the RAG pipeline, users should be aware that the LLM may produce incorrect answers. We hope to support the users in assessing the truth with our web application, as they can browse the figures to learn about them and with the planned feature to show the retrieved chunks along with the answer of the LLM. This way, users can get a clearer picture if the LLM's answer is correct.\nIn conclusion, while RAG on rhetorical ontologies holds significant potential for advancing NLP, addressing these ethical concerns is important to ensure their responsible and fair application."}]}