{"title": "Retrieval Augmented Generation Based LLM Evaluation For Protocol State Machine Inference With Chain-of-Thought Reasoning", "authors": ["Youssef Maklad", "Fares Wael", "Wael Elsersy", "Ali Hamdi"], "abstract": "This paper presents a novel approach to evaluate the efficiency of a RAG- based agentic Large Language Model (LLM) architecture in network packet seed generation for network protocol fuzzing. Enhanced by chain-of-thought (COT) prompting techniques, the proposed approach focuses on the improvement of the seeds' structural quality in order to guide protocol fuzzing frameworks through a wide exploration of the protocol state space. Our method leverages RAG and text embeddings in a two-stages. In the first stage, the agent dynamically refers to the Request For Comments (RFC) documents knowledge base for answering queries regarding the protocol Finite State Machine (FSM), then it iteratively reasons through the retrieved knowledge, for output refinement and proper seed placement. In the second stage, we evaluate the response structure quality of the agent's output, based on metrics as BLEU, ROUGE, and Word Error Rate (WER) by comparing the generated packets against the ground truth packets. Our experiments demonstrate significant improvements of up to 18.19%, 14.81%, and 23.45% in BLEU, ROUGE, and WER, respectively, over baseline models. These results confirm the potential of such approach, improving LLM-based protocol fuzzing frameworks for the identification of hidden vulnerabilities.", "sections": [{"title": "1 Introduction", "content": "Network protocols are the foundation of modern communication systems, enabling the exchange of data between devices, applications, and services. As the protocols increase in complexity, ensuring their reliability and security is an issue of great concern. Finite State Machines (FSMs) of protocols describe protocols formally by defining valid states and transitions that rule message exchanges. FSMs are the subject of widespread application in different activities, from protocol verification and reverse engineering to security testing. In network protocol research, FSMs have been used to describe the state transitions of protocol entities by modeling the message exchange process of network protocols [1]. FSMs, which define the behavior and state transitions of the protocol, can make fuzz testing more focused and efficient to ensure all structural states and transitions of a server under test (SUT) are covered. Additionally, the seeds that are initially used for stateful fuzzing play a very important role in state space exploration. Because most network protocols are stateful, fuzzing is quite hard since the search space grows exponentially and selects an initial seed that will guide the fuzzer's exploration considerably [2].\nHowever, deriving FSMs manually is tedious, necessitating automated protocol analysis and reverse engineering. Protocol reverse engineering recovers specifications like message formats and FSMs from network traces, source code, or binaries. Dynamic analysis observes runtime behavior but suffers from limited coverage due to input diversity [3]. Static analysis offers higher precision but struggles with scalability in complex parsing loops [4]. So, despite progress, challenges remain in handling complex protocols and ambiguities. Recent advances in Large Language Models (LLMs) enable effective FSM extraction and protocol analysis by processing code and textual specifi- cations [5, 6], improving fuzzing and vulnerability detection [7, 8]. With accurate FSM extraction, LLMs can generate high-quality packets that follow the protocol's defined behaviors, which can significantly enrich the initial seed set for fuzz testing. This leads to a more targeted and effective exploration of the state space, enabling better cover- age. Integrating LLMs with existing Automatic Protocol Reverse Engineering (ARPE) techniques could address limitations in traditional FSM extraction approaches [9].\nWe propose a novel approach to protocol FSM extraction and inference by combin- ing RAG [10] with the ReAct framework [11]. Our approach utilizes a RAG pipeline to embed RFC documents in a vector store and performs dynamic domain-specific knowl- edge retrieval during inference. The RAG-ReAct agents reason and act iteratively over the retrieved context effectively using COT prompting techniques. This avoids expensive fine-tuning processes and enhances the output of the model in terms of accu- racy, coherence, and protocol compliance. Our framework applies the use of retrieved contextual knowledge to dynamically enrich protocol initial seeds and assures high- quality outputs. We apply this system to the Real-Time-Streaming protocol (RTSP), using the RFC 2326 document knowledge base showing its capabilities in inferring FSMs with high accuracy. Our framework extends the utility of RAG models beyond traditional natural language processing (NLP) tasks into structured reasoning, and domain-specific protocol analysis. Our system overview can be shown in Figure 1. The paper is organized as follows: Section 2 reviews related work, emphasizing key con- tributions in protocol FSM inference. Section 3 provides background information on"}, {"title": "2 Related Work", "content": "The work [12] proposed SeedMind, a framework that leverages LLMs to generate high-quality greybox fuzzing seeds. In the presence of challenges like heterogeneous input formats, bounded context windows, and unpredictable model behaviors, instead of producing test cases directly as in traditional methods, SeedMind synthesizes test case generators. It then iteratively improves such generators through a feedback- driven process, leading to increased code coverage due to significantly improved seed quality. Experiments were conducted on 166 programs and 674 harnessed from OSS- Fuzz and the MAGMA benchmark showing that on average, SeedMind outperforms SOTA LLM-based solutions such as OSSFuzz-AI and reaches up to 27.5% more cover- age, accounting for code coverage that is comparable to that obtained with manually crafted seeds. Another work proposes ChatFuzz [8], a greybox fuzzer enhanced with generative AI to address the challenge of generating format-conforming inputs for pro- grams that require highly structured data. They propose an approach to integrate LLMs to synthesize structured variants of the seed inputs. These variants are then assessed and added to the AFL++ greybox fuzzer [13], which improves its exploration capability into deeper program states. Their comprehensive evaluation on 12 target programs using three benchmarks exhibits, on average, an edge coverage improvement of 12.77% over AFL++. The results demonstrate that ChatFuzz performs much better on those programs which contain explicit syntax definitions and thus rely heavily on"}, {"title": "3 Background Problem Formulation", "content": "This section provides background information on protocol state machine extrac- tion techniques and LLMs. First, we discuss the advantages and disadvantages of the current existing approaches for FSM extraction. Then, we explore the capabilities of LLMs and some of their applications in different NLP tasks.\nThe protocol FSM describes defines how communication protocols like the RTSP protocol (from RFC 2326) operate 2, explaining essential element as states, inputs, and state transitions. For instance, for the RTSP protocol, the three states as INIT, READY, and PLAY mark a phase the session can be in. While events triggering state transitions are the messages exchanged between the client and the server as SETUP, PLAY, or PAUSE. Effective management of transitions is quite fundamental to any successful communication. Inferring protocol state machines for RTSP is complex and requires sophisticated techniques as static analysis [3], dynamic analysis [4], and nat- ural language processing (NLP) [15]. Static analysis extracts protocol details from source code, but face scalability issues. Dynamic analysis monitors runtime behavior with taint analysis and symbolic execution, but it suffers from poor coverage. While NLP methods mine RFCs, to infer transition relationships between RTSP states, but faces ambiguity issues when analyzing complex protocols.\nLLMs have revolutionized natural language understanding, with applications rang- ing from text generation to comprehension and reasoning. Models built upon the"}, {"title": "4 Methodology", "content": "To infer protocol state machines, we employed a novel RAG approach for the LLMs, enhanced by the ReAct framework [11], that use COT prompting techniques that facilitates logical reasoning, ensuring generated packet sequences adhered to both the syntactic structure and logical flow of the RTSP protocol. The RAG-ReAct agent dynamically retrieves and reasons over domain-specific knowledge embedded in a vec- tor store to answer questions related to initial seed enrichment for fuzzing. The RTSP protocol's RFC 2326 document served as the sole knowledge base. We employed a com- parative experiment between two models which are Gemma-2-9B model and Meta's Llama-3-8B model to carry out the best performing results. Below, we outline the twoO key steps of our methodology: RFC Document Preprocessing, and RAG-ReAct-Agent Inference."}, {"title": "4.1 RFC Document Preprocessing", "content": "Effective preprocessing of the RFC document was critical to ensure accurate knowledge representation and retrieval.\nLet $D = {d_1,d_2,...,d_v}$ represent the set of RFC documents. The preprocessing stage can be defined as a single function:\n$V = Preprocess(D)$ (1)\nThis phase involved two primary tasks: cleaning the document, and chunking it.\n$C(d_i) = Clean(d_i), \u2200i \u2208 {1, ...,N}$. (2)\nWe thoroughly cleaned the RFC document to reduce noise and increase the rele- vance of the information that was retrieved. Table headers, footers, introductions, and any other unnecessary sections that would cause noise to the RAG-ReAct agent had to"}, {"title": "4.2 RAG-ReAct-Agent Inference", "content": "We designed structured prompt templates 3 to guide the agents for accurate retrieval of FSM specifications and proper seed placement. These templates outlined the role of the agent and matched its actions with the protocol specifications. The \"Agent Task\" focused on enriching the initial client request sequences in accordance with the protocol's FSM. The \"Agent Goal\" guided the model in obtaining relevant FSM information from the RFC knowledge base. Clear formatting and content stan- dards were provided in the \"Expected Output\" section. This structured approach enabled the RAG-ReAct agent produce accurate and precise protocol-compliant packet sequences. During inference, the agent was asked questions about initial seed enrich- ment and placement of some new seeds in proper places, inspired by ChatAFL [7]. The retrieval mechanism retrieved the top-k relevant chunks by querying the vector store\nusing cosine similarity to provide context to direct the placement of packets, including the necessary headers and correct field types. This made sure the model had access to domain-specific data that was necessary for accurate reasoning and generation."}, {"title": "5 Experimental Design", "content": "To evaluate the agent responses, we performed an assessment using a log dataset of RTSP-based client-server interactions. We logged these interactions from running ChatAFL [7] on live555 server docker image for 2 hours of fuzzing. The total logs contained 5000 plus entries, simulating RTSP communication sequences, including requests and responses. We guarantee that in the pre-fuzzing phase we would find questioning between the fuzzer and the LLM regarding initial seed enrichment, where the fuzzer asks the LLM about combinations of enriched seeds. We use these typical logs to begin the evaluation process, which were typically 120 entries. Each query is processed by the evaluation pipeline, where the quality and accuracy of the generated outputs have been evaluated against ground truth packet sequences based on three core metrics:\n\u2022 BLEU score: measures the precision of generated packets by calculating the n-gram overlap with ground-truth sequences.\n\u2022 ROUGE score: measures the recall of n-grams of outputs compared to the ground- truth sequences.\n\u2022 Word Error Rate (WER): measures the edit distance between the generated and ground-truth sequences. Lower WER values indicated higher accuracy."}, {"title": "6 Experimental Results and Discussion", "content": "The performance of both the Gemma-2-9B and the Llama-3-8B models, indepen- dently as baseline models and as RAG-ReAct agents demonstrated a clear performance improvement by the RAG-ReAct agents. As shown in both Table 1 and Table 2, the RAG-ReAct agents consistently outperformed base models in different metrics demon- strating better accuracy, contextual relevance. For instance, the \"DESCRIBE\" request, the BLEU score of the Llama-3-8B improved substantially from 80.62% to 90.07%, along with a large reduction in WER from 16.99% to 8.71%. For for complex requests as \"SET_PARAMETER\" and \"ANNOUNCE\", the Llama-3-8B RAG-ReAct agent outperformed Gemma-2-9B RAG-ReAct agent. While Gemma-2-9B had slightly bet- ter averages in some metrics, Llama-3-8B did much better at complicated requests and hence was able to provide more accurate outputs with fewer mistakes. These results show how such RAG-based agentic frameworks work effectively to enhance contextual reasoning and precise output accuracy."}, {"title": "7 Conclusion", "content": "In conclusion, this work addresses the challenges involved in deriving accurate and comprehensive FSMs for complex stateful network protocols. Traditional approaches, such as dynamic and static analyses fall short. Recent development in LLMs and"}]}