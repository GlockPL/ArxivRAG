{"title": "Model and Deep learning based Dynamic Range\nCompression Inversion", "authors": ["Haoran Sun", "Dominique Fourer", "Hichem Maaref"], "abstract": "Dynamic Range Compression (DRC) is a popular audio effect used to control\nthe dynamic range of a signal. Inverting DRC can also help to restore the original\ndynamics to produce new mixes and/or to improve the overall quality of the audio\nsignal. Since, state-of-the-art DRC inversion techniques either ignore parameters\nor require precise parameters that are difficult to estimate, we fill the gap by com-\nbining a model-based approach with neural networks for DRC inversion. To this\nend, depending on the scenario, we use different neural networks to estimate DRC\nparameters. Then, a model-based inversion is completed to restore the original au-\ndio signal. Our experimental results show the effectiveness and robustness of the\nproposed method in comparison to several state-of-the-art methods, when applied\non two music datasets.", "sections": [{"title": "Introduction", "content": "Dynamic Range Compression (DRC) is a fundamental process in audio signal process-\ning which aims at changing the dynamic range of a signal. This technique is widely\nused in various stages of audio production, such as recording, mixing, and mastering,\nto control the loudness of an audio signal and prevent clipping or distortion [1]. How-\never, the application of DRC often leads to changes in the audio's timbre and perceived\nquality, making its inversion a challenging task. Thus, inverting DRC is full of interest\nin the context of audio reverse engineering [2] since it aims at recovering the original\ndynamic range and audio quality of a signal. This task could find many applications\nsuch as signal restoration, remixing, and enhancing creative control.\nInverting DRC is a challenging problem which often requires side information with\nan explicit DRC model and prior knowledge about the DRC parameters to be efficiently\nprocessed. There only exist a few studies which directly address the problem of DRC\ninversion. In [3], the authors consider DRC inversion as a rate-distortion optimization\nproblem using a coder-decoder framework which minimizes both the side-information\nand the reconstruction error when combined with a specific estimator applied to the\ncompressed signal. In [4], the authors propose a specific DRC model which provides\npromising reconstruction approximation but require to know exactly the DRC param-\neters of the compressed signal. Other work such as [5] only attempts to cancel or"}, {"title": "Methodology", "content": "Let x be a one-dimensional real-valued discrete-time signal obtained at sampling rate\nFs. We denote x[n], \u2200n \u2208 {0,1,\u2026\u2026, N \u2013 1} the n-th signal sample of the signal.\nNow, we consider g, the gain function of the DRC effect applied to x for obtaining\nthe compressed signal as:\n$y[n] = x[n] \u00b7 g_{x,q0}[N],$\n(1)\nThe value of g[n] depends on the signal x itself and the DRC parameters qe \u2208 R7,\nwhich is a set of parameters related to the compressor model 0 \u2208 {0, 1, ..., d \u2212 1} is the\nlabel of a DRC profile, with d the maximum number of considered profiles.\nHence, this paper addresses the problem of blindly computing the estimates qe\nand \u00ee, which are the more close as possible from qe and x (in the minimum mean-\nsquared error sense). We consider as unique observation, the compressed signal y and\nwe assume that the applied DRC effect can be approximated using the proposed generic\nDRC model for which the parameters q are unknown."}, {"title": "Dynamic Range Compression", "content": "The reversible DRC model proposed in [4] enables to consider a large variety of com-\npressor types (eg. expander, compressor, or noise gate, etc.) and uses the following set\nof parameters (cf. Table 1 for a description) qe\n{L, R, Tatt, rel, Tatt, Trel,\nTg\n1, p}, where\n\u2022 L: the threshold expressed in dB,"}, {"title": "DRC Inversion using Known Parameters", "content": "The model presented in Section 2.2 allows to estimate \u00ee from y when qe is exactly\nknown. The overall method can be summarized in Algorithm 1 where k=lS and S =\n1\u22121/R.\nIn [4], the author defined a CHARFZERO() function to estimate a zero-crossing\nvalues vo of the characteristic function based on the Newton-Raphson method, p(v) =\n$(\\gamma \u03ba \u03c5[n]^{-5} + \\overline{\u03b3 g[n \u2212 1]})P(v[n]P \u2013 \u03b2\u03c5[n \u2013 1]P) \u2013 \u03b2|y[n]|P.$\n(5)\nThis function offers more control and flexibility, which can be useful for custom be-\nhavior and specific requirements in the root-finding process. However, this comes at\nthe cost of increased complexity and the need for thorough testing. In this work, we\nreplace the original CHARFZERO function with a modification of the Powell hybrid"}, {"title": "Deep learning based DRC parameters estimation", "content": "In this work, we use two method for DRC parameters estimation. In case of the pos-\nsible compressor choice options is known, estimating the compressor profile (label)\n@ instead of directly estimating the DRC parameters often leads to more accurate in-\nversion results. Because we can directly find the corresponding parameters q through\n0. The classification of DRC profile @ can be regarded as an audio classification task,\nsince the signal compressed by a same DRC profile can be regarded as one type. On the\ncontrary, if we only have the compressed signal y, estimating DRC parameters p by re-\ngression task is the only option. This method can achieve the same goal, but generally\nwith lower accuracy."}, {"title": "DRC profile classification", "content": "Early approaches predominantly employed spectral features, and statistical descriptors,\ncombined with classical machine learning algorithms [9, 10]. While these methods\nprovided interpretable results, they often struggled with capturing complex audio pat-\nterns effectively and required manual feature engineering. In contrast, deep learning\nmethods, particularly Convolutional Neural Networks (CNN) [11] and Recurrent Neu-\nral Networks (RNN) [12], have gained prominence due to their ability to automatically\nlearn hierarchical representations from raw audio waveform or spectrograms. Among\ndeep learning-based audio classification methods, the Audio Spectrogram Transformer\n[13] (AST) has emerged as a powerful approach for capturing both temporal and spec-\ntral features of audio signals. In view of the excellent performance of transformer-\nbased models in audio classification tasks in existing studies, we also choose this model\nin our work."}, {"title": "DRC parameters estimation", "content": "Although predicting the DRC profile can obtain accurate DRC parameters, directly es-\ntimating the DRC parameters is more general and will not be limited by the type of\nDRC profile. In the past, some studies have extended the use of early machine learning\ntechniques to parameterize nonlinearities in physical models [14, 15]. Another compu-\ntational intelligence approach [16] estimate synthesizer parameters using a multivariate\nlinear regression model with hand-crafted features. More in line with the spirit of this\npaper is [17] on using U-Net to estimate parameters of multiple audio effects with the\nhelp of raw audio. In [18], 3 different encoders are used for audio effect parameters\nestimation. Among which, the Music Effect Encoder (MEE) [19] performed the best\nfor compression task. In this work we use MEE for regressively estimate the DRC\nparameters. The architecture is illustrated in Figure 2."}, {"title": "Overall Proposed Method", "content": "Now, we propose a new end-to-end DRC inversion method illustrated in Figure 3.\nIt involves a two-phase approach, integrating deep learning techniques and the model-\nbased inversion method presented in Section 2. Taking the compressed signal y as\ninput, we either perform a classification task and use the AST model to predict the\nDRC profile ; or perform a regression task and use the MEE model to estimate the\nDRC parameters po. Then, the DRC inversion model uses the compressed signals y\nand qe to estimate the original signal 2."}, {"title": "Experiments", "content": "In this work, we validate our model on two datasets: MedleyDB [20] with a sam-\npling frequency of Fs = 44, 100 Hz, and DAFX [21] with a sampling frequency of\nFs = 32,000 Hz. Note that, the DAFX dataset provides raw music data, which can be\ndirectly used for signal compression and inversion. However, the MedleyDB dataset\nprovides the raw tracks of various instruments and vocals, which should be mixed to\nobtain a raw music and then be compressed.\nFor the MedleyDB dataset, we randomly select 30 songs from the MedleyDB\ndataset with a total duration of about 1.6 hours and divide them into 5, 785 segments\nof duration t = 5s. For DAFX dataset, for consistency, we extract the same number\nof music clips. Besides, to ensure effective compression, we delete the segments with\na maximum Root Mean Square (RMS) peak less than -60dB. The results are our\nground-truth original signal x.\nTo simulate dynamic range compression, we consider the five distinct DRC profiles\nin Table 1. These DRC profiles correspond to standard compressor presets proposed\npreviously investigate in [4]. Each clip is compressed by these five compressors. As\na result, we get two datasets corresponding to the compressed signal y, respectively"}, {"title": "Datasets", "content": "In this work, we validate our model on two datasets: MedleyDB [20] with a sam-\npling frequency of Fs = 44, 100 Hz, and DAFX [21] with a sampling frequency of\nFs = 32,000 Hz. Note that, the DAFX dataset provides raw music data, which can be\ndirectly used for signal compression and inversion. However, the MedleyDB dataset\nprovides the raw tracks of various instruments and vocals, which should be mixed to\nobtain a raw music and then be compressed.\nFor the MedleyDB dataset, we randomly select 30 songs from the MedleyDB\ndataset with a total duration of about 1.6 hours and divide them into 5, 785 segments\nof duration t = 5s. For DAFX dataset, for consistency, we extract the same number\nof music clips. Besides, to ensure effective compression, we delete the segments with\na maximum Root Mean Square (RMS) peak less than -60dB. The results are our\nground-truth original signal x.\nTo simulate dynamic range compression, we consider the five distinct DRC profiles\nin Table 1. These DRC profiles correspond to standard compressor presets proposed\npreviously investigate in [4]. Each clip is compressed by these five compressors. As\na result, we get two datasets corresponding to the compressed signal y, respectively"}, {"title": "Experimental Settings", "content": "Hardware infrastructure features an Nvidia RTX 4080 GPU, and the software stack\nrevolved around Python as the primary programming language and PyTorch as the deep\nlearning framework of choice. Our evaluation workflow follows a standard supervised\nmachine learning protocol, with the dataset partitioned into training and test sets using\nan 4: 1 split ratio.\nWe uses an Adam optimizer with an initial learning rate of 10-4 and a batch size\nof 12 during a maximum of 500 epochs, decreasing the learning rate per epoch with\nthe exponential way by a factor of a = 0.98. Training stops after 50 epochs without"}, {"title": "Training approaches", "content": "In order to make the results comparable, for the DRC inversion task, as illustrated in\nFigure 4, we compare 2 approaches for training:"}, {"title": "Evaluation", "content": "For evaluation, we compute the following metrics:\n\u2022 $L_{x,x}^{CMSE}$: the Mean Square Error (MSE) between \u00ee and x:\n$L_{x,x}^{CMSE} = \\frac{1}{N} \\sum_{n=0}^{N-1} (\\hat{x}[n] \u2013 x[n])^2$\n(8)\n\u2022 Le given by Equation 7\nBoth the original signal x and the estimated signal \u00ee are normalized by their respective\nRMS values."}, {"title": "Numerical Results", "content": "Our experimental results are mainly divided into three parts: First, we show the algo-\nrithm optimization of the DRC model and discuss the possible reasons. Second, we\nshow the results of the exploration experiment and the generality verification experi-\nment of the AST and MEE models respectively. Finally, we give the DRC inversion\nresults using the complete model and the comparison with some state-of-the-art mod-\nels."}, {"title": "Algorithm optimization", "content": "We first show the optimization results of the CHARFZERO function in the DRC inver-\nsion model. A simple test to compare the performance of the two root-finding methods\nis made. The test audio is a music in MedleyDB dataset of duration t = 57 s. We\nfirst compress the music, and then decompress it using decompressors with different\nroot-finding methods, then compare the decompression time and error. The used DRC\nprofile is the profile \"A\" in Table 1.\nAs results, the decompression time of using the original CHARFZERO function is\n260.3s, while that of using root function is 247.2s. Meanwhile, The $L_{x,\\hat{x}}^{MSE}$ between the\nestimated signal \u00ee and the original signal x is -62.18 dB for the original CHARFZERO\nfunction, while -73.69 dB for the alternative function.\nMathematically, root uses the Levenberg-Marquardt (LM) method, which is effec-\ntive for nonlinear root-finding because it dynamically combines both gradient-descent\nand Gauss-Newton methods. For the nonlinear function \u03bep(v) = 0, LM minimizes:\n|| \u00c9p(v) ||2, and iteratively adjusts parameters to reduce both local error and sensitivity"}, {"title": "Model exploration", "content": "To the best of our knowledge, there is no study which propose to use AST for com-\npressed audio signal classification, we first evaluate its performance for the DRC profile\nclassification task. Thus, we conduct three comparative experiments to decide what is\nthe best choice of input features, input TFRt size, and and the best neural network\narchitecture."}, {"title": "DRC profile classification results", "content": "To the best of our knowledge, there is no study which propose to use AST for com-\npressed audio signal classification, we first evaluate its performance for the DRC profile\nclassification task. Thus, we conduct three comparative experiments to decide what is\nthe best choice of input features, input TFRt size, and and the best neural network\narchitecture.\nBeing inspired by [22], we empirically compare different TFRy: namely Mel Fre-\nquency Cepstral Coefficients (MFCC), Short-Time Fourier Transform (STFT) spec-\ntrogram, Mel Spectrogram (Mel sp.) and Constant-Q Transform (CQT) spectrogram,\nand evaluate their impact on the classification performance of DRC profiles. All the\ntime-frequency features are computed using librosa [23]. Table 3 presents the numer-\nical results. In this experiment, the input size of each time-frequency representation is\n(128, 431). According to the accuracy, using Mel spectrogram as input TFR, achieves\nthe best classification results on both datasets. Specifically, on the MedleyDB dataset,\nthe Mel sp. achieved an accuracy of 0.9558, while on the DAFX dataset, it achieved\nan accuracy of 0.9982. It is worth noting that the training time per epoch for Mel\nspectrogram is also relatively low, indicating its efficiency."}, {"title": "DRC parameters estimation results", "content": "Unlike the AST model, there have been advanced studies using MEE model to estimate\nthe parameters of the audio effect model [18]. Although it is not the same DRC model,\ntheir estimated parameters are also of dimension 6. Therefore, in this work, we directly\nuse the same model configuration. In this task, we minimize the Mean Square Error of\nestimated parameters qe and the real parameters qe:\n$L_{q_0,q_0}^{CMSE} = \\frac{1}{C} \\sum_{i=0}^{C-1} (q_0 [i] \u2013 \\hat{q_0} [i])^2$\n(9)"}, {"title": "DRC inversion results", "content": "On the premise that the results of the DRC profile classification experiment were good\nenough, we perform the DRC inversion experiment.\nThe classification results 0 or the regression results \u0257\u0259, together with the com-\npressed signal y are used as the input of the DRC inversion model, the total number of\ntest samples for both \"M-31\" and \"D-31\" dataset is 7, 173."}, {"title": "Baseline method comparison", "content": "At the end, we conduct a comparative experiment with baseline methods to further\nvalidate the effectiveness of our proposed model-based method. Demucs [24] is an\nadvanced neural network-based model designed for music source separation tasks. In\n[25], the authors used Demucs to achieve removing distortion and clipping applied to\nguitar tracks for music production and got good results. In [7], the authors considered\nremoving multiple audio effects from the same recording and proposed RemFX, a end-\nto-end approach that dynamically combines effect-specific removal models. These two\npure neural network methods are selected as baseline methods. Besides, we also use the\nreal parameters q to directly operate the DRC inversion as a reference for our proposed\nmodel, refereed as \u201cRef\u201d in the table. Since the parameters are correct, the error given\nin this case should be minimal. In principle, the DRC inversion error of our method\nshould be greater than that of the reference method.\nThe results demonstrates that DRC profile classification based DRC inversion is the\nmost effective method among the tested approaches, providing the lowest errors next\nto the reference. The regression approach is a viable alternative but exhibits slightly\nhigher errors and variability. Meanwhile, our proposed methods provide show better\nperformance compared to both the baseline methods in our experiments."}, {"title": "Conclusion", "content": "In this paper, we have developed a model-based method coupled with deep learning\ntechniques for DRC inversion, with a focus on inferring DRC profiles. Our promising\nresults show the effectiveness of the proposed approach for reconstructing audio signals\nwhile simultaneously estimating the underlying DRC profiles. The proposed modified\nAST model obtained better results in DRC profile type classification and inversion\naccuracy compared to traditional audio classification methods presented in [26].\nOur approach opens new avenues for improving audio quality, enabling finer cre-\native control, and meeting industry demands for efficient audio processing tools. The\nability to accurately infer DRC parameters offers opportunities for enhancing audio\nmastering, sound design, and audio restoration applications, ultimately enhancing the\noverall listening experience.\nWe acknowledge certain limitations and areas for improvement for our method.\nThe model is only evaluated with compression and limiter but is not evaluated on ex-\npander and compander. Future research directions may involve exploring alternative\nparameter-based inversion model using neural network, and further numerical experi-\nments considering other types of compressor."}]}