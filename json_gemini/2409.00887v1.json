{"title": "User-Specific Dialogue Generation with User Profile-Aware\nPre-Training Model and Parameter-Efficient Fine-Tuning", "authors": ["Atsushi Otsuka", "Kazuya Matsuo", "Ryo Ishii", "Narichika Nomoto", "Hiroaki Sugiyama"], "abstract": "This paper addresses user-specific dialogs. In contrast to previous research on personalized dialogue focused on\nachieving virtual user dialogue as defined by persona descriptions, user-specific dialogue aims to reproduce real-user\ndialogue beyond persona-based dialogue. Fine-tuning using the target user's dialogue history is an efficient learning\nmethod for a user-specific model. However, it is prone to overfitting and model destruction due to the small amount of\ndata. Therefore, we propose a learning method for user-specific models by combining parameter-efficient fine-tuning\nwith a pre-trained dialogue model that includes user profiles. Parameter-efficient fine-tuning adds a small number of\nparameters to the entire model, so even small amounts of training data can be trained efficiently and are robust to\nmodel destruction. In addition, the pre-trained model, which is learned by adding simple prompts for automatically\ninferred user profiles, can generate speech with enhanced knowledge of the user's profile, even when there is little\ntraining data during fine-tuning. In experiments, we compared the proposed model with large-language-model\nutterance generation using prompts containing users' personal information. Experiments reproducing real users'\nutterances revealed that the proposed model can generate utterances with higher reproducibility than the compared\nmethods, even with a small model.", "sections": [{"title": "1. Introduction", "content": "Deep learning-based dialogue models have made\nsignificant progress over the years. They can now\nconduct conversations comparable to human-to-\nhuman dialogue on any given topic (Shuster et al.,\n2022; Roller et al., 2021; Sugiyama et al., 2023;\nShahriar and Hayawi, 2023). With the improve-\nment of chatbot performance, conversational Al\nhas now been introduced in various services span-\nning the metaverse (Rosenberg, 2023) and gaming\n(Mehta et al., 2022) industries. Recent research\nhas reported that it is possible to simulate the con-\nversation and behavior of multiple agents using a\nlarge language model (Park et al., 2023), where di-\nalogue agents are given personalities and dialogue\nin accordance with their personalities. If these\npersonalities could be extended to real people, it\nwould be possible to instantly form a consensus\namong a large number of people, which is a task\nthat has been impossible until now due to time and\nspace constraints (Toshima et al., 2020). There-\nfore, in this paper, we aim to reproduce real users\nthrough a user-specific dialogue model.\nMuch of the research on giving personality to\nconversational Al has been conducted using the\nPERSONA-CHAT dataset (Zhang et al., 2018),\nwhich consists of several persona descriptions and\ndialogue histories. It evaluates the ability to gen-\nerate consistent dialogues without contradictions\nwhile referring to persona descriptions. However,\nthe dialogue histories in PERSONA-CHAT are gen-\nerated through role-playing by crowd workers on\nthe basis of persona descriptions and are not ac-\ntual conversations between real people. Further-\nmore, the personas in the dataset are defined by\nonly a few sentences, which limits the ability to\nreproduce knowledge or thoughts beyond the per-\nsona description. Thus, different approaches are\nrequired to realize a user-specific dialogue model\nthat can reproduce real users.\nFine-tuning is a practical approach for generat-\ning utterances that replicate a specific character\n(Higashinaka et al., 2018; Mitsuda et al., 2022).\nDialogue histories must be collected in advance\nto reproduce a specific user's dialogue using fine-\ntuning. However, collecting a large amount of dia-\nlogue data can be difficult from a privacy perspec-\ntive, as such data may contain personal informa-\ntion. In previous research, the personality of a\nfamous character was replicated by collecting the\ndialogue data of users who role-played that char-\nacter, but this approach is limited to cases where\nthe personality being collected is well-known and\nhas role-playable characteristics. Therefore, we\nneed an approach that can learn real user person-\nalities even with small amounts of data that can be\ncollected during short dialogues.\nIn recent years, many studies have reported\nusing large language models (LLM) to give dia-\nlogue models individuality (Kasahara et al., 2022;\nRamirez et al., 2023). In these studies, the per-\nsonal characteristics of the interlocutor are de-\nscribed before the dialogue history is given to\nthe language model so that utterances reflecting\nthe described personality are generated from the"}, {"title": "2. Related Work", "content": "Personalized dialogue dataset The PERSONA-\nCHAT dataset is one of the most widely used\ndatasets for research on personalized dialogue,\nand it is also used as a dataset for competitions\n(Dinan et al., 2020). In addition, it has been used\nas a basis for new datasets that include additional\nempathetic conversation data (Zhong et al., 2020)\nand datasets created from website data (Mazar\u00e9\net al., 2018). Previous studies have also examined\nmanipulating PERSONA-CHAT data to improve\ndata quality (Cao et al., 2022).\nDatasets in past studies have been constructed\nby collecting persona descriptions that can be rep-\nresented as key-value pairs such as age and gen-\nder (Qian et al., 2018). Zheng et al. (Zheng et al.,\n2019, 2020) collected large-scale dialogue data\nwith user profiles by estimating user information\nfrom a Chinese microblogging service and pro-\nposed a dialogue model pre-trained with the col-\nlected data. The methods in these studies are very\nsimilar to our own. The estimated user profiles are\nconcatenated into the dialogue context as an input\nsequence in our method, which means it can be\nused without modifying a general language model.\nPersonalized dialogue generation Deep\nlearning-based utterance generation models have\nbeen successful for open-domain conversations.\nPrevious studies have added user embeddings\nto the utterance generation model to generate\npersonalized dialogues (Li et al., 2016b; Kottur\net al., 2017), and several methods generate\nconsistent utterances based on reading persona\ndescriptions (Song et al., 2021; Dong et al., 2022;\nWang et al., 2022). Other methods reference\npersona information in line with the content of\nthe dialogue (Huang et al., 2023) or refine the\ndialogue context to be input to the dialogue model,\nleaving only the context relevant to the persona\n(Zhong et al., 2022). Prior research has reported\nmethods that infer latent persona information\nfrom dialogue history (Cho et al., 2022) or that\nstore long-term memories as persona descriptions\n(Xu et al., 2022). A metric to assess whether\nutterances match the persona characteristics has\nalso been proposed (Miyazaki et al., 2021).\nWe aim to achieve dialogues that reproduce\nreal users, not description-defined personas, and\nadopt a training approach for user-specific models\nthrough fine-tuning rather than referring to descrip-\ntions."}, {"title": "3. Method", "content": "Our task for generating responses given input con-\nsisting of dialogue context, persona, and user ID\ninformation can be formulated as\n$Y = argmax_Y P(Y|X, U, I),$\nwhere $X = {x_0, ..., x_n}$ is a dialogue context,\n$U = {u_{p0}, ..., u_{pm}}$ is a user profile, $Y = {y_0, ..., y_l}$ is a generated response, and $I$ denotes a user ID.\n$x$ and $y$ are tokens for input to the deep learning\nmodel. $u$ represents the user profile items (e.g.,\ngender and age). The user ID is a unique and\nrandom string. Note that we are working on repro-\nducing a specific person's dialogue, which is why\nwe require a user ID to identify the person."}, {"title": "3.2. Overview", "content": "An overview of our personalized dialogue genera-\ntion model is shown in Fig. 1. The first step is to\ntrain a pre-trained model using social dialogue data\nsuch as social networking site (SNS) reply pairs.\nAt this time, we infer the profile of the SNS user\nand include the inferred profile in the input prompts.\nThe next step is to train a model of a real user.\nDuring the fine-tuning step, only the user-specific\nmodel corresponding to the user ID is trained, and\nthe parameters of the pre-trained model are not up-\ndated. The input prompts are entered in the same\nformat as for the pre-training."}, {"title": "3.3. Inferring user profile for pre-training", "content": "Large language models (LLMs) describe informa-\ntion that is characteristic of the user in prompts so\nthat utterances are based on the content of the\nprompts. However, for smaller models, prompting\nhas a limited effect. Therefore, we pre-trained the\ndialogue model with prompts that included the di-\nalogue context and user profile information. In a\npre-trained model that does not include user pro-\nfiles, the model is learned by dialogue from many\nusers who have various backgrounds on SNSs. In\ncomparison, the proposed model learns the user's\nprofile information as a condition for utterance gen-\neration in addition to the dialogue history. Even\nwith the same dialogue history, different utterances\ncan be generated by changing the user's profile.\nSince training a pre-trained model requires a\nhuge amount of dialogue data, we use SNS replies\nas dialogue data for model training. However, ob-\ntaining the uniform user profiles needed for model\ntraining from SNSs is difficult. Therefore, we use\na method for estimating user profiles from text\nposted on SNSs. We obtain a large number of\nuser attributes using a Markov logic-based method\n(Richardson and Domingos, 2006) for estimating\nuser profiles from SNSs developed by Hirano et al.\n(Hirano et al., 2013). They proposed a technique\nthat estimates basic profiles such as age and place\nof residence from text posted on microblogs like X\n(Twitter) and reported that 150 pieces of text are\nneeded to estimate user attributes. Therefore, we\nused a method of dividing the user's posted text\nfor one year into 150 units, estimating the user's\nprofile in each, and taking a majority vote.\nOur user profiles are simplified compared with\nLLM prompts, so we cannot flexibly describe every\nuser image into prompts. However, during model\nfine-tuning, prompts can include attributes tailored\nto the actual user's profile so that the prompts can\nsupplement knowledge about that profile lacking in\na small number of training data."}, {"title": "3.4. Learning pre-trained model", "content": "We train a generative language model based on\nthe Transformer encoder-decoder model (Vaswani\net al., 2017) during the pre-training step using di-\nalogue data that has inferred user profiles. Our\nmethod inputs an estimated user profile as a string\ndirectly into the input prompt:\nPSP: Persona Speaker Prompt\n$[USER] u_{p1}, u_{p2},..,u_{pm} [SEP] x_0, x_1,..,x_n$\nwhere [USER] and [SEP] are special tokens. Our\nmethod can be used without depending on the\nmodel by including the user profile in the input\nprompts. Additionally, the high expressive power\nof the language model allows for robust handling\nof the description of user profiles, such as detailed\nage or geographical information.\nThe input prompt above includes the user profile\nof the speaker, and we call it a Persona Speaker\nPrompt (PSP). In reality, the content of speech\nmay be subject to changes not only by the speaker\nbut also by the conversational partner. We, there-\nfore, propose an additional Persona Pair Prompt\n(PPP) that includes the speaker's profile and the\nconversational partner's profile in the input prompt.\nPPP: Persona Pair Prompt\n$[USER1] u_{p1},u_{p2},..,u_{pm} [USER2] u_{p1},u_{p2},.., u_{pm} [SEP] x_0,x_1,..,x_n$\nThe special tokens [USER1] represent the\nspeaker's profile, and [USER2] represents the part-\nner's profile."}, {"title": "3.5. Parameter-efficient fine-tuning", "content": "During the fine-tuning step, a personalized model\nfor the user is trained using both the pre-trained\nmodel and the user's dialogue data. In this pa-\nper, we train user-specific models using parameter-\nefficient fine-tuning, which involves learning only\na subset of the parameters of a pre-trained model\nrather than all. Reducing the number of parame-\nters to be learned reduces the cost of operating\nmany user models.\nWe use LoRA (Hu et al., 2022) to perform fine-\ntuning, which focuses on the difference in updates\nto parameters. The output $h' \\in R^d$ of the forward\nlayer of the fine-tuned model is calculated on the\nbasis of the weight of pre-trained model $W \\in R^{dxd}$\nand input $x \\in R^d$ as:\n$h' = (W + \\Delta W)x,$\nwhere $d$ denotes the dimension of the network\nand $\\Delta W$ represents the difference in updated\nweights through fine-tuning, which can be further\nexpressed as\n$\\Delta W = BA,$\nwhere $B\\in R^{dxr}$ and $A \\in R^{rxd}$. Here, $r$ denotes\nthe rank and is set to a small value for $d$. The num-\nber of learning parameters is $2dr$, much smaller\nthan full fine-tuning. Since the pre-trained model\nweights $W$ are not updated, switching to a user-\nspecific model becomes possible by modifying only\n$BA$ in accordance with the user ID."}, {"title": "4. Experiments", "content": "We first describe the comparative models. The\nexperiment compares fine-tuning models and does\nnot evaluate the pre-trained models themselves.\nThis is because the pre-trained models do not allow\nfor the input of the user ID $I$ required for the task\nwe defined in 3.1."}, {"title": "4.1.1. Dataset for pre-trained models", "content": "We used Twitter reply pairs to train the pre-trained\nmodels for our experiments and used the data\ncreation method developed by Sugiyama et al.\n(Sugiyama et al., 2023). A pre-training dataset was\ncreated with 1.3 billion reply pairs for the 2020-\n2021 period for 1 million users. The training of\nthe pre-training models with PPP and PSP con-\ntained input prompts that concatenated these user\nprofiles."}, {"title": "4.1.2. Pre-trained models", "content": "The following four pre-trained models were used\nin the experiments. All models features a Trans-\nformer encoder-decoder architecture with 222 M\nparameters.\nPlain T5 This is a general Japanese language\nmodel (Raffel et al., 2020) known to be highly\neffective for fine-tuning with small amounts of data.\nPlain Dialogue We trained a dialogue model us-\ning only the dialogue context from X (Twitter) reply\npairs without user profile prompts.\nPSP Dialogue This pre-trained model trained by\nPSP includes the speaker's user profile and dia-\nlogue context described in 3.4 in the input prompts.\nPPP Dialogue This pre-trained model trained by\nPPP includes the user profiles and dialogue con-\ntext of the speaker and the partner in the input\nprompts described in 3.4."}, {"title": "4.1.3. Fine-tuning training", "content": "For fine-tuning, we used a pre-trained model and a\nsmall amount of user dialogue data to train a user-\nspecific dialogue model. We then compared the\nfollowing fine-tuning methods in our experiment.\nOne-ID The pre-training model is fine-tuned by\nadding the user's unique ID to the beginning of\nthe input prompt. In this paper, the user ID is a\nrandom four-digit alphanumeric string. Since user\nswitching is done only by the user ID, only one\nmodel is trained with this method. This model is\nadvantageous in terms of data volume because\nit can learn the combined dialogue history of all\nusers, but it may also generate the utterances of\nother users, which may pose a risk in terms of\nprivacy and security.\nLoRA User-specific fine-tuning models trained\nwith LoRA are explained in 3.5. One LoRA model\nwas trained per user. We set the rank to $r = 12$,\nand the number of trainable parameters was 1.8\nmillion.\nFULL User-specific models with all pre-trained\nmodel parameters updated by fine-tuning. Each\nuser has one full dialogue model.\nBefore the fine-tuning, domain adaptation learn-\ning to the experimental data was performed on\nthe pre-trained models. This is because the ex-\nperimental data set described below is actual spo-\nken dialogue and chat data, not reply pairs on\nwhich the pre-trained models were trained, and\nfine-tuning with a small amount of data is likely to\nlearn corpus-derived styles rather than personal\ncharacteristics. For domain adaptation, we took all\nuser halves from the training dataset and used the\ntraining data aggregated from them. Fine-tuning in\nthe experiment used the other half of the data.\nFor fine-tuning, we used Adam (Kingma and Ba,\n2015) with a learning rate of $lr = 1e-4$. Early\nstopping was set to terminate learning when the\nvalidation loss began to rise."}, {"title": "4.2. Experiment 1:Next utterance\nprediction", "content": "We first evaluated whether the dialogue models\ncould predict the utterance in the corpus given\nuser information and dialogue context. If a model\ncan generate utterances close to actual utterances\nin the same context as the corpus is input, it can\nreproduce the user's dialogue. We evaluated utter-\nance prediction by training user-specific dialogue\nmodels on multiple dialogue corpora."}, {"title": "4.2.2. Comparison models", "content": "Fine-tuning based models We trained user-\nspecific models for all users in the evaluation\ndatasets using the four pre-training models de-\nscribed in 4.1.2 and the three fine-tuning methods\ndescribed in 4.1.3. For example, for a PCJP with\n100 users, three fine-tunings with ID, LoRA, and\nFULL were trained for 100 users for one pre-trained\nmodel, resulting in 201 models. The total number\nof models was 804 for the four pre-trained models\n(Plain T5, Plain Dialogue, and PPP/PSP Dialogue),\nand three sets of validation were performed, re-\nsulting in 2,412 models to be tested. Then, 3,372\nmodels were tested with UPC and 3,540 with SD.\nPrompt-based models Since the experimental\ndata is in Japanese, the following two models,\nwhich are available in Japanese, were used for\ncomparison.\n- GPT3.5 GPT3.5 (Brown et al., 2020) is an LLM\nmodel running on OpenAl's ChatGPT service\n(OpenAl, 2022). In this paper, we role-played\na speaker to GPT3.5 and generated an ut-\nterance with instructions to output the next\nutterance in the dialogue history. The prompt\ndescribes the user profiles of the role-playing\nspeaker and partner, a self-introductory sen-\ntence created by the speaker, and a dialogue\nhistory of up to 10 turns. We accessed gpt-3.5-\nturbo via OpenAI-API in September 2023.\n- Jp-NeoX-3.6B Jp-NeoX-3.6B is a Japanese\nGPT-NeoX model with 3.6 billion parameters\n(Zhao and Sawada, 2023). This model is\na text completion model. We used input prompts\nwith the same content as GPT3.5 for the input\nprompt, modified into a completion format.\n- Jp-Llama2-7B Jp-Llama2-7B is a model based\non Llama2 (Touvron et al., 2023) with addi-\ntional pre-training to extend Japanese lan-\nguage proficiency (Sasaki et al., 2023). The\ninput prompt uses the same method as Jp-\nNeoX-3.6B."}, {"title": "4.2.3. Metrics", "content": "We used embedding-based metrics (Liu et al.,\n2016) to evaluate the similarity of the test data\nto the reference utterances. The embeddings\nwere created using SentenceBERT (Reimers and\nGurevych, 2019), and cosine distance was used\nfor similarity. We also introduced Acc@sim0,9,"}, {"title": "4.2.4. Result", "content": "The results are discussed in detail in the\nfollowing paragraphs.\nLORA/FULL vs One-ID When PlainT5 and Plain\nDialogue were used as pre-training models, the\nOne-ID model scored higher than the other fine-\ntuning methods. On the other hand, in the case of\nthe PSP or PPP pre-training models that add user\nprofiles, the models with LoRA/FULL user-specific\nmodels scored slightly higher, especially on the\nUPC or PCJP datasets with fewer training data.\nThe results show that it is difficult to learn user-\nspecific models from PlainT5 or Plain Dialogue\nmodels. This is likely because the user's utterance\ngeneration, learned through fine-tuning, is very\ndifferent from the pre-trained model. As a likely\nresult, more training data was needed to learn suffi-\nciently. In other words, by including prompts based\non the user's profile during pre-training, the user-\nspecific model can be additionally trained using the\ndialogue tendencies of users close to the training\ntarget by inputting a profile similar to that of the in-\ndividual model user when fine-tuning the individual\nmodel, so that even with a small amount of training\ndata, the training could reflect the individuality of\nthe user.\nLORA/FULL vs Prompt The reproducibility of ut-\nterance generation using GPT3.5 and other LLMs\nwith user profiles included in the prompts scored\nlower than models trained individually with user\nutterances. This suggests that LLMs make reason-\nable responses to the context of prompt information\nthat includes a user's profile and dialogue history\nbut that these responses are not necessarily the\nuser's specific responses.\nPrompt-based\nutterance generation produced a large number of\nutterances with a similarity of under 0.2 to the ref-\nerence utterances. This means that the generated\nutterances were almost entirely different from the\nreference utterances. The fine-tuned user-specific\nmodels could generate more reproducible utter-\nances, even though the model sizes were much\nsmaller than the compared LLMs. These results\nsuggest that real user interaction, unlike fictional\ncharacters or role-playing, is challenging to repro-\nduce with prompts alone, and fine-tuning is essen-\ntial even for small data sets.\nLORA vs FULL Both LoRA and FULL are fine-\ntuned user-specific models for pre-training. The\nresults show that FULL, which updates all parame-\nters, generated slightly more reproducible utter-\nances. However, no significant differences be-\ntween the two were observed.\nLoRA and FULL should be chosen according to\nthe application. Table 6 shows the specifications\nof the fine-tuning models used in this experiment.\nThe FULL model requires one complete model per\nuser. The model used in the experiment was a\nrelatively small model with 222 million parameters,\nwhich is not a significant problem when training a\nmodel dedicated to a few persons. However, when\nthe number of users increases, it consumes more\nresources. On the other hand, LoRA only has a\nsmall-sized adapter model, so even if the number\nof users with dedicated models increases, the re-\nsource consumption would be minimal compared\nto FULL. The small model size also makes it possi-\nble to dynamically switch adapters while generating\nutterances, allowing for large-scale scaling."}, {"title": "4.3. Experiment 2: Diverse utterance\ngeneration", "content": "We evaluated the reproducibility of the dialogue\ncorpus in 4.2. We define the task in this paper as\nusing dialog context, user information, and user ID\nto determine utterances. Even if the input dialogue\ncontext is the same, the utterance must change\ndepending on the user's information. In the experi-\nments in this section, we evaluated the diversity of\nutterances produced when different user informa-\ntion was input for the same dialogue context."}, {"title": "4.3.1. Experiment datasets", "content": "We used 70 questions from Sugiyama et al.\n(2014)'s personality question set for dialogue con-\ntext."}, {"title": "4.3.2. Comparison models", "content": "We compared three models learned in the\n4.2 experiment, precisely, the One-ID and the\nLoRA/FULL models, which showed high perfor-\nmances in the 4.2 experiments. The inference\nalgorithm used a greedy search to avoid the influ-\nence of the sampling probability."}, {"title": "4.3.3. Metrics", "content": "Since this experiment evaluated the diversity of\ngenerated utterances, we used the Distinct-N met-\nric proposed by Li et al. (Li et al., 2016a). Distinct-N\ncalculates the proportion of different N-grams. For\nthe same input question, we computed the Distinct-\nN of the set of utterances generated by all user\nmodels, with a higher Distinct-N indicating more\nN-grams for the same question. In other words, it\nshows us how various utterances can be generated\ndepending on the users."}, {"title": "4.3.4. Results", "content": "The results for the diversity of user utterances are\nlisted in Table 7. The One-ID model had lower di-\nversities of produced utterances than LoRA/FULL.\nAlthough the One-ID model switches users by the\nID of the input prompt in one model, the expression\nof switching users may be weak. This means that\nit could generate learned utterances from other\nusers, which could be problematic from a security\nand privacy perspective.\nThe model that generated the most variety of\nutterances was the FULL model fine-tuned from a\npre-trained model using PPP, followed by the LoRA\nmodels. FULL and LoRA's difference was similar to\nthe utterance reproducibility experiment described\nin 4.2. LoRA and FULL have the advantage of not\nlearning other users' utterances because they train\nuser-specific models on user-specific data."}, {"title": "5. Conclusion", "content": "This paper described a method for learning dia-\nlogue models to achieve user-specific personal-\nized dialogue. We proposed a method combining\na small pre-trained dialogue model that includes a\nsimple user profile prompt in the input with a user-\nspecific fine-tuning model using parameter-efficient\nfine-tuning. Experimental evaluations using com-\nparative models that combine multiple datasets,\npre-training models, and fine-tuning demonstrated\nthe effectiveness of the proposed method. Fur-\nthermore, we conducted personality reproduction\nexperiments with prompt-based generated utter-\nances using the proposed model and large lan-\nguage models (LLMs). We found that the proposed\nmethod of fine-tuning with a small amount of train-\ning data reproduces personality better than utter-\nances generated from LLMs with prompts contain-\ning personal features.\nIn the future, we will work on speech generation\nbased on personal memories, which is essential\nfor speech demonstrating the individuality of real\nusers. We also plan to proceed with verification of\nthe effectiveness of this method when used with\nmore detailed prompts with LLMs."}]}