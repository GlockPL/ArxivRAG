{"title": "Toward Improving Synthetic Audio Spoofing Detection Robustness via Meta-learning and Disentangled Training with Adversarial Examples", "authors": ["ZHENYU WANG", "JOHN H. L. HANSEN"], "abstract": "Advances in automatic speaker verification (ASV) promote research into the formulation of spoofing detection systems for real-world applications. The performance of ASV systems can be degraded severely by multiple types of spoofing attacks, namely, synthetic speech (SS), voice conversion (VC), replay, twins and impersonation, especially in the case of unseen synthetic spoofing attacks. A reliable and robust spoofing detection system can act as a security gate to filter out spoofing attacks instead of having them reach the ASV system. A weighted additive angular margin loss is proposed to address the data imbalance issue, and different margins has been assigned to improve generalization to unseen spoofing attacks in this study. Meanwhile, we incorporate a meta-learning loss function to optimize differences between the embeddings of support versus query set in order to learn a spoofing-category-independent embedding space for utterances. Furthermore, we craft adversarial examples by adding imperceptible perturbations to spoofing speech as a data augmentation strategy, then we use an auxiliary batch normalization (BN) to guarantee that corresponding normalization statistics are performed exclusively on the adversarial examples. Additionally, A simple attention module is integrated into the residual block to refine the feature extraction process. Evaluation results on the Logical Access (LA) track of the ASVspoof 2019 corpus provides confirmation of our proposed approaches' effectiveness in terms of a pooled EER of 0.87%, and a min t-DCF of 0.0277. These advancements offer effective options to reduce the impact of spoofing attacks on voice recognition/authentication systems.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, ASV has been used extensively for per-sonal biometric authentication. An ASV system aims toverify an identity claim of an individual from their voicecharacteristics [1]. Spoofed voice attacks involve an attackerwho masquerades as the target speaker to gain access into theASV system [2], [3] for use of resources, services or devices.In most cases, the zero-effort imposters can be easily caughtby a general ASV system, but more sophisticated spoofingattacks pose a significant threat to system robustness andcredibility [4]. With easy access to biometric information ofpersonal voices, spoofing attacks are inevitable [5]. Such a potential system security breach represents a key reliabilityconcern of ASV systems. To address this, an audio spoofingdetection system generates countermeasure scores for eachaudio sample to distinguish between genuine (bona-fide)and spoofed speech, which allows for deployment of theASV system into real-world situations where diverse audiospoofing attacks could occur.Since 2015 [6]\u2013[9], the ASVspoof community has been atthe forefront of anti-spoofing research with a series of bian-nual challenges. Their aims are to foster progress in devel-opment of audio spoofing detection to protect ASV systemsfrom manipulation. Existing audio spoofing detection sys-tems have been proposed to address two different mainstream"}, {"title": "II. RELATED WORK", "content": "This section presents a detailed investigation of existingstate-of-the-art countermeasures for audio synthetic spoof-ing detection. The countermeasures are broadly classifiedinto three categories: conventional handcrafted features withmachine learning classifiers, enhanced deep learning ap-proaches, and state-of-the-art end-to-end approaches."}, {"title": "A. CONVENTIONAL APPROACHES", "content": "Researchers in the spoofing detection community haveworked on finding handcrafted features that reflect artefactsbased on phase spectrum, magnitude spectrum, pitch, groupdelay, etc., to distinguish between spoofed and genuine speech [60]\u2013[65]. Since feature extraction and classifiers aretwo main components of spoofing detection systems, theGaussian mixture model (GMM), its variants, and supportvector machine (SVM) classifiers [60], [62], [66]\u2013[68] havebeen extensively explored for synthetic spoofing detection.However, it has been shown that efforts on complex machine-learning-based classifiers are less effective than crafting informative features [69].The Constant-Q Cepstral Coefficients (CQCC) [61] are ex-tracted with the constant-Q transform (CQT), which capturesmanipulation artefacts that are indicative of spoofing attacks.Patel et al. proposed a combination of cochlear filter cepstralcoefficients (CFCC) and change in instantaneous frequency(IF) (i.e., CFCCIF) to detect genuine versus spoofed speech[70]. Additionally, improved classification performance wasobserved when CFCCIF was combined with Mel frequencycepstral coefficients (MFCC) [71] features. For other effec-tive features, the high-dimensional magnitude-based features(i.e., log magnitude spectrum, and residual log magnitudespectrum) and phase-based features (i.e., group delay func-tion, modified group delay function, baseband phase dif-ference, pitch synchronous phase, instantaneous frequencyderivative) have been introduced in [72].Artefacts from synthetic speech reside in different sub-bands, therefore, subband processing is explored to extractdiscriminative features such as linear frequency cepstral co-efficients (LFCC) [14], energy separation algorithm instanta-neous frequency cepstral coefficients (ESA-IFCC) [69], andconstant-Q statistics-plus-principal information coefficient(CQSPIC) [73]. Kaavya et al. proposed another subbandprocessing approach to perform a hierarchical scattering de-composition through a wavelet filterbank, then the absolutevalues of the filter outputs are used to yield a scalogram [74].Previous studies in image processing have extensivelyexplored the concept of texture. It has been found that texturedescriptors such as local binary patterns (LBP) and localternary patterns (LTP) are effective for image classificationtasks. Next, a novel countermeasure based on the analysisof sequential acoustic feature vectors using Local BinaryPatterns (LBPs) was presented to detect LA attacks [67].[65] also employed relative phase shift features and MGDF-based features to detect synthesized/converted speech. LBPsand MGDF [66] are less successful at differentiating betweengenuine and spoofed samples because they are susceptibleto noise, which generates patterns that are similar for bothclasses."}, {"title": "B. DEEP-LEARNING-BASED APPROACHES", "content": "Recent efforts have witnessed a rise in utilization ofdeep-learning-based methods to detect synthesized/convertedspoofing attacks. Alzantot et al. [75] built three variants ofResNet [31] that ingested different feature representations,namely, MFCC, log-magnitude STFT, and CQCC. The fu-sion of three variants of ResNet (i.e., MFCC-ResNet, CQCC-ResNet, and Spec-ResNet) has outperformed the spoofing de-tection baseline methods (i.e., LFCC-GMM, CQCC-GMM).Wang et al. [59] used a 135-layer deep dense convolutionalnetwork to detect voice transformation spoofing. Similarly,Lai et al. [76] adopted two low-level acoustic features,namely, log power magnitude spectra (logspec) and CQCCas input, where the DNN models hinged on variants of all the"}, {"title": "C. END-TO-END APPROACHES", "content": "Today, end-to-end approaches have achieved state-of-the-artperformance in a variety of audio processing applications[83], [84]. Bypassing complex feature engineering, the end-to-end framework takes raw waveforms as input for represen-tation learning and yields corresponding classification deci-sions, which encapsulate pre-processing and post-processingcomponents within a single network [85], [86]. Muckenhirndeveloped a convolutional neural network-based approachto learn features and then built a classifier in an end-to-endmanner [87]. A joint architecture called convolutional Long-Short Term Memory (LSTM) neural network (CLDNN) withraw waveform front-ends was proposed for spoofing detec-tion [88], [89]. In the literature [90], an end-to-end systembased on a variant of RawNet2 encoder [28] and spectro-temporal graph attention networks [91] was used to learnthe relationship between cues spanning different sub-bandsand temporal segments. Jung et al. developed an end-to-end architecture incorporated with a novel heterogeneousstacking graph attention layer, followed by a new max graphoperation and readout scheme, to facilitate the concurrentmodelling of temporal-spectral graph attention for improved"}, {"title": "III. METHODOLOGY", "content": "This section describes each of the relevant components forbuilding our proposed synthetic spoofing detection archi-tecture. This comprises the encoder for general represen-tation learning, attention modules for feature enhancement,and three specific optimization/training schemes to improvemodel accuracy, generalization ability to unseen attacks, androbustness."}, {"title": "A. RAWNET2-BASED ENCODER", "content": "Instead of using hand-crafted features as inputs [97], theRawnet2-based model operates directly upon the raw wave-form without preprocessing techniques [90], [98]. A variantof the RawNet2 model was introduced in [29] for the speakermbedding learning and applied subsequently for buildingspoofing detection systems [90], [99]. Here, we adopt thatmodel to extract high-level representations F\u2208 RC\u00d7S\u00d7T(C, S, and T are the number of channels, spectral bins, andthe temporal sequence length, respectively) from raw wave-forms. According to the literature [29], [30], [99], approachesequipped with a bank of sinc filters show superior effective-ness in terms of both convergence stability and performance.Therefore, a sinc convolution layer is employed for front-endfeature learning. The sinc layer transforms the raw waveformin the time domain using a set of parameterized sinc functionsthat are analogous to rectangular band-pass filters [100],[101]. Each filter within the filterbank possesses its centerfrequencies based on a mel-scale. Cut-in and cutoff frequen-cies are fixed to alleviate over-fitting to training data due totraining data sparsity or rather limited genres of differentspoofing attacks (only 6 for the training and developmentpartitions from the ASVspoof 2019 LA database).The output of each filter is treated as a spectral bin,subsequently, the output of the sinc layer is transformed into a2-dim time-frequency representation by adding a channel di-mension. The result is fed into stacked 2-dim residual blocks[31] with pre-activation [102] for high-level feature learning.Each residual block is comprised of a batch normalizationlayer [103], a 2-dim convolution layer, scaled exponentiallinear units (SeLU) [104], and a max pooling layer fordown-sampling. The specifics of our model configuration aresummarized in Tab. 1."}, {"title": "B. ATTENTION MODULES", "content": "The fundamental building block of convolutional neural net-works (CNNs) serve as the convolution operator, allowingnetworks to learn informative features by combining spa-tial and channel-wise information within the local receptivefields at each layer. Plug-and-play attention modules [33],"}, {"title": "1) Squeeze-and-Excitation", "content": "Squeeze-and-Excitation (SE) module can be integrated intoresidual blocks for learning informative representations bythe insertion after a non-linearity following a convolution[33]. The module as a computational unit is comprised oftwo fully connected layers to learn the importance of eachchannel, which is built on transforming by first compressingand then expanding the full average channel vector. Given the intermediate feature map x \u2208 RC\u00d7S\u00d7T of the Residualblock as input, the SE module first calculates the channel-wise mean statistics e \u2208 RC. Here, the c-th element of e is\n$$e_c = \\frac{1}{S \\times T} \\sum_{i=1}^{S} \\sum_{j=1}^{T} x_{cij}$$\nwhere C, S, and T represent channel, frequency, and timedimensions. The SE module then scales this channel-wise mean by two fully connected layers to obtain the channel-wise attention weights s of the various channels:\n$$s = \\sigma(W_2f(W_1e + b_1) + b_2)$$\nwhere W and b denote the weight and bias of a linear layer.Also, f(\u00b7) is the activate function of the rectified linear unit(ReLU), and \u03c3(\u00b7) is the sigmoid function."}, {"title": "2) Convolutional Block Attention Module", "content": "The convolutional block attention module (CBAM) [34] extends channel-wise attention into two separate dimensions,referred to as the channel and spatial (frequency-temporal)"}, {"title": "3) Simple Attention Module (SimAM)", "content": "Inspired by attention mechanisms in the human brain basedon certain well-known neuroscience theories [107], the sim-ple attention module (SimAM) [35] is proposed to opti-mize an energy function for encapsulating the relevance ofeach neuron. The parameter-free simple attention module(SimAM) has proven to be flexible and effective in enhancingthe learning capabilities of convolution networks with negli-gible computational costs [35], and subsequently applied inspeaker verification [108]. By optimizing an energy functionto capture the significance of each neuron, it generates 3-dimattention weights for the feature map in a convolution layer.\n$$e_t(W_t, b_t, y, x_i) = (y_t \u2013 \\hat{y}_t)^2 + \\frac{1}{M-1} \\sum_{i=1}^{M-1} (y_0 - \\hat{y}_i)^2$$\nGiven the feature map x \u2208 RC\u00d7S\u00d7T in a single channel, tdenotes the target neuron. xi is other neurons, where i is theindex over the frequency-temporal domain and M = S \u00d7 Tisthe number of neurons for each channel. Here, $\\hat{y}_t = W_t x_t +b_t$ and $\\hat{y}_i = W_t x_i + b_t$ are linear transforms for t and xi.Eq. 4 obtains its minimal value when $\\hat{y}_t = y_0$ and $\\hat{y}_i =y_t$.Considering y0 and yt as two distinct values, for simplicity,binary labels (i.e., 1 and -1) are assigned to y0 and yt in thefinal energy function with a regularizer,\n$$e_t(W_t, b_t, y, x_i) = \\frac{1}{M-1} \\sum_{i=1}^{M-1} (-1 - (W_t x_i + b_t))^2 + (1 \u2013 (W_t x_t + b_t))^2 + \\lambda W_t^2$$\nThere are extensive computational resources needed tooptimize each of the neuron's attention weights using ageneral optimizer such as SGD. Fortunately, a closed-formsolution can be leveraged to derive the transform's weightWt and bias bt with optimal energy. Specifically, the minimalenergy of a neuron x in an input feature map x \u2208 RC\u00d7H\u00d7Wis formulated as:\n$$e_x^* = \\frac{4(\\sigma^2 + \\lambda)}{(x \u2013 \\mu)^2 + 2 \\sigma^2 + 2\\lambda}$$"}, {"title": "C. BINARY CLASSIFICATION LOSS", "content": "In this section, the fundamental cross-entropy loss withsoftmax and angular margin-based losses are discussed, andthe weighted additive angular margin loss is proposed forour binary classification. During training, each mini-batchcontains N utterances from either spoofed or genuine speech,whose feature embedding vectors are xi \u2208 RD, with thecorresponding spoofing identity labels being yi, where 1 <i \u2264 N and y \u2208 {0,1} (i.e., 0 denotes spoofed speech and 1represents the genuine)."}, {"title": "1) Revisiting CE-Softmax loss", "content": "The Softmax loss is comprised of a softmax function inte-grated with a multi-class cross-entropy loss, which is formu-lated as,\n$$L_s = - \\frac{1}{N} \\sum_{i=1}^{N} w_{y_i} \\log \\frac{e^{w_{y_i} x_i}}{\\sum_{t=1}^{T} e^{w_t x_i}} = - \\frac{1}{N} \\sum_{i=1}^{N} \\log (1 + e^{(W_{1-y_i} - W_{y_i} x_i)}$$\nwhere W represents the weight vector of the last layer of theencoder trunk, and W0, W1 \u2208 RD are the weight vectors of the spoofed class and genuine class, respectively. $W_{y_i}$ isthe weight of the i-th sample with label yi. This loss functionmerely computes penalties for classification error and doesnot explicitly encourage intra-class compactness or inter-class separation."}, {"title": "2) Angular Margin-based loss", "content": "The softmax loss can be reformulated so that the posteriorprobability only hinges on the cosine value of the anglebetween the weights and input vectors. With normalized unitvectors of W and x, the loss function termed as NormalizedSoftmax Loss (NSL), is written as,\n$$L_N = - \\frac{1}{N} \\sum_{i=1}^{N} \\log \\frac{e^{\\mid\\mid W_{y_i} \\mid\\mid \\mid\\mid x_i \\mid\\mid \\cos(\\theta_{y_i}, i)}}{\\sum_{l=1}^{N} e^{\\mid\\mid W_i \\mid\\mid \\mid\\mid x_i \\mid\\mid \\cos(\\theta_{l}, i)}} = \\frac{1}{N} \\sum_{i=1}^{N} \\log (1 + e^{(cos(\\theta_{1-y_i},i) - cos(\\theta_{y_i},i))})$$\nwhere cos(\u03b8yi,i) denotes the dot product of normalized vector W (|| W ||= 1) and x (|| x ||= 1). Next, x =WUx + by describes the final linear transformation, wherexi \u2208 RD is the penultimate linear layer's output (i.e., D-dim embedding) of the i-th sample with label yi and xo\u2208 R\u00b2 is the last linear layer's output. Finally, $W_{y_i}$ \u2208 RD denotes the$y_i$-th column of the weight W \u2208 RD\u00d72 and by is the bias term.This bias term by\u2081 is set to 0 here, therefore, the linear transformation is reformulated as Wxi = Wyi || xi | cos\u03b8yi,i, where \u03b8yi,i is the angle between the weights and theinput feature. Likewise, this loss function has the same issueas the Softmax loss in that it only computes penalties basedon classification error. This results in embeddings which arelearned by the NSL as not being sufficiently discriminative.Modifications are proposed here to mitigate this issue, wherean additive margin is introduced with the AM-Softmax to make the embedding space of the two classes close to theirweights Wo - W\u2081 and W\u2081 \u2013 Wo. The formula for the AM-Softmax (CosFace) can now be written as,\n$$L_c = - \\frac{1}{N} \\sum_{i=1}^{N} \\log \\frac{e^{s(\\mid\\mid W_i \\mid\\mid \\mid\\mid x_i \\mid\\mid \\cos(\\theta_{y_i},i) - m)}}{e^{s(\\mid\\mid W_i \\mid\\mid \\mid\\mid x_i \\mid\\mid \\cos(\\theta_{y_i},i) - m)} + e^{s(\\mid\\mid W_{1-y_i} \\mid\\mid \\mid\\mid x_i \\mid\\mid \\cos(\\theta_{1-y_i},i)}} = \\frac{1}{N} \\sum_{i=1}^{N} \\log (1 + e^{s(m - cos(\\theta_{y_i},i) + cos(\\theta_{1-y_i},i))})$$\nwhere s denotes a hyper-parameter that rescales up the gra-dient instead of the numerical values becoming too smallwithin the training phase, which helps to expedite opti-mization. Feature maps are rescaled by s, where they areaccordingly projected onto a hypersphere with radius s.Furthermore, an additive angular margin penalty m be-tween Wy and x\u2081 is also incorporated into the equation inorder to simultaneously enhance the intra-class compactnessand inter-class separability, termed as the AAM-Softmax"}, {"title": "3) Weighted Additive Angular Margin loss for binary classification", "content": "Since the dataset employed in this study is unbalanced (e.g.,genuine versus spoofed), different classes are expected topossess individual weights for loss calculation. Here, $W_{y_i}$denotes a manual rescaling weight assigned to class yi. Byadding this weight factor into the equation, a benefit ispossible for the scenario when the training set is unbalanced(e.g., more spoofing samples are included versus genuinesamples). Inspired by earlier research [57], the differentadditive angular margin penalty $m_{y_i}$ can be injected intothe corresponding target angle, which prevents the modelfrom overfitting unseen spoofing attacks to known attacks.Specifically, there exists a distribution mismatch for spoofingattacks in the training and evaluation partition. Two differentmargins are therefore assigned to the bona-fide speech andspoofing attacks, which encourages better compactness forbona-fide samples, and at the same time greater isolation ofthe spoofing attacks. The AAM-softmax (see Eq. 11) is hencereformulated as,\n$$L_w = - \\frac{1}{N} \\sum_{i=1}^{N} w_{y_i} \\log \\frac{e^{s(\\cos(\\theta_{y_i},i) + m_{y_i})}}{e^{s(\\cos(\\theta_{y_i},i) + m_{y_i})} + e^{s \\cos\\theta_{(1-y_i},i)}}}= \\frac{1}{N} \\sum_{i=1}^{N} \\log W_{y_i} (1 + e^{s (\\cos(\\theta_{1-y_i},i) - \\cos(\\theta_{y_i},i) + m_{y_i})})$$"}, {"title": "D. META-LEARNING EPISODIC OPTIMIZATION", "content": "Meta-learning is focused on developing a task-orientedmodel to enhance the learning ability by conducting opti-mization within each subtask (i.e., an episode or a mini-batch), instead of overall engagement for a given problem.A meta-subtask is composed of a support set and a queryset. Examples in the support set are used for learning howto directly solve a subtask, while the query set is usedfor subtask performance assessment. At each step in meta-learning, model parameters are updated based on a randomlyselected subtask. Since the network is presented with varioustasks at each iteration, this enforces learning to distinguishinhomogeneous examples in general, rather than a specificsubset of examples. In realistic settings of the spoofing detec-tion, training data would contain N different types of spoofingattacks manipulated by various spoofing techniques (e.g.A01-A06 in the ASVspoof 2019 logical access (LA) dataset[8], [110]), but the unseen attacks could still occur in theevaluation phase. To simulate this situation during training,we first randomly select K spoofing examples $x^s$ from eachspoofing type respectively, along with 2K bona-fide examplesxb. Next, one spoofing type is randomly included in the queryset while keeping all other types in the support set within eachsubtask. Here, 2K bona-fide examples are equally distributedbetween the query and support set. As a result, we obtainthe following support set S = {x} (N-1)\u00d7KU {x}K1 andquery set Q = {x}_1\u222a{x}_1. Given this formulation ofsupport and query pairs in each episode, with a finite numberof spoofing types of spoofing attacks enrolled into the model,the spoofing attack types in the query set can now vary ineach subtask.To compare samples in the support set and query set, weuse the relation network [58], which parameterizes the non-linear similarity metric using a neural network. Specifically,the relation network simultaneously models the feature rep-resentation and metric over a set of subtasks in order togeneralize to unseen spoofing attacks. Given the input sampleand its corresponding label in terms of (x, y), samples fromthe support set S and query set Q are fed through the encoderfo (see Sec. III-A). Next, an embedding fo(x) from thesupport set and an embedding fo(xj) from the query set areconcatenated to formulate one pair. Considering the numberof samples in S (|S| = NK) and Q (|Q| = 2K), eachsubtask/mini-batch is comprised of 2NK2 permutations as aset P of pairs for metric-based meta-learning. Finally, eachpair is processed by the relation module f, which yieldsa scalar relation output score representing the similaritybetween the feature representation pair,\n$$r_{i,j} = f_{\\phi}([f_{\\theta}(x_i), f_{\\theta}(x_j)])$$\nwhere [., .] denotes the concatenation operation, the networkfo treats the relation score as a similarity measure [58],therefore rij is defined as,\n$$r_{i,j} = \\begin{cases}1, & \\text{if } Y_i = Y_j, \\\\0, & \\text{otherwise}.\\end{cases}$$\nThe network fo and fo are jointly optimized using meansquare error (MSE) objective as in [58], where the relationnetwork output is treated as the output of a linear regressionmodel. The MSE loss for meta-learning here is written as,\n$$L_M = \\frac{1}{2NK^2} \\sum_{i=1}^{N} \\sum_{j=1}^{K} (r_{ij} - 1(Y_i == y_j))^2$$\nAdditionally, we enforce the model to classify samplesin both the support and query sets against the entire set ofclasses in the training set. The entire meta-learning schemewith global classification is depicted in Fig. 2. A hyper-parameter A balances the weighted AAM loss (Eq. 12) andthe MSE loss, where the fusion loss is hereby written as,\n$$L_F = L_W + \\lambda L_M.$$"}, {"title": "E. DISENTANGLED ADVERSARIAL TRAINING", "content": "Next, adversarial examples can be obtained by adding imper-ceptible but malicious perturbations to the original trainingdata, which can compromise the accuracy of a well-trainedneural network [111]. Adversarial examples are commonlytreated as a threat to neural networks. Here, we leverageboth original training data and corresponding adversarial ex-amples to train networks for enhanced system performance.Consider the default adversary generation method, the FastGradient Sign Method (FGSM), which has random perturba-tion and has been used for maximizing the inner part of thesaddle point formulation [112]. A more powerful multi-stepattacker based on the projected gradient descent (PGD) (seeEq. 17) is adopted here to produce adversaries on the fly [51].Given an input training sample x \u2208 D with a correspondingground-truth label y, adversary generation is conducted in aniterative manner as follows,\n$$x^{adv} = \\prod_{X+S}(x^{adv} + \\alpha \\operatorname{sgn}(\\nabla_x L(\\theta, x, y)))$$\nwhere \u03a0 denotes a projection operator, S represents theallowed perturbation size that formalizes the manipulativepower of the adversary, \u03b1 is the step size, L(\u00b7, \u00b7, \u00b7) stands forthe loss function, and \u03b8 indicates the model parameters. Eq.17 then illustrates one step of a multi-step attacker to generateadversaries.The adversarial training framework proposed in [51] onlyused maliciously perturbed samples to train networks. Herethe robust optimization objective illustrates a saddle pointproblem composed of an inner maximization problem and"}, {"title": "1) Adversarial examples", "content": "an outer minimization problem written as,\n$$arg \\min_\\theta E_{(x,y) \\sim D} (\\max_{\\delta \\in S} L(\\theta, x + \\delta, y)).$$\nFor each training data sample x \u2208 D, a set of allowedperturbations \u03b4\u2208 S are introduced to formalize adversaries.Such a training framework has merits as described in [54],[55], [113], but cannot generalize well to original trainingdata [51], [114].To encourage full exploitation of the complementaritynature between original training data and correspondingadversarial examples, adversarial examples are treated asaugmented data, and incorporated with the original data formodel training. The learning objective is formulated as,\n$$arg \\min_{\\theta, \\phi} E_{(x,y) \\sim D} (L_F(\\theta, \\phi, x, y)) + arg \\min_{\\theta} E_{(x,y) \\sim D} (\\max_{\\delta \\in S} L_w (\\theta, x + \\delta, y)$$\nwhere LF and Lw is referred to as Eq. 16 and Eq. 12,respectively."}, {"title": "2) Disentangling via an auxiliary BN", "content": "Earlier studies on adversarial attacks have demonstrated thattraining using adversarial examples can cause label leaking(i.e., the neural network overfits to the specific adversarydistribution), which leads to compromised model perfor-mance [50] [111]. Under the assumption that adversarialexamples and original data come from different underlyingdistributions, Xie et al. proposed disentangled training via anauxiliary batch norm (BN) to decouple the batch statisticsbetween original and adversarial data in the normalizationlayers during model training [56]. This approach wouldallow for better exploitation of the regularization power of"}, {"title": "3) Adversarial training scheme", "content": "Compared to adversarial training [50], [111], disentangledlearning can fully exploit the complementarity nature be-tween original training data and corresponding adversarialexamples. Adversarial examples are generated during modeltraining. In each training iteration, we treat the originaldata mini-batch as adversarial examples at the initial step(i.e., t = 0). Multiple steps for attacking are performedusing the auxiliary BNs. We then derive the adversariesfor the current mini-batch. The objective of incorporatingadversarial examples into training is to improve the modelgeneralization ability to unseen spoofing attacks. We therebysubstitute adversaries corresponding to the bona-fide label(i.e., yadv = 1) with original training samples to maintainan identical data distribution of genuine samples in the ad-versarial mini-batch. Subsequently, we submit the originalmini-batch and adversarial mini-batch to the same network,while calculating the loss via main BNs and auxiliary BNSfor specific mini-batches, respectively. Finally, we minimizethe total loss for the network parameter updates (Eq. 19).We present the complete training scheme with adversarialexamples in Algorithm 1."}, {"title": "IV. EXPERIMENT", "content": "The ASV spoof 2019 corpus on the Logical Access (LA) track[8], [110] is adopted in this work to train and test models. Thecorpus consists of three partitions, namely, training, devel-opment, and evaluation subsets, with each subset containinggenuine and spoofed samples. Different spoofing methods(i.e., voice conversion and speech synthesis) are employedto create spoofing attacks [115]. The evaluation partition"}, {"title": "V. RESULT AND ANALYSIS", "content": "To thoroughly evaluate our proposed methods, we assess the feature enhancement effectiveness for different attentionmodules, then search for a rational perturbation size to craftadversarial examples, and present an ablation study on lossfunctions, and a comparison of our results to the state-of-theart systems in this section."}, {"title": "A. ATTENTION MODULE SELECTION", "content": "The RawNet2-based encoder model learns high-level rep-resentations for spoofing identities, while there are severalattention modules that can be leveraged to refine the inter-mediate feature maps. As noted in Sec. IV-B, the baselinesystem uses a RawNet2-based encoder, which is trained witha cross-entropy (CE) loss (see Sec. III-C1). We compare spoofing detection system performances derived from theencoder (see Sec. III-A) equipped with different attentionmodules. The results are presented in terms of min t-DCFand EER in Tab. 2."}, {"title": "B. SEARCH FOR OPTIMAL PERTURBATION SIZE", "content": "During adversaries generation, a set of allowed perturbations\u03b4\u2208 S formalize the manipulative power ofadversarial examples. We investigate multiple orders of mag-nitude of perturbation size on the effectiveness of enhancingmodel robustness/accuracy."}, {"title": "C. ABLATION STUDY ON LOSS FUNCTIONS", "content": "We perform an ablation study on diverse loss functionsbased on the RawNet2-based architecture. An ablation studyserves to understand the contribution of each component too overall system performance. The base model equipped with SimAM exhibits a satisfyingencoding ability to absorb distinctive information from inputfeatures. Firstly, we minimize a cross-entropy (CE) loss (seeEq. 8) w.r.t. the network parameter for gradient updates. Toencourage better binary classification, we replace the CEloss with the weighted additive angular margin (WAAM)loss (see Eq. 12). Subsequently, we incorporate the meta-learning mean square error (MSE) loss (see Eq. 15) intoa fused total loss function (see Eq. 16). Additionally, toleverage the regularization power of adversarial examples,we conduct disentangled training (see Sec. III-E) with a mixture of original training data and corresponding spoofingadversaries under a combined learning objective (see Eq. 19).A breakdown of the results on the evaluation partitionwith unknown attacks is illustrated in Tab. 4. Each proposedloss function boosts system performance with incrementalimprovement. The WAAM loss outperforms cross-entropyloss, specifically, the relative reduction in EER is up to +8.5%, and + 4.2% on min t-DCF. Additionally, the parameterWy in Eq. 12 is beneficial to the system performance im-provement, which is designed to alleviate the impact by data"}, {"title": "D. VISUALIZATION OF IMPROVEMENT BY PROPOSED APPROACH", "content": "Aligning with the definition of a tandem system as a cascadeof countermeasure (CM) and ASV systems in [117], the CMacts as a gate to filter out spoofing attacks before reachingthe ASV system. The tandem system can encounter threetypes of trials: (i) target, (ii) non-target and (iii) spoof. Onlythe target trials should be accepted while both non-targetand spoof trials should be rejected. Fig. 4 presents scoredensity distributions, which comprises ASV scores (on theleft panel) and CM scores (on the right panel) for bothbaseline CM system and proposed CM system. In Fig. 4,\"Bona\" and \"Spoof\" mean bona fide speech and spoofingattacks, respectively. The proposed CM system tends to yielda wider score distribution, which is consistent with the ideaof better generalization by potentially encompassing scoresfrom unseen samples. Additionally, a larger margin is ob-"}, {"title": "E. PERFORMANCE COMPARISON AGAINST"}]}