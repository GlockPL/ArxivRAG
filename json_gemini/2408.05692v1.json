{"title": "A NOVEL MOMENTUM-BASED DEEP LEARNING TECHNIQUES\nFOR MEDICAL IMAGE CLASSIFICATION AND SEGMENTATION", "authors": ["Koushik Biswas", "Ridam Pal", "Shaswat Patel", "Debesh Jha", "Meghana Karri", "Amit Reza", "Gorkem Durak", "Alpay Medetalibeyoglu", "Matthew Antalek", "Yury Velichko", "Daniela Ladner", "Amir Borhani", "Ulas Bagci"], "abstract": "Accurately segmenting different organs from medical images is a critical prerequisite for computer-\nassisted diagnosis and intervention planning. This study proposes a deep learning-based approach for\nsegmenting various organs from CT and MRI scans and classifying diseases. Our study introduces\na novel technique integrating momentum within residual blocks for enhanced training dynamics in\nmedical image analysis. We applied our method in two distinct tasks: segmenting liver, lung, &\ncolon data and classifying abdominal pelvic CT and MRI scans. The proposed approach has shown\npromising results, outperforming state-of-the-art methods on publicly available benchmarking datasets.\nFor instance, in the lung segmentation dataset, our approach yielded significant enhancements over\nthe TransNetR model, including a 5.72% increase in dice score, a 5.04% improvement in mean\nIntersection over Union (mIoU), an 8.02% improvement in recall, and a 4.42% improvement in\nprecision. Hence, incorporating momentum led to state-of-the-art performance in both segmentation\nand classification tasks, representing a significant advancement in the field of medical imaging.", "sections": [{"title": "1 Introduction", "content": "In modern medicine, medical imaging plays an important role in bridging visual data and clinical insights. Computer\nvision plays a key role in improving the interpretation of complex medical images, including CT, X-rays, and MRIs.\nThis transformational field plays a pivotal role in automating abnormality detection, classifying anatomical structures,\nand quantifying disease features. Real-time surgical guidance, minimally invasive procedures, and ongoing research\ninto interpretability and deployment further emphasize its significance. Healthcare professionals gain the ability to make\ninformed decisions based on a deeper understanding of patients' conditions, even at the early stages. This transformative\ncapability encourages collaboration among computer scientists, clinicians, and researchers, driving innovations with\ngreat promise for healthcare outcomes.\nDeep learning has emerged as a significant tool in clinical support for medical imaging, revolutionizing disease\ndetection, segmentation, and classification Zhang and Qie [2023]. By automating feature extraction, deep learning\nmodels, particularly convolutional neural networks (CNNs), have demonstrated the ability to learn hierarchical features\nfrom raw medical images. Techniques such as segmentation and classification enable these models to extract critical\nvisual cues from various imaging modalities, including CT, MRI, and endoscopy. These advancements assist clinicians\nin disease staging, surgical planning, and assessing treatment responses. Furthermore, deep learning is good at analyzing\npatterns in extensive datasets, which can aid in early disease detection.\nHowever, medical images are more complex than standard images, which makes analyzing them thoroughly quite\nchallenging. Researchers have been working hard to solve these challenges, especially in areas like early diagnosis\nand quantitative imaging, where mistakes can be really risky. Colorectal cancer is one of the most common cancers\nworldwide. Detecting polyps early is crucial, as some types can develop into cancer if not addressed at an early stage.\nHowever, sometimes, it's tough for doctors to differentiate polyps from normal tissue visually. Fortunately, deep\nlearning (DL) models have become a powerful tool for identifying and categorizing abnormalities from medical images.\nThe introduction of residual connection and self-attention mechanisms has further enhanced deep learning and com-\nputer vision domain, allowing them to focus on crucial clinical regions within an image and leading to more robust\narchitectures Chen et al. [2022], Rao et al. [2021]. These innovative methods have greatly enhanced medical imaging,\nleading to more efficient diagnoses and streamlined workflows, thus reducing the strain on healthcare professionals and\nclinical resources over the past decade.\nOur study introduces a method that utilizes the power of the momentum term within the design of the residual\nblock. Incorporating momentum within the residual blocks offers effective network training to enhance the learning\nalgorithm. Our experiments demonstrated that this enhancement led to faster convergence and improved stability, which\nhad the potential to achieve superior performance. The efficacy of our proposed method is supported by extensive\nevaluations across various tasks, including lung, liver, and polyp segmentation, as well as the classification of abdominal\npelvic CT and MRI scans (on RadImageNet Data). Based on these extensive experiments, it is clear that including a\nmomentum-based method in residual block outperforms the current state-of-the-art methods."}, {"title": "2 Related Works and Motivation", "content": "Accurate segmentation and classification of medical images are crucial for com-puter-aided diagnosis and treatment\nplanning but remain challenging due to factors like low contrast, noise, and patient variability. Convolutional neural net-\nworks (CNNs) have shown promise in these tasks, automating diagnosis and aiding medical decision-making Krizhevsky\net al. [2012], Simonyan and Zisserman [2014]. With advancements in deep learning, skip-connection was crucial in\naddressing the degradation problem arising from vanishing gradients. Introducing skip connections in architectures like"}, {"title": "3 Method", "content": "Deep convolutional neural networks have demonstrated exceptional performance in various computer vision tasks and\nhave become state-of-the-art in image classification problems. AlexNet Krizhevsky et al. [2012], VGG Simonyan\nand Zisserman [2014], ResNet He et al. [2016a], Vision Transformer Dosovitskiy et al. [2020] are some popular\narchitectures for image classification problem. However, as the number of layers increases, the problem of vanishing\ngradients becomes increasingly prevalent, which leads to a drop in training accuracy beyond a certain depth. We present\nour approach in the next subsection."}, {"title": "3.1 Residual Network", "content": "In 2015, a group of researchers from Microsoft Research introduced ResNet He et al. [2016a]. This architecture is\ndesigned to overcome the problem of degradation that deep neural networks often face. As the number of layers\nincreases, the accuracy of the network can either saturate or degrade. ResNet addresses this issue by introducing\nresidual connections, also known as skip connections. These connections allow the network to bypass one or more\nlayers during training and inference. Residual connections work by adding the output of a layer to the output of a few\nlayers ahead, creating a shortcut path for gradient flow. This enables the training of much deeper networks. ResNets\nhave been widely adopted in various computer vision tasks such as image classification, object detection, and semantic\nsegmentation. They have achieved state-of-the-art performance on several benchmark datasets."}, {"title": "3.2 Proposed Momentum-based Approach for medical images", "content": "The momentum ResNet Sander et al. [2021] relies on the integration of the momentum within the Residual Block for\nimage classification, as shown in Figure 1. Our methodology is designed to optimize network performance in medical\nimage classification and semantic segmentation tasks. The feed-forward residual block at layer n is defined as follows:\n$$X_{n+1} = X_n + f(x_n, \\theta_n)$$\n(1)\nThe velocity equation is defined as follows:\n$$v_{n+1} = \\gamma v_n + (1 - \\gamma) f(x_n, \\theta_n)$$\n(2)"}, {"title": "3.3 Reversible Property", "content": "In the realm of deep learning, a neural network is considered reversible if all of its activations can be recalculated when\nperforming a backward pass. By contrast, a network that is not reversible requires saving activations from the forward\npass, leading to increased memory usage. Reversible or invertible networks have the unique advantage of being able to\nperform backpropagation without storing the outputs of activation function, thus significantly reducing the memory\nfootprint of models that employ this approach Chang et al. [2017], Gomez et al. [2017], Gugglberger et al. [2022],\nSander et al. [2021]. Momentum-residual block is invertible. We can invert this equation as follows:\n$$X_n = X_{n+1} - v_{n+1}$$\n(4)\n$$v_n = \\frac{1}{\\gamma} (v_{n+1} - (1 - \\gamma) f(x_n, \\theta_n)).$$\n(5)"}, {"title": "4 Experiments and Results", "content": "We have reported results on medical image segmentation problems on different organs like lungs (medical decathlon\ndata), liver (medical decathlon data), and polyps (Kvasir-SEG dataset). For classification, we have considered\nRadImageNet data."}, {"title": "4.1 Medical Image Segmentation", "content": "We evaluated the efficacy of our architecture by considering two tasks: segmentation and classification. We consider the\ndecathlon Segmentation Benchmark lun [2024], Antonelli et al. [2022], Bilic et al. [2023] and the Kvasir-Seg Jha et al.\n[2020] datasets for the segmentation task. The Decathlon is a comprehensive collection of medical image segmentation\ndatasets covering various anatomies, modalities, and sources, including the brain, heart, liver, hippocampus, prostate,\nlung, pancreas, hepatic vessel, spleen, and colon. For our experiments, we consider the Liver Antonelli et al. [2022],\nBilic et al. [2023] and the Lung Antonelli et al. [2022], lun [2024] data. The Kvasir-SEG dataset consists of 1000\nimages, of which 880 were used for training and the remaining for testing.\nTo avoid bias, we divided the Liver data into independent training (70 patients), validation (30 patients), and test (30\npatients) sets. The volumetric CT scans were processed slice-by-slice to fit into regular computer hardware (GPU).\nPrior to segmentation, we extracted healthy liver masks for unbiased results.\nThe liver, Lung, and Kvasir data segmentation experiments were conducted using the PyTorch framework Paszke\net al. [2019]. We consider a batch size of 16 and a learning rate of le\u00af4 for the segmentation tasks. We trained the\nnetwork for 500 epochs with an early stopping patience of 50 to fine-tune the network parameters. To enhance the\nnetwork performance further, we used a hybrid loss function combining binary cross-entropy and dice loss and an\nAdam optimizer for updating the parameters. The data was divided into three sets: 80% for training, 10% for validation,\nand 10% for testing. We resized the image to 256 \u00d7 256 pixels in-plane resolution to balance the training time and\nmodel complexity. All the segmentation experiments were conducted on the A100 GPU server."}, {"title": "4.2 Medical Image Classification", "content": "For the image classification task, we consider the RadImageNet Mei et al. [2022] dataset, which is a medical imaging\ndatabase that is publicly available and designed to improve transfer learning capabilities in medical imaging applications.\nIt is one of the largest medical imaging classification datasets currently available and is intended for use by professionals\nin the field of healthcare. We conducted experiments on CT and MRI abdominal/pelvis using the entire dataset. The\ndataset comprises 28 disease classes, each with an average class size of 4994 and a total of 139,825 slices. The dataset\nis specifically designed to have slices per disease, although the overall scans are in 3D volumes. We conducted our\nexperiments on the dataset of MRI images of the abdomen and pelvis. The dataset consisted of 26 different classes\nof diseases, with an average class size of 3513 slices and a total of 91,348 slices. Although there is some overlap\nbetween this dataset and the CT dataset, the MRI dataset has some unique disease classes, such as enlarged organs and\nlive disease, which are not found in the CT dataset. On the other hand, the CT dataset has a specific class for entire\nabdominal organs.\nWe consider the Tensorflow-Keras Chollet et al. [2015] framework to run the experiments, with MobileNet V2 Sandler\net al. [2019] and ShuffleNet He et al. [2016a] serving as baseline models classification networks. The networks are\ntrained with a batch size of 32, an initial learning rate set at 0.00001, Adam Kingma and Ba [2017] optimizer, and a\nweight decay rate of 1e-4. The data is partitioned into three sets, with 80% used for training, 10% for validation, and\n10% for testing. The results obtained from MRI scan image data are presented in Table 5, while those from the CT"}, {"title": "4.3 Performance Evaluation", "content": "We have examined the momentum-based approach in various situations. We carried out experiments to explore the\nmodel's ability to learn on the test set of Liver, Lung, and Kvasir-SEG datasets for image segmentation and RadImageNet\ndata for CT and MRI image classification. The outcomes pertaining to the observed dataset on the segmentation task"}, {"title": "5 Conclusion", "content": "This study presents a novel momentum-based segmentation and classification approach that effectively segments liver,\nlung, and polyps using the momentum equation and residual block. The findings from various publicly available\ndata demonstrate the efficacy of the proposed classification and segmentation approach. Based on a comprehensive\ncomparison of our momentum algorithm on other datasets, our approach has consistently shown superior performance\nover our competitors. The quantitative and qualitative analysis results indicate that the momentum-based approach is\nmore generalizable to most datasets, making it a suitable tool for clinical settings. Therefore, the proposed momentum-\nbased approach provides a strong benchmark for developing algorithms that can assist clinicians in early lung, liver, and\npolyp detection and medical image classification."}]}