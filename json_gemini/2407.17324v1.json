{"title": "Enhanced Deep Learning Methodologies and MRI Selection Techniques for Dementia Diagnosis in the Elderly Population", "authors": ["Nikolaos Ntampakis", "Konstantinos Diamantaras", "Ioanna Chouvarda", "Vasileios Argyriou", "Panagiotis Sarigianndis"], "abstract": "Dementia, a debilitating neurological condition affecting millions worldwide, presents significant diagnostic challenges. In this work, we introduce a novel methodology for the classification of demented and non-demented elderly patients using 3D brain Magnetic Resonance Imaging (MRI) scans. Our approach features a unique technique for selectively processing MRI slices, focusing on the most relevant brain regions and excluding less informative sections. This methodology is complemented by a confidence-based classification committee composed of three custom deep learning models: Dem3D ResNet, Dem3D CNN, and Dem3D EfficientNet. These models work synergistically to enhance decision-making accuracy, leveraging their collective strengths. Tested on the Open Access Series of Imaging Studies(OASIS) dataset, our method achieved an impressive accuracy of 94.12%, surpassing existing methodologies. Furthermore, validation on the Alzheimer's Disease Neuroimaging Initiative (ADNI) dataset confirmed the robustness and generalizability of our approach. The use of explainable AI (XAI) techniques and comprehensive ablation studies further substantiate the effectiveness of our techniques, providing insights into the decision-making process and the importance of our methodology. This research offers a significant advancement in dementia diagnosis, providing a highly accurate and efficient tool for clinical applications.", "sections": [{"title": "I. INTRODUCTION", "content": "DEMENTIA, a progressive neurological disorder, significantly impairs cognitive function, affecting millions of individuals globally. It poses a substantial burden on patients, caregivers and healthcare systems. Alzheimer's disease, the most common form of dementia, accounts for 60-70% of cases [1]. The strongest known risk factor for dementia is increasing age, with most cases affecting those of 65 years and older. [2] Early and accurate diagnosis of dementia is crucial for effective management and care planning. [3]\nAccording to Smith et al. [4] the advancements in neuroimaging, particularly Magnetic Resonance Imaging (MRI), have revolutionized the diagnostic landscape for dementia. MRI provides detailed brain images, facilitating the identification of structural changes associated with various dementia stages. However, the interpretation of these images typically relies on the expertise of radiologists and the accuracy can vary depending on their level of experience.\nMedical imaging diagnostic efficiency and accuracy may be improved by recent advances in machine learning [5]. Machine learning algorithms, particularly those requiring classification problems, have been successfully used to identify between patients who are demented and those who are not, according to Chiu et al. [6]. Despite these developments, current approaches frequently make use of whole MRI scans, which results in the addition of extraneous data that may compromise the precision and effectiveness of these algorithms.\nThe decision to classify patients into two broad categories demented and non-demented is primarily to robustly determine the presence or absence of dementia in a clinical setting. This binary classification lays the groundwork for clear, actionable diagnostic outcomes. Once dementia"}, {"title": "II. RELATED WORK", "content": "The body of the research about the related work is focusing on the binary classification (demented vs non-demented) of 3D brain MRIs, particularly using the OASIS dataset. Dhinagar et al. [11] conducted a study that highlighted the capability of a 3D CNN model trained from scratch. This model achieved an ROC-AUC of 0.789 for Alzheimer's Disease (AD) classification, demonstrating its ability to generalize across datasets, including handling diverse MRI data from the OASIS dataset. The model showed less susceptibility to overfitting in AD classification compared to Parkinson's Disease (PD) and proposed that such a model could be instrumental in differentiating between AD and PD, especially in complex cases where both diseases present similar symptoms.\nIn another significant work, Yagis et al. [12] focused on the early detection of AD using deep learning and neuroimaging data. Their study emphasized the crucial role of early AD detection, given that diagnostic symptoms often emerge at later stages after substantial neural damage. They employed a 3D VGG variant convolutional network (CNN) for analyzing MRI data, underlining the potential of deep learning in extracting high-level features from neuroimaging. Using the OASIS dataset, they aimed to improve the accuracy of AD classification. The researchers preferred 3D models over 2D to prevent the loss of information, which is common when converting 3D MRIs into 2D images for analysis. Their proposed 3D CNN model achieved a classification accuracy of 69.9% on the OASIS dataset, using 5-fold cross-validation, which was notably superior to that of 2D network models.\nSaratxaga et al. [13] presented a study that developed a deep learning-based method for AD diagnosis using the OASIS neuroimaging dataset. Their experiments tested various models on both OASIS-1 and OASIS-2 datasets for two-class (cognitive normal vs. AD) and three-class (cognitive normal vs. very mild vs. mild and moderate dementia) problems. Notably, the study found that 2D network models in binary classification problem, particularly BrainNet2D and ResNet18, showed accuracy of 0.83 and 0.93 respectively, surpassing previous approaches. At the same time Brain-Net3D achieved an accuracy of 0.84. The study concluded that the 2D approach was more efficient for both binary and multi-class classifications.\nFurthermore, Wen et al. [14] developed an open-source framework for the classification of Alzheimer's disease using 3D convolutional neural networks. This framework extended existing tools to include data from ADNI, AIBL, and OASIS datasets, and focused on 3D subject-level analysis for AD classification. Testing on the OASIS dataset showed an accuracy of 0.68, highlighting the framework's effectiveness in AD classification using deep learning techniques."}, {"title": "III. METHODOLOGY", "content": "In our study, as shown in Fig. 1, we employed a comprehensive methodology that starts with the processing of volumetric brain MRI scans of patients. These MRIs consist of continuous slices, providing an intricate view of the brain's structure. Our aim was to develop a model capable of distinguishing between demented and non-demented patients based on these scans.\nIn the first phase of our methodology which involves a preprocessing pipeline, we decided to exclude data for patients below 60 years of age. This decision was driven by our study's focus on predicting dementia in the elderly, a group at higher risk for this condition. We aimed to maintain a homogeneous dataset, as OASIS2 includes patients above 60 years old only when all patients below 60 were non-demented in the OASIS1 dataset, avoiding in this way to introduce age-related biases. Then, we implemented a novel technique to select the 140 most relevant continuous slices from each brain MRI. Concurrently, we performed minor transformations on the data.\nFollowing the preprocessing, the manipulated volumetric data were passed onto a confidence-based committee. This committee utilized three distinct custom 3D deep learning models: a custom 3D Convolutional Neural Network (CNN) called \"Dem3D CNN\", a custom 3D variation of ResNet called \"Dem3D ResNet\" and a custom 3D variation of EfficientNet called \"Dem3D EfficientNet\". Each model generated predictions with associated confidence levels. The committee evaluated the predictions from each model, taking into account the confidence associated with each. Based on this analysis, a final decision was made to classify each patient as either demented or non-demented."}, {"title": "A. PREPROCESSING PIPELINE", "content": "1) Data Cleaning\nDuring the preprocessing pipeline for this research, a selection process was undertaken to ensure data consistency and avoid data leakage, when combining OASIS1 and OASIS2 datasets.\nFor the OASIS1 dataset, which initially comprised 416 patients, the selection criteria focused on including only those patients with 'MR1' scans (excluding 'MR2' scans\u00b9) and specifically choosing from the 'RAW' files only the first session ('mpr-1'). This filtering was applied to prevent data leakage by avoiding the inclusion of multiple sessions per patient, which could lead to overlapping information in the dataset. As a result of this filtering, all 416 patients from the OASIS1 dataset were retained.\nIn the case of the OASIS2 dataset, which contains longitudinal data for 150 patients, a similar approach was adopted. To maintain consistency and prevent data leakage, only the first visit of each patient was selected, applying the same criteria as used for OASIS1. This procedure resulted in the inclusion of 146 patients from the OASIS2 dataset. Four patients were excluded because they did not have the ('mpr-1') session in their raw data.\nAn additional filtering step was applied to the OASIS1 dataset, considering the age range of the subjects. Since OASIS1 includes patients from ages 18 to over 90, and OASIS2 is focused on subjects aged 60 and above, it was decided to align both datasets by age range. Consequently, patients under the age of 60 were removed from the OASIS1 dataset, reducing the number of patients from 416 to 198. This adjustment ensured consistency with the age range of the OASIS2 dataset and facilitated a more focused study on the older age group, which is more relevant for dementia research.\nAfter these selection processes, the combined dataset resulted in a total of 344 patients. The next step was to classify these patients into two groups: demented and non-demented, based on their CDR. Patients with a CDR of 0.5, 1, and 2 were categorized as demented, while those with a CDR of 0 were considered non-demented. This classification yielded 164 demented and 180 non-demented patients (total 354 patients), providing a balanced dataset for further analysis in the study.\n2) Extraction\nThe next step involved extracting slices from the NIfTI files for each patient. For this task, the 'nibabel' library, a widely recognized toolkit for NIfTI data handling in Python, was utilized to process the MRI data [17]. Using this tool, all the available 256 slices from the NIfTI file of dimensions"}, {"title": "3) Optimized Subset Selection", "content": "At the core of the preprocessing pipeline in this study lies the selection of a subset of 256 slices from the volumetric MRI data, chosen for their high predictive value. This selection is critical as, based on MRI observations, the topmost and bottom-most slices often contain minimal relevant information, contributing little to the predictive model's accuracy. Researches by Lee et al. [18] and Im et al. [19] suggest that the average human head height is around 17.5cm. Considering that each slice in the OASIS datasets is 1.25 mm thick, this led to the choice of the 140 most informative slices for analysis. This focused selection not only ensures the inclusion of the brain's most relevant regions but also enhances the efficiency of training the predictive models. By reducing the dataset to slices that are most likely to contain significant features for dementia detection, the training process becomes more streamlined and focused.\n$\\sigma_f^2(t) = w_0(t)w_1(t) [\\mu_0(t) - \\mu_1(t)]^2$ \nIn order to apply this optimal subset selection, the initial procedure focuses on detecting the Region of Interest (ROI). This ROI will be the sub-area of our calculations. To do that, we applied Otsu's method [20]. As shown in (1), Otsu's method thresholds the images to create a binary distinction between the brain and the background, crucial for accurate region identification. Otsu's method determines an optimal threshold for segmenting images into brain and background areas. This is achieved by maximizing the between-class variance, denoted as $\\sigma_f^2(t)$:\nThis variance is a measure of separation between two classes, defined by their pixel intensity distributions. The probabilities of these two classes, given by $w_0(t)$ for the background and $w_1(t)$ for the brain, are calculated based on the threshold t. The mean intensities of the two classes are represented by $\\mu_0(t)$ and $\\mu_1(t)$. By optimizing the threshold to maximize $\\sigma_f^2(t)$, Otsu's method transforms the gray-scale image into a binary one.\nNext step is to calculate the bounding box for each slice of the same patient. The focus here is to select the largest bounding box from these slices as the ROI for that particular patient. In this way we ensure that our ROI will be shorter from the whole image and will include all the MRIs essential information. After applying Otsu's method for thresholding the MRI images, we label the pixels and we calculate the bounding box, which is the smallest rectangle that can enclose the labeled region. The margins of this bounding box are determined by the extremities of the region."}, {"title": "B. Confidence-based Ensemble Prediction Method", "content": "1) Dem3D ResNet\nThe architecture of the Dem3D ResNet model is a custom one and is an adaptation of the traditional 2D ResNet [22] for 3D data processing. This adaptation is primarily realized through the use of 3D convolutional layers. The basic component of the Dem3D ResNet architecture is a Convolutional Neural Network (CNN), a type of deep neural network highly effective in analyzing visual imagery. CNNs, introduced by LeCun et al. [23]\nThe initial convolutional layer, is designed to process 3D data employing a kernel of size 7 \u00d7 7 \u00d7 7, which moves through the input data in three dimensions (depth, height, width). The stride, set to (1,2,2), determines the step size the kernel takes as it moves across the input volume. This specific stride means the kernel moves by one unit along the depth and by two units along the height and width dimensions. Padding, set to 3, refers to the addition of layers of zeros around the input data, enabling the kernel to process the edges of the input volume. After the convolutional layer, a Batch Normalization layer (BN) [24] is applied, as shown in equation (6). This layer normalizes the output of the convolution by adjusting and scaling the activation.\n$BN(x) = \\gamma \\frac{x - \\mu}{\\sqrt{\\sigma^2 + \\epsilon}} + \\beta$\nwhere x is the input, $\\mu$ and $\\sigma^2$ are the mean and variance, $\\gamma$ and $\\beta$ are learnable parameters, and $\\epsilon$ is a small constant for numerical stability. After this a Rectified Linear Units (ReLU) [25] activation function, equation (7), is applied.\n$ReLU(x) = max(0, x)$ \nwhere x is the input, and the function outputs the maximum of 0 and x, setting all negative values to 0.\nFinally, regarding the initial convolutional layer, a max pooling layer is applied. This layer, using 3D max pooling, reduces the spatial dimensions of the input volume using specific values for kernel size, stride, and padding. Specifically, it is defined with a kernel size of 3 \u00d7 3 \u00d7 3, a stride of 2, and padding of 1.\nIn the core of the Dem3D ResNet network, there are 4 distinct residual layers. Starting with the first one, it consists of 3 blocks. This layer is key to the initial feature extraction, featuring two 3D convolutional layers with 3 \u00d7 3 \u00d7 3 kernels in each block. These convolutions are followed by batch normalization and ReLU activation. A distinctive aspect of this layer is the implementation of residual connections, which enable the addition of the input to the output of the convolutional layers, maintaining the spatial dimensions due to the absence of down-sampling. The ResNet equation for these connections is as follows in (9):\ny = F(x, Wi) + x\nwhere y is the output tensor of the residual block, F(x, Wi) represents the function applied to the input, including layers like convolutions, batch normalization and activation, and Wi denotes the weights of these layers and the x is the input tensor to the block.\nThe network's capacity for feature extraction is further enhanced by the second layer, which adds 4 blocks and 128 more filters. Both the convolutional layers and the residual connections undergo down-sampling as a result of this layer; the latter adjusts by means of a 1 \u00d7 1 \u00d7 1 convolution with a stride of 2, hence decreasing the spatial dimensions. The third layer increases the number of filters to 256 across 6 blocks, which improves feature extraction even more. Its initial block continues the down-sampling that was done in the preceding layer. Here, the residual connections are rearranged to match the lowered dimensions, guaranteeing uniformity in the feature map dimensions. Finally, the fourth layer, with 512 filters and 3 blocks, completes the network's feature extraction process. It continues the trend of down-sampling, initiated in its first block, further reducing the spatial dimensions. The residual connections in this layer are tailored for dimension matching, facilitating efficient feature map propagation through to the final stages of the network.\nAfter the residual layers, the Dem3D ResNet network transitions into an Adaptive Average Pooling layer. This layer adapts the spatial dimensions of the feature maps to a fixed size 1 \u00d7 1 \u00d7 1, ensuring that the subsequent layers"}, {"title": "2) Dem3D CNN", "content": "The Dem3D CNN model is a custom CNN designed for processing three-dimensional data. Its architecture employs a sequence of convolutional, pooling, normalization, and fully connected layers to extract relevant features and facilitate classification tasks.\nIn the model's architecture, the convolutional segment of the network consists of 4 convolutional layers, each applying a 3D convolution operation to the input. A 3D convolution with 64 output channels, a kernel size of 3 \u00d7 3 \u00d7 3, and padding set to 1 are used in the network's Convolutional Layer 1. A ReLU activation function is employed after this layer to add non-linearity. The max pooling operation with a kernel size of two completes the layer sequence. Similar to the first convolution, the second convolution uses a 3D convolution with the same kernel size and padding and keeps the number of output channels at 64. Max pooling, BN, and ReLU activation are also present in this layer. Progressing to Convolutional Layer 3, the network increases the output channels to 128, allowing for the construction of more intricate representations. The kernel size and padding remain consistent at 3 \u00d7 3 \u00d7 3 and 1, respectively. As with the previous layers, this one is succeeded by the ReLU activation, max pooling and BN, maintaining the structural integrity of the network's design. The Convolutional Layer 4 further escalates the complexity by increasing the number of output channels to 256. It upholds the kernel size of 3\u00d73\u00d73 and padding of 1. The sequence of ReLU, max pooling and BNn follows."}, {"title": "3) Dem3D EfficientNet", "content": "The Dem3D EfficientNet model is a custom adaptation of the EfficientNet architecture [27], specifically modified for processing three-dimensional data. This model inherits the core principles of the EfficientNet design, particularly the use of Mobile Inverted Bottleneck blocks (MIB) - a hallmark of the EfficientNet architecture, as presented from (10) to (14), and a scalable architecture, but extends these concepts to handle 3D volumetric data effectively.\nStep 1: Expansion\n$F_{exp}$ = Swish (BatchNorm3d (Conv3d$_{1\\times1\\times1}$(F$_{in}$)))\nStep 2: Depthwise Convolution\n$F_{dw}$ = Swish (BatchNorm3d (Conv3d$_{depthwise}$ (F$_{exp}$)))\nStep 3: Squeeze-and-Excitation\n$F_{se}$ = SEBlock3D(F$_{dw}$)\nStep 4: Projection\n$F_{out}$ = BatchNorm3d (Conv3d$_{1\\times1\\times1}$(F$_{se}$))\nStep 5: Residual Connection\n$F_{final}$ = $F_{in}$ + $F_{out}$\nwhere F$_{in}$ represents the input feature map, F$_{exp}$, F$_{dw}$, F$_{se}$ and F$_{out}$ denote the feature maps at different stages within the block.\nThe model begins with a Stem Layer, consisting of a 3D convolutional layer with 32 output channels, a kernel size of 3, a stride of 2, and padding of 1. This layer is designed to capture initial spatial features from the input data while reducing its dimensions. The stem also includes BN and the Swish activation function, a smooth, non-linear function that helps the model capture complex patterns, as shown in (15) below:\nSwish(x) = x\u00b7 \u03c3(x)"}, {"title": "4) Confidence-based Committee", "content": "A Confidence-based Committee approach is employed to leverage the predictive strengths of Dem3D ResNet, Dem3D CNN and Dem3D EfficientNet models. This committee operates by analyzing the predictions from each of these models for a given input and selecting the prediction with the highest confidence - \"C\" in (16). As mentioned, confidence is derived from the softmax function applied to the models outputs, indicating the models certainty in their decisions.\nPred= max($C_{Dem3D ResNet}$, $C_{Dem3D CNN}$, $C_{Dem3D EfficientNet}$)"}, {"title": "IV. EXPERIMENTAL OUTCOMES", "content": "A. DATASET DESCRIPTION\nData from the OASIS1 [8] and OASIS2 [9] databases, which are both important sources in neuroimaging studies of brain aging and dementia, were used in the context of this investigation. The OASIS1 dataset, which includes cross-sectional MRI data from 416 participants between the ages of 18 and 96, is a publicly available collection of MRI data in the Neuroimaging Informatics Technology Initiative (NITI) format. This dataset includes a wide range of people, from those who are intellectually normal to those who have different degrees of cognitive impairment. Every participant in OASIS1 is represented by a single visit, during which four distinct 1.25 mm-thick T1-weighted MRI images are obtained and saved in NIfTI format. Complementing the OASIS1 dataset, OASIS2 provides longitudinal MRI data, also in NIfTI format, from 150 subjects aged between 60 and 96 years. Subjects in the OASIS2 dataset underwent MRI scans over two to five visits, with each visit spaced at least one year apart. Like in OASIS1, the MRI scans in OASIS2 also feature a slice thickness of 1.25mm. This longitudinal approach, comprising 373 MRI sessions in total, is invaluable for studying the progression of neuro-degenerative diseases such as dementia.\nBoth datasets include vital metadata, featuring key patient characteristics such as age and Clinical Dementia Rating (CDR). The CDR scale categorizes subjects into classes 0, 0.5, 1, and 2, corresponding to no, very mild, mild, and moderate dementia, respectively. This classification provides a standardized measure of dementia severity, enabling the correlation of neuroimaging findings with the progression of cognitive impairment, greatly enriching the research's depth and applicability.\nB. EVALUATION METRICS\nIn evaluating the performance of our classifier for distinguishing between demented and non-demented patients, we employed metrics derived from the confusion matrix. A confusion matrix offers a clear tabular representation of a classification algorithm's performance. In our specific binary classification context, the matrix components are True Positives (TP), True Negatives (TN), False Positives (FP), and False Negatives (FN). Here, TP denotes correctly identified demented cases, TN represents accurately identified non-demented cases, FP comprises non-demented cases mistakenly classified as demented, and FN includes demented cases incorrectly classified as non-demented.\nBased on the outputs of this confusion matrix, we primarily focused on accuracy. Accuracy provides a straightforward measure of the classifier's overall correctness by combining the rates of TP and TN against the total number of cases, as shown in (17).\nAccuracy =$\\frac{TP+TN}{TP+TN+FP+FN}$\nIn addition to accuracy, we will also employ sensitivity and specificity to assess the model's performance. These metrics help in evaluating the effectiveness of the classifier in identifying demented patients (sensitivity) (18) and non-demented patients (specificity) (19) accurately.\nSensitivity =$\\frac{TP}{TP + FN}$"}, {"title": "C. RESULTS", "content": "The training of the models was performed using a 5-fold cross-validation approach. For each fold, the model underwent training for 20 epochs, with a focus on monitoring the validation loss. The final evaluation of the models was conducted on a test set comprising 34 patients. Our confidence-based committee system aggregated the predictions from the individual models, taking into account their confidence levels, to arrive at a final diagnosis for each patient. Table 1 presents a concise summary of the accuracy, sensitivity and specificity results for each model, alongside the training times, enhanced with the standard deviation(std) for these metrics, providing insight into the variance observed across the folds."}, {"title": "1) Validation", "content": "To ensure the validity of our findings, we conducted a validation study using an external dataset, specifically the ADNI dataset [10]. The selection criteria for the data from the ADNI dataset were carefully curated to match the specific requirements of the current study and are detailed in Table 3."}, {"title": "4) Confidence-based Committee", "content": "A Confidence-based Committee approach is employed to leverage the predictive strengths of Dem3D ResNet, Dem3D CNN and Dem3D EfficientNet models. This committee operates by analyzing the predictions from each of these models for a given input and selecting the prediction with the highest confidence - \"C\" in (16). As mentioned, confidence is derived from the softmax function applied to the models outputs, indicating the models certainty in their decisions.\nPred= max($C_{Dem3D ResNet}$, $C_{Dem3D CNN}$, $C_{Dem3D EfficientNet}$)"}, {"title": "V. CONCLUSION", "content": "This study successfully introduced a novel methodology for the binary classification of demented and non-demented patients using 3D brain MRI scans, achieving a notable milestone with an average accuracy of 94.12% on the combination of OASIS1 and OASIS2 datasets. The heart of this achievement lies in the confidence-based classification committee, a harmonious integration of three distinct models\u2014Dem3D ResNet, Dem3D CNN, and Dem3D EfficientNet. This methodology not only enhanced the accuracy of dementia diagnosis but also notably reduced the computational load, thereby marking a step forward in the practical application of AI in clinical settings. The approach of selectively processing MRI scans to focus on the most pertinent data further underscores the innovative angle of this research.\nIn summary, while this study marks a substantial advancement in the field of dementia diagnosis through AI and machine learning, it also opens a gateway to numerous possibilities for future research. These avenues, ranging from technical enhancements to ethical considerations, promise not only to refine the methodology presented but also to contribute substantially to the broader landscape of healthcare and patient management."}]}