{"title": "Embodied AI in Mobile Robots: Coverage Path Planning with Large Language Models", "authors": ["Xiangrui Kong", "Wenxiao Zhang", "Jin Hong", "Thomas Braunl"], "abstract": "In recent years, Large Language Models (LLMs) have demonstrated remarkable capabilities in understanding and solving mathematical problems, leading to advancements in various fields. We propose an LLM-embodied path planning framework for mobile agents, focusing on solving high-level coverage path planning issues and low-level control. Our proposed multi-layer architecture uses prompted LLMs in the path planning phase and integrates them with the mobile agents' low-level actuators. To evaluate the performance of various LLMs, we propose a coverage-weighted path planning metric to assess the performance of the embodied models. Our experiments show that the proposed framework improves LLMs' spatial inference abilities. We demonstrate that the proposed multi-layer framework significantly enhances the efficiency and accuracy of these tasks by leveraging the natural language understanding and generative capabilities of LLMs. Our experiments show that this framework can improve LLMs' 2D plane reasoning abilities and complete coverage path planning tasks. We also tested three LLM kernels: gpt-4o, gemini-1.5-flash, and claude-3.5-sonnet. The experimental results show that claude-3.5 can complete the coverage planning task in different scenarios, and its indicators are better than those of the other models.", "sections": [{"title": "I. INTRODUCTION", "content": "The application of Large Language Models (LLMs) has grown exponentially, revolutionizing various fields with their advanced capabilities [1]. Modern LLMs have evolved to perform various tasks beyond natural language processing. When integrated into mobile agents, these LLMs can interact with the environment and perform tasks without the need for explicitly coded policies or additional model training. This capability leverages the extensive pre-training of LLMs, enabling them to generalize across tasks and adapt to new situations based on their understanding of natural language instructions and contextual cues.\nEmbodied AI refers to artificial intelligence systems integrated into physical entities, such as mobile robots, that interact with the environment through sensors and actuators [2]. The integration of LLMs with embodied AI in applications such as autonomous driving [3] and humanoid robots [4] demonstrates their potential. However, the application of LLMs in controlling mobile robots remains challenging due to issues such as end-to-end control gaps, hallucinations, and path planning inefficiencies. LLMs possess the capability to solve mathematical problems, which directly aids in path planning methods [5].\nPath planning and obstacle avoidance are critical for the effective operation of mobile robots, ensuring safe and efficient navigation in dynamic environments [6]. Coverage path planning is a typical method employed in various research areas, such as ocean seabed mapping [7], terrain reconstruction [8], and lawn mowing [9]. Traditional path planning methods include algorithms such as A* [10], D* [11], and potential field methods [12]. Given a global map, a path-planning method can be framed as a mathematical problem solvable by LLMs. In this context, we simplify some traditional path-planning methods and test LLMs in our mobile robot simulator. LLMS demonstrate their ability to solve mathematical problems collaboratively [13].\nThis paper presents a multi-layer coverage path planner based on existing multimodal large language models. It involves the static low-dimensional deconstruction of unstructured maps, abstracting spatial relationships into mathematical problems for reasoning and solving by prompted LLMs. The reasoning accuracy of the LLM is enhanced through multi-turn dialogues and multimodal interactions. The inferred results from the LLM are combined with the control interface, enabling the mobile agent to control the robot in real time for path planning. Simulation experiments demonstrate that LLMs possess path-planning capabilities in unstructured static maps."}, {"title": "II. RELATED WORKS", "content": "Currently, LLMs are involved in various aspects of mobile robots, including code writing, model training, action interpretation, and task planning. LLMs can process new commands and autonomously re-compose API calls to generate new policy code by chaining classic logic structures and referencing third-party libraries [14]. LLMs have also been used to automatically generate reward algorithms for training robots to learn tasks such as pen spinning [15]. PaLM-E, an embodied language model trained on multi-modal sentences combining visual, state estimation, and textual input encodings, demonstrates the versatility and positive transfer across diverse embodied reasoning tasks, observation modalities, and embodiments [16]. LLMs have shown promise in processing and analyzing massive datasets, enabling them to uncover patterns, forecast future occurrences, and identify abnormal behaviour in a wide range of fields [17]. VELMA is an embodied LLM agent that generates the next action based on a contextual prompt consisting of a verbalized trajectory and visual observations of the environment [18]. Sharma et al. propose a method for using natural language sentences to transform cost functions, enabling users to correct goals, update robot motions, and recover from planning errors, demonstrating high success rates in simulated and real-world environments [19].\nThere is also some research applying LLMs in zero-shot path planning. The 3P-LLM framework highlights the superiority of the GPT-3.5-turbo chatbot in providing real-time, adaptive, and accurate path-planning algorithms compared to state-of-the-art methods like Rapidly Exploring Random Tree (RRT) and A* in various simulated scenarios [20]. Singh et al. describe a programmatic LLM prompt structure that enables the generation of plans functional across different situated environments, robot capabilities, and tasks [21]. Luo et al. demonstrate the integration of a sampling-based planner, RRT, with a deep network structured according to the parse of a complex command, enabling robots to learn to follow natural language commands in a continuous configuration space [22]. ReAct utilizes LLMs to generate interleaved reasoning traces and task-specific actions [23]. These methods typically use LLMs to replace certain components of mobile robots. The development of a hot-swapping path-planning framework centred around LLMs is still in its early stages."}, {"title": "B. Path planning method", "content": "Path planning for mobile robots involves determining a path from a starting point to a destination on a known static map"}, {"title": "III. METHODOLOGY", "content": "As depicted in Figure 1, our method is divided into three main sections: global planning, waypoint evaluation, and navigation. In global planning phase, a coverage planning task in a given map is decomposed into a cell map, and the additional requirement is designed using natural language with a simplified format to decompose LLM responses. During the waypoint evaluation phase, the LLM responses are further evaluated before execution. The theoretical coverage rate and the theoretical shortest path distance are calculated in this phase. Once the desired path passes the evaluation, the planned"}, {"title": "A. Global planning", "content": "We design a waypoint generation prompt with natural language describing 2D grid maps like a chessboard to simplify the inference difficulty of LLMs. During the global phase, a prompt contains the size of the grid map, current location, and response format. We assume the LLM generates the desired waypoint list with a required format which is a local position sequence separated with a bar sign. In order to evaluate the performance and excitability of the planned path, the desired waypoint list is visualised and calculated in the phrase of waypoint evaluation. Considering the robot's kinematic limitation, we prompt a description of mobile agents including equipped sensors, driving commands, and basic status. We experimented with various settings to describe robot behaviors in conversations with ChatGPT. However, we observed that these changes in description had minimal impact on the output responses. We use OpenAI GPT-40 services [34], a multimodal efficient model for inference and reasoning. The temperature parameter with the range from 0 to 2 is set as 0.6 with our prompt for a consistent planned path. Lower values for temperature result in more consistent outputs, while higher values generate more diverse and creative results."}, {"title": "B. Waypoint evaluation", "content": "The response from the LLMs can occasionally be incorrect, leading us to design a waypoint evaluator to mitigate hallucinations. Initially, the desired waypoint list is visualized on a 2D map, providing a clear and precise layout of the proposed route. The shortest path and the number of turns are then calculated mathematically to ensure efficiency and feasibility. Paths that do not meet the required criteria are"}, {"title": "C. Waypoint navigation", "content": "After evaluating the waypoint list, the mobile agent begins to iterate through the waypoints. Due to potential sensor errors and the intricacies of the path-following method, it is essential for the mobile agent to appropriately select the following method. Simple waypoint following methods such as the dog curve and turn-and-drive can be employed to navigate the waypoints with a fixed distance. These methods enable the mobile agent to follow the sequence of waypoints with smooth and accurate navigation along the route.\nIn our approach, we decompose this procedure using a status transform matrix that maps the next driving command based on the current heading, current position, and the next waypoint. This matrix allows for dynamic adjustment and precise control during navigation. Additionally, the designed safety system ensures the execution is safe by preventing collisions with"}, {"title": "IV. EXPERIMENTAL SETUP", "content": "This framework has been implemented on EyeBot simulator [35]. The EyeBot simulator with virtual reality EyeSim VR is a multiple mobile robot simulator with VR functionality based on game engine Unity 3D that allows experiments with the same unchanged EyeBot programs that run on the real robots. We adjust the environmental values based on the task map from 5 \u00d7 5 to 11 \u00d7 11. In each map, the mobile agent is at a random starting position and runs the proposed method in 10 episodes, and all performance metrics are averaged. Three large language models are evaluated in the experiment including gpt-4o, gemini-1.5-flash and claude-3.5-sonnet with the same system prompt and default temperature shown in Figure 1."}, {"title": "B. Metrics", "content": "We referenced the metrics from [36] and [37], including success rate, average distance, and coverage rate. The success rate indicates whether the paths generated by LLMs can cover the designated area. Average distance represents the average path length of the mobile robot, while coverage rate is a metric specific to coverage methods, used to assess the completeness of coverage path planning algorithms.\nIn traditional navigation evaluation standards, task termination is determined by the distance between the agent and the target point, which is effective for path planning problems with clearly defined start and end points. However, for coverage path planning algorithms, the generated paths do not have a clear endpoint, and the coverage path is autonomously decided"}, {"title": "C. Results and analysis", "content": "The performance and time analysis are shown in Table I and Table II. All three models demonstrate the ability to plan a coverage path in a square space with a random start position. However, as the map size increases, the coverage rate decreases by approximately 5% to 10%, though all models maintain a coverage rate above 65%. As shown in Table I, the model claude-3.5-sonnet exhibits the best performance among the three models in terms of coverage rate and weighted path length. Changes in map size do not significantly affect the coverage rate and weighted path for the model gemini-1.5-flash. Conversely, the model gpt-4o achieves a higher coverage rate with smaller map sizes, but this rate decreases as the map size increases. As the map size grows, the actual path length increases more rapidly than the weighted path length, indicating that the planned paths include repeated visits to the same cells based on the random start position.\nThe differences in path length are attributed to the coverage rate of the planned path and the mobile agent's hardware capabilities, such as sensors and actuators. Since the evaluation processes locally with a short time cost (less than 300ms), we sum the inference time and the evaluation time as $T$. $T_i$ and $T_a$ represent the total time spent and the driving part time cost, respectively.\nModel claude-3.5-sonnet performs best and exhibits the fastest inference time in the experiment, planning fully coverage waypoints in various environments. Model gpt-4o shows stable"}, {"title": "V. DISCUSSION", "content": "We propose a novel embodied framework for mobile agents, incorporating weighted evaluation metrics for the specific task of coverage path planning. A key factor of the framework is the use of zero-shot prompts to simplify LLM inference during the initial phase. This approach leverages the power of LLMs to generate effective waypoints without the need for extensive training data, thus streamlining the path-planning process. During the navigation phase, we introduced a robust safety mechanism for mobile agents to avoid obstacles. This mechanism ensures that the mobile agents can navigate safely and efficiently in dynamic environments. Our experiments demonstrate that current LLMs have the capability to function as an embodied AI brain within mobile agents for specific tasks, such as area coverage, when guided by appropriately designed prompts.\nThe competition among LLM companies has significantly advanced the field, freeing researchers from the traditional labelling-training-validation loop in AI research. This shift allows for more focus on innovative applications and real-world deployment of AI technologies. Future research will"}]}