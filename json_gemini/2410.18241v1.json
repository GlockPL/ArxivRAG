{"title": "CHARACTERISING OPEN SOURCE CO-OPETITION IN COMPANY-HOSTED OPEN SOURCE SOFTWARE PROJECTS: THE CASES OF PYTORCH, TENSORFLOW, AND TRANSFORMERS", "authors": ["Cailean Osborne", "Farbod Daneshyan", "Runzhi He", "Hengzhi Ye", "Yuxia Zhang", "Minghui Zhou"], "abstract": "Companies, including market rivals, have long collaborated on the development of open source software (OSS), resulting in a tangle of co-operation and competition known as \u201copen source co-opetition\". While prior work investigates open source co-opetition in OSS projects that are hosted by vendor-neutral foundations, we have a limited understanding thereof in OSS projects that are hosted and governed by one company. Given their prevalence, it is timely to investigate open source co-opetition in such contexts. Towards this end, we conduct a mixed-methods analysis of three company-hosted OSS projects in the artificial intelligence (AI) industry: Meta's PyTorch (prior to its donation to the Linux Foundation), Google's TensorFlow, and Hugging Face's Transformers. We contribute three key findings. First, while the projects exhibit similar code authorship patterns between host and external companies (~80%/20% of commits), collaborations are structured differently (e.g., decentralised vs. hub-and-spoke networks). Second, host and external companies engage in strategic, non-strategic, and contractual collaborations, with varying incentives and collaboration practices. Some of the observed collaborations are specific to the AI industry (e.g., hardware-software optimizations or AI model integrations), while others are typical of the broader software industry (e.g., bug fixing or task outsourcing). Third, single-vendor governance creates a power imbalance that influences open source co-opetition practices and possibilities, from the host company's singular decision-making power (e.g., the risk of license change) to their community involvement strategy (e.g., from over-control to over-delegation). We conclude with recommendations for future research.", "sections": [{"title": "1 Introduction", "content": "Companies have participated in the collaborative development of open source software (OSS) since the late 1990s [1], capitalising on a myriad of benefits, from lower development costs [2, 3] to open standards and interoperability [4, 5]. With the increasing prevalence of commercial participation in OSS development, Computer-Supported Cooperative Work (CSCW) researchers have been encouraged to investigate the incentives, roles, and effects of such commercial activity on the norms, practices, and future trajectories of OSS developer communities [6]. Within this field of research, one line of inquiry focuses on why and how companies collaboratively develop OSS [7, 8], including market rivals and companies that are engaged in patent wars against each other [9, 10]. The term \u201copen source co-opetition\" has been coined to convey this tangle of co-operation and competition between companies [11]. To date, prior work on open source co-opetition primarily focuses on projects that are hosted by vendor-neutral foundations, such as the OpenStack Foundation\u00b2 [12, 13, 9], Linux Foundation (LF) [7], Apache Software Foundation [14], and Eclipse Foundation [15]. Yet due to their vendor-neutrality, foundations play a structural role in enabling collaboration between \u201cunexpected allies\" [16, 7], limiting the generalisability of prior work to OSS projects that lack such vendor-neutral governance, such as ones that are initiated, hosted, and governed by one company (henceforth: company-hosted OSS projects).\nGiven the prevalence and impact of company-hosted OSS project across software domains and industries, from web development [21] to artificial intelligence (AI) [22, 23], it is timely to address this research gap and advance our understanding of open source co-opetition in projects with different governance models. We address this research gap through a mixed-methods analysis of open source co-opetition in three company-hosted OSS projects in the AI industry: Meta's PyTorch prior to its donation to the LF, Google's TensorFlow, and Hugging Face's (HF) Transformers. We examine three targeted research questions (RQ), guided by the objective of extending theory on open source co-opetition strategies and practices to the context of company-hosted OSS projects. First, through repository mining and social network analysis (SNA), we investigate (RQ1) patterns of co-opetition, providing a baseline understanding of commonalities and differences between the three cases. Subsequently, through 10 semi-structured interviews, we investigate (RQ2) the types of collaborative relationships that host and external companies pursue and why, as well as (RQ3) what similarities and differences characterise open source co-opetition practices in company-hosted OSS projects compared to foundation-hosted projects, as identified by prior work.\nWe make three key contributions to the literature on open source co-opetition. First, while code authorship patterns by host and external companies are consistent across the projects over time (e.g., ~80%/20% of commits respectively), we observe varying structures of collaboration between companies on project files (e.g., decentralised vs. hub-and-spoke networks). Second, we identify and characterise three distinct relationship types between host and external companies: strategic, non-strategic, and contractual collaborations. Each type differs in the relevance of business strategy, competitive dynamics, and personal incentives for the involved developers. Some of the observed collaborations are specific to the technology and competitive dynamics in AI industry (e.g., hardware-software optimization or AI model integrations), while others are typical of the broader software industry (e.g., bug fixing, code adoption for increased impact, and outsourcing of development). Third, single-vendor governance in company-hosted OSS projects introduces a power imbalance that influences open source co-opetition practices and possibilities, from the host's singular decision-making authority (e.g., the risk of license changes) to their community involvement strategy (e.g., from over-control to over-delegation)."}, {"title": "2 Related Work", "content": ""}, {"title": "2.1 Commercial participation in OSS development", "content": "Companies have collaborated on OSS development since the 1990s [1]. The last decade, in particular, has seen a \u201crapid acceleration of corporate engagement with open source\" [6], leading to what scholars have called \u201cthe incorporation of the digital commons\u201d [3] or the emergence of a \"commons of capital\" [24]. In light of these developments, CSCW researchers have been encouraged to investigate the incentives, roles, and effects of commercial activity [6].\nCompanies participate in OSS development in various ways, which can be broadly categorised into three models: supporting, collaborating, and hosting OSS [17]. In the supporting model, a company assists an independently hosted project. This may include by deploying developers [25], funding maintainers or the project [26], or joining project steering committees [27], among others. The collaborating model involves multiple organisations sharing control over the project's intellectual property. In the AI industry, this was exemplified by the joint release of the Open Neural Network Exchange (ONNX) by Facebook and Microsoft in 2017, which focused on facilitating interoperability between multiple deep learning frameworks [28]. In the hosting model, a single company exercises full control over a project's governance [29] and intellectual property [17], achieved by employing the maintainers [18] and often requiring contributors to sign contributor license agreements (CLA) [17], among others. For this reason, O'Mahony [18] refers to such projects as \"company-managed projects\" to underline that they are not \"initiated and managed by a distributed group of individuals who do not share a common employer\" [18]. Companies spin-out proprietary software projects into company-hosted OSS projects in order to increase adoption of the software, to benefit from external contributions, or to reduce a competitor's market share [19].\nIn company-hosted OSS projects, companies take different approaches to project governance and community involve-ment in line with their strategic goals [17]. While some companies maintain complete control of their project, which \u201cresembles proprietary development conducted within a glass house\u201d, others strive to attract contributors, which involves significant investment into community development [19]. However, no matter how many resources a company may invest in its project, it is not guaranteed that a company can successfully build and retain a community of contributors in such projects because they are dominated by the company and lack aspects that attract external contributors, such as open community governance or a meritocratic culture [23, 29]. What is more, contributors may be suspicious of projects that \"are viewed as transfers to the community to maintain code as opposed to collaborative partnerships\" [19]. Prior work also shows that the incentives and types of contributions to company-hosted OSS projects tend to be needs-based, compared to a combination of hobbyist and needs-based contributions by contributors to OSS projects that are led and governed by a community [30].\nCompanies have diverse incentives for participating in OSS development, which differ from the primarily intrinsic motivations of volunteer contributors [31, 32]. These incentives encompass both strategic and social benefits. Strategic incentives include reducing development costs [3, 33], influencing open standards [34, 35], and recruiting software engineers [36, 34]. Companies also seek vendor independence [37, 35], faster time to market [38, 37], and enhanced market competitiveness [39, 40]. Social incentives involve reciprocating to the OSS ecosystem [41, 42] and improving corporate reputation as an OSS patron [43, 26]. Additionally, companies benefit from OSS adoption through cost savings, faster development speeds, and improved interoperability [37].\nThese diverse incentives highlight the multifaceted nature of commercial participation in OSS development. However, the collaborative nature of OSS development often leads to scenarios where companies, including market rivals, work together in OSS projects. This phenomenon, known as \u201copen source co-opetition\u201d [11], represents a unique intersection of co-operation and competition in the OSS context. In the following section, we delve deeper into the concept of open source co-opetition, exploring its definition, manifestations, and the current state of research in this area."}, {"title": "2.2 Open source co-opetition: Definition and Prior Work", "content": "It is commonplace for companies to collaboratively develop OSS [44]. As a result, many OSS communities have evolved \u201cfrom networks of individuals to networks of companies\u201d [36]. \u201cOpen-source co-opetition\u201d has been coined to convey the tangle of co-operation and competition between companies in the OSS context [11], drawing on the \u201cco-opetition\" concept from the management science literature [45, 46], which contends that companies, which might be market rivals or even engaged in patent wars, form strategic alliances in areas that far from the customer, such as in research and development (R&D) in the high-technology sector [47, 46], whilst competing on revenue-generating products and services [48]. These alliances are known as \u201caccess relationships\" that provide access to the resources of other companies [49, 50], to facilitate learning [51, 52], and tp enable companies to improve their market position [53, 54] and shape industry standards [55, 56]. These alliances often create strategic interdependencies between companies [46].\nScholars have adopted this framework to investigate strategies and practices of inter-company collaboration in OSS development, both at the level of individual developers and companies [57, 9]. At the developer level, prior work finds that open source co-opetition is collaboration-focused; for example, company-affiliated developers report little interest in which companies other contributors work for and typically view contributors from other companies as their peers [57]. Furthermore, collaboration is characterised by low affiliation-based homophily, with frequent inter-company collaboration in OSS projects [13]. Prior work also identifies two mechanisms of competition at the individual developer level. First, while multiple developers from a company may contribute to an OSS project, there is typically a gatekeeper-which may be one developer or a handful of developers-who coordinates a company's strategy, files issue reports, submits pull requests (PRs), and manages information flows [58, 10]. The gatekeeper has the authority to decide what information or code the company will share with the project, and therefore acts as a key lever for companies to engage in co-operative and competitive interactions simultaneously [58, 57]. Second, the fork provides developers with the option to deviate at any time to pursue their own strategic goals or if they are not content with the direction of the project [44]. The threat of the fork also encourages dominant contributors to appease and retain other contributors [44].\nAt the company-level, a study on the OpenStack ecosystem found that companies engage in intentional, passive, and isolated collaborations [8]. Intentional collaborations are collaborations between companies that have a market relation-ship, such as the supply and consumption of OpenStack software or or service provision [8]. Passive collaborations occur when companies contribute to the same project without explicit coordination, while isolated collaborations take place when a company contributes to a project alone [8]. Another study found that companies that share the same revenue model, such as offering complementary software or hardware, collaborated more than those with different revenue models in the OpenStack ecosystem [13].\nPrior work on open source co-opetition is primarily limited to OSS projects that are hosted by vendor-neutral foundations, including the OpenStack Foundation [12, 13, 9], LF [7], Apache Software Foundation [14], and Eclipse Foundation [15]. However, foundation-hosted projects have key characteristics that threaten the generalisability of prior findings to other project hosting and governance models. Through their vendor-neutrality and open governance, foundations operate as \"boundary organisations\u201d that foster collaboration between diverse contributors, including volunteers and for-profit companies [16]. They are reputed to foster \u201ccommunities of competitors,\u201d where \u201cmarket rivals...intentionally coordinate activities for mutual benefit in precise, market-focused, non-differentiating engagements\u201d [7]. We note that foundation-hosted projects do not shield projects from the dominance of a single company [15, 12]. For example, 10% of companies contribute 80% of commits and 20% of companies employ 80% of the contributors in the OpenStack ecosystem [12]. Furthermore, IBM continued to dominate OSS projects hosted in the Eclipse ecosystem long after it established the Eclipse Foundation [15]. Commercial dominance can have negative consequences for the participation of volunteers [17], which in part is due to the concern of performing free labour for the dominant company [59].\nBeyond OSS projects that are hosted by vendor-neutral foundations, we have a limited understanding of open source co-opetition in OSS projects with different hosting models, such as OSS projects that are initiated, hosted, and governed by one company. To date, only two case studies have investigated open source co-opetition in such scenarios. A network analysis of collaboration in Google's Android simply highlights the dominance of Google developers as well as non-trivial contributions from its market rival Apple [60], while a study on Apple's WebKit demonstrates the methodological utility of temporal network visualisations for observing evolving collaborations between companies [44]. However, these studies fail to investigate open source co-opetition strategies and practices, nor do they consider how different governance approaches taken by host companies influence strategies and practices, from those that maintain control of development [17] to those that adopt a more community-oriented approach [19]. Given the prevalence and impact of company-hosted OSS projects across the software industry, it is timely to investigate the strategies and practices of open source co-opetition in such contexts, and ultimately to advance our understanding of the nature and impact of commercial participation in OSS development [6]."}, {"title": "3 Study Design", "content": ""}, {"title": "3.1 Research objectives and research questions", "content": "Our research objectives are two-fold: first, we seek to test prior theory on open source co-opetition practices in the context of company-hosted OSS projects; and second, to identify and characterise co-opetition practices that are unique to company-hosted OSS projects. Underlying these objectives is our motivating RQ: How do companies co-operate on OSS development when a project is hosted and governed by a single company? We operationalise this motivating RQ by asking three targeted RQs, which we examine through a sequential, mixed-methods analysis of three case studies. First, through repository mining and SNA, we seek to understand (RQ1) typical patterns, if any, of open source co-opetition in company-hosted OSS projects, providing a baseline understanding commonalities and differences between the cases [61]. Subsequently, through 10 semi-structured interviews with company-affiliated contributors to the three projects, we seek to identify and characterise (RQ2) different types of collaborative relationships between host and external companies and their motivations, as well as (RQ3) the similarities and differences that characterise open source co-opetition in company-hosted OSS projects compared to foundation-hosted projects. This research design enables the testing of prior theory with mixed-methods findings from multiple cases [61, 62], and enhances the convergence validity of the findings [63, 64]. Ethical clearance was obtained from the relevant institutional review board by the primary author prior to the commencement of this research project."}, {"title": "3.2 Multiple case study research design", "content": ""}, {"title": "3.2.1 Case selection", "content": "We employed a four-step strategy to select cases. First, we defined the selection criteria: OSS projects had to be hosted by a company, involve external companies, and undergo active maintenance. Second, we selected the AI industry as the boundaries for case selection due to evidence of commercial investments [65, 66] and involvement in the development of OSS [22, 26, 23] and open-weight models [67, 68]. Third, we prepared a \u201cstarting list\u201d of company-hosted OSS projects by downloading a database of over 300 OSS projects from the LF AI & Data Foundation's website [69]. We removed data projects, resulting in 184 AI OSS projects. Fourth, we labelled projects according to the type of its hosting organisation (company, foundation, or university) and sorted the projects by the size of their contributor community. Then, we selected the three top-ranked projects in descending order: Google's TensorFlow, Meta's PyTorch, and HF's Transformers. Given Meta's donation of PyTorch to the Linux Foundation in September 2022 [23], we limited data collection to this time point to ensure that all projects were company-hosted throughout the analysis period.\nThe selected cases-PyTorch, TensorFlow, and Transformers\u2014represent different layers of the AI stack. TensorFlow [70] and PyTorch [71] are foundational deep learning frameworks used to train machine learning models, while Transformers [72] provides higher-level APIs for downloading, fine-tuning, and sharing pre-trained models hosted on the HF Hub, a popular platform for hosting and developing AI models and datasets. Given their widespread usage in the AI industry and large contributor communities, they are promising cases for the study of open source co-opetition. In particular, TensorFlow and PyTorch make for interesting comparative cases because Google and Meta have long been in a heated rivalry over industry adoption of their respective deep learning frameworks [73]. Furthermore, the inclusion of Transformers enables a comparative analysis of projects that are hosted by industry giants (i.e., Meta and Google) and start-ups (i.e., HF), thus overcoming the limited focus on OSS projects hosted by industry giants in prior work [44, 60]. We acknowledge the temporal cut-off in September 2022 and focus on popular company-hosted OSS projects with >1,000 contributors as limitations, which we discuss in Section 5."}, {"title": "3.2.2 Case presentation", "content": "We present the cases below (see summary information in Table 1).\nTensorFlow by Google: TensorFlow is an open source deep learning framework that is widely used in academia and industry for creating and training machine learning models [70]. It was started by Google Brain in 2011 to facilitate the use of neural networks in Google research and products [74]. TensorFlow was publicly released in 2015, and TensorFlow 2 was released in 2019. After its initial release, Jeff Dean from Google stated, \u201cWe're hoping that the community adopts this as a good way of expressing machine learning algorithms of lots of different types and contributes to building and improving [TensorFlow] in lots of different and interesting ways\" [75]. Other reported incentives include increasing adoption, benefiting from crowdsourced innovation, and recruitment [76].\nPyTorch by Meta: PyTorch is an open source deep learning framework widely used in academia and industry for training neural networks [71]. It was released in 2016 and maintained by Facebook AI Research at Meta until its donation to the LF's PyTorch Foundation in September 2022 [77]. Mark Zuckerberg, Meta's CEO, has spoken publicly about the benefits that Meta has derived from the popularity of PyTorch in AI R&D, in particular the crowdsourced innovations that developers in the wider PyTorch ecosystem have contributed back to PyTorch, resulting in improvements [78].\nTransformers by HF: Transformers provides APIs and tools to download, fine-tune, and share pre-trained machine learning models hosted on the HF Hub [72]. Transformers is integrated with TensorFlow and PyTorch, but operates at a higher level of the AI stack. It is developed by HF, a start-up, whose mission is to democratise AI by providing accessible tools and resources for researchers and developers. While HF initially developed a chatbot app, it is now better known for the HF Hub, which hosts a fast-growing number of pre-trained models and datasets, and its OSS libraries (e.g., Transformers and Diffusers), which allow researchers and developers to download, modify, and share models and datasets hosted on the HF Hub. In light of the emerging popularity of its tools and the HF Hub, the start-up has raised hundreds of millions of US dollars in investment [79]."}, {"title": "3.3 Software repository mining", "content": ""}, {"title": "3.3.1 Data collection", "content": "We mined data from each repository's commit logs on GitHub in order to analyse code authorship patterns and distributions. Specifically, we obtained historical commit data from each repository via the GitHub REST API, spanning from the date of the first commit in each repository until 12 September 2022, which we set as the data collection cut-off date to count PyTorch as a company-hosted project. Each commit dataset includes per commit: sha, date, name, email address, modified source files, and lines of code (LOC) added, LOC deleted, and LOC changed (net). We acknowledge that while this data collection cut-off date predates major developments in the AI industry, it is defensible given that our study focuses on testing and extending theory on open source co-opetition in company-hosted OSS projects with insights from the AI industry, rather than focusing on trends in the AI industry per se. We discuss this temporal limitation in in Section 5.2."}, {"title": "3.3.2 Username merging", "content": "We merged multiple identities for unique developers, which is a common problem in software engineering research that arises when developers use multiple accounts on GitHub or due to how Git records their local credentials [85, 86, 87, 88]. Following prior work [89], we built two bipartite networks that respectively mapped each username to all previously used corresponding email addresses and each email address to all previously used corresponding usernames. Then, we merged identities based on the linked username-email address pairs and email address-username pairs. For analytical purposes, we created a unique user ID for each developer identity. This resulted in 3,434\u21923,058, 3,964\u21923,564, and 1,479\u21921,392 contributors in the PyTorch, TensorFlow, and Transformers datasets respectively. Three reviewers cross-validated the accuracy of this approach, identifying 6, 3, and 2 errors in respective datasets."}, {"title": "3.3.3 Bots removal", "content": "Following prior work [8, 88, 90], we removed commits by bots from the datasets. Specifically, we dropped 919 (1.78%), 38,503 (28.20%), and 23 (0.22%) commits from the PyTorch, TensorFlow, and Transformers datasets respectively."}, {"title": "3.3.4 Affiliation identification", "content": "Following prior work [8, 91], we applied a semi-automated approach to identify the affiliations of contributors at the time of each commit. We mined affiliations from the email addresses associated with each commit, which is considered the most accurate source of affiliation data [57, 92]. The affiliations of commits with consumer email addresses, identified using a publicly available list [93, 94], or no email addresses, were left blank. This identified the affiliations of 37.0%, 48.9%, and 9.2% of contributors in the PyTorch, TensorFlow, and Transformers datasets respectively. We discuss the divergence in affiliation identification per project in Section 5.2.\nFor contributors with missing affiliations, we mined affiliations from users' GitHub profiles. To address data quality concerns (e.g., self-reported affiliations are not time-sensitive to activity), three authors cross-validated affiliation data for contributors with 5 or more commits, and manually labelled missing values through Internet searches. We filtered out contributors who had submitted less than 5 commits to limit the analysis to contributors who met a minimum activity threshold and to reduce data labelling burden. Contributors who did not work for a company were recorded as \"volunteers\" and unidentifiable affiliations were recorded as \"unknown.\" When contributors used both company and private email addresses, we linked all commits to their company affiliation.\nThree authors reviewed 100 randomly sampled commits from each project to estimate agreement in the manual labelling. We found 5 inconsistencies, indicating 98.3% agreement. We could not cross-validate the entire dataset due to resource constraints, as finding the affiliation(s) of one contributor took up to 10 minutes. We further evaluated the accuracy of the automated approach against the manually validated ground truth, finding the automated approach had labelled 83.9%, 92.0%, and 39.5% of commits correctly for PyTorch, TensorFlow, and Transformers respectively."}, {"title": "3.3.5 Descriptive analysis", "content": "We report the provenance of commits per affiliation type in Figure 1; the dominance of host companies in Table 3; and the relative contributions of the top ten companies per project in Tables 4-6."}, {"title": "3.4 Social network analysis", "content": ""}, {"title": "3.4.1 Operationalising collaboration", "content": "We employed SNA to investigate open source co-opetition, drawing on prior prior that used SNA to study collaboration among individual developers [95, 85, 96, 97, 98] and companies [14, 99, 100, 9, 8]. While some prior work has operationalise collaboration as discussions in issue trackers [57, 9, 14], we operationalised collaboration as commits made by a pair of contributors to the same file during a release cycle. We did this for two reasons. First, commits represent an accurate, timestamped audit trail of code authorship [60, 8]; and second, examining interactions on code authorship per release enables longitudinal analysis of collaborations [101, 9, 14]. The second step concerned the choice of the unit of analysis. Since this study is concerned with co-opetition between companies, we chose the company as the unit of analysis, following prior work [58, 9, 8]. However, we acknowledge that the aggregation to the company level loses crucial information about the activity of individual developers [25, 102]."}, {"title": "3.4.2 Network construction", "content": "We recorded directed edges between pairs of contributors, who had contributed to the same file(s) during a release cycle, with edges weights corresponding to LOC changed in said file(s) by the respective contributor. For example, if contributor A modified 5 LOC in file F and contributor B modified 6 LOC in file F during the same release, the edge weights for A->B and B->A would be 5 and 6 respectively. The directed networks can therefore be formally represented as \\(G = (C, A_c, E, W_{ij})\\), where C is the set of developers, E is the set of edges, \\(A_c\\) is the set of node attributes, and \\(W_{ij}\\) is the edge weight. We aggregated the release networks into annual snapshots to enable comparative analysis [103]. Next, we assigned unique user IDs to nodes and excluded bots to limit the network to human-to-human collaboration. Then, we constructed company networks by merging developer nodes with the same affiliation, combining their edges, and summing their edge weights. We filtered out nodes with \u201cvolunteer\" or \"unknown\" affiliations."}, {"title": "3.4.3 Network analysis", "content": "We performed the network analysis in three steps. First, we measured three kinds of network centrality to understand different aspects about companies' roles in the collaboration networks (see Tables 4-6). Specifically, out-degree indicates a company's breadth of collaborations [104], PageRank suggests its global importance [105], and betweenness centrality reflects its brokerage role [106]. Second, we visualised annual network snapshots to observe changes in the collaboration relationships between companies [44] and the role of individual companies [99]. For readability, we filtered the networks to the 20 nodes with the highest degree centrality (Figure 2). Third, to account for network size effects in the former steps, we analysed three size-independent metrics of the complete networks over time (see Tables 7-9). Specifically, degree centralisation measures how much the network structure is organised around focal nodes [107]; degree skew indicates the asymmetry of the degree distribution, helping to identify the presence of hubs [108]; and the clustering coefficient quantifies the tendency of nodes to cluster together, helping to identify the presence of tightly-knit communities of collaborating companies [109]."}, {"title": "3.5 Semi-structured interviews", "content": ""}, {"title": "3.5.1 Interviewee sampling", "content": "We recruited 10 company-affiliated contributors for interviews (see Table 2). Our sampling approach involved sending interview invitations to a subset of company-affiliated developers, who were not affiliated with the respective host company [57]. In exchange for their time, we offered to donate 15 USD to a project of their choice. In total, we sent 350 emails to 150 TensorFlow contributors, 150 PyTorch contributors, and 50 Transformers contributors. We sent fewer emails to Transformers contributors due to less company-affiliated contributors in this project. We received 13 responses (3.71%) and 10 acceptances (2.86%)."}, {"title": "3.5.2 Semi-structured interviews", "content": "We conducted 10 digital, semi-structured interviews, which lasted between 30 and 60 minutes. The semi-structured interviews followed an interview guide with five topics: their personal and employer's incentives; their individual and employer's contribution strategies, if any; their experience of collaborating with developers employed by the host company and/or other companies; a discussion of the quantitative findings; and their views on the unique aspects of open source co-opetition in company-hosted OSS projects. During the interviews, we showed the network visualisations to the respondents in order to elicit responses about the evolving relationships between companies in the three projects [110, 111, 112]. Specifically, we asked respondents to identify collaborations between companies that they were aware of, to explain their understanding of the nature and incentives for these collaborations, and to comment on changes in collaborations between companies as shown in the network visualisations (see Figure 2)."}, {"title": "3.5.3 Thematic analysis", "content": "We analysed the interview data following a systematic six-step procedure for thematic analysis; that is, the identification, analysis, and reporting of themes in qualitative data [113]. We adopted an integrated approach to code and identify themes in the interview data, combining deductive and inductive methods [114]. In particular, we used key findings from prior work as initial categories for the deductive coding, whilst inductively coding the interview data following grounded theory approaches to capture novel themes [115]. This combination enabled us to both test prior theory and uncover new findings. The first author performed the initial coding until reaching saturation [115]. A second author validated the codes to enhance the reliability of the analysis, and subsequently the codes were merged into themes [116]. Finally, we member-checked themes with respondents to ensure accuracy and practical relevance [116]. When we quote respondents in Section 4, we identify them with their ID from Table 2 and mention their project(s) in abbreviated form in brackets (PT for PyTorch, TF for TensorFlow, and TR for Transformers)."}, {"title": "4 Results", "content": ""}, {"title": "4.1 RQ1: What, if any, are typical patterns of open source co-opetition in company-hosted OSS projects?", "content": ""}, {"title": "Key findings", "content": "The three projects reveal similar patterns of code authorship between host and external companies, yet distinct structures of collaboration. In each project, the host and external companies account for ~80% and 20% of commits respectively. PyTorch and TensorFlow have decentralised network structures with lower degree centralisation, lower degree skew, and higher clustering coefficients, indicating strong inter-connections between companies. By contrast, Transformers has a hub-and-spoke network structure with higher degree centralisation and lower clustering, underlining HF's broker role between external companies."}, {"title": "4.1.1 Distribution of code authorship by host and external companies", "content": "Host companies are dominant in their respective projects by several metrics (see Table 3). Meta, Google, and HF employ 61.25%, 47.61%, and 32.18% of contributors to their respective projects. These percentages increase in the maximal k-cores of the annual network snapshots, indicating the host companies' control over core development. For example, in the 2022 network snapshots, 31%, 50%, and 9% of contributors to PyTorch, TensorFlow, and Transformers respectively were affiliated to the host company, rising to 42%, 68%, and 38% in the network cores. Host company employees account for approximately 80% of annual commits, while external companies contribute 10-20% of annual commits (Figure 1). The Pareto principle is evident in each project, with less than 20% of contributors responsible for more than 80% of commits. Transformers has the most imbalanced authorship, with 7.54% of contributors making 80% of commits, and has a low bus factor due to most commit activity coming from a few highly active contributors."}, {"title": "4.1.2 Collaboration Networks: Centralised vs Decentralised Collaboration", "content": "We observe distinct patterns of collaboration across the three projects, with PyTorch and TensorFlow exhibiting decentralised structures despite dominant code authorship by the host companies, while Transformers shows a hub-and-spoke structure. In PyTorch, while Meta contributes the majority of commits (84%) and lines of code (84%), many commits are from Nvidia, Intel, AMD, and Google (see Table 4). Similarly, in TensorFlow, Google dominates in commits (85%) but contributes a smaller share of lines of code (34%), with significant contributions from Nvidia, Intel, and IBM, among others (see Table 5). Despite this concentration of authorship, external companies have high out-degree centrality values in both projects, indicating active collaboration on project files among these companies. However, Transformers presents a contrasting picture. HF not only dominates in code authorship (91% of commits, 94% of lines of code) but also in"}]}