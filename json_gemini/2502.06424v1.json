{"title": "CS-SHAP: EXTENDING SHAP TO CYCLIC-SPECTRAL DOMAIN\nFOR BETTER INTERPRETABILITY OF INTELLIGENT FAULT\nDIAGNOSIS", "authors": ["Qian Chen", "Xingjian Dong", "Kui Hu", "Kangkang Chen", "Zhike Peng", "Guang Meng"], "abstract": "Neural networks (NNs), with their powerful nonlinear mapping and end-to-end capabilities, are\nwidely applied in mechanical intelligent fault diagnosis (IFD). However, as typical black-box mod-\nels, they pose challenges in understanding their decision basis and logic, limiting their deployment\nin high-reliability scenarios. Hence, various methods have been proposed to enhance the inter-\npretability of IFD. Among these, post-hoc approaches can provide explanations without changing\nmodel architecture, preserving its flexibility and scalability. However, existing post-hoc methods\noften suffer from limitations in explanation forms. They either require preprocessing that disrupts\nthe end-to-end nature or overlook fault mechanisms, leading to suboptimal explanations. To address\nthese issues, we derived the cyclic-spectral (CS) transform and proposed the CS-SHAP by extend-\ning Shapley additive explanations (SHAP) to the CS domain. CS-SHAP can evaluate contributions\nfrom both carrier and modulation frequencies, aligning more closely with fault mechanisms and de-\nlivering clearer and more accurate explanations. Three datasets are utilized to validate the superior\ninterpretability of CS-SHAP, ensuring its correctness, reproducibility, and practical performance.\nWith open-source code and outstanding interpretability, CS-SHAP has the potential to be widely\nadopted and become the post-hoc interpretability benchmark in IFD, even in other classification\ntasks. The code is available on https://github.com/ChenQian0618/CS-SHAP.", "sections": [{"title": "1 Introduction", "content": "Beyond design and manufacturing, maintenance is also important in the lifecycle of mechanical equipment [1]. Me-\nchanical fault diagnosis (FD) plays a vital role by identifying fault types or locations after their occurrence, enabling\ntargeted maintenance [2]. It not only significantly reduces costs but also minimizes equipment downtime. Conse-\nquently, FD is widely utilized in industrial production and equipment maintenance [3].\nWith the growing complexity of mechanical equipment and advancements in sensor technology, the deployment of\nnumerous sensors generates vast amounts of operational data, marking the advent of big data era [4]. Traditional\nfault diagnosis methods, which depend on prior knowledge and manual processing, are inadequate for the complex\ndiagnostic scenarios posed by big data. In contrast, intelligent fault diagnosis (IFD) utilizes abundant data without\nrelying on prior knowledge, effectively meeting the requirements of big data [5].\nIFD, leveraging the nonlinear mapping of neural networks (NNs), offers an end-to-end feasible solution. IFD has\ndeveloped into a mature and thriving research domain, with numerous advanced NNs being progressively applied to\ndiagnose mechanical components such as bearings [6], gears [7], and pumps [8]. Although significant progress has\nbeen made in areas such as diagnostic accuracy, generalization capability [9, 10], information fusion [11], and few-shot\nlearning [12, 13], the interpretability of IFD remains underexplored.\nNeural networks, as the foundation of IFD, involve multiple nonlinear mappings and are typical black boxes. It is\nchallenging to understand their reasoning basis, logical processes, and applicable scopes [14]. However, interpretabil-\nity is critical for the practical application of IFD [15]. From the user's perspective, non-interpretable IFD struggle to\ngain trust, often necessitating cross-validation, which increases maintenance costs. From the developer's perspective,\nthe lack of interpretability hinders the ability to identify errors and optimize models scientifically. From the appli-\ncation perspective, real-world scenarios are more complex and unpredictable than training data, making it difficult\nfor non-interpretable IFD systems to ensure reliable performance under actual operating conditions. Therefore, the\ninterpretability research of IFD has substantial scientific and industrial significance.\nInterpretability refers to the ability to provide explanations in understandable terms to a human [16]. Existing inter-\npreting methods are generally categorized into two types: ante-hoc (active) and post-hoc (passive).\nAnte-hoc interpretability requires modifications before training, such as changing architectures or optimization pro-\ncesses. For instance, An et al. [17] employed algorithm unrolling to design interpretable NN structures that capture\nfault characteristics through learned dictionaries. Li et al. [18] enhanced traditional transformers by leveraging the\nmulti-head attention mechanism to explain segment contributions. Wang et al. [19] integrated traditional feature ex-\ntraction techniques to design extreme learning machines (ELMs) capable of localizing resonance frequency bands.\nHowever, while these modifications provide NNs with distinct interpretability, they also constrain model structures,\nthereby reducing the flexibility and scalability. Moreover, ante-hoc interpretability can sometimes compromise perfor-\nmance. Despite claims of high accuracy in various studies [20, 21, 22], the constrained architectures inherently limit\nthe potential for further optimization.\nIn contrast, post-hoc interpretability focuses on explaining pre-trained networks without requiring modifications be-\nfore training. This approach avoids introducing additional constraints, ensuring models remain flexible and scalable\nwithout sacrificing performance. Current post-hoc interpretability in IFD primarily focuses on attribution, which aims\nto reveal the basis of decisions by assigning credit (or blame) to the input features [16] (e.g., feature importance).\nTypical attribution methods include class activation mapping (CAM), layer-wise relevance propagation (LRP), and\nSHapley Additive exPlanations (SHAP), etc. Inspired by attribution methods in computer vision, some researchers\nhave extended them to IFD. For example, Wu et al. [23] and Grezmak et al. [24] applied time-frequency transform\nto convert vibration signals into 2D images, then used existing Grad-CAM and LRP to compute contributions, re-\nspectively. However, this approach achieved suboptimal interpretability and is not end-to-end. To achive end-to-end\ninterpretability, Li et al. [25] use the integrated gradient (IG) method to effectively capture the characteristic frequency\nthrough Fourier transform, and Li et al. [26] made further improvement by combining Grad-CAM with correlation-\nbased weighting. Despite these advancements, the time-domain explanations remain insufficiently intuitive and often\nrequire Fourier transform for clearer analysis.\nThe core challenge in post-hoc interpretability for IFD is the form of explanation. End-to-end models typically process\ntime-domain signals as input, but these signals often fail to directly convey mechanistic insights [27]. Consequently,\ntransforming signals from the time domain to more clear domains is a well-established practice in traditional FD [28].\nLikewise, extending the explanation to these clearer domains offers a feasible approach for enhancing the explainabil-\nity of IFD.\nTo facilitate understanding, Fig. 1 illustrates fault representations across different domains. When a fault occurs, as\nshown in Fig. 1(a), the fault component generates periodic impulse responses during rotation, producing the time-\ndomain signal depicted in Fig. 1(b). However, the time domain is prone to noise interference, and attribution methods\noften only capture impulse timings. Therefore, domain transformation can provide clearer fault representations. In\nthe frequency domain shown in Fig. 1(c), fault components appear as sidebands, enabling the explanation of the\ncarrier frequency $f_e$ and indirectly the modulation frequency $f_m$. In the envelope domain shown in Fig. 1(d), fault\ncomponents manifest as modulation frequencies $f_m$ and their harmonics, enabling attribution results to locate $f_m$.\nIn the time-frequency domain shown in Fig. 1(e), faults are represented as periodic impulses, allowing attribution\nmethods to simultaneously reveal the carrier frequency $f_e$ and impulse timings.\nBased on this, some researchers have optimized post-hoc explanation forms by incorporating domain transforma-\ntions [29, 30]. For example, Gwak et al. [31] perturbed samples in the frequency domain to identify critical frequencies\nand decision boundaries of end-to-end models. Herwig et al. [32] extended SHAP to the frequency and time-frequency\ndomains, effectively revealing the contributions of different frequencies $f_e$ from time-domain samples. Going further,"}, {"title": "2 Preliminary", "content": ""}, {"title": "2.1 SHAP", "content": "SHAP (SHapley Additive exPlanations) [35] is a game-theory-inspired approach designed to explain machine learning\nmodel predictions. It quantifies the contribution of each feature in a sample to the model's prediction, i.e., attribution.\nTo understand SHAP, it is essential to first introduce the Shapley value [36], which is a mathematical method for\ndetermining a fair and efficient resource allocation strategy within a group. Its applications include profit sharing\namong stakeholders, cost distribution among collaborators, etc."}, {"title": "2.2 Cyclic-spectral correlation", "content": "Cyclic-spectral correlation (CSC) is an effective signal processing technique for analyzing cyclostationary signals [34].\nUnlike stationary signals, which have constant statistical characteristics, a N-order cyclostationary signal is one whose\nN-th order statistics are periodic over time.\nFor instance, a second-order cyclostationary signal has a periodic autocorrelation function, such as white noise mod-\nulated by a periodic signal. These signals typically represent system responses to periodic excitations. As illustrated\nin Fig. 1(a), rotating machinery induces periodic contact of fault components during rotation, thereby exciting the\nsystem response periodically. The resulting vibration signal, depicted in Fig. 1(b), exemplifies a typical second-order\ncyclostationary signal. This cyclostationary signal has two types of information: the system response frequency ($f_m$)\nand the periodic excitation frequency ($f_c$). While traditional spectral analysis is inadequate for such signal, CSC can\neffectively reveal its hidden features.\nFor a cyclostationary signal x(t), its second-order cyclic stationary moments $R_x(\\tau,t)$ can be computed using a two-\ndimensional autocorrelation function:\n$R_x(\\tau,t) = E[x(t - \\tau/2)x^*(t + \\tau/2)]$\\"}, {"title": "3 Method", "content": ""}, {"title": "3.1 Cyclic-spectral transform", "content": "For end-to-end IFD models, existing SHAP methods can attribute contributions in the time domain or extend to\nfrequency, time-frequency, and envelope domains. However, these approaches often fall short of comprehensively\nrevealing fault components. The CSC method introduced in Section 2.2, has the ability to simultaneously uncover\ncarrier and modulation components, and inspires our motivation of extending SHAP to the CS domain.\nHowever, CSC is inherently designed for stochastic signals and is not directly applicable to the deterministic signals\nused in IFD models. The key to applying CSC to deterministic signals lies in estimating the second-order cyclosta-\ntionary moment $R_x(\\tau, t)$ as mentioned in (6). For second-order stationary signals, increasing the time delay $\\tau$ would\ncause $R_x(\\tau, t)$ to decay to zero. Essentially, it represents the autocorrelation function (ACF) of the signal $x(t)$ at a\nspecific local time $t$. Therefore, we can apply a window $h(t)$ to the deterministic signal $x(t)$ and compute its ACF as\nan approximation $R'(\\tau, t)$. The windowed signal $\\hat x(t', t)$ can be expressed as:\n$\\hat x(t',t) = x(t' - t)h(t')$\\nwhere, $t'$ represents the time-axis, and $t$ denotes the center of the window. Then, $R'(\\tau,t)$ can be derived from the\nACF $R(\\cdot)$ of $\\hat x(t', t)$ along axis $t'$:\n$R'(\\tau,t) = R_{t'}(\\hat x(t', t))$\n$= \\int \\hat x(t' - \\tau/2, t) \\cdot \\hat x^*(t' + \\tau/2,t) dt'$.\nBy substituting the approximate moment $R'_x(\\tau,t)$ into (8), the cyclic-spectral (CS) representation $CS_x(f, a)$ of the\ninput signal $x(t)$ can be expressed as:\n$CS_x (f, a) = \\int \\int R_x(\\tau, t)e^{-i2\\pi(f\\tau+at)} d\\tau dt$\n$= \\int \\Big[ \\int R_{t'}(\\hat x(t',t))e^{-i2\\pi f \\tau}d\\tau \\Big] e^{-i2\\pi at}dt$\n$= \\int F_{\\tau \\rightarrow f}(R_{t'}(\\hat x(t',t))).e^{-i2\\pi at} dt$\\"}, {"title": "3.2 CS-SHAP", "content": "By leveraging the CS transform and inverse CS transform shown in (17) and (18), traditional time-domain SHAP can\nbe extended to the CS domain, as illustrated in Fig. 3.\nTraditional time-domain SHAP computes the contributions of different parts of the time-domain sample x to the pre-\ndiction M(x) using (5), with attribution results corresponding to specific timings. While it offers clear interpretability\nfor simple signals, it faces challenges in real-world high-noise scenarios, where fault features are often obscured by\nnoise.\nCompared to traditional time-domain SHAP, CS-SHAP introduces two main modifications: 1) Sample preprocessing:\nThe CS transform Z preprocesses time-domain samples x into CS samples, including the CS representation CS and\nphase information \u03b8. 2) Model integration: The inverse CS transform $Z^{-1}$ is integrated with the end-to-end model\nM, enabling CS samples as inputs without altering the original model architecture.\nThe proposed CS-SHAP has the following advantages: 1) Reliable interpretability label: The CS domain highlights\nfault information more effectively than the time domain, providing more accurate and reliable ground-truths for inter-\npretability evaluation. 2) Clearer explanations: While the time domain can only reveal the timings of fault compo-\nnents, the CS domain simultaneously reveals both the carrier $f_e$ and modulation $f_m$ frequencies, which is critical for\nfault lacating and reasoning. 3) Noise robustness: The CS domain is less susceptible to noise interference than the\ntime domain, making it more suitable for high-noise scenarios."}, {"title": "3.3 Framework", "content": "The workflow for applying CS-SHAP to end-to-end models for interpretability analysis is depicted in Fig. 4. It com-\nprises five key steps: model preparation, model integration, sample preprocessing, SHAP attribution, and visualization\nwith interpretability analysis.\nFirstly, users prepare an end-to-end model M based on their task requirements, which may derive from various\napproaches, including dynamics, machine learning, or deep learning. Secondly, the prepared model M is integrated\nwith the CS transform Z, creating an integrated model M capable of processing CS samples as input. Thirdly, existing\ntime-domain samples x are transformed into CS samples (CS and 0) using the inverse CS transform $Z^{-1}$. Next,\nSHAP analysis is conducted based on (5), iterating subsets and computing expectations relative to the data distribution\nto quantify the contribution of each part of the CS sample to the prediction M(x). Finally, the CS-SHAP results\n4 are visualized for interpretability analysis, with red indicating positive contributions and blue indicating negative\ncontributions.\nNotably, the contributions in CS-SHAP are influenced by two factors: the relevance of signal components to the current\nclass and their presence. Specifically, the presence (absence) of fault components related to the current class results\nin a positive (negative) contribution, whereas the presence (absence) of fault components related to other classes leads\nto a negative (positive) contribution. As shown in the visualization part in Fig. 4: Component #1, unrelated to all\nthree classes, has zero contribution across all classes regardless of its presence. Component #2, related to Class #2,\nits absence contributes negatively to Class #2 and positively to Classes #1 and #3. Component #3, related to Class #3,\nits presence contributes positively to Class #3 but negatively to Classes #1 and #2."}, {"title": "4 Experiments", "content": "To validate the effectiveness of CS-SHAP, we applied it to three distinct datasets: a simulation dataset, the open-source\nCase Western Reserve University (CWRU) bearing dataset, and a private helical gearbox dataset. The simulation\ndataset, with fully known fault logic and ground-truth, serves as a reliable benchmark for evaluating interpretability\nresults. The CWRU dataset, a widely used open-source benchmark, ensures the reproducibility of CS-SHAP using\nour open-source code. Finally, the private gearbox dataset, collected from a real industrial environment, highlights the\npractical applicability of CS-SHAP in real-world scenarios.\nFor the predictive model M, we selected an end-to-end convolutional neural network (CNN) for analysis, with its\narchitecture detailed in Table 1. Similar to SHAP, CS-SHAP operates as a post-hoc interpretability method, making it\nmodel-agnostic. While the effects of different models will be discussed in Section 5.1, we consistently utilize the CNN\nmodel for validation, ensuring that the assessment of CS-SHAP's interpretability performance remains unaffected."}, {"title": "4.1 Simulation dataset", "content": "We first define the periodic-impulse component $x_p$:\n$x_p(f_m, f_c,t) = \\sum_{k \\in \\mathbb{N}} e^{-\\beta(t-k/f_m)} sin \\Big(2\\pi f_c\\Big(t - \\frac{k}{f_m} \\Big) + \\phi \\Big)$$\\\nwhere, $f_m$ is the excitation frequency of the fault impulse, $f_c$ is the response frequency, $\\beta = 0.04$ is the damping, and\n$\\phi ~ U(0, 2\\pi)$ is the initial phase, where U(a, b) represents a uniform distribution with a lower bound a and an upper\nbound b. The simulation signal can be represented as:\n$x = \\sum_{i=1}^{2} A x_i^p(f_m, f_c, t) + n(t)$$\\\nwhere, $A ~ U(0.8, 1)$ is the amplitude coefficient, and $n(t)$ represents Gaussian white noise with a signal-to-noise\nratio (SNR) of 0.\nIn this dataset, the sampling frequency is set to 10 kHz, and three fault classes are defined: health, Fault #1, and\nFault #2, with their relationships to the components and corresponding parameters depicted in Table 2. Each fault\nclass contains two periodic-impulse components. Specifically, Component Po is shared across all three classes and\nhas zero contribution to any of them. In contrast, other components (i.\u0435., PH, P1, P2) are exclusive to a single class,\ncontributing positively to their corresponding class while contributing negatively to others. The fault logic of this\nsimulation dataset is fully known, facilitating the evaluation of interpretability that is challenging to achieve with other\ndatasets due to the lack of ground-truth. For better understanding, the three fault classes in time domain and frequency\ndomain are shown in Fig. 5.\nThis experiment could be regarded as a 3-class classification task. Each class contains 5000 samples, each with a\nlength of 2000, normalized via mean-std normalization. Of these, 70% are randomly selected for training, while the\nremaining 30% are used for testing. Training parameters include 20 epochs, a batch size of 64, Adam optimizer, and\na learning rate of 0.001 with a 0.99 decay per epoch. Ultimately, the trained CNN model achieved a test accuracy of\n99.98%."}, {"title": "4.2 Open-source CWRU bearing dataset", "content": "The CWRU dataset, a widely recognized benchmark in IFD research, is selected to validate the authenticity and\nreproducibility of CS-SHAP. This experiment chooses the operating condition of a 1 HP load at 1800 rpm. The\ncorresponding bearing characteristic frequencies are listed in Table 3. Samples were collected from the drive end at\na 12 kHz sampling rate, covering four classes: health (H), inner race fault (I), ball fault (B), and outer race fault (O),\neach with a defect size of 0.007 inches. Each class contains 119 samples of 2000 data points. For better understanding,\nthe representations of the four classes in the time domain and frequency domain are shown in Fig. 9, where the healthy\nsample prominently features an amplitude at 360 Hz (nfr). The experimental and training settings were consistent\nwith those of the simulation dataset. The end-to-end CNN model ultimately achieved a test accuracy of 100%.\nUnlike the simulation dataset where fault logic (ground truth) is explicitly defined, the CWRU dataset requires the\nidentification of fault characteristics for each class. For clarity, we denote modulated components as P : (a, b), where\na (Hz) and b (kHz) represent the carrier fe and modulation fm frequencies, respectively. The fault characteristics are\nas follows: The health sample in Fig. 10(a) contains a constant frequency component PH : (0, nfr) and a modulated\ncomponent PH: (4fr, 4.15). The inner race fault sample in Fig. 11(a) includes Pl : (0, 1.46), Pl : (fBPFI, 2.74), and\nPl : (fBPFI, 3.54). The ball fault sample in Fig. 12(a) exhibits a broadband modulated component P: (0-200,3.3).\nThe outer race sample in Fig. 13(a) contains P\u2642: (fBPFO, 2.87) and P3: (fBPFO, 3.4). For simplicity, Grad-\nCAM and Time-SHAP are excluded due to their poor performance, and the remaining SHAP results are shown in\nFig. 10-13(b)-(e).\nAs shown in Fig. 10(b), Freq-SHAP indicates that the contribution to health prediction yH comes from the presence\nof PH. Env-SHAP in Fig. 10(c) reveals that no significant influence of modulated frequencies on yH. TF-SHAP in\nFig. 10(d) similarly attributes yH mainly to the presence of PH, aligning with Freq-SHAP. However, CS-SHAP in\nFig. 10(e), identifies that the yH contributions come from the presence of PH and P\u2081, as well as the the absence of\nPl and P3, where PH and P3 contribute more prominently. CS-SHAP further reveals that the constant frequency\nfm = 0 in Py contributes more significantly to yH than the modulated frequency fm = 4fr, consistent with Env-\nSHAP. Moreover, CS-SHAP exhibits superior precision by capturing positive contributions resulting from the absence\nof other class components (i.e.,Pl and P3)-a phenomenon rarely identified by other SHAP methods. The analysis\nfor Fig. 11-13 are consistent with that of Fig. 10 described above. With the detailed annotations provided in the figures,\nreaders should find them easy to understand."}, {"title": "4.3 Private helical gearbox dataset", "content": "This dataset is collected from a private helical gearbox and is used to validate the practical effectiveness of CS-\nSHAP. The experimental setup and fault types are depicted in Fig. 14. The motor speed is set to 1800 rpm, and\nthe characteristic frequencies are summarized in Table 3. Data was acquired from the drive shaft end-shield at a 12\nkHz sampling rate, comprising four classes: health (H), wear (W), pitting (P), and crack (C). Each class contains 76\nsamples of 2000 data points, and the representations of the four classes in the time domain and frequency domain are\nshown in Fig 15. Experimental and training settings follow those of the simulation dataset, and the end-to-end CNN\nmodel achieves a test accuracy of 100%.\nSimilar to the CWRU dataset, ground-truth, i.e., the characteristics of each class, needs to be determined firstly.\nSpecifically, the health sample in Fig. 16(a) includes PH: (2f1, f\u2081), PH: (0, fmesh), and PH: (2f1, 2fmesh). The\nwear fault sample in Fig. 17(a) contains PW: (0, fmesh), PW: (f2,2fmesh), and Pw: (f2, 2.2). The pitting fault\nsample in Fig. 18(a) exhibits Php : (f1, fmesh), Pp : (f2, fmesh), and P: (f2, 2.3). The tooth crack fault sample in\nFig. 19(a) contains P\u311b : (f2, fmesh), PZ : (f2, 1.1), and P\u1edf : (f2, 2.1).\nUnlike the CWRU dataset, the helical gearbox dataset has greater challenges for interpretability due to the prevalence\nof components with shared carrier frequencies fe or modulation frequencies fm. As for the carrier frequency fc, Pw\nand P share fc = 2fmesh. As shown in Fig. 17(b), the presence of 2fmesh causes Freq-SHAP to attribute both\npositive and negative contributions to both yw and yp, leading to contradictory results. In contrast, CS-SHAP in\nFig. 17(e) effectively differentiates between Puw and PB, assigning entirely positive contributions to yw and entirely\nnegative contributions to yp, thereby resolving the ambiguity.\nRegarding the modulation frequency fm, P\u00b2 and P\u00e5 share fm = f2, with both exhibiting significant energy in\nFig. 19(a). Env-SHAP in Fig. 19(c) indicates that f2 contribute significantly to yc, but fails to distinguish whether\nthese contributions originate from P& or P3, requiring carrier frequency fe for clarification. Freq-SHAP in Fig. 19(b)\n2 loses its attribution capability, as the fe of P and P\u00e5 are assigned nearly negligible contributions, which is unreason-\nable and highlights the limitations of such methods. Conversely, TF-SHAP in Fig. 19(d) identifies the contribution of\nP\u00e5 as greater than P. Similarly, CS-SHAP in Fig. 19(e) shows that the contribution of P\u1edf is the most significant,\nroughly aligning with the results in Fig. 19(d).\nIn summary, CS-SHAP provides a comprehensive explanation by both carrier frequency fe and modulation frequency\nfm. On the one hand, it effectively separates close components, resulting in clearer explanation. On the other hand,"}, {"title": "5 Analysis", "content": "As indicated in (5), SHAP explanations depend on two primary factors: the model M and the data x. Thus, we\nanalyze the CS-SHAP attribution results under different models and noise intensities. All analyses are conducted on\nthe CWRU dataset, following the same experimental settings described in Section 4.2."}, {"title": "5.1 CS-SHAP with different models", "content": "We selected three representative models M: Multilayer perceptron (MLP), Transformer, and ResNet. Their class-wise\ntest accuracies are shown in Fig. 20(a). For CS-SHAP analysis, the same outer race fault sample is selected for all\nthree models. Its multi-domain representations, shown in Fig. 20(b), reveal two components, Pd and P3.\nThe CS-SHAP results for the three models are shown in Fig. 20(c)-(e). the MLP's weak classification capability sig-\nnificantly impulses the CS-SHAP results, with the contribution of Pd nearly zero and P3 present but not prominent.\nIn Fig. 20(d), the Transformer demonstrates improved classification performance, leading to a notable increase in P3's\ncontribution; however, PJ's contribution remains weak. Furthermore, slight amplitudes observed in blank regions sug-\ngest potential instability in the Transformer's results, likely due to the attention mechanism. In Fig. 20(e), the ResNet\nachieves the best performance, with both Po and P3 displaying clear contributions, and P\u266d < P3. Considering the\nCS representation in Fig. 20(b), this result is quite reasonable.\nIn summary, the results of CS-SHAP are indeed influenced by the model M. On one hand, weak classification\ncapabilities lead to less distinct predictions, making it challenging for CS-SHAP to effectively capture contributions.\nOn the other hand, the model type plays a critical role. For example, Transformers, which excel at capturing token\nrelationships through the attention mechanism, may exhibit unstable results compared to CNNs. Nevertheless, CS-\nSHAP consistently provides generally accurate interpretability results across different models M, demonstrating its\nbroad applicability and potential as a universal interpretability algorithm for IFD models."}, {"title": "5.2 CS-SHAP with different noise intensities", "content": "Based on the CNN presented in Table 1, The test accuracies under different noise intensities on the CWRU dataset are\nshown in Fig. 21(a). For CS-SHAP analysis, an outer race fault sample is selected, and its frequency spectrum, CS\nrepresentation, and CS-SHAP results are shown in Fig. 21(b)-(e), respectively."}, {"title": "6 Conclusion", "content": "The form of explanation remains a significant challenge for existing IFD interpretability methods. To address this, we\npropose CS-SHAP, which extends SHAP to the CS domain, where fault features are more distinct and interpretable.\nUnlike existing SHAP extension approaches, CS-SHAP evaluates the contributions of components from both carrier\nfrequency and modulation frequency perspectives, aligning closely with fault mechanisms. This dual-dimensional\nanalysis allows CS-SHAP to effectively distinguish close fault components and excel in high-noise and multi-class\nscenarios. Comprehensive validation on simulation, CWRU, and private datasets demonstrates the superior inter-\npretability, authenticity, and practicality of CS-SHAP. By publicly releasing the code, we aim to establish CS-SHAP\nas a benchmark post-hoc interpretability method for IFD and beyond.\nNevertheless, several challenges remain in advancing the interpretability of IFD. First, the validation of interpretability\noften lacks objective ground-truths, relying on subjective human judgment, which can compromise the reliability\nof explanations. Second, the interpretability inherently involves human involvement, necessitating the development\nof objective and quantifiable metrics to evaluate explanations comprehensively. Finally, while our work enhances\nexplanation forms, the high-dimensional nature of vibration signals poses a significant challenge to the computational\nefficiency of interpretability methods, warranting further exploration."}]}