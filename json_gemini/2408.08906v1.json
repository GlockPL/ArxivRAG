{"title": "Bundle Recommendation with Item-level\nCausation-enhanced Multi-view Learning", "authors": ["Huy-Son Nguyen", "Tuan-Nghia Bui", "Long-Hai Nguyen", "Hung Hoang", "Cam-Van Thi Nguyen", "Hoang-Quynh Le", "Duc-Trong Le"], "abstract": "Bundle recommendation aims to enhance business profitabil-\nity and user convenience by suggesting a set of interconnected items. In\nreal-world scenarios, leveraging the impact of asymmetric item affilia-\ntions is crucial for effective bundle modeling and understanding user pref-\nerences. To address this, we present BunCa, a novel bundle recommenda-\ntion approach employing item-level causation-enhanced multi-view learn-\ning. BunCa provides comprehensive representations of users and bundles\nthrough two views: the Coherent View, leveraging the Multi-Prospect\nCausation Network for causation-sensitive relations among items, and\nthe Cohesive View, employing LightGCN for information propagation\namong users and bundles. Modeling user preferences and bundle con-\nstruction combined from both views ensures rigorous cohesion in direct\nuser-bundle interactions through the Cohesive View and captures explicit\nintents through the Coherent View. Simultaneously, the integration of\nconcrete and discrete contrastive learning optimizes the consistency and\nself-discrimination of multi-view representations. Extensive experiments\nwith BunCa on three benchmark datasets demonstrate the effectiveness\nof this novel research and validate our hypothesis.", "sections": [{"title": "1 Introduction", "content": "Recommendation systems are crucial in enhancing user experiences and shaping\nbusiness strategies, particularly in e-commerce [24,19]. While conventional rec-\nommendation systems traditionally prioritize individual item suggestions, bundle\nrecommendations have been recognized as a superior strategic marketing tactic.\nBundle recommendation, rooted in user behavior and item relevance, involves\ngrouping pertinent items into bundles, such as assortments of items from the\nsame category (e.g., detective books, thrilling games) [5,19], complementary item\nbundles (e.g., men's vest with cravat, phone with case) [19], etc. Recommending"}, {"title": "2 Related Work", "content": "The field of bundle recommendation has witnessed diverse approaches aimed\nat accurately recommending pre-defined item sets to users. Early approaches\n[11], grounded in the BPR framework [15], deliberate users' past interactions\nwith lists of items and individual items. DAM model [5] emerged as a pioneer\nby recognizing the importance of affiliated items within bundles and optimizing\nboth user-item and user-bundle interactions using attention mechanisms and\nmulti-task learning. Recently, BGCN [4] used Graph Convolutional Network\noperations to capture intricate relations between users, items, and bundles from\ntwo distinct views, establishing an effective multi-view learning approach for\nsubsequent SOTA models.\nIn the realm of multi-view architectures, addressing challenges related to the\ninconsistency and integration of information concerning objects has been tackled\nthrough the adoption of contrastive learning (CL) techniques. CrossCBR [12],\nevolving from BGCN, stands out for its remarkable improvements, leveraging\ncross-view contrastive learning to highlight the significance of capturing cooper-\native information from two distinct views. MIDGN [23] introduces the concept of\nintent disentanglement, modeling multiple latent features for each view and em-\nploying contrastive loss between the two views. Our study introduces concrete\ncontrastive learning to underscore the self-discrimination of augmented repre-\nsentations in multi-view learning. In addition, discrete contrastive learning is\nemployed to address the problem of inconsistency between separate views."}, {"title": "3 Methodology", "content": "In this section, we initially formalize the bundle recommendation problem and\ndefine the detailed interaction graph construction. Subsequently, we demonstrate\nthe four important modules of BunCa illustrated in Figure 2 including: (1) Cohe-\nsive View representation learning; (2) Coherent View representation learning; (3)\ncontrastive learning modules; and (4) prediction and joint optimization module."}, {"title": "3.1 Preliminaries", "content": "Given the set of users U = {U1, U2,..., u|u|}, the\nset of bundles B = {b1,b2,...,b||}, and the set of items I = {1,2,...,|z|}.\nThe user-bundle interactions, user-item interactions, and bundle-item affiliations\nare respectively defined as three binary-valued matrices $X \\in {0,1}^{|U|\\times|B|}$, $Y \\in\n{0,1}^{|U|\\times|I|}$, and $Z\\in {0,1}^{|B|\\times|I|}$ where the cell with value 1 denotes an ob-\nserved relation between the user-bundle, user-item, or bundle-item pair, value\n0 for otherwise. The objective of our work is to accurately predict unseen user-\nbundle interactions for recommendation system."}, {"title": "3.2 Cohesive View Representation Learning", "content": "As mentioned, the heterogeneous graph may help enhance robust propagation\nof high-order collaborative signals by incorporating homogeneous correlations.\nBunCa adopts the LightGCN operation [9] to encode cohesive representations of\nusers and bundles, excluding self-connections and non-linear transformations in"}, {"title": "3.3 Coherent View Representation Learning", "content": "For the Coherent View, BunCa aims to explicitly leverage the asymmetric rela-\ntion between items based on the user preference (UP) sub-view and the bundle\nconstruction (BC) sub-view to enhance the modeling of decision-making factors.\nLearning these sub-views improves item embeddings, hence consolidating the\nrepresentations for users and bundles. These representations are fused to high-\nlight vital information that determines user preferences and bundle construc-\ntion. Initially, we employ a coarse-grained mixture method to create item-item\nsymmetric relations. The co-occurrence item matrices from different aspects are\ncomputed by the matrix multiplication as follows:\n$CYP = YY,CC=ZT.Z$\nwhere $CUP, CBC \\in R^{|I|\\times|1|}$ represent item co-occurrence based on user-item in-\nteractions Y and bundle-item affiliations Z. The symmetric connections between\nitems are normalized as follows:\n$\\check{C}_{(i,j)}=\\begin{cases}\n1 & \\text{if } C_{(i,j)} \\geq 1 \\wedge i \\neq j, \\\\\n0 & \\text{otherwise}\n\\end{cases}$\nwhere i, j \u2208 I refer to the corresponding items. Filtering the threshold of $C(i,j)$\ncan be considered empirically to achieve better performance on different data\ndomains. It is notable that the symmetric matrix $C_{I}$ is uniform symbol for\n$C^{UP}, C^{BC}$ due to the similar calculations of two sub-views in many scenarios."}, {"title": "Multi-Prospect Causation Network", "content": "Assuming that causation-sensitive re-\nlationships exist among items frequently purchased together, BunCa employs\nMulti-Prospect Causation Network (MPCNet) to explicitly model asymmetric\nassociations between items. MPCNet is constructed with L prospects, each rep-\nresented by a learnable prospect vector $p\u03b9 \\in R^{d}$. For the l-th prospect, the\nweight $rji$ signifies the influence from item j to item i based on various user\npreferences and bundling strategies, derived as follows:\n$rji^{src dst} = \\Psi(src \u2022 tj \u2295 \\Psi^{ast} \u2022 ti \u2295 \u00de)$\nwhere $\u03a8 src, \u03a8^ast \\in R^{dxd}$ are learnable parameters for the source and destination\nobject in the l-th prospect; ti, tj \u2208 Rd denote the representations of item i and\nitem j; (.) is the non-linear activation function; \u2295 denotes the element-wise\nsummation; and is the bias parameter.\nIn the l-th prospect, the asymmetric causation matrix $A\u00b9 \\in R^{||\\times|1|}$, repre-\nsenting the causation-sensitive relationships among items at fine-grained level, is\ncomputed by the attention mechanism concept of GATv2 [3]. The weight $A(i,j)$\ndescribes how much item i is influenced by item j, defined as follows:\n$A_{(i,j)} = \\frac{\\exp(ri) C_{(i,j)}}{\\max_{j'eI}\\Sigma\\exp(r^{j'i}) \\check{C}_{(i,j),} \u20ac)}$\nwhere e \u2208 R is a fixed constant; display the multiplication between two scalars."}, {"title": "Enhancing Item Representation", "content": "The asymmetric relationships obtained\nfrom MPC-Net are utilized to encode the latent representation of item $t\u2208 R^{d}$\nin the l-th prospect, formulated as follows:\n$t=\u03a3 Ajorc.tj$\nWhere $Iorc \u2208 Rdxd$ denotes the dense layer to learn item features; and $tj \\in\nRd$ denotes other item representation. Subsequently, the multi-prospect item\nrepresentation is devised using the residual connection method as:\nt$\\displaystyle \\frac{1}{L} =\\sum_{k=1}{A}\\documentclass{article}\n\\usepackage{amsmath}\n\\usepackage{amsfonts}\n\\begin{document}\nt_k\n\\end{document} \u03b1 (1-\u03b1)ti$\nwhere $t\u2208 Rd$ is the enhanced item representation, combining individual features\nand aggregated information from connected items with a controlled influence\n\u03b1\u2208 [0,1]. It is notable that to serves as a uniform placeholder, representing\nboth $t^{UP} \u2208T^{UP}$ and $BC \u2208 B^{C}$, denoting the enhanced item representation of\nthe UP sub-view and BC sub-view.\nFor UP sub-view, the item representation $t^{UP}$ is employed alongside the user's\npreference tu \u2208 Tu as the node's initial feature within the user-item graph Gut.\nThe graph-based propagation process utilizes the LightGCN operation similar"}, {"title": "3.4\nContrastive Learning Module", "content": "The discrete contrastive learning is directed at minimizing the inconsistency\nbetween two different views, whereas the concrete contrastive learning strives to\nenhance the distinctiveness of augmented representations."}, {"title": "Discrete Contrastive Learning", "content": "Inspired by CrossCBR [12], BunCa addresses\nvariations in user preferences for items and bundles by minimizing inconsisten-\ncies in representations across different views. The in-batch negative sampling is\nadopted to construct the negative pairs [17]. Relied on InfoNCE [8], the discrete\ncontrastive loss function for user representations is computed from contrastive\npairs $(t^{SV}, RV)$ as follows:\n$L^{DC} = \\frac{1}{|U|} \\Sigma_{UeU}log \u03a3log\\frac{\\exp((cos(t^{SV},RV)/T))}{\\Sigma \\exp((cos(tv, tv)/T))}$"}, {"title": "Concrete Contrastive Learning", "content": "The concrete contrastive learning is devised\nto distinguish the unique characteristics of each individual user and bundle. We\ncreate the combination of user preferences and bundle features as follows:\nt = RvSv, t = tvtv\nwhere ta, to denote the fused multi-view representation of user and bundle,\nrespectively. The formulation of the concrete contrastive loss function for user\nrepresentations is derived as follows:\n$LCC = \\frac{1}{|U|} \\Sigma_{UeU}log \\frac{\u0435\u0445\u0440(1/\u03c4)}{\u03a3'eu \\exp((cos(t,t)/T))}$\nwhere u' denotes a different user of u; cos(.,.) denotes the cosine similarity\nfunction; and 7 is the temperature hyper-parameter that aids in distinguishing\nbetween positive and negative samples. The same operation is repeated for the\nconcrete contrastive loss of bundle LEC.\nThe final contrastive loss is derived from the dyadic contrastive learning\ntechniques described above as follows:\nLCL = \u03b3 (CDCCPC2)+(1\u2212\u03b3)LCC+LEC2\nwhere \u03b3\u2208 [0, 1] controls which contrastive learning is more important."}, {"title": "3.5\nPrediction and Joint Optimization", "content": "For the comprehensive representations, we effectively capture augmented infor-\nmation from both views, derived as follows:\ntu = [utSV || RV], t = [utvSV || RV]\nwhere the hyper-parameter \u03bc\u2208 [0,1] controls the impact of views on the final\nuser's preference and bundle's feature; || denotes the concatenation; and tu, t\u266d \u0404\nR2d respectively represent the fusion of user's preferences and bundle's features,\ncombining Cohesive View and Coherent View learning.\nFinally, the interaction probability \u0177u,b \u2208 R between user u and bundle b is\ncalculated by the inner-product as follows:\n\u0177u,b = (tu) tb\nThe Bayesian Personalized Ranking loss [15] is utilized to enhance probabil-\nities for interacted user-bundle pairs while reducing for non-interacted pairs:\nCBPR = \u2211(u,b,b')\u2208S-Ino (yu,b \u2013 \u0177u,b')"}, {"title": "4 Experiments", "content": "In this section, we conduct extensive experiments on benchmark datasets to vali-\ndate the effectiveness of BunCa and investigate the importance of its components."}, {"title": "4.1 Experimental Setup", "content": "According to popular studies [4,12,14], we adopt three benchmark\ndatasets for the bundle recommendation evaluation, including: The Youshu 1\ndataset consists of bundles formed by lists of books that is purchased in each\nuser session; the NetEase 2 dataset captures user-generated song lists as bundles;\nthe iFashion [6] dataset establishes outfits composed of clothes and accessories as\nbundles. The statistics of these datasets are shown in Table 1. Specially, c-score\nmetric, according to [14], present the high consistency between user-bundle and\nuser-item collaborative relations on iFashion but limited on Youshu and NetEase."}, {"title": "4.2 Performance Comparison to Baselines", "content": "Table 2 illustrates performance comparison between BunCa and related baselines\nin term of R@K, N@K metrics with K\u2208 {10, 20}. Generally, the recommenda-\ntion methods with multi-view learning consistently outperforms the traditional\ntechniques for all metrics. This observation implies the efficiency of the decom-\nposition and modeling of multiple views for the bundle recommendation task.\nAmong the multi-view learning models, BunCa achieves the best performance\nin the benchmark datasets. Compared to applied contrastive learning methods\n(e.g., MIDGN, BGCN, CrossCBR), BunCa represents persistent enhancements,\nwhich verify the effectiveness of assembling discrete and concrete contrastive\nlearning in providing discriminative representation across different views. Com-\npared to the second-best results (BundleGT, EBRec), BunCa produces statis-\ntically significant improvements in terms of R@10 and N@10. Especially, for\niFashion, the notable enhancements are 8.25% to 9.57% for both K\u2208 {10, 20}.\nCompared to the DGMAE distillation framework, the performance of BunCa is\n13% and 17% superior on R@20 and N@20 for iFashion, but weak for Youshu\nand NetEase. They affirm the effectiveness of exploiting item causation-sensitive\nrelationships in small-sized bundles, in which bundle items are more coherent.\nFor the case of large-sized bundle datasets such as NetEase and Youshu, the\nsuperiority of BunCa could be negatively affected due to noisy connections. In"}, {"title": "4.3 Ablation Study", "content": "To investigate the impact of key components in BunCa, we conduct various ab-\nlation studies described below."}, {"title": "Effects of Learning from Different Views", "content": "To assess the impact of inte-\ngrating latent representations from different views, learning Cohesive View (SV),\nCoherent View (RV), UP sub-view, and BC sub-view are selectively omitted and\nevaluated performance on the three datasets. According to Table 3, the results in-\ndicate that learning representations from each view encodes valuable information\nto enhance prediction performance. Excluding SV learning significantly dimin-\nishes BunCa's performance on all datasets, demonstrating its ability to effectively\nleverage high-order collaborative signals between users and bundles. Besides, the\nperformance drops remarkably once RV-view learning is omitted. It demystifies\nthe effectiveness of learning causation-sensitive relationships between items to\nenhance latent representations. UP sub-view representations exhibit a marginal\ndecrease of approximately 1% when omitted on iFashion, contributing the least"}, {"title": "Effect of Contrastive Learning Module", "content": "As depicted in Table 4, we examine\nthe effectiveness of contrastive learning module through experiments involving\nthe removal of the entire module (w/o CL), discrete contrastive learning (w/o\nDC), and concrete contrastive learning (w/o CC). The results across the three\ndatasets simultaneously emphasize the pivotal role of modeling multi-view infor-\nmation integrated with contrastive learning. Notably, the substantial impact of\ndiscrete contrastive learning demonstrates its effectiveness in aligning the repre-\nsentations of seperate views. This implies that each view can extract cooperative\ninformation from the other, leading to mutual enhancement. The addition of con-\ncrete contrastive learning further confirms that the contrastive learning module\ncan enhance the discrimination of each user/bundle in the fused representations."}, {"title": "Importance of Asymmetric Causation Matrix", "content": "The causation matrix A\nlearned by the MPCNet module enhances item-level representation t for bun-\ndle recommendation. In order to assess its significance, we compare it against\nalternatives: i) the original symmetric co-occurrence matrix from UP sub-view (w\nUP-sym) or BC sub-view (w BC-sym); ii) both original symmetric co-occurrence\nmatrices from UP and BC sub-views (w UP-BC-sym); iii) normalized Laplacian\nsymmetric correlation matrix as in [10] (w SnLm). Figure 4 shows a notable per-\nformance decrease of BunCa without asymmetric matrix-enhanced item represen-\ntations, instead simply employing symmetric item-item matrices. This demon-\nstration validates the significance of asymmetric relationships in real-world sce-\nnarios, affirming the hypothesis discussed in Section 1."}, {"title": "Effects of key hyper-parameters", "content": "In Figure 5, the impact of key hyperparam-\neters, \u1e9e and L, on BunCa's performance for iFashion is depicted. The parameter\n\u1e9e regulates the contribution of enhanced item representations from the BC sub-\nview and UP sub-view. As \u03b2 increases, the performance follows an ascending\ntrend until reaching its peak at \u1e9e = 0.8, underscoring the crucial role of the\nBC sub-view in refining item representations. Regarding L, the performance ex-\nhibits minor fluctuations within the range of 1 to 5 prospects before a decline is\nobserved with L = 6. This decline is attributed to noise problems that increase\nsimultaneously with latent features of high-order neighbors. After tuning, the\noptimal settings for iFashion are determined to be \u03b2 = 0.8 and L = 5. Similar\ntuning processes for Youshu and NetEase yield comparable observations."}, {"title": "4.4 Qualitative Showcase", "content": "Some qualitative examples in the iFashion dataset is illustrated in Figure 6 due\nto the coherence and specificity of interconnected items, whereas Youshu and\nNetEase only provide the IDs of objects. The asymmetric weights indicate the\ndifference effect among items, resulting in determining the explicit target of bun-\ndle features. Thereby, within each bundle, certain anchor items can be identified,\nand their influence on complementary items varies depending on causation sig-\nnals. For instance, considering the bundle 15707 containing a shirt and earrings."}, {"title": "5 Conclusion", "content": "This study design a novel approach to address bundle recommendation by em-\nphasizing the significance of asymmetric relationships between items. Our pro-\nposed model BunCa leverages item-level causation-enhanced multi-view learning,\nshowcasing significant improvements and notable points, as evidenced by exten-\nsive analytics conducted on three benchmark datasets. The architecture of BunCa\nlies in learning two distinct views: the Coherent View, employing the Multi-\nProspect Causation Network for causation-enhanced representation learning;\nand the Cohesive View, utilizing high-order collaborative signals of user-bundle\ninteraction to aggregate comprehensive representations. In addition, Bunca si-\nmultaneously integrates concrete and discrete contrastive learning, enhancing\nthe consistency and self-discrimination of representations from both views. Our\nwork not only validates the efficacy of BunCa but also emphasizes the importance\nof considering asymmetric item relationships for bundle-related tasks."}]}