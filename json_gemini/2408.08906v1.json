{"title": "Bundle Recommendation with Item-level Causation-enhanced Multi-view Learning", "authors": ["Huy-Son Nguyen", "Tuan-Nghia Bui", "Long-Hai Nguyen", "Hung Hoang", "Cam-Van Thi Nguyen", "Hoang-Quynh Le", "Duc-Trong Le"], "abstract": "Bundle recommendation aims to enhance business profitability and user convenience by suggesting a set of interconnected items. In real-world scenarios, leveraging the impact of asymmetric item affiliations is crucial for effective bundle modeling and understanding user preferences. To address this, we present BunCa, a novel bundle recommendation approach employing item-level causation-enhanced multi-view learning. BunCa provides comprehensive representations of users and bundles through two views: the Coherent View, leveraging the Multi-Prospect Causation Network for causation-sensitive relations among items, and the Cohesive View, employing LightGCN for information propagation among users and bundles. Modeling user preferences and bundle construction combined from both views ensures rigorous cohesion in direct user-bundle interactions through the Cohesive View and captures explicit intents through the Coherent View. Simultaneously, the integration of concrete and discrete contrastive learning optimizes the consistency and self-discrimination of multi-view representations. Extensive experiments with BunCa on three benchmark datasets demonstrate the effectiveness of this novel research and validate our hypothesis.", "sections": [{"title": "1 Introduction", "content": "Recommendation systems are crucial in enhancing user experiences and shaping business strategies, particularly in e-commerce [24,19]. While conventional recommendation systems traditionally prioritize individual item suggestions, bundle recommendations have been recognized as a superior strategic marketing tactic. Bundle recommendation, rooted in user behavior and item relevance, involves grouping pertinent items into bundles, such as assortments of items from the same category (e.g., detective books, thrilling games) [5,19], complementary item bundles (e.g., men's vest with cravat, phone with case) [19], etc. Recommending bundles based on user preferences poses greater challenges compared to separate items due to data sparsity and the diverse composition of bundles.\nPrior studies have mainly focused on selecting items for bundling [2] and identifying product bundles in commercial markets [20]. However, recent works [4,12] have shifted towards recommending existing bundles, aiming to better align suggested bundles with users' preferences. State-of-the-art (SOTA) bundle recommendation such as MIDGN [23], CrossCBR [12], and BundleGT [22] aggregate items to generate user and bundle representations. However, they often overlook the intricate relationships between individual items within bundles. There has been an initial exploration of the impact of item relationships, often grounded in symmetric correlations, on purchasing decisions for a bundle [10,1]. In real-world scenarios, the influence between items within bundles is usually asymmetric, with anchor items playing a significant role. Symmetric correlation-based recommendation models, as illustrated in Figure 1, fall short in accurately capturing user preferences. While blazers and cravats may be frequently purchased together, their influence on each other is not necessarily symmetrical. Users with an interest to blazers might consider to combine with cravats as accessories, while others primarily interested in cravats may already have suitable blazers, making the combination with pocket squares more logical. Understanding these dynamics requires examining item-item relations across diverse user preferences, which may help improve the bundle recommendation performance.\nApproach and Contributions. Motivated by mentioned limitations of pre-vious works, we introduce BunCa a novel neural architecture for bundle recom-"}, {"title": "2 Related Work", "content": "The field of bundle recommendation has witnessed diverse approaches aimed at accurately recommending pre-defined item sets to users. Early approaches [11], grounded in the BPR framework [15], deliberate users' past interactions with lists of items and individual items. DAM model [5] emerged as a pioneer by recognizing the importance of affiliated items within bundles and optimizing both user-item and user-bundle interactions using attention mechanisms and multi-task learning. Recently, BGCN [4] used Graph Convolutional Network operations to capture intricate relations between users, items, and bundles from two distinct views, establishing an effective multi-view learning approach for subsequent SOTA models.\nIn the realm of multi-view architectures, addressing challenges related to the inconsistency and integration of information concerning objects has been tackled through the adoption of contrastive learning (CL) techniques. CrossCBR [12], evolving from BGCN, stands out for its remarkable improvements, leveraging cross-view contrastive learning to highlight the significance of capturing cooperative information from two distinct views. MIDGN [23] introduces the concept of intent disentanglement, modeling multiple latent features for each view and employing contrastive loss between the two views. Our study introduces concrete contrastive learning to underscore the self-discrimination of augmented representations in multi-view learning. In addition, discrete contrastive learning is employed to address the problem of inconsistency between separate views."}, {"title": "3 Methodology", "content": "In this section, we initially formalize the bundle recommendation problem and define the detailed interaction graph construction. Subsequently, we demonstrate the four important modules of BunCa illustrated in Figure 2 including: (1) Cohesive View representation learning; (2) Coherent View representation learning; (3) contrastive learning modules; and (4) prediction and joint optimization module."}, {"title": "3.1 Preliminaries", "content": "Problem Formulation. Given the set of users $U = \\{U_1, U_2,..., u_{|u|}\\}$, the set of bundles $B = \\{b_1,b_2,...,b_{|B|}\\}$, and the set of items $I = \\{i_1,i_2,...,i_{|I|}\\}$. The user-bundle interactions, user-item interactions, and bundle-item affiliations are respectively defined as three binary-valued matrices $X \\in \\{0,1\\}^{|U|\\times|B|}$, $Y \\in \\{0,1\\}^{|U|\\times|I|}$, and $Z\\in \\{0,1\\}^{|B|\\times|I|}$ where the cell with value 1 denotes an observed relation between the user-bundle, user-item, or bundle-item pair, value 0 for otherwise. The objective of our work is to accurately predict unseen user-bundle interactions for recommendation system.\nGraph Construction in the Cohesive View. Inspired by collaborative fil-tering concepts suggesting that users with mutual interactions share similar preferences [21], we assume that user preference patterns are hidden within the co-occurrence of purchased bundles. In addition, bundles often bought collectively by numerous individuals may indicate shared interests. To capture these hypotheses, the user co-occurrence matrix $C_u = X \\cdot X^T \\in R^{|U|\\times|U|}$ and the bundle co-occurrence matrix $C_B = X^T \\cdot X \\in R^{|B|\\times|B|}$ are both derived from user-bundle interactions. Thereby, we explicitly establishes sets of connections denoted as: $E_{UB} = \\{e_{u,b}|b \\in B \\land u \\in U > X(u,b) = 1\\}$, $E_U = \\{e_{u,u'}|(u,u' \\in U) \\land C_U(u,u') \\geq 1\\}$, $E_B = \\{e_{b,b'}|(b,b' \\in B) \\land C_B(b,b') \\geq 1\\}$. BunCa integrates user-bundle interactions with homogeneous correlations to thoroughly exploit the intrinsic relationships among users and bundles in graph $G = \\{V,\\bar{E}\\}$, where $V = \\{U \\cup B\\}$ and $E = \\{E_{UB} \\cup E_U \\cup E_B\\}$ respectively describe the set of vertices and the set of edges.\nGraph Construction in the Coherent View. The bundle-item bipartite graph $G_{BT}$, and user-item bipartite graph $G_{UT}$ are leveraged to effectively aggregate information on item-level representations. The graph $G_{BT} = \\{V_{BI}, E_{BI}\\}$ is constructed by the affiliations between bundles and items in $Z$, where $V_{BT} = \\{B \\cup I\\}$ and $E_{BT} = \\{e_{b,i}|b \\in B, i \\in I\\}$ represent the set of vertices and edges. User preferences, derived from historical interactions with standalone items, also impact decision-making for bundle purchases. Thus, the graph $G_{UT} = \\{V_{UT}, E_{UI}\\}$, where $V_{UT} = \\{U \\cup I\\}$ and $E_{UI} = \\{e_{u,i}|u \\in U, i \\in I\\}$ are established based on the interactions between users and items in $Y$. Furthermore, at the beginning of the training phase, the features of users $T_u \\in R^{|U|\\times d}$, bundles $T_B \\in R^{|B|\\times d}$, and items $T_I \\in R^{|I|\\times d}$ are randomly initialized, where d is the embedding dimensionality."}, {"title": "3.2 Cohesive View Representation Learning", "content": "As mentioned, the heterogeneous graph may help enhance robust propagation of high-order collaborative signals by incorporating homogeneous correlations. BunCa adopts the LightGCN operation [9] to encode cohesive representations of users and bundles, excluding self-connections and non-linear transformations in"}, {"title": "3.3 Coherent View Representation Learning", "content": "For the Coherent View, BunCa aims to explicitly leverage the asymmetric relation between items based on the user preference (UP) sub-view and the bundle construction (BC) sub-view to enhance the modeling of decision-making factors. Learning these sub-views improves item embeddings, hence consolidating the representations for users and bundles. These representations are fused to highlight vital information that determines user preferences and bundle construction. Initially, we employ a coarse-grained mixture method to create item-item symmetric relations. The co-occurrence item matrices from different aspects are computed by the matrix multiplication as follows:\n$C_I^{UP} = Y \\cdot Y^T, C_I^{BC} = Z^T \\cdot Z$ (3)\nwhere $C_I^{UP}, C_I^{BC} \\in R^{|I|\\times |I|}$ represent item co-occurrence based on user-item interactions Y and bundle-item affiliations Z. The symmetric connections between items are normalized as follows:\n$\\bar{C}_{(i,j)} = \\begin{cases} 1 & \\text{if } C_{(i,j)} \\geq 1 \\land i \\neq j, \\\\ 0 & \\text{otherwise} \\end{cases}$ (4)\nwhere i, j \u2208 I refer to the corresponding items. Filtering the threshold of $C_{(i,j)}$ can be considered empirically to achieve better performance on different data domains. It is notable that the symmetric matrix $C_I$ is uniform symbol for $C_I^{UP}, C_I^{BC}$ due to the similar calculations of two sub-views in many scenarios."}, {"title": "Multi-Prospect Causation Network", "content": "Assuming that causation-sensitive re-lationships exist among items frequently purchased together, BunCa employs Multi-Prospect Causation Network (MPCNet) to explicitly model asymmetric associations between items. MPCNet is constructed with L prospects, each rep-resented by a learnable prospect vector $p_l \\in R^d$. For the l-th prospect, the weight $r_{ji}^l$ signifies the influence from item j to item i based on various user preferences and bundling strategies, derived as follows:\n$r_{ji}^l = \\Psi^l_{src} \\cdot t_j \\oplus \\Psi^l_{dst} \\cdot t_i \\oplus p_l$ (5)\nwhere $\\Psi^l_{src}, \\Psi^l_{dst} \\in R^{d \\times d}$ are learnable parameters for the source and destination object in the l-th prospect; $t_i, t_j \\in R^d$ denote the representations of item i and item j; $\\sigma(.)$ is the non-linear activation function; $\\oplus$ denotes the element-wise summation; and b is the bias parameter.\nIn the l-th prospect, the asymmetric causation matrix $A^l \\in R^{|I|\\times |I|}$, repre-senting the causation-sensitive relationships among items at fine-grained level, is computed by the attention mechanism concept of GATv2 [3]. The weight $A_{(i,j)}^l$ describes how much item i is influenced by item j, defined as follows:\n$A_{(i,j)}^l = \\frac{exp(r_{ji}^l) \\bar{C}_{(i,j)}}{\\max_{j'\\in I}{\\Sigma}_j exp(r_{j'i}^l) \\bar{C}_{(i,j')}, \\epsilon}$ (6)\nwhere $\\epsilon \\in R$ is a fixed constant; \u2219 display the multiplication between two scalars.\nEnhancing Item Representation. The asymmetric relationships obtained from MPC-Net are utilized to encode the latent representation of item $t_i^l \\in R^d$ in the l-th prospect, formulated as follows:\n$\\bar{t}_i^l = \\Sigma_{j\\in I} A_{(i,j)}^l \\Omega^l_{orc} \\cdot t_j$ (7)\nwhere $\\Omega^l_{orc} \\in R^{d \\times d}$ denotes the dense layer to learn item features; and $t_j \\in R^d$ denotes other item representation. Subsequently, the multi-prospect item representation is devised using the residual connection method as:\n$t_i^* = \\alpha \\frac{1}{L} \\Sigma_{k=1}^{L} \\bar{t}_i^l + (1-\\alpha)t_i$ (8)\nwhere $t_i^* \\in R^d$ is the enhanced item representation, combining individual features and aggregated information from connected items with a controlled influence \u03b1\u2208 [0,1]. It is notable that $t_i$ serves as a uniform placeholder, representing both $t_i^{UP} \\in T^{UP}$ and $t_i^{BC} \\in T^{BC}$, denoting the enhanced item representation of the UP sub-view and BC sub-view.\nFor UP sub-view, the item representation $t_i^{UP}$ is employed alongside the user's preference $t_u \\in T_u$ as the node's initial feature within the user-item graph $G_{UT}$. The graph-based propagation process utilizes the LightGCN operation similar"}, {"title": "3.4 Contrastive Learning Module", "content": "The discrete contrastive learning is directed at minimizing the inconsistency between two different views, whereas the concrete contrastive learning strives to enhance the distinctiveness of augmented representations.\nDiscrete Contrastive Learning. Inspired by CrossCBR [12], BunCa addresses variations in user preferences for items and bundles by minimizing inconsistencies in representations across different views. The in-batch negative sampling is adopted to construct the negative pairs [17]. Relied on InfoNCE [8], the discrete contrastive loss function for user representations is computed from contrastive pairs $(t_u^{SV}, t_u^{RV})$ as follows:\n$L^{DC} = - \\frac{1}{|U|} \\Sigma_{u\\in U}log\\frac{exp((cos(t_u^{SV},t_u^{RV})/\\tau))}{\\Sigma_{u'\\in U}exp((cos(t_u,t_{u'})/\\tau))}$ (12)\nwhere u' represents a user other than u; cos(...) denotes the cosine similarity function; \u03c4 is the temperature hyper-parameter that help to distinguish the positive and negative samples. The formula for calculating $L_B^{DC}$ is derived similarly.\nConcrete Contrastive Learning The concrete contrastive learning is devised to distinguish the unique characteristics of each individual user and bundle. We create the combination of user preferences and bundle features as follows:\n$t_u^a = t_u^{RV} \\oplus t_u^{SV}, t_b^c = t_b^{RV} \\oplus t_b^{SV}$ (13)\nwhere $t_u^a, t_b^c$ denote the fused multi-view representation of user and bundle, respectively. The formulation of the concrete contrastive loss function for user representations is derived as follows:\n$L_u^{CC} = - \\frac{1}{|U|} \\Sigma_{u\\in U}log\\frac{\u0435\u0445\u0440(1/\\tau)}{\\Sigma_{u'\\in U}exp((cos(t_u^a,t_{u'}^a)/\\tau))}$ (14)\nwhere u' denotes a different user of u; cos(.,.) denotes the cosine similarity function; and \u03c4 is the temperature hyper-parameter that aids in distinguishing between positive and negative samples. The same operation is repeated for the concrete contrastive loss of bundle $L_B^{CC}$.\nThe final contrastive loss is derived from the dyadic contrastive learning techniques described above as follows:\n$L^{CL} = \\gamma(\\frac{L^{DC}+L_B^{DC}}{2})+(1-\\gamma)(\\frac{L^{CC}+L_B^{CC}}{2})$ (15)\nwhere \u03b3\u2208 [0, 1] controls which contrastive learning is more important."}, {"title": "3.5 Prediction and Joint Optimization", "content": "For the comprehensive representations, we effectively capture augmented infor-mation from both views, derived as follows:\n$t_u = [t_u^{SV} || t_u^{RV}], t_b = [t_b^{SV} || t_b^{RV}]$ (16)\nwhere the hyper-parameter \u03bc\u2208 [0,1] controls the impact of views on the final user's preference and bundle's feature; || denotes the concatenation; and $t_u, t_b \u0404 R^{2d}$ respectively represent the fusion of user's preferences and bundle's features, combining Cohesive View and Coherent View learning.\nFinally, the interaction probability $\u0177_{u,b} \u2208 R$ between user u and bundle b is calculated by the inner-product as follows:\n$\u0177_{u,b} = (t_u)^T t_b$ (17)\nThe Bayesian Personalized Ranking loss [15] is utilized to enhance probabilities for interacted user-bundle pairs while reducing for non-interacted pairs:\n$L^{CBPR} = \\Sigma_{(u,b,b') \\in S}-Iog(\u0177_{u,b} \u2013 \u0177_{u,b'})$ (18)"}, {"title": "4 Experiments", "content": "In this section, we conduct extensive experiments on benchmark datasets to validate the effectiveness of BunCa and investigate the importance of its components."}, {"title": "4.1 Experimental Setup", "content": "Datasets. According to popular studies [4,12,14], we adopt three benchmark datasets for the bundle recommendation evaluation, including: The Youshu 1 dataset consists of bundles formed by lists of books that is purchased in each user session; the NetEase 2 dataset captures user-generated song lists as bundles; the iFashion [6] dataset establishes outfits composed of clothes and accessories as bundles. The statistics of these datasets are shown in Table 1. Specially, c-score metric, according to [14], present the high consistency between user-bundle and user-item collaborative relations on iFashion but limited on Youshu and NetEase.\nEvaluation Metrics. Recall (R@K) and Normalized Discounted Cumulative Gain (N@K) are two commonly employed metrics for the performance of method in bundle recommendation task. R@K measures the proportion of test bundles within the top-K ranking list. N@K manifests normalized discounted cumulative gain scores aimed at obtaining relevant items at higher positions on the ranking list. Both metrics are employed with K\u2208 {10, 20} for performance validation. The smaller the top-K, the more clearly it demonstrates the model's practical recommendation performance. Average performances in 5 runs with various random initialization are reported. Comparisons are evaluated by two-tailed paired-sample Student's t-test with p-value of 0.05."}, {"title": "Baselines", "content": "We compare BunCa to the three groups of state-of-the-art models:\nTraditional Bundle Recommendation (T): BPR [15], LightGCN [9], and DAM [5].\nMulti-view Learning Bundle Recommendation (M): CrossCBR [12], BGCN [4], MIDGN [23], BundleGT [22], and EBRec [7].\nDistillation Bundle Recommendation (D): DGMAE [14].\nFor BPR and LightGCN, we simply consider bundles at the item level similar to previous reputable studies [5,7,19]. For MIDGN, embedding each user or bundle into k chunks within different feature spaces presents challenges for optimizing performance on large datasets like iFashion, particularly when computational resources are limited. For DGMAE, obtaining complete materials from the authors to ensure absolute reproducibility still faces some difficulties. To facilitate a fair comparison, the available results have been compiled from relevant reputable papers.\nImplementation details. BunCa is implemented using PyTorch on NVIDIA P100 and T4 GPUs, with evaluated datasets in Table 1. Baseline methods are evaluated with the same below settings based on source code and results in reputable works [4,12,22]. The initial embedding size is configured as 64. The learning rate is set as le-3. We adopt Xavier initialization and Adam optimizer for trainable parameters. We tune the regularization weight 12 \u2208 {1e - 6, 4\u0435 - 6, 1-5, 4-5, 1e \u2013 4, 4\u0435 \u2013 4}. The \u03b1, \u03b3, \u03bc, \u03b2, \u03bb\u2081 \u2208 [0; 1] are tuned by grid search."}, {"title": "4.2 Performance Comparison to Baselines", "content": "Table 2 illustrates performance comparison between BunCa and related baselines in term of R@K, N@K metrics with K\u2208 {10, 20}. Generally, the recommendation methods with multi-view learning consistently outperforms the traditional techniques for all metrics. This observation implies the efficiency of the decomposition and modeling of multiple views for the bundle recommendation task.\nAmong the multi-view learning models, BunCa achieves the best performance in the benchmark datasets. Compared to applied contrastive learning methods (e.g., MIDGN, BGCN, CrossCBR), BunCa represents persistent enhancements, which verify the effectiveness of assembling discrete and concrete contrastive learning in providing discriminative representation across different views. Compared to the second-best results (BundleGT, EBRec), BunCa produces statistically significant improvements in terms of R@10 and N@10. Especially, for iFashion, the notable enhancements are 8.25% to 9.57% for both K\u2208 {10, 20}.\nCompared to the DGMAE distillation framework, the performance of BunCa is 13% and 17% superior on R@20 and N@20 for iFashion, but weak for Youshu and NetEase. They affirm the effectiveness of exploiting item causation-sensitive relationships in small-sized bundles, in which bundle items are more coherent. For the case of large-sized bundle datasets such as NetEase and Youshu, the superiority of BunCa could be negatively affected due to noisy connections. In real-world scenarios, users tend to buy bundles less frequently compared to indi-vidual items due to the sensitve prices. To effectively promote user consumption and business marketing strategy, the constructed bundles need to be oriented to-wards specific and explicit intentions [22,24,19]. Therefore, advanced approaches that exploit the interaction between items to model the bundle's targets (e.g., BundleGT, EBRec, BunCa) are clearly more effective on iFashion compared to the other architectures. On the other hand, Youshu and Netease data are solely built from large pre-defined item sets via user session and the limited consistency between the U-B and U-I collaborative relations (c - score).\nMoreover, we investigate the distribution of high-level influence items within bundles, determined by their popularity surpassing the average popularity of the items in the same bundle. According to Figure 3, the distribution on iFashion indicates that each bundle's characteristics are mainly shaped by one or two key components. Conversely, many items within the same bundle demonstrate high-level influence in NetEase dataset featuring large-sized bundles (similar to Youshu). This phenomenon causes noise and hinders the identification of anchor items necessary for transparent bundle modeling. DGMAE hardly models bundle-item affiliations in depth but only synthesizes bundle representations based on the average pooling of item representations [14]. Therefore, DGMAE'S performance can be superior on Youshu and NetEase but are significantly limited on iFashion. The above evidence points to a contrast with the practical intuition of bundle recommendation tasks. This statement demystifies the notable con-"}, {"title": "4.3 Ablation Study", "content": "To investigate the impact of key components in BunCa, we conduct various ablation studies described below.\nEffects of Learning from Different Views. To assess the impact of inte-grating latent representations from different views, learning Cohesive View (SV), Coherent View (RV), UP sub-view, and BC sub-view are selectively omitted and evaluated performance on the three datasets. According to Table 3, the results indicate that learning representations from each view encodes valuable information to enhance prediction performance. Excluding SV learning significantly diminishes BunCa's performance on all datasets, demonstrating its ability to effectively leverage high-order collaborative signals between users and bundles. Besides, the performance drops remarkably once RV-view learning is omitted. It demystifies the effectiveness of learning causation-sensitive relationships between items to enhance latent representations. UP sub-view representations exhibit a marginal decrease of approximately 1% when omitted on iFashion, contributing the least valuable information. Conversely, the performance of UP sub-view significantly affected on NetEase with about 10%. The results on iFashion without the BC sub-view highlight the explicit bundle construction more than the results on Youshu and NetEase. This demonstration also contributes to clarifying the ob-servation in Section 4.2. In summary, integrating latent representations through multi-view learning ensures both cohesion and coherence in bundle construction and user preferences, effectively improving performance.\nEffect of Contrastive Learning Module As depicted in Table 4, we examine the effectiveness of contrastive learning module through experiments involving the removal of the entire module (w/o CL), discrete contrastive learning (w/o DC), and concrete contrastive learning (w/o CC). The results across the three datasets simultaneously emphasize the pivotal role of modeling multi-view information integrated with contrastive learning. Notably, the substantial impact of discrete contrastive learning demonstrates its effectiveness in aligning the representations of seperate views. This implies that each view can extract cooperative information from the other, leading to mutual enhancement. The addition of concrete contrastive learning further confirms that the contrastive learning module can enhance the discrimination of each user/bundle in the fused representations.\nImportance of Asymmetric Causation Matrix The causation matrix A learned by the MPCNet module enhances item-level representation t for bun-dle recommendation. In order to assess its significance, we compare it against alternatives: i) the original symmetric co-occurrence matrix from UP sub-view (w UP-sym) or BC sub-view (w BC-sym); ii) both original symmetric co-occurrence matrices from UP and BC sub-views (w UP-BC-sym); iii) normalized Laplacian symmetric correlation matrix as in [10] (w SnLm). Figure 4 shows a notable per-formance decrease of BunCa without asymmetric matrix-enhanced item represen-tations, instead simply employing symmetric item-item matrices. This demonstration validates the significance of asymmetric relationships in real-world sce-narios, affirming the hypothesis discussed in Section 1."}, {"title": "Effects of key hyper-parameters", "content": "In Figure 5, the impact of key hyperparameters, \u1e9e and L, on BunCa's performance for iFashion is depicted. The parameter \u1e9e regulates the contribution of enhanced item representations from the BC sub-view and UP sub-view. As \u03b2 increases, the performance follows an ascending trend until reaching its peak at \u03b2 = 0.8, underscoring the crucial role of the BC sub-view in refining item representations. Regarding L, the performance ex-hibits minor fluctuations within the range of 1 to 5 prospects before a decline is observed with L = 6. This decline is attributed to noise problems that increase simultaneously with latent features of high-order neighbors. After tuning, the optimal settings for iFashion are determined to be \u03b2 = 0.8 and L = 5. Similar tuning processes for Youshu and NetEase yield comparable observations."}, {"title": "4.4 Qualitative Showcase", "content": "Some qualitative examples in the iFashion dataset is illustrated in Figure 6 due to the coherence and specificity of interconnected items, whereas Youshu and NetEase only provide the IDs of objects. The asymmetric weights indicate the difference effect among items, resulting in determining the explicit target of bundle features. Thereby, within each bundle, certain anchor items can be identified, and their influence on complementary items varies depending on causation signals. For instance, considering the bundle 15707 containing a shirt and earrings."}, {"title": "5 Conclusion", "content": "This study design a novel approach to address bundle recommendation by em-phasizing the significance of asymmetric relationships between items. Our pro-posed model BunCa leverages item-level causation-enhanced multi-view learning, showcasing significant improvements and notable points, as evidenced by exten-sive analytics conducted on three benchmark datasets. The architecture of BunCa lies in learning two distinct views: the Coherent View, employing the Multi-Prospect Causation Network for causation-enhanced representation learning; and the Cohesive View, utilizing high-order collaborative signals of user-bundle interaction to aggregate comprehensive representations. In addition, Bunca si-multaneously integrates concrete and discrete contrastive learning, enhancing the consistency and self-discrimination of representations from both views. Our work not only validates the efficacy of BunCa but also emphasizes the importance of considering asymmetric item relationships for bundle-related tasks."}]}