{"title": "EDA-AWARE RTL GENERATION\nWITH LARGE LANGUAGE MODELS", "authors": ["Mubashir ul Islam", "Humza Sami", "Pierre-Emmanuel Gaillardon", "Valerio Tenace"], "abstract": "Large Language Models (LLMs) have become increasingly popular for generating RTL code. How-\never, producing error-free RTL code in a zero-shot setting remains highly challenging for even\nstate-of-the-art LLMs, often leading to issues that require manual, iterative refinement. This addi-\ntional debugging process can dramatically increase the verification workload, underscoring the need\nfor robust, automated correction mechanisms to ensure code correctness from the start.\nIn this work, we introduce AIVRIL2, a self-verifying, LLM-agnostic agentic framework aimed at\nenhancing RTL code generation through iterative corrections of both syntax and functional errors.\nOur approach leverages a collaborative multi-agent system that incorporates feedback from error\nlogs generated by EDA tools to automatically identify and resolve design flaws. Experimental\nresults, conducted on the VerilogEval-Human benchmark suite, demonstrate that our framework\nsignificantly improves code quality, achieving nearly a 3.4\u00d7 enhancement over prior methods. In the\nbest-case scenario, functional pass rates of 77% for Verilog and 66% for VHDL were obtained, thus\nsubstantially improving the reliability of LLM-driven RTL code generation.", "sections": [{"title": "1 Introduction", "content": "The rapid development of Artificial Intelligence (AI) has led to transformative changes across various industries, with\nLarge Language Models (LLMs) standing out as powerful tools capable of generating human-like text and interpreting\ncomplex user instructions. Within the field of hardware design, LLMs hold the potential to revolutionize the entire design\nprocess, with projections suggesting that both front-end and back-end tasks could soon become fully automated [1,2].\nAmong the tasks gaining significant attention is the automated generation of Register Transfer Level (RTL) code.\nBy interpreting user intent with minimal human input, LLMs can streamline workflows, effectively bridging the gap\nbetween conceptual design and physical implementation, thereby ultimately enhancing productivity.\nHowever, despite their potential, the probabilistic nature of LLMs poses critical challenges, particularly in zero-shot\nprompting scenarios. In fact, without task-specific training, LLM outputs often contain syntactical and functional errors.\nWhile progress has been made in Generative AI (GenAI) for RTL design, concerns about the accuracy and reliability of\ngenerated code still remain. Frequently, the output requires substantial manual correction [3], diminishing the efficiency\npromised by this new technology which instead often leads to an increased verification burden. This manual iterative\ncorrection process is time-consuming and can introduce additional errors, thus highlighting a critical gap in current\nsolutions: the lack of robust, automated verification mechanisms enclosed within GenAI solutions.\nIn response, recent efforts have explored integrating multi-agent systems into RTL code generation workflows. These\nsystems utilize collaborative agents that leverage feedback from Electronic Design Automation (EDA) tools to iteratively\ndebug both syntactical and functional errors [3, 4]. However, most current solutions are limited, addressing isolated\nissues, e.g., such as syntax correction or partial debugging, without offering a fully integrated LLM-driven code"}, {"title": "2 Background & Related Work", "content": "Decision-making frameworks for multi-agent systems are set to substantially influence GenAI-driven methodologies in\nhardware design. This section provides an overview of how verbal reasoning and action planning interact in autonomous\nsystems, underscoring their growing role in GenAI applications for RTL design. Recent breakthroughs and key\nchallenges in this evolving field are also highlighted."}, {"title": "2.1 Multi-Agent Systems", "content": "The integration of verbal reasoning with decision-making processes in autonomous systems has been a significant\nfocus of recent research. LLMs have demonstrated their ability to manage multi-step reasoning, solving tasks such as\narithmetic, commonsense reasoning, and symbolic operations [8]. By decomposing complex problems into sequential\nsteps\u2014an approach commonly referred to as chain-of-thought prompting\u2014LLMs effectively enhance the reasoning\nprocess. However, a notable limitation of these models is their dependence on internal reasoning without factoring-in\nany external data. As the reasoning chain lengthens, the risk of errors or hallucinations increases, which can compromise\nthe output reliability. Without external validation, models may generate responses that, while seemingly plausible, are\nultimately inaccurate.\nTo mitigate these shortcomings, recent efforts have explored LLM agents in interactive environments where predictions\nand action planning are based on real-time observations [9]. A notable paradigm in this domain is ReAct [10], which\ncouples reasoning with subsequent actions. This combination enables the model to plan and monitor actions while\nadapting dynamically to inputs received by the environment it operates in. This reasoning process supports the model in\nrefining its plans, while external actions allow for interaction with real-world sources, such as databases, sensors, or other\nagents. This real-world feedback helps validate internal reasoning, reducing errors and hallucinations. As discussed in\nthe next section, GenAI solutions for RTL design have increasingly adopted similar approaches, incorporating reasoning\nand action planning into unified frameworks. As a result, these strategies have enhanced the reliability and quality of\nRTL code, addressing key challenges in automated hardware design."}, {"title": "2.2 GenAI for RTL Design", "content": "Chip-Chat [11] probably represents the first pioneering attempt at reproducing a fully automated hardware design\nworkflow, from initial design to tapeout, by employing general-purpose LLMs like ChatGPT throughout the entire\nprocess. Since then, with the advent of advanced LLMs, zero-shot RTL code generation has significantly improved."}, {"title": "3 AIVRIL2: EDA-Aware RTL Design", "content": "In this section, we detail the internal mechanisms of the proposed framework: a two-stage LLM-aware RTL design\nmethodology with enforced functional verification. The overall structure is depicted in Fig. 1. The framework is built\naround two key loops: the Syntax Optimization and the Functional Optimization loop, each governed by three agents:\nthe Code Agent, Review Agent, and Verification Agent. The Syntax Optimization loop is supervised by the Review Agent,\nwhile the Functional Optimization one falls under the purview of the Verification Agent, as detailed in the following."}, {"title": "3.1 Code Agent", "content": "The Code Agent acts as the primary code generation component within AIVRIL2, and it is responsible for translating\nuser requirements into functional RTL code. As the only source of code generation throughout the process, it ensures\ndesign consistency and coherence. The agent begins by analyzing the user-provided prompt, which outlines the desired"}, {"title": "3.2 Review Agent", "content": "The main role of the Review Agent is to ensure the syntactical correctness of the generated code. Capable of integrating\nwith any industry-standard RTL compiler, its primary function is to meticulously review the code for syntax errors and\nprovide detailed feedback, distilled from compilation logs, to the Code Agent. As illustrated in Figure 2, the Review"}, {"title": "3.3 Verification Agent", "content": "The Verification Agent represents the final stage in our framework and is responsible for ensuring the functional\ncorrectness of the RTL design. This agent triggers once both the RTL code and the testbench have been validated as\nsyntactically correct by the Review Agent. The primary objective of the Verification Agent is to verify that the generated\nRTL code passes all the test cases outlined in the testbench, as generated at step 3 or 6, depending on the stage of the\nprocess. As also shown in Figure 2, the Verification Agent's workflow begins with the simulation process. The agent\nthen analyzes the resulting simulation logs in order to detect any discrepancies between the expected and the actual\noutputs. In the given example, the initial simulation identifies a functional error: \"Test Case 2 Failed: shift_ena should\nbe 0 after 4 clock cycles,\u201d as detailed in step 5. Based on this analysis, the Verification Agent generates a corrective\nprompt to guide the Code Agent in resolving the functional issues identified during the simulation (steps 6 and 7). A\ncritical aspect of this verification workflow is the consistent use of the same testbench throughout all iterations. While\nthe RTL code may undergo multiple revisions based on feedback, the testbench remains unchanged. This approach\nensures a standardized and unbiased evaluation of each RTL version, allowing for precise tracking of improvements and\nconsistent verification in meeting the original functional requirements. The Verification Agent operates in synergy with\nthe Code Agent, providing feedback and receiving updated RTL designs until either all test cases pass successfully or a\npredefined maximum number of iterations is reached. In the example, this iterative process is highlighted when, after\nre-verification following Code Agent's refinements, the output log confirms that \u201cAll tests passed successfully!\u201d (step\n8). This outcome indicates that the RTL now fully satisfies the user's requirements, demonstrating the efficiency of the\nfeedback loop between the Verification and the Code Agent."}, {"title": "4 Experimental Results", "content": "In this section, we present the experimental evaluation of the proposed AIVRIL2 framework. Our goal is to rigorously\nassess the performance and robustness of the tool across a diverse set of benchmarks, ensuring a thorough and unbiased\nanalysis of its capabilities. To achieve this, we selected key evaluation metrics that emphasize the strengths of our\napproach in realistic scenarios. Specifically, we focused on metrics that address both syntactical and functional\ncorrectness, providing a comprehensive perspective on the effectiveness of our solution in handling complex design\ntasks."}, {"title": "4.1 Methodology", "content": "We employed all 156 benchmarks from the VerilogEval-Human benchmark suite [5] in our experiments, which enabled\nus to encompass a broad range of design complexities. For both optimization loops, performance was evaluated using\nthe unbiased pass@k estimator (with k = 1), as described in [14]. We distinguish between pass@ks, which represents\nthe success rate of designs passing all syntax checks, and pass@kf, which reflects the success rate of designs that\nare not only syntactically correct but also functionally accurate. Notably, pass@kF was determined by executing the\ntestbenches provided in the benchmark suite, ensuring a comprehensive validation of the overall approach.\nFor both the syntax check and functional simulation stages, we utilized Vivado Design Suite - HLx Editions 2018.1, as to\neasily enable mixed-language simulations. To gain broader insights into the capabilities of various LLMs in generating\nRTL, we employed different models for the agents: Claude 3.5 Sonnet [15], GPT-40 [16], and Llama3-70B [17]. All"}, {"title": "4.2 Results & Discussion", "content": "Architectural differences among LLMs often lead to varying execution times. This is particularly important to consider\nwhen applying optimization loops around LLMs, as it helps validate the practicality of our approach in real-world\nscenarios. Figure 3 illustrates the average latency for different LLMs, as well as a breakdown of the execution times\nfor both optimization loops across all considered LLM configurations. The most significant latency increase was\nobserved with Llama3-70B when generating VHDL. As the plot suggests, the latency gap from the baseline in this case\nis approximately 6\u00d7 (e.g., 6.68 vs. 39.29 seconds). This is partly due to the higher number of iterations required by\nLlama3-70B to converge towards a solution. More specifically, Llama3-70B required an average of 3.95 cycles for the\nSyntax Optimization loop and 4.7 cycles for the Functional Optimization loop to converge. In contrast, the smallest\nlatency increase was recorded with Claude 3.5 Sonnet for Verilog generation, which showed roughly a 2\u00d7 increase in\nexecution time. This configuration required an average of 2 steps for the Syntax Optimization loop and 3 steps for the\nFunctional Optimization loop. Overall, while some latency gaps may appear significant, it is worth emphasizing that\nthe worst-case average latency introduced by our approach did not exceed 42 seconds. This is a reasonable trade-off,\nconsidering the substantial time saved in avoiding potential manual debugging and verification. Another noteworthy\nobservation is the latency recorded for Claude 3.5 Sonnet during the Functional Optimization loop for VHDL, which\nwas the highest among all solutions. This increased latency can be attributed to the LLM's own processing, particularly\ndue to the higher complexity induced by corrective prompts."}, {"title": "4.3 Comparison with State-of-the-Art Approaches", "content": "As already discussed in Section 2.2, recent frameworks and fine-tuned LLMs have been introduced to enhance RTL\ncode quality within the context of GenAI solutions. Table 2 provides a comparison between our proposed framework\nand existing solutions. For each technique, we report the license associated with the adopted LLM and the pass@1F\nmetric. Due to limited data availability, our comparison focuses on Verilog generation only, as, to the best of the\nauthors' knowledge, this work is the first to evaluate GenAI solutions for VHDL. As shown in the table, our approach\noutperforms existing solutions in both open-source and closed-source regimes. Most notably, the highest performance\ngap is recorded w.r.t. ChipNemo-13B [1], where our solution achieves a 3.4\u00d7 higher pass@1F. These results further\nhighlight the strength of AIVRIL2 in achieving state-of-the-art performance in RTL generation."}, {"title": "5 Conclusions", "content": "In this work, we introduced AIVRIL2, a novel self-verifying, LLM-aware RTL design framework that entails a Syntax\nOptimization and a Functional Verification loop to enhance syntax and functional correctness. Experimental results\ndemonstrated that our framework significantly improves code quality across a wide range of benchmarks, outperforming\nbaseline models and prior solutions in both Verilog and VHDL generation. Despite some added latency, the overall\nexecution times remained reasonable, making the trade-off worthwhile given the reduction in manual verification. These\nresults highlight the robustness and versatility of the proposed framework, paving the way for future advancements in\nautomated GenAI for RTL."}]}