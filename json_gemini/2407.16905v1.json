{"title": "ASSESSING THE ROLE OF CLINICAL SUMMARIZATION AND PATIENT CHART REVIEW WITHIN COMMUNICATIONS, MEDICAL MANAGEMENT, AND DIAGNOSTICS", "authors": ["Chanseo Lee", "Kimon-Aristotelis Vogt", "Sonu Kumar"], "abstract": "Effective summarization of unstructured patient data in electronic health records (EHRs) is crucial\nfor accurate diagnosis and efficient patient care, yet clinicians often struggle with information\noverload and time constraints. This review dives into recent literature and case studies on both the\nsignificant impacts and outstanding issues of patient chart review on communications, diagnostics,\nand management. It also discusses recent efforts to integrate artificial intelligence (AI) into clinical\nsummarization tasks, and its transformative impact on the clinician's potential, including but not\nlimited to reductions of administrative burden and improved patient-centered care.", "sections": [{"title": "Introduction", "content": "Patient information is critical in the delivery of effective care \u2013 thousands of practices, tools, and techniques have been\ndeveloped in patient interview, health record storage, and physical examination purely for the sake of effective usage of\nkey patient information. Clinicians must have an effective understanding of a patient \u2013 including but not limited to\nthe history of present illness (HPI), past medical history (PMH), family history (FH), and more. This allows them to\ndiscern accurate differentials and develop efficacious management plans.\nIn modern healthcare, collected patient information is stored in electronic health records (EHRs), where they lie\nunstructured across thousands of progress notes, lab results, office visits, phone call transcriptions, and the like. Clinical\nsummarization involves condensing this unstructured information into an accurate picture of a patient's medical history\nand current health status into a concise, accessible format. This practice has significant implications for healthcare\nprofessionals, patient health outcomes, and hospital expenditures. However, even in a strictly regulated industry that is\nAmerican healthcare, clinicians have diverse ways of approaching clinical summarization \u2013 with many placing much\ntime, energy, and value, while others not so much.\nTools that streamline the clinical summarization process have been a hot topic of debate, with many arguing for its\neffectiveness in healthcare delivery while others fear issues in data privacy, ethical considerations, and more. This\ndebate is further complicated with the advent of generative AI and its impact on workflows across the industry. However,\nit is no surprise that AI that automates clinical workflow is an exciting frontier. It is an undeniable truth that generative\nAI is finding its foothold cautiously in the hands of physicians \u2013 this review article will explore the current state of\nclinical summarization in healthcare, and how AI pushes its frontiers to previously unexplored heights."}, {"title": "Quantifying Patient Chart Review's Impact on Diagnostic Accuracy and Time Burden", "content": "Patient chart review is the manual clinical summarization conducted through the interpretation of unstructured patient\nhealth data, stored in EHRs in modern times. It is an essential part of any clinical workflow, regardless of clinician,\nspecialty, or patient. Reviewing EHRs allows for the physician to focus on talking with patients effectively by gaining\ncontextual information about the patient.[1] The wealth of information housed within the patient charts is just as\ncritical as the patient interview, physical examination, or lab/imaging workups, especially to avoid misdiagnoses or\ncontraindicatory management plans.\nIn fact, this valuable nature of EHR data is precisely why there are many efforts to implement natural language\nprocessing of clinical narratives into both workflow and diagnostics, including in managing coronary artery disease,\ndepression, and more.[2][3] Especially for patients with chronic conditions, it is generally agreed that clinical free-text,\nor the unstructured narrative information lying inside the health records, is dominant in value over any of the other\nstructured data such as ICD-10 codes, which are often plagued with errors/misdiagnoses.[4] Thus, it should only be\nnatural that literature on EHR have discovered that low quality medical data management and usage are key reasons for\nmedical error. [5]\nOne case study has also shown that unstructured, clinical narrative information contained in EHRs for patient chart\nreview is sufficient for conclusions about the patients' pathophysiological processes and therapeutic advances, even for\nup to 94.9% of cases. In fact, thorough patient chart reviews can take up to 30 minutes per patient case, but this time\ninvestment can have high returns, identifying most or even all of the major patient issues correctly in up to 93.8% of the\ncases. [6]\nHowever, even while taking 30 minutes per patient to conduct a thorough chart review, the diagnostic and management\ndecisions are not perfect \u2013 an independent, second round of patient chart review evaluating the accuracy of the first\nround of patient chart review found that 36.6% of the cases had to be corrected in either the pathophysiological process\nidentification or therapy/management decisions, highlighting the imperfection of even the most thorough patient chart\nreview process. [6]"}, {"title": "Medical Errors Associated with Patient Chart Review", "content": "Most physicians in the United States do not take sufficient time to conduct patient chart review. A survey of 155,000\nU.S. physicians in ambulatory subspecialties or primary care utilizes 5 minutes and 22 seconds per patient encounter[7]\na significant time sink, but nowhere near the 30 minutes average used in the aforementioned case study. The poorer\nquality of the average patient chart review, whether it be due to work burden overload, lack of time, or negligence, leads\nto larger quantities of misdiagnoses, and thus, medical errors/malpractice.\nThere are many medical error scenarios associated with patient chart review. For example, a common case of medical\nerror are iatrogenic adverse drug events (ADE), most commonly caused by inconsistencies in a clinician's knowledge\non patient allergies to medications. There is a wealth of literature and case studies that review these adverse drug\nevents caused by insufficient documentation, poor patient health record communication, and lack of proper information\ncollection from charts. As these case studies show, many of these ADEs involve insufficient knowledge on the side of\na clinician due to incomplete record review and internal inconsistencies found in the unstructured data within health\nrecords.[8] In fact, another study highlights this lack of clinician knowledge despite sufficiently documented patient\ninformation, having caused 29% of the study's preventable ADEs. [9]\nAnother sector where patient chart review is key is transition of care. Patients being transferred between clinicians,\nwhether internally in hospital systems or across practices, require fluid and comprehensive communication of all relevant\npatient health history to prevent confusion, poor management, and ultimately malpractice or negligence. An average\nlarge academic teaching hospital can have up to 4,000 transitions per day, and this high volume of transition is a rich\nbreeding ground for medical errors due to lack of comprehensive patient information and thus, a poor understanding of\na patient's status. [10] In fact, a 2016 study showed that 30% of malpractice claims in the U.S. were attributed to poor\ncommunication between clinicians, resulting in 1,744 deaths and $1.7B in claims.[11]"}, {"title": "Information Overload and Physician Burnout", "content": "The root driver behind patient chart review causing medical errors has been investigated quantitatively through literature.\nOn the other side of the patient-physician interaction, consider the burden of information placed on the physician. Each\npatient can have patient records as short as 29 pages and as long as over 500 pages long, [12] and to paint an accurate\npicture from the mountains of data is a monumental manual task. A physician spends an average of 4.5 hours per day\ndoing EHR workflow, with 33% of that being patient chart review, translating to 1.5 hours of patient chart review per\nday.[7] Even the average U.S. medical resident spends 112 hours per month exclusively reading patient charts. [13]\nIt is difficult to quantify exactly what portion of medical errors are caused by problems with the information crisis\nand electronic health records. However, it is still possible to discern what the errors that were made from information\nhandling processes, which heavily involve patient charts. In fact, one family medicine case study found that 29% of the\nerrors made can be associated with patient information processing. These errors include the availability of information\nwithin patient charts, physician-physician communications, and clinical knowledge gaps.[17]\nAnother study of 2,590 primary care physicians showed that 69.6% receive more information that they can handle.\nThis study measured the number of alerts a physician received, which is a common proxy for measuring information\noverload. Furthermore, these alerts lead to almost 30% of these physicians reporting missing test results and delayed\npatient care as a result, another proxy for medical errors due to the information overload.[18] These studies highlight\nthe burden of information placed on the physician, and how it impacts not just their time usage, but also prevalence of\nmedical errors and physician burnout."}, {"title": "The Role of AI in Clinical Summarization", "content": "The growing crisis in healthcare information volume, physician burnout, and patient-physician relations, increasing\nefforts to incorporate artificial intelligence into clinical summarization. Natural language processing (NLP) can be\nused to determine illnesses or patient information from clinical free-text.[19] The increasing capabilities and token\nstorage of LLMs in 2024 such as Google's Med-Gemini, Meta's Llama 3, OpenAI's ChatGPT4, or Anthropic's Claude\n3.5, has allowed for these models to process the enormous portions of information for summarization and analysis.\nIn recognition of the stringent accuracy, the need for personalization, privacy regulations, and the high knowledge\nfloor needed for AI in clinical workflow, the innovation space gave birth to companies like Sporo Health to combat\nthe aforementioned issues in clinical summarization using AI agents. Several case studies verify AI usage in various\nclinical settings to aid in chart review and summarization of clinical information."}, {"title": "Radiology Case Reports and Biomedical Research", "content": "Radiological reports, essential for diagnosing and monitoring diseases, can be lengthy and complex, often integrated\ninto almost every progress note. While the data is more structured than typical progress notes, there is much to unpack\nin what is necessary information and what is not.\nOne case study utilized NLP summarization models from various sources for the purpose of summarizing neuro-\nradiology case reports and charts. These included models such as BARTcnn, trained on news datasets from CNN,\nLEDClinical, trained on references from the MIMIC-III dataset, and even GPT3 davinci from OpenAI.[20] Both\nclinical-sided physician evaluation of comprehensibility, accuracy, redundancy, and readability as well as standard\nAI-sided quantitative evaluation using s ROUGE or BERTscore[21][22] was performed on the summarization capabilities\nof these models.\nThese AI models, especially BARTcnn and GPT3 davinci, demonstrated considerable summarization capabilities,\nenhancing the readability and comprehensiveness of summaries, while simultaneously reducing text length to less than\n20% of the original case reports. These results are especially notable when considering that most of the models tested\nwere not trained on any clinical dataset, which opens much potential for using these Als as tools for enhancing clinical\nworkflow in fast-paced clinical settings. [20]\nBeyond patient case reports, AI is also applied in summarizing extensive biomedical literature. This includes systematic\nreviews and meta-analyses, which are pivotal for evidence-based medicine. The use of AI helps in distilling vast\nvolumes of data into digestible summaries, although challenges such as maintaining accuracy and managing large\ndatasets persists. [19]"}, {"title": "Capabilities of Large Language Models with Patient Charts", "content": "A recent study published in Nature Medicine evaluated the leading Large Language Models (LLMs) in their ability to\nsummarize clinical information in patient charts.[23] Eight open source and proprietary models including ChatGPT3.5,\nChatGPT4, LLaMa-2, Med-Alpaca, which were then adapted to the summarization tasks at hand using in-context\nlearning (ICL) and quantized low-rank adaptation (QLoRA), were evaluated in its capabilities to summarize progress\nnotes, radiology reports, dialogue, and other patient-sided sources of information. Datasets utilized for clinical\nsummarization tasks included MIMIC-III, MIMIC-CXR, and ProbSum. The study found that the best-performing\nmodels, namely ChatGPT4 adapted with ICL, performed superior to even physicians when evaluated both on the\nAI-sided metrics and clinical-sided expert evaluations by other physicians. In fact, the best model even produced fewer\ninstances of fabricated information, suggesting that its hallucination rate is lower to the average clinician's summary.\nThis has large implications on how the usage of these LLMs can significantly reduce rates of medical error associated\nwith patient chart review."}, {"title": "Methodologies Behind Innovating AI into Clinical Summarization", "content": "Beyond the typical usages of AI in clinical summarization, there have also been efforts to improve AI performance\nin clinical settings. The SPeC framework represents a breakthrough in addressing the variability of AI outputs in\nclinical summarization. By employing soft prompts, this method enhances the stability and consistency of AI-generated\nsummaries, which is critical for clinical accuracy and reliability. The framework aims to mitigate the impact of prompt\nquality on the performance of LLMs, demonstrating a novel approach to improving AI utility in healthcare.[24]\nFurthermore, one must also consider that many AI applications in clinical summarization heavily rely on using\ncomprehensive datasets like the MIMIC series, including MIMIC-CXR, as training data, which contains extensive patient\nreports, unstructured clinical information, radiological reports, and images. While there are not many comprehensive\ndatasets that present an end-all-be-all solution to the open-source data problem in healthcare, the available datasets\nenable the training and refinement of AI models for specific tasks such as disease detection and report generation,\nhighlighting the importance of high-quality, detailed data for successful AI implementation."}, {"title": "Challenges in AI-driven Clinical Summarization", "content": "The use of AI in handling sensitive patient information raises significant privacy concerns. Ensuring the security of\npatient data and compliance with healthcare regulations such as HIPAA in the US is paramount. AI systems must\nbe designed to prevent unauthorized data access and ensure patient confidentiality. The accuracy of AI-generated\nsummaries is heavily dependent on the quality of the input data. Errors in initial data or poorly calibrated AI models can\nlead to incorrect summaries, which may adversely affect patient care. Therefore, continual monitoring and refinement\nof AI systems are necessary to maintain their reliability. Lastly, integrating AI tools into existing healthcare IT systems\nposes significant technical and operational challenges. Compatibility with diverse systems, user training, and the\nadaptation of clinical workflows are essential factors that must be addressed to achieve seamless integration and\nutilization."}, {"title": "Moving Forward", "content": "AI in clinical summarization offers transformative potential for healthcare, promising to enhance the efficiency and\naccuracy of medical documentation and decision-making. However, realizing this potential requires overcoming\nsubstantial challenges in data management, system integration, and maintaining the ethical standards of patient care.\nFuture developments in this field must focus on refining AI technologies, improving their adaptability, and ensuring\nthey align with the overarching goal of improving patient outcomes.\nAs AI continues to evolve, future research will likely explore more sophisticated models that can handle a wider\nrange of data types and clinical scenarios. Additionally, the ethical implications of AI in healthcare, such as racial or\nsocioeconomic bias in AI algorithms and the impact of automation on employment within the healthcare sector, will\nneed to be carefully considered."}]}