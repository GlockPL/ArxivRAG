{"title": "INVESTORBENCH: A Benchmark for Financial Decision-Making Tasks\nwith LLM-based Agent", "authors": ["Haohang Li", "Yupeng Cao", "Yangyang Yu", "Shashidhar Reddy Javaji", "Zhiyang Deng", "Yueru He", "Yuechen Jiang", "Zining Zhu", "Koduvayur Subbalakshmi", "Guojun Xiong", "Jimin Huang", "Lingfei Qian", "Xueqing Peng", "Qianqian Xie", "Jordan W. Suchow"], "abstract": "Recent advancements have underscored the po-\ntential of large language model (LLM)-based\nagents in financial decision-making. Despite\nthis progress, the field currently encounters\ntwo main challenges: (1) the lack of a com-\nprehensive LLM agent framework adaptable\nto a variety of financial tasks, and (2) the ab-\nsence of standardized benchmarks and consis-\ntent datasets for assessing agent performance.\nTo tackle these issues, we introduce INVESTOR-\nBENCH, the first benchmark specifically de-\nsigned for evaluating LLM-based agents in di-\nverse financial decision-making contexts. IN-\nVESTORBENCH enhances the versatility of\nLLM-enabled agents by providing a compre-\nhensive suite of tasks applicable to different fi-\nnancial products, including single equities like\nstocks, cryptocurrencies and exchange-traded\nfunds (ETFs). Additionally, we assess the rea-\nsoning and decision-making capabilities of our\nagent framework using thirteen different LLMs\nas backbone models, across various market en-\nvironments and tasks. Furthermore, we have cu-\nrated a diverse collection of open-source, multi-\nmodal datasets and developed a comprehensive\nsuite of environments for financial decision-\nmaking. This establishes a highly accessible\nplatform for evaluating financial agents' perfor-\nmance across various scenarios.", "sections": [{"title": "Introduction", "content": "The recent studies on large language model (LLM)-\nbased agents have demonstrated impressive perfor-\nmance across a range of decision-making tasks in\ncomplex and open-ended environments spanning\nvarious domains (Zhang et al., 2024b; Guo et al.,\n2024; Eigner and H\u00e4ndler, 2024; Wang et al., 2024).\nHowever, developing agentic frameworks tailored\nspecifically for financial decision-making remains a\nsignificant challenge. This complexity arises from\nthe need for agents to acutely discern and priori-\ntize decisive signals, and then make sequentially\nhigh-quality decisions within the volatile and multi-\nfaceted financial markets, where information varies\nin time sensitivity and modality.\nFurthermore, the design of financial agents be-\ncomes increasingly complex when applied across\nmultiple decision-making tasks, due to the signifi-\ncant variation in key factors influencing financial\ndecisions across different objectives and task types.\nFor instance, single-equity tasks like stock trading\nrequire analyzing company-specific and industry-\nwide data, including market metrics, sector trends,\nperformance reports, and relevant news (Yi et al.,\n2022). In contrast, cryptocurrency trading is highly\nsensitive to crypto-specific news and sentiment\ndue to its dynamic nature (Bhatnagar et al., 2023).\nETFs, on the other hand, typically follow passive in-\nvestment strategies, emphasizing long-term growth\nand cost efficiency (Madhavan, 2016).\nThe recent emergence of financial LLM-based\nagent frameworks such as FINMEM (Yu et al.,\n2024a), FINAGENT (Zhang et al., 2024a), CRYPTO-"}, {"title": "LLM Trading Agents", "content": "In this section, we define a framework of the LLM-\nbased agents in the INVESTORBENCH and formal-\nize the financial decision-making tasks within the\ncontext of partially observable Markov decision\nprocess (POMDP) (Bertsekas and Shreve, 1996;\nLiu et al., 2020; Kabbani and Duman, 2022)."}, {"title": "Definition", "content": "The LLM-based agent in INVESTORBENCH is\nstructured as a large language model-modulo frame-\nwork, designed to match or surpass the capabilities\nof professional human investors. This framework\nconsists of several interconnected modules, each\ntailored to handle the distinct challenges presented\nby the financial market's volatility and complexity:\nBrain/Backbone (LLM): This module, which is\nthe LLM itself, serves as the core of the LLM-\nbased agent. It enhances the agent's capabilities\nby enabling it to understand, process, and generate"}, {"title": "Modeling financial decision-making", "content": "Formally, we model a financial decision-making\nprocess as infinite horizon POMDP with time index\n$T = \\{0,1,2,\\ldots\\}$ and discount factor $\\alpha \\in (0, 1]$."}, {"title": "InvestorBench", "content": "He we introduce the detailed architecture of In-\nvestorBench, as illustrated in Figure 1."}, {"title": "Benchmark Composition", "content": "INVESTORBENCH is organized into four main com-\nponents: (1) Data Sources and Market Environ-\nments: INVESTORBENCH utilizes a wide range of\nopen-source data and incorporates third-party APIs,\nsuch as Yahoo Finance and SEC EDGAR, to create\na comprehensive, multi-modal market environment\ndata warehouse. (2) LLM Agent: INVESTOR-\nBENCH includes an advanced LLM-based agent\nequipped with modules for Brain, Perception, Pro-\nfile, Memory, and Action. This agent is enhanced\nwith external tools (such as tabular data readers and\nAPI callers) and data operations (including vector\ndatabase management, information reinforcement,\nand retrieval). (3) Financial Decision-Making\nTasks: INVESTORBENCH offers three distinct fi-\nnancial decision-making tasks, differentiated by\ntheir asset types. (4) Evaluation Metrics: The effi-\ncacy of all tasks within INVESTORBENCH is evalu-\nated using a set of standard metrics in the quantita-\ntive finance field, providing a thorough evaluation\nof the decision-making capabilities of the LLM-\nbased agent."}, {"title": "Trading Environments", "content": "We release three datasets, each curated from\ndiverse sources, to construct tailored financial\nmarket environments for specific tasks. Our\nobjective is to address the current gap in evaluation\nenvironments for financial decision-making agent\nframeworks and to offer a fully open platform\nfor the comprehensive assessment of agents\nacross various tasks. Below, we introduce each\nenvironment, categorized by task type, detailing its\nscope and the data sources it incorporates."}, {"title": "Evaluation metrics", "content": "We employ four widely recognized financial met-\nrics to evaluate and compare the investment per-\nformance of various LLMs serving as backbones\nacross different tasks: : Cumulative Return (CR)\n(Hull, 2007), Sharpe Ratio (SR) (Sharpe, 1994),\nAnnualized Volatility (AV) (Cochrane, 1988), and\nMaximum Drawdown(MDD) (Ang and Chen,\n2003). Note that CR and the SR are often con-\nsidered more essential than AV and MDD in evalu-\nating asset trading performance due to their focus\non long-term gains and risk-adjusted returns by\ntheir definition. Here, we regard these two met-\nrics as primary metrics when evaluating the exper-\niment outcomes. The detailed explanation is in\nAppendix B."}, {"title": "Experiment and Discussion", "content": "To establish a baseline and assess the perfor-\nmance of LLM agents, we standardize experimen-\ntal settings and evaluation metrics across various\nfinancial decision-making tasks. Results are pre-"}, {"title": "Experiment Setup", "content": "Table 1 summarizes the performance of a compre-\nhensive list of trading agents. For single equity\ntasks, the baseline is set up by Buy and Hold strat-\negy, while for portfolio management task, it is set\nup by an equal-weight portfolio with the detailed\nrational explained in Appendix. In our experiments,\nthe temperature parameter of all LLM-based agent\nsystems is set at 0.6 to balance response consis-\ntency and reasoning creativity. The performance\nmetrics are reported for the test trajectory with the\nmedian CR, SR, AV, and MDD from five repeated\nepochs. (If the median of these metrics does not\nbelong to the same epoch, the performance is based\non the trajectory with the median SR.)\nFurthermore, the selection of warm-up and test\nperiods differs across various tasks due to the vary-\ning time spans of data collected to construct the\nagent environment. For the single-asset trading\ntasks, the warm-up period of stock trading is from\n2020-07-01 to 2020-09-30 and the test period is\nfrom 2020-10-01 to 2021-05-06. The warm-up pe-\nriod of cryptocurrency trading is from 2023-02-11\nto 2023-04-04 and the test period is from 2023-04-\n05 to 2023-11-05. The warm-up period of ETF\ntrading is from 2019-07-29 to 2019-12-30 and the\ntest period is from 2020-01-02 to 2020-09-21.\nFor LLM deployment, we utilize vllm to deploy\nLLMs. For small-scale LLMs (under 10B parame-\nters), we deploy models on two RTX A6000 GPUs,\neach with 48GB DRAM. For mid-scale LLMS\n(10B to 65B parameters), we use four RTX A6000\nGPUs. For large-scale LLMs (over 65B parame-\nters), models are deployed on eight A100 GPUs,\neach equipped with 80GB DRAM."}, {"title": "Result 1: Stock Trading", "content": "Table 2 presents the performance of thirteen back-\nbone models across seven stocks, accompanied by\nthe average of each metric for all stocks to offer a\nmore comprehensive view of their overall perfor-\nmance. We outline three key insights as follows:"}, {"title": "Result 2 & 3: Cryptocurrency Trading\nand ETF Trading", "content": "In the test phases of both cryptocurrency and ETF\ntrading tasks, market trends are mixed. Notably,\nthe cryptocurrency task shows significantly smaller\nprice fluctuations compared to the ETF task. We\noutline the key features of using an LLM-agent to\nmake financial decisions across these two distinct\nmarkets as follows:\nLarge-sized open-source models and propri-\netary models are needed to effectively cap-\nture trading signals of cryptocurrency markets,\nwhich are highly sensitive to news and finan-\ncial sentiment. As shown in Table 3, using mid-\nsized and small-sized open-source models as the\ndecision-making agent backbone generally results\nin weaker performance than the market baseline\nwith respect to CR and SR.\nETF investment requires proprietary models\nenriched with extensive pre-trained knowledge\nto serve as the agent's \u201cbrain\" and provide ro-\nbust reasoning support. As shown in Table 4,\nproprietary models significantly outperform open-\nsource and financial domain-specific models in this\ntask. This advantage arises from the complexity\nof ETF trading, which necessitates interpreting ac-\ntionable signals across diverse sectors, demanding\nmore strategic, long-term decisions grounded in\ndee comprehension and reflection anchored by\nrich pre-contexts."}, {"title": "Discussion", "content": "Combining all the experimental results, we find\nthat the performance of different LLM varies sig-\nnificantly in stock, cryptocurrency, and ETF trad-\ning. This variation not only reflects the inherent\ncomplexity of financial markets, but also highlights\nthe importance of model selection or fine-tuning.\nFor instance, proprietary LLM generally exhibit be-"}, {"title": "Related Work", "content": "The rapid developement of general-domain lan-\nguage models (LMs) has stimulated the explo-\nration of financial LMs, such as pre-trained LMs:\nFINBERT (Liu et al., 2021; Yang et al., 2020;\nAraci, 2019; Huang et al., 2023), FINBERT-MRC\n(Zhang and Zhang, 2023), FLANG (Shah et al.,\n2022), and several financial LLMs: FINGPT(Liu\net al., 2023), FINMA (Xie et al., 2023), IN-\nVESTLM (Yang et al., 2023), BloombergGPT (Wu\net al., 2023), which leverage extensive training on\ndiverse financial datasets (e.g. stock price data,\nfinancial news and analyst reports) and adapt the\ncapabilities of LMs to the unique needs of financial\napplications. Concurrently, the advancement of\nLLMs has significantly enhanced the development\nof language-based agent frameworks in the finan-"}, {"title": "Financial LLM Benchmarks", "content": "In the realm of financial LLMs, several benchmarks\nhave been developed: FLUE (Shah et al., 2022) in-\ntroduces the first comprehensive benchmark with\nfive financial NLP tasks, including sentiment anal-\nysis, headline classification, named entity recog-\nnition, structure boundary detection, and question\nanswering. Pixiu (Xie et al., 2023) expands this\nbenchmark to include financial document under-\nstanding and classification tasks, incorporating mul-\ntimodal datasets. FinBen (Xie et al., 2024) encom-\npasses 36 datasets covering 24 financial tasks. De-\nspite these advancements, there remains a notable\ngap in benchmarks specifically designed for LLM-\nbased agent applications within the financial sector."}, {"title": "Conclusion", "content": "INVESTORBENCH offers the community two dis-\ntinct modes of engagement. The first mode allows\nparticipants to integrate their fine-tuned LLMs into\nthe INVESTORBENCH's agent framework to under-\ntake financial decision-making tasks. This setup\nenables them to benchmark the performance of\ntheir models against those previously experimented\nwith by our work. The second mode permits users\nto directly incorporate the environment and evalu-\nation metrics of INVESTORBENCH into their own\ndesigned agents, facilitating a comparative analy-\nsis of their agent design's effectiveness. This dual\napproach provides a flexible framework for testing\nand enhancing financial decision-making strategies\nwithin the INVESTORBENCH ecosystem.\nFuture research efforts will expand the bench-\nmark by incorporating additional information\nmodalities, such as audio (e.g., earnings call record-\nings) and graphs (e.g., K-lines, trade charts), to\nexplore whether these data types can enhance\ndecision-making quality. The foundational agent\nframework of INVESTORBENCH is designed to\nseamlessly accommodate these modalities, ensur-\ning that the extended benchmark remains easy to\nuse and scalable."}, {"title": "Limitation", "content": "First, INVESTORBENCH is currently focusing on\nsingle-asset financial decision-making task, with-\nout addressing multi-asset tasks such as portfolio\nmanagement. Second, copyright restrictions on fi-\nnancial domain data may compromise the quality\nof the datasets we create, potentially limiting the\nassessment of model performance."}, {"title": "Ethical Statement", "content": "The authors take full responsibility for the devel-\nopment of INVESTORBENCH, ensuring that the\npublicly available part in dataset does not contain\npersonal information, and conform to established\nethical guidelines. The data are shared under the\nMIT license, requiring users to adhere to its terms.\nINVESTORBENCH is intended for academic and ed-\nucational purposes only and is not a substitute for\nprofessional advice. While efforts have been made\nto ensure its accuracy, the authors and their insti-\ntutions disclaim liability for any outcomes arising\nfrom its use. Users agree to take responsibility for\nethical and lawful use and to indemnify the authors\nand their affiliates against any claims or damages\nresulting from reliance on this Material."}, {"title": "A Memory Ranking Mechanism of\nFINMEM", "content": "Upon receiving an investment inquiry, FINMEM re-\ntrieves the top-K critical memory events from each\nlayer and channels them to the immediate reflection"}]}