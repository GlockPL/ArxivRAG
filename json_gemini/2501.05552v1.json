{"title": "The dynamics of meaning through time: Assessment of Large Language Models", "authors": ["Mohamed Taher Alrefaie", "Fatty Salem", "Nour Eldin Morsy", "Nada Samir", "Mohamed Medhat Gaber"], "abstract": "Understanding how large language models (LLMs) grasp the historical context of concepts and their semantic evolution is essential in advancing artificial intelligence and linguistic studies. This study aims to evaluate the capabilities of various LLMs in capturing temporal dynamics of meaning, specifically how they interpret terms across different time periods. We analyze a diverse set of terms from multiple domains, using tailored prompts and measuring responses through both objective metrics (e.g., perplexity and word count) and subjective human expert evaluations. Our comparative analysis includes prominent models like ChatGPT, GPT-4, Claude, Bard, Gemini, and Llama. Findings reveal marked differences in each model's handling of historical context and semantic shifts, highlighting both strengths and limitations in temporal semantic understanding. These insights offer a foundation for refining LLMs to better address the evolving nature of language, with implications for historical text analysis, AI design, and applications in digital humanities.", "sections": [{"title": "1. Introduction", "content": "Large language models (LLMs) have revolutionized numerous domains, demonstrating remarkable performance across a wide array of tasks, including reasoning, understanding, truthfulness, mathematics, and coding (Periti and Montanelli, 2024; Zhao et al., 2023). The capacity of these models is typically assessed through various benchmarks that evaluate their proficiency in each of these domains (Chang et al., 2024). Central to their success is the combination of model size and the data used during pretraining (Zhao et al., 2023). A growing body of literature explores the relationship between the scaling of model size and the emergence of increasingly sophisticated cognitive abilities, commonly referred to as emergent intelligence (Kaplan et al., 2020). Additionally, other studies emphasize the pivotal role of training data quality, specifically highlighting how pretraining on diverse and specialized datasets can significantly enhance a model's reasoning capabilities (Isik et al., 2024).\n\nThe vast corpus of text used to train these models is predominantly derived from content available on the internet, much of which has been produced over the past few decades (Liu et al., 2024). This temporal context inherently introduces challenges, as much of the text that drives current models reflects contemporary understandings of language and meaning. Consequently, the historical evolution of words, their meanings, and their contextual shifts may be underrepresented in modern training data (Manjavacas and Fonteyn, 2022). This temporal gap poses a particular challenge for LLMs when tasked with interpreting how words and phrases have evolved across time.\n\nThis gap has spurred interest in examining whether LLMs, which are typically trained on contemporary data, can capture the historical evolution of words and their meanings (Cuscito et al., 2024; Manjavacas Arevalo and Fonteyn, 2021; Manjavacas and Fonteyn, 2022). The central motivation of this study is to assess whether current LLMs possess the ability to understand semantic shifts over time. Specifically, it seeks to determine whether models, in their current configurations, can track how word meanings have evolved over the past century. In doing so, this study also explores the possibility of establishing this capacity\u2014tracking and interpreting historical linguistic changes\u2014as a benchmark for future advancements in LLM development. This study aims to understand LLM models' ability to understand changes of a word meaning as a critical dimension of reasoning and language comprehension, with potential implications for a variety of applications in both AI development and interdisciplinary research.\n\nThe findings of this study reveal significant variability in the ability of large language models (LLMs) to interpret temporal semantic shifts, emphasizing that training data quality and domain- specific fine-tuning outweigh model size in determining performance. GPT-4 and Claude Instant 100k demonstrated superior factuality and comprehensiveness, reflecting the advantages of robust training methodologies. Meanwhile, the code-based Llama 34B surpassed larger Llama models, underscoring the value of retraining on structured datasets, such as code, to enhance analytical reasoning and temporal understanding. In contrast, models like Google Gemini and smaller Llama variants struggled to capture nuanced historical contexts, highlighting the limitations of general- purpose training approaches. These insights establish a foundation for advancing LLM design and training strategies, enabling improved applications in historical linguistics, digital humanities, and beyond.\n\nThe paper is organised in six sections. A brief review of LLMs with the scope of word meaning development is laid out in section 2. Section 3 discusses the research methodology and the experiment performed to meet with the research aim and gaols. Section 4 presents the results of the experiment. Section 5 has a comprehensive discussion over the results and how they correlate with similar studies in the same domain. Finally, conclusions are shared in section 6."}, {"title": "2. A review of LLMs in the scope of word meaning development", "content": "The evolution of word meanings over time is influenced by a myriad of factors, including social changes, technological advancements, and cultural dynamics. This interplay between language, history, and culture highlights the importance of understanding semantic change as a gradual process that encompasses both lexical and core meaning shifts. Traditionally, semantic change has been examined through corpus linguistics, where researchers analyze texts from different historical periods to identify shifts in word usage and meaning. By examining word frequencies and the contexts in which they appear, scholars can trace the evolution of language over time (Asri et al., 2024).\n\nIn recent years, diachronic word embeddings have emerged as a powerful tool to capture changes in word meanings across time. These embeddings align words with their respective time periods, enabling a strong understanding of how meanings shift in response to cultural and societal changes. Notably, two statistical laws of semantic change have been proposed: i) words that are used more frequently tend to change at a slower rate, ii) polysemous words exhibit a higher rate of change (Hamilton et al., 2016a). This framework allows researchers to categorize various types of semantic shifts such as drift of meaning based on cultural norms (Spataru et al., 2024), specialisation of a meaning over time (Hamilton et al., 2016a), generalisation of a meaning over time (Wegmann et al., 2020), pejoration and amelioration which refers to a shift towards a negative or positive connotations, respectively (Periti and Montanelli, 2024; Wevers and Koolen, 2020), metaphorical meaning added to an existing word based on pop culture or a change in a society (de S\u00e1 et al., 2024) and finally, the broadening and narrowing of a meaning through time (Vijayarani and Geetha, 2020).\n\nOn the other hand, as LLMs become increasingly integrated into daily tasks, their ability to handle semantic change and cultural variations is crucial. By training LLMs on a diverse corpora and fine- tuning them for specific tasks related to semantic change, researchers can enhance their performance in detecting shifts in meaning (Shen et al., 2024; Tao et al., 2023). However, LLMs often propagate cultural biases inherent in their training data, which can skew responses in cross- cultural contexts (Tao et al., 2023). In addition, LLMs may struggle with complex social scenarios and generate text that deviates from intended meaning (Choi et al., 2023; Spataru et al., 2024).\n\nDespite these limitations, LLMs can grasp cultural common-sense when fine-tuned on balanced datasets that incorporate diverse cultural perspectives (Shen et al., 2024). Addressing the biases in LLMs requires training on time-aware datasets that reflect the aftermath of significant cultural events, such as the term \"coronavirus\" and its evolving meanings (Mousavi et al., 2024). This approach allows for a deeper tracing of historical contexts and semantic changes.\n\nThe use of language models to study the evolution of meaning over time has garnered increasing attention in recent research. Several studies have explored the capabilities of lamguage models in tracking semantic shifts and historical language usage. For instance, Bamler and Mandt, (2017) proposed dynamic word embeddings as a method for capturing temporal variations in word meanings, highlighting the utility of diachronic models in understanding historical text corpora. Similarly, Hamilton et al., (2016) introduced dynamic embeddings to study semantic change over decades, demonstrating how embeddings trained on historical corpora reveal shifts in cultural and social contexts. More recently, MacBERTh was specifically designed to analyze historical texts, leveraging transformers to improve the understanding of linguistic evolution across time periods (Manjavacas Arevalo and Fonteyn, 2021)."}, {"title": "3. Research Methodology", "content": "To evaluate the ability of LLMs to capture the temporal dynamics of meaning, we conducted a comprehensive, multi-dimensional experiment using a range of state-of-the-art models.\n\nLanguage models. We evaluate six large language models in this study. The first is ChatGPT (OpenAI, 2022), for which we use text-davinci-002, a 175B parameter model based on the GPT-3 architecture. The second is GPT-4 (OpenAI et al., 2023), and GPT4O (OpenAI et al., 2024), are more advanced model with improved reasoning and contextual understanding, although its exact parameter count is undisclosed, it is estimated to exceed 175B parameters. The third is Claude (Anthropic, 2023), for which we use Claude 1, with parameters ranging from 52B to 100B. The fourth is Bard, based on Google's LaMDA model (Thoppilan et al., 2022), which comes in configurations including 422M, 2B, 8B, 68B, and 137B parameters. The fifth is Gemini (Google DeepMind, 2024), a model from Google's suite with versions estimated to match or exceed the PaLM 540B model. The sixth is Llama (Meta, 2023), for which we used both Llama 1 and Llama 2, was evaluated at different scales: Llama 1 with 34B parameters, and Llama 2 with 7B, 13B, and 70B parameters.\n\nTerm Selection. A carefully curated list of terms was selected to represent diverse domains, including scientific concepts, historical events, and cultural phenomena. These terms were chosen to evaluate how well each model interprets semantic shifts and the historical context associated with each concept. Two key terms were selected for this study: \"Data Mining\" (a technical term) and \"Michael Jackson\" (a cultural figure). These terms span both technological and cultural evolution from the 1920s to the 2020s, offering a robust platform to assess the LLMs' capacity to track and describe temporal meaning changes.\n\nPrompt Design and Input Format. For each term, we designed specific prompts aimed at assessing the models' understanding of the historical evolution of meaning. A typical prompt asked the models to:\n\u201cCreate a table with two columns. The first column should list decades (e.g., 1920s, 1930s, etc.), and the second should describe the meaning and synonyms for the term based on the knowledge and context of that period.\u201d This prompt structure remained consistent across all models, ensuring that the evaluation was controlled, and the comparison was fair. Prompts were specifically crafted to challenge each model's ability to capture and relay temporal semantic shifts without additional training or fine-tuning.\n\nSubjective Evaluations were conducted by human experts. Two methods were selected based on the following criteria: (1) Factuality score: Experts evaluated how well each model captured the evolution of meaning over time, (2) Comprehensiveness score The extent to which the models effectively answered the question including the description length and number synonyms in each answer, if any."}, {"title": "4. Results", "content": "This section presents the findings from a comparative evaluation of LLMs on their ability to understand the temporal dynamics of meaning and semantic shifts for two terms, \"Data Mining\" and \"Michael Jackson\". The analysis reveals notable differences in model performance across metrics, including factuality and comprehensiveness. Key results indicate that models trained with specialized data, such as code, may exhibit enhanced analytical capabilities, potentially influencing their ability to interpret semantic evolution.\n\nHigh-Performing Models\n\nThe models GPT-4 and Claude Instant 100k consistently outperformed other LLMs across both evaluation metrics, demonstrating a high capacity for capturing historical context. Both models scored a maximum of 22 in factuality and near-maximum in comprehensiveness (21 and 22 for Claude Instant 100k and GPT-4, respectively) for the term \"Data Mining.\" A similarly strong performance was observed for the term \"Michael Jackson,\" with GPT-4 achieving the highest comprehensiveness score of 22 and factuality of 21. These scores indicate an advanced capacity in these models to accurately trace semantic evolution, which may stem from robust training data diversity and model architecture optimized for complex language tasks. The consistent performance across terms suggests that GPT-4 and Claude may be more attuned to changes in meaning across different temporal contexts, supporting their utility in applications requiring historical linguistic analysis.\n\nThe Code-Based Llama Model's Unique Strengths\n\nThe model Llama 34B, specifically trained on code and provided by Poe, emerged as a notable outlier within the Llama series, outperforming larger versions, such as Llama 70B and Llama 13B, across factuality and comprehensiveness. This model achieved a factuality score of 12 and comprehensiveness of 20 for \"Data Mining\" and similarly high scores of 18 and 22, respectively, for \"Michael Jackson.\" The distinct performance of this model may be attributable to its extensive retraining on code datasets, which are characterized by structured syntax and logic-driven language. Such exposure potentially enhances a model's analytical capabilities, providing a foundation for more structured thought processes that facilitate better recognition of historical patterns in meaning. This suggests that domain-specific retraining, particularly with code, may imbue LLMs with improved temporal reasoning and analytical rigor\u2014skills critical for comprehending complex semantic shifts. Given these results, further research into code-based retraining could elucidate its potential benefits in enhancing temporal analytical abilities within LLMs.\n\nUnderperformance and Inconsistencies Among Other Models\n\nSeveral models displayed underperformance, particularly smaller Llama variants (Llama 7B) and Google Bard. The Llama 2 7B model, for example, exhibited the lowest scores across both terms and evaluation metrics, scoring 0 for both factuality and comprehensiveness for \u201cData Mining\u201d and only 1 and 0, respectively, for \u201cMichael Jackson.\u201d These findings suggest that model size has some effect, but a larger model size does not guarantee adequate understanding of temporal semantics; instead, both model architecture and training data composition play critical roles. As seen on Google Bard, it displayed low performance, particularly on the \"Data Mining\" term (factuality: 3, comprehensiveness: 0), underscoring the challenges faced by these models in accurately representing historical semantic shifts. These inconsistencies across models, particularly among the Llama and Bard models, imply potential limitations in their training frameworks for tasks requiring deep temporal context comprehension."}, {"title": "5. Discussion", "content": "Implications and Future Directions\n\nThe findings of this study offer several implications for the advancement of LLMs, particularly in fields requiring a in-depth understanding of language evolution, such as digital humanities and historical linguistics. The high performance of GPT-4 and Claude Instant 100k illustrates the potential for well-architected models with diverse training data to provide accurate and comprehensive historical interpretations. The success of the code-based Llama 34B model suggests that retraining on specialized datasets, like code, could be a valuable approach for enhancing models\u2019temporal analytical reasoning. This could have broader applications in improving models' ability to handle structured data and in fields such as digital humanities, where historical accuracy and adequate interpretation are essential.\n\nFuture research should expand the scope of this study by incorporating a larger set of terms and additional time periods to assess models' abilities to generalize across domains and temporal contexts. Further, investigating the specific impacts of code-based retraining or domain-specific dataset integration could offer insights into optimizing LLMs for tasks demanding analytical precision. This study provides foundational evidence that supports the refinement of LLMs to better address evolving language dynamics, with significant implications for enhancing AI's utility in historical analysis and beyond.\n\nThe superior performance of GPT-4 and Claude Instant 100k in this study underscores the importance of model architecture and the diversity of training datasets in achieving accurate temporal semantic understanding. Both models excelled in factuality and comprehensiveness, highlighting their ability to capture historical context with high fidelity. These results align with previous research (e.g., (Chiang et al., 2024)), which identified these models as top performers in reasoning and semantic tasks. However, critiques such as those by Bender et al., (2021) raise questions about whether such capabilities extend beyond statistical pattern recognition, suggesting a need for further validation of these models' capacity for deep semantic understanding in temporally sensitive tasks. The continued dominance of GPT-4 and Claude across various contexts reinforces their potential for applications requiring accurate historical linguistic analysis, while also presenting an opportunity to examine the precise contributions of training methodologies to their performance.\n\nThe observed success of CodeLlama 34B introduces a compelling case for domain-specific retraining as a strategy for enhancing structured reasoning in LLMs. Despite being smaller than other Llama variants, its superior performance in both factuality and comprehensiveness demonstrates the benefits of pretraining on structured datasets such as code. This finding corroborates studies by Aryabumi et al., (2024) and Yang et al., (2024), which emphasized the enhanced reasoning capabilities of models trained on code. Code-based retraining may in still improved logical reasoning and temporal analytical skills, offering broader implications for fields like computational linguistics and data science. However, further research is needed to determine whether such retraining benefits extend to other tasks or are limited to specific applications. Investigating how structured reasoning abilities gained from code datasets translate to understanding unstructured historical data could offer valuable insights.\n\nThe performance inconsistencies across model sizes in this study reveal critical insights into the interplay between model architecture and dataset composition. While larger models, such as Llama 70B, exhibited moderate improvement over smaller variants like Llama 7B, they underperformed relative to the code-based Llama 34B. This finding is consistent with Kaplan et al., (2020) and Hoffmann et al., (2022), who noted that factors such as training data quality and architectural optimization often outweigh the benefits of increasing model size. These results challenge the assumption that larger models inherently perform better, suggesting a paradigm shift toward prioritizing specialized training and architectural efficiency over sheer scale. Such a shift has significant implications for the development of cost-effective, high-performing LLMs capable of adequate temporal analysis.\n\nThe limitations observed in general-purpose models, such as Google Bard and Gemini, further emphasize the need for domain-specific optimization. These models struggled with both factuality and comprehensiveness, particularly in tasks requiring historical and temporal sensitivity. This aligns with findings in Chatbot Arena (Chiang et al., 2024) and related literature, which highlight the challenges faced by general-purpose models in specialized reasoning tasks. Enhancing these models to perform well in temporally complex tasks may require targeted retraining on domain- specific datasets or integration of context-aware mechanisms. Addressing these limitations could make general-purpose models more versatile and effective in a broader range of applications, including digital humanities and historical research.\n\nThe relationship between temporal semantic understanding and training data quality is particularly evident in the strong performance of GPT-4 and CodeLlama 34B. These models underscore the critical role of well-curated and diverse datasets in fostering the ability to interpret and analyze linguistic evolution. Studies such as (Beltagy et al., 2020) and Zhao et al., (2023) similarly emphasize the importance of diverse datasets in enhancing model performance, particularly for tasks involving extended temporal contexts. However, contrasting findings from Chen et al., (2021) suggest potential brittleness in code-trained models, indicating that further investigation is necessary to understand the long-term benefits and limitations of specialized datasets. Future research should aim to delineate the characteristics of training data that most effectively enhance temporal reasoning, particularly in relation to unstructured and evolving linguistic contexts.\n\nThe consistently low scores of smaller models, such as Llama 7B, highlight the challenges inherent in using resource-constrained architectures for complex semantic tasks. This aligns with the findings of Kaplan et al., (2020) and (Schick and Sch\u00fctze, 2020), which emphasize the limitations of smaller models in capturing clear patterns without fine-tuning. While smaller models may hold potential for niche applications with appropriate optimization, their inability to generalize effectively to tasks requiring deep temporal comprehension underscores the need for targeted architectural and dataset enhancements. Future research could explore fine-tuning smaller models for specific historical linguistic tasks, thereby balancing resource efficiency with improved performance.\n\nFinally, these findings hold substantial implications for applications in digital humanities and historical linguistics, where understanding the evolution of language and meaning over time is critical. The ability of GPT-4 and Claude to accurately trace semantic shifts positions them as valuable tools for scholars in these fields. The growing interest in domain-specific language models, such as MacBERTh (Manjavacas Arevalo and Fonteyn, 2021), highlights the demand for systems capable of contextualizing language within historical frameworks. The integration of such models into digital humanities workflows could revolutionize the analysis of historical texts, offering new opportunities for interdisciplinary research. Further efforts to refine LLMs for historical applications could bridge gaps in computational and humanitarian research, fostering a deeper understanding of language dynamics across time."}, {"title": "6. Conclusion", "content": "This study provides critical insights into the performance of LLMs in understanding temporal semantic shifts, emphasizing the roles of model architecture, training data, and domain-specific optimization. The results reveal that state-of-the-art models, such as GPT-4 and Claude Instant 100k, excel in capturing the historical context, showcasing the potential of well-designed architectures and diverse datasets. Moreover, the outstanding performance of CodeLlama 34B highlights the efficacy of retraining on structured datasets, like code, for enhancing logical reasoning and temporal analysis.\n\nContrastingly, the limitations of general-purpose models and inconsistencies among larger models, such as Llama 70B, underscore that size alone does not guarantee superior performance. Instead, this study reinforces the importance of training data quality and architectural refinement in shaping a model's ability to interpret linguistic evolution. Smaller models, like Llama 7B, demonstrated significant deficits in temporal understanding, further highlighting the necessity for targeted fine- tuning to enable such architectures to handle complex semantic tasks effectively.\n\nThese findings have profound implications for the development of LLMs tailored for applications in digital humanities, historical linguistics, and other fields that require temporal sensitivity. By prioritizing diverse, domain-specific datasets and leveraging specialized retraining approaches, future models could achieve higher levels of precision and contextual understanding. This study lays the groundwork for further exploration into the optimization of LLMs for temporal semantic analysis, advocating for a research trajectory that bridges computational advancements with interdisciplinary applications."}, {"title": "Declarations", "content": "Ethical Approval\nNot applicable\nCompeting interests\nThere are no competing interests that we are aware of in reference to this paper.\nAuthors' contributions\nThese authors contributed equally to this work.\nFunding\nNo external funding was received.\nAvailability of data and materials\nData Availability Statement: Data associated in the manuscript are shared in a supplementary file in the published paper."}]}