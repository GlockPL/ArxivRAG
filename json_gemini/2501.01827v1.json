{"title": "The Proof is in the Almond Cookies", "authors": ["Remi van Trijp", "Katrien Beuls", "Paul Van Eecke"], "abstract": "This paper presents a case study on how to process cooking recipes (and more generally, how-to instructions) in a way that makes it possible for a robot or artificial cooking assistant to support human chefs in the kitchen. Such Al assistants would be of great benefit to society, as they can help to sustain the autonomy of aging adults or people with a physical impairment, or they may reduce the stress in a professional kitchen. We propose a novel approach to computational recipe understanding that mimics the human sense-making process, which is narrative-based. Using an English recipe for almond crescent cookies as illustration, we show how recipes can be modelled as rich narrative structures by integrating various knowledge sources such as language processing, ontologies, and mental simulation. We show how such narrative structures can be used for (a) dealing with the challenges of recipe language, such as zero anaphora, (b) optimizing a robot's planning process, (c) measuring how well an Al system understands its current tasks, and (d) allowing recipe annotations to become language-independent.", "sections": [{"title": "1 Introduction", "content": "This paper explores what kind of grounded language processing model is needed for enabling robots or computational cooking assistants to support human chefs in the kitchen. Such human-centric Al assistants would be of great benefit for society because they could sustain the autonomy of aging adults or people with a physical impairment, or they could reduce the pressure on professional chefs who have to work in high-stress situations. We propose a novel approach to computational recipe understanding that mimics the narrative-based sense-making process of humans (Bruner, 1991), which may lead to more intuitive and meaningful human-robot interactions.\nWe first discuss the main challenges of recipe understanding and related work before introducing narrative-based understanding (section 2, also see Van Eecke et al., 2023). We then illustrate the approach through a concrete case study on an English recipe for almond crescent cookies, shown in Figure 1. Finally, we evaluate the benefits and the scalability of the approach, and provide more"}, {"title": "1.1 Challenges", "content": "Recipe understanding is a challenge for robotics because kitchens are rich and dynamically changing environments (Bollini et al., 2013). From a linguistic perspective, recipes come with their own genre-specific syntax and semantics (see a.o. Cotter, 1997; Gerhardt et al., 2013; Cani, 2022) that challenge traditional NLP solutions, of which we summarize the most important ones here:\n\u2022 How-to instructions: Recipes use procedural language, such as imperative commands, which leads to reduced performance of off-the-shelf parsers (Tellex et al., 2020).\n\u2022 Zero anaphora: Recipes are abundant with zero anaphora (e.g. no direct object in the phrase \"mix thoroughly\u201d) because cooking takes place in an actual kitchen that provides the necessary context for filling in the blanks.\n\u2022 Dynamic Environment: Kitchens are dynamic environments in which entities are changed into \"resultant objects\" often without explicit mention of that happening. For instance, the almond cookie recipe (Figure 1) introduces the phrase \"the dough\" for the first time in its fifth instruction without making explicit that it is the resultant object of mixing together various ingredients such as butter, sugar and flour.\n\u2022 Complex Semantics: Recipes require careful management of time, measurement and ordering. Instructions can be explicit (such as \"340 grams flour\u201d or \u201cfor 15-20 minutes\u201d), but recipes also often use vague measurements (\u201cgenerous tablespoons\") and evaluative phrases (\"until"}, {"title": "1.2 Related Work", "content": "Computational recipe understanding and other tasks in Digital Gastronomy (Zoran, 2019) have always enjoyed academic interest (see e.g. the Computer Cooking Contests; Najjar and Wilson, 2017), but especially in the past few years there has been a surge of attention for the broader field of food computing (Harper and Siller, 2015; Min et al., 2019). This surge is driven on the one hand by the explosion of large-scale online data such as recipes and cooking videos; and on the other hand by the breakthroughs in deep learning for handling such large data (e.g. LeCun et al., 2015).\nMost research therefore focuses on aggregating and cleaning up the data; and on the creation of datasets, benchmarks, representations and classification systems for food-related information (e.g. Smith and Lin, 2012; Kicherer et al., 2018; Yagcioglu et al., 2018; Marin et al., 2019; Popovski et al., 2019; Jiang et al., 2020; Tian et al., 2021). This information is then used for various tasks such as recipe generation (e.g. Jabeen et al., 2020; Wang et al., 2022), recipe recommendation (e.g. Haussmann et al., 2019; Tian et al., 2022), question-answering systems (e.g. Manna et al., 2020; Khilji et al., 2021), and so on. Ultimately, such systems aim to provide an appropriate response to a particular input, such as proposing relevant recipes based on the user's preferences.\nEven though such work is relevant to the present study, their goals only require a shallow under- standing of recipes, while our objective is to parse recipes in such a way that a robot can successfully execute it (or more generally speaking, that the robot can successfully execute instructions). This objective requires adequate systems for grounded (Harnad, 1990) natural language understanding (NLU; Allen, 1994, also see Tellex et al., 2020, for a survey).\nDespite a longstanding research history going back to the 1970s (e.g. Winograd, 1971; Hart and Nilsson, 1972), a recent benchmark study has shown that grounded language understanding is still a largely unsolved problem (Shridhar et al., 2020). That is not to say that no progress has been made: thanks to more sophisticated language technologies and the increasing availability of online data, the field has moved away from limited sets of natural language instructions, and has instead set its ambition on mapping open-ended instructions from the web onto everyday manipulation tasks (Tenorth et al., 2010).\nIn the cooking domain, several prototypes and experiments have been reported (Sugiura et al., 2010; Beetz et al., 2011; Bollini et al., 2013; Bezaleli Mizrahi et al., 2023). These studies are usually performed from the perspective of robotics, and mainly examine how existing NLP techniques can be repurposed for the generation of executable robot plans (Tenorth et al., 2010). Language processing therefore typically involves translating instructions onto syntactic parse trees from which semantics can be inferred; or more recently, applying neural network models for directly mapping sentences onto formal semantic representations (Tellex et al., 2020)."}, {"title": "2 Narrative-Based Understanding", "content": "We propose to treat recipes as a form of narrative, taking inspiration from discourse-analysis studies in linguistics (Cotter, 1997) and recent work on the value of narratives for human-centered Al (e.g. Szilas, 2015; Blin, 2022; Steels, 2022; Van Eecke et al., 2023). Narratologists divide a narrative into three interconnected layers (Bal, 1985), illustrated in Figure 2:\n1. The fabula (or story) is a collection of facts, events and actions;"}, {"title": "2.1 Recipes as Narratives", "content": "Let us apply these three layers to recipes-as-narratives. There are two observable layers: the fabula and the narration. The fabula is so vast (i.e. most of its content is irrelevant such as ingredients that won't be used) that a cooking agent can only maintain a partial model, which it obtains through sensorimotor processing and retrieving facts from memory (e.g. which drawer contains the cutlery). While the fabula can be considered as the background against which the narrative should be situated, the narration concerns how the narrative is presented, which can be a written recipe, a cooking video, a dialogue, and so on. This layer is typically analyzed using (multimodal) language processing techniques.\nAt the heart of narrative-based understanding is the plot, which is invisible to the cooking agent and which therefore has to be constructed. The plot is a rich content model in which the relevant elements of the fabula are arranged in a causal network of events. By integrating the diverse and often fragmented and ambiguous input from various knowledge sources (such as language processing, vision and pattern recognition, mental simulation, action monitoring, ontologies, knowledge graphs, and so on), the plot provides a coherent and structured path towards the goal of the narrative (in our case study: delicious almond crescent cookies).\nIn the case of cooking, our main guideline for constructing the causal network of events is the narration. In the simplest case, the narration follows the same order as the plot, but even for recipes there exist many variations (Cotter, 1997). The recipe for almond cookies, for instance, starts with"}, {"title": "2.2 Language as a Form of Action", "content": "Just like narratives involve the active construction of a plot in order to make sense of reality (Bruner, 1991), functional theories of linguistics have considered language to be a form of action ever since the influential works of Wittgenstein (1953), Austin (1962) and Searle (1969). The instructions found in recipes are textbook examples of such speech acts: linguistic expressions that invite the addressee to perform a (mental) action.\nIn robotics and grounded language understanding, those actions take the form of plans that can be simulated or executed by a robot. Traditional approaches typically involve a pipeline going from linguistic expressions to truth-conditional semantic representations (Eckardt, 2006; Tellex et al., 2020), which are then mapped onto an executable robot plan. For instance, the phrase \"take the dough\" can be associated with the logical form  \u2203x : {DOUGH(x) \u2227 TAKEN(x)} (\u201cthere exists an x that is dough and that is taken\u201d), which (using temporal logics; Kress-Gazit et al., 2018) can be specified as becoming True once the robot executes the correct operation and takes the dough. This formal semantic specification is then used for generating an executable robot plan (e.g. Beetz et al., 2011; Bollini et al., 2013; Sugiura et al., 2010).\nIn our approach, we dispense with an intermediary truth-conditional representation and propose that the meaning of a sentence (or indeed, the meaning of the recipe as a whole) is an executable robot plan. For example, the phrase \"take generous tablespoons of the dough and roll it into a small ball' in the almond crescent cookie recipe directly maps onto an actual operation in which the cooking agent uses a tablespoon as a tool of measurement for making several spheres made of dough."}, {"title": "2.3 Personal Dynamic Memory", "content": "Narratives are personal as they are based on past experiences, individual beliefs and values, and on which perspective is taken (Steels, 2020; Van Eecke et al., 2023). For instance, if at the world cup football a small nation eliminates one of the tournament's favourites, their supporters may praise their team's courage and efficient counter tactics, while the losing side might condemn them for playing a defensive \"anti-football\" game.\nNarratives are therefore not constructed out of the blue, but are integrated into a personal dynamic memory (PDM; Steels, 2020). A personal dynamic memory consists of persistent knowledge (e.g. an agent's linguistic inventory, its ontology, and so on) and of past experiences and past narratives. The more cooking experience an agent has acquired throughout its lifetime, the easier it will be able to construct a recipe's narrative."}, {"title": "3 Almond Crescent Cookies", "content": "There is an English proverb that goes the proof is in the pudding, which comes from the older saying the proof of the pudding is in the eating. This expression used to mean quite literally that you have"}, {"title": "3.1 Situated Language Processing", "content": "In order to handle the genre-specific challenges of recipes, we have chosen a construction grammar approach (Fillmore, 1988; Goldberg, 2003; Fried and \u00d6stman, 2004), which we implemented in the open-source formalism Fluid Construction Grammar (FCG; Steels, 2004; van Trijp et al., 2022; Beuls and Van Eecke, 2023). The motivation for this approach is threefold. First, construction grammar is a linguistic theory in which all linguistic information is represented as mappings between form and meaning (called \u201cconstructions\u201d), which makes it convenient to represent both the idiosyncrasies of recipe language as well as its more abstract syntactic structures in a uniform way. Secondly, semantics can but needn't be directly coupled to syntactic structures, which makes it possible to parse sentences directly into language-independent executable robot plans. Finally, the functional scope of constructions is not limited to the sentence level, which means that constructions can represent discourse-level information as well (Fried, 2021).\nThe latter feature of construction grammar is of great importance for recipes. As discussed in section 1.1, recipes are abundant with zero anaphora, which are used by recipe authors as a strategy for cohesion building since these zero anaphora refer to entities that are highly salient in the current discourse context (Cani, 2022). For instance, in the almond cookies recipe, the direct object is omitted in phrases such as \"mix thoroughly\" and \"place onto a parchment paper lined baking sheet\" . Our solution is to include non-linguistic information in language processing, which is supplied by the personal dynamic memory as shown in Figure 3. The PDM is where the recipe's plot is constructed: at each node, the PDM tracks which entities are currently under the attention of the cooking agent (called accessible entities). Accessible entities are like characters that were introduced in prior scenes and that are still present in the current scene.\nMore concretely, linguistic processing makes use of a kind of blackboard that contains all of the information about the accessible entities and the input phrase or sentence. This blackboard is called transient structure because it changes over time as different constructions access and expand its information. Figure 4 illustrates such a transient structure at the beginning of a parsing task for the phrase \"116 grams sugar\". This transient structure consists of four units (which are simply lists of feature-value pairs). The unit called root (on top) contains unhandled information from the input sentence, such as which strings (or tokens) were observed and which strings are adjacent to each other. At this point in the recipe, the cooking agent has already fetched a medium bowl of butter, so there are two accessible entities: the current kitchen state, and the bowl of butter.\nIn Fluid Construction Grammar (FCG), constructions are formalized as schemas that consist of a conditional pole (right-hand side) and a contributing pole (left-hand side). A construction is allowed to add the information of its contributing pole to the transient structure if the feature-value pairs from its conditional pole can be matched against the information already present in the transient structure (Steels and De Beule, 2006). Here is an example of a lexical construction for the word \"sugar\":"}, {"title": "3.2 Meaning and Mental Simulation", "content": "The goal of language processing is not to derive the most accurate syntactic analysis of a sentence: syntactic structures are only built insofar as they help to get to the meaning as efficiently as possible. \"The\" meaning is a bit misleading because language is an inferential coding system (Sperber and Wilson, 1986) so not all the meaning is in the message. For instance, a phrase such as \u201cput two eggs in a bowl\" does not specify which eggs and bowl to take, or that you have to crack the eggs open and get rid of the shells.\nParsing therefore only leads to a partial robot plan that the cooking agent needs to complete and expand upon. For instance, the phrase \"116 grams sugar\" maps onto an operation called fetch-and-proportion, illustrated in Figure 5. Some of the operation's arguments are already provided by the recipe instructions such as which food product to fetch (sugar), shown as cyan circles. However, there are several open slots such as the resultant object, shown as red diamonds. The cooking agent thus needs to find fillers for those slots using different knowledge sources such as its personal dynamic memory and mental simulation. To enable the agent to do so, we used the open-source software tool Incremental Recruitment Language (IRL) for representing, generating and executing robot plans (Steels, 2000; Spranger et al., 2012).\nMore specifically, we implemented a new representation language for cooking that includes 40 predefined cooking operations (called \u201cprimitives\u201d) that encode meaning, temporality and dependencies. The IRL-system can then combine these primitives into graphs that represent complete recipe execution plans. Recurrent graphs can be automatically chunked and stored as"}, {"title": "4 Evaluation and Self-Assessment", "content": "In this section we describe the steps taken towards evaluation as well as first results. Moreover, we discuss how a cooking agent may reason about its own performance."}, {"title": "4.1 Integrative Narrative Networks", "content": "One of the challenges of narrative-based understanding is to monitor how different knowledge sources are integrated with each other, and whether the resulting plot offers a coherent and sensible content model. Crucially, the cooking agent itself should also have a way to monitor its own understanding process.\nWe are approaching this challenge using a new data structure called integrative narrative networks (Baroncini et al., 2023). The key inspiration for such networks comes from the narratological concept of \"narrative questions\", which are the questions that are raised in the audience's mind by a narrative (or that an author wants to be raised). For instance, when a new character is introduced in a movie,"}, {"title": "4.2 Recipe Execution Benchmark", "content": "In order to evaluate our work as well as invite the research community to advance the field of grounded language understanding (and computational recipe understanding in particular), we have released a fully documented recipe execution benchmark (Nevens et al., 2024), which consists of the following components:\n\u2022 A representation language for cooking (see section 3.2) that can express complete recipe execution plans. This representation language is independent from syntax or a particular natural language, so knowledge about syntax is not necessary for annotation.\n\u2022 A test set of 30 English recipes with gold standard annotations. These recipes have been selected for the specific linguistic and extralinguistic challenges in recipe understanding.\n\u2022 A qualitative kitchen simulator that is able to execute the recipe execution plans, and which returns both execution and evaluation results for further inspection.\n\u2022 A suite of metrics that allow multiperspective estimates to optimize transferability to real- world utility. These consist of Smatch (Cai and Knight, 2013), goal-condition success, Dish Approximation Score, and Recipe Execution Time."}, {"title": "5 Conclusions and Future Work", "content": "This paper explored how narrative-based language understanding can be used for processing cooking recipes in a way that allows robots or artificial cooking agents to execute those recipes in a dynamic kitchen environment. Through a case study on an English recipe for almond crescent cookies, we have shown how the rich content models built during narrative-based understanding can be exploited for tackling the specific challenges of recipe language, such as resolving zero anaphora by keeping track of which entities are currently under the cooking agent's attention. We have thereby shown how language processing can be embedded in a system for representing, generating and executing robot plans, coupled to a kitchen simulator. Moreover, we have proposed how narratives may offer a new framework for monitoring and measuring understanding.\nEven though we have illustrated our approach through a concrete implementation and accompany- ing web demonstration, we hope to have convinced the reader that the framework of narrative-based understanding can be operationalized in a multitude of ways. To this end we have published a recipe execution benchmark for comparing different solutions. One key component of this benchmark is a new representation language for cooking, which allows recipes to be annotated in a syntax- and natural-language-independent fashion.\nOur current and future work focuses on automatically learning computational construction grammars for recipe understanding in order to scale our approach. For the reasons detailed in section 2.2, we believe that construction grammar shows great promise to deal with the specific challenges of grounded language understanding, and computational recipe understanding in particular. Important breakthroughs in the automated learning of such grammars have recently been achieved in the domain of Visual-Question Answering (Nevens et al., 2022; Doumen et al., 2024; Beuls and Van Eecke, 2024), which requires a mapping from questions to visual queries in similar ways as recipe instructions map onto executable robot plans.\nBy mimicking the sense-making process of humans, narrative-based language understanding can become a key component in the development of human-centric Al systems. Such systems have many potential benefits for society, as they may interact with humans in more intuitive and meaningful ways."}]}