{"title": "CrowdTransfer: Enabling Crowd Knowledge Transfer in AIoT Community", "authors": ["Yan Liu", "Bin Guo", "Nuo Li", "Yasan Ding", "Zhouyangzi Zhang", "Zhiwen Yu"], "abstract": "Artificial Intelligence of Things (AIoT) is an emerging frontier based on the deep fusion of Internet of Things (IoT) and Artificial Intelligence (AI) technologies. The fundamental goal of AIoT is to establish a self-organizing, self-learning, self-adaptive, and continuous-evolving AIoT system by orchestrating intelligent connections among Humans, Machines, and IoT devices. Although advanced deep learning techniques enhance the efficient data processing and intelligent analysis of complex IoT data, they still suffer from notable challenges when deployed to practical AIoT applications, such as constrained resources, dynamic environments, and diverse task requirements. Knowledge transfer, a popular and promising area in machine learning, is an effective method to enhance learning performance by avoiding the exorbitant costs associated with data recollection and model retraining. Notably, although there are already some valuable and impressive surveys on transfer learning, these surveys introduce approaches in a relatively isolated way and lack the recent advances of various knowledge transfer techniques for AIoT field. This survey endeavors to introduce a new concept of knowledge transfer, referred to as Crowd Knowledge Transfer (CrowdTransfer), which aims to transfer prior knowledge learned from a crowd of agents to reduce the training cost and as well as improve the performance of the model in real-world complicated scenarios. Particularly, we present four transfer modes from the perspective of crowd intelligence, including derivation, sharing, evolution and fusion modes. Building upon conventional transfer learning methods, we further delve into advanced crowd knowledge transfer models from three perspectives for various AIoT applications: intra-agent knowledge transfer, centralized inter-agent knowledge transfer, and decentralized inter-agent knowledge transfer. Furthermore, we explore some applications of AIoT areas, such as human activity recognition, urban computing, multi-robot system, and smart factory. Finally, we discuss the open issues and outline future research directions of knowledge transfer in AIoT community.", "sections": [{"title": "I. INTRODUCTION", "content": "Internet of Things (IoT), a well-known term, refers to a vast network connecting the billions of physical devices (e.g.,"}, {"title": "II. EMBRACING CROWD KNOWLEDGE TRANSFER IN AIOT", "content": "In this section, we first describe the basic concept of traditional transfer learning. Next, we introduce an overview of the AIoT framework, which consists of the embedded computing layer, edge computing layer, and cloud computing layer. Furthermore, we present the definition of CrowdTransfer, a new concept of knowledge transfer, to empower AIoT agents with the capability of self-learning, self-adaptation, and continuous evolution across a diverse range of AIoT applications. In addition, we delve into the intricacies of CrowdTransfer and provide insights to explore how crowd knowledge is transferred among AIoT agents in different scenarios through four fundamental modes: derivation, sharing, evolution, and fusion modes. Finally, we present the general framework of CrowdTransfer for AIoT field to illustrate its key modules and transfer techniques. For brevity, we provide a table of notations used in our work in Table I."}, {"title": "A. Preliminary of Transfer Learning", "content": "Recently, with the rapid growth of data size and computational resources, machine learning has achieved great success in many areas. However, it has limited ability in some real-world applications where there is insufficient data to train the model. In addition, the model trained in one domain can only be directly utilized for another domain with the same data distribution, because many machine learning methods assume that the training and future data must be in the same feature space and have the same distribution, which may not hold in practical scenarios. Knowledge transfer or transfer learning, which aims to transfer knowledge across domains or tasks, is an effective way to solve the above-mentioned problems without much expensive data-labeling efforts.\nTransfer learning [11]\u2013[13] is an important research problem in machine learning. The objective of transfer learning is leveraging knowledge learned from one task or domain to improve the performance of a related, but different, task or domain. This section introduces some basic definitions of transfer learning.\nDefinition 1 (Domain): A domain $\\mathcal{D}_o$ is composed of two components: a feature space $\\mathcal{X}$ and a marginal probability distribution $P(X)$, where $X$ is the particular instance set in the feature space of all possible instances, $\\mathcal{X} = \\{X_1,X_2,..., X_n\\} \\in \\mathcal{X}$. Thus, the domain $\\mathcal{D}_o$can be denoted as $\\mathcal{D}_o = \\{\\mathcal{X}, P(X)\\}$.\nDefinition 2 (Task): A task $\\mathcal{T}_a$ consists of two components: a label space $\\mathcal{Y}$ and an objective decision function $f$, that is, $\\mathcal{T}_a = \\{\\mathcal{Y}, f(.)\\}$. The decision function $f$ is an implicit one,"}, {"title": "B. Overview of AIoT", "content": "The deep fusion of the Internet of Things (IoT) and artificial intelligence techniques has given rise to a promising emerging frontier field of Artificial Intelligence of Things (AIoT) [4], [15], [16]. On one hand, the widespread deployment of IoT devices and the exponential growth of data collected by these devices create an opportunity for artificial intelligence to enable intelligent sensing, communication, and computing within the IoT system. Particularly, it also supports efficient data processing and analysis to provide more intelligent services for users, which can be referred to as Al for IoT. On the other hand, the increasing prevalence of IoT applications provides vast real-world data, which could enhance the deployments of most artificial intelligence models. With the continuous development of embedded chips, processors, and sensors, IoT devices are endowed with enhanced capabilities for intelligent data processing. Collaborative sensing and computing among heterogeneous entities such as portable terminals (e.g., smartphones and wearables), embedded IoT devices (e.g., cameras and smart vehicles), and Internet applications (e.g., edge and cloud servers) bestow new attributes upon artificial intelligence, which can be referred to as IoT for AI. In general, different from IoT, AIoT builds the comprehensive connection of Humans, Machines, and Things to enable more intelligent IoT applications and provide more efficient services. Especially, IoT serves to establish extensive connections for hundreds of millions of physical devices to collect data, while AI algorithms are harnessed for analyzing and mining the potential patterns and strategies from massive amounts of collected data on the end devices, edge nodes, or cloud servers.\nDefinition 4 (AIoT): Based on the deep fusion of artificial intelligence, edge computing, IoT, and other advanced technologies, AIoT aims to establish a more comprehensive connection and intelligent collaboration among Humans, Machines, and Things, and further empower the sensing, communication, computing, and application with AI algorithms, to achieve a self-organizing, self-learning, self-adaptive, and continuous-evolving intelligent computing system.\nThe core of AloT is real-time and efficient data collection and information processing [16]. Benefiting from the introduction of edge intelligence into the AIoT system, AIOT forms a cloud-edge-end architecture, which consists of three layers: embedded computing layer, edge computing layer, and cloud computing layer. The architecture of AIoT is illustrated in Fig. 2. In contrast to the traditional centralized cloud-based data processing approach, AIoT systems leverage a range of computational capabilities across IoT devices, edge networks, and cloud servers distributed across various layers, enabling them to actively engage in computing tasks. Notably, the collaboration of these three layers in the cloud-edge-end architecture not only alleviates the burden of data processing, but also enhances the efficiency of computing and real-time response on terminal and edge devices."}, {"title": "C. Definition of CrowdTransfer", "content": "With the popularity of a large number of smart devices with sensing and computing capabilities, machine learning or deep learning models can be deployed on a diverse range of devices, including edge servers and terminal devices. This enables AIoT to provide safer and more convenient services to humans on wearables, mobile devices, and embedded devices. Different from the traditional centralized learning mechanism whose performance mainly depends on the data collected in advance, the performance of learning models in AIoT applications not only depends on the real-time data obtained by devices, but also is impacted by the practical AIoT scenarios, such as the computing and storage of the device. To understand the main characteristics of machine learning models in the AIoT community, we present some definitions to describe the key factors that could affect the learning process of machine learning models in AIoT applications.\nDefinition 5 (AIoT Agent): An AIoT agent, referred to as $\\mathcal{A}$, embodies a ubiquitous object (e.g., IoT devices, edge devices, and cloud servers) with the capability to execute AI algorithms $f$ based on the collected data $\\mathcal{D} = \\{x,y\\}$ by utilizing IoT hardware $\\mathcal{H}$. The AIoT agent integrates sensing, communication, storage, and computational capabilities into a unified entity to comprehend semantic information from the surrounding environment and engage in inferential decision-making. Notably, the learning process of AIoT agent $\\mathcal{A}$ can be succinctly represented as $f : \\mathcal{H}, x \\rightarrow y$.\nIntuitively, hardware, data, and algorithms are three key elements that typically influence the performance of the AIoT agent in complex and dynamic AIoT scenarios. At the hardware level, the agent encompasses sensor, memory, processor, and communication units, granting it profound sensing, communicative, storage, and computational capabilities. At the data level, the agent is capable of acquiring and storing diverse modalities of data from various sources, including text, images, videos, etc., wherein lies rich information about the target object. At the model level, the agent first trains models based on extensive data to acquire valuable knowledge, then optimizes the models during the inference stage and ultimately deploys the learned models at hardware devices.\nDefinition 6 (AIoT Context): The AIoT context, denoted as $\\mathcal{C}$, contains the information related to AIoT scenarios, including the sensing context involving environmental information, computation context involving hardware resources, and task context involving task-specific requirements. The comprehensive context facilitates a deeper understanding of AIoT scenarios, empowering agents to make more intelligent decisions and responses.\nIn traditional cloud-based centralized learning frameworks, it is assumed that the training and deployment scenarios are consistent, so pre-trained models can achieve satisfactory performance during the inference phase. Conversely, in AIoT scenarios, each device can participate in both the learning and inference processes of the model. However, due to the dynamic nature of AIoT contexts, cloud-based centralized learning methods struggle to achieve optimal model performance. More specifically, the sensing context, primarily concerned with physical conditions of deployment environments (e.g., lighting, noise, etc.) and data types from diverse sensors (e.g., text, images, videos, etc.), exerts a significant influence on the domain of AIoT agents $\\{\\mathcal{X}, P(x)\\}$. The computation context, mainly encompassing hardware information such as memory and processor, directly impacts the resources of AIoT agents $\\mathcal{H}$. The task context, mainly involving task-related details such as label categories, performance requirements, etc., notably shapes the task undertaken by AIoT agents $\\{y, f\\}$.\nTransfer learning is an effective solution to improve model performance by transferring knowledge learned from one source task to another related target task. For example, domain adaptation [17] endeavors to build a model in a source domain that can yield robust results in a target domain with different data distributions. Multi-task learning [18], on the other hand, seeks to learn common features across multiple tasks to effectively transfer information. Meanwhile, meta-learning [19] aims at harnessing prior knowledge derived from multiple tasks to guide learning in new tasks, effectively embracing the concept of learning to learn. Although these transfer learning methods have demonstrated remarkable accomplishments in many tasks, the practical implementation of deep learning models for real-world AIoT applications continues to confront some challenges:"}, {"title": "III. KEY TECHNIQUES OF KNOWLEDGE TRANSFER", "content": "In recent years, transfer learning methods have experienced substantial advancements and have led to the emergence of various learning paradigms. This article embraces a comprehensive understanding of transfer learning, encompassing the sharing of diverse forms of knowledge, e.g., network parameters, typical instances, features, or network structures, between source and target domains/tasks within the scope of this paper. In this section, the key techniques for facilitating knowledge transfer comprise domain adaptation/generalization, multi-task learning, knowledge distillation, and meta learning (as shown in Table III)."}, {"title": "A. Domain Adaptation", "content": "Domain adaptation (DA) aims to build a model that can learn knowledge from semantically related source domains with different distributions to perform the tasks in the target domain [20]. In AIoT scenarios, agents frequently encounter tasks with identical conditional probability distributions (CPDs) but differing marginal probability distributions (MPDs). For instance, a target model deployed in an intelligent surveillance camera exhibits proficient performance under sunny weather conditions, yet experiences a sudden decline in performance during snowy weather conditions. This issue can be resolved through DA, wherein the model is adapted to transition from sunny to snowy weather conditions. The entire process of adaptation necessitates aligning the distribution of data from the source domain with that of the target domain, encompassing the alignment of CPDs, MPDs, or both.\nGiven the feature space of the source domain, $\\mathcal{X}_S$, the feature space of the target domain, $\\mathcal{X}_T$, the label space of the source domain, $\\mathcal{Y}_S$, the label space of the target domain, $\\mathcal{Y}_T$, as well as the training sets of the source domain, $\\mathcal{D}_S = \\{(x_i, Y_i)\\}$ , and the target domain, $\\mathcal{D}_T = \\{x_j\\}$, the objective of DA is to learn a mapping function $f : \\mathcal{X}_S \\rightarrow \\mathcal{Y}_S$. This mapping function aims to minimize the distribution discrepancy between the domains, $D_{KL} (P_S || P_T)$, and a combination with the loss function $\\mathcal{L} (f (x_i), Y_i)$:\n$\\min_f \\mathcal{A}D_{KL} (P_S || P_T) + \\sum_{(x_i,Y_i) \\in \\mathcal{D}_S} \\mathcal{L} (f (x_i), Y_i) \\tag{1}$\nwhere $\\mathcal{A}$ serves as a weighting parameter. At present, dominant methods employed to facilitate DA primarily comprise instance-based adaptation, feature-based adaptation, and model-based adaptation."}, {"title": "B. Domain Generalization", "content": "Domain Generalization (DG) aims to learn a model with strong generalization ability from several domains with different data distributions and achieve better results on the unknown test set [28]. DG methods, in contrast to DA approaches, only necessitate access to the training set during the model training phase. Unlike DA, which demands both source and target domain data from the training and testing sets, DG solely relies on source domain data. Moreover, DG possesses the capacity to handle an unlimited number of potential target domains in the future.\nGiven multiple feature spaces $\\mathcal{X}_S$ of source domains, multiple label spaces $\\mathcal{Y}_S$ of source domains, and a feature space $\\mathcal{X}_T$ of a target domain, the objective of DG is to learn a universal mapping function $f : \\mathcal{X} \\rightarrow \\mathcal{Y}_S$, enabling accurate predictions on unseen target domains. It is typically to combine the prediction loss and the domain discrepancy:\n$\\min \\sum_{i=1}^n\\mathcal{L} (\\mathcal{D}'_S, \\theta) + \\mathcal{A}D_{KL} (P'_S || P_T), \\tag{2}$\nwhere $\\mathcal{L} (\\mathcal{D}'_S, \\theta)$ represents the prediction loss of the source domain $\\mathcal{D}'_S$, $\\theta$ denotes the model parameters, $D_{KL} (P'_S || P_T)$ measures the distribution discrepancy between the source domains and target domain, and $\\mathcal{A}$ is a balancing parameter. Current DG methods can be primarily classified into the following three major categories: (1) Data manipulation-based DG: It involves enhancing the training data through the use of augmentation and variations. By manipulating the data, the training set can be enriched, which results in improved generalization performance; (2) Representation learning-based DG: It focuses on learning domain-transferable features, also known as domain-transferable representation learning. By learning representations that are resilient to domain discrepancies, deep models become more effective in addressing variations across different domains. (3) Learning strategies-based DG: It refers to the integration of other machine learning patterns into multi-domain training, e.g., meta-learning."}, {"title": "C. Multi-task Learning", "content": "The underlying concept of multi-task learning lies in the possibility of knowledge or feature sharing among related tasks. Through the sharing of these task-transferable features, models can effectively transfer information across tasks, enhancing the learning process. Particularly in situations with limited training data, multi-task learning can aid models in acquiring additional information from analogous tasks. Given multiple tasks $\\mathcal{T}_a = \\{T_1,T_2,......,T_n\\}$, each task including a feature space $\\mathcal{X}$ and a label space $\\mathcal{Y}$, along with their corresponding training datasets $\\mathcal{D}_i = \\{(x_i, Y_i)\\}$, the objective of multi-task learning is to learn a set of models $f_1, f_2,..., f_n$, where each model corresponds to a task $T_i$, with the aim of minimizing the loss function across tasks:\n$\\min_{f_1, f_2,..., f_n} \\sum_{i=1}^n \\sum_{(x_j,Y_j)\\in \\mathcal{D}_i} \\mathcal{L} (f_i (x_j), Y_j), \\tag{3}$\nThe design of multi-task learning methods primarily encompasses two approaches: One is learning a shared feature representation for multiple tasks based on shallow or deep models, which can be a subset or transformation of the original feature representation; the other is reducing distribution differences between tasks by task clustering or analyzing of task correlations. In conclusion, this paper divides multi-task learning methods into two types:"}, {"title": "D. Knowledge Distillation", "content": "Knowledge distillation (KD) [58] aims to facilitate knowledge transfer by allowing a small/simple model to closely approximate or even outperform complex/large models, thereby achieving comparable predictive results with reduced complexity. Given the teacher model $\\mathcal{W}$ and student model $w$, along with a set of training data $\\mathcal{D}$, the objective of KD is to learn the student model by minimizing the student loss on the training data, denoted as $\\mathcal{L}_w$, while utilizing the output of teacher model as an additional signal of supervision:\n$\\min_w (\\mathcal{L}_w (w, W) + \\mathcal{A}L_K (T, w, W)), \\tag{4}$\nwhere $L_K$ refers to the loss of knowledge transfer, and $\\lambda$ represents a balancing scalar. This paper categorizes KD methods into the following two types:"}, {"title": "E. Meta-Learning", "content": "Meta-learning [19] aims at leveraging prior knowledge acquired from multiple tasks to guide its learning in new tasks, i.e., learning to learn. Meta-learning consists of the base learning stage and the meta-learning stage. During the base learning stage, internal algorithms are utilized to address a learning task with provided data and optimization objectives. In the meta-learning stage, external algorithms are utilized to update internal learning algorithms, enabling them to improve external optimization objectives, such as generalizability and learning efficiency. Given a meta-training dataset $D_{meta}$, where each meta-task consists of a training set $D_{train}$ and a testing set $D_{test}$, the objective is to learn a model f that achieves high performance on a new task $T_{new}$ with only a small amount of instances $\\mathcal{D}_{train,new}$: \n$\\max_f \\sum_{T_{new}\\in D_{meta}} \\sum_{(x_j,Y_j) \\in D_{train,new}} L_f (f, D_{test,new}),  \\tag{5}$\nwhere $L_f$ is the loss function during meta-training."}, {"title": "IV. CROWD TRANSFER LEARNING MODELS", "content": "Crowd knowledge transfer plays an increasingly prominent role in AIoT. Benefiting from the self-adaptive ability of crowd transfer learning models, they optimize their own modules according to the state of IoT devices and the changes in the environment to improve specific task performances. This section mainly analyzes the crowd transfer learning models in detail to manifest the mechanisms of knowledge usage manners behind various methods.\nDue to the sensing/perception ability of agents, a single modal or task data is not enough to successfully complete a specific task. In AIoT scenarios, there are multiple agents executing different yet related tasks, such as tasks with varying data distributions or different data modalities. Taking into account the interrelated tasks of multiple agents and leveraging shared factors or representations among these tasks is also an important approach to enhance the generalization of individual task learning and facilitate crowd knowledge transfer. This section primarily focuses on introducing the research paradigm of crowd transfer learning models, mainly including centralized inter-agent knowledge transfer, decentralized inter-agent knowledge transfer, and intra-agent knowledge transfer. Table IV summarizes the CrowdTransfer Models.\nSpecifically, the centralized inter-agent knowledge transfer and decentralized inter-agent knowledge transfer summarize crowd knowledge transfer methods from the perspective of interactions among crowd agents. Constrained by the requirements of privacy security, data acquisition ability, etc., it is often challenging for an agent to obtain sufficient data for a specific task, and models cannot be learned well due to limited training data. The target agents can not only achieve self-optimization by using the knowledge of their surrounding agents for reference, but also realize crowd evolution by sharing knowledge with each other.\nThe intra-agent knowledge transfer summarizes crowd knowledge transfer methods from the perspective of agent itself, i.e., attributes of agents (such as data scale, resource, and sensing ability). In AIoT scenarios, agents have different functions, various number/types of basic sensors, and chips with distinct capabilities, which makes each agent form different aspects and levels of knowledge in the process of interacting with contexts, e.g., experiences, policies, or skills."}, {"title": "A. Centralized Inter-agent Knowledge Transfer", "content": "1) Federated Transfer Learning: With the increasing demand for data privacy and the improvement of relevant laws and regulations [90], there are often various restrictions imposed on the exchange of data between agents. Consider a smart city scenario, where multiple types of intelligent cameras are distributed to capture visual information from specific areas. The tasks, such as traffic control and suspect tracking, require aggregating data from different cameras for algorithm training. However, when these cameras are from different companies or involve the privacy of numerous users, sharing and merging the data becomes impractical. Each camera becomes a data island, impeding the exchange of information between cameras and hindering model learning. To address this challenge, Liu et al. [91] propose federated transfer learning (FTL), which integrates transfer learning and federated learning [92]. The FTL emphasizes collaborative modeling and learning on diverse data distributions, offering a promising research direction in achieving the fusion of data among multiple agents. In the scope of this paper, FTL emphasizes knowledge transfer and fusion among a group of agents, enabling the joint optimization of models under specific requirements and limitations. Firstly, different devices train local models based on their own data, and then the device encrypts the model parameters and exchanges intermediate results. Finally, joint training is conducted on these devices to obtain the final optimal model, which is then returned to each device.\nFTL methods have the capability to optimize crowd agents on task data with different sample spaces or feature spaces. This is achieved by transferring features from different feature spaces to the same representations through a virtual collaborator or an aggregation server. Additionally, encryption techniques such as homomorphic encryption and random masks are utilized during the model update stage to ensure data privacy and learning security. The aggregation server utilizes the combined local updates from multiple participating agents to iteratively perform model learning and global updates, minimizing the loss function. Besides, Li et al. [93] explore the problem of federated learning when each agent has different models. They propose the FedMD for heterogeneous federated learning. FedMD allows each agent to independently design the architecture of their local models, and knowledge transformation between agents is achieved through the process of KD. Gao et al. [94] introduce a heterogeneous federated transfer learning strategy, namely HFTL, which aims to address covariate shift in homogeneous feature spaces and bridge different agents with heterogeneous feature spaces. HFTL consists of five components: secure domain adaptation, secure feature mapping, secure federated learning, secure model integration, and local model inference. Furthermore, Nguyen et al. [95] propose two mechanisms for knowledge transfer across devices: one is global knowledge transfer, which involves transferring knowledge from client models to a global model; the other is on-device knowledge transfer, which involves transferring generalized shared knowledge from the global model to client models.\nIn addition, FTL shows remarkable prospects for advancement in numerous domains, including autonomous driving and smart healthcare. For example, Liang et al. [68] propose a federated transfer reinforcement learning approach, namely FTRL, where all agents can utilize knowledge from other agents to make effective actions in the current context. Communication between agents and the federated learning server occurs through Wi-Fi, and each agent performs RL tasks in its specific context, while the server periodically aggregates the models from all agents to generate a joint model for crowd knowledge transfer. Chen et al. [69] introduce a FTL framework applied to healthcare in wearable devices, dubbed as FedHealth, which utilizes federated learning for data aggregation and incorporates transfer learning to construct personalized wearable models. FedHealth starts by training a cloud model on the server side using a public dataset, which is then distributed to all users. Each user can train their own model utilizing their unique local data. Subsequently, the user models are uploaded to the cloud server to facilitate training updates. During the model uploading process, only homomorphically encrypted model parameters are shared, ensuring the privacy of user data and information. Users can perform personalized training by integrating the cloud model with their local model, resulting in a personalized wearable healthcare model. While FTL aims to effectively aggregate data under privacy regulations and achieve knowledge transfer. However, it does impose higher demands on network and computational resources due to frequent encryption and gradient transmission. For example, Jing et al. [96] conduct performance tests on the open-sourced FTL model, i.e., FATE, deployed on Google Cloud and identify that inter-process communication cost is a major bottleneck of FTL. They also observe that software-based encryption methods consume excessive CPU cycles. Sharma et al. [97] argue that the computational overhead of the FTL framework, specifically when using secure multi-party computation and homomorphic encryption protocols, is significant. To address this issue, they leverage secret sharing to enhance the efficiency and security of model collaborative training in the context of crowd knowledge transfer.\nFTL enables the collaborative training of agents across different domains, organizations, or tasks without sharing the raw data to preserve privacy and confidentiality, which is particularly useful in industries like healthcare and manufacturing, where data sharing is restricted by regulations [69], [94]. For instance, in the dynamic landscape of modern manufacturing in smart factories, agents need to rapidly adapt to different applications. Traditional deep learning approaches often falter in new applications across different knowledge domains, primarily due to limited data availability. Furthermore, extensive data sharing among numerous industrial agents raises concerns about the potential exposure of sensitive information. Federated transfer learning emerges as a robust solution to these challenges, promoting knowledge transfer in complicated industrial settings."}, {"title": "B. Decentralized Inter-agent Knowledge Transfer", "content": "1) Distributed Multi-agent Reinforcement Learning: The CTDE-based MARL described in section IV-A4 utilizes the learned policies in a truly decentralized execution environment after training, where each agent just accesses local observations. While such methods demonstrate strong convergence, crowd agents often encounter scenarios in the complex and dynamic AIoT contexts that were unseen during the training stage. Consequently, researchers have delved into a technique that more closely aligns with real-world application environments, namely distributed MARL.\nUnlike CTDE-based MARL, distributed MARL is decentralized during both the training and execution stages. Each agent operates within its own observations throughout the training and execution processes, but could adjust its policy based on interactions with other agents. For example, Heinrich et al. [123] introduce the Neural Fictitious Self-Play (NSFP), a method that combines deep reinforcement learning with fictitious self-play to learn strategies in imperfect-information games without prior knowledge. NSFP employs distributed training across independent agents, efficiently handling large-scale multi-agent environments. Sun et al. [124] introduce TLeague, a robust framework for competitive self-play based distributed MARL, designed to handle the intensive data demands of training high-performance Al for complex games. TLeague facilitates scalable distributed training on a mixture of CPU and GPUs, supporting both single-machine and cluster deployments with Kubernetes, enhancing MARL's accessibility and efficiency in real-world applications. The architecture includes modular components for Actor, Learner, and InferenceServer, optimizing the parallel training process and providing flexibility to extend for various multi-agent problems and new MARL algorithms. Xu et al. [77] present a Distributed-Training-Distributed-Execution (DTDE) MARL scheme for power control in heterogeneous networks (HetNets). They introduce a penalty-based Q-learning (PQL) algorithm that allows each access point in a HetNet to independently make power control decisions based on local information, promoting more efficient cooperation among agents.\nKnowledge transfer in distributed MARL occurs through the process of agents interacting and observing within their respective environments. It often relies on communication mechanisms between agents [125]\u2013[127], facilitating the exploration of more diverse learning trajectories and a broader range of task solutions. Taking the electric vehicle (EV) charging schedules as an example, Zhang et al. [76] adopt the DTDE-based Stackelberg MARL framework. During the training phase, each agent, both EVA and EVs, independently trains local neural networks using only locally available data. This includes their observations and actions, as well as the actions of interacting agents, without the need to share sensitive private information. This approach addresses major concerns related to privacy and communication overhead seen in centralized systems. The EVA, acting as the leader, sets dynamic pricing signals based on the observed state and projected demands, which are then broadcasted to the EVs. In response, each EV, as a follower, decides its charging strategy based on the current price, aiming to minimize its charging costs while adhering to operational constraints such as battery capacity and required charge levels. In the execution phase, the framework facilitates real-time decision-making where each agent, equipped with its policy model, reacts based on its current observation. The distributed execution ensures that all computations, including forward and back-propagation through the neural networks, are localized, significantly enhancing the computational efficiency and scalability of the system. This setup eliminates the dependency on a central coordinator and high-precision modeling, making it robust against the non-stationarity typical of large-scale EV charging scenarios."}, {"title": "C. Intra-agent Knowledge Transfer", "content": "1) Multimodal Learning: In AIoT scenarios, there are typically various data acquired in multiple ways such as sensory, visual, audio, etc. For example, in autonomous driving scenarios, cameras and LiDAR data capture information about surrounding vehicles, buildings, etc., and on-board sensor data, such as speed and steering angle, can be utilized to perceive the vehicle's own information, and the comprehensive fusion of these perceptual information can provide autonomous driving systems with more comprehensive perception and more accurate decision-making. Therefore, facing the challenge of heterogeneous data, the multimodal learning approach plays an important role, which can eliminate the redundant information from different modalities, represent the target in a more comprehensive and multidimensional way to enhance the accuracy and robustness of the overall system [152]."}]}