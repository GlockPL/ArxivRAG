{"title": "Multi-frequency Neural Born Iterative Method for Solving 2-D Inverse Scattering Problems", "authors": ["Daoqi Liu", "Tao Shan", "Maokun Li", "Fan Yang", "Shenheng Xu"], "abstract": "In this work, we propose a deep learning-based imaging method for addressing the multi-frequency electromagnetic (EM) inverse scattering problem (ISP). By combining deep learning technology with EM physical laws, we have successfully developed a multi-frequency neural Born iterative method (NeuralBIM), guided by the principles of the single-frequency NeuralBIM. This method integrates multitask learning techniques with NeuralBIM's efficient iterative inversion process to construct a robust multi-frequency Born iterative inversion model. During training, the model employs a multitask learning approach guided by homoscedastic uncertainty to adaptively allocate the weights of each frequency's data. Additionally, an unsupervised learning method, constrained by the physical laws of ISP, is used to train the multi-frequency NeuralBIM model, eliminating the need for contrast and total field data. The effectiveness of the multi-frequency NeuralBIM is validated through synthetic and experimental data, demonstrating improvements in accuracy and computational efficiency for solving ISP. Moreover, this method exhibits strong generalization capabilities and noise resistance. The multi-frequency NeuralBIM method explores a novel inversion method for multi-frequency EM data and provides an effective solution for the electromagnetic ISP of multi-frequency data.", "sections": [{"title": "I. INTRODUCTION", "content": "The electromagnetic (EM) inverse scattering problem (ISP) is a critical scientific challenge in electromagnetics, involving the inference of unknown scatterers' physical properties within a domain of interest (DOI) from scattered field data [1]. This includes determining their shape, size, location, and EM parameters. ISPs are widely used in various fields such as biomedical imaging [2] [3], nondestructive testing [4] [5], microwave imaging [6], and geophysical exploration [7]-[9]. However, ISPs are inherently nonlinear and ill-posed [1], meaning that the solution may not exist, may not be unique, or may be highly sensitive to measurement data. These characteristics pose significant challenges to solving ISPs.\nTraditional Inverse Scattering Problem (ISP) solutions are pri- marily categorized into two approaches: qualitative and quantitative methods. Qualitative methods focus on the shape and location of unknown scatterers within the domain of interest (DOI), aiming to produce a generally accurate imaging result without prioritizing the exact values of physical parameters, such as electromagnetic properties. Representative qualitative methods include multiple signal classification (MUSIC) [10] [11], the decomposition of the time- reversal operator (DORT) method [12], the linear sampling method (LSM) [13], and the back-propagation (BP) method [14]. Quantitative methods, on the other hand, strive to obtain precise parameters of the scatterer, including exact values for shape, size, location, and electromagnetic properties. These methods typically involve iterative techniques that formulate the ISP as an optimization problem, con- structing a cost function and repeatedly using a forward solver to progressively converge on the solution. Notable quantitative methods include the Born iterative method (BIM) [15], the distorted Born iterative method (DBIM) [16], the variational Born iterative method (VBIM) [17], contrast source inversion (CSI) [18], Gauss-Newton inversion method [19] [20] and the subspace optimization method (SOM) [21], among others. Compared to qualitative approaches, quantitative methods can derive specific values for electromagnetic properties and other scatterer parameters. However, their effectiveness often depends on the quality of the initial solution, which can limit their performance when dealing with strong scatterers or high-contrast targets.\nIn recent years, AI technology has developed rapidly, with machine learning, especially deep learning [22], being successfully applied in many fields such as computer vision (CV) and natural language processing (NLP) [23] [24]. Numerous studies have introduced deep learning technology into EM computation, achieving promising re- sults [25]. Deep learning-based ISP solving methods leverage the excellent information integration and learning capabilities of deep learning, providing advantages in inversion accuracy and computa- tional efficiency [26]\u2013[35]. For instance, Zhang et al. proposed a two-step deep learning method involving Frequency Extrapolation and Scatterer Reconstruction [36]. Pan et al. developed a complex-valued convolutional neural network (CV-CNN) that effectively leverages phase information to address the full-wave nonlinear inverse scat- tering problem (ISP) [37]. Ran et al. applied Convolutional Neural Networks (CNN) to the time-harmonic EM diagnosis of dielectric microstructures [38]. Wang et al. proposed GPRI2Net, based on CNN and recurrent neural network (RNN), which can simultaneously re- construct dielectric constant maps and classify object categories from continuous and long Ground Penetrating Radar (GPR) measurement data [39]. However, many studies, including the aforementioned ones, design deep neural networks for ISP solving in a purely data-driven manner. This approach often results in neural networks being \"black boxes\", making their internal computations difficult to interpret and the design and training processes challenging [40].\nCompared to purely data-driven methods, some research has combined data with physical laws, incorporating physical laws into the design of deep neural networks to construct solution methods that integrate physical laws with data-driven approaches [41]. These methods have yielded excellent results in both efficient EM forward computation [42] [43] and effective ISP inversion [44]. In the field of EM forward computation, Shan et al. proposed Physical Information Supervised Residual Learning (PhiSRL) [43], a robust and versatile deep learning framework for 2D EM modeling. For ISP solutions, Yao et al. integrated a complex-valued deep convolutional neural network (DConvNet) into the supervised descent method (SDM) to achieve offline training and online \"imaging\" prediction for EM inverse scat- tering problems [45]. Liu et al. proposed SOM-Net, embedding the Lippmann-Schwinger physical model into neural network structures, continuously updating the induced current and dielectric constant in the sub-network module of SOM-Net [46]. Hu et al. developed an unsupervised deep learning approach for solving inverse problems, utilizing the computational framework of Physics-Informed neural networks (PINNs) [47].\nIn our previous research, Shan et al. proposed the Neural Born Iterative Method (NeuralBIM) based on the PhiSRL scheme [48]. PhiSRL leverages the mathematical connection between the fixed- point iteration method and the residual neural network (ResNet) to solve linear matrix equations by applying CNNs to learn residual updates. Expanding similar design ideas to ISP solving, we developed NeuralBIM, which uses CNNs to learn residual update rules, con- structs parameterized functions, and simulates the alternating update process of traditional Born iteration methods while inverting both the total field and scatterers. However, traditional BIM and NeuralBIM are limited to single-frequency scattering data inversion and are not equipped to handle the inversion of multi-frequency EM data.\nDifferent frequency EM scattering data contain varied information about the scattering object, making multi-frequency data inversion a valuable research topic. Although deep learning has been success- fully applied to ISP solving, there is limited work focusing on the inversion of multi-frequency EM data [49] [50]. Lin et al. proposed a deep learning-based low-frequency data prediction scheme that integrates information from low-frequency and high-frequency data using frequency-hopping methods to achieve better inversion results [51]. Li et al. introduced a multi-channel scheme of U-Net CNN to process the BP results of multiple frequencies, obtaining an inversion result that integrates multi-frequency information [52]. Hu et al. used a residual fully convolutional network (Res-FCN) to learn the scattering data of each frequency point within a wide frequency band, resulting in a model that effectively performs EM inversion of high-contrast scatterers at any frequency within the band [53]. Despite these successes, these methods remain purely data-driven, lacking the integration of physical law constraints. There remains substantial room for exploring efficient EM inversion methods that can integrate effective information from multi-frequency scattering data, especially methods that integrate data with physical laws.\nThis article focuses on the inversion method of multi-frequency EM data and builds upon previous work on NeuralBIM to develop and implement a multi-frequency NeuralBIM approach [48]. This method integrates multi-task learning technology with NeuralBIM's efficient iterative inversion technique, resulting in a multi-frequency Neural- BIM iterative inversion model. A multi-task learning method guided by homoscedastic uncertainty is employed to adaptively allocate the weight of each frequency data during the iterative computation in training. We use a physics-guided unsupervised learning method to train the multi-frequency NeuralBIM model, which is constrained by the physical laws of the inverse scattering problem, eliminating the need for contrast and total field data. The final multi-frequency NeuralBIM method effectively extracts key information from multi- frequency EM scattering data and achieves robust inversion results for complex scattering objects with high contrast, demonstrating strong generalization and noise immunity.\nThe structure of this article is as follows: Section II introduces the theoretical basis of ISP, and Section III explains the principles and architecture of single-frequency and multi-frequency NeuralBIM. Section IV details the multi-task learning method and unsupervised learning mode used. Section V provides numerical results, demon- strating the effectiveness of the proposed multi-frequency NeuralBIM in solving EM inverse scattering problems. Finally, Section VI sum- marizes the article and outlines the potential impact and contributions of the proposed method in the field of EM inversion."}, {"title": "II. INVERSE SCATTERING PROBLEMS", "content": "Fig. 1 illustrates the inverse scattering problem (ISP) in a two- dimensional region, where the unknown scatterers are located within the DOI, while the background consists of free space. The objective of the ISP is to reconstruct the scatterer contrast parameter, denoted as X. The source and receiving antenna for the transverse magnetic(TM) wave are distributed around the domain, and the incident field Ei and total field Et at position r satisfy the following equations [1]:\n$E_t(r) = E_i(r) + k_0^2 \\int_D G_D(r,r')\\chi(r')E_t(r')dr', r \\in D$  (1)\nwhere DOI is represented as domain D. The scattered field Es received by the antenna at position rs in the receiving area S is given by [1]:\n$E_s(r_s) = \\int_D G_s(r_s, r')\\chi(r') E_t (r')dr', r_s \\in ES$ (2)\nwhere ko is the wave number, Gs and GD are the free-space Green's functions of domain S and domain D, respectively. Using the method of moments (MoM), the DOI is subdivided into discrete elements, allowing for the discretization of the calculation process of (1) and (2). (1) and (2) can be expressed in matrix form:\n$(I-G_D\\Chi)E_t = E_i$ (3)\n$E_s = G_s\\chi E_t$. (4)"}, {"title": "III. NEURAL BORN ITERATIVE METHOD", "content": "A. Traditional Born Iterative Method\nTraditional Born Iterative Method (TBIM) is a common method for solving ISPs. TBIM first solves the optimization problem:\n$min ||E_s - G_s\\chi E_t||^2$ (5)\nto obtain an updated value of \u03c7. The updated value $ \\Chi_{update} $ is obtained and then used to find the updated value of Et\n$E_t^{update} = (I - G_D\\Chi_{update})^{-1} E_i$ (6)\nRepeat the above iterative update process until the iteration result meets the requirements.\nB. Single-Frequency Neural Born Iterative Method\nNeuralBIM enhances the traditional BIM by incorporating the design concept of Physical Information Supervised Residual Learning (PhiSRL) [43]. This method integrates CNN with the algorithm, combining a ResNet [54] and physical laws to learn the rules for iterative updates in BIM. A physically-guided deep neural network simulates the calculation process of the TBIM, resulting in improved convergence and iterative updates of \u03c7 and Et."}, {"title": "The process of updating X in NeuralBIM is as follows:", "content": "$Res_s = E_s \u2013 G_s\\chi^kE_t^k$ (7)\n$\\chi^{k+1} = \\chi^k + N_\\chi^{k+1}(Res_s \\oplus \\chi^k, \\Theta_\\chi^{k+1})$\nwhere $Res_s$ denotes the residual component of the scattered field Es. Concurrently, $N_\\chi^{k+1}$ signifies the CNN associated with \u03c7, as employed within the framework of the model. $ \\Theta_\\chi^{k+1}$ refers to the internal parameter set specific to the \u03c7 \u2013 CNN. The $Res_s$ and $N_\\chi^{k+1}$ are utilized as input parameters for the \u03c7 \u2013 CNN, leading to the iterative update of \u03c7. signifies tensor concatenation. Similarly, the procedure for updating Et using NeuralBIM is as follows:\n$Res_t = E_i - (I \u2013 G_D\\chi^{k+1})E_t^k$ (8)\n$E_t^{k+1} = E_t^k + N_t^{k+1}(Res_t, E_t^k ,\\Theta_t^{k+1})$\nwhere $Res_t$ denotes the residual component of the incident EM field Ei, while $N_t^{k+1}$ represents the Et \u2013 CNN employed in the model. Moreover, $ \\Theta_t^{k+1}$ encapsulates the distinct set of internal parameters that are unique to the Et - CNN. The NeuralBIM algo- rithm systematically executes an iterative computational procedure, as delineated in the respective equations, persisting in this loop until the pre-established criteria for convergence are satisfactorily met. The procedural architecture of the NeuralBIM algorithm is delineated in Algorithm 1."}, {"title": "Algorithm 1 Neural Born Iterative Method", "content": "Initialization: $E_t^0 = E_i, \\chi^0 = 0, k = 0, k_{max}$ \nwhile k<$k_{max}$ do\nstep 1: $Res_s = E_s \u2013 G_s\\chi^kE_t^k$\nstep 2: $\\chi^{k+1} = \\chi^k + N_\\chi^{k+1}(Res_s \\oplus \\chi^k, \\Theta_\\chi^{k+1})$\nstep 3: $Res_t = E_i \u2013 (I \u2013 G_D\\chi^{k+1})E_t^k$\nstep 4: $E_t^{k+1} = E_t^k + N_t^{k+1}(Res_t, E_t^k ,\\Theta_t^{k+1})$\nstep 5: k = k+1\nend while\nOutput: $ \\chi^{k_{max}}, E_t^{k_{max}} $"}, {"title": "C. Multi-Frequency Neural Born Iterative Method", "content": "According to the principle and architecture of NeuralBIM, we improve it to achieve multi-frequency data inversion. For multi- frequency data, the incident field, scattered field, and total field data of the ith frequency are represented as Ei(fi), Es (fi) and Et (fi). According to (7) and (8), we can calculate the residual of the scattered field $Res_s(f_i)$ and the residual of the total field $Res_t (f_i)$ at the ith frequency. For cases with n frequency data, similar to the single-frequency NeuralBIM, the process of updating \u03c7 in multi-frequency NeuralBIM is as follows:\n$Res_s (f_i) = E_s (f_i) \u2013 G_s\\chi E_t^k(f_i)$ (9)\n$Res_s = Res_s (f_1) \\oplus ... \\oplus Res_s (f_n)$ (10)\n$\\chi^{k+1} = \\chi^k + N_\\chi^{k+1} (Res_s \\oplus \\chi^k, \\Theta_\\chi^{k+1})$, (11)\nwhere $Res_s$ is the concatenation of the Es residuals at each frequency, and is the concatenation of two tensors. $G_s^i$ denotes Green's function in free space for the ith frequency. $N_\\chi^{k+1}$ represents the \u03c7-CNN for multi-frequency data, and $\\Theta_\\chi^{k+1}$ is the internal pa- rameter set of the network. Inputting the residual of multi-frequency data and \u03c7 results in an iterative update of \u03c7.\nSimilarly, the process of updating Et for multi-frequency Neural- BIM is as follows:\n$Res_t^i (f_i) = E_i (f_i) \u2013 (I \u2013 G_D\\chi^{k+1})E_t^k(f_i)$ (12)\n$Res_t = Res_t^i (f_1) \\oplus Res_t^i (f_n)$ (13)\n$E_t^{k+1} = E_t^k + N_t^{k+1}(Res_t, \\Theta_t^{k+1})$, (14)\nwhere $Res_t$, is the concatenation of the Ei residuals at each frequency, and is the concatenation of two tensors. $G_D^i$ denotes Green's function in free space for the ith frequency. $N_t^{k+1}$ represents the Et - CNN for multi-frequency data, and $\\Theta_t^{k+1}$ is the internal parameter set of the network. The procedural architecture of the NeuralBIM algorithm is delineated in Algorithm 2."}, {"title": "Algorithm 2 Multi-Frequency Neural Born Iterative Method", "content": "Initialization: $E_t^0 (f_i) = E_i (f_i), \\chi^0 = 0, k = 0, k_{max}$ \nwhile k < $k_{max}$ do\nstep 1: $Res_s^i (f_i) = E_s(f_i) \u2013 G_s^i\\chi E_t^k(f_i)$\n$Res_s = Res_s (f_1) \\oplus ... \\oplus Res_s (f_n)$\nstep 2: $\\chi^{k+1} = \\chi^k + N_\\chi^{k+1} (Res_s \\oplus \\chi^k, \\Theta_\\chi^{k+1})$\nstep 3: $Res_t^i (f_i) = E_i(f_i) \u2013 (I \u2013 G_D^i\\chi^{k+1})E_t^k(f_i)$\n$Res_t = Res_t (f_1) \\oplus ... \\oplus Res_t (f_n)$\nstep 4: $E_t^{k+1} = E_t^k + N_t^{k+1}(Res_t, \\Theta_t^{k+1})$\nstep 5: k = k + 1\nend while\nOutput: $\\chi^{k_{max}},E_t^{k_{max}}$"}, {"title": "IV. MULTITASK LEARNING FOR MULTI-FREQUENCY DATA", "content": "Multitask learning has found widespread application across various domains of deep learning [55], including CV [56] [57], NLP [58], and bioinformatics [59]. It addresses the challenge of optimizing a model with respect to multiple objectives simultaneously [60]. In this study, we employ multitask learning for the inversion computation of multi-frequency data, leading to the development of a multi- frequency NeuralBIM model. This model integrates the information conveyed by each frequency data, thereby enhancing its predictive capability. In the context of the multi-frequency NeuralBIM model, the iterative computation for each frequency data constitutes a distinct task. All these tasks share the initial input data \u03c7\u00ba, as well as the frequency-specific input data Ei (fi), Es (fi) and E (fi). Moreover, they collectively produce a common output $ \\chi^{out} $ and a frequency- specific output $E_t^{out} (f_i)$.\nA. Objective Function of Multitask Learning\nThe loss associated with the ith task, herein referred to as the inverse calculation loss of the ith frequency, is denoted by Lossi. Consequently, the objective function is articulated as the weighted aggregation of the task-specific losses:\n$Obj = \\sum_i w_i Loss_i$ (15)\nAddressing the equilibrium among task-specific losses emerges as a pivotal concern. The distribution of weights, wi, corresponding to each loss exerts a considerable influence on both the efficacy of the model and the computational outcomes. The manual specification of each task's loss is fraught with challenges in achieving optimal results, as each iteration and adjustment of weights demands sub- stantial temporal and resource investments. Hence, the exploration of methodologies for ascertaining optimal weight distribution is warranted.\nA multi-task learning paradigm that leverages homoscedastic un- certainty, embracing probabilistic modeling principles, is proposed for the derivation of optimal task weights [57]. This approach employs homoscedastic uncertainty as a criterion for the apportionment of loss weights across distinct tasks, facilitating ongoing adjustment and learning of these weights throughout the training phase. The founda- tion of this method is the maximization of the Gaussian likelihood estimate predicated on homoscedastic uncertainty, culminating in the formulation of a multi-task loss function. Specifically, within the context of a neural network model tasked with n distinct functions, denoted as\n$D_{out} = N(D_{in}, \\theta)$, (16)\nwhere Din represents the input data, \u03b8 encapsulates the network parameters, and $D_{out}^i$ signifies the output of the ith task, for i = 1,2,..., n.\nThe likelihood is conceptualized as a Gaussian distribution, its mean reflective of the model's output\n$p(D_{out}^i | D_{in}, \\theta) = \\frac{1}{\\sqrt{2\\pi \\sigma_i^2}} exp(-\\frac{||D_{truth}^i - D_{out}^i||^2}{2\\sigma_i^2})$ (17)\n$p(D_{out}^1,..., D_{out}^n | D_{in}, \\theta) = \\prod_i P(D_{out}^i | D_{in}, \\theta)$. (18)\nwherein \u03c3\u03b9 symbolizes the covariance indicative of the network model's uncertainty pertaining to the ith task and $D_{truth}^i$ represents the ground truth. To transform (17) into its maximum likelihood form, the log-likelihood of the model can be maximized by:\n$log \\ p(D_{out}^1,..., D_{out}^n | D_{in}, \\theta) \\propto \\sum_i - \\frac{1}{2 \\sigma_i^2}||D_{truth}^i - D_{out}^i||^2 - log \\sigma_i$. (19)\nBased on (19), using homoscedasticity uncertainty to weight the losses of different tasks, the objective function for multi-task learning can be formulated as:\n$Obj = \\sum_i \\frac{1}{2\\sigma_i^2} Loss_i + log \\sigma_i$. (20)\nHere, homoscedasticity uncertainty \u03c3\u03b9 represents a learnable loss weight parameter that adaptively adjusts the loss weight for each task during the training process. In the context of the multi-frequency NeuralBIM model, the output result for each frequency data computes the corresponding loss Lossi. According to (20), homoscedasticity uncertainty \u03c3\u03b5 is introduced to adjust the loss weight of each frequency during training.\nB. Unsupervised Learning Method\nThe multi-frequency NeuralBIM employs an unsupervised learning method for model training. Unsupervised learning confers benefits such as obviating the need for labeled data, enhancing flexibility and versatility, and diminishing preprocessing requisites. Within the unsupervised learning method, (3) and (4) pertaining to the ISP are utilized to govern the training of the multi-frequency NeuralBIM model. During the training process, the true values of the total field Et, and the contrast X, remain undisclosed. It is postulated that the Green's function, the scattered field Es, and the incident field Ei, are known entities in the ISP. The training model comprehensively assimilates existing physical laws and information, enabling the multi-frequency NeuralBIM to concurrently satisfy (3) and (4) across various frequencies. Specifically, for the ith frequency, the loss function Lossi is defined as:\n$Loss_i = R_{E_i}^i + R_{E_s}^i$ (21)\nwhere $R_{E_i}^i$ is related to the residual of the incident field obtained based on (3):\n$R_{E_i}^i = \\frac{1}{N_{E_i}(f_i)} || (I - G_D^i \\chi_{out})E_t^{out} (f_i) - E_i(f_i)||_F^2$ (22)\nAnalogously, $R_{E_s}^i$ can be procured based on (4), and total variation (TV) regularization is incorporated:\n$R_{E_s}^i = \\frac{1}{N_{E_s}(f_i)} || (E_s(f_i) - G_S^i \\chi_{out}E_t^{out} )||_F^2 + \\alpha || \\nabla \\chi_{out} ||_1$ (23)\nwhere $N_{E_i}(f_i)$ and $N_{E_s}(f_i)$ denote the number of elements in Ei(fi) and Es(fi) respectively. $ \\chi_{out} $ and $E_t^{out} $ are the inverse results of \u03c7 and Et obtained by iterative computation, respectively. The TV regularization term, $|| \\nabla \\chi_{out} ||_1$, introduced in (22), serves to stabilize the training process and ensure commendable boundary delineation and homogeneity of the inversely reconstructed scatterer. \u03b1 is set to 0.00001, $|| \\cdot ||_F$ signifies the Frobenius norm, and $|| \\cdot ||_1$ represents the L1 norm.\nFinally, by amalgamating (20) and (21), the objective function for the multi-frequency neuralBIM, designed to integrate multi-frequency data information through multi-task learning in an unsupervised learning framework, can be derived:\n$Obj = \\sum_i \\frac{1}{2\\sigma_i^2} (R_{E_i}^i + R_{E_s}^i) + log \\sigma_i$, (24)\nwhere $R_{E_i}^i$ and $R_{E_s}^i$ are defined in (22) and (23) respectively. \u03c3i denotes a learnable parameter representing the uncertainty associated with the result of ith frequency. This objective function enables the multi-frequency neuralBIM to conduct multi-task learning across various frequencies in an unsupervised learning method."}, {"title": "V. NUMERICAL RESULTS", "content": "In this section, we first construct multi-frequency NeuralBIM with three frequencies: 3GHz, 4GHz, and 5GHz. Then we use synthetic and experimental data to verify the inversion performance of multi- frequency NeuralBIM. We use the Pytorch library to construct multi- frequency NeuralBIM and the Adam optimizer [61] to optimize the neural network parameters. The computation of multi-frequency NeuralBIM is performed using three Nvidia V100 GPUs.\nA. Synthetic Data Inversion\nAs shown in Figure 1, the domain D (DOI) in the ISP is set to 0.15m\u00d70.15m and divided into a 32\u00d732 grid. The 32 transmitters and receivers are evenly distributed on a circle with a radius of 1.57m centered on the DOI center, forming domain S. The scatterers generating data are two uniform cylindrical combinations randomly distributed in the DOI, with their sizes and contrasts randomly taken from the ranges shown in Table I. The background in the DOI is free space. A sample of some syntactic data scatterers is shown in Fig. 4. After randomly generating scatterers, the EM scattering data of the scatterers under incident fields at 3GHz, 4GHz, and 5GHz are calculated using MoM, namely Ei and Es in (3) and (4). One scatterer and its EM scattering data at three frequencies constitute a data sample. A total of 10,000 data samples were generated, with 80% randomly selected to form the training set and the remaining 20% forming the testing set. The initial value of the scatterer contrast $ \\chi_0 $ is obtained using the BP method, and the initial value of the total field $E_t^0$ is considered to be the incident field Ei.\nThe model underwent training for a total of 260 epochs. Fig. 5(a) illustrates the variation curve of the objective function as defined in (24), demonstrating that the training process of the model ultimately converges, with the loss values for both the training and testing sets being essentially identical. Fig. 5(b) presents the loss values at various frequencies during the training process, calculated using (21). The loss values and their variations at three distinct frequencies during the training are observed to be largely consistent. Fig. 5(c) depicts the variation in the learnable parameters \u03c3i (as introduced in (24)), which are employed to modulate the loss weights of different tasks throughout the training process. It is evident that the weight parameter \u03c3i, derived based on the homoscedasticity uncertainty, can adaptively adjust the loss weights of each task during training, thereby enabling the model to fully utilize multi-frequency information. The diverse information presented in Fig. 5 signifies the stability of multi- frequency neuralBIM training and the dependability of the model architecture.\nA random selection of results from the testing set was used to plot the comparison between the ground truth contrast values and the model inversion results, along with the mean absolute error(MAE) between the two, as depicted in Fig. 6. The inversion results closely resemble the ground truth values in terms of shape and contrast, with errors primarily concentrated around the boundary of the scatterers, indicating satisfactory overall inversion performance.\nA histogram representing the MAE distribution between the train ing and testing datasets is statistically illustrated in Fig. 7. Fig. 7(a) and (b) display the MAE distribution of the real and imaginary parts of the scatterer contrast \u03c7 and the total field Et calculation results, respectively. Fig. 7(c), (d) and (e) show the MAE distribution of Et calculation at three different frequencies. Table II provides the mean and standard deviation of the aforementioned MAE results. The mean and standard deviation of the MAE between \u03c7 and Et of the testing and training sets are found to be essentially identical, as are the mean and standard deviation of the MAE of each frequency Et between the testing and training sets. This consistency aligns with the variations in the objective function and loss at each frequency depicted in Fig. 5, indicating an absence of overfitting in the model training. The information on MAE distribution reflects the effective performance of the inversion calculation and the stability of the model training. Fig. 8 illustrates the iterative calculation process of multi-frequency NeuralBIM model inversion and marks contrast MAE in the interme-"}, {"title": "VI. CONCLUSION", "content": "In this work, we propose a deep learning-based method for solving the multi-frequency EM ISP. By combining deep learning techniques, particularly ResNet, with EM physics principles, we have success- fully developed a multi-frequency NeuralBIM. The proposed multi- frequency NeuralBIM integrates multi-task learning techniques with the efficient iterative inversion processes of NeuralBIM to construct a comprehensive multi-frequency iterative inversion model. This model employs a multi-task learning approach, guided by homoscedastic uncertainty, to adaptively allocate the weights of each frequency's data during training. Additionally, an unsupervised learning method guided by physics principles is used to train the multi-frequency NeuralBIM model. This method is constrained by the physical laws of the ISP and can be used for training without requiring contrast and total field labeled data. The effectiveness of the multi- frequency NeuralBIM is demonstrated through the validation of both synthetic and experimental data. The results show that this method not only enhances the accuracy and computational efficiency of solving ISPs but also exhibits strong generalization capabilities and noise immunity.\nThe multi-frequency NeuralBIM proposed in this article offers an effective solution for EM ISPs and explores a novel inversion technique for multi-frequency EM data. The successful implemen- tation of this method introduces a new perspective and tool for solving EM ISPs, highlighting the potential and practical applications of combining deep learning techniques with physical laws in EM analysis."}]}