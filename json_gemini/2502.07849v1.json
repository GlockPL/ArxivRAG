{"title": "Understanding Classifier-Free Guidance: High-Dimensional Theory and Non-Linear Generalizations", "authors": ["Krunoslav Lehman Pavasovic", "Jakob Verbeek", "Giulio Biroli", "Marc Mezard"], "abstract": "Recent studies have raised concerns about the effectiveness of Classifier-Free Guidance (CFG), indicating that in low-dimensional settings, it can lead to overshooting the target distribution and reducing sample diversity. In this work, we demonstrate that in infinite and sufficiently high-dimensional contexts CFG effectively reproduces the target distribution, revealing a \"blessing-of-dimensionality\u201d result. Additionally, we explore finite-dimensional effects, precisely characterizing overshoot and variance reduction. Based on our analysis, we introduce non-linear generalizations of CFG. Through numerical simulations on Gaussian mixtures and experiments on class-conditional and text-to-image diffusion models we validate our analysis and show that our non-linear CFG offers improved flexibility and generation quality without additional computation cost.", "sections": [{"title": "1 Introduction", "content": "Diffusion models (Sohl-Dickstein et al., 2015; Song and Ermon, 2020; Ho et al., 2020) have become the state-of-the-art algorithms to generate high-quality images, audio and video. By simulating Orstein-Uhlenbeck Langevin dynamics, noise is first progressively added to data until it becomes completely random. Diffusion models then learn to reverse this process and generate new samples through a time-reversed Langevin equation. This backward evolution is steered by a force, the score, that is estimated from the data. An important task for diffusion models is generating data conditioned on a label, e.g., in text-to-image generation, on a textual description which allows the model to generate images that match the content of the description. This can be achieved through the concept of guidance (Dhariwal and Nichol, 2021; Ho and Salimans, 2022). This approach allows the model to generate more specific outputs that align with user intentions or desired properties, rather than producing generic samples from the model of the data distribution. Guidance allows control over the generative sampling process, making it possible to create outputs with higher fidelity and relevance to the input criteria.\nThe first form of guidance introduced was classifier guidance (Song et al., 2020a; Dhariwal and Nichol, 2021). In this approach, one learns scores conditioned on class labels using a classifier that estimates the probability that a given noised image corresponds to the given label. This technique allows for precise control over the attributes of the generated outputs, enhancing their alignment with specific categories. However, the reliance on a pre-trained classifier can be computationally expensive and may introduce biases inherent to the classifier itself.\nClassifier-Free Guidance (CFG) (Ho and Salimans, 2022) was developed as an alternative to overcome these challenges, and was quickly adopted as a standard technique in state-of-the-art diffusion models such as GLIDE (Nichol et al., 2021), DALL-E 3 (Betker et al., 2023), Imagen (Saharia et al., 2022), and EMU (Dai et al., 2023), as well as flow matching based models (Esser et al., 2024). CFG eliminates the need for an external classifier by training the diffusion model to conditionally generate samples based on class labels/textual prompts directly. During training, the model learns to produce both class-conditional and unconditional samples. The score used in classifier-free guidance, however, is not the one guaranteed to give the target distribution. Instead, one adds to the latter an extra term whose role is to better guide the backward process toward the desired labeled data."}, {"title": "2 Related Work", "content": "Classifier-Free Guidance (CFG) has been a topic of interest in recent research, with the original work introducing CFG (Ho and Salimans, 2022) highlighting the trade-off between image quality, measured by Fr\u00e9chet inception distance (FID, Heusel et al. (2017)), and diversity, measured by inception score (Salimans et al., 2016) when adjusting the guidance strength parameter \\(w\\). Since then, a significant body of research has examined CFG from various perspectives.\nTheoretical works on CFG. From a theoretical standpoint, several works also employed Gaussian mixture models to analyze diffusion and guidance, including Chidambaram et al. (2024); Shah et al. (2023); Liang et al. (2024); Cui et al. (2023); Bai et al. (2024). In contrast, Du et al. (2023) explored alternative approaches to conditioning, modifying, and reusing diffusion models for compositional generation and guidance tasks. Bradley and Nakkiran (2024) characterized CFG as a predictor-corrector (Song et al., 2020a), positioning it within a broader context of sampling approaches in order to improve its theoretical understanding, similar to the approach in this paper, however from the perspective of denoising and sharpening processes.\nCFG variants and experimental analyses. Among experimental evaluations of CFG, Karras et al. (2024a) showed that guiding generation using a smaller, less-trained version of the model itself can achieve disentangled control over image quality without compromising variation. Kynk\u00e4\u00e4nniemi et al. (2024) proposed applying CFG in a limited interval, and Wang et al. (2024) proposed using weight schedulers for the classifier strength parameter. Several alternatives to standard CFG have been proposed, such as rectified classifier guidance (Xia et al., 2024) using pre-computed guidance coefficients, projected score guidance (Kadkhodaie et al., 2024) pushing the image feature vector toward a feature centroid of the target class, characteristic guidance (Zheng and Lan, 2023) as a non-linear correction of CFG obtained using numerical solvers, and second-order CFG (Sun et al., 2023) assuming locally-cone shaped condition space. All these variants can be directly combined with our proposed generalization of CFG.\nDynamical regimes, statistical physics and high-dimensional settings. Akin to this work, several works recently studied dynamical regimes of diffusion models, primarily focusing on the standard, non-CFG version (Biroli and M\u00e9zard, 2023; Raya and Ambrogioni, 2024; Biroli et al., 2024; Sclocchi et al., 2024; Yu and Huang, 2024; Li and Chen, 2024; Aranguri et al., 2025). Statistical physics methods have been particularly useful in analyzing high-dimensional settings, e.g., data drawn from the Curie-Weiss model (Biroli and M\u00e9zard, 2023), high-dimensional Gaussian mixtures (Biroli et al., 2024), and hierarchical models (Sclocchi et al., 2024). Other relevant statistical-physics studies include Ghio et al. (2024), who provided a comprehensive theoretical comparison between flow, diffusion, and autoregressive models from a spin glass perspective; Achilli et al. (2024), who extended the theory of memorization in generative diffusion to manifold-supported data; Cui et al. (2025, 2023), who analyzed sample complexity for high-dimensional Gaussian mixtures. A rigorous formulation of diffusion models in infinite dimensional setting was developed by Pidstrigach et al. (2023)."}, {"title": "3 Background and High-Level Discussion", "content": "We begin by providing an overview of the standard framework for generative diffusion, serving as the foundation for our analysis. We let \\{{a_i\\}}_{i=1}^n \\in \\mathbb{R}^d represent \\(n\\) independent data points sampled from the true underlying data distribution \\(P_0(a)\\) that we aim to model.\nThe forward diffusion process, starting from the data points \\{{a_i\\}}_{i=1}^n, is modeled by an Ornstein-Uhlenbeck process, described by the following stochastic differential equation:\n\\[dx(t) = f(t)x(t) dt + g(t) dB(t), \\tag{1}\\]\nwhere \\(dB(t)\\) denotes the standard Wiener process (also known as Brownian motion) in \\(\\mathbb{R}^d\\). At any given time \\(t\\), the state \\(x(t)\\) is distributed according to a Gaussian distribution with mean \\(s(t) \\bar{a}\\) and variance \\(s(t)^2\\sigma(t)^2\\), where \\(s(t)\\) and \\(\\sigma(t)\\) are related to the functions \\(f(t)\\) and \\(g(t)\\) of Eq. (1) by \\(s(t) = exp \\int_0^t d\\tau f(\\tau)\\) and \\(\\sigma(t) = \\int_0^t d\\tau g(\\tau)^2/s(t)^2\\). The forward process is terminated at time \\(t_f \\gg 1\\), when \\(x(t_f)\\) is effectively pure Gaussian noise, distributed as \\(\\mathcal{N}(0, s(t_f)^2 \\sigma(t_f)^2 I_d)\\), with \\(I_d\\) being the identity matrix in \\(\\mathbb{R}^d\\). Note that for \\{{\\bar{a}_i\\}}_{i=1}^n drawn from \\(P_0\\), the distribution \\(P_t(x)\\) at time \\(t\\) is the convolution of the original distribution \\(P_0\\) with a Gaussian kernel.\nThe backward diffusion process operates in reverse time. Denoting reverse time variable by \\(\\tau = t_f - t\\), we can describe the process by the following stochastic equation:\n\\[dx(t) = - f(t)x d\\tau + g(t)^2\\hat{S}(x,t) d\\tau + g(\\tau) dB(\\tau),\\tag{2}\\]\nwhere \\(\\hat{S}(x, t) = \\nabla \\log P_t(x)\\) denotes the score function. The backward diffusion process generates points \\(x\\) sampled from the distribution \\(P_t(x)\\) for every time step \\(\\tau\\). At the end of the backward process, i.e., when \\(\\tau = t_f\\), the process generates points drawn from the original distribution \\(P_0\\).\nIn this work, we focus on generating data that can be categorized into distinct classes. We begin by assuming that the underlying data distribution is a \\(d\\)-dimensional probability distribution \\(P_0(x, c)\\), where \\(c\\) represents a discrete class index and \\(x\\) a \\(d\\)-dimensional vector. The aim is to generate data conditioned on \\(c\\), the class label. The procedure that is mathematically guaranteed to generate the correct (conditioned) target distribution consists of using the true conditional score, \\(S_t(x, c) = \\nabla \\log P_t(x|c)\\) in Eq. (2). CFG, however, does not do that; it instead further directs diffusion in a manner proportional to the difference between conditional and unconditional scores:\n\\[S_t^{CFG}(x, c) = (1 + w)S_t(x, c) - wS_t(x),\\tag{3}\\]\nwhere \\(w\\) denotes the guidance strength parameter."}, {"title": "3.2 Classifier-Free Guidance Works in High Dimension", "content": "CFG and distinct dynamical regimes. Biroli and M\u00e9zard (2023) and Biroli et al. (2024) analyze the dynamical regimes of the backward generative process in Eq. (2) for the case of two classes as \\(d \\rightarrow \\infty\\) through the lens of statistical physics. They identify two distinct regimes\\(^{1}\\) in the time-reversed process: in Regime I, the random dynamical trajectories have not yet committed to a particular class of data. In Regime II, the trajectories have committed to a class and generate the features necessary to produce samples from that class. This distinction is illustrated on a toy example in Figure 2. The transition between the two distinct dynamical regimes occurs at a crossover point called the speciation time, denoted \\(t_s\\).\n\\(^{1}\\) Note that if the perfect empirical score is used, there exists a third regime, Regime III, characterized by collapse, i.e., memorization of the training set, but we shall not discuss it here as it is not relevant to CFG."}, {"title": "4 CFG in the High-Dimensional Limit of Gaussian Mixtures", "content": "Here, we demonstrate the applicability of the general argument presented in Section 3 in a concrete case corresponding to high-dimensional Gaussian mixtures. We describe here the main findings, while the detailed analysis is provided in App. B. Specifically, we examine the case in which \\(P_0(a)\\) represents a superposition of two Gaussians, each carrying equal weight, with means at \\(\\pm m\\) and shared isotropic variance \\(\\sigma^2\\). To ensure that the two Gaussian clusters remain well separated in the limit of high dimensionality, we take the large \\(d\\) limit with fixed values of \\(|m|^2/d\\) and \\(\\sigma\\). We also assume that the score is correctly estimated. The extension to more than two Gaussian is straightforward and discussed in App. E. To simplify the notation, we focus on the SDE forward equation corresponding to \\(f(t) = -1\\) and \\(g(t) = \\sqrt{2}\\) (see Eq. (1)). All results can be easily translated for general choices of \\(f(t), g(t)\\).\nIn this setting, the speciation transition resembles a symmetry-breaking phenomenon, similar to what occurs in thermodynamic phase transitions. Biroli et al. (2024) investigated this phenomenon by analyzing the backward dynamics and determined the speciation timescale as \\(t_s = \\log(d)\\). In their analysis, \\(t_s\\) emerges as the timescale at which diffusion paths commit to a specific category. This is related to a change in the form of the potential in the backward Langevin equation, see Figure 2 (right). Applying this framework we find that the speciation time aligns precisely with the time until which CFG is effective in aiding class selection. Beyond this point, as the trajectory has committed to a class, CFG no longer influences the generated outcome."}, {"title": "4.1 Deriving the CFG Score", "content": "The distribution of the points at time \\(t\\), \\(P_t(x)\\), is the convolution of the initial distribution \\(P_0\\) and a diffusion kernel proportional to \\(e^{-(x - ae^{-t})^2 / (2\\sigma^2 + \\Delta_t)}\\):\n\\[P_t(x) = \\frac{1}{2\\sqrt{2\\pi \\Gamma_t}} \\left[ e^{-(x - me^{-t})^2 / (2\\Gamma_t)} + e^{-(x + me^{-t})^2 / (2\\Gamma_t)} \\right],\\]"}, {"title": "4.2 CFG Provides an Additional Push Toward the Desired Class in Regime I", "content": "We can analyze the score in Eq. (5) to identify which directions of the backward process are affected by CFG. Following Biroli et al. (2024), we first focus on Regime I, taking place on time-scales \\(t_s + O(1) = (1/2) \\log d + O(1)\\). Eq. (5) shows that the CFG-dependent part of the score is aligned on \\(m\\) direction, therefore CFG has no effect on the \"transverse\" directions \\(v \\perp m\\). The projection of the backward Eq. (2) on a unit vector in the space orthogonal to \\(m\\) follows the equation \\(dp = p(1 - 2/\\Gamma_{t_f - \\tau}) d\\tau + \\sqrt{2} dB\\). This is the backward equation for an initial Gaussian \\(\\mathcal{N}(0, \\sigma^2)\\), thus explicitly showing that all components of \\(x\\) orthogonal to \\(m\\) are unaffected by CFG and distributed as in the target distribution for \\(\\tau \\rightarrow t_f\\).\nHowever, when projecting onto \\(m\\) we observe that the CFG score \\(S^{CFG}_t\\) influences the component along \\(m\\). Defining \\(q(t) := \\frac{x \\cdot m}{|m|}\\), where \\(|m| = \\sqrt{d}\\), the evolution of the backward system in Eq. (2) guided to class \\(c = 1\\) is given by the following:\n\\[dq = \\left(q + 2\\left[-q + e^{-(t_s - t_a - \\tau)} \\left((1 + \\omega) - \\omega \\tanh \\left(\\frac{qe^{-(t_s - t_a - \\tau)}}{\\Gamma_t}\\right)\\right)\\right]\\right) d\\tau + d\\eta(\\tau),\\tag{6}\\]\nwhere again \\(\\tau = t_f - t\\), with \\(t_s = (1/2) \\log d\\), \\(\\eta(\\tau)\\) is the square root of two times a Brownian motion, and we used the fact that in Regime I we have \\(\\Gamma_t \\sim 1\\). From now onward, we omit the dependency \\(t(\\tau)\\) for backward time and simply use the notation \\(t\\) to avoid clutter and keep the notation simple.\nEq. (6) can be rewritten as: \\(dq = - \\frac{\\partial V^{CFG}}{\\partial q} d\\tau + d\\eta(\\tau)\\), where the effective potentials has two contributions:\n\\[V^{CFG} = \\frac{1}{2}q^2 + 2 \\left[ -\\frac{e^{-(t - t_s)} q}{3 + 2} + \\ln \\cosh \\left(\\frac{qe^{-(t - t_s)}}{3 + 2}\\right)\\right]:\\]\nFrom Eq. (7), we observe that the effect of CFG is adding to the classifier potential an extra contribution, plotted in Figure 3. The extra potential adds an additional push toward the positive values of \\(q\\), the ones corresponding to the class \\(c = 1\\). As shown from the figure, the effect of CFG is particularly strong for"}, {"title": "4.3 CFG plays no role in Regime II", "content": "The variable \\(q\\) diverges at the end of Regime I and becomes of order \\(\\sqrt{d}\\) in Regime II (as explained by Biroli et al. (2024)). One has therefore to focus on the rescaled variable \\(x \\cdot m/\\sqrt{d}\\). At the end of Regime I, \\(q\\) has realigned with the value it would have had for \\(\\omega = 0\\). Hence, the initial condition in Regime II (when guiding towards either of the classes, \\(c = 1\\) or \\(c = -1\\)) is \\(x \\cdot m/\\sqrt{d} = 0\\), independently of \\(\\omega\\). Moreover, since in Regime II, \\(x \\cdot m| e^{-t} / \\Gamma_t\\) is \\(O(d)\\) and \\(sign(x \\cdot m) = 1\\), one finds that the extra CFG term in Eq. (5) is zero since \\(1 - \\tanh (x \\cdot me^{-t}/ \\Gamma_t) \\rightarrow 0\\) for \\(d \\rightarrow \\infty\\). Therefore, we are able to conclude that for \\(t << t_s\\), for any \\(\\omega\\), in the large \\(d\\) limit the score obtained by CFG is equal to the score within the class \\(S_t^{CFG}(x, c) = S_t(x)\\), thus showing that CFG has no effect in Regime II.\nFurthermore, using that at the time of exit from Regime I, \\(q\\) has the same value as for \\(\\omega = 0\\), the backward dynamics during Regime II leads to the correct conditioned target distribution at the end of the backward process for any \\(\\omega\\). This effect is shown in Figure 1 (right panel) in the case of \\(d = 200\\) and in Figure 4."}, {"title": "4.4 Finite Dimensional Effects: Overshoot of the Mean and Reduction of the Variance", "content": "So far, we have shown that for any value of \\(\\omega\\) the target distribution is correctly reproduced in the infinite-\\(d\\) limit. We now consider the changes brought by considering \\(d\\) large but finite. A detailed analysis is presented in App. C; here we present the main results.\nThe extra CFG term in the score, see Eq. (5), is of the same order as the one corresponding to the conditional score within Regime I and remains so, even for finite \\(d\\). In contrast, in Regime II, the extra CFG term is zero for \\(d \\rightarrow \\infty\\) and exponentially small in \\(d\\) for finite \\(d\\). Thus, for large but finite dimensions, results obtained for \\(d \\rightarrow \\infty\\) carry over: CFG has a substantial effect only in Regime I and, hence, only on the initial condition for the dynamics in Regime II.\nThe effect of CFG in Regime I is to add an extra push toward the desired class. Indeed, the sign of the term introduced by CFG in the score accords with the desired class: in the Langevin equation it gives an extra contribution to the force which is positive for \\(c=+1\\), and negative for \\(c=-1\\). In consequence, the generated distribution shows an overshoot corresponding to the target distribution since its mean is larger for \\(c = +1\\), smaller for \\(c = -1\\). The relative amplitude of the overshoot for Regime II is of order \\(1/\\sqrt{d}\\), and it is due to the role of CFG on the dynamics of Regime I. The extra term due to CFG has another important effect: it leads to a larger second derivative of the potential \\(V^{CFG}(q, t)\\), see Figure 3 and App. C. Thus, the resulting CFG Langevin equation is associated to a potential that is more confining. This explains the numerical observation where we find that the CFG-generated distribution has a smaller variance than the one of the target distribution. The mean overshoot and the decrease in the variance for different guidance strengths are shown in Figure 10 in App. \u0421.\nTwo main conclusions result from this analysis. First, the error due to CFG for finite \\(d\\) agrees well with"}, {"title": "5 More General Guidance Forms", "content": "The blessing of dimensionality that makes CFG work in high-dimensions is due to two main properties: (1) CFG acts in Regime I pushing further in the direction of the desired class, (2) CFG does not play any role in Regime II where the detailed property of the data are generated.\nThis observation makes clear that CFG can be generalized to encompass other guidance schemes that still enjoy the two properties cited above. With this idea in mind, we propose non-linear variants of the CFG score of the type:\n\\[S^{CFG-NL}_t(x, c) = S_t(x, c) + \\left[S_t(x, c) - S_t(x)\\right] \\Phi_t\\left(\\left|S_t(x, c) - S_t(x)\\right|\\right).\\]\nFor constant \\(\\Phi_t(s) = w\\), this reduces to standard CFG. As long as the function \\(\\Phi_t(s)\\) satisfies \\(\\lim_{s\\rightarrow 0} [s \\Phi_t(s)] = 0\\), we know that in Regime II the extra contribution to the score due to \\(\\Phi_t\\) vanishes, thus leading to a correct target distribution in high-dimension. The freedom in the choice of \\(\\Phi_t\\) can be used to improve the effect of CFG in Regime I, helping to push the system in the direction of class \\(c\\), and reducing the unwanted finite dimensional drawbacks leading to mean overshoot and reduced variance. In the following, as a proof of principle, we propose a first candidate for \\(\\Phi_t\\). As we shall show, this choice already allows to improve very efficient generative models. In the long run, we envisage that the whole function \\(\\Phi_t\\) can be optimized as hyper-parameters."}, {"title": "5.1 Non-Linear Classifier-Free Guidance", "content": null}, {"title": "5.2 Power-Law CFG", "content": "We can choose \\(\\phi_t(s) = ws^{-a}\\) with \\(a < 1\\) to obtain the following guidance scheme:\n\\[S^{PL}_t(x, c) = S_t(x, c) + w \\left[S_t(x, c) - S_t(x)\\right] \\left|S_t(x, c) - S_t(x)\\right|^{-a}.\\]\nOne can understand the effect of this non-linear guidance as follows. The \\(l_2\\) distance between scores \\(\\delta S = |S_t(x, c) - S_t(x)|\\) vanishes as \\(e^{-t}\\) at large (forward) times, as all the forward trajectories starting from an initial point \\(\\bar{a}\\) build at time \\(t\\) a Gaussian cloud. Therefore w.r.t. the standard CFG in Eq. (3), this new score acts with an effective guidance strength which changes \\(w\\) to \\(w[\\delta S]^{-a}\\), making it stronger at the beginning of the backward process. Then, when the backward process gets closer to the speciation time, \\(\\delta S\\) decreases, the non-linear strength becomes weaker, and it vanishes in Regime II\\(^{3}\\), as displayed in Figure 8 in App. A.\n\\(^{3}\\) For computational reasons, one could stop applying guidance once the score difference becomes sufficiently small."}, {"title": "5.3 Generative image model experiments", "content": "Models, architectures and datasets. We validate our theoretical findings and test the performance of non-linear CFG both through numerical simulations with Gaussian mixtures with varying dimensions and number of classes, and five generative image models. The latter include: DiT (Peebles and Xie, 2023) as a standard diffusion framework and EDM2 (Karras et al., 2024b) as a state-of-the-art one. We test DiT-XL/2 and EDM2-S versions, trained and evaluated on ImageNet-1k (resolution 256 and 512 respectively) for class conditional generation. We also consider three text-to-image models. The first two models are trained on ImageNet-1k and CC12M (Changpinyo et al., 2021) and evaluated on CC12M, using the diffusion DDPM training objective (Ho et al., 2020) with MMDIT (Esser et al. (2024), similar to SD3) and MDTv2 (Gao et al., 2023) architectures scaled to 800M parameters. The last model uses a MMDiT architecture scaled to 1.6B parameters and is trained with a flow matching objective on YFCC100M (Thomee et al., 2016), CC12M and a proprietary dataset of 320M Shutterstock images, evaluated on COCO dataset (Lin et al., 2014). To ensure the protection of personal data, we blurred human faces in ImageNet-1K and CC12M. Additionally, we utilized Florence-2 (Xiao et al., 2023) to recaption images resulting in more accurate image content descriptions.\nComparing numerical simulations of a mixture of Gaussians to real-world experiments. In Figure 5 we observe similar hump-shaped behavior of the difference between conditional and unconditional score \\(|S_t(x, c) - S_t(x)|\\) for Gaussian mixtures and that of real-world models, both for class-conditional and text-to-image models, thus validating one of the main points of our theoretical framework. Using the parameter \\(a\\) in Power-law CFG, we can alter the shape of these curves, therefore obtaining more flexible frameworks generalizing standard CFG (see Figure 8 in App. B). We find that this flexibility enables faster convergence, yielding paths that consistently have smaller Jensen-Shannon divergence to the target distribution (across all time \\(T\\)), reaching the target distribution faster as well as reducing the overshoot of the target distribution (see Fig. 14, App. E).\nImproving image quality and diversity by non-linear CFG. To evaluate our method, we employed FID (Heusel et al., 2017) measuring image quality, and recall (Sajjadi et al., 2018) measuring diversity. Exact experimental configurations can be found in App. D.2. We benchmarked against the best-performing weight scheduler heuristic from Wang et al. (2024), the dynamic powered-cosine \\(w_t = 0.5(1 - \\cos \\pi(1 - t/T))^w\\), with \\(s, w\\) tunable parameters and \\(T\\) the number of denoising steps. As shown in Table 1, Power-Law CFG performs favorably both in terms of FID and recall. Furthermore, our proposed step-wise CFG heuristic achieved comparable performance to performing hyperparameter search over \\(t_1\\) and \\(t_2\\) but with two fewer hyperparameters, while further combining it with Power-Law yielded slight improvement in FID and notable improvement in recall. Qualitative examples are provided in Figure 6, with additional examples included in App. H (class-conditional) and App. I (text-to-image), displaying the improved realism and the increased diversity of the generated images.\nWhile Power-Law CFG demonstrates consistent benefits across different training objectives, noise schedulers, sampling methods, network architectures and datasets, its performance relative to other possible non-linear guidance strategies remains unexplored. We believe there may be more effective and advantageous strategies, which are worth exploring in future work."}, {"title": "6 Conclusion", "content": "We studied the theoretical foundations of classifier-free guidance (CFG), a widely used method with practical benefits but limited theoretical understanding. Our research revealed that CFG's inaccuracies in low-dimensional spaces do not hold true in the high-dimensional limit, yielding a \"blessing-of-dimensionality\" result. We extended our conclusions to large but finite dimensions, characterizing the discrepancies in lower dimensions. Building on our theoretical analysis, we developed a generalized version of CFG and confirmed its effectiveness through both numerical and real-world experiments, applying it successfully to leading efficient diffusion models. Our results demonstrated improved sample quality and diversity, while reducing the required computation. Future research directions could include a comprehensive evaluation of the advantages and limitations of non-linear CFG in comparison to alternative guidance methods, as well as designing new non-linear CFG techniques."}, {"title": "Impact Statement", "content": "This study contributes to the growing body of research aimed at deepening our theoretical understanding of diffusion models and their broader implications for generative modeling. By bridging the gap between theory and practice, we strive to improve the performance and efficiency of these models, which have far-reaching applications in various fields.\nHowever, as with any powerful technology, there are also potential risks associated with the development and deployment of advanced generative models. The increasing sophistication of deepfakes, for instance, raises concerns about misinformation, propaganda, and the erosion of trust in digital media. Moreover, the misuse of generative models for malicious purposes, such as creating fake identities or spreading disinformation, poses significant threats to individuals, communities, and society as a whole.\nIn light of these challenges, we hope that our paper, along with many others that aim to ameliorate understanding of these models, will contribute to a deeper understanding of their strengths and limitations. We believe that this is essential for developing effective strategies to mitigate the risks associated with generative models, and we hope that our work will be a step toward achieving this goal."}, {"title": "Appendix", "content": "The supplementary material is structured as follows:\n\u2022 In Section A, we give a brief introduction of related work, mainly focusing on the work by Biroli et al. (2024).\n\u2022 In Section B, we present experimental details for numerical simulations involving Gaussian Mixtures.\n\u2022 In Section C, we present the theoretical and numerical findings for finite dimension (including low dimension d).\n\u2022 In Section D we provide experimental details involving real-world experiments.\n\u2022 In Section E, we give the calculation required for computing the CFG score of a mixture of four Gaussians.\n\u2022 In Section F, we perform further numerical experiments examining the non-linear CFG forms.\n\u2022 In Section G, we draw a parallel to the work of Kynk\u00e4\u00e4nniemi et al. (2024), showing that the time interval at which the guidance is applied aligns with our findings."}, {"title": "A Introduction to related work: Classifier-free Guidance (CFG) and Specification Time in the High-Dimensional Limit", "content": "We start by briefly introducing the calculation required for estimating the speciation time \\(t_s\\) for a case of two equally weighted Gaussians. This section is a direct adaptation of the framework introduced by Biroli et al. (2024). The diffusion process", "1))": "n\\[dx(t) = -xdt + dB(t),\\tag{9}\\", "right),\\": "nwhere the function \\(g(x)\\) , defined as\n\\[g(x) = \\log \\int d a P_0(a)"}]}