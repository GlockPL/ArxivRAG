{"title": "On-device Learning of EEGNet-based Network For Wearable Motor Imagery Brain-Computer Interface", "authors": ["Sizhen Bian", "Pixi Kang", "Julian Moosmann", "Mengxi Liu", "Pietro Bonazzi", "Roman Rosipal", "Michele Magno"], "abstract": "Electroencephalogram (EEG)-based Brain-Computer Interfaces (BCIs) have garnered significant interest across various domains, including rehabilitation and robotics. Despite advancements in neural network-based EEG decoding, maintaining performance across diverse user populations remains challenging due to feature distribution drift. This paper presents an effective approach to address this challenge by implementing a lightweight and efficient on-device learning engine for wearable motor imagery recognition. The proposed approach, applied to the well-established EEGNet architecture, enables real-time and accurate adaptation to EEG signals from unregistered users. Leveraging the newly released low-power parallel RISC-V-based processor, GAP9 from Greeenwaves, and the Physionet EEG Motor Imagery dataset, we demonstrate a remarkable accuracy gain of up to 7.31% with respect to the baseline with a memory footprint of 15.6 KByte. Furthermore, by optimizing the input stream, we achieve enhanced real-time performance without compromising inference accuracy. Our tailored approach exhibits inference time of 14.9 ms and 0.76 mJ per single inference and 20 us and 0.83 uJ per single update during online training. These findings highlight the feasibility of our method for edge EEG devices as well as other battery-powered wearable AI systems suffering from subject-dependant feature distribution drift.", "sections": [{"title": "1 INTRODUCTION", "content": "Motor imagery brain-computer interface (MI-BCI) normally uses noninvasive electroencephalogram (EEG) electrodes to perceive a subject's intentions, aiming to present the kinetic movement in a digital system without the need to tense the muscles [29, 43]. Such an interface enables large-scale applications, e.g., for paralyzed users in rehabilitation [2, 4] and willingness control in robotics [23]. For years, researchers have developed abundant algorithms to translate EEG signals into the subject intention, from traditional methods like kernel partial least squares (KPLS) decomposition [45] or Riemannian covariances [13], to the emerged deep learning methods which abstract the EEG features via backpropagation enabled kernel optimization, such as convolutional neural network [30] and transformer with self-attentions [44], etc., the later has proved to supply the state-of-the-art performance in motor imagery classifications [3, 21]. However, one main challenge for EEG-based motor imagery classification, which still blocks the wide spread of consumer-level EEG systems, is the feature distribution drift of EEG signals across different subjects, caused by electrode/gel/skin interface [24], physiological disturbance [41], or diverse personal nature [31, 32], etc., affecting the reusability and generalization of deep learning models. An intuitive method might be recollecting the training data and reconstructing the model, which is time and computationally costly, thus obstructing the model's wide-range deployment.\nOne main approach to address the feature distribution drift across users and avoid an extra expensive workload is the subject-specific network model based on transfer learning [26], which transfers the knowledge learned in one group into the unregistered subjects. Such adaptive models maintain the interpreting ability of individuals with scarce data from the unregistered subjects. For example, in [47], the authors applied transfer learning on the Physionet EEG Motor Imagery dataset by first training and validating over the subjects via a five-fold cross-validation, then a subject-specific training and validation via a four-fold inter-subject generated the final customized models, achieving 70.8% classification accuracy in a four-class task. In [48], a deep transfer learning is developed and validated on dataset III of the second BCI competition, where the authors firstly apply the continuous wavelet transform (CWT) to convert the one-dimensional EEG signal into a two-dimensional time-frequency amplitude representation, and then a pre-trained convolutional neural network is further trained with scarce subject-specific EEG trials and utilized for two-class motor imagery classification, achieving a final classification accuracy of 96.43%. Such works have demonstrated the effectiveness of subject-specific EEG motor imagery classification models based on transfer learning. However, a neglected problem is that those models need to be trained offline on a PC or cloud before the deployment. Such a train-then-deploy design process rigidly separates the learning phase from the runtime inference, resulting in complexity for end users [6, 11]. In practical scenarios, especially on wearables, on-site adaptation is required to ease the post-training and deployment of the transferred models. In other words, the system should be capable of performing on-device continuous learning that automatically adapts to the ever-changing subjects or even the environment by only a few labeled input streams based on the original knowledge. Continuous learning aims to empower the system to incrementally learn non-stationary data streams, addressing the catastrophic forgetting issue that is commonly met in practical neural network deployments, such as testing samples from new tasks or data distribution [1, 46].\nIn this work, we experimentally show that by combining a novel processing unit, which incorporates parallel RISC-V Cores and an AI Hardware accelerator, and our proposed dedicated on-device learning engine, which is based on transfer learning, the accuracy of the EEG motion imaginary from unregistered users with scarce labeled input can be impressively improved, enabling on-site adaptation for wearable EEG systems."}, {"title": "2 RELATED WORK", "content": "Addressing the performance degradation between registered and unregistered users has been an emerging research topic in the ubiquitous computing domain [20, 33]. While different strategies have been proposed [36, 46], a fundamental factor is neglected: the model adaptation, in a lot of cases, needs to be carried out locally on edge devices. On-device learning enables models to train and update directly on extreme edge IoT devices continuously, which has already been successfully applied in different domains of interest. Table 1 lists a few typical domain studies in recent years. The authors in [37] introduced an on-device image classification model based on the MobileNetV1 [22]. A method named \"Latent Replay\" was implemented by storing activation volumes at intermediate layers and achieved state-of-the-art performance on complex video benchmarks combined with continual learning techniques. An on-device training strategy for accelerometer-based hand gesture recognition was presented in [5], where a standard online training approach (TinyOL [40]) with minibatch-based backpropagation was implemented to deal with the catastrophic forgetting issue. When deploying the adaptive model on STM32, the authors observed an acceptable accuracy drop compared with the original models on unconstrained computing platforms. The same edge platform was also adopted in [14] for human activity recognition with a compact adaptive 1D-CNN model that could be trained at full scale. Three submodules were used to implement backpropagation via gradient descent, an orchestrator, and two forward and backward submodules. The orchestrator governs the iterative training procedure by invoking alternatively the Forward and the Backward sub-modules, and allows specifying training hyperparameters. The authors concluded that such a full personalization CNN even outperformed the utilized transfer learning method on the WISDM human activity recognition dataset. In [12], a keyword spotting on-site adaptation system was developed to address accuracy degradation when neural networks are exposed to noisy environments. The system allows backpropagation-based weight optimization in the classifier layer(s) of a pre-trained neural network and achieves up to 14% accuracy gains. On-device tests show that the adaptation on MCUs takes as little as 806 mJ in only 14 s. Besides above works, on-device training has also been explored by applying different schemes of backpropagation for anomaly detection [40], ECG classification [18] (with federated learning), regression application like fuel consumption prediction [18], etc.\nUp to date, there are few works exploring motor imagery with on-device training to overcome the feature drift of EEG signals among subjects, although such drift severely blocks the wide deployment of neural network-based EEG motor imagery classification models. In this work, we built a dedicated on-device training engine for a specific processing unit to enable online learning and demonstrated its efficiency by observing the classification performance with/without on-device training. In summary, we bring the following contributions in this work:\n(1) We propose an on-device learning engine based on dense layer backpropagation to adapt a subject-specific EEG motor imagery classification model. The model has been implemented and evaluated, showing a 7.31% accuracy gain compared with online inference without subject-specific on-device training.\n(2) To optimize the on-device training and inference performance regarding energy and time consumption, especially for wearable EEG devices, we scaled down the input stream (64 channels to 19 channels) and the network size (24.9 KByte to 15.6 KByte) without bringing a significant drop to the classification accuracy (56.98% to 56.41%).\n(3) We presented a comprehensive evaluation of the computing efficiency of the on-device training and inference under different hardware hyper-parameters and input size configurations."}, {"title": "3 METHODS", "content": "Fig. 1 illustrates a wearable EEG system that normally faces the issue of cross-subject feature distribution drift and the online training scheme we implemented in this work. The scheme is demonstrated on an IoT device targeting wearable systems for EEG motor imagery classification. In this section, we will describe all the materials and techniques adopted in this study."}, {"title": "3.1 Dataset", "content": "The well-known publicly available EEG Motor Imagery dataset, Physionet [19], is used to verify our proposal since the dataset was collected from 109 volunteers (data from four of them are discarded as a result of variable trial number), which is suitable for online training evaluation. The volunteer performed different motor/imagery tasks while 64-channel EEG was recorded using the BCI2000 system with a sampling rate of 160Hz. Each volunteer performed 14 experimental runs: two one-minute baseline runs (one with eyes open, one with eyes closed) and three two-minute runs of each of the four following tasks: open and close the left(L)/right(R) fist physically and mentally, open and close both fists/feet(F) physically and mentally. To keep in line with previous four-class classification studies (L/R/0/F where 0 means relax time) [16, 47], we extracted the same classes from the raw dataset into instances of three seconds in length (480 samples) for exploration. Each run gives 21 trials per class per subject. Fig. 1 (left) shows the spatial distribution of 64 electrodes attached across the scalp, which correspond to the 64 channels of the EEG signal. To evaluate the performance of input downscaling, which aims to access the edge training and inference in real-time, we also used 19 and 8 channels as the model input, as shown in the same figure."}, {"title": "3.2 Target device", "content": "For wearable EEG-based system setup, we adopted the GAP9 microprocessor, a lowe power RISC-V-based PULP (Parallel Ultra Low Power) platform developed by GreenWaves Technologies, designed for ultra-efficient Al inference and signal processing. The GAP series is composed of three fundamental blocks: a fabric controller (FC), a smart peripheral controller (\u00b5DMA), and a parallel compute engine (Cluster). The FC is responsible for managing peripheral devices and controlling application execution on GAP9. The \u00b5DMA allows autonomous, low-energy peripheral management and on-the-fly calculation through specialized processing blocks for ultra-low latency tasks. The cluster provides a flexible, on-demand, high-performance programmable calculator for any task that demands significant compute resources such as digital signal processing or machine learning algorithms. Besides this, to achieve ultra-low power computing, the GAP series also adopts Dynamic Frequency and Voltage Scaling (DVFS) in multiple different domains of the chip, which allows elements of the chip to be entirely switched off when not in use but also the actual capabilities and energy consumption to be precisely tuned to the requirements of the task being executed. Such a heterogeneous design has been proven with impressive edge Al performance in a few case studies [8, 10, 34, 35]."}, {"title": "3.3 Neural Network Model", "content": "The motor imagery classification model applied in this work is the well-known EEGNet [25] (with slight adaption), a compact CNN architecture for EEG-based BCIs, proposed by Lawhern et al. in 2018. The network starts with a temporal convolution to abstract shallow features with eight kernels of size (1, SamplingRate/2), then a depthwise convolution is connected to each feature map individually with 16 kernels of size (ChannelNumber, 1), aiming to perceive the frequency-specific spatial patterns. The separable convolution (composed of a depthwise convolution with 16 kernels of size (1, SamplingRate/8) and a pointwise convolution) mixes the feature maps together after learning a temporal summary for each feature map individually. Although there are modified EEGNet for motor imagery recognition with higher accuracy [27, 38], we stick to EEGNet as first it is lightweight for edge systems and IoT devices, second, we are more interested in the performance gain instead of the absolute performance. The first variation of our model compared to the original EEGNet is that we used a fully connected layer followed by a softmax activation, acting as the classifier, gives the probability distribution of the four classes; while in the original model, the authors omit the use of a dense layer for feature aggregation prior to the softmax classification layer, aiming to reduce the number of free parameters in the model. The second variation is that we reduce the second average pooling size from (1, 8) to (1, 4), aiming to supply more space for on-device updating of the dense layer. As the original network was written in the Tensorflow framework, we first rebuilt the network with Pytorch to ease the following hardware deployment on the target device. The depthwise convolution is implemented by setting the group variable of the Conv2D function in Pytorch, as there is no direct depthwise convolution function in Pytorch. During training, the Adam scheme was used as the optimizer and initialized with a learning rate of 0.01 and decays with a gamma of 0.1 every 40 steps. An early stopping scheme is applied with a patience of 10. The categorical cross-entropy loss worked as the loss function in both offline and online training. For offline training, we set the batch size to 16, while during online training, it was set to 1. Fig. 2 presents the building blocks of the network in Pytorch and the corresponding input/output sizes, kernel shape, and the trained amount of parameters. Besides the baseline with a channel number of 64 and a window length of 3 seconds, we also evaluated two model input sizes with channel numbers of 19 and 8 and window length of 2 and 1 second, which also scales down the network footprint from 24.9 KByte to 15.6 KByte and 8.5 KByte. For both training and testing online and offline, network parameters are kept as float type."}, {"title": "3.4 Online training engine", "content": "After the pre-trained model is deployed onto MCUs, the parameters of the backbone (the layers before the final linear one) are frozen and transferred for online adaptation with unregistered users, while the weights and bias parameters of the linear layer are updated iteratively using the gradients calculated on the device along the input stream and the corresponding label. The gradients needed for parameter update are obtained by taking derivatives of the log loss. To expedite the learning process and to escape from local minima, we implement Stochastic Gradient Descent (SGD) with momentum as the optimizer to manage past gradients and perform parameter updates during online training. Concretely, the exponential moving averages (EMA) of the parameters' historical gradients are maintained and updated each time there inputs a new sample.The proposed on-device algorithm 1 describes the online training pipeline and is implemented in C language for the target device."}, {"title": "4 EVALUATION", "content": "As described in the last section, we use EEGNet for the on-device training evaluation, which has been widely applied in related works with variations along improved capability and expanded volume to boost the motor imagery classification performance [15, 28, 42]. Since the deployment in this work targets extreme edge IoT MCUs, we use the baseline of the EEGNet to avoid conflict with the memory budget. Meanwhile, to pursue edge computing efficiency regarding latency and energy consumption, we also evaluate the on-device training performance with another two model configurations by scaling down the input size and sampling window. Specifically, we chose the input channels of 19 and 8 and the sampling window of 2 and 1 second; the trainable parameters amount changes correspondingly. No quantization or pruning is used for compressing."}, {"title": "4.1 Feature distribution drift evaluation", "content": "Feature distribution drift often occurs when meeting users whose data are unavailable during offline training, resulting in a degradation of classification performance. To evaluate this degradation in the case of motor imagery and also the performance boosted by online training, we trained two networks using a small-scale dataset with instances from only 15 volunteers. The aim of such a split is to maximally simulate the practical scenarios and exploit the potential of online learning in cases where data collection is costly. The left volunteer's dataset was used for online training and online testing, with a split rate of 0.5. The two networks were trained with the following strategies:\n(1) Leave one user out: instances from three volunteers are selected as the validation dataset, while the instances from the other volunteers compose the training set, and five-fold cross-validation is used to train the model.\n(2) Leave one session out: instances of each volunteer are shuffled and split into five sessions of equal-size sub-collections. Five-fold cross-validation is carried out: in each round, one session from each volunteer is selected as the validation set, while the union of the rest sessions is used as the training set.\nThe aim of such a training strategy is to assess the influence of user-specific properties on the model performance, which can be expressed by the difference in the classification accuracy between the two trained models [9, 17]. As Table 2 presents, the training accuracy of Leave-One-User-Out degrades with an accuracy of 5.43% compared to the accuracy of Leave-One-Session-Out, which means that meeting the data from the unregistered users will weaken the motor imagery recognition ability to a certain extent, inferring the necessary of using online training to provide customized EEGNet for motor imagery classification."}, {"title": "4.2 On-device training performance evaluation", "content": "To evaluate the capability of post-deployment online training in model customization, half part of the instances from each remaining volunteer are used for online training, and another half part are used for online testing with and without online training. We use the averaged classification accuracy of all the remaining testers to assess the online testing performance before and after onine training. The Leave-One-User-Out offline trained model was used as the backbone, as it is more general in feature abstraction among trained users, and the other trained model is already prior to recognizing the motor imagery of the specific trained users. Table 3 listed the averaged inference accuracy with the three model configurations during different input statuses. As can be seen, the accuracy gain after the on-device training reaches up to 7.31% when using 19 channels of EEG signal and with a window length of 2 seconds. With the even smaller input size (8 channels and 1 second window), there is still accuracy gain (5.87%) by online training; however, the testing accuracy drops obviously, which is not the case when shrinking the input from 64 channels to 19 channels and window length from 3 to 2 seconds. Overall, the result indicates the efficiency of our proposal in EEGNet customization for boosting motor imagery recognition performance with new users."}, {"title": "4.3 On-device computing efficiency evaluation", "content": "The computing efficiency is evaluated by observing the on-device inference/training latency and energy consumption. We set five sets of clock speeds and input voltages to GAP9 for this evaluation: 150MHz/0.65V, 250MHz/0.7V, 300MHz/0.75V, 350MHz/0.8V, and 370MHz/0.8V, a power analyzer is used for the measurement. Fig. 4 and Fig. 5 show the result. During the inference, a smaller input size costs less energy and inference time. In the case of 370 Mhz and 0.8 V power input, per inference takes 2.1 ms and 0.10 mJ, 14.9 ms and 0.76 mJ, 49.3 ms and 2.47 mJ for the three models with different input sizes, respectively. Considering the competitive online testing accuracy after online training, the model with a 2 s window size and 19 channels supplies a maximal 67 Hz update rate at the classification output. Since the online training only updates the dense layer parameters, the cost regarding latency and energy is much smaller than a regular inference. For example, with the 370 MHz and 0.8 V power input, the latency and energy consumption for the three models are 18 us and 0.81 uJ, 20 us and 0.83 uJ, 24 us and 1.03 uJ per update (with single sample and single epoch). Such results guarantee the feasibility of online training for battery-powered wearable EEG devices."}, {"title": "5 CONCLUSION", "content": "This work described an on-device training engine for the EEG-based motor imagery brain-computer interface targeting the IoT MCUs, aiming to address the recognition degradation caused by feature distribution drift in EEG signals when a pre-trained model meets unregistered users. We utilized the baseline of EEGNet, the well-known Physionet EEG dataset, and a newly released MCU with parallel cores for Al execution, demonstrated the effectiveness of our on-device training engine, where the parameters of the final linear layer of the EEGNet are updated along with inputting stream of unregistered users. The updating is supported by the standard backpropagation with stochastic gradient descent as the optimizer. We used three model configurations with different input sizes to assess the on-board inference and training performance, including the recognition ability and computing efficiency. The on-board evaluation shows that with on-device training, the customized EEGNet could bring a classification accuracy gain of up to 7.31% with 19 channels of EEG input and 2 s of window length. Regarding computing efficiency, the onboard experiment shows 14.9 ms and 0.76 mJ per inference and 20 us and 0.83 uJ per update with the same model configuration when giving 0.8 V power input and 370 MHz main clock speed to the device, indicating the feasibility of our online training proposal for edge EEG devices like the wearable form EEG devices powered by batteries."}]}