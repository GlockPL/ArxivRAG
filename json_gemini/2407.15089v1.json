{"title": "Learning Physics for Unveiling Hidden Earthquake Ground Motions via Conditional Generative Modeling", "authors": ["Pu Ren", "Rie Nakata", "Maxime Lacour", "Ilan Naiman", "Nori Nakata", "Jialin Song", "Zhengfa Bi", "Osman Asif Malik", "Dmitriy Morozov", "Omri Azencot", "N. Benjamin Erichson", "Michael W. Mahoney"], "abstract": "Predicting high-fidelity ground motions for future earthquakes is crucial for seismic hazard assessment and infrastructure resilience. Conventional empirical simulations suffer from sparse sensor distribution and geographically localized earthquake locations, while physics-based methods are computationally intensive and require accurate representations of Earth structures and earthquake sources. We propose a novel artificial intelligence (AI) simulator, Conditional Generative Modeling for Ground Motion (CGM-GM), to synthesize high-frequency and spatially continuous earthquake ground motion waveforms. CGM-GM leverages earthquake magnitudes and geographic coordinates of earthquakes and sensors as inputs, learning complex wave physics and Earth heterogeneities, without explicit physics constraints. This is achieved through a probabilistic autoencoder that captures latent distributions in the time-frequency domain and variational sequential models for prior and posterior distributions. We evaluate the performance of CGM-GM using small-magnitude earthquake records from the San Francisco Bay Area, a region with high seismic risks. CGM-GM demonstrates a strong potential for outperforming a state-of-the-art non-ergodic empirical ground motion model and shows great promise in seismology and beyond.", "sections": [{"title": "INTRODUCTION", "content": "The accurate prediction of ground motion waveforms and their characteristics for future earthquakes is crucial for assessing seismic hazards and ensuring the safety and resilience of critical infrastructure. However, it is challenging and resource-intensive to obtain comprehensive ground motion observation across a wide geographic area. Furthermore, predictions of earthquake rupture processes and estimates of the Earth's elastic model remain to exhibit significant uncertainties. The development of precise and robust ground motion prediction methodologies has long been of great interest in seismology and earthquake engineering to complement the limited recorded data.\nExisting ground motion simulation studies branch into two streams: stochastic and physics-based approaches. The first stream, stochastic methods, is rooted in the modulation of Gaussian white noise to reproduce the desired ground motion characteristics [1-3]. They provide a computationally efficient framework to synthesize ground motion data by calibrating stochastic process-based models to match the historical recordings. However, potential limitations exist in representing spatial continuity and physical phenomena. The second stream, physics-based methods, is based on the numerical solution of wave equations [4-8] while considering comprehensive physical characteristics, including fault ruptures [9-12], heterogeneous earth media, and site-specific effects. Although recent advancements in high-performance computing enable simulating high-frequency waveforms of large-magnitude earthquakes (e.g., up to 10 Hz) [13], physics-based methods are computationally demanding. For example, ground motion simulations of the San Francisco Area over a domain of 120 km \u00d7 90 km \u00d7 35 km require 128 NVIDIA A100 GPU nodes and take 6 hours to compute up to a frequency of 5 Hz. Simulations at higher frequencies tend to be computationally prohibitive and these data are typically complemented by stochastic simulations [14, 15]. Furthermore, physics-based simulations face challenges from significant uncertainties in wave theory, subsurface elastic models, and source characteristics.\nMore recently, machine learning (ML) and artificial intelligence (AI) have shed new light on this classic task, primarily through their capability of accelerating earthquake modeling processes. One representative line of work is the application of neural operators for modeling seismic wave propagation [16, 17]. Although these data-driven ML methods show remarkable efficiency, by avoiding the stringent time-step constraints in traditional time-domain physics-based numerical approaches, they require a large amount of high-fidelity data. Researchers have also resorted to incorporating physical constraints into ML models, such as physics-informed neural networks (PINNs) [18]. In particular, by leveraging physical principles as a prior, PINNs have been used for predicting ground motions with a limited amount of training data [19-21]. However, PINNs are known to exhibit fundamental failure modes in network optimization [22-24]. Moreover, due to their specific design of objective functions, PINNs encounter significant limitations in generalizing to different initial conditions and subsurface elastic models. PINNs can be regarded as physics-based and still suffer from uncertainties in the problem setup. In addition, the spectral bias of fully-connected neural networks used by both neural operators and PINNs typically constrains the resolution to low frequencies [20], making broadband synthesis of waveforms challenging.\nGenerative modeling has emerged as an alternative approach for scientific modeling to capture the complexities of natural phenomena, as demonstrated for fluid dynamics [25, 26] and molecular science [27, 28]. It is an inherently stochastic method that incorporates random noise as inputs and utilizes probabilistic processes to generate diverse and realistic data. In the context of earthquake ground motions, generative modeling can produce various waveforms while capturing model uncertainties. This capability is critical due to the significant variability and unpredictability of real-world earthquake ground motions, influenced by factors such as seismic sources, propagation paths, and site conditions. Generative models, which are not governed by specific wave equations or subsurface models, need to learn meaningful wave physics (i.e., governing equations) and site/source conditions from sparse and irregular sensor and earthquake distributions. Generative Adversarial Networks (GANs) and their variants [29-32] have been shown to simulate ground motions with respect to distances, magnitudes, and near-surface velocity structures (Vs30) that follow empirical stochastic characteristics. However, GAN models are subject to well-known issues such as mode collapse and training instability [33], and their approaches cannot capture 3D wave propagation effects (e.g., path effects) due to the limited input conditional variables.\nIn this paper, we demonstrate that generative modeling can be more powerful by introducing Variational Autoencoder (VAE) and incorporating geospatial coordinate information. This approach enables the representation of wave propagation and meaningful spatial variations in ground motions, particularly in learning detailed wave physics and underlying Earth structures. To achieve this goal, we introduce a Conditional Generative modeling framework for Ground Motion (CGM-GM). Recent work [34] indicates that dynamic VAE models are a flexible, user-friendly, and robust alternative to GAN models for time series generation, mitigating common issues such as mode collapse and training instability. The primary advantage of dynamic VAE models is their use of variational sequential architectures (e.g., recurrent neural networks) in both prior and posterior distributions, which facilitates the capture of the temporal evolution (dynamics) of time series. Our main methodological contribution lies in the design of dynamic VAE models for learning time-frequency information and the conditional embedding of physical parameters, including earthquake magnitudes, depths, and geospatial coordinates. This strategy enables the CGM-GM framework to implicitly learn the underlying physics and spatial heterogeneity from observation data, even without explicitly incorporating physical principles. As a result, our generative models can produce realistic simulations that are aware of source, path, and site effects.\nWe demonstrate the effectiveness of our method by focusing on the San Francisco Bay area (SFBA). Despite the relative infrequency of large-magnitude earthquakes, the densely populated SFBA remains a region of significant public interest due to its history of such events. This is different from previous studies [29, 30, 32] that have leveraged a much larger number of large-magnitude earthquakes recorded in Japan. Instead, our work utilizes small-magnitude earthquakes that are crucial for characterizing earthquake ground motion, especially for the linear effects of the path and site. This task presents a significant challenge since our model needs to generalize well with lower signal-to-noise ratio (S/N) data. Moreover, the seismic data are recorded at a limited number of stations per event due to the released seismic energy and attenuation, which leads to a relatively sparse seismic network compared to wavelengths. Our results demonstrate the excellent performance of our proposed model in learning the underlying physics and the remarkable capability of producing Fourier Amplitude Spectra (FAS) maps and capturing spatial heterogeneity. These features distinguish our framework from existing generative models in the context of ground motion generation. Additionally, CGM-GM results exhibit great agreement between generated samples and ground truth data across the entire frequency range ([2, 15] Hz), including waveform shapes, peak ground velocity (PGV) distributions, FAS, and arrival time of earthquake ground motions in the SFBA. By learning the underlying physics, we envision that our approach will yield significant scientific implications and contribute to various downstream tasks."}, {"title": "RESULTS", "content": "Datasets\nThe dataset for the study of small-magnitude earthquakes in 1990-2022 in the San Francisco region is downloaded from the Northern California Earthquake Data Center (NCEDC) database. The stations of interest are chosen within a 50 km radius from the Hayward fault, and the events with magnitude M < 4 recorded within a hypocentral distance Rhyp < 100 km from the selected stations are included. We focus on two horizontal components H1 and H2 of particle velocity considering their direct importance for earthquake hazard analysis. The H1 and H2 components correspond to the East-West (E-W) and North-South (N-S) directions, respectively. After the data selection process illustrated in the Methods section, we retain 5, 108 and 5, 301 recordings available for H1 and H2 components, all within the frequency range of [2,15] Hz.\nConditional generative model\nWe present our CGM-GM framework based on a conditional dynamic VAE framework, as shown in Figure 1(a-d) for generating realistic ground-motion time-series data. The objective is to develop a generative model for predicting ground motions D* at unobserved sources and site locations, with varying earthquake magnitudes, based on actual sparse seismic recordings D. Firstly, in our model, we use Short-Term Fourier Transform (STFT) [35, 36] to decompose the time sequence data $x_{1:T}$ into amplitude and phase information in each time window, where T is the length of the ground motion time series. STFT is an effective technique to extract the time and frequency information, which is also considered in the previous implementation of the GAN model for ground motion generation [30]. Our dynamic VAE model is trained on amplitude information $A_{1:\\tau}$, which is in the time-frequency domain with a new time samplet used in STFT ($\\tau \\le T$). The key methodological contribution lies in the specific design of the prior and posterior distributions in VAE models, where we incorporate temporal dynamics using recurrent neural networks (RNNs) for learning time-frequency information [34, 37]. Next, we employ two strategies to obtain phase information and apply inverse STFT for waveform reconstruction. Specifically, during training, we use the true phase to recover ground motion data and construct a waveform loss to better capture waveform shapes. In the generation stage, phase information is estimated using phase retrieval methods. Furthermore, to generate the earthquakes in which we are interested, we integrate physical parameters (i.e., earthquake magnitudes and depths, geospatial coordinates of sensors and earthquakes) as conditional variables into the CGM-GM framework using Multilayer Perceptron (MLP) layers. These conditional parameters are fundamental for understanding earthquake applications since ground motions vary spatially due to structural heterogeneity and the magnitudes reflect the energy released by rupturing. Hence, Figure 2(c) is particularly novel, as we can obtain spatial variations of ground motions at a given scenario of earthquake locations and magnitudes. Another motivation for using geospatial coordinates is to enable neural networks to implicitly learn the physical interactions, such as path, source, and site effects. The rupture distances Rhyp and incident angles Ahyp can be computed based on the coordinate information (i.e., latitude, longitude, and depth) of earthquake hypocenters and stations of interest. In this study, we have not incorporated variations in focal mechanisms due to our focus on the Hayward fault, where the majority of seismic events exhibit similar focal mechanisms. A more detailed discussion of this aspect is presented in the Discussion section.\nWaveforms and spatial continuity\nBased on earthquake magnitudes and geospatial coordinates of earthquake sources and stations, the generator part of our CGM-GM framework produces physically consistent ground motion data. Figure 1(e) shows three representative comparisons between the generated ground motion waveforms and the true recordings. The selected cases involve seismic waveforms of similar magnitudes but with varying rupture distances, epicenter-station azimuths, and earthquake depths. Furthermore, we produce two random generations (blue) with the defined conditional variables to compare them with the corresponding observed data (red) in the time domain. The generated ground motion sequences effectively capture waveform shapes, frequency contents, peak values (e.g., waveform amplitude), and the arrival time, even for events with different rupture distances, depths, and magnitudes. For instance, in the first earthquake (M=2.51), the model successfully captures the moderate amplitude P-wave packet around 14 seconds, followed by the large amplitude S-wave and surface wave packets starting at 22 seconds. Noticeably, the peak amplitudes of wavefields are well generated. More detailed investigations of these peak amplitudes and their spectra are presented in subsequent sections. Another advantage of generative modeling for ground motion waveforms is to perform uncertainty analysis, as discussed in Supplemental Material B.3. For various earthquake scenarios, the mean curves of generated waveforms can capture dynamic characteristics of ground motion data, and the uncertainty regions show a good coverage of the ground truth. This indicates that our CGM-GM framework is effective and robust for generating earthquake ground motions.\nThe most interesting aspect of our proposed generative model lies in its ability to approximate ground motions for arbitrary (future) earthquakes and sensor locations. To demonstrate it, we compute FAS maps across a specific region in the SFBA. FAS provides valuable insights into the spatial variability of frequency-dependent ground motion and informs seismic hazard assessments, structural design, and risk mitigation strategies. Specifically, using our CGM-GM framework, we generate the ground motions within a selected sub-region of the SFBA, which spans longitudinally from -122.50\u00b0 to \u2212121.35\u00b0 and latitudinally from 37.27\u00b0 to 38.07\u00b0. A uniform 100 \u00d7 100 spatial grid is sampled on a geographic map, yielding 10,000 station coordinates. We utilize an existing earthquake event that occurred at 3:16 AM on October 21, 2011. This event had a magnitude of 3.84, with an epicenter located at latitude and longitude of (37.86\u00b0, -122.26\u00b0) and a depth of 7.94 km. Utilizing these conditions, 10,000 ground motion instances are generated and the FAS values are computed at each spatial location. The FAS map produced by our generative model at 10 Hz is shown in Figure 2(c). Remarkably, the generated FAS map presents spatial continuity for one single realization even between station pairs separated by large distances (e.g., in the southeast of the map). Moreover, we observe the FAS decay with respect to distances and its variation with azimuths, which validates the effectiveness of capturing spatial heterogeneity in ground motions by embedding geospatial coordinates of sources and stations into the CGM-GM framework. These characteristics are consistently seen across frequencies ranging from 2 to 15 Hz and under various earthquake scenarios, as detailed in the Supplementary Material B.6.\nWe conduct a comparative study between the generated results and baseline models specifically tailored for the SFBA [38-40], to assess the performance of our CGM-GM. The selected baseline models integrate methodologies from both ML and seismology. The first method is the empirical ground motion model (GMM), which is built from the observations and widely employed to predict ground motion intensities for seismic hazard analysis [38]. We use a state-of-the-art non-ergodic GMM [40] that incorporates location-specific effects to accurately represent the ground motion intensities. It is specifically built for the SFBA from the same dataset used in this study. The second one, termed CGM-baseline, utilizes the same CGM-GM architecture but only includes three conditional variables: earthquake magnitudes, source depths, and rupture distances. Figures 2(a-b) illustrate the FAS results of the non-ergodic empirical GMM and CGM-baseline. The FAS map generated by the CGM-baseline reveals a radial pattern, attributed to the constrained conditional embedding and the implicit assumption of a homogeneous Earth subsurface across the spatial domain. Hence, the contours of this FAS map are circular, showing geometrical spreading and average attenuation effects. In contrast, the CGM-GM and non-ergodic GMM capture more local features by incorporating location-specific factors, which provides a more nuanced representation of the spatial variability in ground motions. For instance, both models predict larger motions in the southern region near San Jose compared to the CGM-baseline predictions. This is reasonable considering that the soft Bay Mud in the area amplifies the ground motions. However, certain discrepancies are observed in the spatial distributions of FAS maps derived from our generative model and the non-ergodic GMM. The CGM-GM predicts slightly larger motions in the northwest region near San Francisco than the non-ergodic GMM, which is also plausible due to the presence of Bay Mud in the area. The first-order agreement between the CGM-GM and non-ergodic GMM demonstrates the validity of our framework in learning hidden ground motions.\nTo further evaluate the accuracy of all models, we investigate their performance against true ground motion recordings for all earthquake events. Figure 2(d-e) illustrate the averaged FAS differences (Residuals) in the form of a natural logarithm between the true recordings and simulated samples from the non-ergodic GMM, the CGM-baseline, and CGM-GM model across the entire frequency band of [2,15] Hz. This comparison includes the mean values and their associated uncertainties, represented by one standard deviation (std). Overall, our generative model and the non-ergodic GMM show similar residuals. At frequencies below 11 Hz, the CGM-GM slightly outperforms the non-ergodic GMM, though its performance declines at frequencies above 11 Hz. The uncertainty ranges for both models overlap significantly. These findings indicate that the CGM-GM performs comparably to, or even surpasses, the state-of-the-art non-ergodic GMM. In comparison to the CGM-baseline, our CGM-GM demonstrates reduced misfits and uncertainty over the entire frequency, confirming the importance of incorporating spatial heterogeneities into generative models. This evaluation underscores the efficacy of our generative modeling framework for capturing spatial representation in ground motion generation.\nAmplitude spectra\nWe further assess the performance of our CGM-GM in the frequency domain, specifically analyzing FAS values and their frequency distributions versus rupture distances. To present a comprehensive evaluation, we select diverse ranges of earthquake magnitudes and geospatial coordinates, generating 100 random samples for each set of conditional variables. For instance, as shown in the top-left part of Figure 3(a), we select the range of earthquake magnitudes in [1.75, 2.25], the rupture distances in [10, 20] km, and the earthquake depths in [5, 10] km, where 63 ground motion sequences in our field dataset. We obtain the statistical values (e.g., 15th percentile, mean, and 85th percentile) for ground truth and generation results using 63 and 6,300 samples, respectively.\nFigure 3(a) shows the variations of FAS values across diverse earthquake magnitudes and rupture distances. Generally, the FAS results simulated by our CGM-GM model align well with the true FAS curves, especially for mean curves. However, we also observe that the CGM-GM model tends to slightly under-predict at the low-frequency part ([2,3] Hz) and over-estimate at the high-frequency region ([13,15] Hz). This is due to the inductive bias of VAE models, where the learned amplitude information is over-smoothing in the logarithmic space. Similarly, this phenomenon is also seen in Figure 3(b), which illustrates a heatmap of frequency distributions versus rupture distances. The error is computed with the division of the natural logarithm of generated FAS f and ground truth f*, which is given by ln(f/f*). The heatmap of the generation results exhibits a generally good alignment with that of the ground truth data. The discrepancies primarily manifest in low-frequency and high-frequency parts. However, the magnitude of logarithmic division errors remains within an acceptable range (approximately [-1.1, 1.2]). Additionally, we provide the comparisons between the generated and true FAS values across different earthquake depths in the Supplementary Material B.4, and discuss the model performance for the H2 component in the Supplementary Material B.5.\nP and S arrival times\nTo further evaluate the quality of synthesized waveforms, we analyze the statistical properties of amplitudes and arrival times of the generated ground motions in the time domain. Statistical analysis of ground motion data is essential for developing predictive models. In this study, we focus on investigating the relationship between rupture distances and three evaluation metrics: the PGV distribution, the peak arrival time (i.e., arrival times of the wavelet of the PGV), and the arrival times of P- and S- waves. Specifically, we implement 100 realizations of ground motion generation with consistent conditional variables from the SFBA dataset. All the statistical analyses are based on these multiple-run generations. Firstly, the PGV distribution across the rupture distances is visualized in Figure 4(a). The solid lines and dashed lines denote the mean curves and the boundaries of mean \u00b1 standard deviation (std), and the dark points present the corresponding PGV values of data samples. We observe that the generated samples effectively capture the distribution of PGV values, including magnitudes and associated uncertainty regions, across diverse rupture distances. It implies that the generations can match the ground truth data well. Moreover, we analyze the arrival of seismic waves. As shown in Figure 4(b), the generated results present a strong correlation with the ground truth data in terms of the arrival time versus rupture distances. To gain a deeper insight into the performance of our generative model, we further investigate the performance of capturing the arrival time of P and S waves in the EW direction. Specifically, we use the PhaseNet [41] to pick the arrival time of two types of waves with a probability larger than 50%. Figure 4(c) and (d) show the cross-validations between the generated and true arrivals, including 3,138 and 909 samples for P and S waves respectively. The result demonstrates an excellent agreement and validates the effectiveness of our proposed generative modeling method."}, {"title": "DISCUSSION", "content": "In this section, we discuss the inherent sparsity in real-world earthquake datasets and the selection of conditional variables due to their significant effects on the performance of generative modeling. Due to practical constraints, the spatial distribution of seismic stations is often sparse and non-uniform across the geospatial domain. This sparsity leads to uneven data coverage and gaps in the observation data, which poses challenges for generative models in accurately capturing the underlying spatial heterogeneity. This task is intrinsically complicated since it requires the ground motion models to infer spatial variability and site-specific effects without direct observation data. Therefore, the generative models might exhibit artifacts in producing FAS maps for areas lacking measurement data, as illustrated in Figure 2(b).\nIn our generative model, focal mechanisms are not included as conditional variables for two reasons. Firstly, our earthquake data are mostly concentrated around the Hayward and San Andreas Faults, where these earthquakes predominantly exhibit similar focal mechanisms (i.e., the right lateral faulting). Importantly, our primary interest is also in generating waveforms along the Hayward Fault with consistent focal mechanisms, which indicates no domain shift for the earthquake rupturing processes. The second reason is the data limitation. As mentioned, there is insufficient variation in the focal mechanisms of the recorded earthquakes to effectively train the network for arbitrary focal mechanisms parameters (e.g., fault strike). Typically, generative models work well when the generated data interpolates within the range of the training data, as we have demonstrated for source and receiver locations. Incorporating focal mechanisms as a variable would only yield reliable generations within very limited focal mechanisms.\nA potential limitation lies in the lack of the constraints of path effects. The current generative modeling framework only incorporates spatial information as conditional variables without considering the correlation between different pairs of stations and sources. The implicit learning of paths can be achievable since the training waveform data naturally contains the path effect. When numerous waveforms are available for training, the generative model should be able to learn the path effects. However, in reality, the data is often limited and we may need an explicit way to include the path effects. To address this issue, we would like to investigate the incorporation of the spatial correlation, such as Mat\u00e9rn covariance function [42, 43], into generative modeling. In addition, using phase retrieval methods for waveform reconstruction may lead to inaccurate phase information in the generated samples due to the intrinsic difficulty in such ill-posed inverse problems. Hence, we will consider building a generative model directly in the time domain instead of the time-frequency domain to avoid using phase retrieval methods. Another direction is exploring specific techniques, such as generalized variance parameterization [44] and heavy-tailed distributions [45], to mitigate the over-smoothing issue in VAE models."}, {"title": "CONCLUSIONS", "content": "Our proposed generative modeling framework is user-friendly and stable to train. It presents effectiveness and efficiency in producing synthetic ground motions for various earthquake scenarios with different magnitudes and geographical regions in the SFBA. The most exciting part is that our CGM-GM can capture the underlying spatial heterogeneity and physical characteristics, as evidenced by the generation of realistic FAS maps. We conduct a comparative assessment of our CGM-GM against baseline models, including the CGM-baseline and a state-of-the-art non-ergodic GMM. The results demonstrate that our method performs comparably to, and in some aspects slightly surpasses, the most advanced non-ergodic GMM. This validates that incorporating geospatial coordinates as conditional variables effectively enables our model to learn spatial heterogeneities. Moreover, we comprehensively evaluate the performance of the model on generative modeling for ground motion synthesis in both time and frequency domains. For the assessment in the time domain, the ground motion samples generated by CGM-GM show excellent capability of capturing waveform shapes, PGVs, and arrival time. For the evaluation in the frequency domain, the FAS values exhibit great agreement between the observed and generated data. Overall, we anticipate that the promising results of scientific generative AI modeling for ground motion synthesis will encourage researchers to explore this area, and the potential issues we have identified will enable the development of more effective methods for enhancing generation quality."}, {"title": "METHODS", "content": "In this section, we present the technical details of our generative model in the context of ground motion simulation. The entire framework is shown in Figure 1(a-d), including the forward and inverse STFT, the network design of dynamic VAE, the sequential model prior, and the embedding of conditional variables. Here, we use the dataset from the H1 component as an illustrative example, and the results on the H2 component are provided in the Supplemental Material B.2 and B.5.\nForward and inverse STFT\nSTFT has been widely applied in audio processing [46, 47] and seismic data analysis [48-50]. It defines a valuable category of time-frequency distributions [51] that describe the amplitude and phase relationships with respect to time and frequency for any signal. This is achieved by repeatedly applying the Fourier transform within specific time windows. Typically, we use sliding time windows with overlaps to capture signals throughout the entire time domain. Therefore, leveraging STFT in generative modeling [52, 53] facilitates the extraction of time and frequency information A from the ground motion sample x. Although the time-frequency resolution of STFT is fixed in the entire time and frequency domains with the chosen time window length, the inverse STFT is relatively stable compared to other 2D spectral decomposition methods such as continuous wavelet transform. The inverse STFT is employed to reconstruct waveforms from amplitude spectrograms A. During the generation of artificial ground motions, phase retrieval methods are used to estimate the phase information. To be more concrete, these approaches estimate the missing phase information from available amplitude measurements and then recover the timing and shape of seismic waveforms in earthquake ground motion analysis. Various mathematical techniques are leveraged for phase retrievals, such as iterative algorithms and optimization frameworks. For instance, the Griffin-Lim algorithm [54] is widely used thanks to its simplicity and effectiveness. It iteratively refines estimates of seismic wave phases to minimize the discrepancy between the original and reconstructed signals. On the other hand, the Alternating Direction Method of Multipliers (ADMM) [55] is a versatile optimization technique that has gained traction in various scientific domains, including ground motion synthesis [30]. ADMM leverages a convex relaxation framework to decompose complex optimization problems into simpler subproblems and solve the augmented Lagrangian function iteratively. In this paper, we leverage the dynamic VAE model to learn amplitude information and employ the Griffin-Lim algorithm for phase retrieval due to its simplicity. This strategy is chosen over generating phase information with the VAE model, as phase signals are complex and amplitude evolution is relatively smooth over time.\nDynamic VAES\nWe consider a dynamic VAE architecture since it is specifically designed to model sequential data with temporal correlations by extending from standard VAEs [34, 37, 56]. Although VAE models have achieved great success in image processing tasks, the absence of explicit temporal modeling in standard VAEs hinders their effectiveness in tackling time series and audio data [57]. The dynamic VAE models focus on a sequence-to-sequence mode for encoding and decoding. Namely, the latent variable is constructed in the form of a temporal sequence instead of a \"static\" vector. Let us consider a time sequence $x_{1:T} = \\{x_t \\in \\mathbb{R}^N\\}_{t=1}^T$, where T is the sequence length. Dynamic VAE models typically yield a sequence of latent variables $Z_{1:T} = \\{z_t \\in \\mathbb{R}^l\\}_{t=1}^T$. Therefore, the joint distribution of latent and observed sequences can be reformulated as\n$P_{\\theta}(X_{1:T}, Z_{1:T}) = \\prod_{t=1}^T P_{\\theta}(X_t|X_{1:t-1}, Z_{1:t})P_{\\theta}(Z_t|X_{1:t-1}, Z_{1:t-1}).$ (1)\nEq.(1) is a generalized version that describes the generative process in dynamic VAEs. Researchers usually resort to state-space models (SSMs) to simplify the dependencies in conditional distributions of Eq.(1) [57]. One of the most commonly used SSM families is RNNs, which are specifically designed network architectures for handling sequential data and capturing temporal dependencies among data points. However, a significant challenge in training vanilla RNNs is the vanishing and exploding gradient problem. The reason behind this phenomenon is that the gradients can either shrink exponentially (vanishing gradients) or grow exponentially (exploding gradients) when RNNs propagate information through time. This instability hinders effective training and prevents the network from learning long-term dependencies. To alleviate such issues, gating-based RNNs, such as LSTM [58] and GRU [59], are proposed to control the flow of information through the network. By incorporating the auto-regressive recurrence into dynamic VAE models, the generative process can be simplified as\n$P_{\\theta} (X_{1:T}, Z_{1:T}) = \\prod_{t=1}^T p_{\\theta}(X_t|Z_t)p_{\\theta} (Z_t|Z_{1:t-1}).$ (2)\nMoreover, the approximate posterior can be reformulated as\n$q_{\\phi}(Z_{1:T}|X_{1:T}) = \\prod_{t=1}^T q_{\\phi}(Z_t|Z_{1:t-1}, X_{1:t}),$ (3)\nwhere $q_{\\phi}(Z_{1:T}|X_{1:T})$ works as an inference model for the latent sequence $Z_{1:T}$ from the observed sequential data.\nThe training of a dynamic VAE model involves optimizing the evidence lower bound (ELBO) on the marginal likelihood of the observed data $X_{1:T}$. For a given data sample $x_{1:T}$, the marginal likelihood is defined as\n$\\log p_{\\theta}(x_{1:T}) = D_{KL}(q_{\\phi}(Z_{1:T}|X_{1:T})||p_{\\theta}(Z_{1:T}))||p_{\\theta}(z)) + \\mathcal{L}(\\theta, \\phi; x_{1:T})$\n$\\geq \\mathcal{L}(\\theta, \\phi; x_{1:T}),$ (4)\nwhere $D_{KL}(\\cdot)$ denotes the Kullback-Leibler (KL) divergence between the approximate and true posterior distributions. $D_{KL}(\\cdot)$ is a non-negative term. Therefore, $\\mathcal{L}(\\theta, \\phi; x_{1:T})$ represents the ELBO, which is given by [68]\n$\\mathcal{L}(\\theta, \\phi; x) = \\mathbb{E}_{q_{\\phi}(Z|X)} [\\log p_{\\theta}(X|Z)] - D_{KL}(q_{\\phi}(Z|X)||p_{\\theta}(Z)).$ (5)\nThe first and second terms on the right-hand side (RHS) are reconstruction loss and a KL-divergence term, respectively. The KL-divergence works as a regularizer for $\\phi$ that promotes the approximate posterior $q_{\\phi}(Z|X)$ to closely resemble the prior $p_{\\theta}(Z)$. Note that the KL-divergence term in (17) is analytically tractable but the reconstruction error term requires estimation via Monte Carlo sampling. Thus, the expectation w.r.t. $q_{\\phi}(z|x)$ can be estimated by\n$\\mathbb{E}_{q_{\\phi}(z|x)} [\\log p_{\\theta}(x|z)] \\approx \\frac{1}{R} \\sum_{r=1}^R \\log p_{\\theta}(x|z^{(r)}),$ (6)\nwhere R samples $z^{(r)}$ are independently and identically drawn from $q_{\\phi}(z|x)$. Given a dataset $X = \\{x_i\\}_{i=1}^M$, where X consists of M independent and identically distributed (i.i.d.) samples, the resulting estimator of ELBO is written as,\n$\\mathcal{L}(\\theta, \\phi; X) = \\sum_{i=1}^M \\log p_{\\theta}(x_i|z_i)\n- \\sum_{i=1}^M D_{KL}(q_{\\phi}(Z_i|x_i)||p_{\\theta}(Z_i)).$ (7)\nTo optimize (19), stochastic gradient descent (SGD) methods, such as Adam [73], are typically considered. The ELBO $\\mathcal{L}(\\theta, \\phi; X)$ is optimized w.r.t. both the generative parameters $\\theta$ and the variational parameters $\\phi$. Note that $\\mathcal{L}(\\theta, \\phi; X)$ is differentiable w.r.t $\\theta$ but it is problematic to obtain the derivatives w.r.t. $\\phi$. To solve this issue, the reparameterization trick is proposed [68] to conduct a differentiable transform, where $z_i$ can be reparameterized as\n$z_i \\sim \\mathcal{N}(\\mu_{\\phi}(X_i), \\sigma_{\\phi}^2(x_i)),$ (8)\nwhere $\\sigma_{\\phi}(x_i)$ comprises the diagonal elements in a diagonal covariance matrix.\nConditional variables\nWe design an embedding module, consisting of a stack of MLP layers, to integrate the conditional variables into the framework. The illustration of embedding conditional variables is presented in Figure 1(d). To fully encode physical knowledge into the generative process, we apply this shareable embedding module to the encoder, the decoder, and the model prior. For the embedded of physical variables, we use earthquake magnitudes and the geospatial coordinates of earthquake sources and stations. The primary rationale for incorporating geospatial coordinates is that many physical properties, such as source and site effects, are inherently coordinate-based and crucial for ground motion simulation. Neural networks can implicitly learn representations of the underlying physics and kinematics with the coordinates as inputs [18, 61]. Note that, in previous papers [29, 30], the researchers also use the information Vs30. Given that Vs30 is an empirical parameter based on geological coordinates, the embedding network should be capable of implicitly capturing these velocity properties with coordinate information as inputs. Vs30 is a proxy correlated with site-specific ground-motion properties, and it is often used in the development of ground-motion models. However, estimations of Vs30 are not always available at all sites and can present significant uncertainties. Thus, we choose not to integrate Vs30 into our model as a parameter and instead estimate local site conditions directly from ground motion data with conditional generative modeling.\nData selection\nA total of 626,423 recordings are collected that spans from 10 seconds prior to the event time to 60 seconds after the event time, leading to each recording of 70 seconds with 7,000 time steps per component. We perform a selection procedure to ensure only recordings with an acceptable S/N ratio are used. Specifically, the first 10 seconds of each recording are considered as noise, while the subsequent 60 seconds are analyzed as earthquake signals. The Fourier transforms of both the noise and the signal are calculated up to the Nyquist frequency of 50 Hz, and the Fourier amplitudes are smoothed using the Konno-Ohmachi window procedure [62] with a smoothing parameter bexp = 20 [62]. The S/N ratio is computed for each recording by comparing the amplitude spectra of the signal and noise. We keep those recordings with an S/N ratio exceeding 3 across the frequency range of 2 to 15 Hz. Hence, approximately 15,000 recordings per component are retained. Additionally, we conduct a rigorous visual inspection for each time series to exclude those with equivalent noise levels in the first 10 seconds and the last 60 seconds. This process results in 5,108 and 5, 301 recordings available for horizontal components H1 and H2, respectively. After selecting the final recordings, a bandpass filter is applied over the frequency range of interest in [2,15] Hz.\nFigure 5(a) and (b) present the distribution of earthquake depth and the scatter plot of the corresponding magnitudes and rupture distances, respectively. The locations of selected stations and events for the H1 component are shown in Figure 5(c) and (d). Note that our methods are applicable to diverse earthquake ground motion datasets (i.e., different magnitude ranges) and geographical regions. More complete information about the dataset can be found in [63].\nImplementations\nThis part includes the data preprocessing and the training implementations. The last 60 seconds of the SFBA dataset are selected for ground motion generation. The dataset is then split into {80%, 20%} for training and testing, respectively. Namely, the number of training samples is 4086 for the experiments. Firstly, we use STFT to obtain the time-frequency information from the ground motion data since the CGM-GM model focuses on learning the amplitude spectrograms. The window length and hop length are set as 160 and 46, respectively. Therefore, the amplitude spectrogram has a size of 81 \u00d7 131, where 81 is the frequency range and 131 denotes the sequence length. The window length of 160 is equivalent to 1.6 seconds. We use signals between [2,15] Hz for our analysis, and this window length contains three wavelets for the lowest frequency to resolve signals at this frequency. The hop length is more arbitrary, and Welch [64] recommends using a length shorter than half of the window length. Due to the computational cost, we use 46 in this study. We add a minimum threshold of 10-10 for amplitude spectrograms and then convert them into the logarithmic space. Furthermore, the logarithmic time-frequency coefficients are normalized between 0 and 1. For conditional variables, we consider the earthquake magnitudes and geospatial coordinates of sources and stations. Each variable is scaled within [0,1] separately.\nFor the model parameters in CGM-GM, we consider a 3-layer MLP with feature sizes of [32, 32, 16] for embedding conditional variables. The label embedding module, as shown in Figure 1(d), is kept fixed for different parts of the network. For the Encoder component, we use one GRU layer with a hidden dimension of 144 and two independent 2-layer MLPs with dimensions of [64,32] to obtain the sequential latent variables. Note that the outputs from the encoder part, \u03bc1:7 and 01:7, have the same sequence length as the input amplitude spectrogram A1:7. For the decoder, a stack of MLP layers with feature sizes of [128,128,81] is employed for reconstructing the amplitude information. For the sequential prior model, we use one GRU layer with a hidden dimension of 32 and two independent linear layers to get the sequential prior variables. This model architecture contains 0.17 million parameters.\nWe use the Adam [65] optimizer to train the proposed method for 5,000 epochs. The learning rate is set as 8 \u00d7 10-4 initially and decays every 100 steps with a ratio of 0.99. The weight decay parameter is set as 5 \u00d7 10-5 and the batch size is 128. Furthermore, we leverage the grid search to select the hyper-parameters in the loss function. The optimal parameters are defined as \u03b1 = 0.5 and \u03b2 = 0.2.\nEmpirical GMMs\nEmpirical ergodic and non-ergodic GMMs for velocity FAS values are developed to evaluate the ground motions generated by our CGM-GM. Specifically, ergodic GMMs focus on the average scaling of ground motions, and non-ergodic GMMs account for the spatial distribution of ground motions due to path effects related to the 3-D velocity structure. For the ergodic GMM, the functional formulation of the natural log of FAS values, i.e., ln(Y), is given by\n$\\ln(Y; M, R_{hyp}, D_{hyp}) = \\alpha_0 + \\alpha_1 M + \\alpha_2 \\ln(R_{hyp}) + \\alpha_3 D_{hyp} + \\delta B_e + \\delta S2S_s + \\delta P \\frac{RRuP}{100}SP + \\delta W \\frac{Ses}{eS}, (9)$\nwhere \u03b1\u2081M, \u03b12ln(Rhyp), \u03b13Dhyp denote magnitude scaling, geometrical spreading, and depth scaling terms, respectively. dBe, dS2Ss, dPe represent the source, site, and path effects with zero-mean normal distributions. W Ses is the with-site residual, which is also assumed to be normally distributed. The coefficients are derived through linear regression, ensuring a smooth spectrum and imposing physical constraints on the coefficients [66]. Moreover, the total standard deviation of ergodic GMMs is defined as,\n$\\sigma_{fas} = \\sqrt{\\tau^2 + \\phi_{S2S_s}^2 + \\phi_{Ss}^2}, (10)$\nwhere \u03c4, $S2S_s, Oss denote the standard deviation of the mixed-effects coefficients dBe, SS2Ss, 8W Ses, respectively. The parameters of the ergodic GMM in the SFBA at different frequency bands (2, 5, 10, and 15 Hz) are detailed in Table 1.\nFor the non-ergodic GMMs, the source, site, and path terms are considered spatially dependent, which are the functions of the coordinates of sources and sites. Therefore, the non-ergodic GMM is re-written as [67],\n$\\ln(Y; M, R_{hyp}, D_{hyp}, ..., t_{ees}, t_{ss}) =LA24_{Adj-erg}(M, R_{hyp}, D_{hyp}) + \\delta L2L(t_{ees}) + \\delta S2S(t_{ss}) + \\delta P2P(t_{ees}, t_{ss}) + \\delta B^e + \\delta WSP_{es} (11)$\nwhere LA24 is the median from the ergodic model as shown in Eq. 9, 8L2L(tees), 8S2S, 8P2P are the median shifts of the source, site, and path terms. tees and tss represent the earthquake and site locations. Additionally, the term SB\u00b0 + SWSPes denotes the aleatory variability apart from the systematic source, site, and path effects. The Gaussian Process (GP) regression is leveraged to fit the available ground motion data within the SFBA dataset by providing the medians and epistemic uncertainty [40]. The non-ergodic GMMs simulate FAS maps thanks to the capability of spatial interpolation of GP. Furthermore, let the \u03c4\u03bf and sp represent the standard deviations of SB and SW SPes, respectively. The total aleatory variance of non-ergodic GMMs is formulated as,\n$\\sigma_{NE}^2 = \\tau_0^2 + \\phi_{SP}^2. (12)$\nWe utilize the same earthquake scenario and 100 \u00d7 100 spatial coordinates of stations to synthesize the non-ergodic FAS maps.\nData availability\nThe earthquake dataset in SFBA was originally downloaded from NCEDC (https://ncedc. org/). The training and testing dataset in this study was preprocessed and provided from [63].\nCode availability\nAll the source codes to reproduce the results in this study are available on GitHub at https: //github.com/paulpuren/cgm-gm. We provide the training, generation, evaluation, and visualization details."}]}