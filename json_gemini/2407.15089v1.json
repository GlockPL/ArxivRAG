{"title": "Learning Physics for Unveiling Hidden Earthquake Ground Motions via Conditional Generative Modeling", "authors": ["Pu Ren", "Rie Nakata", "Maxime Lacour", "Ilan Naiman", "Nori Nakata", "Jialin Song", "Zhengfa Bi", "Osman Asif Malik", "Dmitriy Morozov", "Omri Azencot", "N. Benjamin Erichson", "Michael W. Mahoney"], "abstract": "Predicting high-fidelity ground motions for future earthquakes is crucial for seismic hazard assessment and infrastructure resilience. Conventional empirical simulations suffer from sparse sensor distribution and geographically localized earthquake locations, while physics-based methods are computationally intensive and require accurate representations of Earth structures and earthquake sources. We propose a novel artificial intelligence (AI) simulator, Conditional Generative Modeling for Ground Motion (CGM-GM), to synthesize high-frequency and spatially continuous earthquake ground motion waveforms. CGM-GM leverages earthquake magnitudes and geographic coordinates of earthquakes and sensors as inputs, learning complex wave physics and Earth heterogeneities, without explicit physics constraints. This is achieved through a probabilistic autoencoder that captures latent distributions in the time-frequency domain and variational sequential models for prior and posterior distributions. We evaluate the performance of CGM-GM using small-magnitude earthquake records from the San Francisco Bay Area, a region with high seismic risks. CGM-GM demonstrates a strong potential for outperforming a state-of-the-art non-ergodic empirical ground motion model and shows great promise in seismology and beyond.", "sections": [{"title": "INTRODUCTION", "content": "The accurate prediction of ground motion waveforms and their characteristics for future earthquakes is crucial for assessing seismic hazards and ensuring the safety and resilience of critical infrastructure. However, it is challenging and resource-intensive to obtain comprehensive ground motion observation across a wide geographic area. Furthermore, predictions of earthquake rupture processes and estimates of the Earth's elastic model remain to exhibit significant uncertainties. The development of precise and robust ground motion prediction methodologies has long been of great interest in seismology and earthquake engineering to complement the limited recorded data.\nExisting ground motion simulation studies branch into two streams: stochastic and physics-based approaches. The first stream, stochastic methods, is rooted in the modulation of Gaussian white noise to reproduce the desired ground motion characteristics [1-3]. They provide a computationally efficient framework to synthesize ground motion data by calibrating stochastic process-based models to match the historical recordings. However, potential limitations exist in representing spatial continuity and physical phenomena. The second stream, physics-based methods, is based on the numerical solution of wave equations [4-8] while considering comprehensive physical characteristics, including fault ruptures [9-12], heterogeneous earth media, and site-specific effects. Although recent advancements in high-performance computing enable simulating high-frequency waveforms of large-magnitude earthquakes (e.g., up to 10 Hz) [13], physics-based methods are computationally demanding. For example, ground motion simulations of the San Francisco Area over a domain of 120 km \u00d7 90 km \u00d7 35 km require 128 NVIDIA A100 GPU nodes and take 6 hours to compute up to a frequency of 5 Hz. Simulations at higher frequencies tend to be computationally prohibitive and these data are typically complemented by stochastic simulations [14, 15]. Furthermore, physics-based simulations face challenges from significant uncertainties in wave theory, subsurface elastic models, and source characteristics.\nMore recently, machine learning (ML) and artificial intelligence (AI) have shed new light on this classic task, primarily through their capability of accelerating earthquake modeling processes. One representative line of work is the application of neural operators for modeling seismic wave propagation [16, 17]. Although these data-driven ML methods show remarkable efficiency, by avoiding the stringent time-step constraints in traditional time-domain physics-based numerical approaches, they require a large amount of high-fidelity data. Researchers have also resorted to incorporating physical constraints into ML models, such as physics-informed neural networks (PINNs) [18]. In particular, by leveraging physical principles as a prior, PINNs have been used for predicting ground motions with a limited amount of training data [19-21]. However, PINNs are known to exhibit fundamental failure modes in network optimization [22-24]. Moreover, due to their specific design of objective functions, PINNs encounter significant limitations in generalizing to different initial conditions and subsurface elastic models. PINNs can be regarded as physics-based and still suffer from uncertainties in the problem setup. In addition, the spectral bias of fully-connected neural networks used by both neural operators and PINNs typically constrains the resolution to low frequencies [20], making broadband synthesis of waveforms challenging.\nGenerative modeling has emerged as an alternative approach for scientific modeling to capture the complexities of natural phenomena, as demonstrated for fluid dynamics [25, 26] and molecular science [27, 28]. It is an inherently stochastic method that incorporates random noise as inputs and utilizes probabilistic processes to generate diverse and realistic data. In the context of earthquake ground motions, generative modeling can produce various waveforms while capturing model uncertainties. This capability is critical due to the significant variability and unpredictability of real-world earthquake ground motions, influenced by factors such as seismic sources, propagation paths, and site conditions. Generative models, which are not governed by specific wave equations or subsurface models, need to learn meaningful wave physics (i.e., governing equations) and site/source conditions from sparse and irregular sensor and earthquake distributions. Generative Adversarial Networks (GANs) and their variants [29-32] have been shown to simulate ground motions with respect to distances, magnitudes, and near-surface velocity structures (Vs30) that follow empirical"}, {"title": "RESULTS", "content": "Datasets\nThe dataset for the study of small-magnitude earthquakes in 1990-2022 in the San Francisco region is downloaded from the Northern California Earthquake Data Center (NCEDC) database. The stations of interest are chosen within a 50 km radius from the Hayward fault, and the events with magnitude M < 4 recorded within a hypocentral distance Rhyp < 100 km from the selected stations are included. We focus on two horizontal components H1 and H2 of particle velocity considering their direct importance for earthquake hazard analysis. The H1 and H2 components"}, {"title": "Conditional generative model", "content": "We present our CGM-GM framework based on a conditional dynamic VAE framework, as shown in Figure 1(a-d) for generating realistic ground-motion time-series data. The objective is to develop a generative model for predicting ground motions D* at unobserved sources and site locations, with varying earthquake magnitudes, based on actual sparse seismic recordings D. Firstly, in our model, we use Short-Term Fourier Transform (STFT) [35, 36] to decompose the time sequence data X1:7 into amplitude and phase information in each time window, where T is the length of the ground motion time series. STFT is an effective technique to extract the time and frequency information, which is also considered in the previous implementation of the GAN model for ground motion generation [30]. Our dynamic VAE model is trained on amplitude information A1:7, which is in the time-frequency domain with a new time samplet used in STFT (\u03c4 \u2264 T). The key methodological contribution lies in the specific design of the prior and posterior distributions in VAE models, where we incorporate temporal dynamics using recurrent neural networks (RNNs) for learning time-frequency information [34, 37]. Next, we employ two strategies to obtain phase information and apply inverse STFT for waveform reconstruction. Specifically, during training, we use the true phase to recover ground motion data and construct a waveform loss to better capture waveform shapes. In the generation stage, phase information is estimated using phase re-trieval methods. Furthermore, to generate the earthquakes in which we are interested, we integrate physical parameters (i.e., earthquake magnitudes and depths, geospatial coordinates of sensors and earthquakes) as conditional variables into the CGM-GM framework using Multilayer Perceptron (MLP) layers. These conditional parameters are fundamental for understanding earthquake ap-plications since ground motions vary spatially due to structural heterogeneity and the magnitudes reflect the energy released by rupturing. Hence, Figure 2(c) is particularly novel, as we can obtain spatial variations of ground motions at a given scenario of earthquake locations and magnitudes. Another motivation for using geospatial coordinates is to enable neural networks to implicitly learn the physical interactions, such as path, source, and site effects. The rupture distances Rhyp and incident angles Ahyp can be computed based on the coordinate information (i.e., latitude, longitude, and depth) of earthquake hypocenters and stations of interest. In this study, we have not incorporated variations in focal mechanisms due to our focus on the Hayward fault, where the majority of seismic events exhibit similar focal mechanisms. A more detailed discussion of this aspect is presented in the Discussion section."}, {"title": "Waveforms and spatial continuity", "content": "Based on earthquake magnitudes and geospatial coordinates of earthquake sources and stations, the generator part of our CGM-GM framework produces physically consistent ground motion data. Figure 1(e) shows three representative comparisons between the generated ground motion waveforms and the true recordings. The selected cases involve seismic waveforms of similar magnitudes but with varying rupture distances, epicenter-station azimuths, and earthquake depths. Furthermore, we produce two random generations (blue) with the defined conditional variables to compare them with the corresponding observed data (red) in the time domain. The generated ground motion sequences effectively capture waveform shapes, frequency contents, peak values (e.g., waveform amplitude), and the arrival time, even for events with different rupture distances, depths, and"}, {"title": "DISCUSSION", "content": "In this section, we discuss the inherent sparsity in real-world earthquake datasets and the selection of conditional variables due to their significant effects on the performance of generative modeling. Due to practical constraints, the spatial distribution of seismic stations is often sparse and non-uniform across the geospatial domain. This sparsity leads to uneven data coverage and gaps in the observation data, which poses challenges for generative models in accurately capturing the underlying spatial heterogeneity. This task is intrinsically complicated since it requires the ground motion models to infer spatial variability and site-specific effects without direct observation data. Therefore, the generative models might exhibit artifacts in producing FAS maps for areas lacking measurement data, as illustrated in Figure 2(b).\nIn our generative model, focal mechanisms are not included as conditional variables for two reasons. Firstly, our earthquake data are mostly concentrated around the Hayward and San Andreas Faults, where these earthquakes predominantly exhibit similar focal mechanisms (i.e., the right lateral faulting). Importantly, our primary interest is also in generating waveforms along the Hayward Fault with consistent focal mechanisms, which indicates no domain shift for the earthquake rupturing processes. The second reason is the data limitation. As mentioned, there is insufficient variation in the focal mechanisms of the recorded earthquakes to effectively train the network for arbitrary focal mechanisms parameters (e.g., fault strike). Typically, generative models work well when the generated data interpolates within the range of the training data, as we have demonstrated for source and receiver locations. Incorporating focal mechanisms as a variable would only yield reliable generations within very limited focal mechanisms.\nA potential limitation lies in the lack of the constraints of path effects. The current generative modeling framework only incorporates spatial information as conditional variables without considering the correlation between different pairs of stations and sources. The implicit learning of paths can be achievable since the training waveform data naturally contains the path effect. When numerous waveforms are available for training, the generative model should be able to learn the path effects. However, in reality, the data is often limited and we may need an explicit way to include the path effects. To address this issue, we would like to investigate the incorporation of the spatial correlation, such as Mat\u00e9rn covariance function [42, 43], into generative modeling. In addition, using phase retrieval methods for waveform reconstruction may lead to inaccurate phase information in the generated samples due to the intrinsic difficulty in such ill-posed inverse problems. Hence, we will consider building a generative model directly in the time domain instead of the time-frequency domain to avoid using phase retrieval methods. Another direction is exploring specific techniques, such as generalized variance parameterization [44] and heavy-tailed distributions [45], to mitigate the over-smoothing issue in VAE models."}, {"title": "CONCLUSIONS", "content": "Our proposed generative modeling framework is user-friendly and stable to train. It presents effectiveness and efficiency in producing synthetic ground motions for various earthquake scenarios with different magnitudes and geographical regions in the SFBA. The most exciting part is that our CGM-GM can capture the underlying spatial heterogeneity and physical characteristics, as evidenced by the generation of realistic FAS maps. We conduct a comparative assessment of our CGM-GM against baseline models, including the CGM-baseline and a state-of-the-art non-ergodic GMM. The results demonstrate that our method performs comparably to, and in some aspects slightly surpasses, the most advanced non-ergodic GMM. This validates that incorporating geospatial coordinates as conditional variables effectively enables our model to learn spatial heterogeneities. Moreover, we comprehensively evaluate the performance of the model on generative modeling for ground motion synthesis in both time and frequency domains. For the assessment in the time domain, the ground motion samples generated by CGM-GM show excellent capability of capturing waveform shapes, PGVs, and arrival time. For the evaluation in the frequency domain, the FAS values exhibit great agreement between the observed and generated data. Overall, we anticipate that the promising results of scientific generative AI modeling for ground motion synthesis will encourage researchers to explore this area, and the potential issues we have identified will enable the development of more effective methods for enhancing generation quality."}, {"title": "METHODS", "content": "In this section, we present the technical details of our generative model in the context of ground motion simulation. The entire framework is shown in Figure 1(a-d), including the forward and inverse STFT, the network design of dynamic VAE, the sequential model prior, and the embedding"}, {"title": "Forward and inverse STFT", "content": "STFT has been widely applied in audio processing [46, 47] and seismic data analysis [48-50]. It defines a valuable category of time-frequency distributions [51] that describe the amplitude and phase relationships with respect to time and frequency for any signal. This is achieved by repeatedly applying the Fourier transform within specific time windows. Typically, we use sliding time windows with overlaps to capture signals throughout the entire time domain. Therefore, leveraging STFT in generative modeling [52, 53] facilitates the extraction of time and frequency information A from the ground motion sample x. Although the time-frequency resolution of STFT is fixed in the entire time and frequency domains with the chosen time window length, the inverse STFT is relatively stable compared to other 2D spectral decomposition methods such as continuous wavelet transform.\nThe inverse STFT is employed to reconstruct waveforms from amplitude spectrograms A. During the generation of artificial ground motions, phase retrieval methods are used to estimate the phase information. To be more concrete, these approaches estimate the missing phase information from available amplitude measurements and then recover the timing and shape of seismic waveforms in earthquake ground motion analysis. Various mathematical techniques are leveraged for phase retrievals, such as iterative algorithms and optimization frameworks. For instance, the Griffin-Lim algorithm [54] is widely used thanks to its simplicity and effectiveness. It iteratively refines estimates of seismic wave phases to minimize the discrepancy between the original and reconstructed signals. On the other hand, the Alternating Direction Method of Multipliers (ADMM) [55] is a versatile optimization technique that has gained traction in various scientific domains, including ground motion synthesis [30]. ADMM leverages a convex relaxation framework to decompose complex optimization problems into simpler subproblems and solve the augmented Lagrangian function iteratively. In this paper, we leverage the dynamic VAE model to learn amplitude information and employ the Griffin-Lim algorithm for phase retrieval due to its simplicity. This strategy is chosen over generating phase information with the VAE model, as phase signals are complex and amplitude evolution is relatively smooth over time."}, {"title": "Dynamic VAES", "content": "We consider a dynamic VAE architecture since it is specifically designed to model sequential data with temporal correlations by extending from standard VAEs [34, 37, 56]. Although VAE models have achieved great success in image processing tasks, the absence of explicit temporal modeling in standard VAEs hinders their effectiveness in tackling time series and audio data [57]. The dynamic VAE models focus on a sequence-to-sequence mode for encoding and decoding. Namely, the latent variable is constructed in the form of a temporal sequence instead of a \"static\" vector. Let us consider a time sequence x1:T = {xt \u2208 RN}{=1, where T is the sequence length. Dynamic VAE models typically yield a sequence of latent variables Z1:T = {Zt \u2208 R\u00b9}f=1. Therefore, the joint distribution of latent and observed sequences can be reformulated as\n\u0420\u03b8(X1:T, Z1:T) = [[Po(XtX1:t-1, Z1:t)Po (ZtX1:t-1, 21:t-1).      (1)\nt=1\nEq.(1) is a generalized version that describes the generative process in dynamic VAEs. Researchers usually resort to state-space models (SSMs) to simplify the dependencies in conditional distributions of Eq.(1) [57]. One of the most commonly used SSM families is RNNs, which are specifically"}, {"title": null, "content": "designed network architectures for handling sequential data and capturing temporal dependencies among data points. However, a significant challenge in training vanilla RNNs is the vanishing and exploding gradient problem. The reason behind this phenomenon is that the gradients can either shrink exponentially (vanishing gradients) or grow exponentially (exploding gradients) when RNNs propagate information through time. This instability hinders effective training and prevents the network from learning long-term dependencies. To alleviate such issues, gating-based RNNs, such as LSTM [58] and GRU [59], are proposed to control the flow of information through the network. By incorporating the auto-regressive recurrence into dynamic VAE models, the generative pro-cess can be simplified as\n\u0420\u03b8 (\u04251:\u0422, 21:T) = \u041f\u0440o(XtZt)Po (ZtZ1:t-1).   (2)\nt=1\nMoreover, the approximate posterior can be reformulated as\nT\n9$(Z1:TX1:T) = [[9$(ZtZ1:t-1, X1:t),  (3)\nt=1\nwhere q(Z1:TX1:T) works as an inference model for the latent sequence Z1:7 from the observed sequential data.\nThe training of a dynamic VAE model involves optimizing the evidence lower bound (ELBO) on the marginal likelihood of the observed data X1:7. For a given data sample x1:T, the marginal likelihood is defined as\nlogp\u03b8(x1:T) = DKL(q\u00a2(Z1:T|X1:T)||po(Z1:T))||po(z)) + L(0, \u0444; x1:T)\n\u2265 L(0, \u0444; x1:T),  (4)\nwhere DKL(\u00b7) denotes the Kullback-Leibler (KL) divergence between the approximate and true posterior distributions. DKL(\u00b7) is a non-negative term. Therefore, L(0, \u0444; x1:T) represents the ELBO, which is given by [68]\nL(0, \u03a6; X1:T) =Eq4(Z1:T|X1:T) [logpo (X1:T|Z1:T)]\n\u2013\nDKL(94(Z1:T|X1:T)||P0(Z1:T)).    (5)\nThe first and second terms on the right-hand side (RHS) are reconstruction loss and a KL-divergence term, respectively. The KL-divergence works as a regularizer for that promotes the approximate posterior q(Z1:T|X1:T) to closely resemble the prior p\u03b8(Z1:T). Note that the KL-divergence term in (17) is analytically tractable but the reconstruction error term requires estimation via Monte Carlo sampling. Thus, the expectation w.r.t. q(Z1:T) can be estimated by\nR\n1\nEqp(z|x) [logpe(x|z)] \u2248\nlogpe(x/z()), (18)\nr=1\nwhere R samples z(r) are independently and identically drawn from q4(z|x). Given a dataset\nX = {x}1, where X consists of M independent and identically distributed (i.i.d.) samples, the resulting estimator of ELBO is written as,\nM\nL(\u03b8, \u03c6; X) = \u2211logpo(xi|zi)\ni=1\nM\nDKL(q$(Zi|xi)||po(Zi)).  (19)\ni=1\nTo optimize (19), stochastic gradient descent (SGD) methods, such as Adam [73], are typically considered. The ELBO L(0, $; X) is optimized w.r.t. both the generative parameters and the variational parameters $. Note that L(0, $; X) is differentiable w.r.t e but it is problematic to obtain the derivatives w.r.t. \u03c6. \u03a4\u03bf solve this issue, the reparameterization trick is proposed [68] to conduct a differentiable transform, where zi can be reparameterized as\n\u0396\u03b9 ~ \u039d(\u03bc\u03c6(\u03a7\u03af), \u03c3(xi)),\n(20)\nwhere \u03c3\u03c6(xi) comprises the diagonal elements in a diagonal covariance matrix."}, {"title": "Embedding conditional variables", "content": "We design an embedding module, consisting of a stack of MLP layers, to integrate the conditional variables into the framework. The illustration of embedding conditional variables is presented in Figure 1(d). To fully encode physical knowledge into the generative process, we apply this share-able embedding module to the encoder, the decoder, and the model prior. For the embedded of physical variables, we use earthquake magnitudes and the geospatial coordinates of earthquake sources and stations. The primary rationale for incorporating geospatial coordinates is that many physical properties, such as source and site effects, are inherently coordinate-based and crucial for ground motion simulation. Neural networks can implicitly learn representations of the underlying physics and kinematics with the coordinates as inputs [18, 61]. Note that, in previous papers [29, 30], the researchers also use the information Vs30. Given that Vs30 is an empirical parameter based on geological coordinates, the embedding network should be capable of implic-itly capturing these velocity properties with coordinate information as inputs. Vs30 is a proxy correlated with site-specific ground-motion properties, and it is often used in the development of ground-motion models. However, estimations of Vs30 are not always available at all sites and can present significant uncertainties. Thus, we choose not to integrate Vs30 into our model as a param-eter and instead estimate local site conditions directly from ground motion data with conditional generative modeling."}, {"title": "Data selection", "content": "A total of 626,423 recordings are collected that spans from 10 seconds prior to the event time to 60 seconds after the event time, leading to each recording of 70 seconds with 7,000 time steps per component. We perform a selection procedure to ensure only recordings with an acceptable S/N ratio are used. Specifically, the first 10 seconds of each recording are considered as noise, while the subsequent 60 seconds are analyzed as earthquake signals. The Fourier transforms of both the noise"}, {"title": "Empirical GMMs", "content": "Empirical ergodic and non-ergodic GMMs for velocity FAS values are developed to evaluate the ground motions generated by our CGM-GM. Specifically, ergodic GMMs focus on the average scaling of ground motions, and non-ergodic GMMs account for the spatial distribution of ground motions due to path effects related to the 3-D velocity structure. For the ergodic GMM, the functional formulation of the natural log of FAS values, i.e., ln(Y), is given by\nln(Y; M, Rhyp, Dhyp) = 20 + A1M + a2ln(Rhyp) + a3Dhyp + dBe + dS2S\u2083 +\nRRuP SP + 8W Ses,   (9)\n100\ne\nwhere a\u2081M, a2ln(Rhyp), a3Dhyp denote magnitude scaling, geometrical spreading, and depth scal-ing terms, respectively. dBe, dS2Ss, dPe represent the source, site, and path effects with zero-mean normal distributions. W Ses is the with-site residual, which is also assumed to be normally dis-tributed. The coefficients are derived through linear regression, ensuring a smooth spectrum and imposing physical constraints on the coefficients [66]. Moreover, the total standard deviation of ergodic GMMs is defined as,\nOfas =\n\u221a\nT2 + $525 + $55,   (10)\nwhere T, $S25, Oss denote the standard deviation of the mixed-effects coefficients dBe, SS2Ss, 8W Ses, respectively. The parameters of the ergodic GMM in the SFBA at different frequency bands (2, 5, 10, and 15 Hz) are detailed in Table 1."}, {"title": null, "content": "For the non-ergodic GMMs, the source, site, and path terms are considered spatially dependent, which are the functions of the coordinates of sources and sites. Therefore, the non-ergodic GMM is re-written as [67],\nIn(Y; M, Rhyp, Dhyp, ..., tees, tss) =LA24Adj-erg(M, Rhyp, Dhyp) + SL2L(tees) + S2S(ts)\n+8P2P(tees, tss) + dB + 8WSPes   (11)\ne\nwhere LA24 is the median from the ergodic model as shown in Eq. 9, 8L2L(tees), 8S2S, 8P2P are the median shifts of the source, site, and path terms. tees and tss represent the earthquake and site locations. Additionally, the term SB\u00b0 + SWSPes denotes the aleatory variability apart from the systematic source, site, and path effects. The Gaussian Process (GP) regression is leveraged to fit the available ground motion data within the SFBA dataset by providing the medians and epistemic uncertainty [40]. The non-ergodic GMMs simulate FAS maps thanks to the capability of spatial interpolation of GP. Furthermore, let the \u03c4\u03bf and sp represent the standard deviations of SB and SW SPes, respectively. The total aleatory variance of non-ergodic GMMs is formulated as,\n\u03c3\u039d\u0395 = \u03a4\u039f + \u03a6P.     (12)\nWe utilize the same earthquake scenario and 100 \u00d7 100 spatial coordinates of stations to synthesize the non-ergodic FAS maps."}, {"title": "Data availability", "content": "The earthquake dataset in SFBA was originally downloaded from NCEDC (https://ncedc.org/). The training and testing dataset in this study was preprocessed and provided from [63]."}, {"title": "Code availability", "content": "All the source codes to reproduce the results in this study are available on GitHub at https://github.com/paulpuren/cgm-gm. We provide the training, generation, evaluation, and visualization details."}, {"title": "Supplementary Material", "content": "This supplementary document provides a detailed description of background knowledge of Variational Autoencoder (VAE) models and supplementary results of our generative models."}, {"title": "A Background", "content": "This section introduces the technical details of VAE models and their corresponding optimiza-tion strategy. VAE [68, 69] has emerged as a powerful framework that bridges probabilistic modeling and deep learning architectures. It has been widely used in image and audio processing to repre-sent complex and high-dimensional data through a learned low-dimensional latent space [70]. As a preliminary step, we first introduce the autoencoder (AE) [71] to provide a clear understanding of its underlying schemes. The general idea is to train a deep neural network to reconstruct the input variable x \u2208 RN with an output variable\u0177 \u2208 RN, where we aim to have x \u2248 \u3121. An AE architecture, typically shown as a diabolo shape, consists of an encoder and a decoder. Specifically, the encoder module learns a low-dimensional latent representation z\u2208 R\u00b9 (l < N) of the input data x. The decoder part aims to reconstruct a high-dimensional output from the low-dimensional feature z.\nFurthermore, VAE is an AE model in a probabilistic formulation. The characteristic of VAE lies in that the output from the decoder is a probability distribution of input data x instead of a deterministic output variable. The encoding of the latent variable z follows the same probabilistic process, where z is then a continuous random variable. To be more concrete, the generative process can be defined as\npo(x) =\nZ\npo (x, z)dz\n=\nZ\npe(x|z)pe(z)dz, (13)\nwhere denotes the distribution parameters that are composed of the network weights of the decoder. po(z) represents the model prior over the latent variable z, which is commonly built as an isotropic Gaussian distribution N(z; 01, I\u2081) [68]. O\u03b9 and I\u012f are a zero-vector (size l) and an identity matrix (with size 1), respectively. Moreover, the likelihood distribution pe(x|z) serves as a probabilistic decoder that generates the observed data x based on the latent variable z. Generally, let us consider p\u0473(x|z) as a multivariate Gaussian distribution,\npo(x|z) = \u039d[x; \u03bc\u03bf(z), \u03c3\u03bf(z)],\n(14)\nwhere the mean \u03bc\u03bf(z) \u2208 RN and the standard deviation \u03c3\u0473(z) \u2208 RN are the outputs of the decoding network. Note that the vector \u03c3\u03b8(z) comprises the diagonal coefficients of a diagonal covariance matrix. A diagonal covariance matrix is preferable for computational efficiency [57, 72] due to the quadratic expansion of covariance parameters with respect to (w.r.t.) the variable dimension.\nFurthermore, since the space of z in Eq. (13) is large, an approximate posterior q\u3085(z|x) is used to reduce the computational effort. q(z|x) works as a probabilistic encoder that is parameterized by . It is formulated as\nq\u00a2(z|x) = \u039d[z; \u03bc\u03c6(x), \u03c3(x)].\n(15)\nHere \u03bc\u2084(x) \u2208 R\u00b9 and \u03c3\u03c6(x) \u2208 R\u00b9 are the outputs of the encoder w.r.t. the data x. Similarly, \u03c3\u03c6(x) consists of the diagonal elements in a diagonal covariance matrix."}, {"title": null, "content": "The training of a VAE involves optimizing the evidence lower bound (ELBO) on the marginal likelihood of the observed data x. For a given data sample x, the marginal likelihood is defined as\nlogp\u0473(x) = DKL(q\u00a2(Z|X)||po(z|x)) + L(0, \u03c6; x)\n\u2265 L(\u03b8, \u03c6; x),\n(16)\nwhere DKL(\u00b7) denotes the Kullback-Leibler (KL) divergence between the approximate and true posterior distributions. DKL(\u00b7) is a non-negative term. Therefore, L(\u03b8, \u03c6; x) represents the ELBO, which is given by [68]\nL(0, $; x) = Eq\u2084(z|x) [logpo (x|z)] - DKL(q$(z|x)||po(z)).\n(17)\nThe first and second terms on the right-hand side (RHS) are reconstruction loss and a KL-divergence term, respectively. The KL-divergence works as a regularizer for that promotes the approximate posterior q\u2084(z|x) to closely resemble the prior pe(z). Note that the KL-divergence term in (17) is analytically tractable but the reconstruction error term requires estimation via Monte Carlo sampling. Thus, the expectation w.r.t. q(z|x) can be estimated by\nR\n1\nEqp(z|x) [logpe(x|z)] \u2248\nlogpe(x/z()), (18)\nr=1\nwhere R samples z(r) are independently and identically drawn from q4(z|x). Given a dataset\nX = {x}1, where X consists of M independent and identically distributed (i.i.d.) samples, the resulting estimator of ELBO is written as,\nM\nL(\u03b8, \u03c6; X) = \u2211logpo(xi|zi)\ni=1\nM\nDKL(q$(Zi|xi)||po(Zi)). (19)\ni=1\nTo optimize (19), stochastic gradient descent (SGD) methods, such as Adam [73], are typically considered. The ELBO L(0, $; X) is optimized w.r.t. both the generative parameters and the variational parameters $. Note that L(0, $; X) is differentiable w.r.t e but it is problematic to obtain the derivatives w.r.t. \u03c6. \u03a4\u03bf solve this issue, the reparameterization trick is proposed [68] to conduct a differentiable transform, where zi can be reparameterized as\n\u0396\u03b9 ~ \u039d(\u03bc\u03c6(\u03a7\u03af), \u03c3(xi)), (20)\nwhere \u03c3\u03c6(xi) comprises the diagonal elements in a diagonal covariance matrix."}, {"title": "B Supplementary results", "content": "In this section, we present supplementary generated samples to evaluate the performance of our CGM-GM framework in terms of waveform shapes, uncertainty quantification, and FAS evaluations. For a comprehensive analysis, we provide generative results for both the H1 and H2 components. Additionally, we set up two scenarios to test the realization of FAS maps in consideration of site and source effects."}]}