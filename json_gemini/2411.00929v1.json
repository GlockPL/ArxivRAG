{"title": "Text2Freq: Learning Series Patterns from Text via Frequency Domain", "authors": ["Ming-Chih Lo", "Ching Chang", "Wen-Chih Peng"], "abstract": "Traditional time series forecasting models mainly rely on historical numeric values\nto predict future outcomes. While these models have shown promising results, they\noften overlook the rich information available in other modalities, such as textual de-\nscriptions of special events, which can provide crucial insights into future dynamics.\nHowever, research that jointly incorporates text in time series forecasting remains\nrelatively underexplored compared to other cross-modality work. Additionally, the\nmodality gap between time series data and textual information poses a challenge for\nmultimodal learning. To address this task, we propose Text2Freq, a cross-modality\nmodel that integrates text and time series data via the frequency domain. Specifi-\ncally, our approach aligns textual information to the low-frequency components of\ntime series data, establishing more effective and interpretable alignments between\nthese two modalities. Our experiments on paired datasets of real-world stock prices\nand synthetic texts show that Text2Freq achieves state-of-the-art performance, with\nits adaptable architecture encouraging future research in this field.", "sections": [{"title": "1 Introduction", "content": "The importance of incorporating textual information into time series forecasting is increasingly\nevident. Real-world time series data is often influenced by external factors, such as news events,\nconsumer feedback, and special occasions, which traditional models fail to account for [1].\nSeveral approaches have been proposed in response to the growing need for multimodal learning in\ntime series forecasting. However, these methods face three significant challenges. First, the scarcity\nof paired datasets that combine time series and text makes the learning process difficult. Second,\ntechniques from other cross-modality tasks, such as cross-attention, are hard to directly apply due\nto the significant modality gap between time series and text. This gap is due to differences such as\ntext being discrete and rich in semantic content, while time series are continuous, focus on temporal\nchanges, and often contain noise. Finally, text often encapsulates high-level patterns, such as overall\ntrends, leading to a one-to-many problem when directly mapping text to time series (see Figure 1).\nTo overcome these challenges, we propose Text2Freq, a framework that align textual information to\ntime series data through the frequency domain. Our approach includes a pre-trained text-to-frequency\nmodule, trained on a boarder dataset to address the issue of limited paired data. Additionally, by\naligning text with the low-frequency components of time series, Text2Freq effectively bridges the\nmodality gap and extracts clear patterns from text, enhancing interpretability.\nWe validate Text2Freq using real-world stock price data paired with synthetic text generated by\nGPT-4 [2]. To the best of our knowledge, Text2Freq is the first method to align textual information\nwith low-frequency series components, leading to improved performance in mulitimodal forecasting\nwith more effective alignment."}, {"title": "2 Problem Formulation and Methodology", "content": null}, {"title": "2.1 Multimodal Time Series Forecasting Enhanced by Textual Data", "content": "Given a multivariate time series $X_{past} \\in \\mathbb{R}^{L\\times C}$ consisting of $L$ past steps and $C$ channels, along with\ncorresponding textual information Text related to the target variable we aim to predict, our objective\nis to predict the future univariate series $X_{future} \\in \\mathbb{R}^{T}$."}, {"title": "2.2 Model Architecture", "content": "The proposed TextToFreq model consists of two stages: a text-to-frequency pre-trained model and\nthe overall fusion model."}, {"title": "2.2.1 Stage 1: The Pre-trained Text-To-Frequency Transformer", "content": "As depicted in Figure 2, we employ a pre-trained BERT [3] to extract text features. These embeddings\nare then mapped to the latent space of low-frequency components in a time series using a Transformer\nEncoder architecture [4]. The mapped embeddings are then decoded back into the time series domain\nfor multimodal fusion in the next stage. Specifically, we apply the Discrete Fourier Transform\n(DFT) to convert the time series into the frequency domain and extract the leading low-frequency\ncomponents, excluding the DC component due to series normalization. To enhance the latent space\nrepresentation in the frequency domain, we utilize a Variational Autoencoder (VAE) [5] architecture,\nas inspired by [6]."}, {"title": "2.2.2 Stage 2: The Multimodal Fusion", "content": "In this stage, we freeze the pre-trained Transformer Encoder from Stage 1 and focus on training the\nremaining components of our model: the unimodal time series forecasting model and the fusion\nlayer. Our objective is to effectively integrate information from both the text and the time series\npredictions into a unified representation, i.e., the time series. Specifically, we employ patching and\nchannel-independence [7] architecture for the unimodal forecasting model. The fusion layer then\nconcatenates the output series from text-to-frequency pre-trained model with the output from the time\nseries forecasting model. This combined information is subsequently processed through an attention\nmechanism to generate the final prediction."}, {"title": "3 Experiment: Stock Price Prediction", "content": null}, {"title": "3.1 Dataset", "content": "For our experiment, we utilized a weekly stock price dataset featuring Apple (AAPL), Microsoft\n(MSFT), and Google (GOOG) stocks from December 1, 2006, to November 30, 2016. To address\nthe challenge of obtaining insightful textual information for each stock, we used GPT-4 to generate\naccurate descriptions of future patterns by providing it with the actual future series for each instance.\nFor our pre-trained model that aim to solve the limited dataset problem, we used the TRUCE dataset\n[8], which contains a more extensive range of paired time-series and text data. This dataset includes\nweekly stock prices from seven companies, totaling 1900 instances, each with a sequence length\nof 12. To enhance the model's capacity, we use the same way to augment the paired text data with\ndescriptions generated by GPT-4."}, {"title": "3.2 Experiment Setup", "content": "We evaluate Text2Freq against two baseline approaches: unimodal time series forecasting models that\nuse only time series data, and multimodal models that integrate both time series and text data. For\nunimodal forecasting, we use PatchTST [7], a representative model in time series forecasting, as our\nbaseline. For multimodal forecasting, we employ a attention-based methodology similar to [1], where\nseries data is processed through a unimodal forecasting model and text data through a Transformer\nEncoder, with outputs combined using an attention mechanism. All models are configured with a\nlook-back window of 36 and a prediction length of 12.\nFurthermore, we compared the alignment by mapping the text sequence directly to the original time\nseries with mapping it to the frequency domain, to evaluate whether the frequency domain provides a\nmore effective learning framework.\nAdditionally, to validate the alignment phenomenon discussed in Introduction 1 and Figure 1, we\nexamined how varying amounts of low-frequency information extracted from the original series affect\nthe alignment between text embeddings and time-series embeddings in the latent space."}, {"title": "3.3 Key Observations", "content": null}, {"title": "3.3.1 Modeling with Text Improves Forecasting Performance", "content": "Incorporating text into forecasting models significantly enhances performance. Our Text2Freq and the\nattention-based multimodal model reduce mean squared error (MSE) by 26% and 14%, respectively,\ncompared to the unimodal time series model PatchTST. By integrating text, these models more\neffectively consider implicit future patterns, addressing the limitations of unimodal models."}, {"title": "3.3.2 Aligning Text to Low-Frequency Components of a Series is Beneficial", "content": "Our method, Text2Freq, shows a 14% improvement in MSE compared to an attention-based multi-\nmodal model. This underscores our assertion that directly learning from both time series and text\ncan lead to a one-to-many problem, where text may align with noisy information that should be\ndisregarded.\nAdditionally, by analyzing the effect of various low-frequency components from the original series on\nalignment (see Table 2) using the TRUCE dataset, we observe that including all frequency components\nduring mapping can cause one-to-many mapping issues, as previously noted. In contrast, using only\nthe lowest frequency components can lead to a many-to-one problem, where multiple pieces of textual\ninformation map to similar wave patterns. Both scenarios present challenges for convergence and can\nresult in either missing or noisy information. Therefore, by carefully selecting the optimal amount of\nlow-frequency components, we can better capture the global trend patterns of a series, improving\nmodel convergence and addressing alignment issues."}, {"title": "3.3.3 Learning in Frequency Domain Yields Better Alignment", "content": "Learning series patterns from the frequency domain offers advantages like a global view and energy\ncompaction [9]. This approach enhances the extraction of high-level patterns and key components\nfrom a series. As shown in Table 2, mapping via the frequency domain (with all frequency compo-\nnents) surpasses direct text-to-series mapping by over 6% in MSE, demonstrating that the frequency\ndomain serves as a more effective medium for bridging the modality gap between text and time series."}, {"title": "4 Conclusion and Future Works", "content": "In this work, we introduce Text2Freq, a novel approach that integrates textual information with time\nseries through a frequency-domain learning process. Our evaluation using a real-world stock price\ndataset demonstrates that mapping text to the low-frequency components of the series and combining\nthis with series predictions significantly enhances time series forecasting. Furthermore, we believe\nthat integrating our pre-trained framework with various advanced models from the fields of time\nseries forecasting and natural language processing, such as foundation models, could further improve\nthe performance and interpretability of multimodal learning. Future work will focus on effectively\ncombining models across different modalities to optimize overall performance in diverse scenarios."}, {"title": "A Related Works", "content": null}, {"title": "Cross-modality Learning in Time Series", "content": "Recent advances in multimodal studies have explored inte-\ngrating text with various data types, such as images [10] and audio [11]. However, the intersection of text\nand time series remains relatively underexplored, This is largely due to the scarcity of paired datasets and the\nfundamental differences between time series data and textual information. Current approaches mainly transform\nor reprogram time series into a text modality [12], [13], [14] to leverage large language models for forecasting\nor other downstream tasks. Despite these efforts, significant advancements in transforming text into time-series\nremains limited."}, {"title": "Integrating Text with Time Series Forecasting", "content": "Research on text-guided time series forecasting is still\nemerging, with a few notable contributions. TEMPO [15] integrates textual information by decomposing series\nand using a transformer architecture. TGForecaster [1] employs PatchTST [7] as a backbone model with a\ncross-attention mechanism to incorporate text into forecasting. Text2TimeSeries [16] integrates real-world events\ninto time series predictions, refining stock price forecasts by mapping event-induced changes to directional price\nmovements. While these approaches improve performance over unimodal models that only take time series\nas inputs, they do not fully address the modality gap or the text-series mapping relationship. In this work, we\nbridge the divergence between time series and text by proposing a framework that integrates textual information\ninto time series forecasting in a more interpretable and effective manner."}, {"title": "B Data Generation: Synthetic Textual Information Generated by GPT-4", "content": "As discussed in the previous section, there is a shortage of insightful and sufficiently paired text and time series\ndata. To address this, we utilize GPT-4 to generate ground-truth pattern descriptions for each target future series.\nThe structure of the prompts used for generation is as follows:"}, {"title": "C Detail Explanation of Model Architecture", "content": "As outlined in the main section, the proposed Text2Freq model comprises two stages: the pretraining phase and\nthe overall fusion model. Below, we provide further details on the architecture of each component."}, {"title": "Details of the Pretrained Text-to-Frequency Transformer", "content": "As shown in Figure 2, Stage 1 of the pretraining process includes two primary substeps: constructing a\nVariational Autoencoder (VAE) architecture to learn the latent space of time series data and using a Transformer\nEncoder to align text embeddings with corresponding series latent representations.\nInspired by [6], we design a VAE to capture the latent space of frequency components within time series data.\nFirst, we transform each series to its frequency spectrum using the Discrete Fourier Transform (DFT). To focus\non low-frequency information, we apply zero-padding to the higher frequencies, preserving a predefined number\nof low-frequency components. These components are then fed into the VAE, where the encoder compresses the\ninput to a latent representation, and the decoder reconstructs the frequency spectrum from this latent space.\nTo align text with series data, we adapt the approach in [2]. Text features are extracted from a pre-trained BERT\nmodel, providing robust embeddings that capture semantic nuances. These embeddings are then mapped to the\nlatent space of the leading low-frequency components of the series using a Transformer Encoder, effectively\naligning the text and series representations."}, {"title": "Details of the Overall Multimodal Fusion", "content": "Following the first stage of pretraining, we freeze the pretrained Text2Freq model and assess its effectiveness\nwithin a multimodal framework that integrates both text and time series inputs to evaluate combined performance.\nFor the time series input, we process the past series data through a unimodal forecasting model, as shown on the\nright side of Figure 2. This model is designed with channel independence and a patching structure [7] to handle\nsequential data effectively.\nFor the text input, we begin by extracting features using a pre-trained BERT model, which captures the semantic\ncharacteristics of the text. These text embeddings are then passed through the frozen Text2Freq model to generate\ncorresponding series patterns.\nOnce we obtain outputs from both modalities, we fuse them using an attention mechanism to allow effective\ninteraction between the time series and text representations, enhancing multimodal predictive performance."}, {"title": "D Limitation", "content": "We validate the effectiveness of the Text2Freq model using stock price data. Experimental results indicate that\naligning text embeddings to the frequency domain significantly outperforms existing methods. However, we\nacknowledge a limitation in the dataset, as it contains information leakage: the text input used in stage 2 is based\non the ground truth description of future patterns, due to limited available data. To address this, future work will\nfocus on evaluating our model with real-world textual data sources, such as news articles or event descriptions,\nto ensure robust validation.\nIn this paper, we also highlight the inherent challenges of aligning time series data with textual information.\nThis alignment task presents opportunities for further research on multimodal fusion in time series forecasting,\nadvancing the integration of diverse data types for improved forecasting accuracy."}]}