{"title": "Steganography Beyond Space-Time With Chain of Multimodal AI Agents", "authors": ["Ching-Chun Chang", "Isao Echizen"], "abstract": "Steganography is the art and science of covert writing, with a broad range of applications interwoven within the realm of cybersecurity. As artificial intelligence continues to evolve, its ability to synthesise realistic content emerges as a threat in the hands of cybercriminals who seek to manipulate and misrepresent the truth. Such synthetic content introduces a non-trivial risk of overwriting the subtle changes made for the purpose of steganography. When the signals in both the spatial and temporal domains are vulnerable to unforeseen overwriting, it calls for reflection on what can remain invariant after all. This study proposes a paradigm in steganography for audiovisual media, where messages are concealed beyond both spatial and temporal domains. A chain of multimodal agents is developed to deconstruct audiovisual content into a cover text, embed a message within the linguistic domain, and then reconstruct the audiovisual content through synchronising both aural and visual modalities with the resultant stego text. The message is encoded by biasing the word sampling process of a language generation model and decoded by analysing the probability distribution of word choices. The accuracy of message transmission is evaluated under both zero-bit and multi-bit capacity settings. Fidelity is assessed through both biometric and semantic similarities, capturing the identities of the recorded face and voice, as well as the core ideas conveyed through the media. Secrecy is examined through statistical comparisons between cover and stego texts. Robustness is tested across various scenarios, including audiovisual compression, face-swapping, voice-cloning and their combinations.", "sections": [{"title": "I. INTRODUCTION", "content": "Steganography is the study of covert writing, which has evolved from rudimentary arts, such as the use of invisible ink, into a sophisticated scientific discipline, interwoven within the field of cybersecurity [1]\u2013[3]. The applications of steganography are vast and varied, encompassing secret communication [4]\u2013[9], anti-counterfeit watermarking [10]\u2013[14], provenance tracking [15]\u2013[17] and forensic analysis [18]\u2013[20], among others [21]\u2013[23]. In general, a steganographic system involves the process of embedding a message into a cover medium and then extracting the hidden message from the resulting stego medium. Steganography manifests in various forms, including visual, aural and linguistic content. In other words, information can be concealed in various aspects of digital media, such as pixel intensities in imagery [24], sound waves in audio [25], synonym words in text [26] and frequency coefficients for transformed media [27]. The distortion introduced by steganographic systems is typically constrained to remain imperceptible to human senses. The fundamental objective of steganography is to keep the hidden information invisible and inaudible to all except the authorised parties who possess the key.\nAs the art and science of steganography continue to evolve, so too does the adversarial technology that seeks to manipulate digital media without authorisation. This evolution is particularly evident in the rise of artificial intelligence (AI), which has introduced transformative possibilities in revolutionising how we approach creativity, problem-solving and decision-making across various domains [28]\u2013[34]. At the same time, however, Al has also unlocked potential threats in cyber-crime, exploiting vulnerabilities on an unprecedented scale [35]\u2013 [39]. Generative AI, for instance, capable of synthesising realistic audio and video streams, has become a threat in the hands of those seeking to manipulate and misrepresent the truth [40]\u2013[46]. This type of synthetic content, often referred to as deepfakes, is highly convincing yet fraudulent, and can be exploited to deceive viewers and listeners, contributing to the spread of misinformation and the erosion of public trust [47]\u2013[54]. As this technology continues to advance, the potential for its misuse grows, raising concerns about the future of the cyber-world and highlighting the pressing need for countermeasures against these threats [55]\u2013[60].\nConsider a human-centric audiovisual content in which an individual's speech was recorded both aurally and visually. Suppose that the message is hidden within the pixel intensities or sound waves, serving an arbitrary purpose. Although steganographic systems can be designed to withstand distortion caused by common signal processing operations such as compression, there remains a risk of unforeseen manipulations that go beyond the robustness premise. Generative AI technologies, such as face-swapping and voice-cloning, can potentially wipe out the hidden message, as the synthetic content has a non-trivial chance of overwriting the subtle changes made for the purpose of steganography.\nIf the signals in both spatial and temporal domains are at risk of unforeseen manipulations, it prompts a reconsideration of what remains invariant after all. In quest for an invariant domain, this study proposes a paradigm in steganography where messages are concealed beyond spatial and temporal domains. Motivated by multi-agent collaboration [61], we"}, {"title": "II. PRELIMINARIES", "content": "A steganographic system can be characterised by several defining properties, including capacity, fidelity, secrecy and robustness. The relative significance of each property depends on the specific application for which the system is intended. We begin by discussing the primary properties typically associated with steganographic systems, and then briefly summarise the scope of this study in relation to each of these properties."}, {"title": "A. Capacity", "content": "Capacity refers to the number of bits that a steganographic system can embed within a given medium. In general, a message can be mapped into a sequence of symbols drawn from an alphabet S, where each symbol can be represented by $log_2 ||S||$ bits. A zero-bit system determines whether or not a specific symbol is present within a medium. The evaluation of zero-bit systems often involves assessing the false alarm rate, which represents the probability that a symbol will be detected in a medium when, in fact, no symbol is actually present. In contrast, a multi-bit system encodes multiple bits of information within a medium, allowing for more practical applications. The evaluation of multiple-bit systems concerns the frequency with which symbols are incorrectly decoded. This study develops both zero-bit and multi-bit steganographic systems for multimodal media."}, {"title": "B. Fidelity", "content": "Fidelity refers to the degree of similarity between the cover and stego versions of the medium. A typical fidelity requirement is based on perceptual similarity, guaranteeing that any distortion caused by the steganographic system is either invisible or inaudible to human perception. The steganographic system should not compromise the integrity of the auditory or visual quality to the point of being noticeable to the listener or viewer. In a broader sense, however, the concept of fidelity can be relaxed to refer to semantic similarity, where the alterations made to the medium may be noticeable but do not change the fundamental meaning or purpose conveyed. This is often exemplified in linguistic steganography, where changes in lexicon, syntax, or even language may result in synonymous expressions or paraphrases that, while recognisable to a human observer, retain the core idea and intent of the original text. For human-centric audiovisual media, fidelity can be broadened to encompass biometric similarity, including face identity for visual content and voice identity for aural content. This study focuses on both semantic and biometric similarities in the context of multimodal steganography."}, {"title": "C. Secrecy", "content": "Secrecy refers to the inconspicuousness of a stego medium to an adversary. It is the primary concern in applications such as covert communications, where the objective is to hide the very fact that secret communication is taking place. The process of detecting stego media is known as steganalysis, in which secrecy is often modelled as statistical undetectability. The presence of statistical or contextual anomalies can be indicative, and therefore, may be used to infer the likelihood of a covert communication. At an abstract level, the statistics of the cover media can be seen as a probability distribution of all possible cover media. However, it is inherently difficult to model such a probability distribution, and therefore, simplified models of cover distribution that reflect some expected characteristics are often used in practice. This study analyses statistical deviations through both empirical and learning-based models."}, {"title": "D. Robustness", "content": "Robustness refers to the ability to reliably decode the message even in the presence of unintentional degradations or malicious operations. It is pivotal in applications such as fact-checking and cyber-forensics, as it enables the tracing of a content's origin and provides a means to verify whether the media has been fabricated or misrepresented. Central to achieving robustness is the principle of orthogonality, which ensures that the embedded message remains unaffected and detectable despite a range of potential manipulations. When the message is embedded in a domain that is either orthogonal or invariant to the potential attacks, it remains immune to their effects. For example, a visual or aural medium can be projected into the frequency domain, where the message is embedded in parts of the frequency spectrum that are less likely to be compromised by potential manipulations."}, {"title": "III. METHODOLOGY", "content": "In general, a steganographic system consists of an encoding process at the sender's side and a decoding process at the receiver's side. It is assumed that one or more keys are shared between the sender and the receiver through a secure key exchange protocol, with the number of keys depending on the capacity setting. We begin by outlining each process and then describe the key components of the proposed methodology."}, {"title": "A. Message Encoding Process", "content": "The encoding process begins with demultiplexing the cover multimedia container into cover video and cover audio. Next, the cover audio is transcribed into cover text, which is then encoded into stego text using the shared key. In the zero-bit capacity setting, only one key K is shared. In the multi-bit capacity setting, the key K to be used is selected from a set of shared keys based on the corresponding message symbol S, where the size of the message alphabet $||S||$ matches the size of the key set $||K||$. The stego text is then narrated into stego audio, and the cover video is synchronised with the stego audio. Finally, both stego video and stego audio are multiplexed into a stego multimedia container. An overview of the message encoding process is illustrated in Figure 1.\na) Demultiplexing: A multimedia container C includes both a video stream V and an audio stream A. The container is split into its individual components as follows:\n${V, A} \\leftarrow Demux(C).$  (1)\nThis separation allows independent processing of each stream.\nb) Transcription: The cover audio stream A is transcribed into the cover text transcript T using a speech-to-text (STT) agent:\n$T = STT(A).$ (2)\nThis transcript serves as a linguistic medium for carrying the message.\nc) Encoding: Consider a language generation agent prompted to paraphrase the given text. The word sampling process during paraphrasing is parameterised by a shared key K, selected based on the intended message symbol. The language generation agent paraphrases the cover text transcript T and results in a stego text transcript T':\n$T' = Gen(T; K).$  (3)\nSpecifically, the stego key K serves as a pseudo-random seed for selecting a set of keywords (tokens) W from the dictionary V, with a pre-defined ratio of selection \u03b4 (0.5 by default), where\n$\u03b4 = \\frac{||W||}{||V||}.$ (4)\nThe word sampling process is biased toward generating tokens in the keyword set W. The output of a language generation agent is a sequence of logits, representing unnormalised probabilities of selecting each token from the dictionary. Let $z_w$ denote the logit for the token w. The probability of selection is biased by adjusting the logit:\n$z'_w = \\begin{cases}\nz_w + \u03b1, & \\text{if } w \u2208 W, \\\nz_w, & \\text{otherwise,}\n\\end{cases}$ (5)\nwhere \u03b1 is a positive parameter controlling the bias strength (4 by default). The probability for sampling each token is then updated by applying the softmax function:\n$p_w = \\frac{\\exp(z'_w)}{\\sum_{w\u2208V} \\exp(z'_w)}.$ (6)\nAs long as the size of the keyword set is large enough, it is possible to preserve semantic equivalence between the cover and stego transcripts, with a statistically significant portion of words sampled from the keyword set.\nd) Narration: The stego text transcript T' is converted into the aural modality using the voice cloned from the cover audio stream A through a text-to-speech (TTS) agent:\n$A' = TTS(T', A).$ (7)\nThis voice-cloning process allows the resulting stego audio stream to retain the characteristics of the original speaker.\ne) Synchronisation: To maintain audiovisual consistency, the stego audio stream $A'$ is synchronised with the cover video stream V using a lip-synchronisation agent:\n$V' = Sync(V, A').$ (8)\nf) Multiplexing: Finally, the stego video stream V' and stego audio stream $A'$ are combined into a stego multimedia container $C'$:\n$C' = Mux(V', A').$ (9)\nThis stego multimedia container is then transmitted via a channel to the receiver, with the risk of unauthorised manipulation."}, {"title": "B. Message Decoding Process", "content": "The decoding process begins with demultiplexing the query multimedia container into query video and query audio. Next, the query audio is transcribed into query text, which is then decoded using one or more shared key. In the zero-bit capacity setting, only one key is shared, and the decision is based on applying a threshold to the likelihood that the query text is unbiased, given the number of observed tokens belonging to the keyword set. In the multi-bit capacity setting, however, every shared key is applied, and the decision is made by selecting the key that minimises the likelihood of unbiasedness, given the keyword set seeded by the key. An overview of the message decoding process is illustrated in Figure 2.\na) Demultiplexing: A query multimedia container $\u0108$ consists of a query video stream $V$ and a query audio stream $\u00c2$. The query container is separated into its individual components as follows:\n${\\hat{V}, \\hat{A}} \\leftarrow Demux(\\hat{C}).$ (10)\nb) Transcription: The query audio stream $\u00c2$ is transcribed into a query text transcript $\u2191$ using an STT agent:\n$\\hat{T} = STT(\\hat{A}).$ (11)\nc) Decoding: In the zero-bit setting, to verify the presence of the message, the decoding process infers the probability that the query text transcript is unbiased, assessing whether the observed number of keywords in the query text transcript deviates significantly from what would be expected under an unbiased scenario. Let n be the total number of tokens in the query text transcript. The number of tokens belonging to the keyword set W is computed by:\n$t = \\sum_{w=1}^n I(z_w \u2208 W),$ (12)\nwhere I is the indicator function. The probability of observing more than t keyword tokens is given by the survival function of a binomial distribution Binomial(n, \u03b4), where d is the ratio of keyword selection. Mathematically, the survival function is the complementary cumulative distribution function, as defined by:\n$SF(t) = 1 - CDF(t) = 1 - \\sum_{i=0}^t \\binom{n}{i} \u03b4^i (1-\u03b4)^{n-i}.$ (13)\nIf the probability given by the survival function is lower than a predefined threshold \u03b8 (0.03 by default), the query text transcript is considered to contain the message, as expressed by:\nDecision = $\\begin{cases}\n\\text{True,} & \\text{if } SF(t) < \u03b8, \\\n\\text{False,} & \\text{otherwise.}\n\\end{cases}$ (14)\nIn the multi-bit setting, to determine the intended message symbol, the decoding process is applied over all keys and selects the one that yields the lowest probability, representing the deviation farthest from the expected statistics of unbiased scenario, as expressed by\nDecision = arg $\\min_{K\u2208K} SF(t_K),$ (15)\nwhere $t_K$ is the number of tokens belong to the keyword set seeded by the key K. Finally, the key that yields the lowest probability can be mapped back to the message symbol."}, {"title": "IV. EVALUATIONS", "content": "To validate the concept of the proposed steganographic methodology, we conducted a series of experiments to evaluate various aspects of the system, including capacity, fidelity, secrecy, and robustness."}, {"title": "A. Experimental Setup", "content": "The proposed steganographic system involves a sequence of pre-trained machine learning models, each responsible for a specific task in the process. The selected models are all open-source and state-of-the-art within their respective domains, as outlined below:\n\u2022 Transcriber: An open-source multilingual speech-recognition model named Whisper developed by OpenAI [63].\n\u2022 Narrator: An open-source multilingual text-to-speech model named XTTS developed by Coqui [64].\n\u2022 Synchroniser: An open-source lip-synchronisation model named Wav2Lip developed by the academic community [65].\n\u2022 Language Generator: An open-source language generation model named Llama developed by Meta."}, {"title": "B. Evaluation of Zero-Bit Capacity", "content": "Figure 3 shows the accuracy of the steganographic system under a zero-bit setting, where the objective is to determine whether a mark is present or absent in a given query medium. We generated 100 marked transcripts from the cover transcript using varied stego keys and 100 unmarked transcripts by paraphrasing the cover transcript without biasing the word sampling process. The receiver operating characteristic (ROC) curve, with an area under the curve (AUC) value of 0.9971, demonstrates the system's high discriminative power in distinguishing between marked and unmarked media. When the threshold @ was set to 0.03, the true positive rate (TPR) was 0.95 and the false positive rate (FPR) was 0.03, reflecting the system's ability to reliably detect marked media while maintaining a low probability of raising false alarms."}, {"title": "C. Evaluation of Multi-Bit Capacity", "content": "Figure 4 presents the relationship between capacity and bit error rate (BER) under a multi-bit setting, where the objective"}, {"title": "D. Evaluation of Fidelity", "content": "Figure 5 presents the cosine similarity across three modalities: video, audio and text, evaluating the alignment of latent embeddings in 100 stego media compared to the cover medium. We converted video streams into face identity embeddings with FaceNet [66], audio streams into voice identity embeddings with SpeechBrain [67], and text transcripts into contextual word embeddings with BERT [68]. The quartile Qo denotes the minimum, Q1 the 25th percentile, Q2 the median, Q3 the 75th percentile and Q4 the maximum. For video streams, the face identity similarities were high with a median of 0.94. For audio streams, the voice identity similarities also remained high with a median of 0.93. For text transcripts, the contextual word similarities were slightly lower and exhibited wider variations with a median of 0.82. This could be improved through the art of prompt engineering, which encourages the language model to more strictly mirror the original text or echo it, rather than loosely paraphrasing, thereby limiting the degree of variation in the generated text."}, {"title": "E. Evaluation of Secrecy", "content": "At first glance, the challenge of steganalysis may appear to be a problem of generative AI detection. However, AI-generated content does not necessarily imply concealed communications, and it is impractical to classify all AI-generated content as stego content. In contrast, we evaluate the statistical deviations between cover and stego texts. Figure 6 shows the frequency distribution of words in the cover and stego texts, plotted on a log-log scale. The distribution for both cover and stego texts follows a similar pattern, with a steep decline in frequency as rank increases, typical of a Zipfian distribution [69]. Figure 7 presents the perplexity distribution for both cover and stego texts, measured using the Llama language model. Both cover and stego texts exhibit a similar range and central tendency in perplexity values, although the stego texts contain more outliers. These findings suggest that, providing the stego texts are not outliers, they can be sampled with the same level of uncertainty as the cover texts, as reflected in their perplexity distribution."}, {"title": "F. Evaluation of Robustness", "content": "Figure 8 presents the robustness of the steganographic system under different conditions: no manipulation, compression, deepfake, and hybrid (both deepfake and compression) scenarios. The compression algorithm reduced the display resolution to 1/16, from 320 x 240 to 80x60 pixels, halved the video frame rate from 14.92 to 7.46 frames per second (fps), and halved the audio sample rate from 44,100 Hz to 22,050 Hz. The deepfake video streams were generated using the face-swapping model SimSwap [70], with 100 faces from the FaceForensics++ dataset [71], while the deepfake audio streams were generated using the voice-cloning model XTTS [64], with 100 voices from the LibriSpeech corpus [72].\nIn the compression scenario, the TPR was 0.95, the same as in the no-manipulation scenario. In the deepfake scenario, the TPR was 0.94, showing only a negligible decrease compared to the no-manipulation scenario, likely due to the unclear speech generated by the voice-cloning model and the imperfections in the speech-to-text model. Overall, these results demonstrate the system's high robustness across various forms of media manipulation. Figure 9 visualises a pair of cover and stego media, along with the compression and deepfake variants. It can be observed that while the cover transcript was altered by the steganographic system, the core semantics were preserved in the stego transcript. For instance, the text changed from 'I confidently expect that within a matter of 10 or 15 years, something will emerge from the laboratories, which is not too far from the robot of science fiction fame' to 'Scientists are likely to create a new artificial life form that closely resembles the intelligent machines of science fiction'."}, {"title": "V. CONCLUSION", "content": "In conclusion, this study investigates the vulnerability of steganography to the evolving capabilities of generative AI, with a focus on the risk of synthetic content overwriting hidden messages. Instead of relying on the spatial or temporal domains, messages are embedded in the linguistic domain of audiovisual content based on a chain of multimodal AI agents. At the core of this chain is a language generation model tasked with paraphrasing the given transcript, while the word sampling process is biased towards a shared set of tokens. The paraphrased transcript is then converted into sound using a voice-cloning model, and the video is aligned with the audio using a lip-synchronisation model. Several aspects of the proposed steganographic system are evaluated, including accuracy, fidelity, secrecy and robustness, across various metrics and conditions. Future research may explore the integration of steganographic methods for individual modalities into a unified framework, where they complement each other through the cooperation and interaction of multimodal Al agents."}]}