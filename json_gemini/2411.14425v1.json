{"title": "Whack-a-Chip: The Futility of Hardware-Centric Export Controls", "authors": ["Ritwik Gupta", "Leah Walker", "Andrew W. Reddie"], "abstract": "U.S. export controls on semiconductors are widely known to be permeable, with the People's Republic of China (PRC) steadily\ncreating state-of-the-art artificial intelligence (AI) models with exfiltrated chips. This paper presents the first concrete,\npublic evidence of how leading PRC AI labs evade and circumvent U.S. export controls. We examine how Chinese companies,\nnotably Tencent, are not only using chips that are restricted under U.S. export controls but are also finding ways to circumvent\nthese regulations by using software and modeling techniques that maximize less capable hardware. Specifically, we argue\nthat Tencent's ability to power its Hunyuan-Large model with non-export controlled NVIDIA H20s exemplifies broader\ngains in efficiency in machine learning that have eroded the moat that the United States initially built via its existing export\ncontrols. Finally, we examine the implications of this finding for the future of the United States' export control strategy.", "sections": [{"title": "Introduction", "content": "In an effort to maintain a technical edge, the United States has sought\nto limit the People's Republic of China's (PRC) artificial intelligence\n(AI) research and development by pursuing export controls on hardware\n(notably chips). As part of this strategy, the United States has created a\nseries of limits on AI hardware procurement including not only chips\nbut also the manufacturing equipment needed to create them [2]. This\nstrategy reflects the assumption that limiting a country's access to\ncutting-edge computing hardware limits the ability to create cutting-\nedge \"AI\" and other advancements. In reality, we argue that both the\nstrategy and its underlying assumption have proven unreliable.\nFirst, major Chinese Al firms-despite the export controls that they\nface-are still managing to access high-end export-controlled chips.\nSecond, Chinese Al labs have leveraged advancements in machine\nlearning (ML) training tools to successfully train state-of-the-art\n(SOTA) models on lower quality, non-export controlled chips (including\nNVIDIA's H20 GPUs), demonstrating that an export strategy based on\nhardware thresholds can be overcome through better software. The\nlatter reality reflects an evolution in the field of machine learning at\nlarge and illustrates the importance of keeping abreast of the cutting\nedge of machine learning and compute efficiency as part of forecasting\ncompetitor capability gains.\nThe strategy of overcoming limited hardware resources with\nbetter software is not unique to the PRC-American academic labs\nare bellwethers for this phenomenon. Both are resorting to clever\noptimizations [15] due to their inability to source high-quality chips\nagainst better-resourced organizations. Interestingly, these trends in\nacademic computing can also offer a useful proxy to understand ways in\nwhich the PRC might achieve its Al goals in spite of an unreliable stream\nof advanced hardware.\nIn light of these challenges, this paper examines recent AI models\nreleased by Chinese companies and examines evidence of Chinese firms\nusing export-controlled chips and cases of efficiency gains with non-\nexport-controlled chips. Specifically, this paper focuses on case studies\nand examples from Tencent, the Chinese video game juggernaut and\nChinese leader in AI research and development. This work represents\nthe first public analysis demonstrating how Chinese companies are\nsuccessfully using NVIDIA's H20 GPUs, explicitly allowed under U.S.\nexport controls, to train state-of-the-art AI, including Tencent's recently\nreleased Hunyuan-Large Model. We highlight Tencent's previous use\nof cutting-edge, export-controlled chips like the NVIDIA A100 for its\nresearch and show how codebase signals can reveal which chips are used\nfor training.\nWhile there has been previous reporting on the porous nature of the\nU.S. export regime [41, 19, 28], this paper takes a deeper dive, focusing\non the methods and techniques enabling Chinese firms to overcome\nits reliance on export-controlled chips and the acquisition and use of\nrestricted microelectronics. Finally, we analyze the broader implications\nof Beijing's evolving evasion strategies."}, {"title": "Chinese Firms are Outpacing Hardware Restrictions", "content": "On November 4, 2024, the Chinese tech giant Tencent released\n\"Hunyuan-Large,\" the largest, open-source, transformer-based mixture-\nof-experts model which achieves state-of-the-art performance on\nmultiple downstream tasks [37].\nDespite its state-of-the-art nature and size, a close examination\nof Hunyuan-Large reveals that it was not trained on state-of-the-art\nhardware. Rather Hunyuan-Large was trained on an export control-\ncompliant chip, the NVIDIA H20, a feat made possible by a series of\ntechniques used to maximize the value of throttled hardware."}, {"title": "Hunyuan-Large: A SOTA, Open-Source LLM", "content": "Hunyuan-Large represents Tencent's newest, open-source LLM. When\ncompared to other state-of-the-art LLMs such as Meta's Llama 3.1 [20],\nMixtral-8x22B [1], and DeepSeek-V2 [7], it achieves state-of-the-art\nperformance on multiple downstream benchmarks such as MMLU [13]\nand CommonsenseQA [38].\nOn November 5, 2024, Hunyuan-Large's training codebase\u00b9 and\nweights\u00b2 were openly released by Tencent on GitHub and Hugging Face,"}, {"title": "Efficiently Training SOTA Models on Nerfed Hardware with Better Software", "content": "Models are becoming smaller, requiring less compute to train, and\nconverging faster as machine learning engineering research unlocks\nefficiencies in old hardware [11]. Here, we analyze the tools, techniques,\nand procedures utilized by projects such as Hunyuan-Large to train\nstate-of-the-art models despite working with throttled hardware."}, {"title": "Ensembles and Mixtures-of-Experts", "content": "Model ensembling represents a common technique in which the outputs\nfrom multiple models are combined to address variance in underlying\ndata distributions or weaknesses in a single, monolithic model with\nindividual, small models ensembled together using less compute and\nproviding higher accuracy than their larger counterparts [16]. Mixture-\nof-experts (MoE) is a related technique that has seen a resurgence with\nmodern LLMs. With a fixed compute budget, MoEs allow for the training\nof bigger models in aggregate while achieving the same accuracy as a\nmonolithic model [33]. Tencent leveraged this technique for Hunyuan-\nLarge to train a strong model efficiently on comparatively limited\nhardware."}, {"title": "Mixed-Precision Training via bfloat16", "content": "Hunyuan-Large also uses mixed-precision training, made possible\nby the use of the bfloat16 data type. The brain floating point number\nwas introduced to the public by Google Brain in 2019 as a shortened,\n16-bit version (bfloat16) of the standard 32-bit IEEE 754 single-precision\nfloating-point format (float32). With a truncated significand such as\nwith float16, but with the dynamic range of float32, the bfloat16\nrepresentation is memory efficient and can run calculations faster. This\nrepresentation has become the de facto standard for both half- and\nmixed-precision training [23].\nMixed precision training has been shown to train models up to 2.5 \u00d7\nfaster than full-precision training with float32 on advanced GPUs such as\nthe NVIDIA A100 [14]. This training paradigm allows for larger models,\nlarger batches, or larger inputs while achieving the same accuracy as\nfull-precision training. NVIDIA introduced bfloat16 support with its"}, {"title": "Quantization", "content": "Using less precise number representations like float16, int16, or even\nbinary comes with drastic memory savings. Larger models can run faster\non constrained resources. Recent advances in quantization have reduced\nmodel sizes and increased throughput by 16x while maintaining, or\nonly slightly degrading, model accuracy [8].\nAs an example, the throughput of an NVIDIA A100 with float32\noperations on tensor cores is 156 TFLOPS, while it can achieve a\nthroughput of int8 operations on tensor cores of 624 TFLOPS, an\nidealized 3x increase in throughput. Meanwhile Meta's Llama-3-8B\ndemonstrates only a 0.019\u00b10.003% reduction in perplexity when being\nquantized from float16 to int8 [30]."}, {"title": "Large VRAM and Sharded Training", "content": "The most significant limiting factor to training large models is the\namount of video random access memory (VRAM) available on GPUs.\nLarger models do not fit on individual GPUs. If multiple GPUs are\navailable, then sharding (splitting) a model across these GPUs allows\nlarge models to be trained. This is no easy feat-effective training in a\nsharded, multi-node environment has been the subject of continual\nstudy in modern machine learning research [9, 39, 22]. Sharding\ncomes with communication overhead, drastically reducing the speed of\nmodel training. Where possible, having high VRAM GPUs can be more\nimportant than having GPUs with a large amount of fast cores. In fact,\nmany resource-constrained organizations such as academic research\nlabs aim to maximize the VRAM/dollar ratio rather than aggregate core\ncounts [15].\nAs mentioned above, the China-export-compliant NVIDIA H20 offers\n96GB of VRAM. In a world where American scientists and companies\nstruggle to get H100s [24] with comparable amounts of VRAM, they\nresort to using older 40/80GB A100s instead. The Chinese market\narguably has an edge over the American market when it comes to high\nVRAM chips as the default chip available to them has high VRAM.\nMoreover, GPUs are scarce across the globe. To make efficient use of\nthis limited resource, techniques and libraries including fully-sharded\ndata parallelism [42] and Microsoft's DeepSpeed [32] are used to train\nlarge models fast. These techniques shard model parameters, gradients,\nand even optimizer states across multiple GPUs which themselves are\nsplit across multiple nodes. The library does this in such a way that\nminimizes communication overhead and any \"bubbles,\" periods where\nhardware goes unused, in the parallel pipeline.\nConstrained to using \"nerfed\" NVIDIA H20 GPUs, the Hunyuan-\nLarge LLM is trained using Microsoft's DeepSpeed library. Specifically,\nthey utilize ZeRo Stage 3 training which partitions all model states\n(parameters, gradients, and optimizer states) across networked GPUs,\nCPUs, and RAM [31].\nOther tricks to overcome the limitations of scarce GPU resources\ninclude gradient accumulation in which multiple batches of data are\npassed through the model before one step of optimization, effectively\nsimulating larger batch sizes for optimization. This is a common\ntechnique when high VRAM GPUs are unavailable. Since Tencent has\naccess to NVIDIA H20 GPUs, they did not use gradient accumulation to\ntrain Hunyuan-Large but other Chinese firms may for other models."}, {"title": "Effectively Using Networked GPUs", "content": "When training in a sharded setting, communication overhead drastically\nslows down the process. Traditionally, GPUs communicate with each"}, {"title": "Overriding Software Limitations in Hardware", "content": "Notably, NVIDIA limits GPUDirect RDMA to only its data center GPU\nofferings, excluding clusters built using consumer GPUs. Thus consumer\nGPUs, including the NVIDIA RTX 4090-common in academic labs-are\nleft to suffer communication overhead that GPUDirect RDMA alleviates\nin data center GPUs.\nThe limiting of direct peer-to-peer communications is not done in\nhardware-it is \"soft locked\" through proprietary NVIDIA drivers. Tiny\nCorp., a startup developing AI \"supercomputers,\" reverse-engineered\nand publicly released custom drivers for the RTX 4090 which enabled\npeer-to-peer communications in June 2024-opening this soft lock.7\nReporting has shown that China is using RTX 3090 and 4090 GPUs for\nAI workloads [12]; drivers such as the one released by Tiny Corp. could\nincrease the effectiveness of these bootleg data centers."}, {"title": "Chinese Firms Bypass Chip Restrictions", "content": "Export controls on advanced semiconductors such as graphics processing\nunits (GPUs) were expanded by the United States in conjunction with\nthe 2022 CHIPS and Science Act under the Biden-Harris Administration.\nSpecifically, the newly introduced export control classification number\n(ECCN 3A090) controls the export of semiconductors marketed for\nuse in data centers that meet a specific performance threshold to\nChinese and Russian entities. As we have previously discussed, certain\nthresholds, such as inter-chip bandwidth, were not adequately designed\nto account for the types of models that could be trained on chips below\nthese thresholds [10]. These thresholds were subsequently revised to\naddress potential 'gray zone' loopholes [4]. In practice, this made export\ncontrols stricter and included large, single-wafer accelerators such as\nthe Cerebras' Wafer-Scale Engine."}, {"title": "Tracking the Use of Export-Controlled Chips Through Code Signatures", "content": "Tencent has publicly advertised their use of NVIDIA H100 and A100 GPUs\nin papers accompanying the release of at least two of their recent models.\nIn May 2024, Tencent released the HunyuanDiT model [17], a text-to-\nimage diffusion transformer comparable to OpenAI's DALL-E 3 [3]. The"}, {"title": "Avenues of Access", "content": "These public acknowledgments from Tencent corroborate reporting [41,\n19, 28] that the PRC is managing to evade U.S. export control. This\nevasion happens in a variety of different ways. By cross-reference\nreporting with the publicly available papers, training codebase, and\nweights from leading PRC AI labs, we not only begin to understand\nthe ways in which PRC companies are accessing restricted chips, but\nalso which models and companies are using which chips, as well well as\nthe techniques being used to overcome having access to chips of lower\nquality.\nStockpiling chips in advance of restrictions. Advanced GPUs\nsuch as the NVIDIA A100 were sold in the Chinese market as there\nwere previously no restrictions on the sale of such components. When\nit became clear that their access to GPUs would be limited, Chinese\ncompanies intensified efforts to stockpile chips. This practice of\nstockpiling continues whenever new restrictions are anticipated but\nnot yet implemented [40, 34]. Aforementioned discussions concerning\nthe future regulation of the H20 may lead to further stockpiling in the\nmonths ahead.\nIllegally exporting and acquiring physical chips. PRC companies\non the entity list also have options when it comes to procuring restricted\nchips, namely purchasing from vendors and illegal markets [41] or using\nsubsidiaries [19] that are not on the entities list. Per Reuters reporting\nin 2023 [41], third-party sellers in China, who range from individuals\nto entire marketplaces of restricted electronics, typically come by their\nwares by either buying up excess stock on the black market or by using a\ncompany outside China to initially acquire the chips without limitations.\nBoth of these approaches allow PRC companies to gain physical\naccess (though in limited amounts) to chips including the A100 and the\nH100. As detailed in Section 3, the precise configuration of networking\nparameters, such as the InfiniBand timeouts and traffic class, provides\na clue that Tencent is utilizing on-premise GPUs where such fine\noptimizations are possible. Cloud computing environments rarely afford\nthe ability to tune networking parameters such as these.\nRenting access or otherwise remotely accessing chips. Beyond\ndirect acquisition, companies in the PRC are also able to access\nlimited chips through cloud computing companies. The Financial Times\nidentified two companies currently sanctioned by the US, iFlytek and\nSenseTime, who were using AI-Galaxy, a cloud computing company, to\naccess A100 chips [28].\nIt is worth noting that NVIDIA H20s are not available for rent through\ncloud services. No U.S.-based cloud providers sell H20 GPU hours, and\nneither do Baidu Cloud, Alibaba Cloud, Huawei Cloud, or Tencent\nCloud."}, {"title": "A Reckoning for U.S. Semiconductor Export Controls", "content": "Advances in machine learning have eroded the moat that the United\nStates initially built to limit access to the latest GPUs via its existing\nexport controls. Moving forward, Washington can either choose to\ndouble down on the idea of export controls, limiting more and more types\nof hardware, or it can recognize the inefficacy of broad semiconductor\nexport controls and pivot to a more nuanced approach.\nThe evidence presented in this paper suggests that export\ncontrols on AI are less effective than Washington might like, and\nthat semiconductor export controls appear to be leaky proxies. So,\nwhat are the alternatives?\nAt present, the United States is attempting to limit the military use\nof Al software without placing restrictions on the export of Al software\nitself. It is unlikely that the United States should, or would, control\nthe spread of Al software. For one, this path is fraught with technical\nand legal risks. Al is inherently dual-use; models built to detect illegal\nfishing vessels [29] can equivalently be used to identify military ones.\nControlling the latter limits the utility of the former. Further, the Ninth\nCircuit established the protection of code as First Amendment-protected"}, {"title": "Conclusion", "content": "Regardless of the approach it takes, the United States must closely\nfollow not only capability gains in Chinese models but also gains\nin software-hardware efficiency. Close monitoring and evaluation of\npublicly available papers, codebases, and weights from leading PRC\nAl labs, exemplified in this paper, can provide insights into not only\nthe use of export-controlled chips by Chinese entities, but also the\ntechniques, tools, and libraries that labs use to make the most of non-\nexport controlled chips. This continuous monitoring may also allow"}]}