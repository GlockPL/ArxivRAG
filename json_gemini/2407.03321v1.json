{"title": "Planetarium: A Rigorous Benchmark for Translating Text to Structured Planning Languages", "authors": ["Max Zuo", "Francisco Piedrahita Velez", "Xiaochen Li", "Michael L. Littman", "Stephen H. Bach"], "abstract": "Many recent works have explored using language models for planning problems. One line of research focuses on translating natural language descriptions of planning tasks into structured planning languages, such as the planning domain definition language (PDDL). While this approach is promising, accurately measuring the quality of generated PDDL code continues to pose significant challenges. First, generated PDDL code is typically evaluated using planning validators that check whether the problem can be solved with a planner. This method is insufficient because a language model might generate valid PDDL code that does not align with the natural language description of the task. Second, existing evaluation sets often have natural language descriptions of the planning task that closely resemble the ground truth PDDL, reducing the challenge of the task. To bridge this gap, we introduce Planetarium, a benchmark designed to evaluate language models' ability to generate PDDL code from natural language descriptions of planning tasks. We begin by creating a PDDL equivalence algorithm that rigorously evaluates the correctness of PDDL code generated by language models by flexibly comparing it against a ground truth PDDL. Then, we present a dataset of 132, 037 text-to-PDDL pairs across 13 different tasks, with varying levels of difficulty. Finally, we evaluate several API-access and open-weight language models that reveal this task's complexity. For example, 87.6% of the PDDL problem descriptions generated by GPT-40 are syntactically parseable, 82.2% are valid, solve-able problems, but only 35.1% are semantically correct, highlighting the need for a more rigorous benchmark for this problem.", "sections": [{"title": "1 Introduction", "content": "Recently, there has been growing interest in using large language models (LLMs) to solve planning problems. Some research has focused on generating plans directly with LLMs Valmeekam et al. [2023a, 2022, 2023b], Silver et al. [2022, 2023]. However, this approach has shown limited success; GPT-4 only achieves 35% accuracy on simple planning problems Valmeekam et al. [2023a]. Another line of research uses LLMs to convert natural language prompts into structured planning languages, such as the planning domain definition language (PDDL) Liu et al. [2023], Xie et al. [2023b], Guan et al. [2023], Chalvatzaki et al. [2023], Yang et al. [2023b]. Early evidence suggests this method performs better than generating plans directly with LLMs Liu et al. [2023]. Despite its promise, there is a lack of rigorous techniques and benchmarks for evaluating the translation of natural language planning descriptions to PDDL."}, {"title": "3 Preliminaries", "content": "To present Planetarium, we first introduce planning, PDDL, and scene graphs."}, {"title": "3.1 Classical Planning Problems", "content": "In a classical planning problem, states are fully observable, there is a finite set of actions, and transitions are deterministic. The goal is to transition from the initial state to the goal state following a transition function. We use the set-theoretic definition of classical planning problems Ghallab et al. [2004].\nDefinition 1. A planning problem P is denoted by the tuple (L, S, A, \\gamma, s_i, g), where:\n\u2022 L is a finite set of proposition symbols representing different facts about the world.\n\u2022 S \u2286 2^L is a set of states. Each state s \u2286 L is the set of true propositions in that state.\n\u2022 A represents the set of actions, where each action a consists of a set of preconditions that must hold for it to be applicable and a set of effects that modify the propositions that are true after its execution.\n\u2022 The transition function \\gamma : S \u00d7 A \u2192 2^S models how the world changes by an action.\n\u2022 si is the initial state of the world from which the problem begins.\n\u2022 g \u2286 L represents the goal propositions, indicating which propositions must be true for a state to be considered a goal state. The set of goal states is Sg = {s \u2208 S | g \u2286 s}.\nA plan \u03c0 =< \u03b1\u2081, an, ..., an > is a sequence of actions that leads from si to any state in Sg following \u03b3. This plan is the solution to a planning problem P."}, {"title": "3.2 Planning Domain Definition Language", "content": "The Planning Domain Definition Language (PDDL) is a specialized language designed to provide a unified way to represent planning problems. It can represent various types of planning problems, including classical planning problems McDermott [2000], Gerevini and Long [2006]. A PDDL planning problem consists of two files: the domain file, which describes the constant parts of the world model, and a problem file, which specifies particular planning scenarios using the world model outlined in the domain file.\nIn the domain file, we specify the set of possible actions A and their preconditions and effects, which collectively define the transition function \u03b3. The problem file defines the initial state si and the goal propositions g. Finally, the set of proposition symbols L is created by combining the predicates from the domain file with the objects defined in the problem file.\nPlanetarium focuses on classical planning problems within the STRIPS subset of PDDL McDermott et al. [1998], Fikes and Nilsson [1971]. STRIPS provides the basic grammar for describing actions by specifying a set of preconditions that must be met for an action to be applicable and a set of effects that modify the propositions that are true after the action's execution. The expressiveness of problems defined in STRIPS is equivalent to those characterized by the set-theoretic definition (Definition 1) of classical planning problems Ghallab et al. [2004]."}, {"title": "3.3 Scene Graphs", "content": "To compare different planning problems, we use scene graphs. A scene graph is a data structure commonly used in fields such as computer vision and graphics Johnson et al. [2015], Chang et al. [2023], rearrangement Ramachandruni et al. [2023], and planning to represent objects, their attributes, and the relationships among them. In our work, we define scene graphs as directed graphs with types and attributes for both nodes and edges. We represent a PDDL problem file with scene graphs as follows. We create one scene graph (the initial scene) for the initial state and another for the set of goal propositions (the goal scene). For every object, we create a node with an object type. Then for every proposition that is listed in the problem file, we create a node with a proposition type. That node is given an attribute with the name of its predicate. Then, for each argument to the predicate in that proposition, we add an edge from the proposition node to the corresponding object. Each such edge is given three attributes: the name of the predicate, the position of the argument (first, second, etc.), and whether it is defined in the initial state or the goal propositions. A scene graph is thus ({OUP}, E), where O is the set of nodes with object type, P is the set of nodes with Proposition type, and E is the set of edges.\nWe further define a problem graph as the combination of an initial scene and goal scene. Given SceneGraphinit = ({OU Pinit}, Einit) and SceneGraphgoal = ({OU Pgoal}, Egoal), then a problem graph merges the scene graphs such that ProblemGraph = ({OU Pinit \u222a Pgoal}, {Einit \u222a Egoal}). We define graph isomorphism on any of these graphs as an edge and type-preserving bijection between nodes, meaning that two graphs share a connectivity structure where all types and attributes match. See Appendix B for diagrams of scene and problem graphs."}, {"title": "4 Evaluation Framework", "content": "In this section, we describe the design of Planetarium. Our goal is to systematically evaluate how well LLMs can translate natural language descriptions of planning tasks into structured planning languages. Planetarium consists of two components: an algorithm that validates whether a ground truth PDDL problem file and an LLM-generated PDDL problem file are equivalent, and a curated dataset of planning tasks against which an LLM can be evaluated."}, {"title": "4.1 Planning Problem Equivalence", "content": "The first step to benchmarking PDDL generation is determining how to decide whether the generated code matches ground truth code. One might assume that checking if two PDDL problem files are equivalent is straightforward. However, the same initial state, goal state pair could be represented by many PDDL problem files, as shown in Figure 1.\nGiven these difficulties, we propose a definition of equivalence in terms of classical planning problems. The main idea is to find a bijective function between the sets of proposition symbols L of each problem, such that when applied to the other elements, this function makes both problems equal. This definition assumes that the set of actions A and the transition function \u03b3 are shared between the two problems. Our formal definition of equivalence between two planning problems is:\nDefinition 2. Two planning problems P\u2081 = (L\u00b9, S\u00b9, A, \u03b3, si\u00b9, g\u00b9) and P2 = (L2, S2, A, \u03b3, si\u00b2, g\u00b2) with the same actions A and transition function \u03b3 are equivalent if there exists a bijective function f : L1 \u2192 L2 such that:\n1. S\u00b2 = {{f(p) : p \u2208 s} : s \u2208 S\u00b9}\n2. s_i\u00b2 = {f(p) : p\u2208s_i\u00b9}\n3. Sg2 = {{f(p) : p \u2208 s} : s \u2208 Sg1}\nThis definition is not directly usable for checking equivalence between two PDDL problem files. This is because our definition relies on finding a bijection between the sets L of each problem, and PDDL does not define these sets directly. To build the set L with PDDL, one needs to use the predicates in the domain file and the objects in the problem file, instantiating each predicate with all possible objects they might take. Since the set of actions A and the transition function \u03b3 are defined in the PDDL domain file, and since the equivalence definition assumes they are shared, we can assume the entire PDDL domain is shared. This fact entails that the predicates will be shared, making it necessary to look for bijective functions for PDDL only over the objects. The challenge is that each PDDL problem file can correspond to many pairs of initial and goal states because the set of goal propositions makes an open-world assumption. That set can leave implicit trivial propositions that are necessarily true and therefore do not change the underlying planning problem. We must therefore fully specify the goal, meaning that we identify all propositions that are true in all reachable goal states when starting from the initial state.\nOur algorithm for checking equivalence is summarized in Algorithm 1. First, we transform each set of initial state and goal state propositions into scene graphs. Second, we fully specify the goal scene graphs by adding all trivially true edges. Finally, we join the initial state scene graph with each goal state graph to create problem graphs and look for a bijection between objects such that the problem graphs are isomorphic. We now discuss these components in more detail.\nTransform to Scene Graphs. From each PDDL problem file, we generate two scene graphs: one for the initial state and another for the goal state (lines 2-3). For each transformation, we first create an object node for each object. Then, for each proposition in the collection, we create a new proposition node and create edges between the proposition node and the objects it takes as arguments. Edge attributes denote argument order, predicate type, and whether the proposition is in an initial or goal scene. See Section 3.3 for further details.\nCheck Easy Cases. For speed, we check several cases and return early if we can (lines 5-7). First, if the number of object nodes in each graph is not equal, the problems cannot be equivalent. Second, if the initial scenes are not isomorphic, then the problems cannot be equivalent. Finally, if the problem graphs, composed of the initial and goal scenes, are isomorphic, then the problems are equivalent."}, {"title": "5 Evaluating LLMs on Planetarium", "content": "As an initial snapshot of the field's current state, we evaluate several API-access and open-weight language models on Planetarium in both zero-shot and fine-tuned settings. We find that while powerful models like GPT-40 can often generate valid PDDL problems (in the sense that some plan solves them), they are rarely correct. This result underscores the need for Planetarium's rigorous approach to evaluation of PDDL generation. The code to recreate the entire evaluation is available at https://github.com/BatsResearch/planetarium.\nModels. We evaluate one API-access model (GPT-40) and three open-weight models (Mistral v0.3 7B Instruct Jiang et al. [2023], and Gemma 1.1 IT 2B & 7B Team et al. [2024]).\nEvaluation Protocol. We evaluate models on the Planetarium test set, which we built by randomly splitting the Planetarium dataset with an 80/20 train/test split. Models are prompted with the natural language description of the task along with the respective domain PDDL. We measure three metrics: the number of syntactically parseable problems generated, the number of solve-able problems, and the number of semantically correct problems. We say a model output is parseable if a PDDL parser supporting : strips can parse a valid PDDL problem from a substring in the output and if it can be converted into our graph representation. A problem is solve-able if it is parseable and there exists a plan that can be applied to the initial scene that results in the goal scene. Due to the size and complexity of some of the problems in our dataset, a generalized classical planner cannot always reliably and quickly return solutions. Therefore, we write specialized planners that work for all problems in our dataset, and generally, all validly defined blocksworld and gripper domain problems, except a few invalid edge cases (e.g., one block on top of two blocks at a time, holding two blocks, etc.). To evaluate the correctness of model outputs, they must be first parseable and solve-able. Then, we use our PDDL equivalence algorithm to verify equivalence to our ground truth PDDL. We found our equivalence algorithm to take on average 12ms per example to compute on an M2 Apple Silicon laptop with batch parallelization.\nFine-Tuning. We fine-tuned the open-weight models using QLoRA with a rank of 16, adhering to the hyperparameter recommendations for small models provided by the original authors Dettmers et al. [2023]. Models were loaded in 4-bit precision and were trained over the training set for a single epoch. Fine-tuning for each model used either two NVIDIA GeForce RTX 3090 GPUs or two NVIDIA A6000 GPUs, operating with data parallelization for approximately 15 hours. We truncate the longest 5% of our training dataset due to GPU memory constraints. Experiments were conducted using a GPU cluster at the Center for Computation and Visualization, Brown University. Additional experiment details are provided in Appendix F.\nResults. The performance of GPT-40, Mistral v0.3 7B Instruct, and Gemma 1.1 IT 2B & 7B on the Planetarium test set is shown in Figure 2. We report the percentage of generated plans that were parseable and correct and report results from zero-shot and fine-tuned settings.\nAnalysis and Discussion. All models exhibited poor zero-shot performance, with GPT-4o achieving the highest accuracy. A breakdown of GPT-40's zero-shot performance, the only model to achieve significant zero-shot performance, shows abstract task descriptions are harder to translate than explicit ones, and fully explicit task descriptions make generating parseable PDDL code easier (Figure 3)."}, {"title": "6 Conclusion, Limitations, and Future Work", "content": "Planetarium is a new benchmark for assessing the ability of LLMs to translate natural language descriptions of planning problems into PDDL. A potential societal impact of this research is ensuring the correctness of translating natural language into structured planning languages. If this translation method becomes widespread but its evaluation remains inaccurate, systems could produce misleading or misaligned results that could cause harm if acted upon. Planetarium highlights the importance of assessing the correctness of translations. We achieve this by reasoning about PDDL semantics and the inherent structure of classical planning problems.\nPlanetarium has a few important limitations: Planetarium currently only supports the Blocks World and Gripper domains. While these domains have been popular for studying LLMs and their relation to planning, incorporating more expressive domains in the future will widen the scope of Planetarium. This benchmark is also currently restricted to the STRIPS subset of PDDL. Extending it to support more expressive subsets of PDDL will allow us to evaluate more complex, real-world planning problems such as non-deterministic, temporal, and numeric domains. Our work reveals generating semantically correct structured planning language descriptions to be a challenging task for language models, with models like GPT-4o achieving 35.1% zero-shot accuracy but producing valid, seemingly correct descriptions 82.2% of the time. We hope that Planetarium will drive progress on hybrid approaches combining LLMs and classic planners, setting a standard for the evaluation of such tasks."}]}