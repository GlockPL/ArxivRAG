{"title": "Joint Resource Optimization, Computation Offloading\nand Resource Slicing for Multi-Edge Traffic-Cognitive\nNetworks", "authors": ["Ting Xiaoyang", "Minfeng Zhang", "Shu gonglee", "Saimin Chen Zhang"], "abstract": "The evolving landscape of edge computing envisions platforms operating as dynamic\nintermediaries between application providers and edge servers (ESs), where task offloading is\ncoupled with payments for computational services. Ensuring efficient resource utilization and\nmeeting stringent Quality of Service (QoS) requirements necessitates incentivizing ESs while\noptimizing the platform's operational objectives. This paper investigates a multi-agent system\nwhere both the platform and ESs are self-interested entities, addressing the joint optimization\nof revenue maximization, resource allocation, and task offloading. We propose a novel\nStackelberg game-based framework to model interactions between stakeholders and solve the\noptimization problem using a Bayesian Optimization-based centralized algorithm.\nRecognizing practical challenges in information collection due to privacy concerns, we further\ndesign a decentralized solution leveraging neural network optimization and a privacy-\npreserving information exchange protocol. Extensive numerical evaluations demonstrate the\neffectiveness of the proposed mechanisms in achieving superior performance compared to\nexisting baselines.", "sections": [{"title": "I. Introduction", "content": "In recent years, a surge of novel applications, such as augmented reality, interactive gaming,\nand autonomous driving, has placed unprecedented demands on computational and network\nresources. These applications are both resource-intensive and delay-sensitive, necessitating\nrobust and low-latency computing frameworks. Multi-access edge computing (MEC),\npreviously referred to as mobile edge computing, has emerged as a promising paradigm to\naddress these challenges. By bringing storage, computing, and networking resources closer to\nend-users at the network edge, MEC enables low-latency services while enhancing privacy and\nsecurity by processing data locally.\nMEC relies on a distributed infrastructure of computing nodes, often termed edge servers\n(ESs), to handle users' tasks. Unlike centralized cloud computing with abundant resources,\nedge servers are typically resource-constrained, posing challenges in meeting the stringent\nQuality of Service (QoS) requirements of modern applications. Although the deployment of\nedge resources continues to expand, their ad hoc configuration often limits scalability and\naccessibility, as many applications utilize these resources privately. To address these\nlimitations, cooperative edge computing has been proposed, enabling collaborative resource\nsharing among edge servers to meet peak computational demands. For instance, offloading\ntasks to non-nearest edge servers within the same metropolitan area network has been shown\nto significantly enhance users' quality of experience.\nBuilding on these developments, this paper envisions the evolution of MEC systems into\nplatforms resembling crowdsourcing ecosystems. Crowdsourcing, defined as obtaining"}, {"title": null, "content": "services, ideas, or resources through contributions from a large group of individuals, offers a\nscalable and flexible approach to problem-solving. Integrating crowdsourcing principles into\nMEC systems, referred to as crowdsourcing-like MEC, provides a compelling vision for\nachieving edge-as-a-service. In such systems, edge service providers with idle resources can\njoin the platform to generate additional revenue, enhancing resource utilization efficiency.\nSimultaneously, application providers can access elastic and scalable edge computing services\ntailored to their needs.\nTo fully realize a crowdsourcing-like edge computing system, several critical challenges\nmust be addressed. These challenges arise from the inherent complexity of managing self-\ninterested participants, ensuring security, adhering to policy compliance, and achieving\neffective system management. Among these, we focus on the following key issues:\n1- Quality of Service (QoS) Assurance: How can the system guarantee the QoS requirements\nof applications? Application providers will only offload their tasks if the platform can\nreliably meet these stringent requirements.\n2- Resource Allocation: How should edge servers (ESs) allocate resources to applications?\nOver-provisioning resources can enhance service quality but may result in reduced revenue\nfor ESs due to the fixed rewards from the platform and resource costs.\n3- Task Dispatching: How can tasks be optimally dispatched to multiple ESs hosting the same\nservice to maximize system performance?\n4- Reward Design: What reward mechanisms should the platform implement to fairly\ncompensate ESs for their contributions while accounting for the self-interest of both the\nplatform and ESs, as both aim to maximize their revenue?\n5- Privacy and Security: How can the system function effectively when participants, such as\napplication providers and ESs, refuse to share sensitive information (e.g., task details or\nresource capacities) due to privacy concerns?\nThese challenges are intricately interrelated, and addressing them in isolation risks rendering\nthe system either infeasible or suboptimal. A holistic approach is thus imperative to develop\neffective solutions that balance performance, fairness, and practicality.\nIn this paper, we consider a scenario where application providers make upfront payments\nto the platform before task offloading begins. Our objective is to address the aforementioned\nchallenges and design efficient and practical mechanisms that ensure participation from all\nstakeholders-application providers, edge servers (ESs), and the platform\u2014while meeting\ntheir diverse requirements for consuming or providing edge services. Specifically, we establish\na game-theoretic framework to model the interactions among the three entities and propose\nboth centralized and decentralized solutions, depending on the level of information the platform\ncan access.\nOur key contributions are summarized as follows:\n\u2022 Comprehensive System Modeling:\nWe present a heterogeneous crowdsourcing-like multi-server and multi-application MEC\nsystem, where edge servers have varying resource capacities, costs, and revenue\nexpectations, while applications differ in workload, budget, and QoS requirements (see Fig\n1). We formulate a joint optimization problem for revenue maximization, resource\nallocation, and task offloading, capturing the system's diverse constraints and interactions.\n\u2022 Game-Theoretic Centralized Solution:\nWe model the interactions between the platform and ESs as a Stackelberg game and\npropose a novel centralized solution based on Bayesian optimization. Unlike traditional\nbackward induction approaches, we develop an efficient algorithm to maximize the\nplatform's revenue under given resource allocations at ESs. The optimal policies for task\noffloading, resource allocation, and reward distribution are derived using this technique.\n\u2022 Privacy-Preserving Decentralized Mechanism:"}, {"title": null, "content": "To address scenarios where application providers and ESs are unwilling to share sensitive\ninformation (e.g., task details, resource capacities), we design a decentralized solution\nusing neural network optimization. This mechanism allows application providers to submit\naggregated workload information, safeguarding their privacy, while ESs determine\nresource allocations locally without exposing private details.\n\u2022 Performance Evaluation and Insights:\nWe conduct extensive numerical evaluations to compare the proposed centralized and\ndecentralized mechanisms with representative baselines. Results demonstrate that both\napproaches significantly improve the platform's revenue and incentivize ESs to contribute\nresources. Interestingly, the decentralized mechanism achieves even better revenue for\nindividual ESs compared to the centralized mechanism, offering valuable insights into\ndesigning and operating crowdsourcing-like MEC systems.\nThe remainder of this paper is organized as follows. Section 2 introduces the system\nmodel and problem formulation. Section 3 presents the optimization-based centralized\nmechanism. Section 4 elaborates on the DRL-based decentralized solution. Numerical\nevaluations and results are discussed in Section 5. and the paper concludes in Section 6."}, {"title": "II. SYSTEM MODEL AND PROBLEM FORMULATION", "content": "Fig 1 illustrates the proposed computation offloading model towards traffic-cognitive\nnetwork slicing in a multi-edge system. The system contains several edge regions, and the Base\nStation (BS) and edge servers in each edge region offer communication and computing\nresources for processing the offloaded tasks from the intelligent applications of users in the\nregion, respectively. Users are randomly distributed within the communication coverage of\neach BS, and the ESP deploys services to edge servers in all regions to achieve service coverage\nfor all users in the system. In each edge region, the ESP first sends slicing requests with\ndemanded resources to the InP and makes payment. Next, the ESP deploys the offloading\nservice on the edge server and manages the owned resources and system states. Finally, through\npaying fees, users can access the offloading service for processing their tasks.\nSpecifically, the edge regions in the system are defined as the set $Reg =\\{reg_1,reg_2, ...,reg_i,...,reg_{|Re g|}\\}$, and the users within the coverage of the region $reg_i$ are\ndenoted as the set $U_i = \\{u_{i, 1}, u_{i, 2}, ..., u_{i, j}, ..., u_{i,, N_i}\\}$, where $N_i$ is the number of users in\n$reg_i$ he communication resources of BSs and the computing resources of edge servers are\nprovided by bandwidths and virtual machines (VMs), respectively. Due to user mobility and\nrequest randomness, the number of users sending offloading in different regions and time-slots"}, {"title": null, "content": "experiences fluctuations, causing inconsistent spatio-temporal distributions of service\ndemands.\nTo improve the efficiency of resource utilization and ESP profits, the ESP analyzes recent\nuser traffic and their resource demands in each region at regular intervals, and then makes slice\nresource adjustments. To avoid QoS degradation caused by frequent slice adjustments, we\nadopt two scales of time-slots to cope with problems with different dimensions. Specifically, a\nlong time-slot is denoted ash, where $h \\in \\{1, 2, ..., H\\}$. At the start of h, the ESP evaluates the\nrequired slice resources in each region based on the information of user traffic and offloaded\ntasks collected in historical time-slots and sends slicing requests to the InP. Meanwhile, the\nlong time-slot h is divided into several short time-slots, and each is denoted as t, where $t \\in \\{1,\n2, ..., T\\}$. At the start of t, users upload their offloading requests to the ESP. The ESP assesses\nresource demands and user priorities and then makes proper decisions on computation\noffloading and resource allocation. At the end of t, the ESP collects the information of user\ntraffic and task completion status in each region for subsequent slice adjustments."}, {"title": "3.1 Communication and Computation Models", "content": "The task of the user $u_{i,j}$ is clarified as a 4-tuple $< d_{i,j}, N_{i,j}, P_{i,j}, l_{i,j} >$, which are the data\nsize, computing density, priority of $u_{i,j}$ and distance between $u_{i,j}$ and the BS, respectively. $P_{i,j}$\nindicates the service level. More revenues can be obtained if the higher-priority tasks are\ncompleted.\nWhen $u_{i,j}$ offloads its task to the edge server for execu-tion, the input data should first be\nuploaded. The bandwidth allocated to $u_{i,j}$ is denoted as $b_{i,j}^{up}$ referring to Shannon's theorem\n[27], the rate of task uploading is\n$r_{i,j} = b_{i,j}^{up}log_2(1+\\frac{Pg_{i,j}}{\\sigma^2}).(1)$\nWhere $p, \\sigma^2$ and $g_{i,j} = Bol_{i,j}^{-\\beta}$ re the upload power, noise power, and channel power gain\nbetween $u_{i,j}$ and the BS, respectively.\nTherefore, the task uploading time is defined as\n$T_{i, j}^{up} = \\frac{d_{i,j}}{r_{i,j}}.(2)$\nOnce a task is uploaded to the BS, the ESP will schedule the task to a specific VM for\nexecution. A VM may execute multiple tasks simultaneously, and thus it maintains a task\nwaiting queue. When a task is scheduled to $VM_m$ the task queuing time is defined as\n$T_{i,j}^{que} = \\sum_{k=1}^{Qm}\\frac{d_{i,k}n_{i,k}}{f^{ege}}, (3)$\nWhere $Q_m$ represents the task waiting queue that already exists when a task arrives at $VM_m$,\nand $f^{edga}$ s the com-puting frequency of $VM_m$\nTherefore, the task execution time is defined as\n$T_{i,j}^{exe} = \\frac{d_{i,j}n_{i,j}}{f^{edga}}(4)$"}, {"title": null, "content": "After completing tasks, the results will be returned to users. Since the output data is much\nsmaller than the input data, the result returning time is typically ignorable [28]. Through\nintegrating the communication and computation models, the task completion time can be\ncalculated by\n$T_{i,j}^{total} =T_{i,j}^{up} +T_{i,j}^{que} + T_{i,j}^{exe}(5)$"}, {"title": "3.2 Profit Model", "content": "When assessing ESP profits, both the revenues and costs of processing tasks should be\nconsidered. The ESP obtains revenues from users by offering services. If user tasks are\ncompleted within the maximum tolerable delay $T^{max}$, the ESP will obtain the revenue $\\Phi$.\nOtherwise, no revenue will be obtained. Hence, the revenue obtained from $u_{i,j}$ within t can be\ndescribed as\n$V_{i,j}^t =\\begin{cases}\\Phi, T_{i,j}^{Total} \\leq T^{max}\\\\0, otherwise\\end{cases}$\nFurther, the ESP will obtain different revenues if it completes tasks with diverse priorities.\nTherefore, the total revenues obtained in all regions within h is defined as\n$R^h = \\sum_{t=1}^{T} \\sum_{i=1}^{|Reg|} \\sum_{j=1}^{N_i}V_{i,j}^tP_{i,j} (7)$\nMeanwhile, the ESP will make payment for the rented resources in each region. The\navailable bandwidths sold by nP in $reg_i$ are defined as $B_i = \\{b_i^1, b_i^2,...,b_i^{|B_i|}\\}$, with the costs\nof $\\{\\zeta_i^1, \\zeta_i^2,...,\\zeta_i^{|B_i|}\\}$. The available numbers of VMs sold by InP in region are defined as $V_i =\\{\\nu_i^1,\\nu_i^2,...,\\nu_i^{|V_i|}\\$\n${\\nu_i^{|V_i|}\\}$, with the costs of $\\{\\varsigma_i^1, \\varsigma_i^2,...,\\varsigma_i^{|V_i|}\\$. The bandwidths and VMs rented by ESP\nin the $reg_i$ are presented as\n$B_i^{esp} = \\sum_{k=1}^{|B_i|}a_i^kb_i^k, V_i^{esp} = \\sum_{k=1}^{|V_i|}\\beta_i^k\\nu_i^k, (8)$\nWhere $a_i^k \\in \\{0,1\\}$ and $\\beta_i^k \\in \\{0,1\\}$ are the renting decisions of the ESP for bandwidths and\nVMs in region, respectively. The total bandwidths and VMs rented by ESP in all regions at\ntime-slot h are\n$B^{esp} = \\sum_{i=1}^{|Re g|}B_i^{esp}, V^{esp} =\\sum_{i=1}^{|Re g|}V_i^{esp}(9)$\nThus, the costs of renting resources within h are\n$C^h = \\sum_{i=1}^{|Re g|} \\sum_{k=1}^{|B_i|}a_i^k\\zeta_i^k + \\sum_{i=1}^{|Re g|} \\sum_{k=1}^{|V_i|}\\beta_i^k\\varsigma_i^k (10)$"}, {"title": "3.3 Problem Formulation", "content": "Our objective is to maximize long-term ESP profits, and thus the optimization problem is\nformulated as\nP1: $max_{\\alpha, \\beta,b,x} \\sum_{h=1}^{H}(R^h \u2013 C^h) (11)$\ns.t$C_1: a_i^k, \\beta_i^k \\in \\{0,1\\}, \\forall i, \\forall k,$\n$C_2: \\sum_{k=1}^{|B_i|}a_i^k = 1, \\forall i,$\n$C_3: \\sum_{k=1}^{|V_i|}\\beta_i^k = 1, \\forall i,$\n$C_4: \\sum_{j=1}^{N_i}b_{i,j}^{up} \\leq B_i^{esp}, \\forall i,$\n$C_5: \\sum_{j=1}^{N_i}f_{i,j}^{edge} \\leq V_i^{esp}, \\forall i,$\nwhere a and $\\beta$ represent the bandwidth and VM renting decisions of ESP in all regions,\nrespectively. b and x represent the bandwidth and VM allocation decisions in all regions,\nrespectively. C1 indicates that ESP can only decide whether to fully rent a type of resource. C2\nand C3 indicate that the ESP can only rent a type of bandwidth and VM. C4 and C5 indicate\nthat the allocated bandwidths and VMs cannot exceed the resources rented by ESP.\nTheorem 1. P1 is an NP-hard problem.\nProof. We aim to prove a special case of P 1 is equivalent to the Maximum Budget Coverage\nProblem (BMCP) that is NP-hard [29]. In BMCP, there is a set E = {e1, e1, ..., en}, where each\nelement owns specific value and cost. The objective of the BMCP is to find the subset $E' \\subseteq E$\nhat can maximize total values while meeting the cost constraint.\nIn the edge region regi, when a, $\\beta$ and b in P 1 are fixed, the offloading requests can be\ndeemed as the elements of E, where the allocated VMs and the revenues from completing tasks\nare mapped to costs and values, respectively. Thus, this special case of P 1 is defined as\n$max\\sum_{j=1}^{N_i}v_{i,j}^tP_{i,j} (12)$\ns.t $ \\sum_{j=1}^{N_i}f_{i,j}^{edge} \\leq V_{i}^{esp}$\nIt can be found that this special case is equivalent to the NP-hard BMCP. By extending the\nabove special case to a multi-edge system, we can derive that P 1 is NP-hard. To enhance QoS\nand ESP profits, it is essential to properly adjust slice resources during the offloading process.\nThe increase or decrease of user traffic and slice resources might lead to significant changes in"}, {"title": null, "content": "problem space. Moreover, the problems of network slicing and computation offloading belong\nto different time scales, raising the problem-solving difficulty. To relieve this issue, we\ndecouple P 1 into two sub-problems and formulate them as follows.\nP 1.1: This sub-problem is to minimize ESP resource costs in long time-slots by making\nslice adjustments while meeting user demands, which is defined as\n$min_{\\alpha, \\beta} \\sum_{h=1}^{H}C^h (13)$\ns. t$C1 - C3,$\n$C6: T_{i,j}^{Total} \\leq T^{max}$"}, {"title": "4. THE PROPOSED SliceOff", "content": "In this section, we first present an overview of the SliceOff. Next, we describe the two core\ncomponents of the SliceOff in detail and provide rigorous theoretical proofs for the\neffectiveness. Finally, we analyze the complexity of the SliceOff."}, {"title": "4.1. Overview of the SliceOff", "content": "The proposed SliceOff aims to improve ESP profits by jointly solving the sub-problems of\nnetwork slicing (P 1.1) and computation offloading (P 1.2). For P 1.1, linear programming and\nrandom rounding are adopted to obtain the optimal slicing scheme. To enhance the cognition\nability for fluctuating user traffic, a self-attention-based traffic prediction model is devised to\nsupport adaptive slice adjustments. For P 1.2, we develop an improved DRL method, where a\ndual-distillation mechanism is designed to explore the optimal policy from different\nenvironmental perspectives to enhance the learning efficiency and adaptability of DRL agents\nin huge problem spaces."}, {"title": "4.2 Prediction-assisted Slice Adjustment", "content": "By evaluating user traffic and offloading demands in var-ious regions, slices can be adjusted\nin advance to bet-ter meet user demands and improve resource efficiency. In multi-edge"}, {"title": null, "content": "environments, the traffic exhibits long-term changes (impacted by application popularity) and\nshort-term fluctuations (impacted by user mobility), and mean-while, different edge regions\nmay have various traffic pat-terns. These factors pose significant challenges to traffic\nprediction. Compared to classic Recurrent Neural Networks (RNNs) and Convolutional Neural\nNetworks (CNNs), the emerging Transformer [30] introduces a self-attention mech-anism to\ncapture the temporal dependencies in the se-quence, avoiding the problem of gradient\nexplosion or vanishing. Considering its excellent ability, we design a self-attention-based\nmethod to predict user traffic in different regions. Moreover, service demands commonly\ndepend on the services provided by the ESP, which can be estimated by analyzing historical\ntask attributes and system loads. Specifically, we adopt a linear programming (LP) solver to\nobtain optimal slicing resources based on traffic prediction and service demands analysis.\nConsidering that P 1.1 is constrained by C1 (i.e, $a_i^k$, $\\beta_i^k \\in \\{0,1\\}$) and the solver outputs real\nsolutions, we utilize random rounding to round real solutions to feasible ones for making slice-\nadjustment decisions. The key steps of the proposed adaptive slice adjustment method are given\nin Algorithm 2.\nStep 1: Predict future traffic. The user traffic in historical system states is first used to\nconstruct the input vectors of the encoder and decoder (Line 1). $X^{his}$ ndicates the histor-ical\ntraffic of all regions. $X^{cur}$ ndicates the traffic collected in the current prediction window that\ncontains the traffic from previous long time-slots. To avoid the high complexity caused by\ncalculating the attention weights of all historical time-slots, we adopt a probsparse self-\nattention [31] in the encoder and design a self-attention distillation between layers to reduce\nnetwork overheads (Line 2). Specifically, the feature extraction from j-th to (j + 1)-th layers is\ndefined as\n$X_{jj+1}^{en} = MaxPool(ELU(Conv1d([X_{en}]^{attention})))(15)$"}, {"title": null, "content": "[Zattention = Soft max(\\frac{OK^TV}{\\sqrt{d}}), (16)\nWhere [\u00b7]attention indicates the probsparse self-attention, d is the dimension of $X^{en}$, Convld\nindicates the one-dimensional convolution, ELU is the activation function, and MaxPool\nindicates the maximum pooling. Q is a sparse matrix that contains the Top-u queries, making\nthe prob-sparse self-attention calculating only O(log L) dot-product for each query-key lookup,\nwhere L is the length of $X^{cur}$. Next, the output of the encoder and $X^{cur}$ are fed into the decoder,\nwhich consists of a multi-head probsparse self-attention and a masked multi-head attention\n(Line 3). Finally, the output of the decoder is fed into the Fully Connected (FC) layer, and thus\nthe future traffic in all regions (i.e., $X^P$) can be predicted (Line 4)."}, {"title": "4.3 Improved DRL with Dual Distillation for Computa-tion Offloading and Resource\nAllocation", "content": "When dealing with the complex problem of computation offloading and resource allocation\nwith variable available resources, existing DRL-based methods reveal the perfor-mance\nbottlenecks caused by the Q-value overestimation and low exploration efficiency. To address\nthese issues, we propose an improved DRL method with dual distillation, whose main steps are\ndescribed in Algorithm 3. Specifically, we introduce twin critics' networks with a delay\nmechanism to solve the Q-value overestimation and reduce variance. Meanwhile, inspired by\nthe dual distillation [33], we adopt two DRL agents that conduct explorations from different\nen-vironmental perspectives and distill knowledge from each other to improve the learning\nefficiency in huge decision spaces. We consider the problem model of P 1.2 as the environment,\nand each DRL agent interacts with the envi-ronment to optimize its policy while distilling\nknowledge from the peer agent's policy. The state space, action space, and reward function are\ndefined as follows."}, {"title": null, "content": "\u2022 State space. It comprises the available bandwidth, VMs, user traffic, and task attributes\nin the current time-slot. To better capture demand features, we transfer the data size and\ncomputing density of tasks into the demands of uploading rate and computing frequency. Thus,\nthe system state at t in regi is defined as\n$s_t = \\{B_i^{esp}, V_i^{esp}, N_i, \\frac{d_{imax}^t}{T_{imax}^{max}},\\frac{d_{ini}^t}{T_{imax}^{max}},P_i\\} (20)$\nWhere $d_{i}^{t}$,$n_{i}^{t}$, and $p_i$ are vectors. For example, $d_{it} = \\{d_{i,1}, d_{i,2},..., d_{i,N_i}\\}$.\n\u2022 Action space. The DRL agent should simultaneously determine the bandwidths and\nVMs to be allocated, and thus the action at t is defined as\n$at = \\{b_i^{t}, x_i^{t}\\}, (21)$\nWhere $b_i^{t} = \\{b_{i,1}^t, b_{i,2}^t,..., b_{i,N_i}^t\\}$ indicates the propor-tion of bandwidths, and the bandwidth\nallocated to $u_{i,j}$ is $b_{i,j}^{t}B_i^{esp}$. $x_i^{t} = \\{x_{i,1}^t, x_{i,2}^t,..., x_{i,N_i}^t\\}$ indica es the VM index, and the VM index\nallocated to $u_{i,j}$ is |$x_{i}^{t}V_i^{esp}$|\n\u2022 Reward function. The objective of solving P 1.2 is to maximize cumulative ESP\nrevenues, and thus the reward function is defined as\n$r_t = \\sum_{j=1}^{N_i}v_{i,j}^t P_{i,j}. (22)$\nIn Algorithm 3, we first initialize the current and peer DRL agents (Line 1), where each\nagent consists of online networks (two critics' networks Q\u2081 and actor's network \u03c0) and target\nnetworks (Q1', Q2' and \u03c0') Different from classic DRL that directly employs the maximized\nQ-value, the proposed method adopts two independent critics' networks to fit the Q-value\nfunction. This design alleviates Q-value overestimation and avoids getting stuck in the sub-\noptimum due to undeserved cumulative errors. For each training epoch, the environment is first\ninitialized for the current DRL agent (Line 3). At each short time-slot t, the state st is fed into\nthe actor's network \u03c0, and then the DRL agent explores the action at at the current state\naccording to \u03c0 and exploration noise (Line 5). After executing compu-tation offloading and\nresource allocation, the environment feedbacks the immediate reward rt and next state st+1\n(Line 6). Next, the state-transition samples are stored in a replay buffer (Line 7), and then K\nsamples are randomly selected to update network parameters (Line 8). When updating the\ncritic's network, \u00e3t+1 at St+1 is first obtained by the target actor's network (Line 9). This\nprocess is defined as\n$\\tilde{a}_{t+1} = \\pi' (s_{t+1}|\\theta_{\\pi'}) = \\varepsilon, \\varepsilon \\sim N(0, \\sigma), (23)$"}, {"title": null, "content": "where the network noise \u025b is utilized as regularization that makes similar actions hold\nequivalent rewards. Next, the target Q-value is calculated by using rt and comparing two\ncritics' networks (Line 10), which is de-scribed as\n$y_t = r(s_t,a_t) + \\gamma\\cdot min_{i =1,2}(Q_{\\theta_i'}^{r}\\tilde{(}s_{t+1},\\tilde{a}_{t+1})). (24)$\nThen, the two critic's networks are updated (Line 11). To decrease the updating frequency\nof the policies with low quality, we adopt a delay mechanism to update the actor's network and\ntarget networks. If t mod 2 = 0, the actor's network will be updated by gradient ascent (Line\n13). This process is defined as\n$\\nabla_{\\theta}J(\\theta) = - \\frac{1}{K}\\sum_{j=1}^{K} \\alpha\\nabla_{\\theta}Q_1(s, a)|_{a = \\pi(s)}\\nabla_{\\theta}\\pi_{\\theta}(s). (25)$\nNext, the policy of the current agent is updated with the peer agent's policy \u00f1. However, it\nis hard to determine which of the two agents performs better at different states. To address this\nissue, we soften the loss function and introduce a weighted loss function to update the policy\n(Line 14). Specifically, the distillation objective function is defined as\n$J_{\\xi}(\\theta) = E_{s\\sim\\pi} [|\\pi(s) - \\tilde{\\pi}(s)|exp(\\alpha^{\\xi_{\\pi}(s)})], (26)$\nwhere exp ($a_{\\pi}(s)$) is the confidence score, and a controls the confidence level that depends\non the accuracy of value-function estimation. $\\xi_{\\pi}^{\\tilde{\\pi}}(s)$ indicates the advantage value of $\\tilde{\\pi}$\ncompared to \u03c0 at s, which is defined as\n$\\xi_{\\pi}^{\\tilde{\\pi}}(s) = V^{\\tilde{\\pi}} (s) \u2013 V^{\\pi}(s), (27)$\nwhere the larger $\\xi_{\\pi}^{\\tilde{\\pi}}(s)$ indicates the loss function is more conducive for the current policy\nto learn from the peer one. Otherwise, it is more inclined to remain unchanged.\nNext, the target networks are updated via soft update (Line 15), and thus the critic's network\nis updated more fre-quently than the actor's and target networks. Unlike directly updating all\nnetworks, this manner reduces cumulative errors and improves training stability. Finally, the\nalgorithm is continuously running to update the peer agent's policy (Line 16). During this\nprocess, each agent is updated ac-cording to its reward function and distillation loss function,\nachieving its own update while learning useful knowledge from the peer agent to enhance itself.\nTheorem 3. Dual distillation between the current and peer agents supports achieving a more\noptimized hybrid policy.\nProof. A hybrid policy consists of the current and peer agents' policies that are chosen\naccording to the relative advantage value, and it is defined as\n$\\pi^*(s) =\\begin{cases}\\pi(s), \\xi_{\\pi}^{\\tilde{\\pi}}(s) > 0 \\\\\\tilde{\\pi}(s), otherwise \\end{cases}(28)$\nTherefore, it can be guaranteed that \u03c0* is a more opti-mized policy than \u03c0 and \u00f1 (i.e,\nVs, V\u03c0* (s) \u2265 V\" (s) and V\u03c0* (s)). V \u03c0 (s) \u2265 V \u03c0\u02dc (s)). Next, we consider a simple form of the\nobjective function, which is defined as\""}, {"title": null, "content": "J\u2084(0) = Es\u314a[[(s) - \u00f1(s)1( (5) > 0)], (29)\nWhere 1 is the indicator function. If\u03be\u03c0' (s) > 0, the value of 1 (\u00b7)is 1. Otherwise, this value\nis 0. Since \u03c1\u03c0* and p\u3047 is similar, the difference between p\u3047 and \u03c1\u03c0* is negligible. Thus, the\nproposed dual-distillation process can be described as\nE5~\u00f1[|| \u03c0(s) \u2013 \u00f1(s) ||\u00b2 1(\u03bet(s) > 0)]\n=\u03a3 || D(\u03c0(s) \u2013 \u00f1(s)) ||\u00b2 +\ns~\u03c1\u03c0;\u03be\u03c0(s)>0\n=\u03a3 || D(\u03c0(s) \u2013 \u00f1(s)) ||\u00b2+\u03a3 || D(\u03c0(s) \u2013 \u00f1(s)) ||\u00b2 (30)\ns~\u03c1\u03c0*;\u03be\u03c0(s)>0\ns~\u03c1\u03c0*;\u03be\u03c0(s)\u22640\n=\u03a3 || \u03c0(s) = \u03c0*(s) ||2\ns~\u03c1\u03c0*\n= \u0395\u03c2~\u03c0*[|| \u03c0(s) \u03c0*(s) |[2].\nBased on the above proof, we can derive that the knowl-edge of \u03c0\u02dc will be transferred to \u03c0\nif the advantage value of \u00f1 is positive. Otherwise, the update of the current policy will ignore\nthe dual-distillation process. Therefore, the dual-distillation enables a more optimized hybrid\npolicy. Further, to reduce the errors of value-function estimation caused by neural networks,\nwe replace 1 (f(s)) with exp (f(s)) and use a to control the confidence level for obtaining\nthe objective function."}, {"title": "5. Performance of Centralized Mechanism", "content": "We begin by evaluating the performance of our centralized resource allocation and task\noffloading mechanism. Figure 3 presents the platform and edge servers (ESs) revenue, the\nnumber of offloaded tasks, and the resource utilization efficiency of ESs under different\nalgorithms. The comparison includes our proposed mechanism, an auction-based algorithm, a\nmax-transaction algorithm, and a greedy approach. This analysis considers a scenario with 3"}]}