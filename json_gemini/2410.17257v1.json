{"title": "Code-Driven Law NO, Normware SI!", "authors": ["Giovanni Sileno"], "abstract": "With the digitalization of society, the interest, the debates and the research efforts concerning \"code\", \"law\", \"artificial intelligence\", and their various relationships, have been widely increasing. Yet, most arguments primarily focus on contemporary computational methods and artifacts (inferential models constructed via machine-learning methods, rule-based systems, smart contracts, ...), rather than attempting to identify more fundamental mechanisms. Aiming to go beyond this conceptual limitation, this paper introduces and elaborates on \"normware\" as an explicit additional stance complementary to software and hardware for the interpretation and the design of artificial devices. By means of a few examples, we argue that normware-centred views provide a more adequate abstraction to study and design interactions between computational systems and human institutions, and may help with the design and development of technical interventions within wider socio-technical views.", "sections": [{"title": "Introduction", "content": "The concept of code-driven law, ie. of \"legal norms or policies that have been articulated in computer code\" by some actors with normative competence, has been convincingly elaborated by Hildebrandt in recent work [1]. Its introduction has the merit to refocus the discussion on the role of artificial devices in the legal activity, rather than on ontological positions expressed under code-is-law or law-is-code banners, which are present, with various interpretations and changing fortunes, in the literature and practice of contemporary regulatory technologies, and technology-oriented legal scholarship (see the overview in [2]).\nAccording to Hildebrandt, code-driven law should be distinguished both from data-driven law, ie. computational decision-making derived from statistical or other inductive methods (including predictions used in support for human decision-making), and from text-driven law, ie. the legal activity performed by humans by means of sources of norms such as statutory and case law. A crucial difference between these forms of \"law\" is that the linguistic artifacts used in text-driven law are characterized by open-textured concepts (eg. reasonableness, bona fide, foreseeability, etc.) and multi-interpretability, and therefore carry inherently a potential of dispute that data-driven or code-driven law do not have (for statistical, or for logical closures). For this reason, code-driven law"}, {"title": "Types of law: a more nuanced distinction", "content": ""}, {"title": "Text-guided law?", "content": "In recent work [1], Hildebrandt refers to \"text-driven law\" as the legal activity performed by humans by means of sources of norms expressed in verbal forms. Such an activity could not have been performed without a whole-historically non-computational technological infrastructure related to textual artifacts (used for printing, distributing, archiving, methods for indexing and retrieving) [10]. However, at a more fundamental level, text-based law inherently relies on language, and natural language functions differently than formal languages used in computational settings. Natural language is open to poly-semy, it strongly relies on analogical constructs, and its use (in production and in interpretation) heavily depends on contextualization. In some occasion, text in laws is intentionally left ambiguous, for instance when legislators, also for reasons of political opportunity, prefer not to take a clear commitment towards a certain outcome. In other cases, multi-interpretability is a consequence of generalization. Law is expected to work in a differed fashion, it does not apply only on known, expected cases, but it aims to be relevant also for cases that have not yet appeared. Humans in the loop are therefore inevitable, in particular with cases exhibiting new features or when changes are made to the institutional structure. Multi-interpretability also entails that different humans may frame the same case selecting and interpreting texts in different ways, opening to disputes and also to uncertainty with respect to the outcome of the decision. Part of the procedural mechanisms in court as well as of the jurisprudential debate have a crucial role in promoting legal certainty, but what matters here to us is that the relation between text and legal activity is not a direct one, and, insofar humans are involved, we should rather refer to \u201ctext-guided law\u201d ."}, {"title": "Uncertainties in data-driven law", "content": "Regardless of how data-driven inferential mechanisms are incorporated in the decision-making process, empirical alignment resulting from machine learning is generally performed against a certain training data-set, in principle collected and engineered to provide a sound statistical closure to the target domain of application. The effectiveness of the trained model to achieve the desired outcome depends not only on the dataset, but also on the specific training method. Let us suppose, without loss of generality, that the data-set consists of a set of instances, each one associated with a label, as in a traditional supervised classification task. From a technical point of view, it is well known that good practices in data science and machine learning associate with critical questions, amongst which: Are the instances in the training data set representative of the domain upon which the model is applied? Is the rationale behind the labelling still the same at runtime? Is the chosen training method providing adequate, reproducible, robust results? The third question can be directly associated to technical aspects, but the first two are prototypical examples of context-centred (and not algorithm-centred) inquiries, in particular concerning the assumptions of statistical closure. Thus, data-driven law can be contested, and indeed best practices entail that it should be scrutinized, even before setting additional re-quirements as eg. explainability or transparency of the inferential process."}, {"title": "Uncertainties in code-driven law", "content": "The third form of legal activity identified by Hildebrandt is \"code-driven law\", for which provisions from various legal sources (eg. legal norms, regulations, policies, agreements, contracts) have been operationalized via computational means. From a historical point of view, the idea of using machines with normative provisions traditionally dates back to Leibniz (Calculemus!), and took more concrete forms with the advent of legal expert systems and various attempts at formalisation of law (eg. [12, 13]), in part renewed during the semantic web technology heyday, and, in narrower forms, in contemporary RegTech (eg. smart contracts), and cyber infrastructure research (eg. data governance, consent management systems). Most distinctive assumptions of these contributions can be categorized within the domain of legal isomorphism [14], susceptible to concerns on whether, to what extent, and how legal sources can be represented in computational artifacts, and normative reasoning automated by computational processes. At a strictly theoretical level, neglecting interpretative and tractability challenges, the problem becomes a purely logical one. Given a formal language, and the associated derivation mechanisms, soundness and completeness can be formally proven to verify a logical closure guaranteeing valid inferences. Let us then suppose that our system is provided with structural knowledge relative to norms in the form of rules, and contingent knowledge relative to the case in the form of facts; within a formal system we can be certain that we utilize these resources to derive logically valid conclusions. But are they correct in a \"practical\" sense? Theory and practice of computational legal theory acknowledge several critical questions in this respect: Were all the relevant fact and rules considered? Is the formalization correct? Is the reasoning tool"}, {"title": "Setting an alternative technological agenda", "content": "Taking into account the critical questions identified in the respective fields of practice, we can conclude that neither data-driven nor code-driven law guarantee legal certainty. The premises on which the underlying computational devices are constructed and deployed will always be \"weak\" to some extent. Besides, software bugs, limitations or hacks (malicious attacks) may occur in computational systems supporting both. Said differently, the computational legalism \u201cideal\u201d works only in so far we forget all what may go wrong. The only way by which these computational devices may achieve legal certainty is by removing the possibility of contestation, which, although this may be seen as a feature of the system, is clearly societally unacceptable.\nNaive computational justice, and its limits Perhaps, a more sustainable path is to reproduce in the computational realm procedures analogous to the ones introduced in human societies, which have proven value in the course of civilizations to deal with the legal (un) certainty of text-guided law. For instance, in order to satisfy principles of justice, such as proportionality and distribution, we may formalize those as meta-rules. In order to keep instrumentality with respect to contextual policy goals, we may require to make these goals explicit, and have them in the loop of the automated reasoning process. The resulting (naive) computational justice stance is based on the belief that a perfect conceptualization will solve all problems observed before. Unfortunately, there are two serious hindrances for such an approach. First, we cannot be sure of any formalization, ever. The strongest support for this claim is not technical, but comes from the human dimension of the problem, the \"referent\" (the entity referred to) that needs to be formalized. For instance, the debates on ethical frameworks and human rights make clear that there is no such a referent, or, if it exists, it does so only on some contextual basis. Second, we may never be ready to have an explicit and complete articulation of policy-makers' purposes. Even imaging that this was possible, by means of perfect introspection and no errors in expression, making clear in detail all what some authority aims to achieve (or does not aim to) would entail to be transparent also on highly contestable issues, which in many occasions would be politically detrimental, and thus not to be expected.\nExpecting wrongs, errors, redirections When both computational legal-ism and (naive) computational justice have been defeated, it seems there is no much hope for an advance in legal technologies. Fortunately, this is not true; new and sounder objectives can be set by starting from opposite assumptions. With respect to computational legalism, we should not suppose that things are"}, {"title": "Normware as artifacts", "content": ""}, {"title": "Directives concerning regulation", "content": "In the most intuitive interpretation, \"normware\" refers to computational arti-facts specifying norms, ie. intelligible directives concerning regulation of be-haviour. Common computational artifacts going under this definition would be access control and usage control policies, machine-readable data-sharing agree-ments, digital consents, policies for digital infrastructure regulating eg. rout-ing, or data-sharing across domains, as well as behavioural policies (scripts) for computational agents. Complementary to these more operational contribu-tions, there is a large body of literature on normative systems, consisting of a vast number of contributions about deontic logic, i.e. the logic of obligation, prohibition, and permission (see the overviews given in [18, 19]), and fewer on other conceptual frameworks (eg. Hohfeld's primitive normative concepts [20, 21, 22, 23, 24, 25]). Yet, it is crucial to observe that any computer program has inherently a \"normative\" interpretation, even without referring to explicit normative concepts, or used explicitly for normative purposes.\nImperative programs The most traditional form of programming artifacts is that of imperative programs. Imperative programs consist of sequences of instructions, ie. actions that ought to be performed by the machine. Even ma-chine code, used to interact with hardware, is generally expressed in imperative terms. However, if the engineering objective for normware artifacts is to achieve some form of legal isomorphism [14] (or, more reasonably, a weaker version of"}, {"title": "Directives concerning qualification", "content": "As soon as we climb the ladder of abstraction we are however confronted with the classic problems of semantics: What do we mean by this? (for language-mediated situations), correlative to What is this? (for concrete, direct situa-tions). Part of these wide issues in philosophy and in symbolic AI goes under the name of qualification problem [28], concerning the adequate expression of the preconditions required for an action (here, a certain naming) to be applica-ble. Interestingly, law attempts to partially solve similar challenges by means of constitutive rules defining within the normative sources what count-as what, or, complementarily, via procedural heuristics like evidential rules emerging from case law.\nFortunately, being in the computational domain provides us with a privi-leged (but also illusive) starting point to tackle this problem, in comparison to a human-centred social domain. This is because hardware manufacturers physically hard-code the (local) semantics of primitive operations, consisting of logical and arithmetic operations, and specific instructions controlling memory or some input/output modules. As long as all possible \"this\" for our domain of concerns can be referred back to these physical primitives, or their logical counterparts, the qualification problem can be solved. However, because in any practical application we need to go beyond the computational boundary (that is, there are always elements referring to or depending on what is outside the computational system), we cannot truly bypass the qualification problem, and"}, {"title": "Directives concerning expectations", "content": "As a discipline, knowledge engineering targets more widely ontologies: shared conceptualizations of a target domain expressed in a machine-processable form [29]. These conceptualization artifacts contain terminological knowledge, but they also include relationships attributed (in most cases by humans) to the target domain: eg. taxonomies, partonomies, causal dependencies and logical constraints. Independently from the specific representational model associated to the various solutions introduced in the literature and by industry, all these artifacts aim to reify expectations in symbolic forms. This was deemed relevant for computational regulative purposes, as most normative reasoning tasks require some form of world knowledge [30], eg. to elaborate on causal chainings for responsibility attribution, to compare the impact of action vs omission of action, to evaluate foreseeability of events. Besides, this elaboration concerns not only physical mechanisms/outcomes but also symbolic ones, as for instance with in-stitutional powers, identifying and handling actions whose performance carries institutional meaning. Unfortunately, it is also well-known that computational ontologies and more generally purely symbolic methods suffer from serious lim-itations (e.g. the infamous knowledge-acquisition bottleneck, the difficulty of alignment across ontologies, the lack of symbol grounding [31], the ramification and qualification problems, and so on), therefore ontologies (or similar types of technologies) cannot be deemed to be a sufficient mean.\nLooking at a higher abstraction level, ontological artifacts are meant to cap-ture what is to be expected, or is at least possible in the target domain. Indeed, beside normativity, the \"norm\" in normware refers also to a normality dimen-sion. Statistical methods are particularly suited to identify what is \"normal\" in a certain sample space, and the same applies with statistical machine-learning: latent spaces captured in machine-learning models are non-intelligible expres-sion of regularities induced from observations. For instance, a \u201ccat\u201d classifier embeds some model of a prototypical cat, time-series predictors embeds models of temporal patterns, word-embeddings reify expectations of proximity between \u201cconcepts\u201d. May these artifacts have also a role within a computational frame-work centred on normware? To answer to this question, we need to take a different route: we need to abstract the fact that there is a designer that in-tentionally specified the device; in other words, we need to look at artifacts in functional terms."}, {"title": "Devices intended to regulate", "content": "All designed artifacts can be interpreted just by knowing the function for which they have been designed. A door regulates the entrance to a certain building or room. A semaphore signals to vehicles, bikes and pedestrians whether they are allowed or prohibited to cross. Suppose the door to be also electronically controlled. In both cases (semaphore, and controlled door), we do not have access to the inner decision-making mechanism that brought to the current output state, but, as far as we can see this output (eg. the door being closed, the light being red), and we know to what is referring to (eg. allowing a certain action or not), we are able to interpret it, adapting our behaviour accordingly. The case of the door goes even further, as the device intervenes in the physical environment disabling our action without requiring our understanding. These examples support the idea that black-boxes as machine-learning models are artifacts expressing some form of normality/normativity, and as such they can be thought as normware artifacts too. In other words, under the lens of normware, there is no functional difference between code-driven and data-driven law. Both forms of computation are meant to regulate behaviours, qualifications, and expectations. For instance, a model trained via reinforcement learning will provide as output actions that have to be performed conditionally to the observed input, a classifier will provide labels to input objects, a temporal predictor projections in the future of given states, an autoencoder a latent model of the domain from which we can identify abnormal instances, and so on."}, {"title": "Normware as processes", "content": ""}, {"title": "Regulation as control", "content": "Institutional systems since ancient times are based on some assumption of in-tentionality (eg. the cases in [32, p. 102]). The behaviour of intentional agents, by definition, can be interpreted in terms of purpose, motives, and motivations. In many cases, however, 'weaker' interpretations of action may also apply, which do not require the existence of a mental state associated with the intent, but still maintain a purposive character. For instance, the notion of control system has a primary role in engineering disciplines, and issues of regulation (eg. homeostasis) are central to the study of biological systems. A crucial difference between control systems and agents is that the latter are deemed to be able to generate their own goals autonomously (albeit with various levels of auton-omy), while for the former, goals have been hard-coded by design (top-down), or by selection through some adaptive, possibly evolutionary process (bottom-up). The goal of an entity is then, in an ecological perspective, the function of the entity within the environmental niche in which it is embedded, and transcends the entity itself. This is clear for designed artifacts, but natural entities also fall under similar considerations without taking a creationist stance (cf. the concept of teleonomy introduced by Monod [33] as counterpart to teleology)."}, {"title": "Indeterminacy of references and directives", "content": "The legal activity and jurisprudential debates make clear that, for socially rel-evant phenomena, references cannot be defined once and for all, nor expressed entirely with a single artifact, and not even taking into account all normative artifacts (pace strong legal positivism). A sounder stance is to see these situa-tional \"points\" (eg. a fairness point) as mere virtual placeholders for setting up socio-technical arrangements, contextually and historically dependent [36]. The correct functioning of these arrangements is enabled only by some common un-derstanding or behavioural coordination amongst participants, which they have agreed, or accepted, or at least not contrasted. This acknowledgement entails that we cannot rely on the assumption that there is only one correct way to model (symbolically or sub-symbolically) what a \u201ccat\u201d is, in all circumstances; that all what a contract means can be reified into a single artifact; that there exists an abstract fairness point, that can be discovered once and for all by some mathematical formula.\nIndeterminacy of references entails indeterminacy of directives, but indeter-minacy of directives may also occur because of antinomies, ie. when two or more conflicting directives exist. Legal systems generally introduce formal criteria to identify the relative priority of norms (eg. lex specialis, superior, and posterior), but it is generally in the hard-cases that one can see that formal criteria are ac-companied by underlying/implicit preferential structures, eventually embodied by the judges (\"voices of the law\"), and sometimes expressed as values (see eg. [37] in the case-based reasoning literature), that are meant to balance or com-plement formal mechanisms (or their absence) to supposedly obtain a more just result. At a fundamental level, the primary source of these indeterminacies are the different positions, perceptions, knowledge, expectations, motivations, and preferences of the various participants to the social gathering, and this diversity in perspectives brings naturally to different qualifications.\nAll these observations apply similarly to components of distributed compu-tational systems. Computational modules with the same function may be given different inputs (eg. two similar sensors placed in different positions), and/or defined by distinct processes (either designed or trained) striving for different goals or value structures, and for this reason may produce conflicting output. Moreover, humans (with all their heterogeneity) intervene in the computational loop, for instance interacting via some interface with the computational system, or possibly feeding it with additional data and/or modifying its code. Conflict-"}, {"title": "Coordination and conflict resolution", "content": "Taken as an atomic component, a piece of normware functions as a coordination mechanism, just like a semaphore. The concern of such coordination may be prescriptive, with normware artifacts meant to regulate other modules in a cer-tain way (w.r.t. behaviour, or terminology); or descriptive, in the sense that a certain coordination function is observed or ascribed to a certain component (in the form of qualifications, or expectations). However, the introduction of the norwmare level of computation is purposely meant to go beyond the single indi-vidual artifact, and to acknowledge the \"ecological\" dimension of computation, ie. the presence and entrenchment of several concurrent possibly conflicting-coordination mechanisms within the same system. The ecological dimension becomes also evident when there are frictions between descriptive and prescrip-tive perspectives upon the same entity.\nDealing with failures We can identify two general families of failures due to conflicts: (i) components may not behave as expected; (ii) components concur-rently sets incompatible directives. Failures of the first type generally trigger some control mechanism that either intervenes on the system (triggering a repair action) or on the environment (remedy action); or, in some cases, by dropping the directive which failed. From a system's point of view, these violations need to be dealt with in order to maintain the encoded coupling between system and environment.\nFailures of the second type are purely internal to the system, and require the inhibition or the removal of a number of components to restore directivity. These conflicts concern the viability of the system. A system which is unable to restore directivity carries the risks of becoming idle, which often does not coincide with begin neutral between the two directions, but de facto taking one of the two by default. For instance, in a context in which both duty of A and prohibition of A are issued, not doing anything means fulfilling the second.\nNote also that it is not necessary for failures to occur to trigger a system's response. Expectations can have a crucial role for anticipating conflicts, pro-moting preventive or preparatory behaviour. The various risk strategies can for instance be thought as meta-directives dedicated to anticipatory functions, capturing the entrenchment between expectations and references targeted by regulations.\nHigher-order indetermination The maintenance of processes of determi-nation of references, and of resolution of conflicts requires in itself some ref-erence/directive. This requirement links to the procedural dimension of law. Conflict resolution directives can in principle also be contested, and dynami-cally changed. In the human realm, any contract needs to comply with contract law, which defines some procedural, formal requirements that make a contract valid. Contract law in itself has been issued by some legislative body, whose members supposing a democratic system were elected, with voting mecha-"}, {"title": "Primary and secondary drivers", "content": "It is not in our scope to participate in the debate on what originates legal sys-tems (eg. Kelsen's Grundnorm, or Schmitt's constituent power). Being in the computational realm provides us with a more controlled grounding than the real world, because some pre-existing regulatory infrastructure is necessarily given: at some micro-level, components will eventually behave as control systems, with no expectation of failure. These elementary capacities of artificial devices (phys-ical, symbolic) are generally associated to powers granted to users/developers. From this insight, we can formulate a distinction between:\n\u2022 code-driven computational entities, whose control flow perfectly aligns with the instructions provided by another component or by a human with adequate powers (eg. the developer);\n\u2022 code-guided computational entities, whose control flow includes mecha-nisms mediating the input instructions with other directives, which in some circumstances may completely override the input.\nCorrespondingly, in terms of normware components, one can distinguish be-tween primary drivers (eg. the ones hard-coded in the processor); from sec-ondary drivers, which contingently contribute to further specify and constrain the system behaviour, in support to primary drivers. Deciding where the boundary lies between primary and secondary drivers is a fundamental design choice, which is obscured by traditional stances on computational artefacts."}, {"title": "Normware in the wild", "content": "When directives are implemented as primary drivers we are in the domain of code-driven and data-driven law. The concept of normware gains however most of its value once secondary drivers are introduced in the system. Differently from hardware and software, which are primarily defined in terms of control, we expect a piece of normware not to be used for control, but primarily for guidance of the computational system. This is a view that we apply naturally when we think of directives expressed to human agents (eg. parents to kids, legislators/policy-makers to social participants), but not to artificial devices. Yet, because normware abstracts the underlying computational technology, it can be used as a framework to evaluate any concept and architecture associ-ated to computational systems: Turing machines, smart contracts, operating systems, the Internet, knowledge-based systems, neural networks and other"}, {"title": "First-order control", "content": "Algorithms expressed in terms of control flow of instructions (specifying the sequence of execution) can be reformulated in terms of control structure of com-putational actors [40]. Consider for instance a \u201cprinting agent\u201d implemented as a Turing machine. Suppose this agent is designed to print on its tape, sequentially and indefinitely, the symbol it observes in its state register, over-writing what is recorded on the tape. Now imagine that, assuming there is no mechanical impediment, a second agent (possibly human) reads/write the state register of the \"printing agent\". The first machine, the controlled entity, can be seen as being subjected to directives (about printing) issued by the second one, the controller entity. The same pattern can be observed between developers and computational systems in code-driven and data-driven systems (see Fig. 1): these systems cannot escape from what they have been instructed to do by the developers. Control structures like this one have a one-to-one mapping to power relationships, and therefore can be captured by adequate normware specifica-tions, although it may be add impractical overhead with simple hierarchical constructs."}, {"title": "Second-order control", "content": "Let us consider that the controller entity of the previous configuration is also a Turing machine. Its internal register may be modified in turn by a programmer,"}, {"title": "Decentralizing control", "content": "Traditional programs, as well as inferential models constructed via machine learning, are generally conceptualized to be executed as single, unitary computa-tional processes. Similarly, the knowledge level presented by Newell [9] assumes"}, {"title": "Research perspectives", "content": "Having set the conceptual horizon of normware, I will now briefly elaborate on two main research tracks relevant for \"normware-centred\" engineering: how to specify normware (for individual artefacts), and how to operationalize normware (as an ecological process), focusing in particular on conflicts."}, {"title": "Specifying code", "content": "Although the paper argues for going beyond a code-driven law perspective, code still plays a central role in code-guided law. To enable humans to specify normware in an intelligible and traceable way, we have plausibly to strive for some adequate mapping from (contextual interpretations of) sources of norms to some computational formal language. Since the first pioneering experiments with TAXMAN for US corporate tax law [12], and the modelling of the British Citizenship Act with a logic program [13], several solutions for specifying nor-mative artifacts (norms, contracts, policies) in a computational processable way have been presented in the literature. Amongst the most recent efforts we acknowledge e.g. LegalRuleML [46, 47], PROLEG [48], InstAL [49], ODRL [50, 51], Symboleo [52], FLINT/eFLINT [53, 54], Logical English [55], Catala [56], Blawx [57], Stipula [58], and DPCL [59]. Legal core ontologies (eg. LKIF-core [60], UFO-L [61]) have also been proposed to systematize concepts and relationships relevant to normative reasoning. No solution amongst those has achieved general acceptance, even less in deployment. More unexpectedly, there exists no common ground (nor representational, nor computational) enabling a comparison between these solutions. Complementary to these efforts, there exist a number of industrial, domain-specific standards, which in contrast to the above are widely used, eg. XACML (for access control) [62], BGP policies (routing) [63], Protune, Rei, Ponder, TrustX (for cloud services) [64]. These solutions considers only few or even no explicit normative concepts; their con-cerns is not modelling what is in the law or in executive policies, but of having effective and computationally efficient instruments of regulation (for security, privacy, etc.). Similar considerations apply to artifacts to specify terminology and expectations like computational ontologies, logic programs, or functionally similar entities.\nLaw-, policy-, and more in general knowledge-centred software is evaluated against both a language dimension (determining what types of knowledge we can specify and how), and a computational dimension (determining what we can actually do with these knowledge artifacts). Approaches giving priority to logical aspects result in well-defined semantics, which enables the possibil-ity of using formal verification to guarantee the correctedness of the system. However, despite efforts in such sense, there are strong reasons to believe we"}, {"title": "Resolving conflicts", "content": "Dealing with pluralism means not only enabling the existence of several concur-rent, potentially competing components, but also to have instruments to resolve such conflicts. Because these instruments are also coordination artifacts, they belong to the normware level. Indeed, one could encode in a normware arte-fact eg. the formal meta-rules determining the priority between laws, or voting mechanisms, or other relevant institutional patterns.\nRelevant conflict resolution mechanisms have been researched in various dis-ciplines, providing in principle off-the-shelf methods that can be reused in a normware-based computational system. For instance, aggregation of preferen-tial structures, eg. by voting mechanisms, have been studied extensively in computational social choice (see eg. [67]), as well as other branches of applied mathematics [68]. Directives can also be seen as public arguments. Formal ar-gumentation theory (eg. [69]) focuses on attacks (and/or support) relationships between individual arguments, and provides several methods to evaluate the strength of arguments based on the whole argumentation system. The various forms of defeasible logics introduce rule priorities in the derivation process, ap-"}, {"title": "Conclusion", "content": "The concept of normware brings to the foreground that both institutional sys-tems (particularly in their procedural aspects) and computational systems are in fact information processing systems. Indeed, any institutional system tran-scends its individual social participants, and, to the extent that such a system is designed (ie. its form has been deliberately chosen by rational agents), it can also be seen as an artificial one. Now, bureaucratic alienation in formal orga-nizations (eg. public administrations) is a well known phenomenon, both for participants in these organizations (cf. Weber's theory of bureaucratic manage-ment, business-IT alignment literature, etc.) and for the various stakeholders interacting with them. Computational systems can be related to an analogous, plausibly even more intense alienation.\nComputers process symbols or numbers without any clue on their meaning further on in the decision process. This implies that, from a systematic point of view, no \"intelligent\" system can be expected without: (i) designing adequate feedback loops (and the associated intervention points); (ii) taking adequately into account a plurality of drivers and of contexts; (iii) being able to identify and overcome the conflicts that will naturally occur. These three points summarize the most distinctive matters we have elaborated in this paper, investigating the various aspects of normware. Engineering perspectives at an hardware (physi-cal artefacts/processes), or software (symbolic artefacts/processes) levels do not provide the right abstraction to discuss about governance (coordination arte-facts/processes) within the computational realm.\nThe continuity between institutional and computational systems however does not imply that accepting more sound computational forms of law will remove the need for human law. On the contrary, as human intervention is required to repair issues due to bureaucratic alienation, the best way to define their relationship (in the human and in the computational domain) is as the relationship higher-courts have towards lower-courts, ensuring that humans will always remain in control and mechanisms like appeals (against decisions) and quashing/overruling (against decision-making processes) become systemic. In fact, a core conclusion of the present contribution is that the socio-technical challenge we are facing is not mechanizing law, but introducing legitimate nor-mative processes within the computational realm. Discussions on legitimacy do not solve challenges on technical possibility; normware may offer a common ground to discuss and advance the latter."}]}