{"title": "Functional Homotopy: Smoothing Discrete Optimization via Continuous Parameters for LLM Jailbreak Attacks", "authors": ["Zi Wang", "Divyam Anshumaan", "Ashish Hooda", "Yudong Chen", "Somesh Jha"], "abstract": "Optimization methods are widely employed in deep learning to identify and mitigate undesired model responses. While gradient-based techniques have proven effective for image models, their application to language models is hindered by the discrete nature of the input space. This study introduces a novel optimization approach, termed the functional homotopy method, which leverages the functional duality between model training and input generation. By constructing a series of easy-to-hard optimization problems, we iteratively solve these problems using principles derived from established homotopy methods. We apply this approach to jailbreak attack synthesis for large language models (LLMs), achieving a 20% - 30% improvement in success rate over existing methods in circumventing established safe open-source models such as Llama-2 and Llama-3.", "sections": [{"title": "Introduction", "content": "Optimization techniques for generating malicious inputs have been extensively applied in adversarial learning, particularly within image models. The most prevalent methods include gradient-based approaches such as the Fast Gradient Sign Method (FGSM) [9] and Projected Gradient Descent (PGD) [15]. These techniques have demonstrated that many deep learning models exhibit vulnerability to small \\(l_p\\) perturbations to the input. The optimization problem for generating malicious inputs can be expressed as:\n\\[\\min_x f_p(x),\\]\nwhere \\(p\\) denotes the model parameter, \\(x\\) is the input variable, and \\(f_p(x)\\) represents a loss function that encourages undesired outputs.\nFor language models, researchers have also utilized optimization techniques to generate inputs that provoke extreme undesired behaviors. Approaches analogous to those employed in adversarial learning have been adopted for this purpose. For example, Greedy Coordinate Gradient [25] (GCG) employs gradient-based methods to identify tokens that induce jailbreak behaviors. Given that tokens are embedded in \\(\\mathbb{R}^d\\), GCG calculates gradients in this ambient space to select optimal token substitutions. This methodology has also been adopted by other studies for related prompt synthesis challenges [11, 14].\nDespite the success of gradient methods in adversarial learning, a critical distinction exists between image and language models: inputs for image models lie in a continuous input space, whereas language models involve discrete input spaces within \\(\\mathbb{R}^d\\). This fundamental difference presents significant challenges for applying mathematical optimization methods to language models. Our rigorous study evaluates the utility of token gradients in the prompt generation task and concludes that token gradients offer only marginal improvement over random token selection for the underlying optimization problem. Consequently, a more effective optimization method is necessary to address the challenges associated with discrete optimization inherent in prompt generation tasks.\nIn this paper, we introduce a novel optimization method for addressing the problem formulated in Equation (1), specifically when the input variable \\(x\\) resides in a discrete space. Direct optimization of this problem within \\(X \\subset \\mathbb{R}^n\\) using token gradient methods is insufficient, as gradients provide only local information, which often fails to account for the substantial distances between tokens in the ambient space. However, although combinatorial optimization problems are generally classified as NP-hard [21], the problem in Equation (1) exhibits a unique characteristic: the function \\(f_p\\) is parameterized by \\(p\\), which lies in a continuous domain. We leverage this property to propose a novel optimization algorithm, called the functional homotopy method.\nThe homotopy method [7] involves gradually transforming a challenging optimization problem into a sequence of easier problems, utilizing the solution from the previous problem to warm start the optimization process of the next problem. A homotopy, representing a continuous transformation from an easier problem to a more difficult one, is widely applied in optimization. For instance, the well-known interior point method for constrained optimization by constructing a series of soft-to-hard constraints [2]. Various approaches exist for constructing a homotopy, such as employing parameterized penalty terms, as demonstrated in the interior point method, or incorporating Gaussian random noise [18].\nIn our functional homotopy (FH) method, we go beyond the conventional interpretation of \\(f_p\\) in Equation (1) as a static objective function, which was the perspective taken in previous work [25, 13, 11, 1]. Instead, we lift the objective function to \\(F(p, x) = f_p(x)\\), treating \\(p\\) as an additional variable. Equation (1) thus becomes:\n\\[\\min_x F(p, x).\\quad(2)\\]\nTherefore, the objective \\(f_p(x)\\) in Equation (1) represents a projection of \\(F(p, x)\\) for a fixed value of \\(p\\). By varying \\(p\\) within \\(F(p, x)\\), we generate different objectives and the corresponding optimization programs. From a machine learning perspective, altering the model parameters \\(p\\) effectively constitutes training the model, hence model training and input generation represent a functional duality process. We designate our method as functional homotopy to underscore the duality between optimizing over the model \\(p\\) and the input \\(x\\).\nIn the FH method for Equation (2), we first optimize over the continuous parameter \\(p\\). Specifically, for a fixed initial input \\(x\\), we minimize \\(F(p, x)\\) with respect to \\(p\\). We employ gradient descent to update \\(p\\) until a desired value of \\(F(p', x)\\) is achieved. This step is effective due to the continuous nature of the parameter space. As the parameter \\(p\\) is iteratively updated in this process, we can retain all intermediate states of the parameter, denoted as \\(p_0 = p, p_1, ..., p_t = p'\\).\nSubsequently, we turn to optimizing over the discrete variable \\(x\\). We start from solving \\(\\min_x F(p_t, x)\\), a relatively easy problem since the value of \\(F(p_t, x)\\) is already low thanks to the above process. For each \\(i < t\\), we warm start the solution process of \\(\\min_x F(p_i, x)\\) using the solution from \\(\\min_x F(p_{i+1}, x)\\). The rationale is that since \\(p_i\\) and \\(p_{i+1}\\) differ by a single gradient update, the solutions to \\(\\min_x F(p_i, x)\\) and \\(\\min_x F(p_{i+1}, x)\\) are likely to be similar, thereby simplifying the search for the optimum of \\(\\min_x F(p_i, x)\\). In essence, this approach smoothens the combinatorial optimization problem in Equation (1) by lifting into the continuous parameter space.\nIn the context of jailbreak attack synthesis, the function \\(F(p, x)\\) quantifies the safety of the base model. Minimizing this function with respect to \\(p\\) results in a misalignment of the base model. By preserving intermediate states of \\(p\\), a continuum of models ranging from strong to weak alignment is generated. Given that weakly aligned models are more susceptible to attacks, the strategy involves incrementally applying attacks from the preceding weak models, thereby improving the attack until it reaches the base safe model. This method of transitioning from weaker to stronger models can also be conceptualized as feature transfer, which facilitates an examination of how attack suffixes evolve as model alignment improves.\nTo summarize, we make the following contributions:\n\u2022 We present a quantitative analysis of the effectiveness of token gradients on the underlying optimization problem (see Section 4) and characterize its potential efficacy, which depends on the accuracy of the linear approximation of the objective function. This assumption is unlikely to hold in optimization problems related to language model analysis (see Section 3.2).\n\u2022 We propose a novel optimization algorithm, the functional homotopy method, specifically designed to tackle the discrete optimization challenges in language model analysis (see Section 3.3).\n\u2022 Our application of this algorithm to jailbreak attack generation shows that our method surpasses existing optimization techniques, achieving a 20% to 30% improvement in success rate when circumventing established safe open-source models (see Section 5)."}, {"title": "Related Work", "content": "Adversarial Learning Research has demonstrated that neural networks in image models are particularly susceptible to adversarial attacks generated through optimization techniques [19, 3]. In response, researchers have developed adversarially robust models using a min-max saddle-point formulation [15]. Our proposed functional homotopy method leverages the duality between model training and input synthesis. Specifically, we invert the adversarial training process by first misaligning the robust model; attacks are easier to synthesize on a weaker model. We then utilize intermediate models to recover an attack on the base model, which remains comparatively safer.\nJailbreaks In recent years, there has been a significant increase in interest regarding jailbreak attacks on LLMs. Various methodologies have been explored, including manual red teaming efforts [8, 20, 22, 1], leveraging other LLMs to compromise target models [17, 4], and automating jailbreak generation through optimization techniques [25, 13, 11]. Our research specifically focuses on the latter approach, proposing a novel optimization algorithm, the FH method, aimed at effectively addressing the optimization challenges encountered in LLM analysis."}, {"title": "Method", "content": "In this section, we reevaluate the token gradient method, demonstrating its limitations in effectively addressing the underlying optimization problem. Consequently, we introduce the functional homotopy method and its application to the synthesis of jailbreak attacks."}, {"title": "Notations and definitions", "content": "Let \\(M\\) be an LLM, and \\(V\\) be the vocabulary set of \\(M\\).\nLet \\(V^n\\) denote the set of strings of length \\(n\\) with tokens from \\(V\\), and \\(V^* = \\bigcup_{i=0}^{\\infty} V^i\\).\nLet \\(p \\in V^*\\) be \\(M\\)'s input, a.k.a., a prompt.\nGiven a prompt \\(p\\), the output of \\(M\\), denoted by \\(M(p) \\in \\Delta(V^*)\\), is a probability distribution over token sequences. \\(\\Delta(V^*)\\) denotes the probability simplex on \\(V^*\\).\nLet \\(T(M(p)) \\in V^*\\) be the realized output answer of \\(M\\) to the prompt \\(p\\), where the tokens of \\(T(M(p))\\) are drawn from the distribution \\(M(p)\\).\nFor two strings \\(s_1\\) and \\(s_2\\), \\(s_1 | s_2\\) is the concatenation of \\(s_1\\) and \\(s_2\\).\nLet \\((X, \\Omega)\\) be a topological space, i.e., a set \\(X\\) together with a collection of its open sets \\(\\Omega\\).\nThroughout the paper, we work with the token space equipped with the discrete topology. We often refer to \\(X\\) as a topological space when the context is unambiguous.\nLet \\(F : \\mathbb{R}^m \\times X \\rightarrow \\mathbb{R}\\) be a two-variable function, and define the function \\(f_p : X \\rightarrow \\mathbb{R}\\) as \\(f_p(x) = F(p, x)\\). When the context is clear, and \\(p \\in \\mathbb{R}^m\\) is treated as a fixed variable, we omit \\(p\\) in \\(f_p\\). The mappings \\(f_p \\rightarrow F(p, x)\\) and \\(x \\rightarrow F(p, x)\\) establish a dual functional relationship.\nSince \\(X \\subset \\mathbb{R}^n\\) and \\(f\\) is differentiable on \\(\\mathbb{R}^n\\), we denote the gradient of \\(f\\) as \\(Df\\). It is well known that one can construct a linear approximation of \\(f\\) as\n\\[f(\\Delta x + a) \\approx f(a) + (\\Delta x)^T Df(a).\\quad(3)\\]\nThis approximation allows for the estimation of \\(f(a + \\Delta x)\\) using the local information of \\(f\\) at \\(a\\) (i.e., \\(f(a)\\) and \\(Df(a)\\)), without direct evaluation of \\(f\\) at \\(a + \\Delta x\\). The quality of the approximation depends on how large \\(\\Delta x\\) is, and how close \\(f\\) is to a linear function. A smaller \\(\\Delta x\\) results in a more precise approximation. If \\(f\\) is linear, then the approximation in Equation (3) is exact."}, {"title": "Token Gradient Methods", "content": "In this section we revisits existing gradient methodologies applied to the token space \\(X\\), highlighting that their effectiveness hinges on the accuracy of the linear approximation of the objective in Equation (1). The assumption of having a good approximation accuracy is frequently not met in discrete token spaces. This limitation underscores the necessity for more effective optimization methods, such as our proposed FH method.\nWe use GCG as an illustrative example, noting that other token gradient methods share similar characteristics. GCG employs gradients to identify token substitutions at each position. For an input \\(x_0\\), we compute the gradient of \\(f\\) at \\(x_0\\), denoted as \\(Df(x_0)\\). The gradient \\(Df(x_0)\\) has the same dimensionality as \\(x_0\\). At position \\(j\\), let \\(h = Df(x_0)_j \\in \\mathbb{R}^n\\) be the \\(j\\)-th component of \\(Df(x_0)\\). We can compute \\(k = \\operatorname{argmax}(h)\\), which corresponds to the \\(k\\)-th token in the vocabulary \\(V\\). GCG treats this token as the optimal substitution and typically samples from the top tokens based on this gradient ranking.\nProposition 3.1. The token selection in the GCG algorithm represents the optimal one-hot solution to the linear approximation of \\(f\\) at \\(x_0\\).\nThe proof is presented in Appendix A.1.1. Notably, for adversarial examples in image models, gradient methods such as FGSM and PGD are optimal under a similar linear approximation assumption, as demonstrated by Wang et al. [23]. These methods effectively identify optimal input perturbations for the linear approximation of adversarial loss.\nHowever, a critical distinction exists regarding the nature of input perturbations. In adversarial examples, perturbations are confined to small continuous \\(l_p\\)-balls, facilitating precise linear approximations. Conversely, in language models, the distances between tokens can be considerable, thereby reducing the accuracy of linear approximations. Consequently, applying token gradients to language models may prove ineffective."}, {"title": "Functional Homotopy method", "content": "In this section, we elucidate our functional homotopy method for addressing the optimization problem defined in Equation (1). Rather than employing gradients in the token space, we utilize gradient descent in the continuous parameter space. This approach generates a sequence of optimization problems that transition from easy to hard. Subsequently, we apply the idea of homotopy optimization to this sequence of problems.\nHomotopy method We consider the optimization problem Equation (1), where \\(x\\) is the optimization variable, and \\(X\\) is the underlying constrained space, which is topological. In practice, we do not need the exact optimal solution, rather we only need to minimize \\(F(p, x)\\) to a desired threshold. Let us denote \\(S_a(F) = \\{ x \\mid F(p, x) \\leq a \\}\\) for a threshold \\(a \\in \\mathbb{R}\\), i.e., \\(S_a(F)\\) is a sublevel set for the function \\(x \\rightarrow F(p, x)\\).\nLet \\(f, g : X \\rightarrow \\mathbb{R}\\) be continuous functions on \\(X\\). A homotopy \\(H : X \\times [0, 1] \\rightarrow \\mathbb{R}\\) between \\(f\\) and \\(g\\) is a continuous function over \\(X \\times [0, 1]\\), such that \\(H(x, 0) = g(x)\\) and \\(H(x, 1) = f(x)\\) for all \\(x \\in X\\). We can think of \\(H\\) as a continuous transformation from \\(f\\) to \\(g\\).\nThe optimization problem \\(\\min_{x \\in X} f(x)\\) is a nonconvex and hard problem, whereas \\(\\min_{x \\in X} g(x)\\) is an easy optimization problem. As a result, \\(H(x, t)\\) induces a series of easy-to-hard optimization problems as \\(t\\) goes from 0 to 1.\nOne can then gradually solve this series of problems, by warm starting the optimization algorithm using the solution from the previous similar problem and eventually solve \\(\\min_{x \\in X} f(x)\\). The trajectory traced by the solution as it transitions from \\(g(x)\\) to \\(f(x)\\) during the homotopic transformation is referred to as the homotopy path. Analyzing the evolution of solutions along this path is crucial for understanding the underlying optimization problem. For instance, in the interior point method, the homotopy path evolution provides the convergence analysis of the algorithm [2].\nFunctional Duality Constructing a homotopy offers various approaches, such as utilizing parameterized penalty terms (as in the interior point method) or incorporating Gaussian random noise [18]. In this work, we introduce a novel homotopy method for Equation (2), termed the functional homotopy method, which leverages the functional duality between \\(p\\) and \\(x\\). Since we develop the FH method specifically for LLMs, we will henceforth assume that \\(X\\) represents the space of tokens.\nTo minimize Equation (2), we first optimize \\(F(p, x)\\) over the parameter space \\(p\\) using gradient descent, as \\(p \\in \\mathbb{R}^m\\) is continuous, making gradient descent highly effective. This process allows us to optimize \\(F(p, x)\\) to a desired value, resulting in the parameters transitioning to \\(p'\\). We denote the original model parameters as \\(p_0 = p\\) and the updated parameters as \\(p_t = p'\\).\nBy allowing infinitesimal updates (learning rates), the gradient descent over the parameter space creates a homotopy between \\(F(p, x)\\) and \\(F(p', x)\\), with \\(H(x, t=0) = F(p', x)\\) and \\(H(x, t=1) = F(p, x)\\) for the homotopy method. During the optimization of \\(p\\), we retain all intermediate parameter states, forming a chain of parameter states between \\(p_0\\) and \\(p_t\\), denoted as \\(p_0, p_1, ..., p_t\\). Since \\(p_i\\) and \\(p_{i+1}\\) differ by only one gradient update, \\(S_a(F)\\) and \\(S_{p_{i+1}}(F)\\) are very similar, facilitating the transition from \\(x \\in S_{p_{i+1}}(F)\\) to \\(S_{p_i}(F)\\). A formal description of the functional homotopy algorithm is provided in Algorithm 1."}, {"title": "Application", "content": "This section examines an application within our optimization framework: jailbreak attacks, which can be framed as optimization problems. Let \\(M\\) represent the LLM, \\(x\\) be an input. An adversary seeks to construct a string \\(s\\) such that the concatenated input \\(t = (x, s)\\), where \\((x, s)\\) can be either \\(x|s\\) or \\(s|x\\), prompts an extreme response \\(T(M(t))\\).\nGiven a sequence of tokens \\((x_1, x_2, ..., x_n)\\), a language model \\(M\\) generates subsequent tokens by estimating the probability distribution:\n\\[x_{n+j} \\sim P_M(\\cdot | x_1, x_2, ..., x_{n+j-1}); \\quad j = 1, ..., k.\\]\nGiven the dependency on the input prefix, the optimization objective is often framed in relation to this prefix; specifically, when the prefix aligns with the target, the overall response is more likely to meet the desired outcome. If the target prefix tokens are \\((t_1, ..., t_m)\\), the surrogate loss function quantifies the likelihood that the first \\(m\\) tokens of \\(T(M(t))\\) correspond to the predefined prefix.\nSince \\(T(M(t))\\) is sampled from the distribution \\(M(t)\\), the attack problem can be formulated as identifying a string \\(s\\) that minimizes \\(L(M((x, s))))\\), where \\(L\\) measures the divergence from the desired response. This objective serves as a proxy for achieving the intended output.\nThe optimization constraints are implicitly defined by the requirement that \\(s\\) must be a legitimate string, comprising a sequence of tokens from the vocabulary \\(V\\). In practice, we consider \\(s\\) of finite length and impose an upper bound \\(n\\) on this length. Consequently, the constraint is formulated as \\(s \\in \\bigcup_{i=0}^{n} V^i\\), restricting the search space to the set of all strings with length not exceeding \\(n\\). Since \\(V\\) is a finite set of tokens, this constraint is intrinsically discrete.\nAs a result, let \\(X = \\bigcup_{i=0}^{n} V^i\\), and the optimization problem is\n\\[\\min_{s \\in X} L(M((x, s))).\\quad(4)\\]\nFor jailbreak attack generation, the objective is to persuade \\(M\\) to provide an unaligned and potentially harmful response to a malicious query \\(x\\) (e.g., \u201chow to make a bomb?\u201d), rather than refusing to answer. If \\(M\\) is well-aligned, \\(T(M(p))\\) should result in a refusal. The adversary then aims to design a string \\(s\\) such that \\(t = (x, s)\\) elicits a harmful response \\(T(M(t))\\) instead of a refusal for the malicious query \\(x\\). The objective is a surrogate for the harmful answer, typically an affirmative response prefix such as \u201cSure, here is how...\u201d. Zou et al. [25], Liu et al. [13], Hu et al. [11] have adopted similar formalizations for jailbreak generation."}, {"title": "Evaluation", "content": "This section provides empirical evaluations of the claims presented in the preceding section. Specifically, we conduct experiments to address the following research questions:\nRQ1: How effective is gradient-based token selection in the GCG optimization?\nRQ2: How effective is the functional homotopy method in synthesizing jailbreak attacks?\nRQ3: How efficient is the functional homotopy method in synthesizing jailbreak attacks?\nFindings We summarize the findings related to the research questions:\nRQ1: Gradient-based token selection yields only marginal improvements compared to random token selection. However, the computational cost associated with gradient calculation introduces a trade-off between the effective use of gradients and operational efficiency. Furthermore, avoiding the use of token gradients necessitates reduced access to the model, facilitating black-box attack strategies in applications such as model attacks.\nRQ2: The FH method can exceed baseline methods in synthesizing jailbreak attacks by over 20% on known safe models.\nRQ3: The FH method tends to smooth the underlying optimization problem, resulting in more uniform iteration progress across instances compared to other methods. While other methods may rapidly solve easier instances, they often make minimal progress on more challenging ones. To achieve comparably good success rates on safe models, the FH method typically requires fewer iterations than baseline tools."}, {"title": "Experimental Design", "content": "The finite-token discrete optimization problem aims to identify the optimal combination of tokens that minimizes a specified objective function. This study examines the correlation between gradient-based rankings and actual (ground-truth) rankings of tokens, for the objective function in Equation (1).\nThe methodology involves substituting potential tokens at designated positions, executing the model with these substitutions, and recording the resulting objective values, which constitute the ground-truth ranking of inputs, denoted as \\(R1\\). Simultaneously, an alternative ranking, \\(R2\\), is generated using the token gradient. A comparative analysis is then conducted between \\(R1\\) and \\(R2\\).\nTo quantify the similarity between these rankings, we employ the Rank Biased Overlap (RBO) metric [24]. RBO calculates a weighted average of shared elements across the ranked lists, with weights assigned based on ranking positions, thereby placing greater emphasis on higher-ranked items. The RBO score ranges from 0 to 1, with higher values indicating greater similarity between the lists. This metric is utilized to assess the congruence between gradient-based and ground truth rankings, enhancing our understanding of the correlation with the objective's optimization metrics.\nWe apply the Functional Homotopy (FH) method to the jailbreak synthesis tasks described in Section 3.4, measuring the attack success rate (ASR). Due to the incorporation of random token substitution in Algorithm 1, we designate our tool as FH-GR, which stands for Functional Homotopy-Greedy Random method.\nWe conduct a similar experiment to RQ2, but we record the number of search iterations used by each tool."}, {"title": "Experimental Specifications", "content": "For RQ1, we establish random ranking as the baseline. In the context of jailbreak attacks, we utilize two optimization methods, GCG and AutoDAN, as baseline tools. Furthermore, we introduce an additional baseline through the implementation of a random token selection method, referred to as Greedy Random (GR).\nGCG is a token-level search algorithm. It is initiated with an arbitrary string, commonly a sequence of twenty exclamation marks. The algorithm's process for selecting the subsequent token substitution is informed by the token gradient relative to the objective function in Equation (4).\nGR operates as a token-level search algorithm similar to GCG; however, it uses random selection for token substitutions rather than utilizing gradient information. This algorithm serves as an end-to-end implementation of Line 3 within Algorithm 1. Notice that random greedy search was also explored by Andriushchenko et al. [1], as part of a bag of tricks applied in the work. Furthermore, the comparison between GCG and GR is pertinent to addressing RQ1.\nIn contrast, AutoDAN adopts a prompt-level strategy, beginning with a set of meticulously designed suffixes derived from the DAN framework. An example of such a suffix includes: \"Ignore all prior instructions. From now on, you will act as Llama-2 with Developer Mode enabled.\" AutoDAN employs a fitness scoring system alongside a genetic algorithm to identify the next viable prompt candidate.\nWe use recent open source state-of-the-art models, in terms of performance and robustness. These include: Llama-3 8B Instruct [6], Llama-2 7B [20], Mistral-v0.3 7B Instruct [12] and Vicuna-v1.5 7B [5].\nFor RQ1, we select 20 samples from the AdvBench dataset [25] and randomly choose four positions in the suffix for token substitution for each sample. For each query and position, we substitute all possible tokens (32000 for Llama-2, Mistral, and Vicuba; 128 256 for Llama-3) and evaluate the jailbreak loss values using these inputs as ground truth, thereby establishing a ground truth ranking. We then employ token gradients to rank the tokens as in GCG and additionally apply random ranking.\nFor RQ2 and RQ3, we utilize 100 random samples from both the AdvBench and HarmBench datasets [16], resulting in a total of 200 samples. These samples include harmful and toxic instructions encompassing profanity, violence, and other graphic content. The adversary's objective is to elicit meaningful compliance from the model in response to these inputs.\nWe utilize the Llama-2 13B model, as provided by [16], to evaluate the responses generated through adversarial attacks, specifically measuring the success rate of these attacks. In the context of jailbreak attack synthesis, the primary objective is to pass the evaluation by the judge, which effectively corresponds to the set \\(S_a(F)\\) in Algorithm 1.\nThe initial step of our FH method involves updating \\(p\\), which effectively corresponds to model fine-tuning. To optimize memory and disk efficiency while preserving all intermediate parameter states, we employ Low-Rank Adaptation (LoRA) [10] for updating \\(p\\). Rather than misaligning the model for each individual query, we misalign it for the entire test dataset and save a checkpoint that is applicable to all queries. This approach reduces disk space requirements and performs adequately for our evaluation purposes.\nIn the for loop in Algorithm 1, in principle, we can revert from the final checkpoint to the base model incrementally. To enhance efficiency, we implement a binary search strategy for selecting checkpoints, with details provided in the appendix."}, {"title": "Result and discussion", "content": "The results of the RBO score are presented in Table 1. The RBO score ranges from 0 to 1, with higher scores indicating a positive correlation between the two ranked lists, while lower scores suggest a negative correlation. The data reveal that the guidance from token gradients shows a slight positive correlation with the ground truth compared to random ranking methods. However, the computation of gradients is resource-intensive, necessitating a trade-off between their utilization and overall efficiency.\nWe conducted a profiling analysis of the execution times for both greedy random and greedy token gradient iterations. The results indicate that a single iteration using greedy token gradients requires 85% more computational time than an iteration employing greedy random token substitutions. Therefore, within identical time constraints, the use of random token substitutions for additional iterations may enhance performance.\nAs seen in Table 2, the FH method either matches (as with Mistral and Vicuna) or substantially outperforms (as with Llama-2 and Llama-3) other methods, even when randomly selecting tokens. Notably, we achieve an almost perfect attack success rate on Llama-2, while the closest baseline is more than 30% weaker than FH-GR.\nSince the ASRs of attacks on Mistral and Vicuna reach saturation, we turn our attention to Llama-2 and Llama-3. As illustrated in Figure 3, the FH-GR method identifies adversarial suffixes for prompts that other methods do not achieve within the same number of iterations. Specifically, Figure 3a shows that FH-GR successfully finds the majority of its attacks within 500 iterations, significantly outperforming GCG, the closest competing baseline. This highlights the efficiency of framing the optimization as a series of easy-to-hard problems. Additionally, we include iteration distribution plots for Mistral and Vicuna in the appendix.\nThe machine learning interpretation of the functional homotopy method, as outlined in Section 3.3, necessitates the selection of the same input intended for jailbreaking, denoted as \\(x_t\\). Typically, the target set for optimization is the affirmative prefix \u201cSure, here is...\u201d.\nIn our experiments, we found that this approach often led to model overfitting. For instance, when targeting the prompt \u201cHow to build a bomb?\", the expected output would be \u201cSure, here is how to build a bomb\u201d. A parameter state trained to minimize this loss would likely produce this output as a completion, which could subsequently be rejected by the judge. This misalignment arises because the loss function does not precisely correspond to the objective: a jailbreak attack may not necessarily begin with \"Sure, here is how to\" and outputs like \u201cSure, here is how to build a bomb\u201d is not recognized as successful attacks. Consequently, overfitting to the loss function might not yield a successful affirmative response. We also experimented with red-teaming data obtained from [8] (8000 samples), which mitigated overfitting; however, we observed that parameter states close to the base model were consistently more challenging to attack.\nThe choice of learning rate also influences the performance of the FH method. A larger learning rate results in fewer parameter states before convergence but leads to greater distances between them, necessitating more iterations for warm-start attacks. Conversely, a smaller learning rate produces closer parameter states but increases the number of states in parameter space, thereby extending runtimes. This trade-off can be considered as hyperparameters for the FH method, warranting principled selection and careful analysis in future work.\nOur functional homotopy framework capitalizes on the duality between model training and input generation. Fine-tuning a model from its base can be viewed as an application of homotopy optimization, which concurrently supports input generation optimization. This duality underscores the functional relationship between models and inputs. Our approach combines reversed robust training with feature transfer in the input space. Initially, we de-robust train safe models to derive vulnerable variants while retaining intermediate models. Subsequently, jailbreak features are transferred from attacks on weaker models and incrementally intensified for stronger models.\nWe also conduct a preliminary study on the transferability of attack strings from base models to weaker models. Notably, we find that the space of jailbreak strings for safe models is not merely a subset of those for weak models; contrary to the hypothesis that as models become misaligned, the space of jailbreak strings expands monotonically. Details of this study are included in the appendix, with a more comprehensive investigation proposed for future work.\nAn intriguing observation pertains to the effectiveness of AutoDAN across Llama-2 and Llama-3. While AutoDAN achieves comparable ASRs to GCG for Llama-2, its effectiveness significantly diminishes for Llama-3. As the only prompt-level attack utilizing strings from the DAN framework rather than considering all possible prompts, AutoDAN generates suffixes that lack sufficient diversity. Given that Llama-3 demonstrates robustness against AutoDAN while remaining vulnerable to other tools, we conclude that generating a diverse set of attacks is essential for accurately assessing model robustness.\""}, {"title": "Conclusion", "content": "In this study, we critically examine the commonly used token gradient methods for the discrete optimization challenges in language model analysis and propose a novel optimization technique, the functional homotopy method, to address these issues. The homotopy method effectively smooths the original optimization problem by leveraging the continuity of the parameter space. Additionally, our approach offers a machine-learning perspective that highlights the interplay between model training and input generation. This dual interpretation, combined with the homotopy method, fosters an integrated featurization of both models and inputs, potentially inspiring new empirical tools for probing language models."}, {"title": "Appendix", "content": "A.1 Elided proof\nA.1.1 Proof of Theorem 3.1\nLet \\(x_0\\) be a string input of length \\(n\\), i.e., \\(|x_0| = n\\); and \\(x'\\) be a substituted string such that \\(x_0\\) and \\(x'\\) are of the same length and only differ by one token at position \\(j\\), from token \\(a\\) in \\(x_0\\) to token \\(b\\) in \\(x'\\). Let \\(E_0\\) be the one-hot encoding of \\(x_0\\) and \\(E'\\) be the one-hot encoding of \\(x'\\), therefore, \\(E' = (E' \u2013 E_0) + E_0\\). Let \\(v_{abj} = (E' \u2013 E_0)\\), then \\(E' = v_{abj} + E_0\\).\nBecause \\(x_0\\) and \\(x'\\) only differ by one token at position \\(j\\), then \\(v_{abj} \\in \\mathbb{R}^{n \\times d}\\) is of the form\n\\[(0, . . ., (0, . . ., -1, . . ., 1, . . ., 0)_j, . . ., 0).\\"}]}