{"title": "Leveraging LLM for Automated Ontology Extraction and Knowledge Graph Generation", "authors": ["Mohammad Sadeq Abolhasani, Arizona State University", "Rong Pan, PhD, Arizona State University"], "abstract": "Extracting relevant and structured knowledge from large, complex technical documents within the Reliability and Maintainability (RAM) domain is labor-intensive and prone to errors. Our work addresses this challenge by presenting OntoKGen, a Genuine pipeline for Ontology extraction and Knowledge Graph (KG) generation. OntoKGen leverages Large Language Models (LLMs) through an interactive user interface guided by our adaptive iterative Chain of Thought (CoT) algorithm to ensure that the ontology extraction process and, thus, KG generation align with user-specific requirements. Although KG generation follows a clear, structured path based on the confirmed ontology, there is no universally correct ontology as it is inherently based on the user's preferences. OntoKGen recommends an ontology grounded in best practices, minimizing user effort and providing valuable insights that may have been overlooked, all while giving the user complete control over the final ontology. Having generated the KG based on the confirmed ontology, OntoKGen enables seamless integration into schemeless, non-relational databases like Neo4j. This integration allows for flexible storage and retrieval of knowledge from diverse, unstructured sources, facilitating advanced querying, analysis, and decision-making. Moreover, the generated KG serves as a robust foundation for future integration into Retrieval-Augmented Generation (RAG) systems, offering enhanced capabilities for developing domain-specific intelligent applications.", "sections": [{"title": "1 INTRODUCTION", "content": "The complexity and volume of records and technical documents have been rapidly increasing across various engineering fields, including the semiconductor sector. These documents, essential for ensuring equipment's reliability and maintainability (RAM), often span hundreds of pages and encompass a broad array of topics. Engineers need to quickly access and locate specific information without sifting through entire sources and documents to find their desired information, where key details may be buried within extensive technical manuals. Beyond merely retrieving information, they also require tools to visualize data, uncover hidden relationships, and make inferences to support decision-making. This highlights the necessity for an efficient, automated system capable of extracting, organizing, and leveraging this knowledge for various analytical purposes, which is the primary motivation behind developing an LLM-assisted platform.\nTransforming knowledge into a graspable form that is easy to transmit, and process is vital for effective operations. Knowledge Graphs (KGs) are pivotal in organizing and representing this knowledge [1]. KGs enable the seamless connection of vast amounts of heterogeneous information buried in engineering documents, offering a unified view that facilitates predictive maintenance, failure analysis, and decision-making. By linking different pieces of information, KGs enhance the ability to uncover hidden patterns and relationships, leading to improved operational efficiency and reduced downtime.\nOntologies provide the structural foundation for describing and structuring domain knowledge within KGs, representing the entities and relationships specific to the technical documents. However, constructing ontologies and KGs has traditionally required extensive collaborative and interdisciplinary efforts, often demanding significant time and expertise [2]. LLMs offer a promising solution by automating the extraction of ontologies and the generation of KGs as they encode rich world and domain-specific knowledge, enabling efficient information extraction through well-designed prompting techniques [3]."}, {"title": "2 LITERATURE REVIEW", "content": "The expertise required in graph structures, web technologies, existing models, vocabularies, rule sets, logic, and best practices poses significant challenges in constructing meaningful KGs. Meyer et al. (2024) investigated the potential of ChatGPT to address these challenges, demonstrating that ChatGPT can automatically generate KG, though validation and refinement were often required to ensure accuracy. Tahsin et al. (2024) used LLMs to tackle the problem of formalizing knowledge from unstructured maintenance work orders. They proposed a framework for creating semantic KGs using a Simple Knowledge Organization System (SKOS) thesaurus extended with a fine-tuned LLM. Kommineni et al. (2024)"}, {"title": "3 METHODOLOGY", "content": "OntoKGen is designed to generate KGs that are tailored specifically for the RAM domain. OntoKGen integrates OpenAI's API to harness the power of LLMs to automate the extraction of domain-specific ontologies and generate KGs based on user inputs without requiring local computational resources. At the core of the OntoKGen (as shown in Figure 1) is an interactive conversational interface, which engages the user in a dialogue to gather the necessary information for ontology extraction and, subsequently, KG generation."}, {"title": "3.1 Overview of the Proposed System", "content": "OntoKGen is designed to generate KGs that are tailored specifically for the RAM domain. OntoKGen integrates OpenAI's API to harness the power of LLMs to automate the extraction of domain-specific ontologies and generate KGs based on user inputs without requiring local computational resources. At the core of the OntoKGen (as shown in Figure 1) is an interactive conversational interface, which engages the user in a dialogue to gather the necessary information for ontology extraction and, subsequently, KG generation."}, {"title": "3.2 Chain of Thought (CoT) Prompting", "content": "Wei et al. (2023) introduced the concept of chain-of- thought prompting as a strategy that enhances the reasoning capabilities of language models by breaking down complex tasks into smaller, manageable steps. This approach enables the model to solve intricate problems more effectively by generating intermediate steps that lead to the final solution.\nConventional CoT prompting often involves adding brief instructions like \"Let's think step by step\" at the end of a prompt. This simple addition encourages the language model to record its reasoning process sequentially, which helps reduce errors and hallucinations.\nOur approach goes further by not only asking the LLM to perform tasks step-by-step but also clearly defining each step. We incorporate our adaptive iterative CoT algorithm to ensure that the LLM executes tasks with consistency and precision. This methodology builds on the strengths of CoT prompting while adding rigor through explicitly defined steps, significantly improving the reliability and accuracy of the KG generation."}, {"title": "3.3 Ontology Extraction", "content": "Ontology extraction is a key component of OntoKGen, providing a structured framework that directs the knowledge graph (KG) generation process. An ontology defines concepts (nodes), relationships (edges), and the attributes (properties) of these nodes. Without an ontology, the KG would lack the necessary structure and coherence, making it difficult to extract meaningful insights and perform reliable analyses. Specifying the concepts and relationships in advance helps avoid ambiguities and ensures the integrity of the final KG."}, {"title": "3.4 Knowledge Graph Generation", "content": "Compared to the ontology extraction, which requires significant user interaction, the KG construction is more automated, as the ontology now serves as the structural blueprint for the KG generation and reflects all user-specific requirements. Our adaptive iterative CoT algorithm includes comprehensive steps and considerations to reduce the need for user intervention while allowing for necessary adjustments.\nOnce the ontology is confirmed, OntoKGen moves forward with the KG generation based on the algorithm illustrated in Figure 3. The ontology serves as a blueprint, ensuring the KG is generated with a clear and consistent representation of domain-specific knowledge. This process is crucial for creating a coherent and structured KG that accurately reflects the information extracted from the text."}, {"title": "3.5 User Interface", "content": "The user interface is a critical component of OntoKGen, designed to facilitate smooth and efficient interaction between the user and the LLM. It guides users through the entire process of ontology extraction and KG generation, designed based on the best practices rooted in manual ontology extraction and knowledge discovery.\nThrough this interface, users can iteratively refine both the ontology and KG. This continuous engagement throughout the process keeps users involved in every step and significantly minimizes rework. The LLM uses the entire conversation history, drawing on both past and current user inputs, to maintain context, reduce errors and hallucinations, and improve the overall quality of the final KG.\nWe also leverage LLM to assist users in generating useful queries during the process. Users may need help remembering specific definitions, identifying concepts, or even some quick suggestions, and the LLM can provide valuable assistance in these areas. This collaborative environment allows users to benefit from the LLM's general knowledge and reasoning capabilities. Our user interface also maintains contextual awareness throughout the process. Even if off-topic questions arise from the user (Figure 4), OntoKGen is designed to address them briefly and then guide the user back to the current stage of the KG generation to ensure that the user remains on track."}, {"title": "3.6 Cypher Query Generation", "content": "Once the KG generation is complete, upon user confirmation, OntoKGen facilitates the transition of the KG to the Neo4j, a non-relational database with a flexible schema, using Cypher Query. By utilizing the MERGE command, the system ensures that nodes, relationships, and properties are created simultaneously. This prevents issues such as trying to create relationships for non-existent nodes and avoids duplicating nodes. This automated transition extends database utilization, which enables advanced querying, visualization, and inference via the generated KG within the Neo4j."}, {"title": "4 CASE STUDY", "content": "This case study demonstrates the implementation of OntoKGen within the RAM domain. It showcases the effectiveness and flexibility of OntoKGen in extracting and structuring domain-specific knowledge."}, {"title": "4.1 Problem Definition", "content": "The main challenge addressed in this case study involves the extraction of relevant and structured knowledge from large, complex technical documents within the RAM domain, specifically focusing on semiconductor manufacturing equipment. Traditional knowledge extraction methods are both labor-intensive and error-prone, often resulting in incomplete or inconsistent knowledge representations. Additionally, users"}, {"title": "4.2 Data Collection", "content": "For this case study, the document titled Background Statement for Semiconductor Draft Document 6578 was used as the primary source for comprehensive text. Due to its length and technical complexity, manually extracting relevant information and constructing a KG from this document would be a challenging task. The document contains text, tables, and graphs with the primary focus on the textual content, which formed the basis for ontology extraction and KG generation.\nInitially, users interact with OntoKGen by providing targeted knowledge that specifies their area of interest within the RAM domain. The targeted knowledge can range from a straightforward query, such as 'I want to know about equipment states' to more detailed one or even a part of the comprehensive text. For instance, in this case study, the targeted knowledge included definitions of concepts like \"Productive State (PRD)\" and associated activities and sub-states. OntoKGen used this input to structure the ontology and then generate a KG by reviewing the comprehensive text for relevant instances that align with the confirmed ontology."}, {"title": "4.3 Ontology Extraction Process", "content": "The ontology extraction process in this case study demonstrates the interactive and iterative nature of OntoKGen. The process begins by prompting the user to provide either a predefined ontology or a short text specifying the targeted knowledge. Based on the user's input, OntoKGen suggests additional concepts to ensure broader coverage. For example, in this case study, the user initially provided the concept of \"Productive State (PRD)\" along with related activities. OntoKGen proposed expanding the scope by including higher- level concepts such as \"Equipment System,\" demonstrating its ability to refine and enhance the ontology for greater consistency and coverage.\nUpon user confirmation of the identified concepts, OntoKGen then identified relationships between the confirmed concepts, such as \"Has State,\" \"Has Metric,\" and \"Has Activity.\" User feedback is integrated to refine these relationships, including hierarchical associations within equipment states or activities tied to sub-states. OntoKGen then, carried out relationship confirmation by presenting the identified relationships to the user for final approval.\nFinally, the system reviews the targeted knowledge to identify additional attributes for nodes beyond id and name, such as a \"brief explanation,\" and suggests these enhancements to the user to improve clarity. Upon user approval on the properties, OntoKGen presents the complete ontology for final approval, ensuring that the final ontology is accurate, comprehensive, and tailored to the user's specific needs, establishing a solid foundation for the subsequent KG generation phase.\nThe final confirmed ontology for this case study comprised the following key elements:\nConcepts: Equipment System, Equipment States (e.g., Productive State, Scheduled Downtime State), Sub-States (e.g., SDT preventive maintenance, SDT setup), Activities (e.g., Regular production, Rework), Metrics (e.g., Equipment- Dependent Metrics)\nRelationships: Has State, Has Sub-State, Has Activity, and Has Metric.\nProperties: Mandatory properties for each node (name, id), with user-specified attributes \"brief explanation\"."}, {"title": "4.4 Knowledge Graph Generation Process", "content": "The KG generation process begins once the final ontology is confirmed by the user. OntoKGen then requests the comprehensive text, in this case \"Background Statement for Semiconductor Draft Document 6578\". Following the adaptive iterative CoT algorithm, OntoKGen carries out KG generation in two main phases: Creation and Review.\nPhase 1: Creation\nThe system first reviews the confirmed ontology and begins by identifying relevant concepts and relationships from the comprehensive text\nStep 1: Identify Concepts\nOntoKGen starts by examining the comprehensive text to find instances that match the first concept in the ontology, such as \"Equipment System.\" A node is created for each identified instance, with properties including an ID, name, and a brief explanation. For example, a node for \"Equipment System\" may have the following properties:\n\u2022\tNode: Equipment System\n\u2022\tProperties: {id: \"equipmentSystem1\", name:\n\t\"Equipment System\", briefExplanation: \"Central node\n\tcontaining all equipment states, activities, and\n\tmetrics.\"}\nThe system then identifies the next concept in the ontology, such as \"Equipment States,\" and repeats the process iteratively until all concepts are covered.\nStep 2: Identify Relationships\nOntoKGen then identifies the first relationship in the confirmed ontology, carefully reviews the text to find instances that align with this relationship and creates relationships between the corresponding nodes. For example, the relationship \"Has State\" is made between \"Equipment System\" and Productive State (PRD)\" based on the information in the text.\nOntoKGen then identifies the next relationship in the ontology and repeats the process until all relationships are covered.\nStep 3: Identify Properties\nThe system then reviews the confirmed ontology to identify properties for each concept, adding properties to the corresponding nodes. Then, the process is repeated until all properties are covered. This ensured that all relevant properties were accurately represented in the KG."}, {"title": "Phase 2: Review", "content": "OntoKGen reviews the entire comprehensive text again to ensure all instances and relationships mentioned in the text, which align with the ontology, are represented in the KG. Any missing nodes or relationships are added as required.\nStep 5: Review the Graph\nFinally, the system performs a final review of the entire constructed KG to ensure all nodes, relationships, and properties are correctly represented according to the confirmed ontology and the text. It checks for unconnected nodes and adds necessary relationships to ensure a fully connected graph.\nThroughout this process, the system strictly adheres to several additional predefined rules, such as using human- readable names, abbreviations, and identifiers, to maintain uniformity and set a solid foundation for further querying and analysis."}, {"title": "4.5 Cypher Query Generation", "content": "After generating the KG based on the confirmed ontology and comprehensive text, the final step in the pipeline prompts the user to specify whether Cypher queries are needed to import the generated KG into Neo4j.\nUpon approval, OntoKGen generates the necessary Cypher queries using the MERGE command to create nodes and relationships simultaneously to prevent issues such as duplicate nodes or attempts to create relationships for non-existent nodes. Then, the complete Cypher commands are provided for execution in Neo4j."}, {"title": "4.6 Results and Discussion", "content": "The generated KG in Neo4j demonstrates OntoKGen's ability to transform comprehensive technical documents into structured, actionable knowledge. Figures 5 and 6 provide visualizations of the generated KG. The KG includes various nodes, relationships, and properties, and the following are some key examples from the KG highlighting essential benefits.\nCentral Node\nThe Equipment System node serves as the central hub, connecting all other nodes in the graph. This centralization enables the interconnection of all relevant data points, providing a holistic view of the equipment's states, activities, and metrics.\nInterconnected Equipment States\nRelationships between the Equipment System and various Equipment States (e.g., Productive State) allow users to easily navigate between different nodes, in this case states, and understand their connections and dependencies.\nDetailed Sub-States and Activities\nLinking sub-states and activities to their respective equipment states provides a detailed breakdown of the equipment's operational context. This granularity allows users to pinpoint specific activities and sub-states that impact equipment performance, facilitating targeted analysis and improvements."}, {"title": "Comprehensive Metrics", "content": "Metrics nodes connected to the Equipment System enable users to evaluate performance metrics in context. This integration supports comprehensive performance analysis, helping to pinpoint areas for potential improvement."}, {"title": "Accuracy and Completeness", "content": "The generated KG accurately reflects the information provided in the comprehensive text. Every concept, sub-state, activity, and metric is correctly represented, showcasing OntoKGen's effectiveness in extracting and structuring domain- specific knowledge."}, {"title": "Efficiency", "content": "The automated process significantly reduces the manual effort required to construct a KG from lengthy and complex documents. OntoKGen's capability to dynamically update and refine the ontology based on user input ensures the final KG is comprehensive and tailored to the user's needs."}, {"title": "User Interaction", "content": "While the KG generation phase required minimal user interaction, the initial ontology extraction phase ensured that all user-specific requirements were incorporated. This balance between automation and user involvement enhances both the efficiency and accuracy of the final KG."}, {"title": "Integration into Neo4J", "content": "The generated KG in Neo4j serves as a powerful tool for exploring and analyzing RAM-related data. OntoKGen's ability to transform extensive technical documents into structured knowledge not only saves time and reduces errors but also provides a comprehensive, user-tailored knowledge graph that supports advanced data operations and insights."}, {"title": "5 CONCLUSION AND FUTURE WORKS", "content": "In this paper, we demonstrated how OntoKGen facilitates ontology extraction and KG generation within the Reliability and Maintainability domain, specifically applied to semiconductor equipment. OntoKGen's interactive approach, combined with our adaptive iterative CoT algorithm, ensures that the ontology and generated KG are tailored to user-specific requirements, resulting in a structured and meaningful knowledge representation.\nBy automating the extraction process and incorporating user interaction at critical stages, OntoKGen significantly reduces manual effort and minimizes errors. The generated KGs provide a robust framework for advanced querying, analysis, and decision-making. Additionally, these KGs enhance inference capabilities by revealing relationships that might otherwise be difficult to identify manually. Furthermore, KGs constructed in various domains can serve as valuable sources for Retrieval-Augmented Generation (RAG) applications, paving the way for creating more intelligent domain-specific AI systems in the future.\nFor this paper, we employed a human-in-the-loop approach to evaluate the performance of OntoKGen. Although we have set the foundation for competency question answering to evaluate the method's accuracy, conducting this quantitative analysis and presenting those results are beyond the scope and limitations of this paper. Therefore, they will be addressed in future work.\nOur Future work will focus on leveraging the generated KGs as sources in Retrieval-Augmented Generation (RAG) systems, enhancing the development of more intelligent and domain-specific AI solutions. Additionally, we aim to implement live data manipulation directly from the interactive interface, enabling users to update and modify the KG dynamically. These advancements will significantly enhance the intracavity and usability of the system, making it a more powerful tool for knowledge management and decision- making."}]}