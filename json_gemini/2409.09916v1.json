{"title": "SFR-RAG: Towards Contextually Faithful LLMs", "authors": ["Xuan-Phi Nguyen", "Shrey Pandit", "Senthil Purushwalkam", "Austin Xu", "Hailin Chen", "Yifei Ming", "Zixuan Ke", "Silvio Savarese", "Caiming Xiong", "Shafiq Joty"], "abstract": "Retrieval Augmented Generation (RAG), a paradigm that integrates external\ncontextual information with large language models (LLMs) to enhance factual\naccuracy and relevance, has emerged as a pivotal area in generative AI. The LLMs\nused in RAG applications are required to faithfully and completely comprehend the\nprovided context and users' questions, avoid hallucination, handle unanswerable,\ncounterfactual or otherwise low-quality and irrelevant contexts, perform complex\nmulti-hop reasoning and produce reliable citations. In this paper, we introduce SFR-\nRAG, a small LLM that is instruction-tuned with an emphasis on context-grounded\ngeneration and hallucination minimization. We also present ContextualBench,\na new evaluation framework compiling multiple popular and diverse RAG\nbenchmarks, such as HotpotQA and TriviaQA, with consistent RAG settings\nto ensure reproducibility and consistency in model assessments. Experimental\nresults demonstrate that our SFR-RAG-9B model outperforms leading baselines\nsuch as Command-R+ (104B) and GPT-40, achieving state-of-the-art results in 3\nout of 7 benchmarks in ContextualBench with significantly fewer parameters. The\nmodel is also shown to be resilient to alteration in the contextual information and\nbehave appropriately when relevant context is removed. Additionally, the SFR-\nRAG model maintains competitive performance in general instruction-following\ntasks and function-calling capabilities.", "sections": [{"title": "Introduction", "content": "Retrieval Augmented Generation (RAG) has recently garnered significant attention as one of the\nmost prominent areas of research in generative AI [53, 54], driven by the latest advancements in\nfoundational large language models (LLMs) [4, 39, 29, 30, 40, 9, 14, 2]. RAG frameworks are well-\nsuited for solving knowledge-dependent problems or questions, where external contextual information\nis provided and the generated answer is expected to be factually grounded on the contextual cues. In\npractice, the RAG setup is designed such that a generator LLM works in tandem with a knowledge\nretriever. The retriever [26, 46, 5, 21] is tasked with retrieving passages relevant to a given query from\na database of documents (potentially the entire internet). The LLM interacts with users, formulates\nqueries for the retriever to gather knowledge, and finally answers users' questions. To retrieve the\nmost accurate context information, the retriever typically relies on an embedding model [28, 26, 5, 21],\nand optionally employs a re-ranker to get a refined list of context documents [24]. Recent research\nhas also led to the development of more sophisticated RAG frameworks [1, 13, 22, 47, 16, 45] that\ninvolve multiple inference steps to improve the reliability of answers."}, {"title": "SFR-RAG", "content": "In this work, we focus our efforts on the generator LLM component of the RAG framework.\nTraditional general-purpose LLMs trained for chat often struggle when directly applied to the\nRAG framework. This can be attributed to several potential factors, including:\n\u2022 The knowledge in the context obtained from the retriever might conflict with the training data used\nfor the LLM.\n\u2022 The LLM is not trained to deal with conflicting or redundant facts from the retriever.\n\u2022 In scenarios where the retrieved knowledge is insufficient, the LLMs revert to answering questions\nbased on its training data.\n\u2022 It may also fail to provide adequate citations or to call appropriate functions and parameters to\nretrieve appropriate contexts in an agentic environment [50], in which the model may use provided\nfunctions or tools to perform tasks.\nRecent attempts have focused on training LLMs specifically tuned to succeed in the RAG framework,\nsuch as Command-R(+) [36] and RAG-2.0 [37]. Such RAG-specific LLMs not only serve as the\nfoundation for generating up-to-date and factual AI responses, but also enable quick adoption in\ndifferent domains, avoid the need to increase model capacity, context length or fine-tune an LLM on\npotentially proprietary data.\nIn this work, we introduce SFR-RAG\u00b9, a 9-billion-parameter language model trained with a significant\nemphasis on reliable, precise and faithful contextual generation abilities specific to RAG and relevant\nagentic tasks. Beyond contextual tasks, SFR-RAG is also trained to serve as a competitive AI\nassistant in regular tasks [12, 7]. We develop a comprehensive recipe, on both data synthesis and\ntraining procedures, to train the base LLM so that it is familiar and adaptable to diverse real-life\nRAG use cases. This includes precise factual knowledge extraction, distinguishing relevant against\ndistracting contexts, citing appropriate sources along with answers, producing complex and multi-hop\nreasoning over multiple contexts, consistent format following, as well as refraining from hallucination\nover unanswerable queries. SFR-RAG is also equipped with function calling and agentic abilities,\nwhich enable it to proactively search for knowledge from external tools, as well as conduct complex\ninference and reasoning strategies similar to Self-RAG [1], ReAct [50] and alike [22, 51, 20, 34]."}, {"title": "SFR-RAG", "content": "In this section, we provide more insights into SFR-RAG. First, we introduce a novel chat template\ncomprising two new chat roles with specific functions (\u00a72.1). Then, we briefly discuss the training\nprocess of SFR-RAG (\u00a72.2)."}, {"title": "SFR-RAG Chat Template", "content": "Most instruction-tuned language models often feature a chat template that allows for three\nconversational roles: (i) System role, typically specified once at the beginning, is used to define the\ngeneral characteristics of the AI assistant with general instructions on how to respond to user inputs,\n(ii) User role specifies where user messages reside, and (iii) Assistant turn is where the model\nresponds to the user's query in accordance to the guidelines given by the System turn.\nHowever, as more complex applications with (potentially multi-step) retrieval or function calling are\nbeing employed, such roles may have to handle increasingly complex and confusing data formats.\nFor example, in retrieval tasks, external context information may be injected into the System or\nUser turn, or may even form a part of the Assistant turn if the context is retrieved following a"}, {"title": "SFR-RAG Fine-tuning Process", "content": "One of the most important goals of SFR-RAG is to make full use and complete comprehension\nof any provided contextual information in the real-world RAG scenarios. This trait includes many\ncapabilities, among which are (i) extracting relevant information from arbitrary long contexts,\n(ii) recognizing the lack of relevant information and abstaining from hallucinated generation,\n(iii) recognizing potential conflicting information in contextual passages, and (iv) being resilient to\ndistracting, counter-intuitive information or contents that are out-of-distribution from the pre-training\nprocess. We fine-tuned SFR-RAG via standard supervised fine-tuning and preference learning\n[40, 9, 31], using extensive instruction-following data that mimic real-world retrieval question\nanswering applications."}, {"title": "Evaluation", "content": "There are already several evaluation protocols available to measure performance of LLMs and RAG\nsystems on contextual understanding across different domains and complexities [15, 23, 25, 49, 13,\n42, 6, 18]. However, prior studies [36, 37, 1, 50] have reported results on non-overlapping measures,\ndatasets and inconsistent setups, especially on which contextual content to present to the LLMs and\nmodel hyper-parameters. This causes challenges in directly comparing results from different studies.\nTo offer a better common ground, we propose ContextualBench, which is primarily an aggregation\nof 7 popular contextual question answering tasks, namely HotpotQA, TriviaQA, TruthfulQA, PopQA,\n2WikiHopQA, Musique and Natural Questions (NQ) [15, 23, 25, 49, 13, 42, 18]. There are a few key"}, {"title": "Dataset Specific Settings", "content": "For 2WikiHopQA, HotpotQA and Musique, the context documents are\nalready provided for each question, so we use them directly as contextual sources. For TriviaQA,\nTruthfulQA, and NQ, the questions come with their respective Wikipedia article or source URL. We\nscraped the web content from these sources and used Cohere embedding [35] to retrieve top-10 chunks\nfrom the contextual sources where each chunk is 512 tokens long. Meanwhile, PopQA itself does not\ncome with context documents, so we make use of the off-the-shelf context documents produced by\nthe Self-RAG retriever [1]. For each task, we use the test set if they are complete with gold labels,\notherwise we use the entire validation set to measure models' performance. This is different from\nCommand-R's report [36], where HotpotQA evaluation was conducted on a 100-sample subset of\nvalidation set, with no details about the context documents disclosed.\nNote that ContextualBench contains popular existing benchmarks, such as TriviaQA and TruthfulQA,\nwhere evaluation utilizes certain contexts to which models are expected to be faithful. That is,\nmodels are expected to utilize only the information found in such contexts, in contrast to traditional\nclosed-book QA settings, where the parametric knowledge of LLMs are evaluated sans provided\ncontexts. In other words, the presence of these contexts may cause the scores to differ significantly."}, {"title": "Experimental Results on ContextualBench", "content": "Table 1 compares the performance of our 9B SFR-RAG model on ContextualBench against state-\nof-the-art large models as well as comparable ones across the 7 question answering tasks. PopQA\nscores are measured in easy matching, while the remaining are measured in exact matching. As\nshown, GPT-40 [30] unsurprisingly aces most of the benchmarks. However, given its small size, our\nSFR-RAG-9B model significantly outperforms strong open-source baselines such as Command-R\nand Command-R+ that have up to 10 times larger parameter counts. Remarkably, it achieves the\nstate of the art in TruthfulQA, 2WikihopQA and HotpotQA in contextual settings. Overall, it also\nachieves the state of the art average performance, demonstrating our model's strong ability across\nmany contextual tasks. In particular, our model excels at 2WikiHopQA, with nearly a 25% increase\nin performance compared to GPT-40. Meanwhile, our 9B model consistently outperforms Llama-3.1\n8B Instruct and gemma-2-9b-it across most benchmarks."}, {"title": "Resilience to Unanswerable, Conflicting and Counterfactual Contexts", "content": "Because most QA benchmarks are realistically based on real-world facts, understanding LLMs\nperformance in contextual QA tasks may be ambiguous because high scores may be attributed to\neither (i) the ability to seek accurate facts from the contextual documents and content, or (ii) the"}, {"title": "Standard Benchmarks", "content": "We also evaluate our SFR-RAG model in the traditional few-shot prompting benchmarks [12, 7] to\nmeasure its parametric knowledge as well as general instruction following and reasoning abilities.\nUsing the similar setups in the Open LLM leaderboard [3], we employ the standard evaluation harness\n[11] to evaluate our model in MMLU (5 shots), GSM8K (5 shots with strict matching), Winogrande\n(5 shots), TruthfulQA (0 shot MC2), Hellaswag (10 shots with normalized accuracy) and ARC-C (25\nshots with normalized accuracy) [12, 7, 33, 23, 52, 6].\nAs shown in Table 2, our SFR-RAG model performs competitively in terms of world knowledge,\ncommon sense and reasoning abilities, despite the fact that it is optimized for contextual and retrieval\nuse cases. Particularly, our 9B model outperforms Command-R [36] with 35B parameters in MMLU,\nGSM8K, TruthfulQA as well as ARC-C. Meanwhile it remains competitive to Llama-3.1-Instruct [9]\nand gemma-2-9b-it [38]."}, {"title": "Conclusion", "content": "We present SFR-RAG, a LLM fine-tuned with an emphasis on faithful contextual comprehension and\nunderstanding for retrieval augmented generation applications. The SFR-RAG model is trained to\nminimize hallucination, effectively handle unanswerable, counterfactual or low-quality and irrelevant\ncontexts. It is also capable of performing complex multi-hop reasoning and producing citations\nreliably and accurately. We also introduce ContextualBench, which is a compilation of various\npopular RAG benchmarks evaluated under consistent and appropriate settings. The experiments show"}]}