{"title": "Feature Importance in Pedestrian Intention Prediction: A Context-Aware Review", "authors": ["Mohsen Azarmi", "Mahdi Rezaei", "He Wang", "Ali Arabian"], "abstract": "Recent advancements in predicting pedestrian crossing intentions for Autonomous Vehicles using Computer Vision, particularly Deep Neural Networks (DNNs) are promising. However, the black-box nature of DNNs poses challenges in understanding how the model works and how input features contribute to final predictions. This lack of interpretability delimits the trust in model performance and hinders informed decisions on feature selection, representation, and model optimisation; thereby affecting the efficacy of future research in the field. To address this, we introduce Context-aware Permutation Feature Importance (CAPFI), a novel approach tailored for pedestrian intention prediction. CAPFI enables more interpretability and reliable assessments of feature importance by leveraging subdivided scenario contexts, mitigating the randomness of feature values through targeted shuffling. This aims to reduce variance and prevent biased estimations in importance scores during permutations. We divide the Pedestrian Intention Estimation (PIE) dataset into 16 comparable context sets, measure the baseline performance of five distinct neural network architectures for intention prediction in each context, and assess input feature importance using CAPFI. We observed nuanced differences among models across various contextual characteristics. The research reveals the critical role of pedestrian bounding boxes and ego-vehicle speed in predicting pedestrian intentions, and potential prediction biases due to the speed feature through cross-context permutation evaluation. We propose an alternative feature representation by considering proximity change rate for rendering dynamic pedestrian-vehicle locomotion, thereby enhancing the contributions of input features to intention prediction. These findings underscore the importance of contextual features and their diversity to develop accurate and robust intent-predictive models.", "sections": [{"title": "I. INTRODUCTION", "content": "THE integration of autonomous vehicles (AVs) into urban environments is a revolutionary shift in transportation, which enhances safety, efficiency, and accessibility. Central to the safe operation of AVs is their ability to accurately anticipate pedestrians' actions and respond timely, particularly when pedestrians crossing actions are likely. In recent years, there has been growing research interest in pedestrian intention prediction [1]\u2013[3], thanks to the enhancement of Computer Vision techniques, particularly through learning-based methodologies like deep neural networks (DNNs), on relevant tasks including pedestrian detection [4], human action recognition [5], trajectory and scene prediction [6].\nPedestrian intention prediction models typically function in two main stages. In the first stage, they extract visual cues and feature representations from sequential video images, capturing the characteristics of the pedestrian such as their moving trajectory, appearance attributes, body pose, and contextual information from the surrounding environment, including a semantic map of the entire scene [7], [8]. In the second stage, a DNN model processes these extracted features by analysing their spatial and temporal dimensions using specific fusion strategies, which collaboratively contribute to intention prediction [9].\nWhile DNNs appear effective in intention prediction, their black-box nature poses challenges in understanding the contribution of each input feature to the final prediction [10]. This lack of interpretability hinders the transparency and reliability of pedestrian intention prediction systems, necessitating the development of methods to elucidate the decision-making mechanisms of these models. Moreover, this interpretability can provide insights into how the model works and aid in informed decisions on feature selection, representation, and model optimisation.\nRecent studies on pedestrian intention prediction, often include ablation studies that simplify input feature sets. They train models on different combinations of feature sets and then determine which model performs better [11]\u2013[14]. Feature"}, {"title": "II. BACKGROUND", "content": "This section initially provides a broad overview of deep neural network (DNN) architectures commonly used in predictive models for pedestrian crossing intentions. We then discuss these models' input features and fusion approaches. Table I outlines the following subsections and the candidate models utilised in this study for feature analysis.\nA. Model Architectures\nDistinct strengths in capturing complex patterns of pedestrian behaviour, environmental context, and traffic dynamics are evident in each DNN architecture. For instance, convolutional neural networks (CNNs) excel at extracting spatial features from images, revealing visual information, such as recognising traffic users [20], pedestrian actions [13], and intentions [2]. While conventional CNNs, which use 2D convolution operators, may struggle with sequential data, 3D CNNs show improved performance instead in intent-predictive models [8], [13], [16], [21], [22].\nRecurrent neural networks (RNNs) are effective at modelling temporal dependencies, capturing the sequential nature of pedestrian dynamic behaviours through a memory mechanism, like LSTM [23] and GRU [24], that enables them to preserve information about previous inputs, rendering them suitable for predicting intentions [11], [12], [22], [25], [26].\nGraph convolutional networks (GCNs) are adept at processing graph-structured data, enabling the modelling of complex relationships between pedestrians, vehicles, and environmental factors [27]\u2013[31]. Moreover, Transformer architectures excel at capturing long-range dependencies and contextual information by leveraging self-attention mechanisms [32], making them practical in large-scale datasets of complex traffic scenes for understanding pedestrian intentions [14], [33], [34].\nHybrid architectures have also been studied to simultaneously accomplish multiple tasks for predicting pedestrian action [5], future trajectory [35], and crossing intention [36], [37]. However, the information-sharing mechanisms between different tasks in these models can complicate the assessment of the features' contribution by creating complexity in the connection between input features and output predictions.\nThe candidate models in this study, as indicated in Table I by star sign, have all approached intention prediction as a singular task and framed it as a binary classification to determine whether the pedestrian is crossing in front of the AV or not.\nB. Model Input Features\nRecent research on predictive models for pedestrian crossing intentions has explored different features concerning pedestrians, environment representation, and ego-vehicle motions to depict the interaction context between autonomous vehicles and pedestrians. For example, pedestrian bounding boxes (abbreviated as BBox) are inputted into a Transformer-based"}, {"title": "III. RELATED WORK", "content": "This section presents relevant studies evaluating input feature importance in the development of pedestrian intention"}, {"title": "IV. METHODOLOGY", "content": "This study applies the permutation feature importance (PFI) method to evaluate the importance of each input feature in five different DNN-based model architectures for predicting pedestrian crossing intention. In contrast to traditional PFI, which randomly shuffles feature values across the entire dataset, our method, Context-aware PFI (CAPFI), shuffles values within a subset of video scenarios sharing similar contextual characteristics. This section initially introduces the distribution of data samples in each context. Then, we propose our alternative feature representation of ego-vehicle locomotion. Finally, the CAPFI technique used in this study to evaluate the candidate models and their input features' importance is detailed. Figure 2 provides an overview of the candidate models and input features that we aim to evaluate for their importance in this study.\nA. Data Distribution and Subset Creation\nPedestrian Intention Estimation (PIE) dataset [25], serves as one of the largest resources for training and evaluating models to predict pedestrian crossing intention scenarios. The dataset is recorded at 30 frames per second (fps) under daylight conditions: a sunny, clear day with high-definition (HD) resolution (1920 \u00d7 1080), spanning six hours of video capturing a total of 1841 pedestrian-vehicle interaction scenarios. In each interaction sample, a critical moment is defined as the moment where both the pedestrian and the driver focus their attention on each other. All candidate models were trained to predict the pedestrian's crossing intention at this critical moment by\n1) Crossing State: This group consists of the entire test and validation samples from the dataset and the environmental context is not separated. This group is subcategorised by the intention label. Each video sample has a duration of 1 second, beginning 0.5 seconds before the critical moment and ending 0.5 seconds after the critical moment.\n2) Roadway Type: The potential variation in pedestrian behaviours, influenced by roadway type [19], is captured in this categorisation. By assessing the performance of intention prediction models against various roadway types, we can uncover the strengths and weaknesses of each model specific to the given roadway, and potentially reveal unknown risks that each model may pose to pedestrians.\n3) Traffic-Light State: Subsets are formed from video samples captured at four-way intersections and T-junctions with traffic lights. Different traffic-light states impose varying levels of constraint or permission for pedestrian crossings, influencing the pedestrian decision-making process and the\nlikelihood of crossing [55]. The prediction performance assessments provide insights into how these models respond to differences in signalisation.\n4) Crosswalk State: Crosswalk-designated areas typically offer enhanced safety and visibility for pedestrians, potentially affecting their crossing intentions compared to scenarios with no such infrastructure [56]. This differentiation is essential for assessing how accurately intent-predictive models capture the influence of designated infrastructure on pedestrian behaviour.\n5) Proximity Level: Different distance ranges may correspond to varying levels of perceived safety or risk for pedestrians, influencing their decision to cross or wait [57]. These subsets allow us to investigate models' performance across different ranges of distances from pedestrian to ego-vehicle. As the dataset doesn't include the distance parameter, we estimate the distances through a monocular depth estimation algorithm [58].\n6) Ego-Vehicle Speed: Variations in ego-vehicle speed can alter the perceived risk and urgency of crossing, thus influencing pedestrian intention [59]. Performance analysis through this group allows us to elucidate how intent-predictive models adapt to changes in vehicular motion and the predictive factors that drive pedestrian behaviour in such scenarios.\nB. Ego-vehicle Locomotion Representation\nAs depicted in Figure 4, most crossing samples occurred when the ego vehicle was either stationary or moving at a low speed. This prompts the question of whether models should prioritise this feature or not. A model trained only on speed value achieves an AUC of 0.83\u00b10.002 and F1 score 0.74\u00b10.003. Every input feature combination when it is included, F1 score increases by over 25% on average. It appears this model ends"}, {"title": "V. EXPERIMENTS", "content": "This section presents the evaluation of candidate models within the defined subsets of the PIE dataset's test and validation samples, considering specific contextual characteristics\nto measure the baseline performance for each model. Subsequently, we shift our focus to hazardous pedestrian-crossing scenarios. Following this, we evaluate the importance of input features using CAPFI across different scenario contexts. Finally, we assess the contribution of the proposed feature representation to the models' performance.\nA. Performance Evaluation\nThe performance of intent-predictive models is evaluated using standard machine learning metrics. These metrics include Accuracy (Acc), which quantifies the model's ability to accurately predict the binary classification of a pedestrian's intention to cross or not. However, accuracy alone may not be sufficient when the dataset is imbalanced, as it could be high even if the model fails to detect instances of a particular class (e.g., crossing intention). The area under the ROC curve (AUC) indicates the model's proficiency in distinguishing between two classes of crossing\" or \"not crossing\". A high AUC implies that the model can effectively prioritise instances with higher probabilities of crossing. The F1 score represents the harmonic mean of precision and recall rate. A high F1 score indicates that the model is effectively minimising both false positives (predicting a pedestrian intends to cross when they don't) and false negatives (failing to predict when a pedestrian intends to cross), thus contributing to pedestrian safety by reducing both types of errors.\nB. High-Risk Crossing Scenarios\nWe identify combinations of subsets that result in high-risk scenarios for pedestrians if the intent-predictive model underperforms to detect their intentions correctly with a very low Accuracy (Acc) and F1 score. For instance, in $S_C \\cap S_{Acc}$ scenario, the context is when the pedestrian intends to cross and the vehicle is accelerating towards it. Another instance (scenario C) involves $S_C \\cap S_{MB} \\cap S_{NZC} \\cap S_{Const}$, where the pedestrian intends to cross at a non-designated midblock, and the ego vehicle has not changed or decreased its speed.\nC. Analytical Review on Feature Importance\nWe initially calculated the permutation feature importance scores for the candidate models, using the entire test and"}, {"title": "VI. CONCLUSION", "content": "In this study, we conducted a comprehensive evaluation of five architecture-distinct intent-predictive models for pedestrian crossing scenarios using the Pedestrian Intention Estimation (PIE) dataset. Our experiments included context-aware performance evaluation, analysis of high-risk crossing scenarios, and assessment of input feature importance and ego-vehicle motion representations. The performance evaluation revealed nuanced differences among candidate models across various contextual characteristics. Generally, models performed better in scenarios with decreasing ego-vehicle speed, designated crosswalks, and red traffic lights. However, midblock scenarios posed significant challenges, resulting in the lowest performance in cooperation with baseline performance. Identifying high-risk crossing scenarios highlighted potential hazards if models fail to accurately detect pedestrian intentions, emphasising the importance of robust predictive capabilities, and the lack of large-scale datasets that capture a wide array of traffic contexts and edge-case scenarios.\nAdditionally, we not only evaluated the permutation feature importance across all contexts spread in the test and validation sets but also considered context-aware permutation feature importance by subdividing contexts. This approach enabled us to obtain more interpretable and reliable feature importance assessments with reduced variance in importance scores.\nFeature importance analysis revealed the critical role of input features such as pedestrian bounding box, ego-vehicle speed, and local context features in predictive performance, and body pose is deemed less significant for models, potentially due to susceptibility to noise and occlusion. Despite variations in model architectures, there was a striking resemblance in how models responded to evaluations across various contexts and feature permutations, suggesting the fundamental relevance of certain features to the task.\nenhance predictive capabilities and pedestrian safety is crucial, as this study was limited to the most common input features used in intent-predictive models, leaving many features yet to be assessed."}, {"title": "VII. BIOGRAPHY", "content": "Mohsen Azarmi is a Ph.D. Student at the University of Leeds, Institute for Transport Studies, UK. He holds a master's degree in Artificial Intelligence & Robotics and his main research direction and expertise are Computer Vision, Deep Neural Networks, and multi-sensor data fusion with a particular focus on pedestrian activity recognition, transportation and traffic safety.\nMahdi Rezaei is an Associate Professor of Computer Vision and Machine Learning and Leader of the Computer Vision Research Group at the University of Leeds, Institute for Transport Studies. He received his PhD in Computer Science from the University of Auckland, with the Top Doctoral Thesis Award in 2014. Offering 18 years of service and research experience in academia and industry, Dr Rezaei has published 60+ journals and conference papers in top-tier venues. He is also the Principal Investigator, lead Co-Investigator, or Collaborator of multiple European, UKRI, and EPSRC AV-related projects such as L3Pilot, Hi-Drive, IAA, Research England, and MAVIS.\nHe Wang is an Associate Professor at the Department of Computer Science, University College London (UCL) and a Visiting Professor at the University of Leeds. He is the Director of High-Performance Graphics and Game Engineering and Academic Lead of Centre for Immersive Technology. His current research interest is mainly in Computer Graphics, Vision and Machine Learning and applications.\nAli Arabian received the M.Sc. degree in ergonomics from the Tehran University of Medical Sciences, in 2019. He is currently pursuing a Ph.D. degree in transport studies at the Institute for Transport Studies, University of Leeds. His current research interest is mainly in the human factors of highly automated vehicles, particularly the allocation of visual attention during the transition from automated driving and HMI design."}, {"title": "APPENDIX", "content": "This section presents detailed evaluation results of CAPFI scores for each model within specific contexts."}]}