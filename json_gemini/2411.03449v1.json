{"title": "AI Horizon Scanning - White Paper p3395\nPart III. Technology Watch: a selection of key developments,\nemerging technologies, and industry trends in Artificial\nIntelligence", "authors": ["George Tambouratzis", "Marina Cort\u00eas", "Andrew R. Liddle"], "abstract": "Generative Artificial Intelligence (AI) technologies are in a phase of unprecedented\nrapid development following the landmark release of Chat-GPT, which brought the phe-\nnomenon to wide public attention. As the deployment of AI products rises geometrically,\nconsiderable attention is being given to the threats and opportunities that AI technologies\noffer, and to the need for regulatory and standards initiatives to ensure that use of the\ntechnology aligns with societal needs and generates broad benefits while mitigating risks\nand threats. This manuscript is the third of a series of White Papers informing the de-\nvelopment of IEEE-SA's p3995 'Standard for the Implementation of Safeguards, Controls,\nand Preventive Techniques for Artificial Intelligence Models' [1], Chair Marina Cort\u00eas.\nThis part focuses on assessing calmly and objectively, as far as is possible, the current\nstate of Artificial Intelligence (AI) technology development and identifying predominant\ntrends, prospects, and ensuing risks. It necessarily forms a snapshot of the current instant\nof a rapidly-evolving landscape, with new products and innovations emerging continuously.\nWhile our main focus is on software and hardware developments and their corporate con-\ntext, we also briefly review progress on robotics within the AI context and describe some\nimplications of the substantial and growing AI energy demand.", "sections": [{"title": "1 Introduction", "content": "Generative Artificial Intelligence (AI) models promise a major impact on society through a\nvariety of mechanisms that will require careful development and monitoring. A characteristic\nof the most influential models, the so-called Large Language Models (LLMs) based on the\ntransformers architecture [2], is that they push at the boundaries of what is technologically\nfeasible in hardware as well as software innovation. Simply training a leading-edge model\nrequires specialist hardware at scale and major corporate resources in the range tens or even\nhundreds of millions of dollars. Even executing a query requires remote cluster-scale compu-\ntation; servicing Chat-GPT queries is estimated to cost its operator OpenAI over one million\ndollars per day. Moreover, suitable hardware for running such tasks is currently essentially a\nmonopoly of NVIDIA through its Graphics Processing Unit (GPU) technologies, with other\ncompanies struggling to build rival chipsets, such as Google with its Tensor Processing Units\n(TPU).\nThe present authors are ongoing volunteer contributors to the emerging IEEE standard\np3395 \u2018Standard for the Implementation of Safeguards, Controls, and Preventive Techniques\nfor Artificial Intelligence (AI) Models', Chair: Marina Cort\u00e9s, Vice-chair: Jayne Suess, Sec-\nretary: Janusz Zalewski [1]. As part of our horizon-scanning process to set the scene for\ndeveloping the p3395 standard, already described in our initial article [3], we have undertaken\na snapshot of the technological status and its direction of evolution, as of late Autumn 2024.\nThis article describes that snapshot.\nAdvances in terms of computing equipment during 2024 have appeared at an ever-increasing\npace to support development of more powerful AI algorithms and multi-modal generational\nmodels. Almost every week major announcements are issued regarding new products (e.g.\nspecialised hardware), services (new algorithms to support content creators), and new genera-\ntive models. This means that more powerful services become possible, but also that these will\nbe more expensive to lease and utilise. The danger of smaller research teams and countries\nbeing left out is clear, leading to the possibility of a handful of players having a dominant\nposition in the field of AI. Since AI is at a state where all content can be used for training\nalgorithms, there is a clear need to form safeguards to protect the public's safety and privacy,\nwithout which there is a risk of personal data being stored in very large models and then\ninadvertently being divulged as a response to even an accidentally-posed query.\nThe ever-increasing popularity of LLMs has made them a means of first and last recourse\nfor both entrepreneurs and students, with tasks ranging from information gathering and report\npreparation to strategic planning. The public seems in awe of the executive officers of high-tech companies (which since 2023 equates predominantly to AI-focused companies). Demand\nfor AI-based products and services appears to be almost insatiable and new products gain\nheadlines and have strong pre-sales and sales figures at least on release date. This focus"}, {"title": "2 Trend analysis: an economy-based viewpoint", "content": "The growing influence of AI is reflected in the rise in market capitalisation ranking of IT\n(Information Technology) companies/corporations in comparison to other types of companies.\nThis indicates the market focus in the particularly hot area of AI, which tends to influence\nmost areas ranging from manufacturing of goods to public services.\nA snapshot at the beginning of November 2024 shows that six US IT giants [in order\nNVIDIA, Apple, Microsoft, Alphabet (Google), Amazon, and Meta (Facebook)], all with\nsubstantial AI activities, occupy 6 of the top 7 places in the global market capitalization\nrankings [4] (the one exception being the oil company SaudiAramco, placed 6th globally).\nEighth is Taiwan's TSMC (Taiwan Semiconductor Manufacturing Company), operator of the\nworld's most advanced chip manufacturing facilities, which is a key player in AI hardware and\nmanufactures chips for numerous companies including Apple and NVIDIA."}, {"title": "2.1 Case studies", "content": "To elaborate what this means, it is worth noting that NVIDIA, the leading designer of AI-\ncritical GPU equipment, has a market capitalisation above 3 trillion USD and quarterly sales\nof 30 billion USD [5] whilst the leading manufacturer of standard computer processors (Intel)\nhas a market capitalisation of 84 billion USD and sales of 13 billion USD [6]. So despite its\nhistorical dominance of the area, now Intel is over 30 times smaller in market value and yet\nhas 40% of the income of NVIDIA, in a full reversal of the state-of-play 10 years ago. Notably,\nIntel's stock has fallen from a level of 200 to 240 billion USD in market capitalisation (Autumn\n2020) to 146 billion billion USD in April 2024 and has continued falling (as of Autumn\n2024) [7]. To put that further into perspective, the established computer manufacturer Dell\nTechnologies has a market capitalisation of 80 billion USD (again about 30 times smaller than\nNVIDIA) and 23 billion USD of quarterly sales for the second quarter of 2024 (25% fewer\nsales) [8]. So, the trend is that AI-focussed companies are viewed by investors as current\n(and future) major generators of growth. It is possible that this spectacular rise will be\nfollowed by a trough of disillusionment at some point, but no such consistent signs are visible\nto date. Recently NVIDIA shares did fall by almost 10% in a day (this being reported as the\ngreatest loss in market capitalisation) as \u201coptimism about the boom in artificial intelligence\n(AI) dampened\" [9], but they promptly bounced back in a matter of days.\nResearch in AI, predominantly coinciding with deep learning, is reliant on specialised\nhardware being available in the form of GPUs. The four main global companies manufacturing\nAI-supporting hardware are NVIDIA (currently number 1 in capitalisation), TSMC (which\nmanufactures most of NVIDIA's hardware and is currently ranked 8th in capitalization),\nBroadcom (currently number 10) and AMD (currently number 45)."}, {"title": "2.2 Fair Standard activities", "content": "It is vital that standards and regulatory activities do not inadvertently favour large companies\nin detriment of smaller ones. This might happen, for example, through standardizing the\ndelivery of multiple documentation packages which large companies can deploy large numbers\nof personnel to manufacture, but which smaller companies might struggle to comply with. It\nis a challenge to ensure that standards are fair to different countries and to differently-sized\ncompanies. Any standards-based regulation or safeguards would need to safeguard the public\ninterest without stifling progress or making compliance too costly to achieve."}, {"title": "3 AI-related hardware product releases", "content": "The latest family of NVIDIA GPUs will result in a cumulative surge of computing capabilities\nof approximately 1000 times for inference (generative) processes within a space of 8 years,\nexceeding Moore's law provisions [12]. Advanced features in the latest NVIDIA hardware\ninclude self-test and security capabilities, though how successfully this is ascertained remains\nto be disclosed. NVIDIA recently announced a business shift towards AI and an emphasis on\nsoftware (see for example this March 2024 CNBC news report [13]), providing subscription\nto proprietary software (e.g. pre-trained models) using the NVIDIA Inference Microservice\n(NIM) concept, for a fixed cost per GPU per annum. Emphasis has also been placed on\nhardware with a lower energy cost per computation unit, as discussed in our paper I [3].\nNotable hardware developments include the release by Amazon Web Services (AWS) of\ntheir latest processors for AI applications (Graviton 4 & Trainium 2), indicating the focus\ntowards custom AI chips to compete with NVIDIA hardware. However, AWS is following a\nmiddle road, also offering the use of NVIDIA chips to its customers. Google also announced\ntheir new generation of Tensor Processing Units (TPUs) called Trillium [14]."}, {"title": "4 Collaboration between companies", "content": "There is substantial upheaval as AI-related companies sense the change in paradigm and try\nto best position themselves. They establish collaborations with other players with comple-\nmentary expertise, since AI is too wide to be covered by one single player. In early 2024\nMicrosoft announced the creation of a new specialist AI division [15], hiring several scientists\nin what has been characterised as a development in the AI arms race, for instance in the\nCNBC report cited above.\nApple has announced a collaboration with OpenAI to use ChatGPT based models, to\nprovide access to sufficiently powerful LLMs. These new AI features are provided free-of-\ncharge but limited to users of upper-end iPhone PRO models (see for example Marques\nBrownlee's recap of Apple's 2024 Worldwide Developers Conference (WWDC) [16]). As noted\nin Section 3, Apple has shown a preference to using Google-designed hardware."}, {"title": "5 Developer access to pre-trained models.", "content": "Amazon (via AWS) have been promoting the Amazon Bedrock system to provide already-\ntrained generative models for use by the community to develop custom applications, via a\nsubscription scheme. Similarly, NVIDIA allow customers to access pre-trained models via\nthe NIM concept, allowing service developers to access models for a fixed cost per GPU per\nannum.\nFollowing a different LLM-to-users approach, Meta are releasing the family of LLAMA-3\nmodels for use by the community without charge, including a 400-billion parameter non-sparse\nmodel (cf. Yann LeCun interview [17]). LLAMA-3 generates output in multiple modalities\nprovided as open-source technology, in contrast to pay-per-use models [18]. Recently NVIDIA\nhas adopted a similar policy by releasing its text and image LLM model (with 72 billion\nparameters) known as NVLM-72B to the public for free non-commercial usage, while also\nproviding its code as open-source. NVLM-72B [19] is claimed to rival Chat-GPT4 in terms\nof performance and to suitably integrate text and video data to boost both tasks.\nIn April 2024, Google released new tools for developing custom LLMs [20], via the Ver-\ntex AI Model Garden, that includes the latest Gemini 1.5 model (see also the summary in\nRef. [21]). The current Gemini model has been claimed to have a larger context than previ-\nously released LLMs, by almost an order of magnitude, reaching up to 2 million tokens correct\nas of May 2024) and provide a multi-modal model (covering 'text, images, video, code, and\nmore'). Multimodality can support more complex and elaborate text-based queries, allowing\nto select for example videos that show the improvement of a child's swimming style over time."}, {"title": "6 The upcoming generation of AI models", "content": "There is intense debate on the next model(s) which will advance AI/ML. The current state-of-\nthe-art architecture is still the transformer [2], which was proposed seven years ago. Though\nvariants have been put forward, no fundamentally different paradigm to supplant it is visible\non the horizon. The transformer's designers agree [22] that the next big model \u201cwill have to be\nclearly, obviously better\u201d, to advance AI. Essential properties reported include context, token-\ngeneration ability, and adaptive computation, to reduce wasted computations depending on\nthe complexity of the task.\nYann LeCun (Meta) has stated that to advance beyond the current AI models (LLMs),\nnew architectures must reason and plan ahead rather than \u201cregurgitate reasoning\" [17]. Here,\none should probably add the efforts to create systems that perform chain-of-thought reasoning\n[23], but as the first systems of this generation (exemplified by OpenAI's \u2018o1' family of models)\nrepresent a very recent addition to operational LLMs, these are discussed in the penultimate\nsection of the present article."}, {"title": "7 Megatrends", "content": "Recently IEEE released a report on the 2024 Technology Megatrends [24], which focuses on\n3 areas, namely\n1. Digital Transformation,\n2. Sustainability,\n3. Artificial General Intelligence (AGI)."}, {"title": "8 Robotics and A\u0399", "content": "Another field in the intensifying 'AI arms race' involves highly-autonomous humanoid robots,\nwhich for instance might address shortages in the workforce and provide personalized health\ncare for the elderly and those with health conditions or impairments. Entities involved in this\neffort include OpenAI (providing mainly the human-to-robot interface), Tesla (with the Opti-\nmus product range, pitched as a general domestic helper and companion), NVIDIA's project\nGr00t which provides a general-purpose foundation model for humanoid robots [25], and\nFigure whose humanoid robot exploits this NVIDIA learning technology. Aims include \"un-\nderstanding natural language and emulating movements by observing human actions; quickly\nlearning coordination, dexterity and other skills in order to navigate, adapt and interact with\nthe real world\" [26]. This raises potential security concerns as robots come to interact widely\nwith humans and the environment in the open world as well as in situations where humans\nare most vulnerable and dependent on external help. Such setups further increase the need\nfor further safeguards being integrated in robotics-related AI products."}, {"title": "9 Selected New Initiatives", "content": "Progress in LLMs continues with emphasis on building a set of both larger models and lighter\nmodels, depending on the application. Mobile companies focus on smaller and computa-\ntionally lighter models which can outperform LLMs (for example Apple's REALM [27]) via\ncontextual information by combining modalities. In June 2024 Apple announced 'Apple Intel-\nligence', that allows the user to access more advanced interactive features sprinkled in various\nmodules of its iOS operating system. In their collaboration with OpenAI to use ChatGPT\nmodels, Apple do most of the processing on-device, or in-house on exclusively Apple silicon\n('Private Cloud Compute'), to support anonymization and data security. AI features are pro-\nvided free-of-charge but only for upper-end mobile models (see e.g. Marques Brownlee's recap\n[16] and this CNET review [28] of Apple's WWDC 2024). It is chastening to note that even\nif one buys the top-of-the-line iPhone devices in the EU, the functionalities related to Apple\nIntelligence will have been deactivated due to the EU policies towards AI [29].\nThough the business model behind such AI agents for handheld devices is not yet fully\nestablished, there is increased evidence of wider and relatively silent release to the potential\ncustomers (even without them being aware, which may raise concerns on private data usage).\nAs an example ChatGPT now provides its services freely without login requirements with the\ncaveat that user feedback may be used for training. Experts advise against releasing personal\ninformation in relevant queries. Probably, in the foreseeable future, AI-related features will be\nbundled via the operating system on high-end mobiles rather than as leased services procured\nby the user. This in turn requires safeguards in the service design to inform the user of\npossible data compromise.\nRecently OpenAI has presented GPT Strawberry and made available the ol-preview as\nwell as the lighter 01-mini LLMs [30]. This novel family of LLMs is claimed to incorporate a\nthought process that allows it to reflect and reason for some seconds before answering and is\nclaimed to reach Ph.D. level of thinking, probably including chain-of-thought reasoning [23].\nChain-of-thought reasoning has been studied by multiple research groups at both Google and\nOpenAI and is well summarised by Matthew Berman [31]: \u201cthe software pauses for a matter\nof seconds before responding to a prompt, while behind the scenes and invisible to the user,\nit considers a number of related prompts and then summarises what it considers to be the\nbest response\". Notably, during the development of this new family of LLMs, OpenAI has\ncollaborated on security issues with the U.S. and U.K. governments.\nEvaluation of the reasoning model of ol includes established exams such as the Mathe-\nmatics Olympiad (AIME tests) where ol is reported to attain a score of 83%, versus only 13%\nfor GPT-40, and emphasis is placed on tackling tasks such as software coding and deciphering\nor solving logic puzzles. The newer models seem much more capable of reasoning and of\njustifying their choices, though they have not yet been released for public use. Apparently\nthey are to be used in a high-low mix with standard LLMs used to answer easier prompts and\nmore elaborate models such as ol with much longer inference times being used to respond to\nmore difficult tasks. This strategy seems to mirror implementing a version of the 'thinking\nfast and slow structure' in human thinking strategy, which is conceptually appealing [32].\nReasoning capabilities of LLMs have been studied by the research community, to determine\nif there exist reasoning gaps between the claimed and actual accuracy obtained [33]. More\nrecently, an extensive study of limitations of current LLM models has been performed, with the\naim of determining more reliable metrics [34]. It has been found that the reasoning achieved\nis closer to sophisticated pattern-matching rather than true logical reasoning. Experiments\nclaim a drop of up to 65 percent in accuracy for state-of-the art models. Whilst the latest 'ol'\nLLMs are less susceptible to this effect, they suffer a 15+ percent drop in accuracy, indicating\nthat further research is needed to achieve true reasoning capabilities. It is also shown that\nthe injection of out-of-context statements can mislead LLMs to produce erroneous answers,\nraising doubt over dependence on such LLMs.\nIn terms of risks to humans, the development of AI models able to reason and express the\nrationale of a choice seems a positive step. There are however many potential risks including\nthe following:\""}, {"title": "10 Fuelling the technology's energy needs", "content": "Training of the very large models required by modern AI involves large computing infras-\ntructures coupled with 24/7 availability. Earlier the tendency was to place supercomputers\nin colder climates to reduce active cooling requirements and close to renewable sources, to\nuse power produced with reduced carbon footprint. For example, Reykjav\u00edk in Iceland hosts\nthe world's first zero-emission supercomputer at the Thor Data Center. This supercomputer\nrelies on completely renewable sources for its power, rather than fossil fuels.\nIn a recent reversal of this trend, Microsoft, Google, and Amazon have all announced\nplans to place datacenters next to nuclear power facilities within the US. While principally\na statement about the rapidly-growing energy demands from AI, this may also be motivated\nby a political desire to reduce dependence on globalized infrastructures in favour of national\nones. In any event the near-simultaneity of these announcements should not go unremarked.\nMicrosoft has chosen to source energy by reactivating the Three-Mile Island reactors [37],\nwhile by contrast Google and Amazon are opting to co-finance new small modular nuclear\nreactors [38, 39] (Amazon is also placing a datacentre next to an existing Pennsylvanian\nnuclear power plant). Each company are keen to emphasise the use of nuclear as a nearly\ncarbon-free form of energy, though this argument is significantly undermined by it being new\nenergy use rather than diversion of generation from fossil fuels (even if one sets aside the\nunsolved problem of very long-term safe and economic storage of nuclear waste). Moreover,\ngrowth in AI energy demand will motivate continued use of fossil-fuel generation that might\notherwise have been decommissioned, for example the speculation that China might divert\nsubstantial power output from aluminium smelting to AI datacentres [40]."}, {"title": "11 Discussion", "content": "Our snapshot captures AI technologies on a sharply-rising trajectory, with 8 of the 10 largest\ncompanies in the world strongly identified with progress in this area. What we cannot say\nat this point is whether this trajectory will be long sustained into the future, though no\nsigns of slowing down are evident at this point in time. Nevertheless, there are quite a few\nconsiderations that may come into play in the near future, which we list here.\nOn the hardware side, a danger is manufacturers being unable to keep up with demand,\nstalling progress. This may be exacerbated by the current reliance on single dominant players\nfor AI chip design (NVIDIA), advanced chip fabrication facilities (TSMC), and deep ultraviolet\nlithography equipment (ASML). It will be interesting to watch how other players enter or\nre-enter those markets, and whether China in particular can overcome import restrictions\nthrough further developing its own advanced manufacturing capabilities.\nA further possibility is that the energy infrastructure is unable to keep up with demand.\nThe recent ventures by major players into nuclear power plants [37, 38, 39], both new and old,\nfor dedicated data-center use has certainly raised concerns as well as eyebrows. The financial\nmuscle and political power of the bigger players may create energy access imbalances both\nbetween nations and amongst disadvantaged groups within nations, as well as questioning\nthe relevance of national grids. Moreover, this demand threatens to reverse the already very\nlimited progress made over the past few decades on the environmental costs of energy use,\nfor instance by motivating continued operation of ancient fossil-fuel burning plants. Indeed,\nas reported in Ref. [42], Eric Schmidt has offered the stark opinion that the environment\nis already a write-off and we that have to stake all our chips (both poker and silicon) on\nadvanced AI finding a solution. At the very least these issues could and should lead to\nsubstantial informed and public debate on the extent to which the benefits of various diverse\nAI technologies can justify the downstream environmental costs.\nOn the software side a wide spectrum of outcomes is possible. Noting that after the best\npart of a decade there has been no substantial improvement on the transformers architecture\nof Ref. [2], the current rapid rate of progress may stagnate (see for example Ref. [43]). This\ncould be worsened by a stifling of innovation if the models themselves become too expensive\nto produce, and too technically complicated, leading to a virtual monopoly of products and\nmodels by established players that new companies are unable to break into. On the opposite\nextreme the models may become so complex and powerful that the ability to provide human\ninput and guidance is lost.\nSocietal factors may also come to dominate. We already highlighted above the potential\nenvironmental impacts of AI energy use. Another relevant area is that of privacy, data security,\nand copyright, whose protection may require a substantial stemming of ambition (see our\ninitial paper [3] and references therein). AI is already under a spotlight for its ready enabling\nof both inadvertent misinformation and malicious disinformation, and its public support would\nbe further compromised if it is implicated in a future major infrastructure/supply-chain event\n(either accidental such as the July 2024 Crowdstrike event [44] or via intentional cyberattack).\nIn any event, society deserves and must insist on a strong say on the future direction of a\ntechnology which promises, or threatens, seismic transformation and which is presently under\nthe control of an alarmingly small group of individuals."}, {"title": "12 Author short biographies", "content": "George Tambouratzis received a Diploma in Electrical Engineering from N.T.U.A, Athens,\nGreece, and a Ph.D. in Neural Networks and Pattern Recognition, from Brunel University.\nHe has held a senior research post at Athena Research Centre, Athens, Greece (ILSP) since\nMarch 1999. His research interests include Pattern Recognition, Artificial Neural Networks,\nComputational Intelligence algorithms and Natural Language Processing. He is a Senior\nMember of IEEE and a member of the IEEE System, Man & Cybernetics Society and the IEEE\nComputational Intelligence Society. He has served as the coordinator and lead investigator in\nseveral research projects, mainly projects funded by the European Commission. He has also\nserved as an expert for the European Commission.\nMarina Cort\u00e9s obtained a Ph.D. in Theoretical Physics at the University of Sussex (2008).\nShe was awarded several independent research fellowships at Lawrence Berkeley National\nLaboratory (California), University of Cape Town, South Africa, and the Royal Observatory\nin Edinburgh, where she won a prestigious Marie Curie Fellowship. She is currently Research\nFaculty at the University of Lisbon, Portugal. Cort\u00eas's work has influenced early universe\ncosmological inflation [45, 46, 47], and her work on the origin of the arrows of time [48] was\nawarded first place in the Inaugural Buchalter Cosmology Prize in 2014 [49]. The award\nrecognised their challenging of the time-symmetric laws, and their introduction of the arrow\nof time back onto the foundations of theoretical physics. Cort\u00eas has recently founded the new\nscientific field of Biocosmology [50, 51, 52, 53, 54].\nShe is the Chair of IEEE-SA's p3995 working group: Standard for the Implementation of\nSafeguards, Controls, and Preventive Techniques for Artificial Intelligence (AI) Models [1].\nAndrew Liddle is a physicist and cosmologist based at the University of Lisbon, Portugal. He\nobtained his Ph.D. at the University of Glasgow, and has held faculty positions at Imperial\nCollege London, at the University of Sussex where he directed the Astronomy Centre for many\nyears, and at the University of Edinburgh. He has worked on major international projects\nincluding the European Space Agency's Planck satellite and the ongoing Dark Energy Survey.\nAuthor of five books and almost three hundred peer-reviewed articles, he is rated by the\nannual Stanford University review of scientific citation impact [55] as being in the top 0.05%\nof scientists worldwide."}, {"title": "13 Disclaimers", "content": "This article solely represents the views of a set of authors within the IEEE P3395 Working\nGroup, and is not a consensus document. It does not represent a position of either IEEE or\nthe IEEE Standards Association.\nSpecifically this document is NOT AN IEEE STANDARD. Information contained in this\nWork has been created by, or obtained from, sources believed to be reliable, and reviewed\nby members of the activity that produced this Work. IEEE and the P3395 Working Group\n(WG) expressly disclaim all warranties (express, implied, and statutory) related to this Work,\nincluding, but not limited to, the warranties of: merchantability; fitness for a particular\npurpose; non-infringement; quality, accuracy, effectiveness, currency, or completeness of the\nWork or content within the Work. In addition, IEEE and the P3395 WG disclaim any and all\nconditions relating to: results; and workmanlike effort. This document is supplied \"AS IS\"\nand \"WITH ALL FAULTS.\"\nAlthough the P3395 WG members who have created this Work believe that the informa-\ntion and guidance given in this Work serve as an enhancement to users, all persons must rely\nupon their own skill and judgment when making use of it. IN NO EVENT SHALL IEEE\nSA OR P3395 WG MEMBERS BE LIABLE FOR ANY ERRORS OR OMISSIONS OR\nDIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL\nDAMAGES (INCLUDING, BUT NOT LIMITED TO: PROCUREMENT OF SUBSTITUTE\nGOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS; OR BUSINESS INTERRUP-\nTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN\nCONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHER-WISE) ARISING IN ANY WAY OUT OF THE USE OF THIS WORK, EVEN IF ADVISED\nOF THE POSSIBILITY OF SUCH DAMAGE AND REGARDLESS OF WHETHER SUCH\nDAMAGE WAS FORESEEABLE.\nFurther, information contained in this Work may be protected by intellectual property\nrights held by third parties or organizations, and the use of this information may require the\nuser to negotiate with any such rights holders in order to legally acquire the rights to do\nso, and such rights holders may refuse to grant such rights. Attention is also called to the\npossibility that implementation of any or all of this Work may require use of subject matter\ncovered by patent rights. By publication of this Work, no position is taken by the IEEE\nwith respect to the existence or validity of any patent rights in connection therewith. The\nIEEE is not responsible for identifying patent rights for which a license may be required, or\nfor conducting inquiries into the legal validity or scope of patents claims. Users are expressly\nadvised that determination of the validity of any patent rights, and the risk of infringement\nof such rights, is entirely their own responsibility. No commitment to grant licenses under\npatent rights on a reasonable or non-discriminatory basis has been sought or received from\nany rights holder.\nThis Work is published with the understanding that IEEE and the p3395 WG members\nare supplying information through this Work, not attempting to render engineering or other\nprofessional services. If such services are required, the assistance of an appropriate professional\nshould be sought. IEEE is not responsible for the statements and opinions advanced in this\nWork."}]}