{"title": "How Do Artificial Intelligences Think?\nThe Three Mathematico-Cognitive Factors of\nCategorical Segmentation Operated by Synthetic\nNeurons", "authors": ["Michael Pichat", "William Pogrund", "Armanush Gasparian", "Paloma Pichat", "Samuel Demarchi", "Michael Veillet-Guillem"], "abstract": "How do the synthetic neurons in language models create \"thought cat-\negories\" to segment and analyze their informational environment? What\nare the cognitive characteristics, at the very level of formal neurons, of\nthis artificial categorical thought? Based on the mathematical nature of\nalgebraic operations inherent to neuronal aggregation functions, we at-\ntempt to identify mathematico-cognitive factors that genetically shape\nthe categorical reconstruction of the informational world faced by artifi-\ncial cognition. This study explores these concepts through the notions of\npriming, attention, and categorical phasing.", "sections": [{"title": "1 Introduction", "content": ""}, {"title": "1.1 Synthetic Explainability and Cognitive Inference", "content": "Making an artificial neural network explainable means translating its operations\ninto a language that is accessible and logical for humans [25, 56, 57, 58]. This\ninvolves examining the network's observable actions within an interpretative\nframework that assigns relevant meaning to its operations. In our approach, we\nutilize concepts derived from human cognitive psychology as heuristic or analog-\nical bridges between human and artificial intelligence. This requires continuous\nconsideration of potential pitfalls, such as anthropomorphizing algorithms [52],\nconfusing behavior with cognition [12], or merging observer and observed sys-\ntem, a risk highlighted by cybernetics, systems theory, and enactive cognitive\nscience [78, 79, 71, 73].\nThe practical utility of this cognitive explainability approach unfolds in two\ndirections. First, it helps to prevent erroneous or potentially dangerous re-\nsponses from the artificial neural system, such as cognitive biases [29], cultural\nbiases [42], hallucinations [40, 49], or excessive emphasis on certain inputs [26].\nSecond, it improves the efficiency of language models [8] by further aligning\nthem with human expectations [44].\nIn this study, we explore an approach to explainability focused on a fine\ncognitive granularity, referred to as mechanistic explainability. Rather than\nexamining network outputs in relation to inputs on a global scale [86], this\napproach targets a microscopic analysis. Specifically, we delve into the fun-\ndamental cognitive units of formal neural networks-synthetic neurons, either\nindividually or in groups within layers [21, 22, 32, 53]. Our objective is to in-\nfer the internal cognitive mechanism of artificial networks at a genetic level to\nunderstand how the categories and concepts vectorized by formal neurons are\nlocally constituted."}, {"title": "2 Epistemological Status of Synthetic Thought\nCategories", "content": ""}, {"title": "2.1 Structural and Functional Construction of Synthetic\nCognition", "content": "By structural (i.e., architectural) and functional (i.e., mathematical) design,\nthe cognition of components within a synthetic neural network is inherently\ncategorical [11, 32, 14, 43, 87, 57, 58]. In simplified terms, the functioning of\neach formal neuron can be described in three stages:\n1. Integration: Each formal neuron receives inputs from its precursor neu-\nrons, where each input can be interpreted as the degree of membership of\na current element (such as a token in language models) to the category\nassociated with a precursor neuron.\n2. Weighted Combination: Through an aggregation function 1, these in-\nputs are combined to produce a resulting category. This combination is"}, {"title": "3 Problem Statement", "content": "How do synthetic neurons construct the categorical dimensions through which\nthey segment and analyze their environment (e.g., tokens in language models)?\nWhat are the developmental characteristics of this artificial categorical thinking,\nand how are these categories vectorized by synthetic neurons? Specifically, what\nare the genetic factors that influence or govern these categorical constructions?\nMore precisely, which factors determine the level of membership (i.e., activa-\ntion level) of a token within a synthetic neural category, thereby shaping the\nextension and hence the \"semantics\" of this category? In other words, how do\nthese factors quantitatively and qualitatively constitute the genetic variables of\ncategorical segmentation (of the token world) performed by synthetic neurons?"}, {"title": "4 Methodology", "content": ""}, {"title": "4.1 Methodological Positioning", "content": "Investigating these questions requires recognizing that the cognitive and con-\nceptual properties of artificial neural networks do not emerge by magic or chance.\nIn an embodied cognition framework [71, 72, 2, 55], these properties directly re-\nsult from the specific characteristics of the physical structure within which they\nemerge.\nA central structural and functional component of a neural network is the\naggregation function governing the linear combination and vector projection of\ninput categorical dimensions into a resulting categorical dimension. This aggre-\ngation function, along with other elements (including the activation function),\ngenetically and functionally shapes the dimensional categorical segmentation\nspecific to each formal neuron.\nObserving the nature and operators constitutive of this aggregation func-\ntion, of the form $\\sum(W_{i,j}x_{i,j}) + a$, suggests that it mathematically generates and\nformats the categorical segmentation performed by synthetic neurons through\nat least three mathematico-cognitive factors. We will investigate these factors\nin this exploratory work: the first factor is associated with the variable $x_{i,j}$, rep-\nresenting the activation values of categorical outputs from precursor neurons,\ncognitively interpreted as categorical priming (or effect X). The second factor re-\nlates to the parameter $w_{ij}$, the weighting assigned to these outputs, interpreted\nas categorical attention (or effect W). Finally, the third factor concerns the lin-\near additive combination of the terms $W_{i,j}x_{i,j}$; within the aggregation function,\ncognitively denoted as categorical phasing (or effect $\\Sigma$)."}, {"title": "4.2 Methodological Choices", "content": "In this exploratory research, we focus on the GPT model proposed by OpenAI,\nspecifically its GPT-2XL version. This choice is due to GPT-2XL's sufficient\ncomplexity, allowing us to examine advanced synthetic cognitive phenomena\nwithout reaching the sophistication of GPT-4 or its multimodal version, GPT-\n40. A practical consideration also guided our preference for GPT-2XL: in 2023,\nOpenAI shared, in the article by Bills et al. [11], parameter details as well as\nactivation values for its neurons, which serve as the basis for our analysis.\nFor simplicity, this exploratory study is limited to the first two layers of\nGPT-2XL (layers 0 and 1), each comprising 6,400 neurons. Regarding tokens\nand their activation values among these 12,800 formal neurons (i.e., 2 x 6,400),\nwe have decided to consider, for each neuron, the 100 tokens with the highest\naverage activation values (referred to as \"core-tokens\")."}, {"title": "4.3 Statistical Choices", "content": "Our descriptive and inferential statistical analyses were conducted using Python's\nSciPy library, following guidance from Howell [39] and Beaufils [10].\nTo assess the normality of our data, a necessary condition for performing\nparametric tests, we adopted a dual approach. First, we employed various in-\nferential tests: the Shapiro-Wilk test (effective for small samples), the Lilliefors\ntest (suitable for small samples when normal distribution parameters are un-\nknown and estimated from the data), the Kolmogorov-Smirnov test (preferred\nfor large samples), and the Jarque-Bera test (focusing on symmetry and kur-\ntosis, valid for large samples). Second, we used a descriptive approach with\nindices such as skewness and kurtosis, and graphical methods like the QQ-plot\nto compare the observed distribution with a theoretical normal distribution.\nThe results, not reproduced here, indicate a relatively mixed normality in\nour data, leading us primarily towards Spearman's ordinal correlation studies in\nanalyzing relationships between variables associated with our hypotheses. This\napproach allows us to avoid normality prerequisites and mitigate bias introduced\nby outliers. When necessary, we applied univariate goodness-of-fit tests to infer"}, {"title": "4.4 Objective and Implementation of the Study in Terms\nof Statistical Observables", "content": "the significance of observed phenomena (notably regarding the positivity and\nsignificance of ordinal correlations obtained for each neuron in layer 1).\nIn our statistical framework, the composite units include the 6,400 \"desti-\nnation\" neurons in layer 1, their 100 respective core-tokens (tokens with the\nhighest average activation levels), as well as the 10 precursor neurons (from\nlayer 0) with the highest connection weights to each destination neuron. We\nfocused on the 100 tokens most highly activated by each neuron, deeming it less\nrelevant initially to examine tokens weakly or not activated by them, as they\nfall partially outside the extension of the category associated with each neuron.\nThe objective of this exploratory study is to identify synthetic cognitive factors\nthat partially drive the categorical segmentation performed by formal neurons.\nThese factors are mathematically embedded in the neural aggregation function\nand influence the identification of core-tokens for a given neuron, that is, the\ndetermination of the content of its categorical extension.\nMore specifically, we aim to verify to what extent the membership of a core-\ntoken to the specific category of a destination neuron depends on three cognitive\nfactors that we will define and propose: categorical priming, categorical atten-\ntion, and categorical phasing. The level of membership of a core-token (in layer\n1, the destination layer) to the category associated with a neuron will be mea-\nsured by the activation value of this token within the relevant neuron. Priming\nwill be evaluated based on the activation value of a token in its respective pre-\ncursor neurons (in layer 0). Attention will be assessed through the connection\nweights linking destination neurons (layer 1) to their top 10 precursor neu-\nrons (those with the highest connection weights) in layer 0. Finally, categorical\nphasing will be quantified by analyzing the frequency with which a core-token\nwithin a destination neuron (layer 1) also appears as a core-token among the 10\nassociated precursor neurons (layer 0)."}, {"title": "5 Definition of Synthetic Cognitive Concepts Stud-\nied and Results", "content": ""}, {"title": "5.1 Synthetic Categorical Priming", "content": "In human psychology, priming [3, 18, 83, 38] is a cognitive process in which an\ninitial stimulus triggers a preliminary stage of cognitive processing, thus facil-\nitating, accelerating, or preparing the reception of a second, related stimulus.\nSpecifically, semantic priming is a process by which the meaning of one element\n(e.g., a word) becomes more accessible to an individual through prior exposure\nto another semantically related element. The priming effect is typically studied\nin terms of response delay in lexical decision or text comprehension tasks, where"}, {"title": "5.2 Synthetic Categorical Attention", "content": "response time can indicate the existence, structure, and strength of semantic re-\nlationships between words and concepts in long-term semantic memory.\nThe notion of priming is related to that of activation [47, 15, 46], postulating\nthat cognitive contents or processes can exhibit variable intensity levels of ac-\ntivity. Prototypical examples involve biological neural structures whose activity\nlevels can be physiologically \"directly\" measurable (even if this measurement is\npartly a methodological and statistical reconstruction). In the case of priming,\nactivation is conceptualized as the propagation of activation: a cognitive char-\nacteristic (e.g., meaning) is \u201cspread\u201d from an entity A (which activates first) to\nan entity B (which activates as a causal result) (e.g., from one word to another)\nif A and B are structurally or temporarily linked.\nWe hypothesize a transposition of the concept of priming, as defined above\nin the fields of neuroscience and human cognitive psychology, into the domain\nof synthetic cognition. Mathematically, due to the construction of the aggrega-\ntion function $\\sum(W_{i,j}x_{i,j}) + a$, for a given element (e.g., a token or other), the\nactivation value of the category carried by a destination neuron (on layer n)\nis directly a function (modulo the activation function) of the activation values\n$X_{i,j}$ of the categories associated with its precursor neurons (on the subordinate\nlayer n 1). In other words, in epistemological alignment with the original\nnotion of priming, the prior activation (when it exists for a given token) of the\ncategories vectorized by precursor neurons should \"mathematically propagate\"\nthe activation of the category associated with their corresponding destination\nneuron. We thus formulate, in these terms, a hypothesis of synthetic categorical\npriming within artificial neural networks.\nFrom a quantitative perspective, the empirical observable associated with\nour hypothesis of synthetic categorical priming is the activation value of des-\ntination neurons as a function of their precursor neurons. Specifically, data\ncompatible with our hypothesis should show, for a given series of tokens, a re-\nlationship between the activation value of destination neurons on layer n + 1\nand that of their respective precursor neurons. We operationalize this approach\non the 6,400 neurons in layer 1 of GPT-2XL, considering for each destination\nneuron its 10 precursor neurons with the highest connection weights and its 100\ntokens associated with the highest average activation values (core-tokens) (only\ncore-tokens activated in at least one precursor neuron are included).\nStatistically, we test an ordinal relationship (Spearman's $\\rho$) between the\naverage activation rank (ranging from 1 to 100) of the 100 core-tokens of each\nof the 6,400 destination neurons in layer 1 and the mean cumulative activation\nvalues (i.e., summed) of these tokens within the 10 associated precursor neurons\n(each core-token of a destination neuron having a non-negative activation value\nfor each of the 10 relevant precursors).\nTable 1 shows a positive relationship with an extremely strong effect size\n(p = .94) and statistical significance (p < .001). Figure 1 illustrates this overall\npositive monotonic trend, though with occasional pronounced peaks in variabil-\nity. Figure 2 provides a view for an example neuron, with a regression line again\nshowing a positive relationship, although less pronounced in this case."}, {"title": "5.2.1 Quantitative Approach to Synthetic Categorical Attention", "content": "In human cognitive psychology, attention is defined as a specific calibration of\nactivity according to its purpose, resulting in greater efficiency in information\nintake processes (including selectivity) and execution processes (including pre-\ncision and speed) [60, 66, 59, 63, 69, 27, 68, 19, 82, 36]. In terms of external in-\nformation intake, attention is related to conceptualization [74, 75], meaning the\nidentification of only those parameters (objects relevant to the activity) whose\nconsideration is crucial for successful task performance. Actions must thus\nbe adjusted to these parameters to ensure efficiency. Here, attention involves\nfiltering and structuring the excessively large amount of available perceived in-\nformation, or inhibiting information deemed irrelevant, in order to focus mental\neffort and informational selectivity on specific objects and properties. Regard-\ning task execution, attention is linked to the control, by the central system, of\nthe activity, which may involve assigning varying degrees of weight (priority,\norder, reliability, etc.) to certain internal information (knowledge, representa-\ntions, schemas) or verifying the quality of task performance within its temporal\nsequence."}, {"title": "5.3 Synthetic Categorical Phasing", "content": "From a physiological perspective, attention is driven by the limited information-\nprocessing capacity of the nervous system, leading to selective choices in the\nintegration, activation, and utilization of sensory data or stored memory (se-\nmantic, procedural) [34, 6]. This process is achieved through an orientation\nresponse, which directs information-seeking activities toward a specific type of\ninformational characteristics.\nWe hypothesize here a transposition of the concept of attention, as pre-\nviously described in cognitive psychology and human neuroscience, into the\nfield of artificial cognition. This is based on the mathematical construction of\nthe aggregation function $(\\sum W_{i,j}x_{i,j}) + a$, where, for a given element (a token),\nits activation value within the category associated with a destination neuron\nis inherently dependent (apart from the activation function) on the connection\nweights $w_{ij}$ between this destination neuron and its precursor neurons. In other\nwords, and in epistemological continuity with the original concept of attention,\nthe connection weights with precursor neurons act as direct regulators of the\nlevel of information uptake (i.e., activation levels) derived from these precursor\nneurons-ranging from inhibition or filtering of data for negative, near-zero, or\nweakly positive weights, to strong mathematical-cognitive focus and integra-\ntion for significant weights. Thus, in terms of execution, the neuronal connection\nweights govern the degree of information utilization that the artificial cognitive\nsystem deems relevant from preceding synthetic categories in performing the\ncurrent task of a given successor neuron, which involves calculating the degree\nof membership of a given token in the category constitutive of this superordi-\nnate neuron. We define this hypothesis as synthetic categorical attention within\nartificial neurons, which we denote as effect \"W.\""}, {"title": "5.2.1 Quantitative Approach to Synthetic Categorical Attention", "content": "Quantitatively, the empirical observable associated with our hypothesis of syn-\nthetic categorical attention is, for a given token, the activation value of destina-\ntion neurons as a function of their connection weights with respective precursor\nneurons. To test this hypothesis, we examine the relationship between the\nactivation value of destination neurons and the connection weights with their\nprecursor neurons. According to this hypothesis, activation should increase with\nhigher values of these antecedent weights. We apply this approach to the 6,400\nneurons in layer 1 of GPT-2XL, taking into account for each destination neu-\nron its 10 precursor neurons with the highest connection weights and its 100\ntokens with the highest average activation values (core-tokens) (note that only\ncore-tokens activated in at least one precursor neuron are considered). From a\nstatistical perspective, and in a more operationalized form, we test for an ordinal\nrelationship (measured with Spearman's $\\rho$) between (i) the average activation\nrank (ranging from 1 to 100) of the 100 core-tokens of each of the 6,400 desti-\nnation neurons in layer 1, and (ii) the average cumulative connection weights\n(i.e., summed) with their respective (1 to 10) precursor neurons for which these\ntokens are also core-tokens.\nIn Table 2, we observe a positive ordinal relationship between the activation"}, {"title": "5.3.1 Quantitative Approach to Synthetic Categorical Phasing", "content": "Through the construction of the aggregation function $\\sum(W_{i,j}x_{i,j}) + a$, we pos-\ntulate a third mathematico-cognitive factor influencing the level of token at-\ntribution to a neuronal categorical dimension. We term this factor \"synthetic\ncategorical phasing,\" or effect \"$\\Sigma$,\" as the aggregation function of a destination\nneuron sums, for a given token, the weighted values of its activations $W_{i,j}x_{i,j}$\nwithin its respective precursor neurons. Several studies in human cognitive psy-\nchology and neuroscience involving the notion of phasing could potentially serve\nas partial analogies for synthetic cognition in this area; for example, studies on\nperceptual modality topics [48, 41] or brain synchronizations [1, 16, 62, 67, 65].\nIn the realm of synthetic cognition, we define synthetic categorical phasing\nby the notion that a token, previously highly activated for different precur-\nsor neurons (i.e., a core-token of these precursor neurons), must, due to the\nmathematical construction of the aggregation function, be associated with a\nhigh activation level within the related destination neuron. This is because\nthe token is co-activated within the various terms constituting the aggregation\nfunction; this co-activation leads to an additive concatenation, resulting in a sig-\nnificant activation level for this token at the output of the destination neuron.\nSuch a token is therefore theoretically subject to the phasing of the neural cat-\negories of the involved precursors: these precursor categorical segments, though\nconceptually potentially distinct, are jointly activated, generating a categorical\n\"echo\" or \"resonance\" for this specific token. This occurs through a categorical\nintersection traced across these dimensions, thereby strengthening the output\nactivation level of the destination dimension."}, {"title": "5.2.2 Qualitative Approach to Synthetic Categorical Attention", "content": "Quantitatively, we operationalize our hypothesis of categorical phasing as fol-\nlows: the more a destination neuron's core-token is also a core-token for a greater\nnumber of its precursor neurons (with high connection weights), the higher its\nactivation level in this destination neuron. This hypothesis thus posits a positive\nmonotonic relationship between these two variables. Table 4 presents the com-\npiled results from local-level analytic testing of this hypothesis, i.e., for each of\nthe 6,400 individual destination neurons in layer 1. We observe a strong ordinal\ncorrelation between the two variables, with a large effect size (Mean $(\\rho)$ = .976),\nhigh significance (% of (p(p) < .05) = 99.40%; p($\\chi^2$) < .0001), and overwhelm-\ningly positive directionality (% of (p > 0) = 99.45%, p($\\chi^2$) < .0001). Table 5\ndisplays the results of global-level testing of this hypothesis across all data as a\nwhole (Nmax = 6,400 neurons in layer 1 x 10 precursors in layer 0 x 100 core-\ntokens). We again find a strong, positive, and significant ordinal correlation\nbetween the two variables (p = .989, p($\\rho$) < .001). Figure 9 graphically illus-\ntrates this trend, showing a pronounced logarithmic distribution leading to an\nasymptotic plateau, while Figure 10 provides an example for a control neuron\nwith a distinctly positive regression line."}, {"title": "5.3.2 Qualitative Approach to Synthetic Categorical Phasing", "content": "Let us now, within a qualitative framework, establish reference points to un-\nderstand the cognitive modalities through which categories initially distinct\nor, at the very least, non-isomorphic-associated with precursor neurons can\nbecome locally phased categorically, i.e., for given tokens. This approach aims\nto further conceptualize the phenomenology through which such categorical in-\ntersections and crossings of categorical segments may manifest. Thus, we aim\nto better understand how, through these intersections, precursor neurons se-\nlectively feed into and generate the categorical extensions of their respective\ndestination neurons. This process enables the selective extraction of categor-\nical sub-dimensions from the categories carried by precursor neurons, thereby\nconstructing the specific categorical nature of their destination neuron.\nFor illustrative purposes only, again without aiming for systematic classi-\nfication or exhaustiveness, Table 6 presents types of qualitative examples of\ncategorical phasing modalities. These examples necessarily involve cases where"}, {"title": "5.4 Overview of the Three Factors in Categorical Segmen-\ntation", "content": "different categories at the level of precursor neurons are jointly activated for the\nsame given tokens; strong co-activations genetically trigger significant activation\nof the associated destination neuron's category or, in other words, genetically\ndefine the content (in terms of tokens) of the categorical extension of this des-\ntination category. (For reference, a category's extension is defined here, within\nan a-cut fuzzy logic perspective, as the 100 most activated tokens, known as\ncore-tokens).\nWe qualitatively identify three main types of categorical intersections:\n1. Intra-lexical intersection (semantic identity): Example: two precur-\nsor categories each contain, among their respective core-tokens, the same\ntokens \"manager\" and \"leadership,\" which then form a categorical sub-\ndimension extracted from the full extension of the two involved precursor\ncategorical dimensions.\n2. Sub-lexical intersection (semantic inclusion): Example: one precursor\ncategory includes core-tokens such as \u201cexecutive,\u201d \u201cmanager,\u201d\u201cleader,\u201d\n\"chief,\" \"director,\" \"CEO,\" and \"supervisor\"; another includes \"director,\u201d\n\"executive,\" and \"CEO.\u201d This latter series is included within the former,\nthus forming a categorical sub-dimension extracted from both precursor\ncategorical dimensions.\n3. Extra-lexical intersection (bi-lexicality): Example: one precursor cate-\ngory's core-tokens include \"knife,\" \"gun,\" \"mortar,\u201d \u201cbomb,\" \"axe,\" \"cleaver,\u201d\n\"sword,\" and \"grenade\" (weapons); another includes \u201ccleaver,\u201d \u201cspatula,\u201d\n\"colander,\u201d \u201cknife,\u201d\u201cmixer,\u201d and \u201cmortar\u201d (kitchen utensils). The inter-\nsection of these two distinct lexical fields includes \"knife,\" \"mortar,\" and\n\"cleaver,\" which thus form a categorical sub-dimension within the core-\ntokens of both precursor categorical dimensions.\nThese illustrative cases, again without aiming for generalization, allow us to\nsee how the process of categorical phasing enables the extraction of co-activated\ncategorical sub-dimensions from precursor neurons' categories, which then con-\nstitute the core-token extension of their respective destination neurons.\nWe have posited the existence of three synthetic cognitive factors that partially\ngenerate the categorical segmentation specifically operated by a formal neu-\nron. These factors are mathematically embodied in the neuronal aggregation"}, {"title": "6 Conclusion", "content": "function, which, together with the activation function, governs the determina-\ntion of the tokens that will constitute a given neuron's core-tokens, i.e., the\ncontent of its categorical extension. These three factors-categorical priming,\nattention, and phasing thus drive the categorical segmentation that neurons\nperform within the universe of tokens.\nTo obtain a general quantitative representation of the combined action of\nthese three factors, we conducted a multiple linear regression on the activation\nrank of core-tokens in destination neurons as a function of (i) the average num-\nber of times these core-tokens are also core-tokens in the associated precursor\nneurons (a1) (effect $\\Sigma$), (ii) the average connection weight of destination neu-\nrons with their associated precursor neurons (a2) (effect w), and (iii) the average\nactivation of these core-tokens in the relevant precursor neurons (az) (effect x).\nThis regression is performed, for statistical feasibility, only on the core-tokens of\ndestination neurons that are core-tokens in at least one of the involved precursor\nneurons; when a destination core-token is a core-token in multiple precursors,\nits associated weight is the sum of the precursor weights involved, and its acti-\nvation is likewise summed across these precursors. Additionally, this regression\nis conducted on the 6,400 neurons constituting layer 1.\nThis linear regression (see Table 7) shows positive and notable standardized\ncoefficients for the three postulated factors (s-a\u2081 = .86, s-a2 = .56, s-a3 = .65),\nconsistent with our hypotheses. We also observe that the respective impacts\nof these three independent variables on the dependent variable are significant\nand of a similar magnitude (r\u00b2(a1) = .74, r\u00b2(a2) = .75, r\u00b2(\u0430\u0437) = .54), suggest-\ning that the three identified factors contribute comparably to the categorical\nsegmentation operated by the destination neurons.\nHowever, these results remain uncertain, as our normality tests (Shapiro-\nWilk, Kolmogorov-Smirnov, and Jarque-Bera) on the residuals do not align\nwith expected application conditions, as indicated by Figures 10 to 12, which\nreveal outliers. Additionally, we suspect collinearity effects among the three\nfactors, as they are likely highly correlated. These results should therefore be\nconsidered illustrative only.\nIn this exploratory study, we investigated, both quantitatively and qualita-\ntively, the genetic factors involved in the categorical segmentation (of the token\nworld) performed by synthetic neurons. Based on the aggregation function"}]}