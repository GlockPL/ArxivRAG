{"title": "ERAS: Evaluating the Robustness of Chinese NLP Models to Morphological Garden Path Errors", "authors": ["Qinchan (Wing) Li", "Sophie Hao"], "abstract": "In languages without orthographic word boundaries, NLP models perform word segmentation, either as an explicit preprocessing step or as an implicit step in an end-to-end computation. This paper shows that Chinese NLP models are vulnerable to morphological garden path errors-errors caused by a failure to resolve local word segmentation ambiguities using sentence-level morphosyntactic context. We propose a benchmark, ERAS, that tests a model's vulnerability to morphological garden path errors by comparing its behavior on sentences with and without local segmentation ambiguities. Using ERAS, we show that word segmentation models make garden path errors on locally ambiguous sentences, but do not make equivalent errors on unambiguous sentences. We further show that sentiment analysis models with character-level tokenization make implicit garden path errors, even without an explicit word segmentation step in the pipeline. Our results indicate that models' segmentation of Chinese text often fails to account for morphosyntactic context.", "sections": [{"title": "Introduction", "content": "When working with languages that do not mark word boundaries in their writing systems, the task of word segmentation, where texts are parsed into word-level tokens, is non-trivial. Nonetheless, in high-resource languages like Chinese, the state of the art in word segmentation is strong, with F1 scores close to 100% for common benchmarks (Emerson, 2005; Huang et al., 2020; Ke et al., 2020; Lin et al., 2023, inter alia).\nWord segmentation is subject to structural ambiguity: there may be more than one way to segment a text into words or morphemes. In English, for example, the word unlockable can be understood to mean 'unable to be locked' (un + lock-able), or 'able to be unlocked' (unlock + able). In some cases, a sequence of words or morphemes that appears ambiguous may be disambiguated by morphosyntactic context. This paper investigates whether Chinese NLP models correctly resolve local structural ambiguities caused by morphological garden paths. If they do not, then we expect models to make garden path errors by parsing locally ambiguous substrings incorrectly. To that end, we propose the Evaluation of Robustness to Locally Ambiguous Segmentation (ERAS) benchmark, a synthetic test set consisting of locally ambiguous test sentences paired with unambiguous but otherwise identical control sentences."}, {"title": "ERAS: A Benchmark for Detecting Garden Path Errors", "content": "ERAS consists of 203,944 pairs of test and control sentences, available in both simplified and traditional characters, synthetically generated from templates. ERAS is organized into 39 minimal pair paradigms (Warstadt et al., 2020), examples of which are shown in Figure 3. Each paradigm is defined by two templates, one for test sentences and one for control sentences. Within each paradigm, the two templates are identical, except that the test template contains a morphological garden path and the control template does not.\nWe evaluate models on ERAS by testing the null hypothesis that models perform similarly on test and control sentences. If a model performs better on control sentences than on test sentences, then we conclude that this model is susceptible to garden path errors. ERAS is designed to test two kinds of models: Chinese word segmentation models, which may incorrectly segment morphological garden paths, and sentiment analysis models, whose outputs may be influenced by the sentiment of words that could only exist if morphological garden paths are implicitly segmented incorrectly."}, {"title": "Dataset Structure", "content": "As shown in Figures 2 and 3, test and control templates differ in terms of a three-character substring called the test site. In test templates, the first two and last two characters of the test site form words from the ANTUSD sentiment lexicon, which overlap at the middle character. One of the two words is designated as the true word, while the other is designated as the canary word. In each test template, the true word and canary word have differing sentiment labels (+, 0, or \u2013), and only the true word may appear in a valid segmentation of the sentence. For each test template, a control template is formed by manually generating a locally unambiguous paraphrase of the test template's test site."}, {"title": "Explicit vs. Implicit Segmentation Errors", "content": "ERAS measures susceptibility to two kinds of segmentation errors: explicit and implicit. An explicit segmentation error occurs when a model outputs word segmentation information that parses the canary word as a word. An implicit segmentation error occurs when a model does not output word segmentation information, but nonetheless behaves as though the canary word were parsed as a word. We detect implicit segmentation errors in Section 4, where we evaluate sentiment analysis models on ERAS by testing the null hypothesis that sentiment predictions for ERAS sentences are not influenced by their paradigms' canary sentiment labels."}, {"title": "Dataset Construction", "content": "ERAS was constructed via the following steps.\nCreation of Templates. We form an initial list of test sentence test sites by extracting all word pairs of the form (x1x2,x2x3) from the ANTUSD lexicon, where x1, x2, x3 are single characters, such that x1x2 and x2x3 have different sentiment labels. For each word pair, we manually generate two Mandarin Chinese sentences subject to the following criteria: (1) both sentences contain the test site x1x2x3, (2) both sentences are locally ambiguous at the test site and nowhere else, and (3) one sentence is left-branching and the other is right-branching. We discard all the word pairs for which we were unable to generate the two sentences, and we discard sentences for which the true sentiment label is 0.1 The remaining 39 sentences are manually converted into test templates by replacing certain content words with one of the following slots: concept, entity, modifier, noun, object, person, or verb. For each test template, we construct the corresponding control template by paraphrasing the test site without local ambiguity.\nSentiment Labeling. ANTUSD provides sentiment scores on a continuous scale from -1 (negative) to 1 (positive), as well as categorical labels (positive, negative, or neutral) from each annotator. We consider a word to be labeled as + (resp. -) if its sentiment score is at least .4 (resp. less than -.4), and more annotators labeled the word as positive than negative (and vice versa). We consider a word to be labeled as 0 if it meets the following criteria: its sentiment score is 0, the majority of annotators labeled it as neutral, and at least two annotators marked it as a \"non-sentiment word.\"\nSlot Filling. Each of the seven slot types (concept, entity, modifier, noun, object, person, verb), is associated with a manually constructed word list. To generate test and control sentences, we present each template to bert-base-chinese (Devlin et al., 2019), with all slots masked out. We then fill the slots iteratively from left to right, at each step using all words from the appropriate word list whose masked language modeling probability scores exceed a certain threshold.3\nConversion to Traditional Characters. ERAS is constructed using simplified characters. We create a traditional-character version of ERAS using the chinese-converter Python package.4"}, {"title": "Human Evaluation", "content": "Our setup for detecting implicit segmentation errors using ERAS is based on the assumption that both test and control sentences have the sentiment value given by the paradigm's true sentiment, but that test sentences are treated as having the canary sentiment if and only if they are segmented incorrectly due to garden path errors. In order to verify this, a sample of 20 sentence pairs from each paradigm was evaluated by 5 native speakers of Mandarin Chinese, with each annotator evaluating 4 sentence pairs per paradigm. We assume that (1) the sentiment of control sentences is given by their paradigms' true sentiment labels and (2) annotators do not make garden path errors while reading test sentences, and we seek to verify that the sentiment of each test sentence matches that of its corresponding control sentence.\nAnnotation Task. Annotators were asked to rank sentence triples in order of sentiment polarity. For each test-control pair (t, c), annotators were presented with triples of the form {t,c1, c2} and {C, C1, C2}, where c\u2081 and c2 are control sentences. Each annotator ranked 208 sentence triples, the minimum necessary to ensure that all test-control pairs assigned to the annotator are represented.\nEvaluation. We assume that any sentence that is ranked more positively (resp. negatively) than a control sentence with a label of + (resp. -) also has a label of + (resp. \u2013). Therefore, we say that a test-control pair (t, c) with a true sentiment of + (resp. -) is annotated correctly if t is ranked at least as positively (resp. negatively) as c, relative to c\u2081 and c2. Because we have ensured in Subsection 2.3 that true sentiment labels can only be + or \u2013, we do not need to consider cases where the control sentence has a sentiment of 0; in such cases, unless t has exactly the same ranking as c, we cannot determine whether or not t has a sentiment of 0."}, {"title": "Explicit Garden Path Errors", "content": "Our first experiment evaluates word segmentation models according to their vulnerability to explicit segmentation errors due to garden path phenomena. Under the hypothesis that word segmentation models may segment canary words as words, we predict that test-sentence test sites will be segmented less accurately than control-sentence test sites."}, {"title": "Experimental Setup", "content": "We test word segmentation models by using them to segment all sentences in the ERAS dataset. We evaluate models based on whether test sites are segmented correctly; we do not measure how well models segment other parts of the sentence. We consider a left-branching sentence with test site x1x2x3 to be segmented incorrectly if a word boundary is placed between x1 and x2, but not between x2 and x3. A right-branching sentence is segmented incorrectly if a word boundary is placed between x2 and x3, but not between x1 and x2."}, {"title": "Evaluation", "content": "For each paradigm, we define a model's paradigm test accuracy to be the percentage of test sentences within that paradigm that the model segments correctly, and we define the model's overall test accuracy to be the mean of the model's paradigm test accuracy across all paradigms. Paradigm control accuracy and overall control accuracy are defined analogously."}, {"title": "Results", "content": "As reported in the first column of Table 1, all of our models achieve a lower accuracy on test sentences than control sentences. This confirms our hypothesis that garden paths serve as a source of explicit word segmentation errors. We find that the MSR and PKU models are the least susceptible to garden path errors, in the sense that they exhibit the smallest gap in performance between test and control sentences. By that metric, the MaxMatch baseline and the Jieba model are the most susceptible to garden path errors. The non-neural PKUSEG model slightly outperforms the AS and CityU models in terms of test-control gap, but this is largely because PKUSEG achieves the lowest overall accuracy on control sentences.\nLeft-Branching Bias. The other columns of Table 1 report overall accuracies for left- and right-branching paradigms, separately. These results reveal a bias in our models for producing left-branching segmentations, in the sense that all of our models perform better on left-branching sentences than right-branching sentences. The only exception to this trend is that CityU performs better on right-branching test sentences than left-branching test-sentences. MaxMatch explicitly incorporates this bias by iterating through the text from left to right; but since the other models do not incorporate an explicit concept of directionality, we assume that the left-branching bias in these models is learned from the training corpus."}, {"title": "Implicit Garden Path Errors", "content": "Our second experiment evaluates sentiment analysis models according to their vulnerability to implicit segmentation errors due to garden path effects. Our hypothesis is that the sentiment polarity of canary words will contribute to the sentiment labels assigned by the models to test sentences, even though these words should, in theory, be excluded from the semantics of these sentences. We therefore predict that, for example, a sentiment analysis model should label a test sentence with a negative-sentiment canary word as being \u201cmore negative\" on average than the corresponding control sentence. We also predict that providing word boundary information during pre-training or fine-tuning will improve a sentiment model's performance according to the aforementioned metric."}, {"title": "Experimental Setup", "content": "We test binary sentiment analysis models, which produce a single logit representing predicted sentiment polarity, by having them predict the sentiment of each sentence in ERAS. Our evaluation of these models is analogous to the paradigm described in Subsection 2.4, which we used for our human evaluation of ERAS's sentiment properties. To that end, we consider a +/\u2013 or +/0 sentence pair to be classified incorrectly if its test sentence receives a lower sentiment score than its control sentence. A -/+ or -/0 sentence pair is classified incorrectly if its test sentence receives a higher sentiment score than its control sentence."}, {"title": "Evaluation", "content": "We define the paradigm accuracy of a sentiment analysis model on a paradigm to be the percentage of sentence pairs in that paradigm that are classified correctly by the model. The overall accuracy of a model on ERAS is the mean of that model's paradigm accuracies across all paradigms."}, {"title": "Causal Analysis", "content": "We expect that a model that is completely immune to implicit garden path errors would make no systematic distinctions in sentiment between test and control sentences. Such a model would achieve an overall accuracy of 50%. When a model achieves an overall accuracy of 50%, however, we do not know whether this is because the model did not make any garden path errors, or whether it is because the model made some number of garden path errors while also making errors in the opposite direction. For this reason, we perform an occlusion study (Zeiler and Fergus, 2014) in order to determine what percentage of ERAS mis-classifications were caused by garden path errors.\nAs illustrated in Figure 4, our occlusion study involves masking out the 1st character in right-branching test sites and the 3rd character in left-branching test sites, effectively ablating the canary word in test sentences. We assume that an incorrect ERAS classification is caused by an implicit garden path error if ablating the canary word causes the model's control and test outputs to become more similar to one another. Following Balkir et al. (2022), we define necessity to be the percentage of ERAS errors that are caused by implicit garden path errors according to our occlusion test, and sufficiency to be the percentage of implicit garden path errors detected by our occlusion test that result in an ERAS misclassification. We calculate the garden path error rate (GPER) as follows:\nGPER = (1 \u2013 overall accuracy) \u00b7 necessity.\nThe GPER measures the percentage of ERAS examples for which the model makes an implicit garden path error, leading to a misclassification."}, {"title": "Results", "content": "The results of our implicit garden path error experiment are shown in Table 2. The RoBERTa-330M model achieves the best GPER among the off-the-shelf models, and our WWM+CWS model achieves the best GPER among our fine-tuned models. The RoBERTa-330M model also achieves the best overall accuracy among the off-the-shelf models, but the WWM+CWS model achieves the worst overall accuracy across all models. Instead, the Sentiment Only model achieves the best overall accuracy, outperforming the human baseline.\nError Analysis. The right-hand side of Table 2 (\"Control - Test Sentiment\u201d) shows the average difference in sentiment scores assigned by our models to control vs. test sentences, where scores range from 0 (most likely to be -) to 100 (most likely to be +). We would ideally like these numbers to be as close to 0 as possible, since this would indicate that the model makes no systematic distinction between control and test sentences. This error analysis reveals that for all models except RoBERTa-330M and WWM+CWS, the -/+ paradigms result in the greatest discrepancy in output between control and test sentences. Indeed, the three models with ERAS accuracies above 50 are also those with the smallest control-test differences for -/+ paradigms. This suggests that -/+ sentences are the ones for which our models are most likely to commit implicit garden path errors.\nWord Boundary Supervision. The GPER results show that both whole word masking and joint training on word segmentation are effective methods for mitigating susceptibility to implicit garden path errors, and that using both techniques in combination results in the best GPER. However, the CWS and WWM+CWS models also have the poorest performance in terms of ERAS overall accuracy as well as ASAP test set accuracy. This suggests that joint training on word segmentation is effective in reducing susceptibility to garden path errors, but makes the model more susceptible to other types of errors, with the costs of the latter outweighing the benefits of the former. On the other hand, the use of whole word masking does not exhibit this tradeoff, though it only enables a modest reduction in GPER.\nTest Accuracy and GPER. Figure 5 reveals a correlation between test set accuracy and GPER: better-performing sentiment analysis models are more susceptible to implicit garden path errors. No such relationship is observed between test set accuracy and ERAS overall accuracy, however. Thus, the increased susceptibility to garden path errors for better-performing models is offset by other factors that influence ERAS overall accuracy."}, {"title": "Discussion and Related Work", "content": "Left-Branching Bias in Humans. Much work has been done in psycholinguistics on the human processing of Chinese morphological garden paths (Inhoff and Wu, 2005; Huang and Li, 2020; Huang et al., 2021; Tong et al., 2023; Huang and Li, 2024). Huang and Li (2020), in particular, identify a human left-branching bias, similar to the left-branching bias observed for word segmentation models in Section 3. They find that human readers spend less time looking at left-branching morphological garden paths than right-branching ones, all else equal, indicating that the former are easier to process than the latter. On the other hand, Liao et al. (2024) did not observe a left-branching bias when instructing GPT-3.5 models to perform word segmentation.\nGarden Paths in Word Segmentation. Rule-based, statistical, and non-neural machine learning methods have been proposed for correctly segmenting morphological garden paths in Chinese word segmentation (Sun and T'sou, 1995; Han et al., 2001; Li et al., 2003; Xiong and Zhu, 2007; Gao and Guo, 2009). These techniques mostly involve first identifying locally ambiguous substrings, possibly with the help of a lexicon of locally ambiguous substrings, and then choosing a segmentation for each of those substrings based on the surrounding context. Corpus analyses have found that morphological garden paths comprise roughly 4% of Chinese text (Qiao et al., 2008; Yen et al., 2012)."}, {"title": "Targeted Evaluation in NLP", "content": "Minimal pair benchmarks have been used to evaluate language models' compliance with morphosyntactic constraints such as subject-verb agreement or negative polarity item licensing (Linzen et al., 2016; Marvin and Linzen, 2018; Warstadt et al., 2020). Fu et al. (2020) propose an error analysis framework that compares Chinese word segmentation models' performance across inputs with differing values for various features, such as sentence length or word frequency."}, {"title": "Conclusion", "content": "This paper has proposed a benchmark, ERAS, that detects garden path errors in Chinese NLP models, with or without an explicit word segmentation step in the pipeline. Using ERAS, we have observed that both word segmentation models and sentiment analysis models are vulnerable to garden path errors. In both cases, models seem to inherit this vulnerability from their training distributions. The MSR segmentation corpus most effectively defends against garden path errors, while the ASAP dataset seems to exacerbate susceptibility to garden path errors. We also find that garden path errors are driven by particular kinds of inputs: left-branching inputs in the case of word segmentation, and -/+ inputs in the case of sentiment analysis.\nIt has been argued that character-level tokenization is superior to word-level tokenization for Chinese neural NLP models (Li et al., 2019), and indeed, most Transformer language models for Chinese use character- or byte-level tokenization. Our findings from Section 4, however, have shown that a total lack of word boundary information makes a model highly vulnerable to implicit garden path errors. We have shown that injecting word boundary information into the model through whole word masking or joint training on word segmentation can significantly reduce implicit garden path errors, though care must be taken to avoid degradations in model performance. We leave the development of such measures to future work."}, {"title": "Limitations", "content": "ERAS can only be used for two kinds of models: word segmentation models and sentiment analysis models. In particular, our mode of evaluation for sentiment analysis models requires access to the model's logits, and therefore it is not compatible with large language models whose logits are not available to the user.\nERAS is also a large, synthetically generated dataset, consisting of minimal pair paradigms. Large synthetic minimal pair datasets are known to have the following limitations. First, large datasets are intrinsically impossible to evaluate fully (Bender et al., 2021), and synthetic minimal pair datasets are often found to contain examples that do not conform to the intended properties of the datasets (Blodgett et al., 2021). Second, minimal pair datasets have been criticized for lacking structural diversity (Javier Vazquez Martinez et al., 2023). ERAS is not an exception to either of these limitations."}, {"title": "Ethical Considerations", "content": "We are not aware of any risks or ethical concerns arising from the work described in this paper."}]}