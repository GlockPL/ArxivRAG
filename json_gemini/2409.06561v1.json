{"title": "ChatGPT's Potential in Cryptography Misuse Detection: A Comparative Analysis with Static Analysis Tools", "authors": ["Ehsan Firouzi", "Mohammad Ghafari", "Mike Ebrahimi"], "abstract": "The correct adoption of cryptography APIs is challenging for mainstream developers, often resulting in widespread API misuse. Meanwhile, cryptography misuse detectors have demonstrated inconsistent performance and remain largely inaccessible to most developers. We investigated the extent to which ChatGPT can detect cryptography misuses and compared its performance with that of the state-of-the-art static analysis tools. Our investigation, mainly based on the CryptoAPI-Bench benchmark, demonstrated that ChatGPT is effective in identifying cryptography API misuses, and with the use of prompt engineering, it can even outperform leading static cryptography misuse detectors.", "sections": [{"title": "1 INTRODUCTION", "content": "Cryptography plays a vital role in software security by safeguarding data confidentiality. However, improper adoption (i.e., misuses) is prevalent [8, 10, 12, 13], and these misuses occur regardless of developer experience [11]. In response to these challenges, researchers have invested significant effort in building misuse detection tools [18, 21, 24] and designing more usable APIs [9, 15].\nThe recent surge in the use of Large Language Models (LLMs), such as ChatGPT, to facilitate software development has motivated researchers to explore these models for enhancing security as well [16, 27]. In this paper, we delve into this exciting prospect by investigating the capabilities of ChatGPT in detecting security risks specifically related to the Java Cryptography Architecture (JCA). Therefore, we asked the following research question (RQ): How well does ChatGPT perform in detecting Java cryptography misuse?\nWe conducted a rigorous evaluation primarily based on CryptoAPI-Bench, a benchmark specifically designed for Java cryptography"}, {"title": "2 JAVA CRYPTOGRAPHY", "content": "We present existing tools to uncover cryptography misuses as well as the established benchmarks to compare such tools."}, {"title": "2.1 Misuse Detectors", "content": "Java Cryptography Architecture (JCA) is a Java framework for cryptographic operations like encryption, decryption, signing, and verification. While JCA offers comprehensive tools, correct usage is vital to ensure security, as improper implementation can lead to vulnerabilities. Misuse of JCA is common, as evidenced by various studies [12, 19]. Incorrect usage can compromise security through weak keys, inadequate algorithm selection, improper handling of salts and nonces, or incorrect signature validation. To mitigate these risks, static analysis tools exist to identify cryptography misuse, e.g., SpotBugs with FindSecBugs plugin [7], CogniCrypt [17], CryLogger [22], and CryptoGuard [23]."}, {"title": "2.2 Benchmarks", "content": "Evaluating these tools requires robust benchmarks with realistic misuse patterns. In the realm of JCA misuse detection tools, several benchmarks exist (e.g., OWASP Benchmark [20], MUBench [3], CryptoAPI-Bench [1], CAMBench [25]), each with its limitations. We chose CryptoAPI-Bench as it is specifically designed for cryptographic analysis. In contrast, other benchmarks often include cryptography as just a subset of broader security concerns. Additionally, the performance results of various static analysis tools on CryptoAPI-Bench are well-documented in academic literature. This allows us to compare ChatGPT's results with those of existing tools, providing a comprehensive analysis of its capabilities. For checking the generalizability of our prompt optimization, we used CAMBench-a new, comprehensive benchmark for cryptographic API misuse detection tools. However, we did not use it as the base due to the lack of evaluation results for existing tools.\nCryptoAPI-Bench. This benchmark comprises 171 test cases utilizing the JCA and Java Secure Socket Extension (JSSE) APIs. Among these, 136 intentionally contain cryptographic API misuses, while the remaining 35 use the APIs correctly.\nThe test cases address various scenarios, each with a distinct purpose:\n1. Basic Cases: Focus on vulnerabilities within a single method, providing a foundational assessment of a tool's ability to detect straightforward cryptographic flaws.\n2. Advanced Cases: This category evaluates a tool's ability to identify vulnerabilities from various sources like methods, classes, variables, or conditional statements.\n2.1. Interprocedural: Involve vulnerabilities spanning multiple methods, challenging the tool to trace complex method invocations.\n2.2. Field-sensitive: Examine vulnerabilities dependent on data flow across different fields of the same object, evaluating the tool's precision in analyzing object-oriented structures.\n2.3. Combined: Present sophisticated scenarios merging interprocedural and field-sensitive aspects, requiring holistic vulnerability detection.\n2.4. Path-sensitive: Involve vulnerabilities based on conditional branches, testing the tool's capability to navigate diverse program paths.\n2.5. Miscellaneous: Include cases with irrelevant constraints and interfaces, testing the tool's robustness against diverse inputs and scenarios beyond typical use cases.\n2.6. Multiple Class: Involve vulnerabilities originating from external Java classes, simulating real-world situations where cryptographic weaknesses may spread across different program modules.\nThe misuses covered by cryptoAPI-bench are listed in Table 1. It also includes the description of each misuse, corresponding CWE-IDs, potential attacks, relevant APIs, and the number of test cases associated with each misuse.\nPrevious studies [2, 30] evaluated several tools using CryptoAPI-Bench and found CryptoGuard to be the most effective one, making this tool our baseline for comparison."}, {"title": "3 METHODOLOGY", "content": "We assessed ChatGPT's proficiency in detecting JCA misuse, and then improved its detection capabilities through prompt engineering. Lastly, we conducted a re-evaluation to confirm the results of our prompt optimization."}, {"title": "3.1 ChatGPT's JCA Misuse Detection", "content": "The objective of this stage was to evaluate ChatGPT's ability to identify misuse within the JCA using the CryptoAPI-Bench benchmark dataset. To ensure a comprehensive analysis, we followed four steps:\nStep 1. Research and Compilation of Security Violation Rules: We conducted an extensive review of the latest advancements in crypto misuse analysis. This review included consulting tools such as CryLogger [22] and CogniCrypt [17] and examining insights from recent scholarly article [8]. From this research, we compiled a detailed list of security violation rules that serve as guidelines for identifying potential vulnerabilities in cryptographic implementations.\nStep 2. Analysis of CryptoAPI-Bench Gaps: We examined CryptoAPI-Bench to identify scenarios that lacked test cases, based on the security rules identified in Step 1. For each identified gap, we sourced three relevant code snippets from Stack Overflow that demonstrated the insecure patterns derived from our compiled violation rules.\nStep 3. Security Evaluation of Test Cases: We prompted ChatGPT (GPT-3.5-turbo) to evaluate the security of each CryptoAPI-Bench test case using the query: \u201cPlease assess the security of the provided code and identify any vulnerabilities\". Recognizing the potential variability in responses from ChatGPT for identical prompts at different times, we issued this query three times to ensure reliability in the results.\nStep 4. Assessment of Extracted Code Snippets: We repeated the security evaluation process for the code snippets sourced in Step 2 to further assess ChatGPT's detection capabilities.\nIn the end, we identified specific test cases and code snippets where ChatGPT exhibited limitations in detecting misuse effectively.\""}, {"title": "3.2 Prompt Engineering", "content": "To enhance ChatGPT's detection abilities, we adopted a systematic approach detailed in the following steps:\nStep 1. We searched Google Scholar for recent research papers that contained keywords such as \"ChatGPT\" or \"Prompt Engineering\". We limited our investigation to papers published over the last three years (2022-2024) in top venues (core ranking A or A+) or those on arXiv with more than 5 citations. Additionally, we manually checked the conference programs for top-tier venues such as ICSE, FSE, ASE and ESEM to find related papers. From these sources, we collected prompt patterns acknowledged to enhance the quality of ChatGPT's responses.\nStep 2. Development of Optimized Prompts: Building on insights from the recent scholarly article [8] and the security violation rules identified in the previous stage, we utilized the prompt patterns established in Step 1. This led to the creation of optimized prompts specifically tailored for each misuse category."}, {"title": "3.3 Evaluation", "content": "We evaluated the optimized prompts using the CryptoAPI-Bench benchmark to compare the results with ChatGPT's performance without prompts. Additionally, to ensure generalizability, we also conducted an additional evaluation using a different benchmark. Specifically, for each test case where ChatGPT initially performed weakly, we executed new test cases from CAMBench to ensure the robustness of our findings and to mitigate any bias."}, {"title": "4 RESULT", "content": "We investigated the performance of ChatGPT in uncovering cryptography misuses in JCA and applied prompt engineering to enhance its effectiveness. Table 2 shows the performance results of CryptoGuard, ChatGPT, and ChatGPT with engineered prompts based on misuse categories, while Table 3 compares ChatGPT's performance with and without prompt engineering in both basic and advanced test cases."}, {"title": "4.1 ChatGPT's JCA Misuse Detection", "content": "4.1.1 Weak symmetric Encryption Algorithm: While the ChatGPT evaluation result suggests that it does not match up to CryptoGuard's performance in weak algorithm detection, it still demonstrates commendable proficiency, particularly in detecting basic cases. Additionally, it exhibits a robust ability to identify DES even in complex scenarios like interprocedural and field-sensitive contexts. However, our analysis reveals a notable issue where it mistakenly did not categorize IDEA 2 and Blowfish\u00b3 as weak algorithms.\n4.1.2 Weak Encryption Mode: Remarkably, both ChatGPT and CryptoGuard exhibited the same precision and recall in detecting the insecure Electronic Codebook (ECB) encryption mode. In a specific test case where no security risks were present, ChatGPT not only confirmed the absence of insecurity but also issued a warning: \u201cAlthough the class name suggests ECB mode (EcbInSymmCryptoCorrected), the code initializes the cipher in CBC mode (AES/CBC/PKCS5Padding). This inconsistency could lead to confusion and potential vulnerabilities\u201d.\nWe noted the absence of these test cases in CryptoAPI-Bench:\n1. Test cases with unspecified encryption modes for Cipher, which default to using ECB, a mode known to be insecure.\n2. Test cases with Cipher Block Chaining (CBC) encryption mode in client/server scenarios. This oversight may expose systems to security vulnerabilities, including the risk of an oracle-padding attack\nWe observed that ChatGPT successfully detected that the default encryption mode for symmetric encryptions, when not explicitly specified, is ECB and flagged it as insecure.\nWhile the CBC mode offers a robust mechanism for data confidentiality through its probabilistic encryption properties, it lacks message integrity protection. This vulnerability renders CBC unsuitable for applications requiring both confidentiality and authenticity, particularly in client-server communication scenarios. An evaluation of ChatGPT's responses to code snippets that utilize CBC encryption mode, extracted from accepted answers on StackOverflow, reveals a tendency for the model to recommend CBC as a secure option. This occurs even when CBC may not be the appropriate choice. For instance, in a security assessment for a client/server code snippet (from SO post ID 18291987), ChatGPT continued to suggest using CBC, despite its known unsuitability in certain contexts.4\n4.1.3 Predictable Key: While ChatGPT is not primarily designed as a detection tool, it notably surpassed CryptoGuard, a widely-used detection tool, in the realm of predictable key detection. ChatGPT achieved an impressive F-measure of 92.43%, outperforming CryptoGuard, which attained a score of 76.92%.\n4.1.4 Static Salt: ChatGPT, with an F-measure of 88.6%, demonstrates a slightly better ability to detect static salt than CryptoGuard, which has an F-measure of 85.71%.\nWe discovered the lack of test cases for small-size salts, a factor contributing to the weakness of Password-Based Encryption (PBE). Salts less than 64 bits are insufficient for effective security, as they significantly increase the risk of brute-force and rainbow table attacks.\nWe observed that ChatGPT can detect small-sized salts; for example, when directly provided with 4 as the salt size, it identifies this as a low salt size, which is insecure. However, if the size is derived from a calculation, such as keysize/64 where keysize equals 256, it fails to detect the insecurity6.\n4.1.5 Low Iteration: While the comparison between ChatGPT and CryptoGuard may suggest a low detection ability for ChatGPT, in reality, we observed that ChatGPT demonstrates robust capability in detecting the value of iteration counts across various scenarios, even when passed through parameters. However, it is important to note that while ChatGPT can successfully identify the value of iteration count in many instances, there are cases where it struggles to detect insufficient numbers of iterations.\n4.1.6 Weak Random generation: ChatGPT exhibited slightly lower precision than CryptoGuard in detecting weak random generation but achieved better recall and F-measure.\n4.1.7 Predictable PBE Password: While ChatGPT exhibits proficiency in predictable key detection, its performance in predictable password detection is comparatively weaker.\n\u2192 We observed that there were no test cases for checking weak PBE algorithms, such as the insecure \"PBEWithMD5AndDES\" or the bad practice \u201cPBKDF2WithHmacSHA1\u201d. This absence of tests can lead to the usage of these vulnerable algorithms, thereby compromising the overall security of the encryption process..\nWe observed that ChatGPT correctly flagged \u201cPBEWithMD5AndDES\u201d as a non-secure password-based key generation technique, but it recommended \u201cPBKDF2WithHmacSHA1\u201d as a secure option 8, whereas it is not a good practice. In some cases, ChatGPT suggested \"PBKDF2WithHmacSHA256\" for higher security.\n4.1.8 Static Initialization Vector: The precision of ChatGPT was comparable to CryptoGuard, but it demonstrated superior recall in this aspect (100%).\n\u2192 We found no test cases to verify if the same IV (Initialization Vector) was reused. This oversight could lead to potential replay attacks or compromise the encryption scheme's security, making it easier for attackers to decrypt the data..\n4.1.9 Predictable Password in keyStore. We observed that both ChatGPT and CryptoGuard demonstrated remarkable proficiency in detecting Predictable Passwords in keyStore. Their performance was notably similar, with both achieving a flawless 100% recall and an F-measure exceeding 93%."}, {"title": "4.1.10 Vulnerability in SSL/TSL", "content": "In our observations, ChatGPT did not perform as well as Cryptoguard. Cryptoguard outperformed it significantly, achieving a 100% recall rate and an F-measure of 95.83% in detecting SSL/TSL related vulnerabilities.\n4.1.11 Insecure Asymmetric Ciphers. We observed that ChatGPT excelled in detecting RSA keys with a key size less than 2048 bits as insecure across various test cases, outperforming CryptoGuard in this aspect.\nWe observed that there were no test cases for utilizing RSA with no padding, as well as for using PKCS1-v1.5 padding, both of which are considered bad practices in cryptography.\nWe observed that ChatGPT can detect RSA with no padding. However, it incorrectly considers PKCS1-v1.5 padding as a secure and good option 10, despite this being a bad practice and vulnerable to chosen-ciphertext attacks [5].\n4.1.12 Weak Hash Function. Similar to Cryptoguard, ChatGPT demonstrated proficiency in detecting Weak Hash Functions, achieving a recall rate of 100%.\nIn summary, we made the following observations about Chat-GPT's performance in detecting cryptography misuse, highlighting areas where prompt engineering could be beneficial:\n\u2022 High false positives in path-sensitive test cases.\n\u2022 Low accuracy in detecting insecure sizes.\n\u2022 Low recall and precision in detecting low iteration counts in PBE.\n\u2022 Considering CBC as a good practice regardless of context.\n\u2022 Considering common weak practices as good practices, such as using \"PBKDF2WithHmacSHA1\" for key generation or using \"PKCS1-v1.5\u201d padding."}, {"title": "4.2 Prompt Engineering", "content": "Despite the high volume of recent publications on large language models (LLMs), we found only four particularly useful for extracting prompt engineering techniques [6, 26, 28, 29]. From these papers, we learned that creating effective ChatGPT prompts necessitates understanding the user's objectives, recognizing ChatGPT's capabilities and limitations, incorporating relevant domain knowledge, and providing clear and specific instructions. Additionally, providing a few example responses can greatly assist ChatGPT in delivering more accurate and targeted answers.\n4.2.1 Prompt Optimization: In order to gain more accurate detection results we did the following steps.\nRole Specification: We directed ChatGPT to assume the role of a security expert with extensive expertise in cryptography. This approach enhances the accuracy and relevance of the responses by focusing on a specific domain.\nClarification: For cases where we find that ChatGPT recognizes common bad practices as good or practices that can be good or bad depending on the context (such as using CBC), we clearly state that these practices are blacklisted and issue a warning against them.\nGuided Logical Processing: We implemented steps to refine ChatGPT's understanding of checking the outcomes of calculations and conditions. This adjustment has improved the model's ability to detect false positives, enhance path sensitivity, and incorporate the results of calculations into its security assessments. For example, in section 4.1.4, we discussed how previously ChatGPT could not detect an insecure salt size when calculating keysize/64 where the keysize equals 256. However, with these improvements, it can now recognize such issues11.\nProviding Code Examples: To minimize ambiguity and enhance the precision of ChatGPT's analysis, few-shot examples are provided to clarify specific issues, thereby improving ChatGPT's ability to offer accurate and actionable advice.\nGuided Breakdown of Rules: To enhance ChatGPT's proficiency in detecting misuses of the JCA, each violation rule is meticulously broken down into simpler, more manageable components. This structured approach allows ChatGPT to better understand and evaluate each element."}, {"title": "Listing 1: Example of a true-negative test case", "content": ""}, {"title": "Listing 2: Optimized prompt result for Listing 1", "content": "Control of Verbosity: A recent study [14] indicates that ChatGPT often provides verbose replies, which can result in the transmission of incorrect information. To address this issue, we have adjusted the verbosity of ChatGPT's responses. This adjustment aims to reduce ambiguity and the spread of misinformation.\nListing 2 shows ChatGPT's response 12 alongside the guided prompt for the code snippet in Listing 1, which represents a path-sensitive and true negative test case. Initially, ChatGPT flagged it as insecure, struggling to track the data flow effectively. However,"}, {"title": "5 DISCUSSION", "content": "5.1 ChatGPT vs. Static Analysis Tools\nParameter Passing. Static analysis tools can struggle when it comes to accurately tracking parameter passing in code [4, 30]. This can lead to missed vulnerabilities or errors. However, ChatGPT has demonstrated proficiency in understanding parameter passing (see Section 4.1.4 example).\nLower and Upper Case Usage. Static analysis tools often face challenges in handling variations in case sensitivity [4]. ChatGPT, on the other hand, can adeptly detect vulnerabilities regardless of case usage. For example, whether it is \"AES/ECB\" or \"aes/ecb\", ChatGPT is capable of identifying vulnerabilities in both cases.\nPath Sensitivity. Static tools may struggle with path-sensitive cases, where the behavior of the program depends on the specific path taken through the code [2, 4]. While initial challenges may exist with path-sensitive cases, ChatGPT can overcome them through prompt engineering and guidance (see Table 3)."}, {"title": "5.2 ChatGPT and Iteration Count", "content": "While investigating the ability of ChatGPT to detect iteration counts less than 1000 for PBE in JCA, we observed that it struggled with identifying low iteration counts in several cases. We attempted to address this challenge by providing prompt guidance and using a few-shot example approach. However, despite detecting the iteration count correctly in some instances, ChatGPT still produced incorrect results in comparison. For instance, in the answer13 for"}, {"title": "6 THREATS TO VALIDITY", "content": "The possibility of data leakage from CryptoAPI-Bench, which may have been used in ChatGPT's training, is a potential threat to internal validity. However, there is no descriptive information about the misuses linked to the test cases (code snippets) and the issues are detailed in a separate Excel file located in a different directory. ChatGPT's descriptions did not closely resemble the content of the Excel file, and the low precision in detecting misuse for low Iteration count cases (48% precision) suggests that data leakage is unlikely. Nevertheless, further investigation is warranted.\nThe variability in ChatGPT's responses, even when the same prompt is used multiple times, also poses a potential threat to internal validity. To mitigate this threat, we implemented a procedure where each prompt was submitted three times. We then based our analysis on the aggregated results of these three responses, rather than relying on a single instance. This approach helps to ensure a more reliable assessment of ChatGPT's detection ability.\nThere exists a threat to external validity from the fact that we mainly relied on the CryptoAPI-Bench benchmark to assess ChatGPT, limiting the generalizability of our findings. To address this issue, we also analyzed a set of misuse cases from StackOverflow (in total 24 test cases) that were not addressed in CryptoAPI-Bench. Additionally, we examined optimized prompts on test cases from CAMBench (34 new test cases)."}, {"title": "7 CONCLUSION", "content": "Cryptography is crucial for data confidentiality, but the complexity of cryptography APIs often leads to widespread misuse in software systems.\nWe investigated ChatGPT's performance in detecting cryptography misuses using two cryptography benchmarks and 24 test cases collected from StackOverflow. Our findings revealed that, with optimized prompts, ChatGPT is effective at identifying cryptography misuses in Java Cryptography Architecture (JCA). Notably, it outperforms CryptoGuard, the leading state-of-the-art cryptography misuse detector.\nWe conducted this study using GPT-3.5 Turbo, and in the future, we plan to investigate current models such as GPT-40 for ChatGPT and cover test cases that are representative of real-world cryptography API use."}]}