{"title": "Fire-Image-DenseNet (FIDN) for predicting wildfire burnt area using remote sensing data", "authors": ["Bo Pang", "Sibo Cheng", "Yuhan Huang", "Yufang Jin", "Yike Guo", "I. Colin Prentice", "Sandy P. Harrison", "Rossella Arcucci"], "abstract": "Predicting the extent of massive wildfires once ignited is essential to reduce the subsequent socioeconomic losses and environmental damage, but challenging because of the complexity of fire behaviour. Existing physics-based models are limited in predicting large or long-duration wildfire events. Here, we develop a deep-learning-based predictive model, Fire-Image-DenseNet (FIDN), that uses spatial features derived from both near real-time and re-analysis data on the environmental and meteorological drivers of wildfire. We trained and tested this model using more than 300 individual wildfires that occurred between 2012 and 2019 in the western US. In contrast to existing models, the performance of FIDN does not degrade with fire size or duration. Furthermore, it predicts final burnt area accurately even in very heterogeneous landscapes in terms of fuel density and flammability. The FIDN model showed higher accuracy, with a mean squared error (MSE) about 82% and", "sections": [{"title": "1. Introduction", "content": "The frequency and intensity of large wildfires have increased in many parts of the world in recent years (Dutta et al., 2016, Iglesias et al., 2022, J et al., 2022). Large wildfires have a significant impact on ecological resources (Keeley et al., 2019, Halofsky et al., 2020), local and regional climate (Bar\u00f3 et al., 2017, Stocker et al., 2021), social infrastructure (Thomas et al., 2017, Fraser et al., 2022, Varga, 2022) and human life and well-being (Johnston et al., 2012, Bowman et al., 2017, Yu et al., 2020, Chen et al., 2021). Significant resources are spent on firefighting, preventing and managing wildfires (Wang et al., 2021, Simon et al., 2022). Predicting the spread and potential final extent of a given wildfire timely is important for disaster response and management (Fairbrother and Turnley, 2005, Taylor et al., 2013), potentially including decisions about the allocation of firefighting resources and community evacuations.\nSeveral types of models have been developed to simulate fire spread (Sullivan, 2009), including empirical models (Plourde et al., 1997, Guariso et al., 2002) and physics-based models (Alexandridis et al., 2008, Anderson et al., 1982, Burgan, 1984, McArthur, 1967). Empirical models are based on statistical relationship between environmental factors and fire behaviour (Sullivan, 2007). Physics-based models rely on physical principles, such as Rate of spread (ROS) modelling (Johnson and Miyanishi, 2001) or Huygens wavelet principle (Anderson et al., 1982). Among them, the Cellular Automata(CA) approach proposed by (Alexandridis et al., 2008) uses regular square meshes to simulate fire propagation along the grid to the neighbour cells. Each cell is categorised as non-combustible, combustible, burning, or burnt. At each"}, {"title": "2. Methodology", "content": "In this section, we present the structure, training methods and evaluation metrics of the proposed FIDN model."}, {"title": "2.1. Overall Research Framework", "content": "In this study, we propose the Fire-Image-DenseNet (FIDN) model for accurate prediction of wildfire burnt areas utilizing advanced deep learning techniques. Our approach is driven by the critical need for effective and timely wildfire forecasting of where fire would stop in the absence of human intervention, which can significantly enhance preventive measures and resource allocation during wildfire incidents. The FIDN model combines the strengths of DenseNet architecture for feature extraction with a custom forecasting network designed to produce high-resolution predictions of final burnt areas. Through this methodology, we aim to leverage satellite observationsof the first three days of fire spread and relevant environmental data"}, {"title": "2.2. Densely Connected Convolutional Networks", "content": "The CNNs is an important method in the field of image feature extraction that has been evolving for over 20 years (LeCun et al., 1989). Compared with fully connected neural networks, it uses convolutional operations that are more appropriate for processing two-dimensional image information and significantly reduce the number of parameters (Bouvrie, 2006). During the long development history of CNNs, many classical models have been proposed. From the initial 5-layer LeNet5 (LeCun et al., 1998) to the Residual Network (ResNet) (He et al., 2016) with over 100 layers, CNNs have been enhanced gradually to extract image features. In recent years, two main directions have been proposed to improve the effectiveness of CNN, either by increasing the depth of the network such as ResNet (He et al., 2016) or by extending the width of the network such as GoogleNet's Inception (Szegedy et al., 2016).\nAs the depth of the network increases, the problem of vanishing gra-dients (Hanin, 2018, Huang et al., 2017) has been noticed, leading to a degradation of network performance (Hochreiter, 1998). ResNet attempts to address performance degradation through residual learning. Residual learn-ing is making shortcut connections between layers, which allows the stacked layers to learn directly from the input layers (He et al., 2016). GoogleNet's"}, {"title": "2.3. Fire-Image-DenseNet(FIDN)", "content": "The Fire-Image-DenseNet (FIDN) model is designed for wildfire prediction and consists of two main components: a feature extraction network and a forecasting network. The FIDN model inputs consist of two types of data: Remote Sensing Data of Wildfires (fireburnt areas of the first three days after ignition) and relevant Geographic and Meteorological Data in the corresponding ecoregions including vegetation density, biomass carbon den-sity, forest and grassland distribution, slope, wind angle and velocity, and"}, {"title": "2.3.1. Feature Extraction Network: FIDN Encoder", "content": "The feature extraction network is responsible for extracting and concate-nating feature maps from various input images of all 15 layers, which are then fed into the forecasting network. The network is built using DenseNet architecture, specifically adapted for wildfire prediction by removing the top classification layer.\nEach FIDN Encoder consists of convolutional layers followed by Dense blocks and Transition layers. To introduce non-linearity in the model and ad-dress the vanishing gradient problem, we apply the Rectified Linear Unit(ReLU) activation function after Batch Normalization in all convolution and dense block contexts throughout the model.\nAs mentioned above, The feature extraction network accommodates two types of inputs: Remote Sensing Data of Wildfires and Geographic and Me-teorological Data. Based on the objectives of feature extraction, we have selected different input resolutions for these data types.\nFor remote sensing images of wildfire burnt areas, which contain critical details essential for capturing the dynamic changes of wildfires, we have cho-sen a relatively high resolution. This choice facilitates the preservation of spatial and visual details, thereby enabling more precise feature extraction. In this study, we use a resolution of 512x512 for this purpose.\nConversely, for images representing other vegetation, tropological and meteorological features, such as biomass, slope, and wind, we aim to reduce computational complexity during feature extraction while ensuring that these features are effectively processed and integrated. Therefore, we standardize these features to a smaller, uniform resolution of 128x128. By handling them separately, we ensure that each data type is appropriately processed, preserving the integrity of the information. This method allows each type of data to be processed and integrated effectively, considering their unique characteristics and resolutions.\nTo accommodate these different image dimensions and types, we employ two variants of the FIDN Encoder: FIDN Encoder-512 and FIDN Encoder-128. It is important to note that while we have chosen input dimensions of 512x512 and 128x128 in this design, the architecture and methodology are highly versatile and flexible. Researchers can adjust input resolutions and encoder structures based on specific research requirements and data charac-teristics to suit different datasets and prediction tasks. This design approach is adaptable to images of other dimensions and can be expanded to develop"}, {"title": "2.3.2. Forecasting Network: FIDN Decoder", "content": "The FIDN Decoder aims to predict the final burnt area by process-ing the concatenated features through a series of deconvolutional layers and Conv Blocks. The structure of the decoder includes: a deconvolution layers (Conv2DTranspose) with kernel sizes of 2 and strides of 2, used to upsample the feature maps gradually. The deconvolution layer is followed by a Conv Block, which includes a convolutional layer with a 3 \u00d7 3 window and ReLU activation. for data ascension and valid information separation.\nThe encoded input (after the feature extraction network) is passed through 5 FIDN Decoders sequentially. The final output layer applies a sigmoid ac-tivation function to produce a predicted image with dimensions 512 \u00d7 512."}, {"title": "2.4. Loss Function and Metrics", "content": "To accurately assess our model's performance in predicting binary im-ages of wildfire burnt areas, we employ a combination of evaluation metrics: Binary Cross-Entropy (BCE), Mean Squared Error (MSE), Root Relative Squared Error (RRMSE), Structural Similarity Index Measure (SSIM), and Peak Signal-to-Noise Ratio (PSNR). The use of binary representation frames our task as a binary classification problem for each pixel, making BCE and MSE essential for evaluating classification accuracy and prediction error. Ad-ditionally, RRMSE, SSIM, and PSNR are chosen to measure the visual quality and structural integrity of the predicted images against actual satellite observations.\nFor the sake of notation, in the following equations, we assume a prepro-cessed wildfire burnt area image consists of N \u00d7 M pixels. (i, j) represents the pixel coordinates in the image with 0 \u2264 i \u2264 N, 0 \u2264 j \u2264 M. Ft) denotes the true burnt image observed by the satellite on day t.  F(nk) is a binary number representing the burn information at pixel (i, j) on day nk. The predicted burnt status (i.e., the output of predictive models) is denoted by\n F(nk) ."}, {"title": "1. Binary Cross-entropy(BCE)", "content": "Binary Cross-entropy is a loss func-tion commonly used in binary classification problems (Ho and Wookey, 2019). The formula for this algorithm is shown in Eq. 1.\nBCE=\u2212\n1\nN M\n\u2211\ni=0\nN\n\u2211\nj=0 (F(nk)ij \u00b7log(F(nk)ij )+(1\u2212F(nk)ij )\u00b7log(1\u2212(F(nk)ij)), (1)\nWhen Binary Cross-entropy is selected as the loss function, this prediction task can be regarded as a binary classification problem on the pixel level, predicting whether the region represented by each pixel has been burnt out or not."}, {"title": "2. Mean Squared Error(MSE)", "content": "Mean Squared Error measures the average squared difference between the estimated and actual values, a long-established metric for evaluating the similarity of images (Marmolin, 1986), and physical fields Xu et al. (2024), Fu et al. (2023). The MSE formula is presented in Eq. 2.\nMSE =\n1\nN M\n\u2211\ni=0\nN\n\u2211\nj=0 ((F(nk)ij ) \u2212 (Fnk))2 (2)"}, {"title": "3. Relative Root Mean Squared Error(RRMSE)", "content": "Root Mean Squared Error (RMSE) is the square root of MSE, while Relative Root Mean Squared Error (RRMSE) is the dimensionless form of RMSE as formulated using Eq. 3.\nRRMSE=\n\u221aMSE\nN\n\u2211\ni=0 (F(nk))2 (3)"}, {"title": "4. Structural Similarity(SSIM)", "content": "Structural Similarity is a measure of the similarity between two images (Wang et al., 2004). For simplicity, here we denote x as the actual field of burnt status F(t) and y as the predicted burnt status F(t), the SSIM between them can then be formalised by Eq. 4.\nSSIM(x,y)=\n(2\u00b5x+\u00b5y+c1)(2\u03c3xy+c2)\n(\u00b52x+\u00b52y+c1)(\u03c32x+\u03c32y+c2)\n(4)\nwhere (\u00b5x, \u03c32x)/(\u00b5y, \u03c32y) denote the mean and the variance of x and y respectively, \u03c3xy denotes the covariance of x and y, c1 and c2 are constant coefficients"}, {"title": "5. Peak signal-to-noise ratio (PSNR)", "content": "Peak signal-to-noise ratio, as defined in Eq. 5, is also a well-known metric for image similarity (Hore and Ziou, 2010).\nPSNR=10\u00b7log10 (\nMax (F(t)kij)2\nMSE)(5)\nwhere Max(Ft)) is the maximum value in the final burnt area. Compared to MSE (Sara et al., 2019), PSNR is also capable of giving perception-based errors."}, {"title": "3. Study area and Data curation", "content": "In this section, we describe the data sources and preprocessing methods used to train and test FIDN.\nFormally, for a wildfire event indexed k of duration nk days, {F(t)kij}nk denotes the burnt area on day t, which is defined on a two-dimensional grid.F(t)kij \u2208 RNk\u00d7RMk where Nk\u00d7 Mk is the dimension of the ecoregion. Each point in the grid Ft) (0 \u2264 i \u2264 Nk, 0 \u2264 j \u2264 Mk) is represented in binary numbers, where 0 for not burnt and 1 for burnt. This approach streamlines the model's focus on predicting the final burnt area, simplifying input complexity and enhancing both training and prediction efficiency. Such binary simplification reduces the computational load, crucial for accurately forecasting fire spread with clear target states. Additionally, acquiring and processing more detailed wildfire-related parameters is notably time-consuming, making the binary representation advantageous by mitigating the extensive time and resources required for data collection and preparation.\nThe FIDN model takes the burnt area of the first three days after ig-nition (i.e. F(0), F(1) and F(2)) as input and outputs the final burnt area (F(nk)). The data of {F(t)}t=1,...,nk is extracted from the daily fire perimeter database generated from the Moderate Resolution Imaging Spectroradiome-ter (MODIS) and the Visible Infrared Imaging Radiometer Suite (VIIRS) active fire products Scaduto et al. (2020). VIIRS detected hot spots twice a day on a global scale at a resolution of 275m while MODIS provides hot spot detection 4 times a day globally (Giglio et al., 2016). To characterize"}, {"title": "4. Numerical Results", "content": "In this section, we present and analyze the FIDN model proposed in this paper for predicting the final burnt area of wildfires in the test dataset. The performance of the proposed approach is compared against the state-of-the-art CA (Alexandridis et al., 2008) and MTT (Finney, 2002) models.\nAs mentioned in Section 2, We train our predictive model, FIDN, using the daily burnt area for 243 individual wildfires from the western US that"}, {"title": "5. Conclusion and future work", "content": "In this paper, we propose a deep learning predictive model, named Fire-Image-DenseNet (FIDN), which takes the initial burnt area (for the first three days), together with geophysical and climate data as inputs to predict the final burnt area of wildfires. We have shown that our new FIDN model pro-duces realistic predictions of final burnt areas independent of fire size or fire duration. The structure of FIDN relies on the advanced DenseNet network that takes full advantage of convolutional neural networks and significantly reduces computational costs and computation time.\nSince the model ingests remotely sensed information, it would be possible to update the predictions regularly using fire line and burn data from MODIS to take account of any changes in fire behaviour. At present, the model uti-lizes a combination of current reanalysis data. Future research will explore the integration of real-time data sources to enable real-time forecasting ca-pabilities. This would make it possible to use the model to determine the potential impact of specific fire-fighting strategies to manage ongoing wild-fire events, such as the optimal location for the application of fire retardants or the creation of fire breaks. While it would be useful to test the FIDN model in other regions, the method is data-agnostic and could be applied to wildfires in other areas globally. Thus, the FIDN model can provide a useful tool to enable land managers and fire services to deal with wildfires more promptly, thus reducing the negative impacts of fire on the environment."}, {"title": "Appendix: comparison against an autoregressive fire prediction model", "content": "In our study, we initially evaluated various deep learning models and ulti-mately selected DenseNet for our Fire-Image-DenseNet (FIDN) approach. \u03a4\u03bf explore alternative models further, we considered ConvLSTM, a state-of-the-art deep learning model commonly utilized for forecasting spatial-temporal sequences. However, the primary objective of our research is to predict the final burnt area of wildfires from the onset of ignition. ConvLSTM, by con-trast, is inherently designed to predict subsequent frames within a sequence, which poses limitations in our context due to the variable durations of wild-fires.\nSubsequently, we analyzed and compared the performance of the two models in predicting the final burned area of wildfires based on the data presented in Table 6. The results for SSIM indicate that both the mean and median values for FIDN are significantly higher than those for ConvLSTM, suggesting that FIDN performs better in capturing the structure and details of the images. Similarly, the PSNR results, while showing higher values for ConvLSTM, also exhibit a larger standard deviation, indicating instability and unreliability in its predictions. In terms of MSE, while ConvLSTM shows lower values, our images are largely binary, with most pixels indicating un-burned areas (value 0), making MSE less reflective of accuracy in the actually burned regions. The RRMSE metric, on the other hand, reveals that FIDN achieves lower relative error, emphasizing its ability to accurately predict the crucial non-zero areas that define the final burnt regions in these binary images. Notably, in the RRMSE metric, both the mean and median values for FIDN considerably outperform those of ConvLSTM, underscoring its ad-vantage in relative error measurement. Our tests showed ConvLSTM could only predict the fourth day's burned area accurately, leading to predictions that closely resemble the initial input image rather than the final burnt area.\nTo further demonstrate FIDN's predictive accuracy for final burned ar-eas, we selected three prolonged wildfires for case analysis. These images illustrated the significant discrepancies between the predictions made by the ConvLSTM model and the actual burned areas (See Figure 11). Through these real-world examples, it becomes evident that while ConvLSTM may"}]}