{"title": "Self-Explaining Hypergraph Neural Networks for Diagnosis Prediction", "authors": ["Leisheng Yu", "Yanxiao Cai", "Minxing Zhang", "Xia Hu"], "abstract": "The burgeoning volume of electronic health records (EHRSs) has enabled deep learning models to excel in predictive healthcare. However, for high-stakes applications such as diagnosis prediction, model interpretability remains paramount. Existing deep learning diagnosis prediction models with intrinsic interpretability often assign attention weights to every past diagnosis or hospital visit, providing explanations lacking flexibility and succinctness. In this paper, we introduce SHy, a self-explaining hypergraph neural network model, designed to offer personalized, concise and faithful explanations that allow for interventions from clinical experts. By modeling each patient as a unique hypergraph and employing a message-passing mechanism, SHy captures higher-order disease interactions and extracts distinct temporal phenotypes as personalized explanations. It also addresses the incompleteness of the EHR data by accounting for essential false negatives in the original diagnosis record. A qualitative case study and extensive quantitative evaluations on two real-world EHR datasets demonstrate the superior predictive performance and interpretability of SHy over existing state-of-the-art models. The code is available at https://anonymous.4open.science/r/SHy.", "sections": [{"title": "1. Introduction", "content": "Electronic health records (EHRs) are large-scale chronologies of patients' hospital visits, encapsulating their longitudinal healthcare experiences (Si et al., 2021). The surge in EHR data has fostered the development of deep learning models for tasks like diagnosis prediction, mortality prediction, and drug recommendation (Xu et al., 2023; Song et al., 2018; Tan et al., 2022). Among these, diagnosis prediction based on longitudinal EHRs is of particular significance, as it directly correlates with health risk identification and the quality of personalized healthcare (Zhang et al., 2019). As shown in Figure 1, longitudinal EHR data comprise sequentially time-stamped hospital visits, each being an unordered set of diagnoses (Zhang et al., 2020a). The aim of diagnosis prediction is to forecast potential diagnoses for a patient's subsequent visit based on historical records.\nBecause the outcomes of diagnosis prediction are communicated to both clinicians and patients, model interpretability is crucial (Tonekaboni et al., 2019; Meng et al., 2022). Concerns that post-hoc ex-"}, {"title": "2. Related Work", "content": null}, {"title": "2.1. Deep Learning on Longitudinal EHRS", "content": "Applying deep learning models to longitudinal EHRS for predictive tasks centers around learning adequate patient representation (Choi et al., 2018, 2016b; Tan et al., 2024). To model temporal disease progression"}, {"title": "2.2. Intrinsically Interpretable Models", "content": "Intrinsic interpretability, which means that predictive models provide their own explanations, is favored over post-hoc interpretability that necessitates a separate model for explaining a black-box model, because the explanations provided by intrinsically interpretable models are exploited in the decision-making process and faithful to model predictions (Du et al., 2019; Rudin, 2019). SENN (Alvarez Melis and Jaakkola, 2018) is a class of self-explaining neural networks whose interpretability is enforced via regularization. A self-explaining deep learning model proposed by Li et al. (2018) utilizes an autoencoder and a prototype classifier network to provide case-based rationales. The attention mechanism has been"}, {"title": "3. Methodology", "content": "An overview of the proposed model, SHy, is illustrated in Figure 2. Before delving into the details of the method, it is essential to formulate the problem at hand: diagnosis prediction using longitudinal electronic health record data."}, {"title": "3.1. Problem Formulation", "content": "An EHR dataset contains various diseases, each assigned a diagnosis code according to the International Classification of Diseases, Ninth Revision (ICD-9). ICD-9 codes have a hierarchical structure. For example, both acute respiratory failure (ICD-9 code 518.81), and chronic respiratory failure (518.83) are children of other diseases of lung (518.8). The set of all unique diagnosis codes within an EHR dataset is denoted as $C_1, C_2, ..., C_{|c|} \\in C$, and $|C|$ indicates the size of this set. Assuming that we have N patients in a longitudinal EHR dataset, we can represent the n-th patient as a sequence, $[(e_n^1, t_n^1), (e_n^2, t_n^2), ..., (e_n^{T(n)}, t_n^{T(n)})]$, where T(n) is the number of past visits, $e_n^j$ denotes the diagnosis codes recorded in the j-th visit, and $t_n^j$ signifies the timestamp. $e_n^j \\in {0,1}^{|C|}$ is a multi-hot vector, where the i-th entry equals 1 if visit j includes $c_i$. The task"}, {"title": "3.2. Personalized Disease Representation Learning", "content": "Before detailing how SHy learns personalized diagnosis code embeddings to reflect different comorbidities, we outline how it models hierarchical disease relationships, a common practice in related works (Ma et al., 2018b; Qiao et al., 2020; Peng et al., 2021a,b)."}, {"title": "3.2.1. LEARNING HIERARCHICAL DISEASE EMBEDDINGS", "content": "ICD-9 organizes diseases into a tree structure with each child node having a single parent. This medical ontology can be used to enhance the representation learning process for diagnosis codes, defining relative disease distances. Thus, previous work has"}, {"title": "3.2.2. CONSTRUCTING PATIENT HYPERGRAPHS", "content": "To model individual comorbidities for personalized patient representation, we should represent each patient as an independent entity and effectively capture disease interactions. One intuitive method is to represent patients as ordinary graphs where diseases form nodes and co-occurrences create edges. However, this strategy requires the construction of an adjacency matrix of size $|C|\\times |C|$ for every patient. Since an EHR dataset typically contains thousands of unique diagnosis codes and tens of thousands of patients, this leads to prohibitively high space complexity. Moreover, an ordinary graph only models pairwise interactions, but the co-occurrence of multiple diseases in a single visit suggests non-pairwise relationships. Hypergraphs, as an alternative to ordinary graphs, can address these issues. They can represent higher-order relations because hyperedges in hypergraphs can connect any number of nodes. Therefore, we model each patient as a hypergraph, with diseases as nodes and hospital visits as hyperedges. In this way, higher-order interactions among diseases can be captured. Each patient hypergraph, G = (C,E), can be represented as an incidence matrix $P \\in {0,1}^{|C|\\times T}$, where $P_{ij} = 1$ if the j-th visit"}, {"title": "3.2.3. MODELING INDIVIDUAL COMORBIDITIES", "content": "To model distinctive comorbidities and thus learn personalized diagnosis code embeddings, SHy conducts message passing on the constructed patient hypergraphs. With numerous hypergraph neural network architectures in the existing literature, we experimented with several state-of-the-art models, the results of which are discussed in Appendix B. We empirically selected UniGIN (Huang and Yang, 2021) as SHy's message passing mechanism. UniGIN generalizes Graph Isomorphism Networks (GIN) (Xu et al., 2018) to hypergraphs by formulating it as a two-stage aggregation process. Specifically, SHy first obtains visit embeddings by aggregating the embeddings of diagnosis codes within the respective visit:\n$V_j^{(z)} = \\frac{1}{|e_j|} \\sum_{i \\in e_j} M_i^{(z)}$,\nwhere $V_j^{(z)}$, $|e_j|$, and z denote the embedding of the j-th visit, number of diseases within the j-th visit, and the index of UniGIN layers, respectively. We set $M_i^{(0)} = M$. Next, SHy updates diagnosis embeddings by aggregating the embeddings of visits containing the corresponding diagnosis:\n$M_i^{(z+1)} = \\sigma (W^{(z)}_{GIN}((1+\\epsilon)M_i^{(z)} + \\sum_{j \\in E_i} V_j^{(z)}))$,\nwhere $\\sigma$ is Leaky ReLU, $W^{(z)}_{GIN} \\in \\mathbb{R}^{d^{(z+1)} x d^{(z)}$ denotes learnable weights of the z-th UniGIN layer, $\\epsilon$ is a learnable parameter, and $E_i$ represents the set of indices of visits including $c_i$. By stacking Z layers of message passing mechanisms on individual patient hypergraphs, SHy adeptly models complex interactions among diseases within the Z-hop neighborhood. Thus, disease embeddings for a specific patient are strongly influenced by the combinations of diseases that this patient had within and across different visits.\nIn summary, after this stage, an updated personalized embedding table of diagnosis codes, $M^{(Z)} \\in \\mathbb{R}^{|C|\\times d^{(Z)}}$, is obtained for each patient. The superscript (Z) will be omitted in subsequent sections."}, {"title": "3.3. Temporal Phenotype Extraction & Modeling", "content": "Since the diagnosis history of a patient possibly suffers from incompleteness, SHy introduces false negative disease-visit pairs into the constructed patient hypergraph prior to phenotype extraction. These additions are generated through calculating the multi-head weighted cosine similarity between nodes and hyperedges:\n$S_{ij} = \\frac{1}{n_s} \\sum_{k=1}^{n_s} \\frac{(\\Phi_k M_i) \\cdot (\\Phi_k V_j)}{||\\Phi_k M_i || ||\\Phi_k V_j ||}$,\nwhere $\\odot$ symbolizes element-wise multiplication, $S_{ij}$ denotes the similarity score between the embeddings of $c_i$ and the j-th visit, $\\Phi_k \\in \\mathbb{R}^{n_s \\times d^{(z)}}$ represents a stack of $n_s$ independent learnable weight vectors, and $V_j$ is obtained through Equation (2). To avoid adding redundant connections, SHy enforces $S_{ij} = 0$ if $c_i$ was originally included in the j-th visit. Next, SHy derives a supplementary patient hypergraph, $\\Delta P \\in {0,1}^{|C|\\times T}$, based on the similarity scores:\n$\\Delta P_{ij} = \\begin{cases} 1, & S_{ij} \\in topk(S, p\\sum |e_j|)  \\ 0, & S_{ij} \\notin topk(S, p\\sum |e_j|) \\end{cases}$,\nwhere p is the ratio of the number of connections in the supplementary hypergraph to those in the initial patient hypergraph. Then, an updated patient hypergraph, $P' = P + \\Delta P$, is produced. SHy essentially augments the original patient records with additional disease-visit pairs possessing the highest similarity scores, with the quantity of the supplementary pairs being p of the original total diagnosis count.\nSHy extracts K temporal phenotypes, each being a unique subgraph of the updated patient hypergraph. Specifically, to extract Phenotype k, SHy learns a binary matrix denoted by $\\Gamma_k \\in {0,1}^{|C|\\times T}$. Each entry, $\\Gamma_{ij}$, serves as a masking factor for $P_{ij}$ and is a random variable following a Bernoulli distribution parameterized by a probability weight, $O_{ij}$. This weight is derived from the embeddings of the corresponding disease and visit:\n$O_{ij} = MLP([M_i || V_j])$.\nTo allow backpropagation while producing the discrete binary matrix $\\Gamma_k$, SHy employs the Gumbel-Softmax trick:\n$\\Gamma_{ij} = \\sigma(\\frac{\\log(\\frac{O_{ij}}{1-O_{ij}}) + (g_0 - g_1)}{\\tau})$,"}, {"title": "3.4. Prediction and Objectives", "content": "To predict subsequent diagnoses, SHy embeds K temporal phenotypes using a Gated Recurrent Unit (GRU) and location-based attention mechanism:\n$V^k = {\\Psi^k}^\\top M$\n$H_1^k, H_2^k, ..., H_{T(t)}^k = GRU(V_1^k, V_2^k, ..., V_{T(t)}^k)$\n$\\alpha^k = Softmax(MLP(H_t^k))$\n$U^k = \\alpha^k H_t^k$,\nwhere $V^k \\in \\mathbb{R}^{T \\times d^{(z)}}$ is a stack of embeddings of visits in Phenotype k, $H_t^k \\in \\mathbb{R}^{d_{hid}}$ denotes the hidden state corresponding to the t-th visit, $\\alpha_t^k \\in \\mathbb{R}^{T}$ represents weights of hidden states, and $U^k \\in \\mathbb{R}^{d_{hid}}$ is the embedding of Phenotype k. Next, SHy derives importance weights, $\\alpha \\in \\mathbb{R}^{K}$, for all phenotypes with a self-attention mechanism:\n$head_i = Attention(UW_i^Q, W_i^K, UW_i^V)$\n$\\alpha = Softmax([head_1 || head_2 || ... || head_{n_h}]w^o)$.\nHere, $W^Q \\in \\mathbb{R}^{d_{hid} \\times d_Q}$, $W^K \\in \\mathbb{R}^{d_{hid} \\times d_Q}$, $W^V \\in \\mathbb{R}^{d_{hid} \\times d_V}$, and $w^o \\in \\mathbb{R}^{d_V}$ are learnable parameters, and $Attention(Q, K, V) = Softmax(\\frac{QK^T}{\\sqrt{d_k}})V$, where $d_k$ denotes the dimensionality of K. The final prediction, $\\hat{y} \\in \\mathbb{R}^{|C|}$, is a weighted sum of predictions from K phenotypes:\n$\\hat{y} = \\alpha (Softmax(UW + b))$,\nwhere $W \\in \\mathbb{R}^{d_{hid} \\times |C|}$ and $b \\in \\mathbb{R}^{|C|}$ denote learnable parameters. The prediction loss for all patients is calculated using cross-entropy:\n$L_{pred} = \\frac{1}{N} \\sum_{n=1}^N -[y_n \\log(\\hat{y}_n) + (1 - y_n) \\log(1 - \\hat{y}_n)]$,\nwhere $y_n = e_{m(n)+1}$. The K temporal phenotypes, along with their respective importance weights, act as model explanations. To ensure that the extracted phenotypes faithfully preserve relevant input information, SHy employs a GRU decoder, the details of which are introduced in Appendix C, to reconstruct the original patient hypergraph a sequence of multi-hot vectors from the concatenated phenotype embeddings, $[U_1 || U_2 || ... || U_K]$. The fidelity of explanations is enhanced by penalizing the reconstruction error:\n$L_{fidelity} = \\frac{1}{N} \\sum_{n=1}^N \\frac{1}{T^{(n)}} \\sum_{j=1}^{T^{(n)}} \\sum_{i=1}^{|C|} -(P_{ij} \\log(\\hat{P}_{ij}) + (1 - P_{ij}) \\log(1 - \\hat{P}_{ij}))$,\nwhere $\\hat{P}$ denotes the reconstructed hypergraph for the n-th patient. Moreover, the K temporal phenotypes need to be non-overlapping in order to be meaningful, i.e., different phenotypes include different diagnoses for a given visit. SHy achieves distinctiveness by penalizing common diagnoses across K binary masks for one visit:\n$B_j = [\\Gamma_{1j}, \\Gamma_{2j}, ..., \\Gamma_{Kj}] \\in \\mathbb{R}^K$\n$L_{distinct} = \\frac{1}{N} \\sum_{n=1}^N \\frac{1}{T^{(n)}} \\sum_{j=1}^{T^{(n)}} ||I_{T^{(n)}} - B_j B_j^\\top||^2$,\nwhere $I_{T^{(n)}}$ denotes a $T^{(n)} \\times T^{(n)}$ identity matrix, $\\Gamma_{kj}$ represents the j-th column of the binary mask $\\Gamma_k$, and $B_j$ specifies the diagnoses each masking matrix retains for the j-th visit. The aim is to encourage columns of $B_j$ to form an orthonormal set. Since $B_j$ is a binary matrix, columns being orthonormal vectors implies that there is no overlap across the K phenotypes for the j-th visit and each phenotype only includes one diagnosis for this visit. Thus, $L_{distinct}$ also pushes the phenotypes to be concise. Lastly, SHy enforces regularization to prevent the distribution of the K attention weights from being uniform or too extreme, ensuring clear relative importance among phenotypes and no extracted phenotype receiving 0 as the weight:\n$L_{\\alpha} = \\frac{1}{N} \\sum_{n=1}^N (\\frac{|(\\alpha^n) - (\\frac{\\overline{\\alpha}}{K})|^2}{||\\alpha^n||^2})$,\nwhere $\\alpha^n$ denotes attention weights for the phenotypes of the n-th patient. The final loss function is"}, {"title": "4. Experiments", "content": "In this section, we evaluate SHy against state-of-the-art diagnosis prediction models in terms of predictive performance and interpretability, and assess the effectiveness of its novel components. We further demonstrate SHy's robustness against false negative diagnoses and its explanation capabilities, highlighting how domain experts can seamlessly intervene in the prediction process."}, {"title": "4.1. Data Description and Experimental Setup", "content": "We utilize the MIMIC-III and MIMIC-IV datasets for our experiments, both of which are de-identified and publicly-available collections of electronic health records associated with patients admitted to the Beth Israel Deaconess Medical Center (Goldberger et al., 2000; Johnson et al., 2016b). Although structurally similar, MIMIC-III includes data from 2001 to 2012, while MIMIC-IV spans from 2008 to 2019, leading to significantly different data distributions. As observed in Table 5, MIMIC-IV notably possesses a greater number of diagnosis codes and patients.\nOur evaluation metrics for diagnosis prediction are Recall@k and nDCG@k. We employ three metrics for a quantitative evaluation of explanation quality. Faithfulness measures the Pearson correlation between importance weights and changes in prediction upon removal of the corresponding explanation units from the input. Ranging from -1 to 1, a high value indicates that the provided explanations can faithfully reflect the model's reasoning process (Alvarez Melis and Jaakkola, 2018). Complexity counts the number of diagnoses in the given explanation:"}, {"title": "4.2. Predictive Performance Comparison", "content": "For both MIMIC-III and MIMIC-IV, where the average number of diagnoses per visit ranges between 10 and 20, we set k = {10,20} for Recall@k and nDCG@k. Table 1 compares the performance of SHy with baseline models for diagnosis prediction, along with the count of learnable parameters for each model. Overall, SHy delivers strong predictive performance, surpassing most baselines across all metrics on both datasets. In particular, SHy outperforms ConCare and Doctor AI, two black-box models, by up to 37.44% in Recall@10 (MIMIC-III) and 64.43% in nDCG@20 (MIMIC-IV), respectively. In contrast, SHy's edge over T-LSTM isn't as pronounced, especially on MIMIC-IV, which can be attributed to T-LSTM's much larger number of parameters. The large model size of T-LSTM can bring high expressiveness given ample training data. When juxtaposed with interpretable models, SHy's superiority is even more pronounced: outperforming RETAIN, Dipole, and Timeline by up to 70.53% in Recall@20 on MIMIC-IV, 66.84% in nDCG@10 on MIMIC-IV, and 28.50% in nDCG@10 on MIMIC-III, respectively. It is intriguing to note that SHy's margin over AdaCare is much narrower (4.39% in Recall@20 on MIMIC-III), with the difference reducing further on MIMIC-IV. This is potentially due to AdaCare's larger size.\nAlthough SHy adopts a hierarchical disease embedding approach from CGL, it outclasses CGL by 5.86% in Recall@10 on MIMIC-IV. This can be ascribed to CGL's reliance on a disease co-occurrence graph, which lacks the capability to capture higher-order disease interactions in the manner hypergraphs can. However, modeling patients as hypergraphs is insufficient. The essence lies in performing message passing to learn personalized disease embeddings that reflect individual comorbidities. This claim can be"}, {"title": "4.3. Robustness Against False Negatives", "content": "To quantitatively evaluate whether SHy can effectively deal with incomplete patient EHRs, we randomly mask out 25% and 75% of input diagnoses in the test data to simulate varying levels of data incompleteness and assess the impact on SHy's performance relative to three top-performing baselines. From Table 2, we observe that SHy consistently surpasses all baselines across all metrics, affirming its robustness against false negative diagnoses. Notably, SHy exhibits the least performance degradation, verifying its efficacy in contexts with incomplete data. Additionally, SHy's phenotypes, despite their conciseness, recovered an average of 4.83%, 0.74%, 10.14%, and 1.67% of the masked diagnoses across the four different settings, demonstrating SHy's adeptness at handling data incompleteness. The inclusion of $L_{distinct}$, which encourages the explanations to be concise, results in false negatives that are not critical in predicting future diagnoses being excluded from the extracted phenotypes, leading to a modest recovery"}, {"title": "4.4. Evaluation of Model Explanations", "content": "Table 3 highlights the superior quality of explanations provided by SHy compared to other self-explaining diagnosis prediction models. Notably, while all baseline models have Faithfulness scores below 0.5, suggesting a weak to medium correlation between generated weights and prediction changes upon removal of the explanation units, SHy showcases a much stronger correlation. Since RETAIN, AdaCare, and Timeline offer explanations by assigning a weight to every diagnosis, their Complexity score equals to the average number of historical diagnoses per patient in MIMIC-III. Dipole assigns visit-level attention scores, making the generated explanations too coarse to be eligible for calculating Complexity. Although SHy provides explanations by extracting multiple phenotypes (subgraphs of the patient hypergraph) and introduces false negative disease-visit pairs before extraction, the total number of diagnoses in all phenotypes is, on average, lower than number of historical diagnoses the patient has in the record. This indicates that SHy's phenotype extraction module effectively filters out irrelevant noise, yielding concise explanations.\nA peculiar observation is the superior quality of explanations by SHy w/o. $L_{\\alpha}$, based on the three metrics. We looked into the explanations it offered, and found that for most of the patients, the generated $\\alpha$ were (1.0, 0.0, 0.0, 0.0, 0.0), and only one of the five temporal phenotypes was non-empty. Based on how Faithfulness and Distinctness are calculated, it is reasonable for SHy w/o. $L_{\\alpha}$ to achieve outstanding results in these two metrics. SHy w/o. $L_{fidelity,\\alpha}$ shows a similar behavior. Thus, we can understand the importance of $L_{\\alpha}$ in preventing the attention scores from being too extreme.\nComparing SHy with SHy w/o. $L_{fidelity}$, SHy w/o. $L_{distinct}$ with SHy w/o. $L_{fidelity,distinct}$, SHy w/o. $L_{\\alpha}$ with SHy w/o. $L_{fidelity,\\alpha}$, and SHy w/o. $L_{distinct,\\alpha}$ with SHy (only $L_{pred}$) reveals that the inclusion of $L_{fidelity}$ consistently enhances Faithfulness, albeit modestly. Moreover, removing $L_{distinct}$ leads to substantial degradation across all metrics. The uptick in Complexity and downturn in Distinctness underscore its significance in generating concise, non-overlapping explanations. The pronounced decline in Faithfulness when excluding $L_{distinct}$ stems from near-identical phenotypes having"}, {"title": "4.5. Case Study", "content": "To showcase SHy's capabilities in accommodating interventions from domain experts, we conduct a case study on a patient with three historical visits. Figure 3 illustrates this case study. SHy accurately predicted 7 out of 9 diagnoses for the next visit. In particular, SHy anticipated the onset of a urinary tract infection, despite the lack of information on the timing of the next visit, and in the absence of any previous records explicitly indicating urinary tract problems for the patient. Additionally, SHy identified acidosis, a condition that was not recorded in the patient's last three visits. Thus, SHy demonstrated capabilities beyond merely replicating past diagnoses. Interestingly, SHy's prediction listed diabetes, which was not confirmed by the ground-truth label. However, considering the patient's recent diagnosis of cirrhosis of liver a condition affecting insulin sensitivity and the chronic nature of diabetes mellitus, this prediction still holds merit.\nSHy offered compelling rationales for its predictions. Each extracted phenotype reflected a unique facet of the patient's health status. Phenotype 1 indicated that the patient might have experienced endocrine system abnormalities, possibly even severe hypoglycemia, due to diabetes; Phenotype 2, which consistently highlighted pneumonia at all visits, symbolized worsening respiratory health and a compromised immune system; Phenotype 3 underlined pneumonia complications and congestive heart failure, suggesting a high probability of hypoxia; Phenotype 4 indicated significant liver impairment and resulting coronary artery lesions; Phenotype 5 implied that the abnormal immune response was detrimentally affecting the bones and joints. Every phenotype contributed to the prediction result. Pneumonia, chronic obstructive bronchitis and acute respiratory failure could be inferred from Phenotype 2; urinary tract infection, closely associated with diabetes and acute kidney failure, with hypoxia as the main driving force, could be anticipated based on Phenotype 1 and 3; hepatic encephalopathy could be predicted through Phenotype 4; Phenotype 5, reflecting the patient's waning immune system, played a suggestive role in predicting most lesions. The weights assigned to phenotypes were justifiable. Phenotype 2, which received the highest weight, was the most critical because the patient had diagnoses related to the respiratory system across all past and subsequent visits, and a consistent diagnosis of pneumonia suggested a weakening immune system and a critical health condition; Phenotype 5, assigned the lowest weight, was less relevant compared to the other phenotypes, as the patient did not receive diagnoses similar to those within this phenotype during the last two visits. More analysis on the case study can be found in Appendix E"}, {"title": "5. Conclusions", "content": "In this study, we introduce SHy, a self-explaining model for diagnosis prediction. It represents each patient's longitudinal EHR as a hypergraph and employs message passing to derive personalized disease embeddings. With these embeddings, SHy offers tailored explanations by extracting temporal phenotypes upon which predictions are based. With a novel combination of objectives, we ensure that these temporal phenotypes are concise, faithful, distinct, and easy to be edited by domain experts. Quantitative evaluations highlight SHy's competitive predictive performance and superior explanatory capabilities, advocating its potential as an AI assistant. Future endeavors include employing timestamps in the prediction process and devising more robust metrics for evaluating the explanation quality of diagnosis prediction models."}, {"title": "Appendix A. Deep Learning on Hypergraphs", "content": "The success of graph neural networks (Kipf and Welling, 2017) has spurred hypergraph-based deep learning methods. Models updating node embeddings of hypergraphs through clique-expansion or its variants were proposed (Feng et al., 2019; Gao et al., 2022; Bai et al., 2021; Yadati et al., 2019). Hyper-SAGE (Arya et al., 2020) was developed for inductive hypergraph learning, capturing relations within and across hyperedges. HNHN (Dong et al., 2020) employed a normalization strategy that could be adjusted according to datasets. Jo et al. (2021) innovated edge representation learning on graphs by introducing dual hypergraphs. HCNH (Wu and Ng, 2022) utilized the hypergraph reconstruction loss for semi-supervised node classification. Chien et al. (2022) introduced AllSet, a generalized framework encapsulating most existing propagation rules on hypergraphs. For EHR-based tasks, HCL, ProCare, and CACHE emerged as three hypergraph neural network models (Xu et al., 2022; Tan et al., 2023; Cai et al., 2022b), with the former two lacking interpretability and the last one prone to false negative diagnoses."}, {"title": "Appendix B. Comparing Hypergraph Neural Networks", "content": "To optimize the performance of SHy in diagnosis prediction, we experimented with 8 state-of-the-art hypergraph neural network architectures. As SHy represents each patient through a distinct hypergraph and all patient hypergraphs utilize a shared message-passing mechanism, only inductive hypergraph neural network models can be considered. The results in Table 4 indicate that UniGIN (Huang and Yang, 2021), AllSet Transformer (Chien et al., 2022), and Uni-GAT outperform others on the MIMIC-III dataset, whereas UniGIN, UniGCN, and HyperGCN (Yadati et al., 2019) are the top performers on MIMIC-IV. Given UniGIN's consistently high performance across both datasets and its fewer parameters relative to UniGAT and AllSet Transformer, we adopted UniGIN as the message-passing mechanism for SHy on both datasets."}, {"title": "Appendix C. Details of the GRU Decoder", "content": "SHy utilizes a GRU decoder to reconstruct patient hypergraphs from the embeddings of the temporal phenotypes, denoted as $[U_1 || U_2 || ... || U_K] \\in \\mathbb{R}^{Kd_{hid}}$. Specifically, the reconstructed patient hypergraph, P, is derived as follows:\n$H_1, ..., H_T = GRU([U_1 || ... || U_K], ..., [U_1 || ... || U_K])$\n$P = \\sigma (H W_{recon} + b_{recon})$,\nwhere $\\sigma$ denotes the sigmoid function, $H_t$ is the hidden state corresponding to the t-th visit, and $W_{recon}$ and $b_{recon}$ are learnable parameters. In essence, SHy duplicates the concatenated phenotype embedding T times, providing the same input to the decoder GRU at each time step and reconstructing the columns of P using the derived hidden states."}, {"title": "Appendix D. More on Experimental Setup", "content": null}, {"title": "D.1. Dataset Statistics", "content": "Details on the employed datasets are in Table 5."}, {"title": "D.2. Baseline Descriptions", "content": "We compare SHy with 13 representative state-of-the-art models on diagnosis prediction:\n\u2022 Doctor AI (Choi et al., 2016a) utilizes a GRU for learning patient representation.\n\u2022 RETAIN (Choi et al., 2016c) employs RNNs and an attention mechanism for interpretable predictions.\n\u2022 Dipole (Ma et al., 2017) leverages bidirectional RNNs with an attention mechanism for interpretability.\n\u2022 T-LSTM (Baytas et al., 2017) uses a time-aware long short-term memory to learn patient representation.\n\u2022 GRAM (Choi et al., 2017) pinfuses knowledge from medical ontologies into dispease embeddings via attention.\n\u2022 CGL (Lu et al., 2021a) achieves accurate diagnosis predictions via collaborative graph learning."}, {"title": "D.3. Hyperparameters", "content": "The datasets are split into training, validation, and testing sets using an 0.8:0.1:0.1 ratio. We employ the Adam optimizer and standardize the batch size to 128 across all models. We carefully tune the learning rate and specific hyperparameters of the baseline models to optimize their performance. Through grid search, hyperparameters for SHy are finalized: K = 5 and Z = 2 for both MIMIC-III and MIMIC-IV. Details for other hyperparameters are available in our repository. The models are trained on a server with NVIDIA A40 GPUs. For all experiments, we present the average results from 5 runs with random model initializations."}, {"title": "Appendix E. More on Case Study", "content": "SHy enhanced its explanatory capability by including false negatives. For Phenotype 1, a diagnosis of pneumonia was retrospectively added to the initial visit, reflecting the patient's respiratory problems, such as bronchiectasis, in the same visit, and subsequent pneumonia diagnoses; also, this adjustment further emphasized the patient's enduring respiratory and immune system problems.\nA clinician observed that SHy initially overlooked corticoadrenal insufficiency, and none of the phenotypes included this diagnosis in the third visit. Since rheumatoid arthritis is an autoimmune disease, which could be a major cause of corticoadrenal insufficiency, this clinician decided to intervene by incorporating corticoadrenal insufficiency in the third visit into Phenotype 5 and proceed with the predictive process"}]}