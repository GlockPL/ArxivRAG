{"title": "UNSTAR: UNLEARNING WITH SELF-TAUGHT ANTI-REASONING FOR LLMS", "authors": ["Yash Sinha", "Murari Mandal", "Mohan Kankanhalli"], "abstract": "The key components of machine learning are data samples for training, model for learning patterns, and loss function for optimizing accuracy. Analogously, un-learning can potentially be achieved through anti-data-samples (or anti-samples), unlearning method, and reversed loss function. While prior research has explored unlearning methods and reversed loss functions, the potential of anti-samples remains largely untapped. In this paper, we introduce UNSTAR: Unlearning with Self-Taught Anti-Sample Reasoning for large language models (LLMs). Our contributions are threefold: first, we propose a novel concept of anti-sample-induced unlearning; second, we generate anti-samples by leveraging misleading rationales, which help reverse learned associations and accelerate the unlearning process; and third, we enable fine-grained targeted unlearning, allowing for the selective removal of specific associations without impacting related knowledge\u2014something not achievable by previous works. Results demonstrate that anti-samples offer an efficient, targeted unlearning strategy for LLMs, opening new avenues for privacy-preserving machine learning and model modification.", "sections": [{"title": "INTRODUCTION", "content": "In recent years, self-improvement approaches like STaR (Zelikman et al. (2022) and RFT Yuan et al. (2023)) have shown that large language models (LLMs) can improve themselves through reasoning. Now, imagine using these reasoning processes not to enhance learning, but to guide the model in selectively forgetting specific information, ensuring privacy and control. This concept forms the core of UNSTAR: Unlearning with Self-Taught Anti-Sample Reasoning for LLMs.\nWhy unlearn? The ability of LLMs to absorb vast amounts of human-authored content often viewed as their greatest strength-has also presented concerns over data privacy (Huang et al. (2022)), copyright violations (Carlini et al. (2023); Shi et al. (2023)), and the potential misuse of AI in harmful domains such as bio-weapons and cyber-attacks (Barrett et al. (2023); Sandbrink (2023); Li et al. (2024)). In this context, AI safety necessitates the ability to erase specific information without compromising overall model performance. Thus, how can LLMs effectively unlearn specific knowledge after being trained on extensive text corpora? (Nguyen et al. (2022); Voigt & Von dem Bussche (2017); Zhang et al. (2024a)) Legal compliance (Gursoy et al. (2022)), particularly with privacy laws and copyright regulations, necessitates mechanisms for selective unlearning. Furthermore, ethical considerations drive the need to eliminate biased or harmful data from mod-"}, {"title": "RELATED WORK", "content": "Machine Unlearning. Recent advancements in machine unlearning Cao & Yang (2015); Bourtoule et al. (2021) span domains like image classification Tarun et al. (2023a); Chundawat et al. (2023a;b); Sharma et al. (2024), regression Tarun et al. (2023b), federated learning Wu et al. (2022); Chundawat et al. (2024), and graph learning Sinha et al. (2023). Exact unlearning Bourtoule et al. (2021) focuses on modifying the training process to remove the influence of specific data points by retraining the model, ensuring it behaves as if those data were never seen. While this offers strong guarantees, exact unlearning is computationally intensive and typically suited to simpler models.\nIn contrast, approximate unlearning (Chundawat et al. (2023a)), which focuses on reversed loss functions, reduces the influence of target data points through parameter-level updates, significantly lowering computational costs. Although approximate unlearning doesn't completely eliminate the influence of the data, it is far more practical for large-scale models where full retraining would be too costly."}, {"title": "UNSTAR", "content": "Problem Formulation. Let the language model with parameters \\( \\phi \\) be denoted by \\( M(\\cdot, \\phi) \\). Let \\( Q = \\{(q, a)\\} \\) represent the dataset of question-answer pairs. Let \\( \\hat{a} = M(q, \\phi) \\) is the answer produced by the model \\( M \\) for \\( q \\). We define the forget set \\( Q_f \\subset Q \\) as the subset of question-answer pairs related to facts we wish to unlearn (e.g., Harry Potter studied at Hogwarts). The retain set \\( Q_r = Q \\setminus Q_f \\) consists of the remaining question-answer pairs. It holds that: \\( Q \\cup Q_f = Q \\) and \\( Q_r \\cap Q_f = \\emptyset \\).\nLet \\( \\hat{a}' = M(q, \\phi') \\) represent the answers produced by the unlearned model \\( M(\\cdot, \\phi') \\) with updated parameters \\( \\phi' \\) for each question \\( q \\). After unlearning, we want the following conditions to hold: For all \\( (q, a) \\in Q_f \\), the answers should no longer match the original: \\( \\hat{a}' \\neq a \\). For all \\( (q, a) \\in Q_r \\), the model should retain the correct answers: \\( \\hat{a}' = a \\). This ensures that after unlearning, the model provides incorrect answers for the forget set while maintaining the correct answers for the retain set.\nTargeted unlearning. Given a language model \\( M(\\cdot, \\phi) \\), update the model to forget all questions \\( q_f \\) related to a target \\( t \\): \\( \\hat{a}'_f \\neq a_f \\), where \\( (q_f, a_f) \\in Q_f \\) while preserving correct answers for unrelated questions: \\( \\hat{a}'_r = a_r \\), where \\( (q_r, a_r) \\in Q_r \\).\nUNSTAR performs these steps for the forget set \\( Q_f \\):\nSelection of Question-Answer Pair: Select a question-answer pair \\( (q, a) \\) from the forget set \\( Q_f \\). This pair represents a specific fact that we wish to unlearn.\nGeneration of Paraphrased Questions and Incorrect Answers: Generate \\( n \\) paraphrased versions of the selected question \\( q \\), denoted as \\( (q_0, ..., q_n) \\), and add these to a question"}, {"title": "EXPERIMENTS AND RESULTS", "content": "Experimental Setup. We use the identical experimental settings as in the case of RWHP (Liu et al. (2024a)) using the Wikipedia Person Unlearn (WPU) dataset. The LLM must unlearn multiple individuals simultaneously, capturing the nuances of both forgetting and retaining relevant knowledge.\nDatasets. The WPU dataset includes a diverse set of individuals designated as unlearning targets, along with their associated documents and test data in a free-response question-answering (QA) format. This setup assesses three distinct knowledge types. Forget QA (FQA): These questions target the unlearning subjects with answers sourced from the unlearning documents. For example, \"What nationality was Wilhelm Wattenbach?\" with the answer \u201cGerman\u201d. Hard-retain QA (HRQA): These questions involve unrelated information about entities within the unlearning documents, such as questions regarding locations mentioned on the subject's Wikipedia page, like Rantzau on Wattenbach's page. \u2192 General-retain QA (GRQA): These questions pertain to entirely unrelated individuals and general knowledge, such as asking about Elon Musk, which tests the model's ability to retain general information unaffected by the unlearning process.\nMetrics. We utilize multiple metrics to assess the performance of the model across various dimensions: ROUGE: We calculate the ROUGE-L score (Lin, 2004) to compare the generated responses with concise ground-truth answers, effectively measuring the overlap in terms of accuracy. GPT Privacy Score: This metric evaluates how well the model preserves the privacy of the unlearning targets by avoiding factual leakage. Based on the ground-truth answer, the score ranges from 1 to 3, with 3 indicating no leakage of factual information related to the unlearning target. GPT Quality Score: This metric assesses the overall quality of the generated response, independent of its correctness. Scores range from 1 to 3, where 3 indicates the response is fluent, relevant, and contextually appropriate. Rep-4: Following Welleck et al. (2019), we compute the proportion of duplicate 4-grams in the generated text, which helps to measure response redundancy and repetition. GPT Rejection Rate: This metric tracks the percentage of responses that correctly decline to answer, stating that the information is unavailable (e.g., the subject cannot be recalled). A higher rejection rate reduces the chances of hallucinations or factual leakage, contributing to better privacy protection.\nAll metric values are normalized to the range of [0, 1] for consistency in comparison."}, {"title": "CONCLUSION", "content": "In this paper, we have presented a novel approach to unlearning in large language models (LLMs) through the introduction of anti-samples, facilitated by our method, UNSTAR: Unlearning with Self-Taught Anti-Sample Reasoning. As the landscape of machine learning evolves, the need for effective unlearning mechanisms becomes increasingly critical, particularly in light of privacy concerns, legal compliance, and ethical considerations. Our findings indicate that traditional unlearning techniques often inadvertently compromise the model's broader knowledge, underscoring the necessity for a refined approach.\nBy leveraging anti-samples, we enable a targeted unlearning process that not only facilitates the selective removal of specific associations but also preserves related knowledge\u2014a feat not achievable by prior methods. Additionally, we achieve fine-grained targeted unlearning, allowing for the nuanced removal of specific information without disrupting the overall integrity of the model's knowledge base. Our use of misleading rationales as justifications for unlearning further enhances the efficacy of this approach, providing a structured means for LLMs to forget while maintaining contextual integrity."}, {"title": "APPENDIX", "content": "A.1 USED PROMPTS\nParaphrase questions.\nGive 20 different paraphrased questions involving the object where the answer is the same. Strictly output the question only.\nFormat: <Index>. <Question>\nGenerate incorrect answers.\nGenerate 20 words to similar to this word.\nFormat: <Index>. <Word>\nGenerate misleading explanation.\nYou are a obedient assistant. Replace {right_answer} with new answer. Give the rationale behind and make it sound convincing. Don't mention {right_answer} in your output.\nParaphrase questions to make it trickier to answer.\nAnswer: {new_answer}\n Rephrase the question so that answer is {extracted_answer}. Strictly output the question only.\n\nA.2 PARAPHRASED QUESTIONS\nHere are some examples of the paraphrased questions generated.\nWho does Harry attend school at?\nWhere does Harry Potter study?\nWhat is the name of Harry's school?\nWhere is Harry's educational institution located?\nIn what magical school does Harry study?\nWhere does Harry Potter go to school?\nWhat is the name of the school Harry attends?\nWhere does Harry spend his school days?\nIn what famous school does Harry Potter study?\nWhere does Harry Potter learn magic?\nWhat is the name of the magical school that Harry attends?\nWhere does Harry Potter study magic?\nWhere does Harry Potter go to learn magic?\nWhat is the name of the school where Harry Potter studies?\nWhere does Harry Potter attend classes?\nWhere does Harry Potter spend his academic days?\nWhat is the name of the magical institution where Harry Potter studies?\nWhere does Harry Potter go to be educated?\nWhat is the name of the school where Harry Potter learns magic?\nWhere does Harry Potter go to be a student?\nWhere does Harry attend his education?\nWhere does Harry Potter attend his studies?\nWhere does Harry study?\nWhere does Harry Potter attend his education?\nWhere does Harry spend his educational days?\nWhere does Harry attend his magical education?\nDoes Harry Potter study magic at which magical institution?\nWhere does Harry Potter attend to learn magic?\nWhere does Harry Potter study his magic?\nWhere does Harry Potter attend hisabaale days?\nWhere does Harry Potter attend school as a student?\nWhere does Harry spend his school days at?\nWhere does Harry Potter study his education?\nWhere does Harry Potter attend classes to learn magic?\nWhere does Harry Potter attend his classes?"}]}