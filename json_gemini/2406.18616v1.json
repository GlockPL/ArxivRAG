{"title": "Towards Large Language Model Aided Program\nRefinement", "authors": ["Yufan Cai", "Zhe Hou", "Xiaokun Luan", "David Sanan", "Yun Lin", "Jun Sun", "Jin Song Dong"], "abstract": "Program refinement involves correctness-preserving transformations\nfrom formal abstract specification statements into executable programs. Tradi-\ntional verification tool support for program refinement is highly interactive and\nlacks automation. On the other hand, the emergence of large language models\n(LLMs) enables automatic code generation from informal natural language spec-\nifications. However, code generated by LLMs is often unreliable. Moreover, the\nopaque procedure from specification to code provided by LLM is an uncontrolled\nblack box. We propose LLM4PR a tool that combines formal program refine-\nment techniques with informal LLM-based methods to (1) transform the spec-\nification to pre- and post-conditions, (2) automatically build prompts based on\nrefinement calculus, (3) interact with LLM to generate code, and finally, (4) ver-\nify that the generated code satisfies the conditions of refinement conditions, thus\nguaranteeing the correctness of the code. We have implemented our tool with\nGPT4 and Coq and evaluated it on the HumanEval and EvalPlus datasets.", "sections": [{"title": "1 Introduction", "content": "Background. Recently, AI-powered large language models (LLMs) have advanced\nrapidly in mathematics, reasoning, and programming [48,36]. Industrial products like\nGPT4 [32] and Copilot [21] greatly assist programmers in coding-related tasks. In gen-\neral, the programmer inputs a specification of the question in natural language, and\nthen the LLM will generate the associated code, which basically translates the natural\nlanguage to the programming language. The end-to-end framework of deep learning\nmodels makes it possible to generate the intended program in a very flexible way. Some\nstudies, however, show that programmers usually find it hard to trust and debug the\nLLM-generated code [42,16] as the generation procedure is opaque and out of control.\nPast works like Code2Inv [40,39] proposed an end-to-end learning framework to learn\nand generate a valid proof for a program by interacting with the proof checker. With the\nemergence of LLM applications, recent works investigate methods that combine LLMs\nwith formal verification techniques for generating program properties and invariants\n[10,2]. The recent works based on deep learning techniques usually adopt an end-to-end"}, {"title": null, "content": "framework and rely on various informal heuristics like the chain of thoughts to control\nthe reasoning of LLMs [45]. The verification procedure usually involves another LLM\nto check the output of the LLM in a debating-like procedure [47].\nChallenges. While the above methods show the significant potential of LLMs in code\ngeneration and program verification, there remain questions in verifying and controlling\nthe code generation procedure. Besides, LLMs often generate unsound and insecure\ncode that users would typically have no clue how to fix them. Building trust and inter-\npretability in the code generation process is extremely important in practice since the\ngenerated code will be adopted in a large context and should be properly maintained. As\na complementary method, program refinement involves correctness-preserving trans-\nformations from formal specification statements into executable code. However, the\ncurrent transformation from specifications to code based on program refinement cal-\nculus is largely designed or even implemented by hand, which is costly and laborious\n[29,41,9]. Naturally, the manual transformation of program refinement always tends to\nbe an ad-hoc procedure that is hard to generalize and apply in industry.\nProposed Solution. In this work, we propose a mostly automated approach called\nLLM4PR to combine the formal program refinement calculus with informal LLMs to\nrefine the specification and generate verified code step by step automatically. LLM4PR\nalso combines some automated theorem provers(ATPs) to verify the code and justify\nthe choice of the refinement laws made by LLMs. Our approach is complementary to\nLLMs, automated theorem provers, and traditional verification tools. While the formal\nspecification still requires manual effort for the initial input in the first step, it should\nnot be a hurdle for the formal methods community and is necessary since, otherwise,\nthere is no correctness to speak of. Besides, our LLM also facilitates the formalization\nprocedure shown in the experiment. To the best of our knowledge, LLM4PR is the first\nframework that combines LLMs and program refinement techniques.\nMotivating Example. We illustrate our motivation using a program for computing the\nsquare root of a real number. In Figure 1, we show the code snippets generated by\nGPT4 and Copilot. The LLMs can generate almost correct code. However, these pro-\ngrams still contain some bugs. Both upper two programs are wrong in the case $N < 1$\nas $N * N < N$. Mathematically, the choice of the variable high as the upper bound\nof the square root of $N$ should be larger than $N + +$ as $\\forall N, (N + 1)^2 \\geq N$. We try to\nfix the GPT4 code with the prompt The upper bound is wrong for N less than 1. How-\never, the newly generated code still fails on several cases like sqrt(5) since the variable\n$x$ goes to a fixed point but does not terminate the loop. The final code (bottom right)\nwith the formal constraints shows the conditions that should be obeyed for GPT4. In\ncontrast, our program refinement with the LLM will automatically generate prompts\nwith constraints to generate the code and refine the specification shown in Section 6.1.\nIntuitively, we regard the LLMs as \u201cconstraint solvers\u201d, whose powerful extensibility\nand rich background knowledge shed light on the potential of automation for program\nrefinement. Our program refinement can passively \u201cassert\u201d constraints that help debug-\nging and actively \"verify\u201d constraints that benefit code generation."}, {"title": "Contributions", "content": "The contributions of the paper are summarized below.\n1. A framework LLM4PR for mostly automated program refinement with the LLMs,\nincluding a formal specification language $L_{spec}$, a programming language $L_{pl}$ asso-\nciated with our program refinement calculus, and a verification strategy that verifies\nthe outputs of LLM based on Coq and ATPs.\n2. A GPT4 variant fine-tuned with program refinement instructions and knowledge of\nour defined languages and laws.\n3. A dataset of formal specifications and an evaluation benchmark based on the sam-\nples of the HumanEval and EvalPlus datasets."}, {"title": "2 Preliminaries", "content": "This section introduces the background knowledge of program refinement. We mainly\nfollow Morgan's notations in [29]."}, {"title": "Specification", "content": "describes what a program is expected to do. In detail, a specification\ncontains variants, a precondition, and a postcondition, in the form\nvariants : [precondition, postcondition].\nVariants are the list of program variables, the precondition describes the initial states,\nand the postcondition describes the final states of the program.\nRefinement of the specification is the relation between two expressions where one can\nsolve the other. Formally, we have the following laws of refinement:"}, {"title": "Definition 1 (Strengthen Postcondition Law).", "content": "Let the precondition pre and post-\ncondition post be any FOL formula, if post' \u21d2 post, then x : [pre, post] \u2286 x:\n[pre, post']."}, {"title": "Definition 2 (Weaken Precondition Law).", "content": "Let the precondition pre and postcondition\npost be any FOL formula, if pre \u21d2 pre', then x : [pre, post] \u2286 x : [pre', post]."}, {"title": null, "content": "The relation symbol \u2286 is called refinement. For two formulae A and B, A entails\nB (A\u21d2 B) means that in every state if A is true then B is true.\nSkip is a command where the final state of the program is the same as its initial state. If\nthe precondition of the specification entails the postcondition, it can be refined by skip."}, {"title": "Definition 3 (Skip Law).", "content": "If pre \u21d2 post, then x : [pre, post] \u2286 skip."}, {"title": "Sequential Composition", "content": "refines a single specification to two others."}, {"title": "Definition 4 (Sequential Composition Law).", "content": "Let mid be any formula except for pre\nor post. x : [pre, post] \u2286 x : [pre, mid]; x: [mid, post]."}, {"title": "Assignment", "content": "assigns the variant with new expressions. We denote post(x := E) as a\nnew condition that assigns all occurrences of x in post by E. If the precondition entails\nthe new postcondition after the assignment, it can be refined by assignment."}, {"title": "Definition 5 (Assignment Law).", "content": "Let E be any Expression, post(x := E) assigns\nevery x in post with E. If pre \u21d2 post(x := E), then x : [pre, post] \u2286 x = E."}, {"title": "Alternation", "content": "is built by guarded branches."}, {"title": "Definition 6 (Alternation Law).", "content": "Let GG be the disjunctive normal form of the guards\n$G_0, G_1,,\u2026, G_i, \u2026, G_n$, if pre \u21d2 GG, then x : [pre, post] \u2286 if ||(Gi then x :\n[Gi\u2227pre, post]) where if || Gi then means if G\u2080 then ... else if G\u2081 then ... ."}, {"title": "Iteration.", "content": "Iterations (while loops) are built by loop conditions, invariants, and variants.\nAn invariant inv is a formula that if is true initially, stays true for each repetition. The\nvariant V of the iteration is chosen to guarantee the termination of the iteration."}, {"title": "Definition 7 (Iteration Law).", "content": "Let Inv, the invariant, be any formula; let V, the vari-\nant, be any integer-valued expression. Let GG be the disjunctive normal form of the\nguards $G_0, G_1, ..., G_i, ..., G_n$ then x : [Inv, Inv \u2227\u00acGG] \u2286 while ||(Gi do x :\n[Inv \u2227 Gi, Inv\u2227 (0 \u2264 V < Vo)]) where Vo is the initial value of V, while || Gi do\nmeans while G\u2080 do ... else G\u2081 do ... else Gn do."}, {"title": "Expand.", "content": "It expands the variant list by introducing another variant."}, {"title": "Definition 8 (Expand Law).", "content": "Let x be the origin variant and y be another variant and\ny\u2080 be the initial value of y, then x : [pre, post] \u2286 (x, y) : [pre, post \u2227 y = y\u2080]"}, {"title": "Procedure.", "content": "A procedure is declared by a name, some parameters, and a program."}, {"title": "Definition 9 (Procedure).", "content": "procedure N (param V : T) \u2252 Prog."}, {"title": "Definition 10 (Procedure Value Specification).", "content": "Given a procedure that refines\nprocedure Proc (param f : T) \u2252 f : [pre, post], with post containing no f. Let A be\nsome expression, then w : [pre\u27e8f := A\u27e9,post\u27e8f := A\u27e9] \u2286 Proc(A)"}, {"title": "3 Formal Languages in Our Approach", "content": "We introduce our formal specification language $L_{spec}$ used to describe the specifica-\ntion and the programming language $L_{pl}$ for our generated code. We further define the\nannotated programming language for the program refinement procedure, which con-\ntains both $L_{spec}$ and $L_{pl}$. Formally, it is a tuple (Lspec, Lpl) that has two parts, one for\neach of the above languages, respectively. As these languages closely interacted with\nthe LLMs, we target designing languages well understood and applied by LLMs."}, {"title": "3.1 The Specification Language $L_{spec}", "content": "Our specification language $L_{spec}$ extends first-order logic (FOL) and is a subset of the\nlanguage of Coq [6]. The LLMs are familiar with both FOL and Coq grammar. We\nfollow the standard syntax and semantics of FOL and highlight the following notations.\nVariants and Constants. We use lower case words like x, y, z to denote the variants that\nwill change in the refinement and upper case words like N, M to denote constants. Both\nvariants and constants should be typed.\nRelations and Functions. We use common relation operators and function operators in\nSMT, such as <, =, +, -, *, /, Array[Int], Array[Int : Int].\nSyntax. We define our specification based on the first-order theory and theory of arrays.\nThe full syntax of Lspec is given in Table 1, where (Specification) defines the specifica-\ntion that needs to be refined, (Definition) defines the condition that the variants should\nsatisfy, (Params) defines the variants and constants. In the case of (atom), \u27e8Expr\u27e9\u2080\ndenotes the previous value of the expression, (Name) [(atom)] specifies the array se-\nlecting operation, and \u27e8Name\u27e9[(atom):\u27e8atom)] is used for array slicing operation.\nThe remainder of the syntax is standard FOL used in SMT solving.\nSemantics. We follow the standard FOL semantics defined in Coq and only present the\nnotable elements in Table 2. Note that the theory of arrays is realized by relations and\nfunctions, similar to its treatment in the literature [13]."}, {"title": "3.2 The Program Language $L_{pl}", "content": "Our program language is mainly based on While language. The language is kept simple\nto make it easier for the LLM to understand and generate. The complete syntax of our\nprogram language is given in Table 3. Our programming language is imperative and\nhas data types for booleans, natural numbers, integers, float, characters, and arrays. We\ninclude the extension of Array and Assert statements. The array has a natural number\nindex type and the reading, updating, and slicing operations. To control the size and\nstructure of programming, we also incorporate the use of procedures. The procedure is\ndeclared by a name, some parameters, and an associated program follows Definition 9.\nThe formal semantics follows the literature [26]."}, {"title": "4 The Refinement Laws in Our Approach", "content": "This section introduces our program refinement laws used for interaction with the LLMs.\nWe aim to transform the refinement laws to facilitate both LLM interaction and ATPs\nverification. Our defined refinement laws can be utilized by our LLM."}, {"title": "Lemma 1 (Initialised Skip Law).", "content": "Let $x_0$ denote the initial value of variant $x$, if $(x =\nx_0) \u2227 P\u21d2 Q$, then the specification $x : [P, Q] \u2286 Skip$."}, {"title": "Proof.", "content": "Use the skip law in Definition 3 as P \u21d2 Q."}, {"title": "Seq.", "content": "We extend a new sequential composition law to flexibly divide one specification\ninto two parts."}, {"title": "Lemma 2 (Flexible Sequential Composition Law).", "content": "Let P, Q, A, B, C, D be some\nformulate, if $(P \u21d2 A) \u2227 (B \u21d2 C) \u2227 (Q \u21d2 D)$, then the specification $x : [P, Q] \u2286 x :\n[A, B]; x : [C, D]$."}, {"title": "Proof.", "content": "First, use the sequential composition law in Definition 4, $x : [P,Q] \u2286 x :\n[P, B]; x : [B, Q]$. Then refine the two parts with the weaken-precondition law in Defi-\nnition 2, $x : [P, B] \u2286 x : [A, B]; x : [B, Q] \u2286 x : [C, Q]$. Finally refine the second part\nwith the strengthen-postcondition law in Definition 1, $x : [C, Q] \u2286 x : [C, D]$."}, {"title": "Assign.", "content": "We have two assignment laws. The initialized assignment law utilizes the initial\nvalues of the variants to simplify the further proof for $pre \u21d2 post(x := E)$. The fol-\nlowing assignment law allows any assignment in its second half provided the changed\nvariants."}, {"title": "Lemma 3 (Initialized Assignment Law).", "content": "Let E be any Expr in the programming\nlanguage, post(x := E) replaces every x in the formula post with E. If (x = xo)^(y =\nYo) \u2227 pre \u21d2 post(x := E), then x, y : [pre, post] \u2286 x = E."}, {"title": "Proof.", "content": "Use the assignment law in Definition 5 as pre\u21d2 post(x := E)."}, {"title": "Lemma 4 (Following Assignment Law).", "content": "Let E be any Expr in the programming\nlanguage, post(x := E) replaces every x in the formula post with E. x : [pre, post] \u2286\nx: [pre, post(x := E)] ; x = E."}, {"title": "Proof.", "content": "First use the sequential composition law, x: [pre, post] \u2286 x: [pre, post(x :=\nE)]; x: [post(x := E), post]. Then refine the second part using the assignment law,\nx : [post(x := E), post] \u2286 x = E."}, {"title": "Alternate.", "content": "The if-else alternation law is a simplified version of the original one. Intu-\nitively, it separates the specification into a case analysis."}, {"title": "Lemma 5 (If-else Alternation Law).", "content": "Let P, Q, and G be some formulae, then the spec-\nification $x : [P, Q] \u2286 if (G) (x : [P\u2227G, Q]) else (x : [P \u2227 \u00acG, Q])$."}, {"title": "Proof.", "content": "As Pre \u21d2 G \u2228 \u00acG based on the law of excluded middle, the lemma can be\ndirectly implied from the alternation law in Definition 6."}, {"title": "Iterate.", "content": "We extend the origin iterative law to float numbers, which need to find an up-\nper bound to guarantee the loop termination in finite time. The first new specification\nassigns the initial value to the invariant and the second specification preserves the in-\nvariant and changes the variant during the iteration until the negated guard condition\nholds. In practice, based on the convergence of monotonic sequences of real numbers,\nwe replace the existing condition with the monotonic and bounded condition given in\nLemma 7. To avoid infinite loops, we add the assertion to check whether the expression\nV decreases by at least the error bound of the floating-point precision."}, {"title": "Lemma 6 (Initialised Iteration Law).", "content": "Let P, I, and G be some formulae, V be any\nvariant expression, and i and M are positive integers, then the specification $x : [P, I \u2227\n\u00acG] \u2286 x : [P, I] ; while(G) do (x : [I \u2227 G, I \u2227 (\u2203i < M, V_i \u2192 \u00acG)])$."}, {"title": "Proof.", "content": "First, using the sequential composition law in Definition 4, x : [P, I \u2227 \u00acG] \u2286\nx : [P, I]; x: [I, I \u2227 \u00acG]. Then refine the second part with the iteration law in Defini-\ntion 7. Note that we replace the condition for integer-valued variants with any variant\nexpression for scalability. To guarantee the termination of the iteration, a state of variant\nshould exist to negate the guard condition after finite iterations."}, {"title": "Lemma 7 (Flexible Iteration Law).", "content": "Let P, I, and G be some formulae, V be any variant\nexpression, then the specification x: [P, I \u2227 \u00acG] \u2286 x : [P, I] ; while(G) do (x :\n[I \u2227 G, I \u2227 V < Vo]; assert V \u2260 Vo)."}, {"title": "Proof.", "content": "First, follow the initialized Iteration Law. Then, note that the float precision error\nis e, then we have i [\u2713] < M, V < 0 \u2192 \u00acG."}, {"title": "Lemma 8 (Traverse Law).", "content": "Let l be the list of type T, natural numbers m and n denote\nthe range, pre and P be some formula, 1: [pre,\u2200i : nat \u2227 m < i < n \u2192 P(l, i)] \u2286\nl, i : [pre, l[m]]; i = m ; while(i < n) do (l, i : [P(l, i), P(l, i + 1)]; i = i + 1)."}, {"title": "Proof.", "content": "First, using the expand law and sequential composition law in Definition 4, l, i :\n[pre, l[i] ^ i = m];l,i : [l[i] ^ i = m,l[i] > i = n]. Then refine the second part\nwith the initialised assignment law Lemma 3 and iteration law in Definition 7, we have\ni = m ; while(i < n) do (l, i : [P(l, i), P(l, i) ^0 \u2264 n \u2212 i < n-io]. Finally, using the\nfollowing assignment law in Lemma 4 for the specification, [P(l, i), P(l, i + 1) ^ 0 <\nn - (i + 1) < n \u2212 i]; i = i + 1 and can be simplified to the target."}, {"title": "Semantics", "content": "The semantics shown in Figure 2 is defined according to the refinement\nlaws proved above."}, {"title": "5 LLM4PR: Program Refinement with LLM", "content": "This section presents our approach that combines the above program refinement laws\nwith the LLMs for automation.\nOverview. Figure 3 shows an overview of our approach. The formal specification writ-\nten in Lspec will be first transformed to an abstract syntax tree and LLM4PR will ex-\ntract the conditions to input the LLM. The LLM will select a predefined law to refine\nthe specification based on the description and constraints of the formal specification,\nand then generate the associate code with the law. LLM4PR correspondingly generates\nthe proviso condition of the law and builds the verification scripts to justify the code\ngenerated by the LLM. ATPs will try to automatically verify the scripts and output the\nsuccess message or error message. Based on the ATP result, the LLM will regenerate\nthe code if failed, or the LLM4PR will save the verified code and generate the new spec-\nification if succeeded. If getting multiple times of failure, LLM4PR will trace back to\nthe last refinement step and specification and interact with the LLM to choose another\nlaw and generate the associated code. Table 4 shows a summarization of the actions of\nLLM and LLM4PR using the predefined six kinds of refinement laws.\nActively Prompt. A prompt for the LLM like GPT4 refers to the instruction given to\nthe model to elicit a response. The traditional design of prompts always follows some\nstatic templates like Program Refinement for the following specification. In this work,\nwe regard the LLM as a constraint solver and actively build the prompt, including as-\nsociated logical formulae for specifications step by step. These formulae contain the\nconstraints that the output of LLM should satisfy. Consequently, the prompts contain\nthe constraints written in Lspec and previous failure history if it exists. The LLM will\nselect the refinement law and generate the associated code based on the given prompts."}, {"title": "Retrieval Augmented LLM with Fine-tuning.", "content": "We provide the LLM with the refine-\nment procedures library as background knowledge so that the LLM can utilize the past\nknowledge with the retrieval augmented techniques. We also customize the LLM for\nour program refinement task by crafting prompts and instructions based on the refine-\nment laws mentioned above. The LLM is fine-tuned with the examples in Morgan's\nbook [29], formal specification language Lspec, and our program language Lpl."}, {"title": "Specification Formalization", "content": "The first input of our LLM4PR should be a formal specifi-\ncation that needs the user to formalize the requirement. The LLMs can auto-formalize\nthe specification to our Lspec, but it still needs the user to verify the correctness of the\ntransformation from informal description to formal specification. It should not be a hur-\ndle for the formal methods community and is necessary since, otherwise, there is no\ncorrectness to speak of."}, {"title": "6 Evaluation", "content": "In this section, we first do the qualitative analysis of the detailed example to show\nthe benefits of our approach and then the quantitative analysis of the most popular\nbenchmark datasets compared to the state-of-the-art LLMs."}, {"title": "6.1 Case Study", "content": "We show how LLM4PR deals with the motivating example of Section 1 in Figure 5.\nMore examples are shown in [3]. The statement tagged with # for code comments and\nthe precondition and postcondition is the current specification. The verification state-\nment is the proviso condition to apply the refinement law. Note that we remove the\ncondition of iteration termination check in (...) for a concise presentation. In detail, the\nLLM first sequentially splits the original specification into two parts. Informally, the\nfirst specification defines x, y such that $x^2 < N < y^2$, which can be implemented\nby assignment. Note that the assignment of y needs to satisfy the constraints in the\npostcondition of the specification that is $N < y^2$, eliminating the possibility of bugs\nof LLMs like y = N in Figure 1. The second specification preserves the invariant\n$x^2 < N < y^2$ and makes the variants x, y closer until $x + e >= y$, which can be\nimplemented with the iteration. The invariant, the guard condition, and the variant can\nbe extracted from the specification. The LLM reduces the distance between x and y to\nassign x or y with the mean of x and y. It uses alternation to add another constraint to\nstrengthen the precondition and make it easier to conclude the postcondition.\nCompared to the LLM-generated code, each refinement step can be verified as each\nhas its associated specifications. LLMs, on the other hand, are used to select the re-\nfinement law and generate associated code automatically based on the generated con-\nstraints. The constraints are automatically built based on the choice of the law and the\ngenerated code in LLM4PR. When the refinement law is applied, the new specification\nwill be generated based on the refinement laws with LLM4PR."}, {"title": "6.2 Experiments", "content": "Dataset and Implementations We choose the HumanEval dataset as the benchmark,\nwhich is widely used in evaluating code generation [32,12,44]. To evaluate LLM4PR\nwith formal specifications, we transform 157 examples in the HumanEval dataset to a\nformal specification dataset, where 115 examples are correctly transformed by GPT4\nand all formal specifications are manually checked. Note that 7 examples can not be\ntransformed to formal specifications. Besides, to test the correctness and robustness of\nthe generated code, we adopt the EvalPlus [28] dataset with the same examples but\naverage more than 80x the number of test cases. We choose GPT4 as the base model\nand fine-tune it with examples from Morgan's book [29] and then test LLM4PR on the\nabove dataset."}, {"title": "6.3 Limitations", "content": "First, the capability of LLM4PR largely depends on the capabilities of LLMs and ATPs.\nTo remedy the limitation, users can be involved in the procedure of program refinement\nby selecting the law, building, and checking the proof. Second, if a refinement lacks\nproof of the loop termination in the iterative law, we still consider it as partially cor-\nrect. We create more iteration laws and the traverse law in Section 4 to help avoid the\ntermination condition, as proving termination is a hard and generally undecidable prob-\nlem. Third, LLM4PR is designed to guide LLM in generating more robust code, not for\nanalyzing problems and building specifications, where the latter still requires human\ninput. However, it should not discount our approach since a definition of correctness is\nnecessary for verified code."}, {"title": "7 Related Work", "content": "Program Refinement. [4], [29], [5] defines a formal method to build a program from its\nspecification. It mainly focuses on the correctness of a given specification and refine-\nment of a program while preserving its correctness. Some works propose a formaliza-\ntion of the refinement calculus in interactive theorem provers such as [20] for Isabelle\nand [1] for Coq [6]. Recent works utilize refinement calculus on different applications\nincluding [20,17,18]."}, {"title": "Theorem Proving.", "content": "There are two main types of tools for theorem proving: Interac-\ntive Theorem Provers (ITPs) and Automated Theorem Provers (ATPs) [31]. ITPs, also\nknown as proof assistants, interact with humans in the process of proof building and de-\nvelopment, like Isabelle [33], Coq [6], Lean [30]. ATPs prove the goals automatically,\nincluding E-prover [38], cvc4 [7], vampire [25] and Z3 [15]. Some ITPs also incorpo-\nrate automated provers like Isabelle with Sledgehammer [8] and Coq with Coqhammer\n[14]."}, {"title": "Formal methods with LLM.", "content": "Recent research on generating formal mathematical proofs\nutilizes machine learning techniques for proof search and premise selection. Existing\nworks like GPT-f [35], PACT [22], Expert Iteration [34] use LLMs to generate actions,\nand the search engine tries to find possible correct steps using the actions provided by\nthe model. Some works including HTPS [27], and DT-Solver[43] enhance the search\nengine by machine learning techniques. Thor [24] uses the neural policy models incor-\nporating ATPs to prove the theorems. LeanDojo [46] enables interaction with the proof\nenvironment Lean [30]. It extracts fine-grained annotations of premises in proofs from\nLean, providing valuable data for premise selection."}, {"title": "Verification with LLM.", "content": "One of the key challenges of LLMs is their tendency to \"hal-\nlucinate\", which refers to generating information that is not just incorrect but often\nfabricated specious text. [23] sketches a self-monitoring and iterative prompting way\nthat uses formal methods to detect the hallucination and steer the LLM to the correct\nspecification. [11] builds the specialized prompt based on counterexamples provided by\nmodel checking and conducts code debugging and repairing based on LLMs."}, {"title": "8 Conclusion", "content": "We have presented a tool LLM4PR for automated generation of verified code using\nLLMs, Coq and ATPs. We formally transform the specifications into code based on our\nrefinement laws and LLMs. Our approach also extends the formal refinement calculus\nand builds active prompts to the informal LLMs. Finally, LLM4PR uses the ATPs to\nverify the refinement condition and the code based on the precondition and postcon-\ndition of the specification. Our experiments show that our method can generate more\nrobust and correct code compared to the state-of-the-art LLMs."}]}