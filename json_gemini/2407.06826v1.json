{"title": "VRDSynth: Synthesizing Programs for Multilingual Visually Rich Document Information Extraction", "authors": ["Dat Nguyen", "Tung Do-Viet", "Hung Nguyen-Duy", "Tuan-Hai Luu", "Hung Le", "Bach Le", "Patanamon (Pick) Thongtanunam"], "abstract": "Businesses often need to query visually rich documents (VRDs), e.g., purchase receipts, medical records, and insurance forms, among many other forms from multiple vendors, to make informed decisions. As such, several techniques have been proposed to automatically extract independent entities of interest from VRDs such as extracting price tags from purchase receipts, etc. However, for extracting semantically linked entities, such as finding corresponding price tags for each item, these techniques either have limited capability in handling new layouts, e.g., template-based approaches, or require extensive amounts of pre-training data and do not perform well, e.g., deep-learning approaches.\nIn this work, we introduce a program synthesis method, namely VRDSYNTH, to automatically generate programs to extract entity relations from multilingual VRDs. Two key novelties, which empower VRDSYNTH to tackle flexible layouts while requiring no pre-training data for extracting entity relations, include: (1) a new domain-specific language (DSL) to effectively capture the spatial and textual relations between document entities, and (2) a novel synthesis algorithm that makes use of frequent spatial relations between entities to construct initial programs, equivalent reduction to prune the search space, and a combination of positive, negative, and mutually exclusive programs to improve the coverage of programs.\nWe experiment on two popular VRD understanding benchmarks, namely FUNSD and XFUND, on the semantic entity linking task,", "sections": [{"title": "1 INTRODUCTION", "content": "Businesses often have to collect and store information from various sources for administrative tasks: from medical records, bills, purchase receipts, and insurance forms to technical reports from different vendors. These administrative documents often have various layouts with different visual elements such as images, graphics, tables, diagrams, etc, and hence, they are also called visually-rich documents (VRDs) [1]. A massive amount of data today is stored in the form of VRDs as a way for business enterprises to retain and exchange information. Often, businesses need to query this data to make informed decisions, e.g., enterprises need to extract prices for sold items from purchase receipts to claim credits for goods and services tax (GST). This motivates several recent approaches that can automatically extract useful information from VRDs [2-13]."}, {"title": "2 RELATED WORKS", "content": "To automatically extract information from documents with varied layouts, there are three main directions: rule-based approach, deep learning-based approach, and program synthesis.\nRule-based and template-based approach Traditional approaches in document image processing makes use of heuristic rules [12, 29-31]. These rules rely on carefully designed feature engineering, e.g., projection profile alignments [12], similar words and box size and distances [30, 31] to identify the desired document entities [32]. Based on these alignments, researchers [30, 33] have shown that a template can also be built for each document form [34]. After building the template, visual and textual features can be used to calculate the similarity between a given template and a target document image, e.g., [33, 35]. Additionally, [36] proposes a finer-grained template using the combinations of TF-IDF, angle, and distance between entities. While the rule-based and template-based methods perform well for a fixed set of document formats, when there exist more varied document formats from different business vendors, the management of these templates can become intractable. Additionally, template-based approaches are also prone to varying visual quality of documents, i.e., document images with low visual quality may unduly be classified as new templates, rendering template-based approaches imprecise. We aim to automatically aid developers in developing information extraction rules by automatically synthesizing programs based on example input document annotation. The synthesized rules can be seen as a matching template for each entity.\nDeep Learning-based Information Extraction More recently, deep learning has also been applied for information extraction from visually rich documents. [11] uses a recurrent neural network (RNN) to extract entities based on their textual features. They ignored the contribution of image and layout features and relied on the left-to-right reading order. [10] proposed a new chargrid representation and used a convolutional neural network (CNN) to segment the regions containing desired entities in the chargrid. Nevertheless, 2D chargrid or segmentation-based IE methods usually do not work in the case of dense documents with little space between entities. Graph Convolution Network (GCN) [37-39] have also been applied for visually-rich document information extraction by converting the input document into a document graph [5, 23, 40-43] and uses graph neural networks for entity recognition by formulating the problem into node classification, in which each entity is a node. For relation extraction, LayoutLMv2 [3] and LayoutLMv3 [4] are language-specific versions that work only in English. Since we focus on multi-lingual relation extraction, we use the state-of-the-art multi-lingual relation extraction-LayoutXLM [15] as the baseline. TPP [16] re-formulate entity linking as token reading order and utilizes transformers to predict these reading orders. While TPP is a promising method for entity linking, it requires additional annotations, which are not available and are not consistent with existing baselines and datasets. Our work relies on the output of semantic entity recognition and the document graph used by Qasim et al. [23]. However, we propose a new DSL along with a synthesis algorithm for this domain.\nProgram Synthesis for Information Extraction Program synthesis has long been used for different scenarios, ranging from programs handling primitive operations [20, 44], extracting information from spreadsheets [18, 19, 21], sequences [1], web data, PDF documents [7, 22, 45] and manipulating images [46]. These works generally propose either a new domain-specific language or a new technique for efficiently navigating the search space in synthesizing programs. The closest works to ours are that of [1, 7, 22] and [46]. [7] and [22] propose the usage of a transition system to extract the desired entity from a starting entity that matches specific conditions such as containing a word or lying on the left or right of a specific block. [46] proposed using a new DSL that involves the relation between entities to localize the desired image regions. Our domain-specific language also contains elements specifying the spatial relation between entities as well as textual constraint (containing specific text or specific character) like [7, 22]."}, {"title": "3 PROBLEM DEFINITION", "content": "We give a brief definition of a symbolic representation of a document Dy below, following Liu et al. [5].\nDEFINITION 1 (SYMBOLIC VISUALLY RICH DOCUMENT). A document Dy is conceptualized as an ensemble of entities denoted by Dv = {e1, e2, ... eN }, where N is the total number of entities in the documents. Each entity e\u00a1 is a tuple of (ei.text, ei.pos, ei.lbl) where ei.text is the textual content of the entity, ei.pos is characterized by coordinates (ei.Xo, ei. Yo, li.X1, li.y\u2081) denotes the rectangular bounds of the entity, originating from the starting coordinate (ei.x0, ei.yo) to its conclusive boundary at (ei.x1, ei.y\u2081) and ei.lbl is the predicted label of each entity from semantic entity recognition task.\nTo facilitate the ground for synthesizing relational rules on these visually rich documents, we use ei.center to denote the center $\\frac{(e_{i}.x_{0} + e_{i}.x_{1}}{2}, \\frac{e_{i}.y_{0} + e_{i}.y_{1})}{2}$. We also build a set of relations DR = {(rij)} following Qasim [23]. Each relation rij is a directed spatial relation between two entities e\u00a1 = rij.from and ej = rij.to in Dv along with a relation type rij.lbl that is either top, down, left, right, denoting the spatial alignments between entities.\nGiven this definition of symbolic visually rich document, we define the task of semantic entity linking in Definition 2.\nDEFINITION 2 (SEMANTIC ENTITY LINKING). Given a Symbolic VRD Dy as defined in Definition 1, the Semantic Entity Linking outputs a set of connections, L, between pairs of elements (ei, ej) \u2208 Dy \u00d7 Dy such that ej has semantic connections (i.e., is key, value or subheader of) ei.\nIn the context of visually rich documents, the \"connection\" in semantic entity linking refers to the relational information embedded within the document elements. These connections are not spatial or sequential linkages but are semantic associations that define the hierarchy of information in the document.\nFor instance, consider a form in Figure 3: the two entities \"Event Name\" and \"The USQ Spring Festival\" have a semantic association: The former is the question (i.e., key) while the latter is the answer. Similarly, in the same form, a section titled \"Special Event Information Sheet\" has associations with its sub-sections (e.g., \"General Information\u201d and \u201cHours\u201d), which are semantically linked as they elaborate on the broader \"Special Event Information Sheet\" category. The problem of identifying these relationships is called semantic entity linking.\nTo formulate the input and output of program synthesis, we present a formalization for semantic entity linking in the context of program synthesis. Suppose we have a dataset consisting of instances of symbolic visually rich documents, each represented as Di where Di = {e1, e2, ... eN } are elements defined in Definition 1, alongside with these documents, we are provided with the semantic link between Li existing elements, where each semantic link (ej, ek) \u2208 Li is an ordered pair of entities from D\u012f, indicating a directional relationship from one element to another (i.e., L\u00a1 \u2286 D\u00a1 \u00d7 Di)."}, {"title": "4 DOMAIN SPECIFIC LANGUAGE", "content": "In this section, we explain in detail our proposed DSL - a context-free grammar - that is specifically used to describe the search space of the program synthesis task. In the domain of symbolic visually-rich documents, our proposed grammar is engineered to be sufficiently expressive to enable sophisticated operations and queries while maintaining the tractability of the search space.\n4.1 Grammar\nWe propose a DSL in Figure 2 and describe the syntax of the DSL below.\nPrograms and Sub-programs(P): At the highest level, programs are either Find, Union, or Exclude programs. To describe in a bottom-up manner, each Find program can be regarded as a single query that returns linkable pairs. All three types of programs return linkable pairs. Union programs aggregate results from multiple sub-programs, and Exclude programs filter out results of a specific program (first argument) from another program (second argument)."}, {"title": "4.2 Denotational Semantics of the DSL", "content": "In this Section, we describe the denotational semantics of our DSL. We first describe the semantic domains of the DSL, followed by describing each evaluation rule in a bottom-up manner.\nSemantic Domains The denotational semantics of the DSL uses the following domains: (1) Dp is the domain of all possible programs, (2) Dc is the domain of conditions (3) Dy is the domain of visual elements in a document, (4) DR is the domain of relationships between visual elements, (5) Dset is the domain of sets of visual elements and (6) DBool is the domain of boolean values {true, false}.\nSemantic Rules for Programs The interpretation of programs is defined recursively based on the program's structure. Below we denote the semantics of the DSL programs. The semantic of Find relies on evaluating the potential bindings of (e.g., possible elements that can be assigned to) each relation and variable. Thus, we define valuation function pair (bu, br) as a function that assigns values to variables and relationships:\n$b: V\\rightarrow D_{y}  b_{r}: R \\rightarrow D_{R}$\n(3)\nWe denote the valuation of v given binding b as [[v]]b and valuation of r given binding b as [[r]]b:\n[[V]]b = b(V) (4)\n[[V.lbl]] = [[V]]b.lbl (5)\n[[V.text]] = [[V]]b.text\n[[V.X1] b = [[V] b.X1 (6)\n[[V.xo] b = [[V]]\u044c.\u0425\u043e\n[[V.y1]b = [[V]]b-\u04231 (7)\n[[V.yo]]b = [[V]]b.yo (8)\n[[R.lbl]]b = [[R]]b.lbl\n[[R.mag]] b = || [[R]]b.from.center - [[R]]b.to.center||1 (9)\nWhere || || is the L\u2081 norm between two positions. The semantic function [[]] maps syntactic constructs (e.g., conditions) to their semantic (e.g., truth values) under a binding b. For a condition C, [[C]]b is true or false depending on whether C holds under b. We describe the semantics of evaluating conditions in a bottom-up"}, {"title": "5 MOTIVATING EXAMPLE", "content": "This section presents a motivating example that uses a specific program in the DSL to link entities. Consider the event organization form in Figure 3, where each entity is assigned with a corresponding label: \"Special Event Information Sheet\" is the header, \"General Information\" is also a header, and under this header there exists three keys and three values. We aim to link each header to the corresponding subheaders, each subheader to the corresponding keys, and each key to the corresponding values.\nTo provide a clear understanding of how one might tackle this challenge programmatically, we introduce a program depicted in Figure 3b. This program links all pairs that satisfy either one of the three sub-programs. The first Find sub-program links between header and subheader, the second program links between header and corresponding keys, and the final program links between keys and value. The results of these programs are combined to get the final results.\nAll the three programs shares the variable set {00, 01} and relation variable set {ro}. Each variable can be mapped to a corresponding entity, i.e., e \u2208 Dy, and each relation variable can be mapped to corresponding relations, i.e., (ei, ej) \u2208 Dr, in Definition 1. Initially, without any constraint, all variables and relation variables can be bound to any entity and relations. With added constraints, such as \u0e02.lbl == Header (variable vo has to have label Header), the space of possible binding B is pruned. In our case, the third argument of the Find program is the constraint to prune this search space. For header linking programs, this condition prunes the possible bindings of variables and relations. In detail, it requires four sub-conditions: there must exist a relation between the valuation of vo and v1 (i.e., entities that bind to variable vo and v\u2081). Furthermore, this relation has to have the label Down. The entities that can be bound to vo and v\u2081 must have label Header. Furthermore, vo's text must not contain a colon while v\u2081 does to avoid linking headers of the same levels. We specifically save vo as the initial entity to be linked with. This means that for every found binding, vo is the starting entity in which we want to link every valuation of the Vset_return with. In this case, for every binding, we would link the valuation of vo and v\u2081. In this example, \"Special Event Information Sheet\" is linked to \"General Information\" and \"Hours\".\nFor header-question (header to key), we have an Exclude program, specifying that we want to find a set of links that satisfies the first program but avoid the links that model the second program: The first Find program dictates that header-linking should link two entities 00, 01 corresponding to Header and Question (Key) label, but avoid the keys that belong to the other headers in the program. \"General Information\" can be linked towards \"Event Name\", \"Event Location\" and \"Event Dates\u201d but not towards \"Monday-Friday\" and \"Saturday-Sunday\" since they already belong to another header (Hour). Since the first program's results cannot include the second program, we call the second Find program mutually exclusive program of the first find program.\nFinally, the third program links corresponding keys and values. Particularly, it links each key to the value on the right of it, given that the distance is sufficiently small (ro.mag < 0.2), where 0.2 is the ratio on the page's maximum dimension (width or height)."}, {"title": "6 SYNTHESIZING PROGRAMS FOR VRD INFORMATION EXTRACTION", "content": "Taking as input the set of documents {D} along with the corresponding specifications {M}, our goal is to synthesize a single final that precisely links the entities following the specifications. For this, we first construct a relation set DR for each document D, in which DR consists of all relations between entities in D. We construct a document graph G = <D, DR) for each document to represent the relations between entities. Our synthesis algorithm,"}, {"title": "6.1 Construction of Initial Programs", "content": "Recall that the search space can be large due to the expressive power of our DSL, and thus, our goal is to effectively restrict the search space by automatically constructing a set of initial programs, from which our synthesis procedure mutates and evolves to find high-quality candidate programs consistent with the provided specifications. These initial programs provide useful clues for our synthesis procedure to start the search in a more effective way."}, {"title": "6.2 Iterative Refinement of Programs", "content": "The initial programs can be imprecise since they lack additional structural and textual constraints. In this step, we iteratively refine the programs to find high-quality candidates. The refinement algorithm is defined in Algorithm 3. Each iteration starts with the current set of programs and the search is performed by first converting the current condition C in the Find program into a conjunction of C and an unknown condition And(C, ). We enumerate possible candidates to fill in the hole while making use of equivalence reduction to avoid enumerating redundant programs. Among the enumerated candidates, we keep three types of programs: the more precise programs for the next iterations, the perfect positive programs (that output all correct pairs), and the negative programs (that output all pairs of entities that should not be linked). At the end of each iteration, we also extend the set of positive programs by combining positive, negative, and mutually exclusive programs.\nBelow, we describe in detail each component.\nEquivalence reduction with term rewriting. To prune the space of possible programs in the enumeration phase, we leverage equivalent reduction [25] in the form of term rewriting rules below. These rules are applied in a bottom-up manner to all the enumerated programs and help filter out redundant candidates.\nAnd(A, A) \u2192 A\nAnd(A, False) \u2192 False\nAnd(A, True) \u2192 A\nF < F \u2192 False\nEqual(S, S) \u2192 True\nContains (S, S) \u2192 True\nF > F \u2192 False\nV.label == V.label \u2192 True\nR.label == R.label \u2192 True\nV.x0 < V.x1 \u2192 True\nV.x1 <V.x0 \u2192 False\nV.y0 < V.y1 \u2192 True\nV.y1 < V.y0 \u2192 False\nPrecision-oriented program selection. The ultimate goal of our approach is to synthesize programs that can precisely capture the semantic relationship between entities as stated in Section 3. We formalize this goal and our detailed refinement process below.\nGiven a graph dataset {G} and a specification {M} on this graph dataset, for each program p, we collect the set of all possible bindings that satisfy the condition of p as Bp. Among all bindings in Bp, we further divide them into two sets $B_{p}^{+}$ and $B_{p}^{-}$. $B_{p}^{+}$ denotes the set of bindings that models the original specifications (i.e., $\\forall b\\in B_{p}^{+}, \\forall v_{ret} \\in V_{set\\_return}, (b[v_{0}], b[v_{ret}]) \\in M$), and $B_{p}^{-}$ denotes the set of bindings that do not model the specifications. We can calculate the precision of the program by counting all the linked entities within $B_{p}^{+}$ and $B_{p}^{-}$:\n$prec(B_{p}^{+}, B_{p}^{-}) = |B_{p}^{+}|/(|B_{p}^{+}|+|B_{p}^{-}|)$ (22)\nOur observation is that, given an initial And constraint, any additional constraints will reduce either or both $B_{p}^{+}$ and $B_{p}^{-}$. Thus, we keep adding the constraints that improve the precision of the program. For every Find program p, let {C} be the set of constraints that has yet to appear in p and is valid towards p.\nTo keep track of programs performing similarly, we keep version spaces of programs that have similar $B_{p}^{+}$ and $B_{p}^{-}$ (i.e., VS : (P(B),P(B)) \u2192 P(Dp)), where P denotes power sets). To further avoid synthesizing redundant programs, we keep track of the set of covered specifications (i.e., $\\cup_{p} B_{p}^{+}$) and only accept candidates that cover a yet-covered part of specifications for further extension.\nGenerating additional positive programs by using mutually exclusive programs. While enumerating, we also keep track of perfect-positive programs (that only output correct pairs of linked entities) and perfect-negative programs (only output pairs of entities that should not be linked). At the end of each iteration, we collect additional perfect program set PP*, the set of perfect negative programs NP* (programs that only give examples that do not match the specification), and the set of new version space with improved precision. These positive programs and negative programs cover the perfect set PCover and NCover, respectively. In practice, we also observe the mutually exclusive property between certain entities. For example, in Figure 3, in the header-key linking, we can express the rule \"find the key below target header, but does not belong to another header\u201d as an exclude program of two Find programs.\nFinally, to construct the final program, we perform union on all of these positive sub-programs PP and exclude the union of all negative sub-programs NP:\nPfinal := Exclude(Union(pp \u2208 PP), Union(np \u2208 NP))"}, {"title": "7 EXPERIMENT", "content": "We implement VRDSYNTH in Python with over 7,000 lines of code. The experiments are performed on a computer equipped with AMD Ryzen Threadripper PRO 3995WX, with 128 GB of RAM and with RTX 4090 GPU with 24GB of VRAM. We set the maximum synthesis time of VRDSYNTH to be 2 hours on all tasks. Since the programs can be synthesized offline, this can be seen as analogous to training time for machine learning models.\nBenchmark. We evaluate VRDSYNTH on semantic entity linking task on the FUNSD [14] and XFUND [24] datasets. These two"}, {"title": "7.1 RQ1: Effectiveness of VRDSYNTH and its Extension", "content": "We use the DSL defined in Section 4 for the base version of VRDSYNTH and expand the relation label grammar rule as in equation 2 for VRDSYNTH Table for all forms across 8 languages. For each language, we use the training documents to synthesize a program and evaluate the synthesized program on the test set. For LayoutXLM [15], InfoXLM [26] and XLM-Roberta [27], we use the training documents for fine-tuning the pre-trained model and evaluate the fine-tuned model on the language's test set. Table 1 presents the precision, recall, and F1 score for both VRDSYNTH'S synthesized program and pretrained models [15, 26, 27].\nRegarding the F1 score, VRDSYNTH outperforms LayoutXLM, InfoXLMBase and XLMRobertaBase in 5, 6 and 7 out of 8 languages respectively. In all 8 languages, VRDSYNTH achieves better precisions than the pre-trained language models. Among all languages, VRDSYNTH achieved the highest F1 score (0.727) in French forms. Additionally, for English forms, VRDSYNTH achieved 41.89%, 263.31% and 162.39% higher F1 score than LayoutXLM, InfoXLMBase and XLMRoberta Base, respectively.\nUsing the table module to extend VRDSYNTH to VRDSYNTH Table further improves the performance of the synthesized programs in 5 languages: English, Germany, French, Japanese, and Chinese. Addi-tionally, VRDSYNTHTable outperforms LayoutXLM, InfoXLMBase\nRQ1 Conclusion: VRDSYNTH, without requiring pre-trained data or pre-training procedure, achieved significantly higher average precision than all baselines and outperformed LayoutXLM on 5 out of 8 languages in terms of F1 score. VRDSYNTH Table improved VRDSYNTH'S performance in 5 languages, outperformed all the base variants of pre-trained models in 7 out of 8 languages and large variants of pre-trained models on 4 out of 8 languages."}, {"title": "7.2 RQ2: Contribution of negative and mutually-exclusive sub-programs", "content": "VRDSYNTH makes use of both positive and negative sub-programs in the synthesis procedure. To measure the contribution of negative programs, we perform a comparison of synthesized programs' performance before and after adding negative/mutually exclusive programs in terms of F1 score in Figure 4.\nResults show a consistent improvement of the F1 score of VRDSYNTH in all languages. In detail, we can see improvements of 2%, 5%, 9%, 1%, 7%, 6%, 8%, 3% on en, de, es, fr, it, ja, pt, and zh respectively. This constitutes an overall improvement of 5% in terms of F1 score."}, {"title": "7.3 RQ3: Efficiency of VRDSYNTH", "content": "We measure the inference time and memory usage of VRDSYNTH'S variants - VRDSYNTHpos and VRDSYNTH full (using only positive programs and all programs, respectively) along with LayoutXLM. To provide a precise comparison, we set the number of available CPU cores to 1 and do not use GPU.\n7.3.1 RQ3.1. Inference time efficiency. We note down the mean and standard deviation of runtimes of the synthesized programs generated by different variants of VRDSYNTH versus the baselines in Table 2. VRDSYNTH inference time is 4.15 seconds on average, this speed is better than InfoXLMLarge, while being comparable with XLMRobertaLarge and is slightly less efficient than LayoutXLM. The positive-program-only version of VRDSYNTH is much more efficient, running on an average of only 1 second per document. VRDSYNTH full is more efficient than its extension, VRDSYNTH Table which takes on average of 17.08 seconds for each form, due to additional same rows and columns relations detected by the table module.\nWe note that VRDSYNTH's inference is implemented in Python, while the baselines are based on Pytorch, which is implemented in C++, thus, in future implementation, it would be interesting to see the improvement in using C++ for executing VRDSYNTH'S synthesized programs.\n7.3.2 RQ3.2. Memory efficiency. Table 3 summarizes efficiency of all techniques. VRDSYNTH requires only 1 MB of storage and 380 MB of memory for inference, significantly lower than LayoutXLM at 1.48GB for storage and 3.04GB for memory inference. VRDSYNTH Table, despite requiring more memory than VRDSYNTH,"}, {"title": "8 THREATS TO VALIDITY", "content": "Threats to internal validity Relate to possible errors in our implementation and experiments. We have rechecked our implementation and experiments and fixed the errors that we have found. Still, there could be additional errors that we did not notice. We have carefully constructed a replication package and ensured that the exact commands and hyperparameters used for reproducing the experiments are included.\nThreats to external validity Correspond to the generalizability of our findings. VRDSynth consists of two components: the DSL and the synthesis algorithm. The DSL is designed based on various kinds of documents with various languages so it should cover various structures, still, it is possible that there exists specific documents where structures are not represented by the DSL. Furthermore, the synthesis algorithm works by identifying subgraphs from document graphs that match specific patterns in terms of structure and properties. These patterns are initially mined from the dataset and then iteratively extended. Thus, in the presence of long-distance and rare relations, it will be hard to either discover this relationship with mining or iterative refinement of programs. This problem is difficult for any approach handling VRDs. We tried mitigating the threat on the generalizability of both DSL and synthesis algorithm by experimenting on datasets containing varied real-world documents such as FUNSD and XFUND. To further mitigate the former threat, we also experimented with the extensibility of VRDSynth's DSL to adopt a domain-specific module to tackle table structures, namely, VRDSYNTH Table without changing the synthesis algorithm, however, it is still possible that the DSL might need to be extended again to tackle even more challenging domains.\nThreats to construct validity Correspond to the suitability of our evaluation metrics. For RQ1 and RQ2, we measured the performance of all baselines using well-known metrics- precision, recall and F1 score. For RQ3.1, we measured both the mean and standard deviation of inference time in seconds for each language and baseline. For RQ3.2, we measured both the maximum storage and runtime memory of all baselines."}, {"title": "9 CONCLUSION AND FUTURE WORKS", "content": "We introduced a synthesis-based approach towards visually rich document understanding. In detail, we proposed a new expressive DSL enabling us to represent programs that link entities based on"}]}