{"title": "Enhancing In-Hospital Mortality Prediction Using Multi-Representational Learning with LLM-Generated Expert Summaries", "authors": ["Harshavardhan Battula", "Jiacheng Liu", "Jaideep Srivastava"], "abstract": "In-hospital mortality (IHM) prediction for ICU patients is critical for timely interventions and efficient resource allocation. While structured physiological data provides quantitative insights, clinical notes offer unstructured, context-rich narratives. This study integrates these modalities with Large Language Model (LLM)-generated expert summaries to improve IHM prediction accuracy.", "sections": [{"title": "Objective", "content": "In-hospital mortality (IHM) prediction for ICU patients is critical for timely interventions and efficient resource allocation. While structured physiological data provides quantitative insights, clinical notes offer unstructured, context-rich narratives. This study integrates these modalities with Large Language Model (LLM)-generated expert summaries to improve IHM prediction accuracy."}, {"title": "Materials and Methods", "content": "Using the MIMIC-III database, we analyzed time-series physiological data and clinical notes from the first 48 hours of ICU admission. Clinical notes were concatenated chronologically for each patient and transformed into expert summaries using Med42-v2 70B. A multi-representational learning framework was developed to integrate these data sources, leveraging LLMs to enhance textual data while mitigating direct reliance on LLM predictions, which can introduce challenges in uncertainty quantification and interpretability."}, {"title": "Results", "content": "The proposed model achieved an AUPRC of 0.6156 (+36.41%) and an AUROC of 0.8955 (+7.64%) compared to a time-series-only baseline. Expert summaries outperformed clinical notes or time-series data alone, demonstrating the value of LLM-generated knowledge. Performance gains were consistent across demographic groups, with notable improvements in underrepresented populations, underscoring the framework's equitable application potential."}, {"title": "Conclusions", "content": "By integrating LLM-generated summaries with structured and unstructured data, the framework captures complementary patient information, significantly improving predictive performance. This approach showcases the potential of LLMs to augment critical care prediction models, emphasizing the need for domain-specific validation and advanced integration strategies for broader clinical adoption."}, {"title": "Keywords", "content": "electronic health records; in-hospital mortality; large language models; machine learning; ICU; clinical notes."}, {"title": "Introduction", "content": "Predicting In-hospital mortality (IHM) in Intensive Care Unit (ICU) is critical for improving patient outcomes and optimizing healthcare resources. Timely identification of high-risk patients enables early interventions, potentially saving lives and reducing healthcare costs. Advances in machine learning and the widespread adoption of Electronic Health Records (EHRs) have facilitated the development of predictive models in critical care settings. These models traditionally rely on structured data, such as vital signs and laboratory results, which are continuously recorded in ICUs [8,10,14,15]. However, such models often fail to incorporate unstructured clinical data, which provides valuable contextual information about patient conditions.\nClinical notes, a key component of EHRs, capture detailed observations, assessments, and care plans from healthcare providers. These notes offer a qualitative dimension that complements the quantitative nature of structured data. Despite their value, integrating clinical notes into predictive models is challenging due to the variability of natural language and the need for domain expertise to extract meaningful insights. Recent advancements in Natural Language Processing (NLP) have enabled the processing of unstructured text, transitioning from traditional feature-based methods [2] to sophisticated transformer-based architectures like ClinicalBERT and BioBERT [1,13].\nDomain-specific LLMs, such as Med42, MedPaLM, and GPT-40, represent a new frontier for under-standing clinical narratives [4-6]. These models embed extensive medical knowledge in their parameters and have demonstrated proficiency in generating summaries and interpreting nuanced clinical informa-tion. By leveraging these capabilities, LLMs can distill critical insights from clinical notes, enhancing predictive model accuracy. However, directly using LLMs for predictions introduces challenges, partic-ularly in quantifying uncertainty [3,17]. In high-stakes settings like ICUs, such limitations could lead to unintended consequences in clinical decision-making. To address these risks, this study focuses on transforming clinical notes into Expert-Based Clinical Representations (EBCRs) by infusing domain knowledge from LLMs rather than relying on LLMs directly for predictions. This approach ensures the predictive model remains interpretable and improves uncertainty quantification.\nThis study proposes a novel multi-representational learning framework that integrates structured time-series physiological data with unstructured clinical notes and LLM-generated expert summaries through EBCRs. Structured data provides quantitative insights, while clinical notes and LLM-generated summaries contribute qualitative perspectives, enabling a comprehensive understanding of patient health. By incorporating domain knowledge from LLMs, the proposed approach bridges the gap between structured and unstructured data, enhancing predictive performance and robustness.\nA retrospective cohort analysis was conducted using the MIMIC-III (Medical Information Mart for Intensive Care III) database [12], focusing on ICU patients admitted for at least 48 hours. A neural network model was developed to integrate the multi-representational data sources through a joint learning framework, with performance evaluated using the Area Under the Receiver Operating Characteristic Curve (AUROC) and Area Under the Precision-Recall Curve (AUPRC). Comparative analyses were performed against baseline models that used only structured data or single textual representations."}, {"title": "Materials and Methods", "content": "This study utilized the Medical Information Mart for Intensive Care III (MIMIC-III) database, a publicly available dataset containing de-identified health records of ICU patients at the Beth Israel Deaconess Medical Center [12]. The analysis focused on patients admitted to the ICU for at least 48 hours, as this period is critical for predicting in-hospital mortality due to the heightened risk of acute deterioration during early ICU stages [9, 10]. We constructed the dataset based on the preprocessing pipeline suggested by [10], we selected 10 clinical variables with minimal missing data: diastolic blood pressure, systolic blood pressure, mean arterial blood pressure, heart rate, temperature, respiration rate, oxygen saturation (SpO2), fraction of inspired oxygen (FiO2), blood pH value, and blood glucose levels. Missing values were imputed, and corresponding imputation masks were added for robustness. Abnormal values, such as negative SpO2 readings, were excluded, and extreme outliers were truncated. The variables were aggregated into hourly time series by calculating the average of"}, {"title": "In-hospital Risk of Mortality Prediction for ICU Patients", "content": "Below, we present the mathematical definitions for each component and detail the structure of the multi-representational learning approach. Let $X = \\{x_t\\}_{t=1}^{T}$ represent the time-series physiological data, where $T$ is the total number of time steps (measured in hours), and $x_t \\in \\mathbb{R}^d$ denotes the vector of $d$ physiological measurements at time $t$. In this study, $T$ is set to 48 hours. Let $N_T$ denote the chronological concatenation of clinical notes recorded during the first 48 hours for a given patient. The LLM-generated expert summary, represented as $N_{expert} = f_{LLM}(N_T)$, is treated as an auxiliary trans-formation of the original textual data. The target variable $y \\in \\{0,1\\}$ indicates in-hospital mortality, with $y = 1$ if the patient died prior to discharge and $y = 0$ otherwise."}, {"title": "Baseline: Time-Series LSTM Model", "content": "The baseline model employed in this study is inspired by previous works such as [10]. For predicting in-hospital mortality, we utilized a Long Short-Term Memory (LSTM) network [11] to capture temporal dependencies within the time-series physiological data $\\{x_t\\}_{t=1}^{T}$. At each time step, the LSTM takes the current input $x_t$ and the previous hidden state $H_{t-1}$ to compute the updated hidden state $H_t$:\n$H_t = LSTM(x_t, H_{t-1})$, for $t = 1$ to $T$.\nThe final hidden state at $t = 48$ is used to generate the prediction for in-hospital mortality:\n$\\hat{y} = \\sigma(W_m h_{48} + b_m)$,\nwhere $\\hat{y}$ represents the predicted probability of in-hospital mortality, $\\sigma(\\cdot)$ is the sigmoid activation function, $W_m$ is the weight matrix of the final fully connected layer, and $b_m$ is the bias term. The model was trained using binary cross-entropy loss to minimize the error in predicting mortality outcomes. To address potential overfitting, L2 regularization was incorporated during training."}, {"title": "Textual Representations Embedding", "content": "Both the original clinical notes and the LLM-generated summaries were encoded using a Feature Extractor built on ClinicalBERT [1], a transformer-based language model trained on clinical text. Since modeling clinical notes involves sequential prediction, it requires aligning discrete textual events with continuous time-series data recorded at hourly intervals. To achieve this, feature maps $U_i$ were generated by independently processing each note $N_i$ through the Feature Extractor. For every time step $t = 1,2,..., T$, the aggregated text representation $U_t$ was computed as follows:\n$U_i = FeatureExtractor (N_i)$ for $i = 1,..., K$,\n$w(t, i) = exp(-\\lambda \\cdot (t - CT(i)))$,\n$U_t = \\frac{1}{M} \\sum_{i=1}^{M} w(t, i)$,\nwhere $M$ is the total number of notes available before time step $t$, and $\\lambda$ is a decay hyperparameter optimized using the validation set. The term $w(t, i)$ represents a temporal weighting function that applies an exponential decay based on the difference between the current time step $t$ and the chart time $CT(i)$ of the note. This approach ensures that recent notes, which are more indicative of the patient's current condition, are given greater importance in the aggregated representation $U_t$."}, {"title": "LLM-Generated Summary Embedding", "content": "The expert summary generated by the LLM, denoted as $N_{expert}$, was processed to derive the auxiliary text embedding $V_t$. To create the input for the LLM, all clinical notes $N_1$ through $N_K$, documented during the time period $t = 1$ to $t = T$, were concatenated ($\\parallel$) in chronological order to form a single document $N_T$:\n$N_T = N_1 \\parallel N_2 \\parallel ... \\parallel N_K$.\nThe LLM-generated summary was then produced by applying the LLM function $f_{LLM}$ to $N_T$, where $f_{LLM}$ utilized a hard prompt to generate a structured summary. Details of the prompt used can be found in the supplementary materials.\n$N_{expert} = f_{LLM}(N_T)$.\nThe resulting expert summary $N_{expert}$ was subsequently encoded into its corresponding embedding $V_t$ using a Feature Extractor,\n$V_t = FeatureExtractor(N_{expert})$."}, {"title": "Joint Learning", "content": "To effectively capture complementary information from the different data modalities, the embeddings were combined through a joint fusion mechanism, specifically using concatenation:\n$h_{concat} = [H_t; U_t; V_t] \\in \\mathbb{R}^{h+2b}$,\nwhere $b$ is the embedding size generated by the Feature Extractor, and $[\\cdot ; \\cdot]$ denotes concatenation of vectors along the feature dimension. The joint embedding $h_{concat}$ was then passed through a fully connected layer to compute the final output:\n$z = W h_{concat} + b$,\nwhere $W \\in \\mathbb{R}^{(h+2b)}$ represents the weight matrix, and $b$ is the bias term. The final probability of in-hospital mortality, $\\hat{y}$, was obtained by applying a sigmoid activation function to $z$:\n$\\hat{y} = \\sigma(z)$,\nwhere $\\sigma(\\cdot)$ is the sigmoid function."}, {"title": "Implementation Details", "content": "The implementation of the model involved specific hyperparameters and training strategies. For the time-series data, the LSTM network used a hidden size of $h = 256$, while textual embeddings were generated using ClinicalBERT, which produces embeddings of size $b = 768$. The joint fusion of time-series and textual representations was implemented via concatenation of embeddings. Optimization was performed using the Adam optimizer with a learning rate of $1 \\times 10^{-4}$, and L2 regularization was applied with $\\lambda = 1 \\times 10^{-5}$ to mitigate overfitting. The models were trained with a batch size of 32, and early stopping was employed to monitor performance on the validation set, halting training if the validation loss did not improve for 5 consecutive epochs.\nSince the data usage agreement of the MIMIC-III dataset explicitly limits the use of cloud-hosted LLMs like GPT-4 [16], we relied on open-source model, Med42v2-70B, which can be run locally. Due to limited computational resources, we did not test our approach with other open-source, medical-specialized LLMs. As for smaller-sized LLMs, such as the Med42-8B model, a visual quality check of its outputs revealed that hallucination problems were so pervasive that the outputs were often unreliable. This experiment was conducted using an NVIDIA A100 80GB GPU, and it required approximately 80 hours to process the clinical notes and generate expert opinions using Med42v2-70B."}, {"title": "Results", "content": "We evaluated the performance of various models for predicting in-hospital mortality. Given the class imbalance in the dataset, where only 13% of patients experienced mortality, the AUPRC was chosen as the primary evaluation metric because it is well-suited for imbalanced classification problems [7]. Additionally, the AUROC was reported to provide a complementary assessment of model performance.\nThe baseline time-series-only model achieved an AUROC of 0.8320 and an AUPRC of 0.4513, es-tablishing a foundation for comparison. Incorporating textual data from clinical notes significantly improved predictive performance. The model using clinical notes alone achieved an AUROC of 0.8488 and an AUPRC of 0.5337, representing a 2.02% and 18.26% improvement, respectively, over the base-line. This suggests the added predictive power of clinical notes, which capture qualitative aspects of patient health not present in structured time-series data.\nUsing only the LLM-generated expert summaries led to further performance improvements, with the model achieving an AUROC of 0.8873 and an AUPRC of 0.5978. This corresponds to a 6.65% improvement in AUROC and a 32.46% improvement in AUPRC compared to the baseline. These results indicate that expert summaries, represented as EBCRs incorporating domain knowledge from the LLM, effectively enhance predictive performance by providing a distilled and complementary rep-resentation of clinical notes.\nThe integration of multiple modalities through joint fusion yielded the best results. Combin-ing time-series data with clinical notes achieved an AUROC of 0.8853 and an AUPRC of 0.6056, representing 6.41% and 34.19% improvements over the baseline, respectively. Finally, the proposed multi-representational model, which integrates time-series data, clinical notes, and expert summaries through EBCRs, achieved the highest performance metrics, with an AUROC of 0.8955 and an AUPRC of 0.6156. This corresponds to a 7.63% improvement in AUROC and a 36.41% improvement in AUPRC compared to the baseline. Notably, adding expert summaries to the joint fusion model led to a 1.15% improvement in AUROC and a 1.65% improvement in AUPRC compared to the model that excluded them.\nThese results demonstrate the utility of integrating LLM-generated summaries with other data modalities. Expert summaries not only outperformed individual modalities such as time-series data or clinical notes alone but also significantly enhanced the performance of joint fusion models. This suggests that the summaries capture complementary information that enhances the overall predictive capability."}, {"title": "Discussion", "content": "This study shows the effectiveness of integrating multiple data representations using joint fusion to improve in-hospital mortality prediction. By combining time-series data, clinical notes, and LLM-generated expert summaries, the proposed multi-representational learning framework captures com-plementary information, and improving the model's predictive performance. The inclusion of expert summaries through EBCRs, which infuse domain knowledge from an LLM conditioned on clinical notes, provides distilled insights and highlights critical aspects that may not be explicitly captured in"}, {"title": "Qualitative Evaluation", "content": "y-tsne\nthe raw notes or physiological data. These findings have significant clinical implications, enabling early and accurate identification of high-risk patients, which is crucial for timely interventions and efficient resource allocation.\nTo further assess the effectiveness of the proposed framework, we conducted t-SNE visualizations of the intermediate hidden representations from the time-series model, pooled clinical note embeddings, and EBCRs. These visualizations (Figure 2) illustrate that the positive and negative classes are well separable in the EBCRs, indicating that the integration of complementary representations enhances discriminative power.\n10.0\nt-SNE plot\n7.5\n5.0\n2.5\n0.0\n-2.5\n-5.0\n-7.5\nLabels\nLabel 0\n-10.0\nLabel 1\n-10 -5 0 5 10\nx-tsne\ny-tsne\nt-SNE plot\n7.5\n5.0\n2.5\n0.0\n-2.5\n-5.0\n-7.5\nt-SNE plot\n10.0\n7.5\n5.0\n2.5\ny-tsne\n0.0\n-2.5\n-5.0\nLabels\nLabel 0\n-7.5\nLabel 1\n-10.0 -7.5 -5.0 -2.5 0.0 2.5 5.0 7.5 10.0\nx-tsne\nLabels\nLabel 0\n-7.5\n\u2022 Label 1\n-5.0 -2.5 0.0 2.5 5.0 7.5 10.0\nx-tsne\n(a) t-SNE plot of Time Series em-\nbeddings\n(b) t-SNE plot of pooled clinical\nnotes embeddings\n(c) t-SNE plot of Expert Opinion\nembeddings\nFigure 2: t-SNE plots of different embeddings"}, {"title": "Performance across Various Racial Groups", "content": "We also evaluated the model's performance across demographic groups in the test set to ensure fairness and robustness. Table 3 presents the AUROC and AUPRC metrics for both the Time-Series (Only) baseline and the multi-representational model. The results indicate that the multi-representational model consistently outperformed the baseline across all demographic groups, particularly in AUPRC, which is crucial for handling imbalanced datasets. These findings demonstrate the model's potential to provide equitable performance across diverse populations."}, {"title": "Limitations and Future Work", "content": "The experimental results demonstrate that models using LLM-generated expert summaries through EBCRS outperformed those relying solely on time-series data or clinical notes. The superior perfor-mance of the joint fusion model indicates that leveraging complementary modalities creates a more robust representation of patient status. These findings underscore the potential of LLMs in augmenting textual data representations without directly relying on them for prediction, which mitigates challenges related to the quantification of uncertainty in LLM-driven predictions.\nHowever, there are several limitations to consider. The study utilized a single dataset, MIMIC-III, which, while comprehensive, may not fully capture the diversity of ICU populations and care protocols across different hospitals or geographic regions. External validation on datasets from other institutions is necessary to confirm the generalizability of the proposed framework. Additionally, the quality of"}, {"title": "Conclusion", "content": "This study demonstrates that integrating LLM-generated expert summaries as auxiliary textual rep-resentations through EBCRs and joint fusion enhances the predictive power of in-hospital mortality models. By leveraging the domain knowledge embedded in LLMs and conditioning it on patient-specific clinical notes, this approach captures complementary information from diverse data sources, improv-ing model performance in critical care settings. The findings highlight the efficacy of simple fusion techniques in integrating structured and unstructured data, offering a practical pathway for develop-ing robust clinical prediction models. Future work could explore fine-tuning LLMs on domain-specific datasets to improve the quality of expert summaries and investigate advanced fusion mechanisms, such as attention-based approaches, to further optimize multi-modal integration. Additionally, developing interpretability techniques to better understand the contributions of each modality would enhance the trustworthiness of these models in clinical applications. By advancing the integration of structured data and unstructured clinical narratives, this study provides a foundation for more accurate and com-prehensive predictive models, paving the way for improved patient outcomes and resource allocation in critical care."}, {"title": "Funding", "content": "This research is not funded."}, {"title": "Conflicts of Interest", "content": "The authors declare no conflicts of interest."}, {"title": "Data Availability", "content": "Data are available from the MIMIC-III database with credentialed access. We are planning to release the code upon the paper's acceptance."}]}