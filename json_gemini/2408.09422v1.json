{"title": "Distinguish Confusion in Legal Judgment Prediction via Revised Relation Knowledge", "authors": ["Nuo Xu", "Pinghui Wang", "Junzhou Zhao", "Feiyang Sun", "Lin Lan", "Jing Tao", "Li Pan", "Xiaohong Guan"], "abstract": "Legal Judgment Prediction (LJP) aims to automatically predict a law case's judgment results based on the text description of its facts. In practice, the confusing law articles (or charges) problem frequently occurs, reflecting that the law cases applicable to similar articles (or charges) tend to be misjudged. Although some recent works based on prior knowledge solve this issue well, they ignore that confusion also occurs between law articles with a high posterior semantic similarity due to the data imbalance problem instead of only between the prior highly similar ones, which is this work's further finding. This paper proposes an end-to-end model named D-LADAN to solve the above challenges. On the one hand, D-LADAN constructs a graph among law articles based on their text definition and proposes a graph distillation operation (GDO) to distinguish the ones with a high prior semantic similarity. On the other hand, D-LADAN presents a novel momentum-updated memory mechanism to dynamically sense the posterior similarity between law articles (or charges) and a weighted GDO to adaptively capture the distinctions for revising the inductive bias caused by the data imbalance problem. We perform extensive experiments to demonstrate that D-LADAN significantly outperforms state-of-the-art methods in accuracy and robustness.", "sections": [{"title": "1 INTRODUCTION", "content": "The application of artificial intelligence models to assist with legal judgment has become popular in recent years. Legal judgment prediction (LJP) aims to predict a case's judgment results, such as applicable law articles, charges, and terms of penalty, based on its fact description, as illustrated in Table 1. Such a technique can not only assist judiciary workers in processing cases but also offer legal consultancy services to the public. Previous literature typically formulates the LJP as a joint task with three text classification subtasks: applicable law article prediction, charge prediction, and the term of penalty prediction. Multifarious methods have been proposed and got some successes, from the early rule-based methods [19, 20] to the recent neural-based models [5, 6, 9, 21, 35, 45].\nA main drawback of existing methods is that they fail to solve the issue of confusing law articles (or charges). This issue describes the situation where similar cases tend to be misjudged against each other due to the high similarity of their corresponding law articles (or charges). For example, in Fig. 1, Article 385 and Article 163 all describe offenses of accepting bribes, and their subtle differences are whether the guilty parties are state staff. From this perspective, the key challenge to solving the confusing charges issue is to capture essential but rare features for distinguishing confusing law articles.\nTo distinguish confusing charges to solve this issue, Hu et al. [9] define ten discriminative at- tributes, and Lyu et al. [22] propose four types of criminal elements. However, the heavy dependence on expert knowledge of the definition and labeling makes applying these two methods to different civil law systems hard. Inspired by the fact that Luo et al. [21] use the attention vector of law"}, {"title": "2 RELATED WORK", "content": "Our work solves the problem of the confusing charge in the LJP task by referring to the calculation principle of the graph neural networks (GNNs). In this section, we will introduce related works from these two aspects."}, {"title": "2.1 Legal Judgment Prediction", "content": "The early works on LJP focus on analyzing existing legal cases in specific scenarios with mathemat- ical and statistical algorithms [10, 13, 15, 24]. Besides, some studies developed machine learning- based methods [19, 20, 26] to solve the problem of LJP, which almost combines some manually designed features with a linear classifier to improve the performance of case classification. The shortcoming is that these methods rely heavily on manual feature engineering and suffer from the generalization problem.\nIn recent years, due to the rapid development of neural networks, researchers have widely used neural networks to solve LJP tasks, mainly divided into two main lines of work. The first line of work focuses on improving the performance by investigating the relationship between the three subtasks, i.e., the relevant law article prediction, charge prediction, and term of penalty prediction. Zhong et al. [45] first model the explicit dependencies among subtasks with scalable directed acyclic graph forms and propose a topological multi-task learning framework for effectively solving these"}, {"title": "2.2 Graph Neural Networks", "content": "Due to their excellent performance in graph structure data, GNNs have attracted significant attention [2, 8, 12] recently. In general, existing GNNs focus on proposing different aggregation schemes to fuse features from the neighborhood of each node in the graph for extracting richer and more comprehensive information. Kipf et al. [12] propose a graph convolution network that uses mean pooling to pool neighborhood information. GraphSAGE [8] concatenates the node's features and applies the mean/max/LSTM operators to aggregate neighborhood information for inductively learning node embeddings. MR-GNN [36] aggregates the multi-resolution features of each node to exploit node information, subgraph information, and global information together. Besides, Message Passing Neural Networks [7] further consider edge information when they are doing the aggregation. However, the aggregation schemes lead to the over-squashing and over- smoothing issues of GNNs [17, 28, 43], i.e., the aggregated node representations would become indistinguishable, which is entirely contrary to our goal of extracting distinguishable information. Therefore, we propose our graph distillation operation based on a distillation strategy instead of aggregation schemes to capture the distinguishable features between similar law articles."}, {"title": "3 PROBLEM FORMULATION", "content": "In this section, we introduce some notations and terminologies. Then we formulate the LJP task. To facilitate understanding of the subsequent method introductions, we summarize the main notations in Table 2.\nLaw Cases. Each law case consists of a fact description and several judgment results (cf. Table. 1). The fact description is represented as a text document, denoted by $f$. The judgment results include applicable law articles, charges, terms of penalty, whose label sets are denoted by $Y_l$, $Y_c$, and $Y_t$ respectively. We use $|Y|$ to represent the number of labels for the corresponding judgment result. Thus, a law case can be represented by a tuple $(f, y_l, y_c, y_t)$.\nLaw Articles. Law cases are often analyzed and adjudicated according to a legislature's statutory law (also known as written law). Formally, we denote the statutory law as a set of law articles $L = {L_1, ..., L_m}$, where $m$ is the number of law articles. Similar to the fact description of cases, we also represent each law article $L_i$ as a document.\nLegal Judgment Prediction. Given a training dataset $D = {(f, y_l, y_c, y_t)_z}^{q}_{z=1}$ of size $q$, we aim to train a model $F(\u00b7)$ that can predict the judgment results for any test law case with a fact description $f_{test}$, i.e., $F(f_{test}, L) = (\\hat{y}_l, \\hat{y}_c, \\hat{y}_t)$, where $\\hat{y}_l$, $\\hat{y}_c$, and $\\hat{y}_t$ represent the predicted relevant law article, charge, and the term of penalty, respectively. Following [38, 45], we assume each case has only one applicable law article and charge."}, {"title": "4 OUR METHOD", "content": ""}, {"title": "4.1 Overview of Framework", "content": "In our framework D-LADAN (cf. Fig. 4), the representation of fact description of a case consists of three parts: a basic representation denoted by $v_f$, a prior distinguishable representation (regard as prior representation) denoted by $v_f^l$, and a revised distinguishable representation (regard as revised representation) denoted by $v_f^r$, i.e., $v_f' = [v_f \\oplus v_f^l \\oplus v_f^r]$, where the symbol $\\oplus$ denotes the concatenation operation. The basic representation $v_f$ contains basic semantic information for matching a group of law articles that may apply to the case. In contrast, the prior representation $v_f^l$ considers the semantic similarity relation between the prior definitions of law articles and captures features that can effectively distinguish confusing law articles. In addition, to overcome the imbalance problem, the revised representation $v_f^r$ dynamically senses the similarity relation of"}, {"title": "4.2 Distilling Law Articles", "content": "As mentioned earlier, a case might be misjudged due to the high similarity of some law articles. To alleviate this problem, we design a law distillation module (cf. Fig. 5) to extract distinguishable and representative information from the prior definition of all law articles. Specifically, it first uses a graph construction layer (GCL) to divide law articles into different communities. Then, we apply the graph distillation layer to learn the discriminative representation of each law article community, called the prior distinction vector in the remainder of this paper."}, {"title": "4.2.1 Graph Construction Layer", "content": "To find probably confusing law articles, we first construct a fully-connected graph $G^\u2217$ for all law articles $L$, where the weight on the edge between a pair of law articles $L_i, L_j \\in L$ is defined as the cosine similarity between the two articles\u2019 TF-IDF (Term Frequency-Inverse Document Frequency) representations $tf\\_idf_i$ and $tf\\_idf_j$. Since confusing law articles are usually semantically similar and there exists sufficient information to distinguish dissimilar law articles, we remove the edges with weights less than a predefined threshold $\u03b8$ from graph $G^\u2217$. By setting an appropriate threshold $\u03b8$, we obtain a new graph $G = {g_i}_{i=1}^k$ composed of several disconnected subgraphs $g_1, ..., g_k$ (or, communities), where each $g_i, i = 1, ..., k$ contains a community of probably confusing articles. Our later experimental results demonstrate that this easy-to-implement method effectively improves the performance of D-LADAN."}, {"title": "4.2.2 Graph Distillation Layer", "content": "To extract distinguishable information from each community $g_i$, a straightforward way is to delete duplicate words and sentences presented in law articles within the community (as described in Sec. 1). In addition to introducing significant errors, this simple method cannot be plugged into end-to-end neural architectures due to its non-differentiability. To overcome the above issues, inspired by the popular graph convolution operator (GCO) [8, 12, 30],"}, {"title": "4.3 Distilling Revised Memories", "content": "The imbalance problem may cause the model\u2019s biased understanding of the similarity relation between law articles. To solve this issue, we design the revised memory mechanism to dynamically sense the semantic similarity relationship between law articles that the model learned. Then, we propose a memory distillation module to learn the revised distinguishable representation (hereinafter called revised distinction vector) for each memory, relying on the fully-connected similarity graph and the weighted graph distillation layer."}, {"title": "4.3.1 Revised Memory", "content": "To sense the semantic similarity relation of law articles that the model learned, we define a memory mechanism where each \u201cmemory\u201d is associated with the corresponding law article, which is denoted as $M = {m_{L_1}, ..., m_{L_m}}$, where $m_{L_i} \\in \\mathbb{R}^{d_s}$ and $M \\in \\mathbb{R}^{m \\times d_s}$."}, {"title": "4.3.2 Fully-connected Similarity Graph", "content": "As memory is proposed to evaluate the posterior similarity between law articles, the similarity metric needs to be consistent with the metric function of the corresponding classifier. Here we show the cosine distance-based formula (refer to Eq. 4):\n$a_{L_i, L_j} = cos(m_{L_i}, m_{L_j}) = \\frac{m_{L_i} \u00b7 m_{L_j}}{||m_{L_i}|| ||m_{L_j}||}$  (1)\nAfter computing the scores of each memory pair, we get a fully-connected graph denoted by $G_M = {M, A_M}$, where the nodes represent the revised memories $m_{L_i} \\in M$ and edges have the weights $a_{L_i,L_j} \\in A_m$. The basic encoder and prior encoder enable the model the basic ability to distinguish confusion, and the revised encoder is used to sense the model\u2019s lack of detail in distinguishing confusion and to correct it. Therefore, we need to maintain all the details on the fully-connected graph of revised memory instead of using grouping and other methods to prune it (refer to Sec. 4.2.1)."}, {"title": "4.3.3 Weighted Graph Distillation Layer", "content": "As the edge weights of the fully-connected graph reflect the similarity between law articles that the model learned, we use the weighted version GDO to utilize the edge weights and compute the revised distinction vector for each memory, inspired by the graph attention network [31]. The computation formula is\n$\n\\begin{aligned}\n\\alpha_{L_i, L_j} &= \\frac{\\exp (a_{L_i,L_j})}{\\sum_{L_j \\in L \\backslash \\{L_i\\}} \\exp (a_{L_i,L_j})}, \\\\\nm^{(l+1)}_{M}(m^{(l)}_{L_i}) &= \\Phi_M^{(l)}(m^{(l)}_{L_i} \\oplus  \\sum_{L_j \\in L \\backslash \\{L_i\\}} \\alpha_{L_i, L_j}  \\Psi_M^{(l)}(m^{(l)}_{L_i} \\oplus m^{(l)}_{L_j})) + b). \n\\end{aligned}\n$\nwhere $\\alpha_{L_i,L_j}$ is the normalized weight and $\\Phi_M^{(l)} \\in \\mathbb{R}^{d_{l+1} \\times d_l}$, $\\Psi_M^{(l)} \\in \\mathbb{R}^{d_{l+1} \\times 2d_l}$ are the trainable self- weighted matrix and the neighbor similarity extracting matrix for the memory distillation module, respectively. As the revised distinction vectors require a finer granularity to revise the biased understanding of the similarity between law articles caused by $v_f$, $v_f^l$ and $v_f^r$ we discard the setting of community and directly use the memory representation after $H$ layers as the final revised distinction vectors, i.e., $y_i = m_{L_i}^{(H)}$. Referring to the setting of existing memory networks [14, 41], we set the key vector $k_i$ of each revised distinction vector $y_i$ for querying. As the revised memories themselves have strong semantic characteristics, in D-LADAN, we simply set them as the key vectors, i.e., $k_i = m_{L_i} = m_{L_i}^{(0)}$.\nBesides, it is worth noting that the revised memory mechanism is only related to the similarity relation between labels (i.e., law articles) that the model learned. Therefore, it is suitable for extending this mechanism to other sub-tasks (e.g., charge prediction and term of penalty prediction)."}, {"title": "4.4 Re-encoding Fact with Distinguishable Attention", "content": "In D-LADAN, the distinction vectors {pi} and {y}, are computed to capture the corresponding distinguishable features from fact descriptions. Specifically, we first generate the most relevant distinction context vectors, $\\beta$ and $\\hat{\\gamma}$, based on the semantic correlation between the input fact description and the distinction vectors. Then, two similar re-encoders are used to generate the distinguishable representations of the input fact description relying on the $\\beta$ and $\\hat{\\gamma}$, respectively."}, {"title": "4.4.1 Distinguishable Context Generation", "content": "To capture a law case's prior distinguishable features from its fact description $f$, we define the following nonlinear function to compute the semantic correlation between it and all communities $g_i$ in the graph $G$:\n$\\mathbb{X} = \\text{softmax}(W_g v_f + b_g)$, (2)\nwhere $v_f$ is the basic representation of fact description $f$, $W_g \\in \\mathbb{R}^{k \\times d_s}$ and $b_g \\in \\mathbb{R}^k$ are the trainable weight matrix and bias respectively. Each element $\\mathbb{X}_i \\in \\mathbb{X}, i = 1, ..., k$ reflects the closeness between fact description $f$ and law articles community $g_i$. The most relevant distinction vector $\\beta$ is computed as the weighted sum of all prior distinction vectors, that is:\n$\\beta = \\sum_{i=1}^k \\mathbb{X}_i \\beta_i$\nAs for the revised distinguishable features, we use the following metric-based matching function to compute the semantic relativity between the input fact description and revised memories:\n$S_i = \\text{cos}(W_k(v_f \\oplus v_f^r), k_i)$,  (3)\nwhere $W_g \\in \\mathbb{R}^{d_s \\times 2 d_s}$ is the trainable weight matrix that maps fact representations into the same vector space as key vectors. The most relevant revised distinction vector $\\hat{\\gamma}$ is computed by the same softmax function and weighted sum function with that prior distinction vectors $\\beta$ used, i.e., $\\mathbb{\\hat{S}} = \\text{softmax}([S_1, ..., S_m])$ and $\\hat{\\gamma} = \\sum_{i = 1,...,m} \\mathbb{\\hat{S}}_i \\gamma_i$. Then, the generated distinction vectors $\\beta$ and $\\hat{\\gamma}$ are input into the subsequent re-encoder for attentively extracting distinguishable features from fact description $f$."}, {"title": "4.4.2 Fact Re-encoder", "content": "Inspired by [39], we attentively extract distinguishable features based on word-level and sentence-level Bi-directional Gated Recurrent Units (Bi-GRUs). Since the calculation process is completely consistent, we only show the generation process of the prior representation $v_f^l$. Specifically, for each input sentence $S_i = [w_{i,1},..., w_{i,n_i}]$ in the fact description $f$, word-level Bi-GRUs will output a hidden state sequence, that is,\n$h_{i,j} = [\\overrightarrow{GRU}(w_{i,j}), \\overleftarrow{GRU}(w_{i,j})], j = 1, ..., n_i,$\nwhere $w_{i,j}$ represents the word embedding of word $w_{i,j}$ and $h_{i,j} \\in \\mathbb{R}^{d_w}$. Based on this hidden state sequence and the prior distinction vector $\\beta$, we calculate an attentive vector $[\\alpha_{i,1}, ..., \\alpha_{i,n_i}]$, where each $\\alpha_{i,j}$ evaluates the discrimination ability of the corresponding word $w_{i,j} \\in S_i$. $\\alpha_{i,j}$ is formally computed as:\n$\\alpha_{i,j} = \\frac{\\exp(\\text{tanh}(W_w h_{i,j})^T (W_{gw} \\beta))}{\\sum_l \\exp(\\text{tanh}(W_w h_{i,l})^T (W_{gw} \\beta))},$"}, {"title": "4.5 Prediction", "content": "Based on $v_f'$, we use the multi-task decoder to generate a corresponding feature vector $v_i'$ for each sub-task $i \\in \\{l, c, t\\}$, as mentioned in Sec. 3, i.e., $l$: law article prediction; $c$: charge prediction; $t$: term of penalty prediction. To obtain the prediction for each sub-task, we choose the metric-based classifier. Here we show the formula based on cosine distance consistent with the fully-connected graph computation in Sec. 4.3:\n$\\hat{y}_i = \\text{softmax}(\\tau_i \\frac{(v_i^l)^T W_i}{||v_i^l|| \u00b7 ||W_i||}), \\quad i \\in \\{l, c, t\\}$  (4)\nwhere $W \\in \\mathbb{R}^{d_s \\times |Y_i|}$ and $\u03c4_i$ are parameters specific to the corresponding sub-task and note the $\u03c4_i$ is a trainable scalar value."}, {"title": "4.6 Training", "content": "Loss Function. For training, we compute the cross-entropy loss function for each sub-task and take the loss sum of all sub-tasks as the overall prediction loss:\n$L_p = - \\sum_{i} \\sum_{j=1}^{|Y_i|} Y_{ij} \\text{log}(y_{i,j}), i \\in \\{l,c,t\\},$\nwhere $|Y_i|$ denotes the number of different classes (or, labels) for the corresponding sub-task and $[Y_{i,1}, Y_{i,2}, \u00b7\u00b7\u00b7 , Y_{i,|Y_i|}]$ refers to the one-hot ground-truth labels vector. Besides, we also consider the"}, {"title": "4.7 The Upgraded Version: D-LADAN meets Transformers", "content": "From pre-trained models (PLMs) [4, 18, 33] to large language models (LLMs) [1, 3], Transformer- based architectures have enabled significant advances in the field of NLP and demonstrated their effectiveness in capturing context. To further demonstrate the effectiveness of our proposed method, we propose an upgraded version of D-LADAN based on transformer-based architecture. In this section, we use the BERT as an example to show how D-LADAN can be improved, which is denoted as D-LADANBERT.\nSince PLMs have great advantages over the RNN models in long-distance text perception and context modeling, D-LADANBERT discards the hierarchical design and models the case from the token level directly. Thus, fact description is treated as a sequence of tokens, i.e., $f = [t_1, ..., t_{ns}]$, where $ns$ is the sequence length. Taking the fact description as an input, D-LADANBERT first uses the BERT model to get the hidden representation of each token, i.e.,\n$[t_1, ..., t_{ns}] = \\text{BERT}([t_1, ..., t_{ns}])$,\nwhere $t_i \\in \\mathbb{R}^{d_{BERT}}$ denotes the token representation of the token $t_i$ and $d_{BERT}$ is the output dimension of BERT."}, {"title": "5 EXPERIMENTS", "content": "In this section, we introduce the setting of experiments and report the results with specific analyses."}, {"title": "5.1 Datasets", "content": "To verify the effectiveness of our method, we conduct experiments on two typical datasets: 1) the Chinese AI and Law challenge (CAIL2018) dataset [34] and 2) the Criminal dataset [9]. The statistics of these two datasets are shown in Table 3, and the detailed introduction is as follows:\n\u2022 CAIL20182 [34]: to evaluate the performance of our method, we use the two publicly available sub-datasets of the CAIL2018 dataset: CAIL-small (the exercise stage dataset) and CAIL-big (the first stage dataset). The case samples in both datasets contain fact descriptions, applicable law articles, charges, and the term of penalty. As for data processing, we first filter out samples with fewer than ten meaningful words. To be consistent with state-of-the-art methods, we filter out the case samples with multiple applicable law articles and multiple charges. Meanwhile, referring to [45], we only keep the law article and the charge that applies to not less than 100 corresponding case samples and divide the terms of penalty into 11 non-overlapping intervals.\n\u2022 Criminal3 [9]: to further prove the ability of D-LADAN to solve the imbalance problem as well as the confusing law article (or charge) problem, we evaluate it on the available datasets from [9], which contains real cases for few-shot charges prediction. The dataset has three subsets of different sizes, denoted as Criminal-S (small), Criminal-M (medium), and Criminal-L (large). These datasets also filtered cases involving multiple defendants and multiple charges."}, {"title": "5.2 Baselines and Settings", "content": "Baselines. We compare D-LADAN with baselines including:\n\u2022 CNN [11]: a CNN-based model with multiple filter window widths for text classification.\n\u2022 HARNN [39]: an RNN-based neural network with a hierarchical attention mechanism for document classification.\n\u2022 FLA [21]: a charge prediction method considering the interaction between fact description and applicable laws. It points out that law articles can help filter out key information related to jurisprudence in a legal case as the judges must cite the applicable law articles to determine the final charges. Thus, FLA first proposes a retrieval method to select the top-k relevant law articles for each case. Then, FLA uses the attention mechanism to capture the legal-related information of legal cases based on the context vectors of selected law articles. Finally, the extracted vector representation is employed to predict the charges.\n\u2022 Few-Shot [9]: a deep neural network-based model aims to solve both problems of the few- shot charges and the confusing charges. It manually annotates ten distinguishable attributes of charges to enhance the relation between fact description and charges. In practice, it constructs the attribute prediction sub-task and proposes the attribute-aware attention mechanism to enhance the charge-related semantic information of fact descriptions.\n\u2022 TOPJUDGE [45]: a topological multi-task learning framework that considers the relationship between three sub-tasks in LJP. This model formalizes the explicit dependencies over sub- tasks in a directed acyclic graph, following the judge's judgment norms under the statutory system, in which the judge first evaluates the possible violation of the law, then determines the crime, and finally judges the punishment according to the law.\n\u2022 MPBFN-WCA [38]: another multi-task learning framework for LJP task. Compared with the TOPJUDGE [45], its innovation lies in the backward verification framework besides the typical forward dependency, which is inspired by the assumption that after making a decision, judges should analyze and confirm whether the charges and penalty conditions are following the provisions of the law articles.\n\u2022 LADAN [35]: the proposed method of our conference version, which only considers the prior relationships between law articles and uses the GDO to determine the differences between similar law articles. In other words, such a model only combines the basic representation and the prior representation as the final representation of the fact description, i.e., $v_f' = [v_f \\oplus v_f^l]$.\n\u2022 GFDN [44]: a modified method of the LADAN model which transforms the fact description to a graph structure from a sequence, and then uses the graph convolutional network as the basic encoder to get a better representation."}, {"title": "5.3 Basic Performance Evaluation", "content": "To compare the performance of the baselines and our methods, we choose four metrics widely used for multi-classification tasks, including accuracy (Acc.), macro-precision (MP), macro-recall (MR), and macro-F1 (F1). Since the confusing law article (or charges) issue often occurs between a few categories and both CAIL and Criminal datasets are quite imbalanced, we mainly evaluate all methods with the F1 score, which more objectively reflects the effectiveness of our D-LADAN and other baselines. Table 4, 5, and 6 shows the experimental results on CAIL-small, CAIL-big, and Criminal datasets, respectively. Our D-LADAN performs the best in terms of all evaluation metrics. Compared with the state-of-the-art R-former model, our D-LADAN improved the F1-scores of law article prediction, charge prediction, and the term of penalty prediction on dataset CAIL-small by 0.87%, 0.51%, and 1.20% respectively, and about 0.76%, 0.31%, and 3.01% on dataset CAIL-big. For the"}, {"title": "5.4 Study of Data Imbalance", "content": "To verify the advance of our model in dealing with the imbalance problems, we have constructed a rich variety of experiments, including:\n(1) In view of the phenomenon shown in Fig. 3, to verify that our D-LADAN can effectively improve the performance of tail categories, we investigate D-LADAN's performance under this circumstance from the perspective of instances. Referring to the setup of CL4LJP [42], we test D-LADAN on the cases of tail law articles and charges, which contain fewer than 200 cases in the CAIL-small dataset. As for the term of penalty, we do not test on this sub-task due to its relatively balanced distribution of class labels, i.e., each class has more than 200 samples. As shown in Fig. 7, although all models perform worse on the tail classes of the CAIL-small dataset than in all categories, D-LADAN improves performance more on the tail classes over the other three baselines, especially on the F1-score metric. This experimental result proves that the improvement of D-LADAN for the tail categories is significant. Notice that LADAN's tail performance is lower than the baselines, i.e., Neurjudge and CL4LJP, we can assert that the significant improvement in tail categories comes from our proposed revised memory mechanism for D-LADAN. By dynamically sensing the posterior semantic similarity relationships between law articles (and charges), D-LADAN can learn how to adaptively revise the inductive bias caused by the data imbalance problem.\n(2) To further verify that our method effectively solves the data imbalance problem, we also construct a comparative experiment from the perspective of categories. Following the experi- mental setup of [9], we restrict the situation to the charge prediction task to avoid interference from a multi-task framework and evaluate the performance of D-LADAN on charges with different frequencies. Table 7 shows the results, where improvement with underline is rela- tive to Few-shot. We see that D-LADAN improves the prediction accuracy of low-frequency (i.e., few-shot) charges most significantly, up to 9.33%, and outperforms all baselines in all evaluation indexes. This result demonstrates the effectiveness of D-LADAN in solving the data imbalance problem.\n(3) To prove the remarkable contribution of the momentum-updated revised memory mechanism in solving the imbalance problem, we follow the principle of controlling variables and make a"}, {"title": "5.5 Ablation Experiments", "content": "To further illustrate the significance of considering the difference between law articles, we conducted ablation experiments on model D-LADAN+MTL with dataset CAIL-small. The ablation variations include:\n\u2022 -no RM: To show the importance of our revised memory mechanism (RM), we build a variation model without the RM, i.e., use only the $v_f' = [v_f \\oplus v_f^l]$ to predict all results.\n\u2022 -no GCL: To evaluate the effectiveness of our graph construction layer (GCL), we build a D-LADAN model with the GCL\u2019s removing threshold $\u03b8 = 0$, i.e., directly applies the GDO on the fully-connected graph $G^\u2217$ to generate a global distinction vector $\u03b2$ for re-encoding the fact description."}, {"title": "5.6 Case Study", "content": "To intuitively verify that D-LADAN effectively extracts distinguishable features, we visualize the attention mechanism of D-LADAN's encoders. Fig. 9 shows two law case examples that correspond to Article 385 and Article 163 respectively, where the darker the word is, the higher the attention score it gets in the corresponding encoder, i.e., its information is more important to the corresponding encoder. For the basic encoder, we see that the vital information in these two cases is very similar, in which both contain the word like \u201cuse position\u201d, \u201caccept benefit\u201d, \u201caccept ... cash\u201d, etc. Therefore, when using just the representation of the basic encoder to predict acceptable law articles, charges, and terms of penalty, these two cases tend to be misjudged. As we mentioned in Section 4.4, with the prior distinction vector, our prior encoder focuses on extracting distinguishable features like defendants' identity information (e.g., \u201ccompany manager\u201d and \u201cworking in the Cadastral Unit of Luocheng Branch of Luohe City Land and Resources Bureau\u201d in our examples), which partly distinguish the applicable law articles and charges of these two cases. In addition, we notice that the revised encoder focuses on the valuable information more purely, where the words with light color"}, {"title": "5.7 Robustness of Different Backbones", "content": "As the framework of D-LADAN is backbone-independent, it is easy for it to transfer across different backbone models. In this section, we take an experiment to demonstrate that the D-LADAN framework can deliver improvements on different backbone models. We choose three different backbone models, in addition to the HARNN and BERT used in the previous experiments, we also compare another:\n\u2022 Lawformer [33]: a PLM model with the RoBERTa structure, which is obtained by fine-tuning on Chinese legal long documents using roberta-wm-ext [4] checkpoint.\nSince Lawformer can accept longer input lengths, we set the maximum document length as 1,024 for it.\nAs shown in Table 9, our D-LADAN framework achieves significant improvements on all back- bone models, it further proves the effectiveness of the framework. In addition, we notice that the absolute boost obtained by the DLADAN framework tends to become smaller for more capable back- bone models. This may reflect the fact that more linguistically competent models have themselves mastered some ability to distinguish subtle differences."}, {"title": "5.8 Optimal Weight of Training Loss", "content": "To explore the influence of the prior community selection and revised memory selection, we experiment with groups of different hyper-parameters (\u03bbc, \u03bbm) of loss function on the CAIL-small dataset to find the optimal combination. In this experiment, we use the grid search strategy and set the search range of each hyper-parameter to [0.1, 0.25, 0.5, 0.75, 1.0"}]}