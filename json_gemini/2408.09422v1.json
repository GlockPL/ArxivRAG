{"title": "Distinguish Confusion in Legal Judgment Prediction via Revised Relation Knowledge", "authors": ["Nuo Xu", "Pinghui Wang", "Junzhou Zhao", "Feiyang Sun", "Lin Lan", "Jing Tao", "Li Pan", "Xiaohong Guan"], "abstract": "Legal Judgment Prediction (LJP) aims to automatically predict a law case's judgment results based on the text description of its facts. In practice, the confusing law articles (or charges) problem frequently occurs, reflecting that the law cases applicable to similar articles (or charges) tend to be misjudged. Although some recent works based on prior knowledge solve this issue well, they ignore that confusion also occurs between law articles with a high posterior semantic similarity due to the data imbalance problem instead of only between the prior highly similar ones, which is this work's further finding. This paper proposes an end-to-end model named D-LADAN to solve the above challenges. On the one hand, D-LADAN constructs a graph among law articles based on their text definition and proposes a graph distillation operation (GDO) to distinguish the ones with a high prior semantic similarity. On the other hand, D-LADAN presents a novel momentum-updated memory mechanism to dynamically sense the posterior similarity between law articles (or charges) and a weighted GDO to adaptively capture the distinctions for revising the inductive bias caused by the data imbalance problem. We perform extensive experiments to demonstrate that D-LADAN significantly outperforms state-of-the-art methods in accuracy and robustness.", "sections": [{"title": "1 INTRODUCTION", "content": "The application of artificial intelligence models to assist with legal judgment has become popular in recent years. Legal judgment prediction (LJP) aims to predict a case's judgment results, such as applicable law articles, charges, and terms of penalty, based on its fact description, as illustrated in Table 1. Such a technique can not only assist judiciary workers in processing cases but also offer legal consultancy services to the public. Previous literature typically formulates the LJP as a joint task with three text classification subtasks: applicable law article prediction, charge prediction, and the term of penalty prediction. Multifarious methods have been proposed and got some successes, from the early rule-based methods [19, 20] to the recent neural-based models [5, 6, 9, 21, 35, 45].\nA main drawback of existing methods is that they fail to solve the issue of confusing law articles (or charges). This issue describes the situation where similar cases tend to be misjudged against each other due to the high similarity of their corresponding law articles (or charges). For example, in Fig. 1, Article 385 and Article 163 all describe offenses of accepting bribes, and their subtle differences are whether the guilty parties are state staff. From this perspective, the key challenge to solving the confusing charges issue is to capture essential but rare features for distinguishing confusing law articles.\nTo distinguish confusing charges to solve this issue, Hu et al. [9] define ten discriminative at- tributes, and Lyu et al. [22] propose four types of criminal elements. However, the heavy dependence on expert knowledge of the definition and labeling makes applying these two methods to different civil law systems hard. Inspired by the fact that Luo et al. [21] use the attention vector of law articles to extract the corresponding key feature from fact description, a recent important direction of recent research to solve the confusing law articles (or charges) is to mine valid information from prior knowledge of law articles and charges for extracting distinguishable semantic features from the fact descriptions. Different from the framework of [21](as shown in Fig. 2a), where each law independently attentively extracts features from fact description, recent works generally model the prior relationship between law articles (or charges) to capture the distinguishable features. The most typical of them is our previous version, i.e., LADAN [35], whose framework is in Fig. 2b. LADAN constructs the graph structure of law articles based on the prior word frequency similarity and divides law articles into several communities, in each of which law articles are easy to be confused from the perspective of prior. Then, it proposes a graph distillation operator to learn the differences between confusing law articles and attentively extract the distinguishable features from cases' fact descriptions. The subsequent studies more or less follow this insight to solve the confusing law article (or charge) issue. For example, Dong et al. [5] further model the 'article-charge-penalty' relationship and solve LJP as a node classification task by proposing a graph reasoning network. Zhang et al. [42] then extend these prior relationships to the instance level and present a contrastive learning framework to solve JLP. They consider cases whose applicable law articles or charges with co-ownership as negative samples and achieve state-of-the-art performance.\nAlthough these works have made full use of the prior knowledge of the law and achieved consid- erable results, Zhang et al. [42] still state that existing methods are not ideal for the improvement of the tail category. As evidence, Fig. 3 shows the LADAN's accuracy on different frequency law articles and charges. We see that the LJP task is under a data imbalance distribution, and the performance of LADAN decreases with the decrease in frequency. We argue that the inductive bias caused by the data imbalance problem destroys the pre-established relationship structure based on prior knowledge and causes posterior confusing law articles (or charges). The data imbalance problem reflects a phenomenon that the many-shot knowledge (or elements) covers the few-shot one during the learning process. For ease of understanding, we take the following example that combines Fig. 1 and 2b."}, {"title": "PROBLEM FORMULATION", "content": "In this section, we introduce some notations and terminologies. Then we formulate the LJP task. To facilitate understanding of the subsequent method introductions, we summarize the main notations in Table 2.\nLaw Cases. Each law case consists of a fact description and several judgment results (cf. Table. 1). The fact description is represented as a text document, denoted by f. The judgment results include applicable law articles, charges, terms of penalty, whose label sets are denoted by $\\mathcal{Y}_l$, $\\mathcal{Y}_c$, and $\\mathcal{Y}_t$ respectively. We use $|\\mathcal{Y}_i|$ to represent the number of labels for the corresponding judgment result. Thus, a law case can be represented by a tuple $(f, \\mathcal{Y}_l, \\mathcal{Y}_c, \\mathcal{Y}_t)$.\nLaw Articles. Law cases are often analyzed and adjudicated according to a legislature's statutory law (also known as written law). Formally, we denote the statutory law as a set of law articles $\\mathcal{L} = {L_1, ..., L_m}$, where m is the number of law articles. Similar to the fact description of cases, we also represent each law article $L_i$ as a document.\nLegal Judgment Prediction. Given a training dataset $D = {(f, \\mathcal{Y}_l, \\mathcal{Y}_c, \\mathcal{Y}_t)_z}_{z=1}^q$ of size q, we aim to train a model $F(\\cdot)$ that can predict the judgment results for any test law case with a fact description $f_{test}$, i.e., $F(f_{test}, \\mathcal{L}) = (\\hat{\\mathcal{Y}}_l, \\hat{\\mathcal{Y}}_c, \\hat{\\mathcal{Y}}_t)$, where $\\hat{\\mathcal{Y}}_l$, $\\hat{\\mathcal{Y}}_c$, and $\\hat{\\mathcal{Y}}_t$ represent the predicted relevant law article, charge, and the term of penalty, respectively. Following [38, 45], we assume each case has only one applicable law article and charge."}, {"title": "4 OUR METHOD", "content": "In our framework D-LADAN (cf. Fig. 4), the representation of fact description of a case consists of three parts: a basic representation denoted by $v_f$, a prior distinguishable representation (regard as prior representation) denoted by $v_f^p$, and a revised distinguishable representation (regard as revised representation) denoted by $v_f^r$, i.e., $v_{f'} = [v_f \\oplus v_f^p \\oplus v_f^r]$, where the symbol $\\oplus$ denotes the concatenation operation. The basic representation $v_f$ contains basic semantic information for matching a group of law articles that may apply to the case. In contrast, the prior representation $v_f^p$ considers the semantic similarity relation between the prior definitions of law articles and captures features that can effectively distinguish confusing law articles. In addition, to overcome the imbalance problem, the revised representation $v_f^r$ dynamically senses the similarity relation of law articles learned by the model and adaptively mines the differences that further enhance the distinguishability of the vector representation of the description. To more graphically illustrate how our D-LADAN solves the confusing problems mentioned above, we refer to Table 1 and Fig. 1 and provide a practical example of what we expect D-LADAN to do, as follows,\nExample 4.1. When getting the case's fact description of Table 1 as input, D-LADAN encodes the full text equally into the basic representation $v_f$. Then, D-LADAN notices that Article 385 and 163 are highly similar, it uses the law distillation module to capture the difference between these two articles, i.e., the word \"Any state staffs\" and \"The employees of companies, enterprises or other units\". D-LADAN's prior encoder further uses such distinguishable keywords to focus attention on capturing the corresponding information from the fact description (i.e., \"his service as a company manager\" words in Table 1) to get the prior representation $v_f^p$. During the model training, if D-LADAN finds that the representations of two law articles gradually become similar due to data imbalance (e.g., Article 163 and 164), it uses the memory distillation module to capture the difference (e.g, the words \"accept\" and \"give\") between laws with a posterior high similarity. D-LADAN's revised encoder uses the posterior differences to focus attention on capturing the distinguishable information (i.e., \"he illegally accepted the benefit fee of 40,000 yuan\" words in Table 1) to get the revised representation $v_f^r$. Combining these three representations, D-LADAN can solve the confusing problem in the LJP task well.\nAs we mentioned, it is easy to distinguish dissimilar law articles as sufficient distinctions exist, and the difficulty in solving confusing charges lies in extracting distinguishable features of similar law articles. To obtain the basic representation $v_f$, we choose a popular document encoding method (e.g., CNN encoder [11] or Bi-RNN encoder [39]). To learn the prior representation $v_f^p$, we use the law distillation module first to divide law articles into several communities to ensure that the law articles of each community are highly similar, and then extract each community i's prior distinction vector (or prior distinguishable features) $\\beta_i$ from the basic representations of law articles in the community i. Given the case's fact description, based on all communities' distinction vectors, we generate the most relevant one (i.e., $\\beta$ in Fig. 4) for attentively extracting the prior distinguishable features $v_f^p$ in the subsequent fact re-encode module (i.e., the prior encoder in Fig. 4). To generate the revised representation $v_{f'}$, we propose a revised memory mechanism with the memory distillation module, which considers the fully-connected similarity graph of memories and computes the revised distinction vector $\\gamma_i$ for each memory $m_i$. Then, we generate the most relevant one (i.e., $\\hat{\\gamma}$ in Fig. 4) for each case's fact description to capture the revised distinguishable feature by the similar fact re-encode module (i.e., the revised encoder in Fig. 4). In addition, in the training processing, we momentum update the revised memories with the parameters of the law article classifier after each training step to sense the semantic similarity relation between law articles that the model learned. In the following, we will elaborate on the law distillation module (Sec. 4.2), the memory distillation module (Sec. 4.3), and the fact re-encode module, i.e., the prior encoder and the revised encoder in Fig. 4(Sec. 4.4)."}, {"title": "4.2 Distilling Law Articles", "content": "As mentioned earlier, a case might be misjudged due to the high similarity of some law articles. To alleviate this problem, we design a law distillation module (cf. Fig. 5) to extract distinguishable and representative information from the prior definition of all law articles. Specifically, it first uses a graph construction layer (GCL) to divide law articles into different communities. Then, we apply the graph distillation layer to learn the discriminative representation of each law article community, called the prior distinction vector in the remainder of this paper.\nTo find probably confusing law articles, we first construct a fully-connected graph $G^*$ for all law articles $\\mathcal{L}$, where the weight on the edge between a pair of law articles $L_i, L_j \\in \\mathcal{L}$ is defined as the cosine similarity between the two articles' TF-IDF (Term Frequency-Inverse Document Frequency) representations $tf\\_idf_i$ and $tf\\_idf_j$. Since confusing law articles are usually semantically similar and there exists sufficient information to distinguish dissimilar law articles, we remove the edges with weights less than a predefined threshold $\\theta$ from graph $G^*$. By setting an appropriate threshold $\\theta$, we obtain a new graph $\\mathcal{G} = {g_i}_{i=1}^k$ composed of several disconnected subgraphs $g_1, ..., g_k$ (or, communities), where each $g_i, i = 1, ..., k$ contains a community of probably confusing articles. Our later experimental results demonstrate that this easy-to-implement method effectively improves the performance of D-LADAN.\nTo extract distinguishable information from each community $g_i$, a straightforward way is to delete duplicate words and sentences presented in law articles within the community (as described in Sec. 1). In addition to introducing significant errors, this simple method cannot be plugged into end-to-end neural architectures due to its non-differentiability. To overcome the above issues, inspired by the popular graph convolution operator (GCO) [8, 12, 30], we propose a graph distillation operator (GDO) for effectively extracting distinguishable features. In contrast to the GCO that computes the message propagation between neighbors and aggregates these messages to enrich representations of nodes in the graph, the basic idea behind our GDO is to learn efficient information with distinction by removing similar features between nodes.\nSpecifically, for an arbitrary law article $L_i$, GDO uses a trainable weight matrix $\\Psi$ to capture similar information between it and its neighbors in the graph $\\mathcal{G}$, and a matrix $\\Phi$ to extract effective semantic features of $L_i$. At each layer $l \\geq 0$, the aggregation of similar information between $L_i$ and its neighbors is removed from its representation, that is,\n$v_{L_i}^{(l+1)} = \\sigma(\\Phi^{(l)}(v_{L_i}^{(l)} \\oplus (\\sum_{L_j\\in N_i} \\Psi_{L_i,L_j}^{(l)} v_{L_j}^{(l)} ) + b^{(l)}))$,\nwhere $v_{L_i}^{(l)} \\in \\mathbb{R}^{d_l}$ refers to the representation of law $L_i$ in the $l$-th graph distillation layer, $N_i$ refers to the neighbor set of $L_i$ in graph $\\mathcal{G}$, $b^{(l)}$ is the bias, and $\\Phi^{(l)} \\in \\mathbb{R}^{d_{l+1}\\times d_l}$ and $\\Psi^{(l)} \\in \\mathbb{R}^{d_{l+1}\\times 2d_l}$ are the trainable self-weighted matrix and the neighbor similarity extracting matrix for the law distillation module respectively. Note that $d_l$ is the dimension of the feature vector in the l-th graph distillation layer. We set $d_0 = d_s$, where $d_s$ is the dimension of basic representations $v_f$ and $v_{Li}$. Similar to GCO, our GDO also supports multi-layer stacking.\nUsing GDO with $H$ layers, we output law article representation of the last layer, i.e., $v_{L_i}^{(H)} \\in \\mathbb{R}^{d_H}$, which contains rich distinguishable features that can distinguish law article $L_i$ from the articles within the same community. To further improve law articles' distinguishable features, for each subgraph $g_i, i = 1, 2, ..., k$ in graph $\\mathcal{G}$, we compute its prior distinction vector $\\beta_i$ by using pooling operators to aggregate the distinguishable features of articles in $g_i$. Formally, $\\beta_i$ is computed as:\n$\\beta_i = [MaP({v_{L_j}^{(H)}})_{L_j \\in g_i}), MiP({v_{L_j}^{(H)}})_{L_j \\in g_i})]$,\nwhere $MaP(\\cdot)$ and $MiP(\\cdot)$ are the element-wise max pooling and element-wise min pooling operators respectively."}, {"title": "4.3 Distilling Revised Memories", "content": "The imbalance problem may cause the model's biased understanding of the similarity relation between law articles. To solve this issue, we design the revised memory mechanism to dynamically sense the semantic similarity relationship between law articles that the model learned. Then, we propose a memory distillation module to learn the revised distinguishable representation (hereinafter called revised distinction vector) for each memory, relying on the fully-connected similarity graph and the weighted graph distillation layer.\nTo sense the semantic similarity relation of law articles that the model learned, we define a memory mechanism where each \u201cmemory\u201d is associated with the corresponding law article, which is denoted as $\\mathcal{M} = {m_{L_1}, ..., m_{L_m}}$, where $m_{L_i} \\in \\mathbb{R}^{d_s}$ and $M \\in \\mathbb{R}^{m\\times d_s}$.\nAs memory is proposed to evaluate the posterior similarity between law articles, the similarity metric needs to be consistent with the metric function of the corresponding classifier. Here we show the cosine distance-based formula (refer to Eq. 4):\n$a_{L_i, L_j} = cos(\\theta(m_{L_i}),\\theta(m_{L_j})) = \\frac{\\theta(m_{L_i}) \\cdot \\theta(m_{L_j})}{||\\theta(m_{L_i})|| \\cdot ||\\theta(m_{L_j})||}$,\nAfter computing the scores of each memory pair, we get a fully-connected graph denoted by $\\mathcal{G}_{\\mathcal{M}} = {\\mathcal{M}, \\mathcal{A}_{\\mathcal{M}}}$, where the nodes represent the revised memories $m_{L_i} \\in \\mathcal{M}$ and edges have the weights $a_{L_i,L_j} \\in A_\\mathcal{M}$. The basic encoder and prior encoder enable the model the basic ability to distinguish confusion, and the revised encoder is used to sense the model's lack of detail in distinguishing confusion and to correct it. Therefore, we need to maintain all the details on the fully-connected graph of revised memory instead of using grouping and other methods to prune it (refer to Sec. 4.2.1).\nAs the edge weights of the fully-connected graph reflect the similarity between law articles that the model learned, we use the weighted version GDO to utilize the edge weights and compute the revised distinction vector for each memory, inspired by the graph attention network [31]. The computation formula is\n$\\alpha_{L_i, L_j} = \\frac{exp(a_{L_i, L_j})}{\\sum_{L_j \\in \\mathcal{L}\\{L_i\\}} exp(a_{L_i, L_j})}$,\n$m_{L_i}^{(l+1)} = \\sigma (\\Phi^{(l)}(m_{L_i}^{(l)} \\oplus (\\sum_{L_j \\in \\mathcal{L}\\{L_i\\}} \\alpha_{L_i, L_j} \\Psi^{(l)} (m_{L_i}^{(l)} \\oplus m_{L_j}^{(l)})) + b^{(l)}) )$,\nwhere $\\alpha_{L_i, L_j}$ is the normalized weight and $\\Psi^{(l)} \\in \\mathbb{R}^{d_{l+1}\\times d_l}$ $\\Phi^{(l)} \\in \\mathbb{R}^{d_{l+1}\\times 2d_l}$ are the trainable self-weighted matrix and the neighbor similarity extracting matrix for the memory distillation module, respectively. As the revised distinction vectors require a finer granularity to revise the biased understanding of the similarity between law articles caused by $v_f$ $v_f^p$ and $v_{f'} ^r$, we discard the setting of community and directly use the memory representation after H layers as the final revised distinction vectors, i.e., $\\gamma_i = m_{L_i}^{(H)}$. Referring to the setting of existing memory networks [14, 41], we set the key vector $k_i$ of each revised distinction vector $\\gamma_i$ for querying. As the revised memories themselves have strong semantic characteristics, in D-LADAN, we simply set them as the key vectors, i.e., $k_i = m_{L_i} = m_{L_i}^{(0)}$.\nBesides, it is worth noting that the revised memory mechanism is only related to the similarity relation between labels (i.e., law articles) that the model learned. Therefore, it is suitable for extending this mechanism to other sub-tasks (e.g., charge prediction and term of penalty prediction)."}, {"title": "4.4 Re-encoding Fact with Distinguishable Attention", "content": "In D-LADAN, the distinction vectors {$\\beta_i$} and {$\\gamma_i$}, are computed to capture the corresponding distinguishable features from fact descriptions. Specifically, we first generate the most relevant distinction context vectors, $\\beta$ and $\\hat{\\gamma}$, based on the semantic correlation between the input fact description and the distinction vectors. Then, two similar re-encoders are used to generate the distinguishable representations of the input fact description relying on the $\\beta$ and $\\hat{\\gamma}$, respectively.\nTo capture a law case's prior distinguishable features from its fact description f, we define the following nonlinear function to compute the semantic correlation between it and all communities $g_i$ in the graph $\\mathcal{G}$:\nX = softmax($W_g v_f + b_g$),\nwhere $v_f$ is the basic representation of fact description f, $W_g \\in \\mathbb{R}^{k\\times d_s}$ and $b_g \\in \\mathbb{R}^{k}$ are the trainable weight matrix and bias respectively. Each element $X_i \\in X, i = 1, ..., k$ reflects the closeness between fact description f and law articles community $g_i$. The most relevant distinction vector $\\beta$ is computed as the weighted sum of all prior distinction vectors, that is:\n$\\beta = \\sum_{i=1}^k X_i \\beta_i$\nAs for the revised distinguishable features, we use the following metric-based matching function to compute the semantic relativity between the input fact description and revised memories:\n$S_i = cos(\\theta(W_k(v_f)), k_i)$,\nwhere $W_g \\in \\mathbb{R}^{d_s\\times 2d_s}$ is the trainable weight matrix that maps fact representations into the same vector space as key vectors. The most relevant revised distinction vector $\\hat{\\gamma}$ is computed by the same softmax function and weighted sum function with that prior distinction vectors $\\beta$ used, i.e., $\\mathcal{S} = softmax([S_1, ..., S_m])$ and $\\hat{\\gamma} = \\sum_{i=1.....m} S_i \\gamma_i$. Then, the generated distinction vectors $\\beta$ and $\\hat{\\gamma}$ are input into the subsequent re-encoder for attentively extracting distinguishable features from fact description f.\nInspired by [39], we attentively extract distinguishable features based on word-level and sentence-level Bi-directional Gated Recurrent Units (Bi-GRUs). Since the calculation process is completely consistent, we only show the generation process of the prior representation $v_f^p$. Specifically, for each input sentence $S_i = [w_{i,1}, ..., w_{i,n_i}]$ in the fact description f, word-level Bi-GRUs will output a hidden state sequence, that is,\n$h_{i,j} = [GRU(\\overrightarrow{w}_{i,j}), GRU(\\overleftarrow{w}_{i,j})], j = 1, ..., n_i$,\nwhere $w_{ij}$ represents the word embedding of word $w_{i,j}$ and $h_{ij} \\in \\mathbb{R}^{d_w}$. Based on this hidden state sequence and the prior distinction vector $\\beta$, we calculate an attentive vector $[\\alpha_{i,1}, ..., \\alpha_{i,n_i}]$, where each $\\alpha_{i,j}$ evaluates the discrimination ability of the corresponding word $w_{i,j} \\in S_i$. $\\alpha_{i,j}$ is formally computed as:\n$\\alpha_{i,j} = \\frac{exp(tanh(W_w h_{i,j})^T (W_{g\\beta}) )}{\\sum_{l} exp(tanh(W_w h_{i,l})^T (W_{g\\beta}) )}$,"}, {"title": "4.5 Prediction", "content": "Based on $v_f^s$, we use the multi-task decoder to generate a corresponding feature vector $v_i^s$ for each sub-task $i \\in {l, c, t}$, as mentioned in Sec. 3, i.e., l: law article prediction; c: charge prediction; t: term of penalty prediction. To obtain the prediction for each sub-task, we choose the metric-based classifier. Here we show the formula based on cosine distance consistent with the fully-connected graph computation in Sec. 4.3:\n$\\hat{y}_i = softmax(\\tau_i \\frac{(v_i^s)^T W_i}{||v_i^s|| \\cdot ||W_i||})$, $i \\in {l, c, t}$\nwhere $W \\in \\mathbb{R}^{d_s\\times |\\mathcal{Y}_i|}$ and $\\tau_i$ are parameters specific to the corresponding sub-task and note the $\\tau_i$ is a trainable scalar value."}, {"title": "4.6 Training", "content": "For training, we compute the cross-entropy loss function for each sub-task and take the loss sum of all sub-tasks as the overall prediction loss:\n$\\mathcal{L}_p = -\\sum_{i} \\sum_{j=1}^{|\\mathcal{Y}_i|} Y_{ij} log(y_{i,j})$, $i \\in {l,c,t}$,\nwhere $|\\mathcal{Y}_i|$ denotes the number of different classes (or, labels) for the corresponding sub-task and $[Y_{i,1}, Y_{i,2}, \u00b7 \u00b7 \u00b7 , Y_{i,|\\mathcal{Y}_i|}]$ refers to the one-hot ground-truth labels vector. Besides, we also consider the loss of law article community selection (i.e., Eq. (2)) and the revised memory selection (i.e., Eq. (3)):\n$\\mathcal{L}_c = -\\lambda_c \\sum_{i=1}^k X_i log(X_i); \\mathcal{L}_m = -\\lambda_m \\sum_{i=1}^m S_i log(S_i)$,\nwhere $[X_1, X_2, . . ., X_k]$ and $[S_1, S_2, . . ., S_m]$ are separately the one-hot ground-truth vectors of the community and the revised memory, where only the element that covers the correctly applicable law article of input legal case is set to 1 and others are 0. In summary, our final overall loss function is as follows:\n$\\mathcal{L} = \\mathcal{L}_p + \\lambda_c \\mathcal{L}_c + \\lambda_m \\mathcal{L}_m$,\nwhere $\\lambda_c$ and $\\lambda_m$ are the weight hyper-parameters.\nAs each row parameter of the metric-based classifier can be approximated as a prototype of the corresponding category [37], we use the parameters of the law article classifier to update the revised memories with a momentum term $\\Lambda$ after each training step. For a given training step t, the update formula is\n$\\mathcal{M}^{(t)} = \\mathcal{M}^{(t-1)} + (1 - \\Lambda) \\mathcal{W}_l^{(t)}$,\nwhere $\\mathcal{W}_l^{(t)}$ denotes the parameters specific to the sub-task of law article prediction. Notice that the classifiers and the revised memories need to choose a consistent metric for the momentum updating (cf., Eqs. (1) and (4)). Besides, as the revised memory mechanism is independent of prior knowledge, it can be configured for each sub-task. In this work, we also configured revised memory $M_c$ for the charge prediction sub-task.\nSince the revised memory needs to roughly represent the similarity relationship between categories learned by the model at least, in the actual training, D-LADAN initializes the revised memory with the parameters of the corresponding classifier after a warm-up training. Assuming that warm-up training steps are $t_w$, then the revised memory is initialized by,\n$\\mathcal{M}^{(0)} = \\mathcal{W}_l^{(t_w)}$\nNote that we freeze the revised representation $v_f^r$ and only use the partial loss (i.e., $\\mathcal{L} = \\mathcal{L}_p + \\lambda_c \\mathcal{L}_c$) for the warm-up training."}, {"title": "4.7 The Upgraded Version: D-LADAN meets Transformers", "content": "From pre-trained models (PLMs) [4, 18, 33] to large language models (LLMs) [1, 3], Transformer-based architectures have enabled significant advances in the field of NLP and demonstrated their effectiveness in capturing context. To further demonstrate the effectiveness of our proposed method, we propose an upgraded version of D-LADAN based on transformer-based architecture. In this section, we use the BERT as an example to show how D-LADAN can be improved, which is denoted as D-LADANBERT.\nSince PLMs have great advantages over the RNN models in long-distance text perception and context modeling, D-LADANBERT discards the hierarchical design and models the case from the token level directly. Thus, fact description is treated as a sequence of tokens, i.e., f = [$t_1, ..., t_{ns}$], where ns is the sequence length. Taking the fact description as an input, D-LADANBERT first uses the BERT model to get the hidden representation of each token, i.e.,\n[$t_1, ..., t_{ns}$] = BERT([$t_1, \u00b7\u00b7\u00b7, t_{ns}$]),\nwhere $t_i \\in R^{d_{BERT}}$ denotes the token representation of the token $t_i$ and $d_{BERT}$ is the output dimension of BERT.\nThen, due to the proven ability of transformer layers to better capture long-range dependencies in language, we replace RNN layers with transformer layers in D-LADANBERT to model the contextual information. The specific calculation formula is as follows,\n[h1,\u00b7\u00b7\u00b7, hng] = Transformer([t1, ..., tns]),\nwhere Transformer(\u00b7) denotes a transformer layer which consists of a 12-head self-attention layer and a feedforward layer and $h_i \\in R^{d_{BERT}}$ is the hidden representation of the token $t_i$.\nTo unify the basic structure of the model, D-LADANBERT uses a self-attention-like context attention layer to aggregate the token hidden representations to the fact representation. We denote the context vector by c*, then the specific formula for the context attention layer is as follows,\nq* = Wqc*; ki = Wkhi; vi = Whhi,\n$A_{*,i} = \\frac{exp(q k_i)}{\\sum_i exp(q k_i)}$\n$v_f^s = \\sum_{i=1}^{n_s} A_{*,i} v_i$\nwhere Wq, Wk and Wa are trainable weight matrices. Following the design of D-LADAN, the corresponding context vector $c_h$ is a trainable vector when computing the base representation $v_f$.\nAs for the prior representation $v_f^p$ and revised representation $v_f^r$, the corresponding context vector are still the distinction vectors, i.e., $c_p = \\beta$ and $c_r = \\hat{\\gamma}$."}, {"title": "5 EXPERIMENTS", "content": "In this section, we introduce the setting of experiments and report the results with specific analyses.\nTo verify the effectiveness of our method, we conduct experiments on two typical datasets: 1) the Chinese AI and Law challenge (CAIL2018) dataset [34] and 2) the Criminal dataset [9]. The statistics of these two datasets are shown in Table 3, and the detailed introduction is as follows:\n\u2022 CAIL20182 [34]: to evaluate the performance of our method, we use the two publicly available sub-datasets of the CAIL2018 dataset: CAIL-small (the exercise stage dataset) and CAIL-big (the first stage dataset). The case samples in both datasets contain fact descriptions, applicable law articles, charges, and the term of penalty. As for data processing, we first filter out samples with fewer than ten meaningful words. To be consistent with state-of-the-art methods, we filter out the case samples with multiple applicable law articles and multiple charges. Meanwhile, referring to [45], we only keep the law article and the charge that applies to not less than 100 corresponding case samples and divide the terms of penalty into 11 non-overlapping intervals.\n\u2022 Criminal\u00b3 [9]: to further prove the ability of D-LADAN to solve the imbalance problem as well as the confusing law article (or charge) problem, we evaluate it on the available datasets from [9], which contains real cases for few-shot charges prediction. The dataset has three subsets of different sizes, denoted as Criminal-S (small), Criminal-M (medium), and Criminal-L (large). These datasets also filtered cases involving multiple defendants and multiple charges."}, {"title": "5.2 Baselines and Settings", "content": "Baselines. We compare D-LADAN with baselines including:\n\u2022 CNN [11", "39": "an RNN-based neural network with a hierarchical attention mechanism for document classification.\n\u2022 FLA [21", "9": "a deep neural network-based model"}]}