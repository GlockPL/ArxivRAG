{"title": "Metric-DST: Mitigating Selection Bias Through Diversity-Guided Semi-Supervised Metric Learning", "authors": ["Yasin I. Tepeli", "Mathijs de Wolf", "Joana P. Gon\u00e7alves"], "abstract": "Selection bias poses a critical challenge for fairness in machine learning, as models trained on data that is less representative of the population might exhibit undesirable behavior for under-represented profiles. Semi-supervised learning strategies like self-training can mitigate selection bias by incorporating unlabeled data into model training to gain further insight into the distribution of the population. However, conventional self-training seeks to include high-confidence data samples, which may reinforce existing model bias and compromise effectiveness. We propose Metric-DST, a diversity-guided self-training strategy that leverages metric learning and its implicit embedding space to counter confidence-based bias through the inclusion of more diverse samples. Metric-DST learned more robust models in the presence of selection bias for generated and real-world datasets with induced bias, as well as a molecular biology prediction task with intrinsic bias. The Metric-DST learning strategy offers a flexible and widely applicable solution to mitigate selection bias and enhance fairness of machine learning models.", "sections": [{"title": "Summary", "content": "Selection bias poses a critical challenge for fairness in machine learning, as models trained on data that is less representative of the population might exhibit undesirable behavior for under-represented profiles. Semi-supervised learning strategies like self-training can mitigate selection bias by incorporating unlabeled data into model training to gain further insight into the distribution of the population. However, conventional self-training seeks to include high-confidence data samples, which may reinforce existing model bias and compromise effectiveness. We propose Metric-DST, a diversity-guided self-training strategy that leverages metric learning and its implicit embedding space to counter confidence-based bias through the inclusion of more diverse samples. Metric-DST learned more robust models in the presence of selection bias for generated and real-world datasets with induced bias, as well as a molecular biology prediction task with intrinsic bias. The Metric-DST learning strategy offers a flexible and widely applicable solution to mitigate selection bias and enhance fairness of machine learning models."}, {"title": "Keywords", "content": "Selection bias, Metric learning, Semi-supervised learning, Diversity, Fairness, Machine learning."}, {"title": "Introduction", "content": "Machine learning (ML) algorithms enabling predictive modeling and data-driven decision-making have contributed important advances across disciplines. The increasing pervasiveness of ML in society also raises awareness about its potential impact on people's lives and the need to ensure fairness in predictions made by ML models. Selection bias is one of the most common sources of unfairness in ML, where the training data is not representative of the underlying population, with some groups or profiles appearing more prominently while others might be excluded [1-5].\nMitigating selection bias is crucial to ensure fairness, accuracy, and reliability of machine learning models. Several approaches have been proposed to address this issue, including data preprocessing techniques [6\u20138], reweighting methods [9\u201315], and algorithmic fairness measures [16, 17]. Most of these methods are proposed under the umbrella term of domain adaptation (DA), which adjusts models to account for distribution shifts between source and target prediction domains. Available DA approaches typically focus on adapting models to specific test sets, which can limit the generalizability of the models beyond the train and test data.\nSemi-supervised learning has gained traction to address bias by leveraging abundant unlabeled data that might offer further insight into the true underlying distribution of the data but cannot be directly used in supervised learning. A common framework for semi-supervised learning relies on self-training that iterates between (i) building a model with supervised learning and (ii) using the model both to predict pseudo-labels for unlabeled samples and to select a subset to incorporate into the learning during the subsequent iteration. Conventional self-training selects pseudo-labeled samples based on model confidence, often focusing on the most confident predictions [18, 19], which can reinforce the bias in the data by incorporating samples similar to others already in the biased labeled set [20\u201322].\nTo counteract this confirmation bias, the DCAST [21] semi-supervised strategy gradually includes diverse pseudo-labeled samples above a relaxed confidence threshold. Diversity is achieved by choosing samples from distinct clusters, identified based on sample distances or dissimilarities. The preferred DCAST approach leverages distances within a learned class-informed latent space, rather than the original feature space, to lessen the influence of uninformative features. This can be especially important for high-dimensional data, however the approach cannot be combined with classifiers lacking such latent representations. Additionally, DCAST presumes that the different clusters in the latent space capture diverse sets of samples, which can be suboptimal if the data cannot be meaningfully clustered.\nWe introduce Metric-DST, a self-training framework relying on metric learning to enable more general selection bias mitigation for diversity-aware prediction models. Metric learning offers a suitable alternative to obtain a class-informed latent space [23] by optimizing a transformation of the original feature space to a lower dimensionality in a class-contrastive manner. Metric-DST uses this mechanism to learn a bounded latent space where distances between samples reflect both dissimilarity and class membership, and then generates random locations within the space to select diverse samples that are predicted by a companion classifier above a relaxed confidence threshold. Metric-DST exploits sample diversity during model learning to improve generalizability, and can be used with virtually any type of classifier."}, {"title": "Results and Discussion", "content": "The aim of the proposed semi-supervised Metric-DST framework is to learn a prediction model with improved robustness to selection bias by leveraging available unlabeled data for additional representativeness of the underlying population distribution (Fig. 1). Using self-training, unlabeled samples are gradually pseudo-labeled and selected to be incorporated into model learning. Since conventional self-training is prone to reinforcing data bias, Metric-DST seeks to counter such behavior through the selection of diverse pseudo-labeled samples. To achieve this, Metric-DST exploits a metric learning model formulation to generate class-informative representations of samples in a bounded latent space. Briefly, at each self-training iteration, Metric-DST first learns a transformation function or model $f_\\theta$ from the labeled samples $X_L$ and respective labels $Y_L$ using metric learning with a contrastive loss to optimize class separation in the learned latent space (Fig. 1, Methods). The learned transformation $f_\\theta$ is used to obtain embeddings or representations $Z_U$ of the unlabeled samples $X_U$ in the new space. Then, the learned representations are used by Metric-DST in two ways: (i) to make predictions and thus assign pseudo-labels to unlabeled samples, using a simple weighted k nearest neighbors classifier; and (ii) to select $p/2$ diverse pseudo-labeled samples per class as randomly generated points in the latent space whose nearest pseudo-labeled sample satisfies a relaxed confidence threshold $\\mu$.\nWe evaluated the bias mitigation ability of the proposed diversity-guided Metric-DST method against two approaches: Metric-ST, a similarly semi-supervised variant relying on conventional self-training without diversity; and Supervised, vanilla supervised learning. Generally, our goal was to investigate if Metric-DST could build models with improved robustness to selection bias and if the diversity strategy was effective in that regard. All three strategies used metric learning with an identical neural network architecture, in combination with weighted kNN for prediction. Different bias scenarios were also considered across generated and real-world benchmark binary classification datasets, as well as a molecular biology challenge inherently affected by selection bias called synthetic lethality prediction. Each of the three learning methods was assessed for each bias scenario across 10 different train/test splits (Methods)."}, {"title": "Model learning under selection bias with Metric-DST", "content": "The aim of the proposed semi-supervised Metric-DST framework is to learn a prediction model with improved robustness to selection bias by leveraging available unlabeled data for additional representativeness of the underlying population distribution (Fig. 1). Using self-training, unlabeled samples are gradually pseudo-labeled and selected to be incorporated into model learning. Since conventional self-training is prone to reinforcing data bias, Metric-DST seeks to counter such behavior through the selection of diverse pseudo-labeled samples. To achieve this, Metric-DST exploits a metric learning model formulation to generate class-informative representations of samples in a bounded latent space. Briefly, at each self-training iteration, Metric-DST first learns a transformation function or model $f_\\theta$ from the labeled samples $X_L$ and respective labels $Y_L$ using metric learning with a contrastive loss to optimize class separation in the learned latent space (Fig. 1, Methods). The learned transformation $f_\\theta$ is used to obtain embeddings or representations $Z_U$ of the unlabeled samples $X_U$ in the new space. Then, the learned representations are used by Metric-DST in two ways: (i) to make predictions and thus assign pseudo-labels to unlabeled samples, using a simple weighted k nearest neighbors classifier; and (ii) to select $p/2$ diverse pseudo-labeled samples per class as randomly generated points in the latent space whose nearest pseudo-labeled sample satisfies a relaxed confidence threshold $\\mu$.\nWe evaluated the bias mitigation ability of the proposed diversity-guided Metric-DST method against two approaches: Metric-ST, a similarly semi-supervised variant relying on conventional self-training without diversity; and Supervised, vanilla supervised learning. Generally, our goal was to investigate if Metric-DST could build models with improved robustness to selection bias and if the diversity strategy was effective in that regard. All three strategies used metric learning with an identical neural network architecture, in combination with weighted kNN for prediction. Different bias scenarios were also considered across generated and real-world benchmark binary classification datasets, as well as a molecular biology challenge inherently affected by selection bias called synthetic lethality prediction. Each of the three learning methods was assessed for each bias scenario across 10 different train/test splits (Methods)."}, {"title": "Metric-DST mitigates bias induced to generated and real-world datasets", "content": "We first evaluated Metric-DST, and the Metric-ST and Supervised baselines, on binary classification tasks using artificially generated and real-world benchmark datasets with induced selection bias. Briefly, for each train/test split, the train set comprising 90% of the data was further randomly split into labeled (30%) and unlabeled (70%) subsets. The Supervised approach trained using labeled data alone, while Metric-(D)ST trained using both labeled and unlabeled data. For experiments using bias, selection bias was induced only to the labeled subset, enabling us to assess if the trained model could generalize beyond the biased training data and also leverage the unlabeled data to do so. For comparison, we also trained separate models without bias induction and using a random selection of samples (as many as used in the biased selection)."}, {"title": "Moons dataset and delta bias", "content": "The generated moons dataset contained 2000 data points in 2 dimensions, distributed over two classes, with the class-specific point clouds forming interleaving moon shapes (Fig. 2a). We induced selection bias using a technique termed delta bias to obtain a set of either 100 or 200 class-balanced samples in the vicinity of user-defined points $\\Delta_0$ and $\\Delta_1$ for classes 0 and 1, respectively. We also used two combinations of $\\Delta$ points: identical for both classes, $\\Delta_0 = \\Delta_1 = (0,0)$; and different per class, with {$\\Delta_1 = (1,0.5)$, $\\Delta_1 = (0,0)$}."}, {"title": "Higher-dimensional two-cluster datasets and hierarchy bias", "content": "We complemented the generated data using 8 balanced binary classification datasets of 2000 samples spread over two clusters per class. The datasets spanned four dimensionalities or numbers of features (16, 32, 64, and 128), paired with an additional setting determining whether 100% or 80% of those features were informative for the classification task. We selected a biased subset of 100 or 200 samples from each dataset using hierarchy bias with bias ratio $b = 0.9$ [21], which favored samples from one specific cluster identified de novo per class (Methods, Supplementary Fig. S1).\nTraining on a random selection of 100 or 200 samples caused a decrease in the performance of supervised learning across 7 of the 8 datasets compared to training without bias (Fig. 2c, purple vs. grey). The biased selection using hierarchy bias led to a further decrease in supervised model performance beyond the impact of random selection and respective reduction in sample size, with a change in median AUROC between 0.06 and 0.17 for 100 samples and between 0.03 and 0.14 for 200 samples (Fig. 2c, blue vs. purple). The Metric-ST method relying on conventional self-training was comparable or worse than supervised learning concerning robustness to induced hierarchy bias, and led to significant decreases in performance for 2 out of the 8 datasets for both 100 and 200 selected samples (Fig. 2c, yellow vs. blue, p-values < 0.03). Metric-DST was mostly comparable to supervised learning, with only two significant differences: a performance increase for 100 samples with 16 dimensions of which 80% informative (Fig. 2c, green vs. blue, p-value < 0.05), and a performance drop for the 200 sample selection of the 64-dimensional dataset with 80% informative features (p-value 0.004). We also observed non-significant increases in median AUROC for 100 samples with 64 dimensions of which 80% informative (medians 0.73 vs 0.76) and for 200 samples with 16 and 32 dimensions of which 80% informative (medians 0.77 vs 0.79 for 16 dimensions and 0.83 vs 0.85 for 32 dimensions).\nOn the generated higher-dimensional datasets, Metric-DST displayed superior robustness to induced hierarchy selection bias compared to the Metric-ST approach. Mostly Metric-DST was able to protect the supervised learning performance, with occasional very modest improvements."}, {"title": "Real-world benchmark datasets with hierarchy bias", "content": "Event though artificially generated data and bias induction may offer some sense of control over the conditions of the experiments, there is still a multiplicity of factors to consider, and it is unlikely that the generated datasets capture the complexity and exhibit the behavior of real-world datasets. For this reason, we also evaluated the mitigation of selection bias on 8 real-world binary classification tasks using public datasets. We induced hierarchy selection bias with ratio $b = 0.9$, targeting selections of 60 and 100 samples due to the limited size of some datasets (Methods, Supplementary Fig. S2).\nTraining on the biased sample selection led to an overall decrease in the performance of supervised learning models compared to training on the original data or a random selection (Fig. 2d). The effect of the induced hierarchy bias was however less pronounced using the larger 100 sample selection, and did not significantly affect model performance for datasets like Raisin and Breast cancer for which the sample count corresponded to a substantial portion of the data (~153 samples in the labeled training set before bias induction).\nUsing the 60 sample selection, Metric-ST improved performance in two datasets, Raisin and Rice (p-values 0.006 and 0.020). Metric-DST resulted in significantly improvements for three datasets, Fire (p-value 0.049), Raisin (p-value 0.020), and Adult (p-value 0.002). Additionally, Metric-DST increased performance in the Fire dataset as well, but the change was not significant (p-value 0.064). While Metric-ST showed potential, Metric-DST demonstrated a greater overall impact. Using the 100 sample selection, neither semi-supervised Metric-(D)ST approach delivered significant performance improvements consistently across datasets: only on one instance Metric-DST improved significantly over supervised learning on the biased data, on the Rice dataset (p-value 0.020). It is worth noting that the larger biased selection of 100 samples did not affect the original performance as much, leaving limited room for improvement for semi-supervised learning methods. Some datasets, especially Breast cancer, could also potentially harbor easily separable classes, a dynamic that may cause biased selections to still capture the original decision boundary, thereby rendering semi-supervised methods less effective. Overall, Metric-DST showed improved robustness to selection bias compared to Metric-ST, and the ability to preserve or improve performance compared to supervised learning across all datasets."}, {"title": "Metric-DST mitigates selection bias for synthetic lethality prediction", "content": "The evaluation with induced biases on generated and real-world benchmark datasets enabled us to assess the effectiveness of the learning methods in cases where the biases in the data are unknown or difficult to characterize. However, artificially induced biases also have their limitations, and the insights gained from such experiments might not translate well to real-world prediction tasks inherently affected by complex selection biases. To cover this scenario, we finally evaluated Metric-DST on a molecular biology challenge, called synthetic lethality (SL) prediction, where the set of labeled samples available for training is known to be biased. We performed three experiments to evaluate Metric-DST on SL prediction, which were designed to control the extent of the difference in selection bias between paired train and test sets (Methods)."}, {"title": "Randomized split for similar train/test selection bias", "content": "We assessed the supervised and semi-supervised learning methods on SL prediction for each of five distinct cancer types under similar selection bias between train and test sets. The supervised model showed noteworthy median AUPRC performances for the BRCA and LUAD cancer types (0.854 and 0.837, respectively). Metric-ST and Metric-DST both led to marginal, non-significant improvements in median AUPRC performance compared to supervised learning for LUAD (0.843 and 0.851), and Metric-DST also for BRCA (0.859) (Fig. 3a, green vs. blue). Possibly due to the ample sample sizes (Supplementary Tables S1-S3) and high starting performances of BRCA (1443 SL, 1010 non-SL pairs) and LUAD (594 SL, 5509 non-SL pairs), the use of additional pseudo-labeled data yielded inconsequential performance gains.\nWe noticed improvements of Metric-ST and Metric-DST over supervised learning in median AUPRC for the cancer types with more limited numbers of labeled samples, including CESC, OV, and SKCM. However, owing to relatively large variances, the only significant improvement was seen with Metric-DST for CESC (Fig. 3a, green vs. blue, p-value 0.014). Additionally, both Metric-DST and Metric-ST seemed superior to supervised learning for CESC and OV in median AUPRCs (Metric-DST CESC: 0.696, OV: 0.772; Metric-ST CESC: 0.683, OV: 0.765; supervised CESC: 0.587, OV: 0.701). We also saw a moderate non-significant improvement in median AUPRC of the Metric-(D)ST methods over supervised learning for the SKCM dataset (Metric-DST 0.769, Metric-ST 0.771, supervised 0.747).\nIn summary, the application of Metric-DST looked cautiously promising in the context of a randomized split, preserving similar biases between train and test sets, for cancer types with more limited sample sizes (CESC, OV, and SKCM)."}, {"title": "Double holdout for distinct train/test selection bias", "content": "We also assessed Metric-DST with paired train and test sets yielding different biases, adopting a double holdout technique where gene overlap between test and train sets was entirely prevented. This restrictive split resulted in a diminished train set size, reaching its lowest for the CESC dataset with only 90 samples.\nRelative to the randomized split experiment, supervised learning using double holdout resulted in lower median AUPRCs (Randomized split vs. Double holdout in BRCA, OV, CESC, SKCM, and LUAD: 0.853 vs. 0.527, 0.701 vs. 0.558, 0.587 vs. 0.560, 0.747 vs. 0.497, and 0.837 vs. 0.517, respectively) (Fig. 3b). This was expected due to the restrictions imposed by the double holdout to ensure zero overlap in individual genes, in addition to zero overlap in gene pairs between train and test sets. Although some performance differences could be observed between the Metric-(D)ST methods and supervised learning for the BRCA, LUAD, OV, and SKCM datasets, none of them reached statistical significance. Metric-ST showed higher median AUPRC than Metric-DST and supervised learning for LUAD, OV, and SKCM, while Metric-DST did better in this regard for BRCA and CESC. The only significant improvement in AUPRC performance was recorded for CESC, with Metric-DST outperforming the supervised model (median AUPRC 0.60 vs. 0.56, p-value 0.010). It is important to note that the semi-supervised methods did not cause significant decreases in performance relative to supervised learning.\nMultiple factors might explain the lack of effectiveness of Metric-DST for some cancer types. For instance, the restrictions imposed by the double holdout procedure may have caused too extreme differences in biases between the train and test sets, due to the absence of shared genes. An additional contributing factor could be the reduction in train set size, exemplified by the CESC dataset (Supplementary Table S4). The impact of these constraints also resulted in a large performance decrease for the baseline supervised model (Fig. 3a-b), making the recovery more difficult for the semi-supervised techniques which rely heavily on an initial successful model."}, {"title": "Cross dataset split with naturally occurring selection bias", "content": "To evaluate bias mitigation with naturally occurring differences in selection bias between train and test sets, we set up the data splits to train using SL labeled samples from one study and test on SL labeled samples from another study, encompassing six permutations across three studies (ISLE, dSL, and EXP2SL). For BRCA, when trained on ISLE and tested on dSL, both Metric-ST and Metric-DST induced an increase in the minimum AUPRC performance by over 0.2, but overall there were no significant differences in performance between the two semi-supervised methods and supervised learning (Fig. 3c). For LUAD, the Metric-(D)ST methods resulted in significant performance improvements only for the setting that trained on dSL and tested on EXP2SL significant differences (median AUPRC: Supervised 0.536; Metric-ST 0.561 with p-value 0.049; Metric-DST 0.576 with p-value 0.014). The remaining study combinations did not reveal significant changes either, but we observed small decreases in median AUPRC for Metric-ST trained on ISLE and tested on dSL, as well as for Metric-DST trained on dSL and tested on ISLE.\nTaking all experiments on synthetic lethality prediction into account, it is important to highlight that the two semi-supervised Metric-(D)ST methods significantly outperformed supervised learning on three scenarios, while never performing significantly worse. Instances where Metric-ST and Metric-DST yielded no clear impact might be attributed to multiple factors, including the inherent complexity of the problem with baseline supervised learning performances hovering around 0.5, or extreme disparities between the train and test sets."}, {"title": "Metric-DST promotes diversity in selected pseudo-labeled samples", "content": "To verify if the diversity approach of Metric-DST was able to select more diverse samples, we analyzed the Euclidean pairwise distances between pseudo-labeled samples assigned to the same class label in the learned embedding space, using the BRCA Randomized split as an example (Fig. 3d). The distances were larger on average for pseudo-samples selected by Metric-DST, confirming a more heterogeneous sample selection compared to Metric-ST."}, {"title": "Conclusion", "content": "In this work, we proposed Metric-DST, a semi-supervised framework coupled with metric learning to build prediction models with improved robustness to sample selection bias. Metric-DST relies on self-training to incorporate unlabeled samples for additional representation and insight into the underlying distribution of the population. Crucially, Metric-DST introduces a strategy to counter confirmation bias of conventional self-training by learning from a more diverse set of samples.\nDiversity is introduced via metric learning of a class-contrastive representation, which facilitates the pseudo-labeling and identification of dissimilar unlabeled samples to include in the training. Evaluation using artificially generated and real-world datasets with induced selection bias suggested the potential of self-training to enhance model generalizability, yet also its susceptibility to exacerbate data bias. The proposed diversity-guided approach, Metric-DST, showed greater resilience than conventional self-training, albeit with modest performance improvements. Application to synthetic lethality prediction showed that semi-supervised metric learning could augment performance in scenarios where train and test sets yielded similar or distinct naturally occurring selection biases. It was reassuring that Metric-DST was able to preserve the performance obtained with supervised learning or deliver more robust models in all contexts, and especially under challenging conditions, such as with limited numbers of training samples or weak baseline models.\nUtimately, the effectiveness of Metric-DST is contingent upon factors such as the performance of the underlying base model, the type and extent of the data bias, and the ratio of features to samples, among others. Future work warrants a deeper exploration of the potential of the Metric-(D)ST learning framework, including refinement of neural network architectures and loss functions. Leveraging metric learning as a means of diversifying pseudo-sample selection in combination with various classifiers could further expand the scope of the model. We also envision further addressing the limitations of the existing pseudo-labeled sample selection approach, which could be extended to ensure a more comprehensive representation of the embedding space by excluding unpopulated regions."}, {"title": "Experimental procedures", "content": "Metric-DST is a semi-supervised ML framework based on metric learning to obtain an embedding function or transformation that is informative for a classification task of interest with increased robustness to selection bias. Learning is accomplished via self-training, where the transformation is gradually refined by incorporating a diverse selection of newly pseudo-labeled unlabeled examples into the training process. The learned transformation serves the dual purpose of predicting pseudo-labels and assessing sample diversity to counter the data bias.\nEach self-training iteration involves three steps: (1) learn a metric embedding function from the labeled data such that the latent representation of a sample also yields pertinent information about class separation, (2) pseudo-label unlabeled samples based on the learned transformation so they can be considered as candidates for selection and training, (3) select a diverse subset of pseudo-labeled samples and include them in the labeled train set for the next iteration."}, {"title": "Metric-DST", "content": "Metric-DST is a semi-supervised ML framework based on metric learning to obtain an embedding function or transformation that is informative for a classification task of interest with increased robustness to selection bias. Learning is accomplished via self-training, where the transformation is gradually refined by incorporating a diverse selection of newly pseudo-labeled unlabeled examples into the training process. The learned transformation serves the dual purpose of predicting pseudo-labels and assessing sample diversity to counter the data bias.\nEach self-training iteration involves three steps: (1) learn a metric embedding function from the labeled data such that the latent representation of a sample also yields pertinent information about class separation, (2) pseudo-label unlabeled samples based on the learned transformation so they can be considered as candidates for selection and training, (3) select a diverse subset of pseudo-labeled samples and include them in the labeled train set for the next iteration."}, {"title": "Learning of a metric embedding function", "content": "At iteration t, Metric-DST first learns a transformation function or model $f_\\theta^{(t)}$ based on the labeled samples in matrix $X^{(t)}$ and the corresponding binary labels $y^{(t)}$ using metric learning. The general goal is to learn a transformation of an individual sample vector x to a latent embedding representation $z = f_\\theta^{(t)}(x)$, guided by class assignments and inter-sample distances, such that samples of the same class are closer together and samples from different classes are distanced further apart in the learned embedding space. Various model architectures could be used for the transformation, in this case we used a feed-forward neural network with a single hidden layer. The model is optimized based on the contrastive loss function designed to minimize intra-class distances and maximize inter-class distances of samples in the embedding space (Eq. 1)."}, {"title": null, "content": "$L_{contrastive} = \\sum_{(i,j)\\in P} 1_{y_i=y_j} max{0, d_{i,j} - m_{pos}} + 1_{y_i\\neq y_j} max{0, M_{neg} - d_{i,j}}$"}, {"title": null, "content": "Here, $d_{i,j}$ denotes the Euclidean distance between samples $x_i$ and $x_j$ in the embedding space, thus $d_{i,j} = d(f_\\theta^{(t)}(x_i), f_\\theta^{(t)}(x_j))$. Symbol P represents the set of all sample pairs within a training batch, and the indicator function $1_{condition}$ takes value 1 if the condition holds or 0 otherwise. The positive and negative margins, $M_{pos}$ and $M_{neg}$, are used to prevent the algorithm from forcing samples with the same labels to overlap completely or samples with different labels to be separated infinitely. Specifically, the distance between samples with the same labels only increases the loss when it exceeds the positive margin, and the distance between samples with different labels stops contributing to the loss once the distance exceeds the negative margin.\nOnce the transformation has been learned from the labeled samples $X^{(t)}$, it can be applied to obtain embedding representations for unlabeled samples in $X^{(t)}$ as well. We denote the embedding matrix containing the representations of all samples, labeled and unlabeled, by $Z^{(t)}.$"}, {"title": "Pseudo-labeling of unlabeled samples through metric embedding", "content": "The transformation model $f_\\theta^{(t)}$ learned from the labeled data cannot be directly used to make predictions and thus assign pseudo-labels to unlabeled samples. To classify the unlabeled samples, Metric-DST applies a weighted version of k nearest neighbors (kNN) to the embedding matrix $Z^{(t)}$ with the learned representations $z^{(t)} = f_\\theta^{(t)}(x)$ of all samples. For a given unlabeled sample i with representation $z^{(t)}_i \\in Z^{(t)}$, Metric-DST identifies the set $N_i$ of its k closest labeled samples in $Z^{(t)}$. The prediction class probability $\\tilde{y}_i \\in [0,1]$ for sample $x_i$ is then calculated as a weighted average of the probabilities of the k neighbors, as given by Eq. 2. The calculation factors in the distance of each neighbor representation to $z_i$, so that closer neighbors contribute more than farther ones."}, {"title": null, "content": "$\\tilde{y}_i = \\frac{\\sum_{n \\in N_i} y_n \\times (1 - d_{i,n}) + (1 - y_n) \\times d_{i,n}}{k}$"}, {"title": "The probability", "content": "$\\tilde{y}_i = \\frac{\\sum_{n \\in N_i} y_n \\times (1 - d_{i,n}) + (1 - y_n) \\times d_{i,n}}{k}$"}, {"title": null, "content": "The probability $\\tilde{y}_i$ represents the confidence of the model, where values close to 1 and 0 indicate high confidence in predicting class 1 and class 0, respectively. The final class label $\\hat{y}_i$ is obtained by thresholding the probability value $\\bar{y}_i$ as per Eq. 3."}, {"title": null, "content": "$\\hat{y}_i = \\begin{cases} 1, & \\text{if } \\tilde{y}_i > 0.5 \\\\ 0, & \\text{otherwise} \\end{cases}$"}, {"title": "The probability", "content": "$\\hat{y}_i = \\begin{cases} 1, & \\text{if } \\tilde{y}_i > 0.5 \\\\ 0, & \\text{otherwise} \\end{cases}$"}, {"title": "Selection of diverse pseudo-labeled samples", "content": "After assigning pseudo-labels, Metric-DST selects which newly pseudo-labeled samples to include in the labeled set for the subsequent training iteration.\nConventional self-training (ST) typically chooses the p newly pseudo-labeled samples with the highest confidence [19], where p is a user-defined parameter. The reliance on confidence alone promotes confirmation bias, where the model is likely to follow and strengthen the selection bias present in the labeled data. Additionally, ST is not class-aware in that it does not consider that the model may not be similarly confident about prediction of different classes, which could further lead to unwanted biases such as class imbalance. To address both issues, Metric-DST performs diversity-guided self-training (DST), which introduces sample diversity and class balancing into the selection of pseudo-labeled samples using the learned metric embedding. Diversity is achieved through randomness in the choice of each pseudo-labeled sample as follows. First, Metric-DST creates a candidate point in learned embedding space $Z_i^{(t)}$ as a tuple of randomly generated coordinates in the range [0,1]. Then, the pseudo-labeled sample closest to the candidate point is identified based on the Euclidean distance (Eq. 2). The selected pseudo-labeled sample is designated for inclusion in the labeled train set for the subsequent iteration if the confidence on its prediction surpasses a predefined relaxed threshold $\\mu$. Class balance is achieved by selecting p/2 positive and p/2 negative pseudo-labeled samples sequentially using the aforementioned procedure for each self-training iteration. If Metric-DST fails to secure a sufficient number of pseudo-labeled samples within 50 \u00d7 p attempts for any one self-training iteration, undersampling of the majority class is employed to obtain a class balanced set of pseudo-labeled samples."}, {"title": "Evaluation of Metric-DST", "content": "We evaluated the Metric-DST semi-supervised model learning strategy proposed to mitigate sample selection bias against two baselines: Metric-ST, also a semi-supervised approach based on metric learning to train models using both labeled and unlabeled data, but paired with conventional self-training and thus missing the class-awareness and diversity elements of Metric-DST; and Supervised, referring to the traditional supervised metric learning technique to train models from labeled data alone. We used the same neural network model architecture as a basis with all learning strategies, consisting of an 8-dimensional hidden layer and a 2-dimensional output layer. Unless otherwise specified, the batch training size was set to 64, and the confidence threshold $\\mu$ was set to 0.9. We further relied on weighted kNN with k = 5 to make predictions based on the metric embedding of a sample. Finally, we assessed the bias mitigation ability of Metric-DST across a range of binary classification tasks and selection bias scenarios, ranging from artificially generated and real-world benchmark data with induced selection bias to an important prediction task in molecular biology intrinsically affected by selection bias."}, {"title": "Datasets and selection bias", "content": "We generated the simplest \"moons\" dataset as a binary class-balanced set of 2000 samples or points in a 2-dimensional space, such that the samples of the two classes formed interleaving half circles (or moons), using the make_moons function from scikit-learn [24"}]}