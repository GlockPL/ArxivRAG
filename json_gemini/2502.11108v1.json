{"title": "Knowledge Graph-Driven Retrieval-Augmented Generation: Integrating Deepseek-R1 with Weaviate for Advanced Chatbot Applications", "authors": ["Alexandru Lecu", "Adrian Groza", "Lezan Hawizy"], "abstract": "Large language models (LLMs) have significantly advanced the field of natural language generation. However, they frequently generate unverified outputs, which compromises their reliability in critical applications. In this study, we propose an innovative framework that combines structured biomedical knowledge with LLMs through a retrieval-augmented generation technique. Our system develops a thorough knowledge graph by identifying and refining causal relationships and named entities from medical abstracts related to age-related macular degeneration (AMD). Using a vector-based retrieval process and a locally deployed language model, our framework produces responses that are both contextually relevant and verifiable, with direct references to clinical evidence. Experimental results show that this method notably decreases hallucinations, enhances factual precision, and improves the clarity of generated responses, providing a robust solution for advanced biomedical chatbot applications.", "sections": [{"title": "I. INTRODUCTION", "content": "To combat hallucinations of language models, coupling LLMs with structured data sources such as Knowledge Graphs (KGs) offers an effective strategy. Retrieval-Augmented Generation (RAG) techniques merge the generative capabilities of LLMs with external, domain-specific information, improving both the reliability and clarity of the responses produced.\nWe present a system that uses a knowledge graph-driven RAG approach to enhance advanced chatbot applications. Our solution integrates three key components: a knowledge graph maintained in GraphDB, a vector-based retrieval system using Weaviate, and a locally deployed language model, Deepseek-R1:7B, for natural language generation. The knowledge graph stores structured domain-specific information, while Weaviate facilitates the semantic search of embeddings derived from this graph. Deepseek-R1 then utilizes the retrieved context, in combination with user queries, to generate accurate and context-aware responses.\nThis integrated architecture is particularly effective for ap- plications in specialized domains such as age-related macular degeneration (AMD), where complex biomedical entities and causal relationships must be captured and communicated ac- curately. By anchoring LLM outputs in a verified knowledge base, our system ensures that generated responses are both fluent and factually correct.\nThe technical task is to extract both causal relations (RE) and named entities (NER) from medical abstracts. The investi- gation domain for named entities is restricted to 12 entities: (i) disease, (ii) symptom, (iii) treatment, (iv) risk factor, (v) test/- diagnostic, (vi) gene, (vii) biomarker, (viii) complication, (ix) prognosis, (x) comorbidity, (xi) progression, (xii) body part. We consider 8 causal relations: (i) cause (causes or contributes to the occurrence of another entity), (ii) treat (is a treatment or intervention for another entity), (iii) present (is a symptom or manifestation of another entity), (iv) diagnose (is a test or diagnostic tool), (v) aggravate (worsens or exacerbates another entity), (vi) prevent (prevents or reduces the occurrence or development of another entity), (vii) improve (enhances or improves the condition or treatment of another entity), (ix) affect (affects a certain body part)."}, {"title": "II. RELATED WORK", "content": "KRAGEN [1] is a framework that combines knowledge graphs with retrieval-augmented generation to address intricate issues in the biomedical field. The study highlights advanced prompting methods, including graph-of-thoughts, to system- atically break down tasks and reduce hallucinations in large language model outputs.\nPolat et al. [2] have examined different prompt engineering techniques to extract knowledge. The findings indicate that straightforward instructions coupled with task demonstrations significantly boost extraction performance in various large language models, particularly when examples are chosen using retrieval methods.\nMuntean et al. [3] investigated the performance of LLMs in a specific ophthalmological domain, that is, age-related macu- lar degeneration. The study reveals that ChatGPT4 and PaLM2 are valuable instruments for patient information and education based on the evaluation methodology proposed by Singhal et al. [4]. However, since there are still some limitations to these models, a fine-tuned model tailored for age-related macular degeneration has been proposed. Nevertheless, this approach can be adapted to other fields by following the same steps.\nAdditional research further supports the integration of struc- tured knowledge with generative models. Lewis et al. [5] introduced the Retrieval-Augmented Generation framework, demonstrating that grounding LLM outputs in external data significantly enhances factual accuracy. Wei et al. [6] showed that chain-of-thought prompting can guide LLMs through mul- tistep reasoning processes, a capability essential for complex biomedical queries. Yang et al. [7] further emphasized that merging knowledge graphs with LLMs leads to more reliable and interpretable outcomes."}, {"title": "III. SYSTEM ARCHITECTURE", "content": "Figure 2 presents an overview of the proposed solution, organized into three main phases. In the Annotation & Data Collection an ontology that includes causal relations relevant to AMD is engineered using the Protege editor. Annotators use the CausalAMD ontology to label relations from abstracts with the appropriate predicates and entity types. It also serves as the basis for an automatically generated prompt that in- structs the language model to extract causal relations from the abstract. The abstracts were collected from the Dimensions database (https://www.dimensions.ai/). In the Data Processing phase, causal relations are extracted using the GPT-401-mini model. After disambiguating the extracted relations, we utilize the HermiT reasoner [8] to conduct reasoning and transfer all inferred knowledge into a Knowledge Graph, which is maintained using the Ontotext GraphDB tool. Finally, the RAG model phase converts the refined data into semantic vectors using an embedding model, forming a comprehensive context. This context is then processed by a Large Language Model to generate an answer for the user. In general, the architecture integrates ontology-based annotation, causal relation process- ing, and retrieval-augmented generation to deliver accurate and context-aware responses."}, {"title": "A. Ontology Engineering", "content": "The ontology provides a structured framework for model- ing causal relationships in age-related macular degeneration (AMD), combining biomedical concepts with clinical evi- dence. It integrates entities (genes, symptoms, treatments), causal predicates (causes, treats, aggravates) and provenance data from research publications.\nCentral to the design is the Entity class, which catego- rizes AMD-related concepts into subclasses such as Gene, Biomarker, and Treatment. These entities connect via Relation instances, which define subject-predicate-object triples while linking to source publications through the PROV-O ontology. This ensures that every causal claim refers to a clinical trial."}, {"title": "B. Enriching Knowledge Graph", "content": "Enriching the knowledge graph involves a systematic pro- cess of extracting, validating, and integrating new causal relations from medical abstracts. The system first processes each abstract using large-language models to extract structured representations of causal relations. These representations cap- ture the relation type, the names and types of the involved entities, and the publication identifier, which preserves the provenance of the information.\nOnce the relations are extracted, they undergo a rigorous validation procedure. This step ensures that each relation adheres to a set of predefined valid types for both entities and relations. Any discrepancies are addressed by applying dis- ambiguation and normalization techniques. Domain-specific synonyms and abbreviations are standardized, and conflicts in entity types are resolved by selecting the most frequently oc- curring or prioritized type. This refinement process minimizes duplication and maintains consistency across the knowledge graph.\nFollowing validation, the refined relations are transformed into a series of RDF triples that conform to the underlying ontology. Unique identifiers are generated for each relation, and the resulting triples incorporate both the relational data and associated publication details. These triples are then inserted into the knowledge graph using dynamically gener- ated SPARQL queries, ensuring that the new information is seamlessly integrated with the existing data."}, {"title": "1) Prompt Engineering for Relation Extraction:", "content": "In this process, a prompt is automatically generated based on the CausalAMD ontology. The ontology provides a structured list of entity types and relation types that are relevant to age- related macular degeneration.\nIn our experiments, we compared different prompting strate- gies for extracting causal relations from medical abstracts With zero-shot prompting, the model only received instruc- tions, which led to ambiguous output. Single-shot prompting improved performance by providing one clear example, but it was the few-shot approach that proved to be the most effective.\nAs shown in our prompt template including multiple examples helped the model strictly adhere to the specified entity and relation labels and consistently generate the desired JSON format.\nThis prompt instructs the language model to analyze an abstract and output causal relations in a precise, structured JSON format. The format is designed to capture details such as the relation type, the names and types of the two entities involved, and the publication identifier to maintain provenance. By enforcing a standardized output format, the prompt mini- mizes ambiguity and simplifies the subsequent validation and integration steps.\nThe prompt is continually updated by querying the ontology, ensuring that any changes, such as the addition of new entities or relation types, are automatically reflected. This synchroniza- tion with the ontology helps maintain consistency between the annotation process and the extraction of causal relations."}, {"title": "2) Refinement of Extracted Relation:", "content": "To ensure high- quality data integration into the knowledge graph, our system employs a post-processing pipeline that refines and normalizes the causal relations extracted from medical abstracts. The refinement begins with a synonyms mapping and removal of trailing, non-informative words. For example, abbreviations such as \"amd\" are standardized to \"age-related macular degen- eration\" using a predefined synonym dictionary, while trailing words like \"cnv\" or \"ga\" are removed to clean the entity names. The function responsible for this task converts names to lowercase, cuts whitespace, and condenses multiple spaces into a single space.\nThe pipeline further addresses inconsistencies in entity-type assignments. When the same entity appears with multiple labels across different relations, the system aggregates these occurrences and applies a priority scheme to select the most appropriate type. For example, if an entity is variably labeled as both 'symptom' and 'complication', the label that is more frequent or holds higher priority based on a predefined hierar- chy is chosen. This step ensures that each entity is consistently represented throughout the dataset.\nFinally, the system eliminates duplicate relations and filters out self-relations (where an entity would erroneously appear as both subject and object), resulting in a clean, non-redundant set of causal relations. This refined dataset is then used to populate the knowledge graph, ensuring that the integrated information is accurate, standardized, and ready for semantic querying and reasoning."}, {"title": "C. Retrieval-Augmented Generation (RAG) Workflow", "content": "The Retrieval-Augmented Generation (RAG) module is the core component that bridges structured knowledge from our Knowledge Graph with natural language generation. This module is designed to leverage both vector-based retrieval and context enrichment to deliver accurate, context-aware responses in our chatbot application.\nThe RAG model integrates a structured retrieval mechanism with the DeepSeek-R1 [9] model to generate responses in- formed by curated knowledge and user input in real time. It achieves this by:\nRetrieving Relevant Knowledge: Structured relations are stored in GraphDB and transformed into semantic em- beddings via an embedding model. These embeddings capture the inherent relationships and properties of the data, enabling an effective semantic search.\nContext Enrichment: These embeddings are used to build a detailed context that encapsulates both the underlying ontology and the immediate conversation cues. This en- riched context provides the necessary background infor- mation for the language model, ensuring that responses are accurate and relevant.\nAnswer Generation: The LLM processes the enriched context to produce coherent, context-aware responses."}, {"title": "1) Embedding and Knowledge Retrieval:", "content": "In the initial phase of the workflow, structured knowledge is maintained within a GraphDB instance that underpins our domain ontol- ogy and inter-entity relationships.\nThese embeddings are then stored in Weaviate, a vector database optimized for semantic search. The Weaviate schema is defined by 3 primary classes: Entity that captures fundamental attributes such as the name and type of the entity, Publication that contains the publication name, and Relation which represents the connections between entities using the relation predicate, including references that link relations with a publication.\nThis schema is designed to preserve the semantic rela- tionships inherent in the Knowledge Graph while facilitating efficient vector-based retrieval. When a user query is received, the system uses these embeddings to perform a semantic search, retrieving the most relevant pieces of information from Weaviate."}, {"title": "2) Context Construction:", "content": "The context construction phase is designed to dynamically assemble an informative context based on the user's input, thereby enabling the generation of responses that are both contextually relevant and factually grounded.\nUpon receiving a user query, the system first identifies entities that semantically match the input. The function is a semantic search mechanism that converts the input text into a vector representation using a pre-trained transformer model (text2vec_transformers). The vector is then compared against the stored embeddings in Weaviate by calculating the cosine similarity between the query vector and each entity's vector representation. The result is a ranked list of entities that are most semantically similar to the user's query, ensuring that the system captures nuanced meaning instead of simple keyword matching.\nOnce the relevant entities have been identified, the next step is to enhance the context by retrieving relational information. Specifically, the system extracts the top k relations in which these identified entities appear as the subject or object of the relation. This approach ensures that the context is not limited to isolated entities, but enriched by the relations connecting these entities together. Each retrieved relation also includes a reference to an associated publication, providing provenance and increasing the credibility of the information. This link to publications is important because it grounds the context in verifiable sources and adds an additional layer of reliability to the responses generated by the system.\nThis context forms a comprehensive snapshot of the relevant domain knowledge, capturing both the semantic associations between entities and the supporting evidence from scholarly sources. The enriched context is then provided as input to the LLM, where it informs it to generate context-aware responses."}, {"title": "3) Language Generation:", "content": "Language generation is the last step in our process. Here, the language model takes the user's questions along with extra context and creates a clear answer. The extra context includes important details we got from our data search. This additional information helps the model understand the full picture. By including the conversation history, the system can refer back to previous questions and provide more detailed answers when needed.\nThe model processes the input and generates a response in real time. The response is built from tokens that stream back to the user. The final answer is then sent back to the user. This process supports follow-up interactions, meaning the user can return to an earlier question and ask for more details. The conversation history is maintained and updated in each interaction, ensuring that the context is preserved.\nThe DeepSeek-R1 model runs locally. We are using DeepSeek from Ollama with 7 billion parameters. Running the model locally reduces network delays and offers more control over the processing environment, and also the costs of using the DeepSeek API are zero."}, {"title": "4) Prompt Engineering for RAG application:", "content": "The prompt template guides the large language model (LLM) to function as a specialized medical research assistant for age-related mac- ular degeneration (AMD). Its design enforces accuracy, trans- parency, and clinical relevance through explicit constraints.\nThe prompt begins by defining the role and scope of LLM: it must act as a trusted AMD expert, relying exclusively on the provided context. Clinical trial IDs are formatted as markdown hyperlinks to enable direct verification by the user. In this way, the user can click on the link directly in the chat application. When no references exist in the context, the model explicitly states this limitation to avoid misleading inferences.\nThe prompt prohibits the fabrication of references or un- supported claims. It also requires the model to articulate uncertainty, for example, noting missing data or conflicting evidence, when the context is not sufficient for confident answers. Responses must maintain a professional tone, sim- plifying complex medical concepts without compromising precision.\nThis prompt design addresses critical challenges in med- ical AI by prioritizing transparency, reliability, and safety. Clinical trial identifiers are formatted as hyperlinks to enable direct source validation, a feature that fosters trust in clinical workflows where rapid verification is essential. Explicitly indicating uncertainty-by noting absent data or contradictory evidence-aligns with well-established methods in medical research, allowing users to evaluate the confidence level of the findings. To comply with regulatory standards, the prompt strictly prohibits fabricated claims, prioritizing patient safety over speculative output. By embedding these principles, the system shifts from a general-purpose language model to a domain-specific assistant tailored for AMD research. This alignment guarantees that the output adheres to the method- ological standards required in healthcare, making it under- standable for both clinicians and researchers.\nThe complete source code for this project is available for exploration and contribution in our GitHub repository, which you can access here. In addition, a live version of our chat application is up and running and can be tested here."}, {"title": "IV. CONCLUSION", "content": "In this study, we have created an innovative framework that combines structured biomedical knowledge with language gen- eration, specifically aimed at age-related macular degeneration (AMD). Our system utilizes a custom knowledge graph along- side a domain-specific ontology to extract and verify causal relationships from medical abstracts, thus increasing the relia- bility and interpretability of chatbot responses. By integrating curated data with real-time user input, this approach shows potential in minimizing model hallucinations and enhancing factual accuracy in biomedical applications. Future research could investigate the integration of additional relational details, such as negative or probabilistic interactions, to enhance the representation of biomedical processes. Moreover, expanding the system's reasoning capabilities might provide deeper in- sights into ambiguous cases, facilitating broader applications across diverse medical fields."}]}