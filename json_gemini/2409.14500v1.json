{"title": "TabGraphs: A Benchmark and Strong Baselines for\nLearning on Graphs with Tabular Node Features", "authors": ["Gleb Bazhenov", "Oleg Platonov", "Liudmila Prokhorenkova"], "abstract": "Tabular machine learning is an important field for industry and science. In this\nfield, table rows are usually treated as independent data samples, but additional\ninformation about relations between them is sometimes available and can be used\nto improve predictive performance. Such information can be naturally modeled\nwith a graph, thus tabular machine learning may benefit from graph machine\nlearning methods. However, graph machine learning models are typically evaluated\non datasets with homogeneous node features, which have little in common with\nheterogeneous mixtures of numerical and categorical features present in tabular\ndatasets. Thus, there is a critical difference between the data used in tabular and\ngraph machine learning studies, which does not allow one to understand how\nsuccessfully graph models can be transferred to tabular data. To bridge this gap,\nwe propose a new benchmark of diverse graphs with heterogeneous tabular node\nfeatures and realistic prediction tasks. We use this benchmark to evaluate a vast set\nof models, including simple methods previously overlooked in the literature. Our\nexperiments show that graph neural networks (GNNs) can indeed often bring gains\nin predictive performance for tabular data, but standard tabular models also can\nbe adapted to work with graph data by using simple feature preprocessing, which\nsometimes enables them to compete with and even outperform GNNs. Based on\nour empirical study, we provide insights for researchers and practitioners in both\ntabular and graph machine learning fields.", "sections": [{"title": "1 Introduction", "content": "Tabular data is ubiquitous in industry and science, and thus machine learning methods for working\nwith such data are of great importance. A key distinction of tabular data is that it typically comprises a\nmixture of numerical and categorical features that widely vary in their distribution and have different\nmeanings and levels of importance for the task. Such features are typically called heterogeneous\nor tabular. Deep learning methods do not always perform well on datasets with heterogeneous\nfeatures, so the machine learning methods of choice for tabular data are ensembles of decision trees,\nin particular gradient-boosted decision trees (GBDT) (Friedman, 2001). However, there is a growing\nnumber of recent works trying to adapt deep learning methods to tabular data (Arik & Pfister, 2019;\nBadirli et al., 2020; Huang et al., 2020; Gorishniy et al., 2021, 2022; Hollmann et al., 2022).\nIn tabular machine learning, table rows are typically treated as independent data samples. However,\nthere is often additional information available about the relations between samples, and leveraging"}, {"title": "2 Related work", "content": "Machine learning for tabular data The key distinction of tabular data is that it typically consists of\na mixture of numerical and categorical features with vastly different meaning and importance for the\ntask. Standard deep learning models often do not perform well on such heterogeneous features. Thus,\nthe preferred methods for tabular data typically involve ensembles of decision trees, such as gradient\nboosted decision trees (GBDTs) (Friedman, 2001), with the most popular implementations being\nXGBoost (Chen & Guestrin, 2016), LightGBM (Ke et al., 2017), and CatBoost (Prokhorenkova et al.,\n2018). However, deep learning models have several advantages compared to tree-based ones, such\nas modularity, ease of integration of different data modalities, the ability to learn meaningful data\nrepresentations, and the ability to leverage pretraining on unlabeled data. Because of this, there has\nbeen an increasing number of works trying to adapt deep learning to tabular data (Klambauer et al.,\n2017; Arik & Pfister, 2019; Song et al., 2019; Popov et al., 2019; Badirli et al., 2020; Hazimeh et al.,\n2020; Huang et al., 2020; Gorishniy et al., 2021; Kadra et al., 2021; M\u00fcller et al., 2021; Gorishniy\net al., 2022; Hollmann et al., 2022; Chen et al., 2023; Feuer et al., 2024). Further, there is recent\nresearch comparing different kinds of tabular models and trying to determine which ones are the best\n(Shwartz-Ziv & Armon, 2022; Grinsztajn et al., 2022; McElfresh et al., 2023).\nAmong the tabular deep learning literature, the retrieval-augmented deep learning models (Kossen\net al., 2021; Qin et al., 2021; Somepalli et al., 2021; Du et al., 2022; Gorishniy et al., 2024) are\nparticularly relevant to our work. For each data sample, these models retrieve information about\nother examples from the dataset, typically employing some form of attention mechanism (Bahdanau\net al., 2014; Vaswani et al., 2017), and use it to make predictions. Thus, these models learn to find\nother relevant samples in the dataset, where relevance is determined by feature similarity. This can be\nviewed as an implicit learning of a similarity graph between data samples. A recent work by Liao &\nLi (2023) directly considers this as a problem of graph structure learning and applies a GNN on top\nof the learned graph. In contrast, in our work, we assume that some (ground-truth) relations between\ndata samples are already given in advance, which is common in many real-world applications, and\nfocus on the models that can utilize these relations.\nMachine learning for graphs Graphs are a natural way to represent data from various domains.\nHence, machine learning on graph-structured data has experienced significant growth in recent years,\nwith graph neural networks (GNNs) showing particularly strong results on many graph machine\nlearning tasks. Most of the proposed GNN architectures (Kipf & Welling, 2016; Hamilton et al.,\n2017; Veli\u010dkovi\u0107 et al., 2017) can be unified under a general message-passing neural networks\n(MPNN) framework (Gilmer et al., 2017). However, GNNs are typically evaluated on graphs with\nhomogeneous node features, such as bags of words or bags of word embeddings. For instance, the\nmost frequently used datasets for node classification are the three citation networks cora, citeseer,\nand pubmed (Sen et al., 2008; Namata et al., 2012; Yang et al., 2016; McCallum et al., 2000; Giles\net al., 1998). The first two datasets use bags of words as node features, while the third one uses\nTF-IDF-weighted bags of words. Other datasets for node classification often found in the literature\ninclude coauthorship networks coauthor-cs and coauthor-physics (Shchur et al., 2018) that use\nbags of words as node features, co-purchasing networks amazon-computers and amazon-photo\n(Shchur et al., 2018) that also use bags of words. In the popular Open Graph Benchmark (OGB) (Hu\net al., 2020), ogbn-arxiv, ogbn-papers100M, and ogbn-mag datasets also use bags of words as\nnode features, while ogbn-products uses dimensionality-reduced representations of bags of words.\nIn a recently proposed benchmark of heterophilous graphs (Platonov et al., 2023b), roman-empire\nuses word embeddings as node features, while amazon-ratings and questions use bags of word\nembeddings. While there are a few graph datasets that have tabular features, such as the fraud-yelp\ndataset from Mukherjee et al. (2013) and the fraud-amazon dataset from McAuley & Leskovec\n(2013), they are not very popular, and the works that do use them (e.g., Zhang et al., 2020; Dou et al.,\n2020) typically do not apply any specialized feature processing and do not compare with GBDT\nbaselines, thus ignoring the specifics of tabular node features. Indeed, fully leveraging the specifics\nof tabular node features is difficult for these datasets, since feature types are not explicitly provided\nwith the data. From these examples, it becomes clear that the effectiveness of graph machine learning\nmodels on graphs with heterogeneous node features remains under-explored.\nOne more downside of existing popular GNN benchmarks is that they often do not provide realistic\nand meaningful prediction tasks. For instance, the most popular task in current academic graph ML\nis predicting paper subject areas in citation networks. However, it can be done better by analyzing"}, {"title": "3 TabGraphs: a benchmark of graphs with tabular node features", "content": "In this section, we introduce our new benchmark of graph datasets with heterogeneous tabular\nnode features. Our datasets cover the setting of transductive node property prediction (either node\nclassification or node regression), which is the most common setting in modern graph machine\nlearning and can be used to model many applications where tabular data appears. Some of these\ndatasets were adapted from open sources (in this case, we either modified node features or added\nrelational information to the datasets), while others are entirely new. Below, we briefly describe\nour datasets. A more detailed discussion, including information about the sources of data, the\npreprocessing steps, and the presented node features, can be found in Appendix A.1. Note that in\nall our graphs, the edges are based on external information (e.g., inter-sample interactions, activity\nsimilarity, physical connections) rather than feature similarity, thus providing additional information\nfor learning that is otherwise unavailable to models.\ntolokers-tab This dataset is based on the data provided by the Toloka crowdsourcing platform\n(Likhobaba et al., 2023). The nodes represent tolokers (workers) who perform work for customers,\nand they are connected by an edge if they have worked on the same task. The task is to predict which\ntolokers have been banned in one of the projects.\nquestions-tab This dataset is based on the data from a question-answering website. The nodes\nrepresent users who post questions or leave answers on the site, and two users are connected by a\ndirected edge if one of them has answered the other's question. The task is to predict which users\nremained active on the website (i.e., were not deleted or blocked).\ncity-reviews This is a fraud detection dataset collected from a review service of organizations in\ntwo major cities. The nodes are users who leave ratings and post comments about various places, and\nthey are connected with an edge if they have left reviews for the same organizations. The task is to\npredict whether a user leaves fraudulent reviews.\nbrowser-games This dataset is collected from an online game platform. The nodes represent\nbrowser games that are developed and uploaded by various independent publishers, and they are\nconnected with an edge if they are frequently played by the same users during a specific period of\ntime. The task is to predict the categories of games."}, {"title": "4 Simple model modifications", "content": "Standard models for tabular machine learning cannot leverage information provided by the graph\nstructure available in the data, while standard models for graph machine learning can struggle to\nefficiently use heterogeneous node features. Thus, both approaches can be suboptimal for learning on\ngraphs with heterogeneous tabular node features. However, one can apply simple modifications to\nthese models that can make tabular ML models graph-aware and enable graph ML models to better\nhandle heterogeneous node features. Note that, while the modifications discussed in this section\nare quite simple, they were overlooked in previous works on learning on graphs with tabular node\nfeatures, which focused on designing much more complicated models without comparing them to\nsimple baselines."}, {"title": "4.1 Making tabular models graph-aware", "content": "A simple approach to make models that cannot explicitly process graphs perform better on graph-\nstructured data is to augment node features with information obtained from the node's neighborhood\nin the graph. One way to do this is to aggregate the features of the node's (possibly multi-hop)\nneighbors and add this aggregated information to the node's original features. This method was\npopularized in modern graph machine learning literature by Wu et al. (2019). Their approach (SGC)\naggregates features from the node's neighborhood by several passes of a standard graph convolution\n(Kipf & Welling, 2016) and uses these features instead of the original ones. We modify this approach\nto make it more suitable for heterogeneous features. In particular, we compute different kinds of\nfeature statistics (such as mean, maximum, and minimum values) over the 1-hop neighborhood of\neach node and, together with the node degree, append them to the original features. Thus, the new\nfeatures of each node contain the information about its neighborhood in the graph. We refer to this\nprocedure as Neighborhood Feature Aggregation (NFA), since it mainly augments node features\nwith information about its neighbors' features, and describe it in more detail in Appendix B.1. Note\nthat this approach is very scalable, as it only requires a single pass over the graph edges to compute\nadditional features for all nodes.\nOther approaches to augmenting node features using graph structure are possible, for example, extend-\ning node features with information about local substructures in the graph or with node embeddings\nlearned in an unsupervised way, such as DeepWalk (Perozzi et al., 2014) (see Appendix B.1 for more\ndetails). We experimented with some of these approaches and found that using DeepWalk node\nembeddings as additional node features provides significant performance gains on city-roads-M\nand city-roads-L datasets. Thus, we use these node embeddings as additional features in all our\nexperiments on these two datasets. One more important advantage of such feature augmentation\napproaches is that they allow tabular models to take advantage of unlabeled nodes in the graph, which\nare otherwise not used by these models, in contrast to GNNs."}, {"title": "4.2 Making GNNs work better with heterogeneous features", "content": "The main problem of heterogeneous features for standard neural networks is the presence of numerical\nfeatures. Even when preprocessed with transformations such as standard scaling, min-max scaling, or\nquantile transformation to standard normal or uniform distribution, these features still often cannot be\nused by neural networks as effectively as by decision trees (see Appendix B.2 for a discussion of this).\nHowever, Gorishniy et al. (2022) have recently proposed specialized numerical feature embeddings\nthat can often improve the processing of numerical features by neural networks. This technique adds\na learnable module that transforms numerical features into embeddings that are more suitable as input\nfor neural networks. In particular, Periodic-Linear-ReLU (PLR) numerical feature embeddings\ntend to significantly improve the performance of neural networks working with numerical features,\nsee Appendix B.2. However, this technique was never used with GNNs before. In our experiments,\nwe apply PLR embeddings for training GNNs on graphs with heterogeneous node features."}, {"title": "5 Experiments", "content": "In this section, we describe our experiments on the proposed TabGraphs benchmark. The details of\nour experimental setup and hyperparameter tuning for different models are provided in Appendix D."}, {"title": "5.1 Models", "content": "Simple baseline As a simple baseline, we use a ResNet-like model: an MLP with skip-connections\n(He et al., 2016) and layer normalization (Ba et al., 2016). This model does not have any information\nabout the graph structure and operates on nodes as independent samples (we call such models\ngraph-agnostic). This model also does not have any specific design for working with tabular features.\nTabular models We consider the three most popular implementations of GBDT: XGBoost (Chen &\nGuestrin, 2016), LightGBM (Ke et al., 2017), and CatBoost (Prokhorenkova et al., 2018). Further, we\nconsider two recently proposed deep learning models for tabular data. One is MLP-PLR (Gorishniy\net al., 2022), a simple MLP augmented with PLR numerical feature embeddings. It has been shown\nby Gorishniy et al. (2022) that this model outperforms many other tabular deep learning methods.\nAnother is TabR-PLR (Gorishniy et al., 2024), which is a retrieval-augmented model. TabR-PLR also\nuses PLR embeddings for numerical features processing, although it uses a simplified version of them\ncalled lite (see Appendix B.2 for a detailed discussion), as is done in the original implementation of\nthe model (Gorishniy et al., 2024). Note that all models discussed above are graph-agnostic.\nTo investigate how effectively graph structure can be used in combination with tabular models, we\nalso experiment with the proposed NFA strategy for augmenting node features with information about\nthe features of 1-hop neighbors in the graph, as described in Section 4.1. In particular, we provide\nsuch an augmentation for LightGBM, an efficient implementation of GBDT, and MLP-PLR, a simple\nyet strong neural baseline. We denote these models with -NFA suffix. Comparing the performance of\nstandard models and their versions with graph-augmented node features is one way to see if graph\ninformation is helpful for the task.\nGraph deep learning models We also consider several representative GNN architectures. First,\nwe use GCN (Kipf & Welling, 2016) and GraphSAGE (Hamilton et al., 2017) as simple classical\nGNN models. For GraphSAGE, we use the version with the mean aggregation function, and we do\nnot use the neighbor sampling technique proposed in the original paper, instead training the model on\na full graph, like all other GNNs in our experiments. Further, we use two GNNs with attention-based\nneighborhood aggregation functions: GAT (Veli\u010dkovi\u0107 et al., 2017) and Graph Transformer (GT)\n(Shi et al., 2020). Note that GT is a local graph transformer, i.e., each node only attends to its\nneighbors in the graph (in contrast to global graph transformers, in which each node attends to\nall other nodes in the graph, and which are thus not instances of the standard MPNN framework).\nWe equip all 4 considered GNNs with skip-connections and layer normalization, which we found\nimportant for stability and strong performance. We add a two-layer MLP with the GELU activation\nfunction (Hendrycks & Gimpel, 2016) after every neighborhood aggregation block in GNNs. Our\ngraph models are implemented in the same codebase as ResNet we simply swap each residual\nblock of ResNet with a residual neighborhood aggregation block of the selected GNN architecture.\nThus, comparing the performance of ResNet and GNNs is one more way to see if graph information\nis helpful for the task. Further, for all the considered GNNs, we experiment with their versions\naugmented with PLR embeddings, as described in Section 4.2 we denote these models with -PLR\nsuffix (we do not use these model modifications for the hm-prices dataset, since it does not contain\nnumerical features).\nSpecialized models We also use two recently proposed methods designed specifically for learning\non graphs with heterogeneous tabular node features: BGNN (Ivanov & Prokhorenkova, 2021) and\nEBBS (Chen et al., 2022)."}, {"title": "5.2 Results", "content": "In this subsection, we compare and analyze the performance of all the models on the proposed\ndatasets. The results for classification and regression datasets are provided in Table 2.\nFirst, we note that our simplest baseline ResNet achieves worse results than GBDTs and neural tabular\nlearning models on all the proposed datasets. This shows that our datasets indeed have meaningful\ntabular features, and methods designed specifically for tabular data outperform a simple deep learning\napproach.\nSecond, all the considered GNNs outperform ResNet on the proposed graph datasets, with the only\nexception of GT on the questions-tab dataset. Since our ResNet and GNNs are implemented"}, {"title": "6 Conclusion", "content": "To conclude, we introduce TabGraphs, a benchmark for learning on graphs with heterogeneous tabular\nnode features, which covers various industrial applications and includes graphs with diverse properties\nand meaningful prediction tasks. Using the proposed benchmark, we evaluate a large set of models,\nincluding standard baselines and advanced neural methods for both tabular and graph-structured\ndata. Our experiments show that several previously overlooked model modifications, such as node\nfeature augmentation based on graph neighborhood for graph-agnostic tabular models or numerical\nfeature embeddings for GNNs, allow one to achieve the best performance on such data. Based on\nour empirical study, we provide insights and tips for researchers and practitioners in both tabular\nand graph machine learning domains. We hope that the proposed datasets will contribute to further\ndevelopments in these fields by encouraging the use of graph ML methods for tabular data and by\nproviding an alternative testbed for evaluating models for learning on graph-structured data."}, {"title": "A The TabGraphs benchmark details", "content": "A.1 Datasets descriptions\nIn this section, we provide more detailed descriptions of the TabGraphs datasets. The instruction on\nhow to download the datasets can be found in our repository. In most of our datasets, the features\ncome with their names, which are stored in our data files (the exceptions are the city-reviews,\nbrowser-games, web-fraud, and web-traffic datasets, for which the features are anonymized).\nNote that none of the proposed datasets contain any personal information.\ntolokers-tab This is a new version of the tolokers dataset from Platonov et al. (2023b). It\nis based on the data from the Toloka crowdsourcing platform (Likhobaba et al., 2023). The nodes\nrepresent tolokers (workers) and they are connected by an edge if they have worked on the same\ntask within one of several projects. The task is to predict which tolokers have been banned in\none of the projects. For this dataset, we kept the task and graph from the previous version, but\nreplaced the processed node features with unprocessed ones. The new node features include various\nperformance statistics of workers, such as the number of approved assignments and the number\nof skipped assignments (numerical features), as well as worker's profile information, such as their\neducation level (categorical feature).\nquestions-tab This is a new version of the dataset questions from Platonov et al. (2023b). It\nis based on the data from a question-answering website. Here, nodes represent users, and a directed\nedge (u, v) connects users u and v if user u answered a question posted by user v. The task is to\npredict which users remained active on the website (i.e., were not deleted or blocked). For this\ndataset, we kept the task and graph from the previous version (except we provide directed edges, in\ncontrast to the previous version of the dataset in which the graph was converted to an undirected one\nand no information about the original edge directions was provided), but replaced the node features\nto make them heterogeneous. The original version of this dataset used bag of word embeddings\nrepresentations of user descriptions as node features, while our features are based on the activity\nof users on the website, such as articles count, achievements count, subscribers count, categories\nsubscriptions count, rating (numerical features), as well as their profile information, such as what city\nthe user is from (categorical feature), whether the user has a profile description, whether the user has\nfilled the education field, whether the user has left a contact URL (binary features). Note that these\nnew features are much more predictive of the target, as demonstrated by much better performance\nachieved by models on the new version of the dataset compared to the previous one.\ncity-reviews This dataset is obtained from the logs of a review service. It represents the\ninteractions between users of the service and various organizations located in two major cities. The\norganizations are visited and rated by users, so the dataset is originally bipartite and contains entities\nof these two types. Thus, we transform it by projecting to the part of users. Let $P \\in \\{0,1\\}^{m\\times n}$\nbe a binary adjacency matrix of users and organizations, where m is the number of organizations,\nn is the number of users, and $p_{ij}$ denotes whether a user j has left a review for an organization\ni. Then, $B = P^T P \\in \\mathbb{R}^{n\\times n}$ corresponds to the weighted adjacency matrix of users, where $b_{ij}$\nis the dot product of columns i and j in P. Here, the more common rated organizations there are\nfor two users, the greater the weight of the connection between them. Further, we obtain a binary\nadjacency matrix $A \\in \\{0,1\\}^{n\\times n}$ of users with $a_{ij} = [b_{ij} \\geq y]$ by applying a threshold y to the\nweights $b_{ij}$. The resulting graph is undirected, and the task is to predict whether a user is a fraudster.\nThe features include the information about the user profile, such as the length of the nickname in\ncharacters (numerical feature) and whether the profile information is hidden (binary feature), as well\nas their behavior on the websites and other services, such as the share of negative ratings among user\nreviews, the number of search queries, the number of different categories in search queries (numerical\nfeatures), the type of browser (categorical feature).\nbrowser-games This dataset is obtained from the logs of an online game platform and represents\nthe network of browser games that are created and hosted by various game developers. These games\nare played by users, so the dataset is originally bipartite and contains entities of these two types.\nThus, we transform it by projecting to the part of games. Let $P \\in \\{0,1\\}^{m\\times n}$ be a binary adjacency\nmatrix of users and games, where m is the number of users, n is the number of games, and $P_{ij}$\ndenotes whether a user i has played a game j. Then, $B = P^T P \\in \\mathbb{R}^{n\\times n}$ corresponds to the weighted"}, {"title": "A.2 Datasets properties", "content": "A key characteristic of our benchmark is its diversity. As described above, our graphs come from\ndifferent domains and have different prediction tasks. Their edges are also constructed in different\nways (based on user interactions, activity similarity, physical connections, etc.). However, the\nproposed datasets also differ in many other ways. Some properties of our graphs are presented\nin Table 1 (see below for the details on how the provided statistics are defined). First, note that\nthe sizes of our datasets range from 11K to 3M nodes. The smaller graphs can be suitable for\ncompute-intensive models, while the larger graphs can provide a moderate scaling challenge. The\naverage degree of our graphs also varies significantly most graphs have the average degree\nranging from tens to hundreds, which is larger than the average degrees of most datasets used in\npresent-day graph ML research; however, we also have some sparser graphs such as questions-tab,\ncity-roads-M, city-roads-L. The average distance between two nodes in our graphs varies from\n2.23 for browser-games to 194 for city-roads-L, and graph diameter (maximum distance) varies\nbetween 7 for browser-games to 553 for city-roads-L. Further, we report the values of clustering\ncoefficients which show how typical are closed node triplets for the graph. In the literature, there are\ntwo definitions of clustering coefficients (Boccaletti et al., 2014): the global clustering coefficient and\nthe average local clustering coefficient. We have graphs where the clustering coefficients are high or\nalmost zero, and graphs where global and local clustering coefficients significantly disagree (which\nis possible for graphs with imbalanced degree distributions). The degree assortativity coefficient is\ndefined as the Pearson correlation coefficient of degrees among pairs of linked nodes. Most of our\ngraphs have negative degree assortativity, which means that nodes tend to connect to other nodes with\ndissimilar degrees, while for the city-roads-M and city-roads-L datasets the degree assortativity\nis positive and large.\nFurther, let us discuss the graph-label relationships in our datasets. To measure the similarity of labels\nof connected nodes for regression datasets, we use target assortativity the Pearson correlation\ncoefficient of target values between pairs of connected nodes. For instance, for the city-roads-M\nand city-roads-L datasets, the target assortativity is positive and quite large, which shows that\nnodes tend to connect to other nodes with similar target values, while for the web-traffic dataset,\nthe target assortativity is negative. For classification datasets, the similarity of neighbors' labels\nis usually called homophily: in homophilous datasets, nodes tend to connect to nodes of the same\nclass. We use adjusted homophily to characterize homophily level, as it has been shown to have\nmore desirable properties than other homophily measures used in the literature (Platonov et al.,\n2023a). In Table 1, we refer to adjusted homophily as target assortativity, as it is a special case of the\nassortativity coefficient (Newman, 2003). We can see that for the city-reviews dataset, adjusted\nhomophily is positive and quite large, which shows that this dataset is homophilous, while for the\nrest of our classification datasets, adjusted homophily is close to zero. One more characteristic to\ndescribe graph-label relationships is label informativeness (Platonov et al., 2023a). It shows how\nmuch information about the label of a given node can be derived from the label of a neighbor node. In\nour datasets, label informativeness correlates with adjusted homophily, which is typical for real-world\nlabeled graphs.\nNote that some of our graphs contain unlabeled nodes. This is a typical situation for industry and\nscience, yet it is underrepresented in graph machine learning benchmarks. Unlabeled nodes give an"}, {"title": "B Simple modifications for tabular models and GNNs", "content": "B.1 Feature augmentation based on graph structure\nThere are a number of possible approaches to augmenting node features with graph-based information\nin order to provide graph-agnostic models with some information about the graph.\nNeighborhood Feature Aggregation (NFA) First, we describe our Neighborhood Feature Ag-\ngregation (NFA) technique. This technique augments node features with the information about\nfeatures of the node's neighbors in the graph. As we show in our experiments, this technique often\nsignificantly improves the performance of graph-agnostic tabular models. We consider the set of"}, {"title": "B.2 Embeddings for numerical features", "content": "In practice, neural networks are good at handling data with binary features and with categorical\nfeatures transformed to binary features by one-hot encoding (when input features are immediately\nfollowed by a linear transformation, as is typically the case in neural networks, the model essentially\nlearns an embedding for each binary feature). However, numerical features can be a problem for\nneural networks. Typical neural network building blocks represent (mostly) smooth functions, and\nthus neural networks cannot sharply vary their predictions based on changes in numerical features.\nHowever, in many cases, such smooth decisions are suboptimal. In contrast, decision trees, which are\nthe basis of GBDT, select thresholds for values of numerical features and make hard discontinuous\ndecisions based on them. This strategy often fits tabular data with rich numerical features better, and\nthis is often considered to be one of the main reasons why neural networks still cannot consistently\noutperform GBDT models on tabular data, despite the large amount of research resources spent on\nimproving neural networks for tabular data (Shwartz-Ziv & Armon, 2022; Grinsztajn et al., 2022;\nMcElfresh et al., 2023).\nRecently, Gorishniy et al. (2022) proposed several specialized techniques for embedding numerical\nfeatures to improve the performance of neural networks on tabular data. These techniques introduce\nlearnable modules that transform numerical features into embeddings - arguably a more natural\nform of inputs for neural networks. Of several methods proposed in the original paper, we focus on\nPeriodic-Linear-ReLU (PLR) numerical feature embeddings, since according to the experiments\nfrom the original paper they provide the best average performance. This method is inspired by\nperiodic activation functions that have recently found success in computer vision (Mildenhall et al.,\n2021; Tancik et al., 2020; Sitzmann et al., 2020; Li et al., 2021). The PLR embedder first passes a\nnumerical feature through several sine and cosine functions with different (learnable) frequencies\nobtaining a periodic embedding, and then passes this embedding through a linear layer and a ReLU\nactivation function obtaining the final numerical feature embedding that becomes the input to the\nmain model (see the original paper of Gorishniy et al. (2022) for more details)."}, {"title": "C Additional related work: graph machine learning for relational databases", "content": "A field of research related to our work is machine learning for relational databases. This field also\ndeals with a combination of tabular and graph data", "relational\ndatabase": "a collection of tables", "graph": "a graph\nwith multiple types of nodes and/or edges. The nodes correspond to table entries (with nodes from\ndifferent tables having different types) and edges correspond to relationships between entries of\ndifferent tables (with different types of edges representing different kinds of relationships). Due\nto this possibility of representing relational databases as a heterogeneous graph, there have been\nseveral works applying graph machine learning methods to relational databases (Schlichtkrull et al.,\n2018; Cvitkovic, 2020; Krivosheev et al., 2020; Bai et al., 2021; Vogel et al., 2023; Zahradn\u00edk et al.,\n2023; Hilprecht et al., 2023; Zhang et al., 2023). Regarding publicly available datasets, for a long\ntime the main source of open RDB data for machine learning was the Prague Relational Learning\nRepository (Motl & Schulte, 2015). However, some of its datasets are synthetic, most of its datasets\nare quite small, and not all of its tasks are realistic. Further, on some of its tasks, even quite simple\nmodels achieve nearly perfect performance, and thus these tasks cannot be used for meaningful model\ncomparison (Wang et al."}]}