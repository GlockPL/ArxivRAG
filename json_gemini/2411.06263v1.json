{"title": "Federated Split Learning for Human Activity Recognition with Differential Privacy", "authors": ["Josue Ndeko", "Shaba Shaon", "Aubrey Beal", "Avimanyu Sahoo", "Dinh C. Nguyen"], "abstract": "This paper proposes a novel intelligent human activity recognition (HAR) framework based on a new design of Federated Split Learning (FSL) with Differential Privacy (DP) over edge networks. Our FSL-DP framework leverages both accelerometer and gyroscope data, achieving significant im- provements in HAR accuracy. The evaluation includes a detailed comparison between traditional Federated Learning (FL) and our FSL framework, showing that the FSL framework outperforms FL models in both accuracy and loss metrics. Additionally, we examine the privacy-performance trade-off under different data settings in the DP mechanism, highlighting the balance between privacy guarantees and model accuracy. The results also indicate that our FSL framework achieves faster communication times per training round compared to traditional FL, further emphasizing its efficiency and effectiveness. This work provides valuable insight and a novel framework which was tested on a real-life dataset.", "sections": [{"title": "I. INTRODUCTION", "content": "In recent years, the widespread adoption of mobile devices has led to a growing interest in human activity recognition (HAR) using wearable sensors [1], [2]. This area has emerged as a novel research focus within artificial intelligence and pattern recognition [3]. This field intersects artificial intelli- gence and pattern recognition, with applications ranging from sports activity detection and smart homes to health support and beyond. By leveraging sensor data from devices like smartphones and wearables, HAR enables real-time monitor- ing and analysis of human activities. This capability is piv- otal in enhancing personalized healthcare, improving athletic performance analysis, and developing intelligent environments that adapt to users' needs seamlessly. Modern HAR systems, particularly those powered by deep learning techniques, offer several advantages over traditional methods [4]. They can automatically learn relevant features from raw sensor data, eliminating the need for manual feature engineering and thus improving accuracy and robustness. Moreover, deep learning models can handle complex, nonlinear relationships in the data, leading to better generalization across different users and activity types. Furthermore, HAR contributes to the ad- vancement of human-computer interaction by enabling natural interfaces that respond to users' physical actions and gestures. This technology has the potential to revolutionize how users interact with devices and how devices understand and re- spond to human behavior in real-world settings. However, the widespread adoption of HAR is constrained by challenges such as privacy concerns associated with personal data collected from users' devices. Addressing these challenges requires innovative approaches in data anonymization, secure data storage, and compliance with regulations like General Data Protection Regulation (GDPR).\nFederated Learning (FL) concepts have risen as potential solutions to privacy concerns. FL is a collaborative framework that takes advantage of user devices' enhanced computational power. In FL multiple users collaboratively train a machine learning model without sharing their personal data with the server, or other users. A global model is downloaded from the server by all user devices, then the users individually train the model using their local data, then finally the server averages the parameters of all users to form a new global model. This process is then repeated until the desired performance has been reached and shared with the client devices. Some models require many parameters which signify a potential limitation of FL.\nNew concepts involving Split Learning (SL) have been de- veloped as potential solutions to the limitations of FL [5], [6]. In SL, a model is initiated and then split into two models, the client-side model and the server-side model. Clients download their side of the model, which involves the input layer and preceding layers until the pre-defined cut layer. The Server- side model contains the rest of the model starting from the cut layer, to the output layer. Training begins at the client-side model with the client's raw data until the cut layer is reached, the intermediate activations at this layer are then sent to the server to continue training. The server then trains its model up to the output layer, computes the loss, and starts back-propagation which will be completed on the client's side.\nFederated Split Learning (FSL) has been developed to take advantage of both FL's collaborative framework and SL's splitting structure. The training process in FSL is similar to that in SL until the completion of the backward pass. The weights of the client models are then aggregated to produce a new global client model, and the server-side weights are updated based on the computed gradients. This method efficiently trains a deep neural network model while preserving user data privacy."}, {"title": "A. Related Works", "content": "Several state-of-the-art techniques have introduced feature extraction and selection methods for HAR using traditional machine learning classifiers. With the emergence and ad- vancement of high computational resources, deep learning techniques have become widely used in various HAR systems. These techniques efficiently retrieve features and perform classification, significantly enhancing the performance of HAR systems. Recently, FL has been studied to further improve the performance of HAR. Specifically, the authors in [7] evaluated FL for training a HAR classifier and compared it to centralized learning using two models-a deep neural network and softmax regression\u2014trained on synthetic and real-world datasets. In [8], an FL system was proposed for HAR, with a perceptive extraction network for feature extraction to improve recognition accuracy. The study in [9] proposed a prototype- guided FL framework for HAR that addresses data issues in real-world environments by efficiently decoupling represen- tation and classifier in heterogeneous FL settings. The work in [10] proposed an FL system for HAR that dynamically learns personalized models by capturing user relationships and iteratively merging model layers based on user similarity. As reported in [11], the authors designed a 2-dimensional FL framework to address data insufficiency and security in cyber-physical-social systems.\nRecently, SL and SFL has been recently studied in various IoT domains. The authors in [12] comprehensively surveyed the emerging applications of FL in IoT networks, exploring FL's potential across various IoT services: data sharing, of- floading, caching, attack detection, localization, mobile crowd-sensing, and privacy as well as security enhancements. In [13], the authors proposed an efficient SL framework for resource-constrained edge computing systems, combining the benefits of FL and SL. The authors in [14] introduced a modified SL system with an autoencoder and adaptive threshold mecha- nism, reducing communication and computation overhead in an IoT system with minimal performance loss. The work in [15] proposed adaptive resource-aware SL for efficient IoT model training, accelerating processes on resource-constrained devices and minimizing straggler effects with device-targeted split points, while adapting to varying network throughput and computing resources. A dynamic FSL framework was devel- oped by the researchers in [16] to address data and resource heterogeneity in IoT, enhancing efficiency through resource- aware split computing of deep neural networks and dynamic clustering of training participants. Despite these research ef- forts, the application of FSL has not been investigated for HAR in the literature. Exploring FSL in HAR is crucial as it paves the way for scalable and efficient deployment of personalized activity recognition systems in IoT and wearable technology, catering to individualized user needs while respecting data privacy and security."}, {"title": "B. Our Key Contributions", "content": "In this paper, we propose a novel collaborative privacy- enhanced HAR framework through the development of an FSL algorithm with differential privacy (DP) [17] in edge computing. The contributions of this paper are summarized as follows.\n1) We present an FSL algorithm for collaborative privacy- enhanced HAR in edge computing. In this framework, edge devices (EDs) are involved to partially perform for- ward propagation and backpropagation on the client-side models. The remaining workload of the model training will be executed at the edge server through the server- side model, which allows for mitigating the computation burden on resource-constrained EDs.\n2) Moreover, to enhance privacy protection for activations, a DP mechanism is integrated at EDs to add a mask to hidden the shared information against potential data threats.\n3) We conduct simulations on real-life HAR datasets to verify the feasibility of our FSL method. Implementation results demonstrate that our approach can significantly enhance the training performance with much lower train- ing latency, compared with traditional training methods. We also validates the impacts of DP in HAR performance under different training settings."}, {"title": "C. Paper Structure", "content": "The rest of the paper is structured as follows. In Section II, we present our system model, detailing the architecture and components of our proposed system. Section III presents simulations and performance evaluations for the proposed FSL approach under different network settings. Finally, Section IV concludes the paper."}, {"title": "II. SYSTEM MODEL", "content": "This paper considers a collaborative HAR system with a set of edge devices (EDs) denoted by N and a single edge server, as illustrated in Fig. 1. Each Mobile Device (MD) n \u2208 N is assumed to be equipped with a wearable sensor attached to the human body and synchronized to emit human motion data. For example, a smartwatch is typically equipped with an accelerometer and a gyroscope which could generate a signal vector at a time. A multidimensional time series containing signal vectors can be used to represent the sensing data over time in HAR.\nThere are two key components in our collaborative HAR.\n\u2022 EDs: We assume that each client can perform forward propagation and backpropagation on the client-side model using their powerful MD. The local dataset Dn, contain- ing Dn data samples owned by edge device n, is repre- sented as $D_n = \\{(X_{n,k}, Y_{n,k})\\}_{k=1}^{D_n}$, where $X_{n,k} \\in \\mathbb{R}^{d \\times 1}$ denotes the k-th input data in the local dataset Dn and $Y_{n,k} \\in \\mathbb{R}^{1}$ is the label of $I_{n,k}$. Consequently, the total dataset D, with D = \u2211n=1 Dn data samples, is denoted by D = \u222aN 1 Dn. The client-side model is represented as $W_c \\in \\mathbb{R}^{u \\times 1}$, where u denotes the dimension of the client-side model's parameters."}, {"title": "B. Proposed FSL Design for Collaborative HAR", "content": "This section presents the proposed FSL design for a col- laborative HAR system. The foundational idea of FSL begins with the server initializing a Machine Learning (ML) model, splitting the model via layer-wise model partitioning, and then sharing the client-side model with all participating MDs. Training is performed next until the model converges. For device n, for training round t \u2208 T = {1, 2, ..., T}, the FSL training process consists of the following stages.\n1) Client-side Model Forward Propagation: First, forward propagation is performed on the ED for the client-side model. Precisely, a mini-batch BnC Dn containing b data samples is randomly selected from its local dataset. The input data and labels of the mini-batch are represented by $X_n(t) \\in \\mathbb{R}^{b \\times d}$ and $y_n(t) \\in \\mathbb{R}^{b \\times 1}$, respectively, while Wc,n(t \u2212 1) denotes the client-side model of edge device n. After processing the input data from the mini-batch through the client-side model, the cut layer produces the intermediate activations. Intermediate activations from the ED n are given as the following equation where activation's dimension per data sample is denoted by q:\n$S_n(t) = f (X_n(t); W_{c,n}(t \u2212 1)) \\in \\mathbb{R}^{b \\times q}$ (1)\n2) Activations Transmission: The intermediate activations Sn(t) produced by the client-side models of all partic- ipating EDs \u2200n \u2208 N are then shared with the server over a wireless channel. To further enhance privacy for FSL training, we integrate a Gaussian-based local Renyi DP mechanism G(0, an) for EDs. Each ED n enforces DP to its activations by adding a certain amount of noise defined by a pair of parameters (En, an), which provides a strong criterion for privacy preservation. Here, an > 0 is the distinguishable bound of all outputs on neighboring datasets x,x' in a database X, and an represents the probability of the event that the ratio of the probabilities for two adjacent datasets x,x' cannot be bounded by en after adding a privacy-preserving mechanism. With an arbitrarily given an, a smaller en gives a less distinguishability of neighboring datasets and thus increases the privacy preservation but degrades the training performance, e.g., accuracy. Based on our RDP analysis in previous work [17], we consider the standard deviation of the Gaussian noises, denoted as on, which is defined as\n$\\sigma_n = \\frac{H}{\\sqrt{e^n - z}}$ (2)\nwhere H, z are constant. Hence, the activations of each ED n after being enforced by DP can be expressed as\n$S_n(t) \\leftarrow S_n(t) + \\zeta_n$, (3)\nwhich is then shared with the server for the model forward process.\n3) Server-side Model Forward and Back Propagation: After receiving the DP-enforced activations from the cut layer of ED n,\u2200n \u2208 N, the server computes the remaining layers of the model and reaches an output. This marks the conclusion of the forward propagation process. The server then starts the Back Propagation process by calculating the loss using the prediction and the true output. The server continues to compute backpropagation for its layers until the cut layer is reached. The server-side model is expressed as:\n$W_s(t) = [w_{s,l_s} (t); w_{s,l_{s-1}} (t); ... ; w_s^1(t)]$ (4)\nwhere w is the k-th layer in the server-side model and ls signifies the number of server-side model layers. Mathematically, the gradients of the server-side model are expressed as:\n$G_s(t) = \\begin{bmatrix} g_{s,l_s}(t) \\\\ g_{s,l_{s-1}}(t) \\\\  \\\\ g_s^1(t) \\end{bmatrix}$ (5)"}, {"title": "4) Client-side Model Back Propagation", "content": "At this stage, each ED uses the received activations to complete the parameter update of its client-side model. The client-side gradients for edge device n can be calculated as:\n$G_{c,n}(t) = \\begin{bmatrix} g_{c,l_e}^n(t) \\\\ g_{c,l_{e-1}}^n(t) \\\\  \\\\ g_{c_1}^n(t) \\end{bmatrix}$ (6)\nwhere ghi represents the gradients of the client-side k- th layer of edge device n. The final step for this stage is to update the client-side model. Thus, for ED n, the client-side model is updated using\n$W_{c,n}(t) \\leftarrow W_{c,n}(t \u2212 1) \u2013 \\eta_c G_{c,n}(t)$ (7)\n5) Aggregation of client model weights: The final stage of the FSL training process is aggregating the client model weights through federated averaging.\n$W_c(t+1) = \\frac{1}{N} \\sum_{N\\in N} W_{c,n}(t)$ (8)"}, {"title": "III. SIMULATIONS AND EVALUATION", "content": "Dataset Preparation: For our simulations, we used the UCI HAR Dataset [18]. The dataset contains 6 regular activities, more specifically 3 dynamic activities (going upstairs, going downstairs, walking) and 3 static activities (standing, sitting, laying). The data was obtained from 30 subjects executing the daily activities listed above. During their performance, the subjects were wearing a Samsung Galaxy S II, using the smartphone's accelerometer and gyroscope, three-axial linear acceleration and three-axial angular velocity at a constant rate of 50 Hz were collected. The collectors then manually labeled the data using the video-recorded. Finalizing their dataset, they randomly divided the data into two sets where 70% generates the training data, and 30% the test data. Noise filters were then applied to the sensor data, which were then sampled in fixed-width sliding windows of 2.56 sec and 50% overlap (128 readings/window)\nTraining Settings: We carried out experiments on a server equipped with a Core(TM) i7-8700 CPU and 16 GB of RAM. Our algorithm was constructed using PyTorch 2.2.0, and we evaluated the latency per round using Python's time module. To evaluate the algorithm, we ran tests using different e values, and we also conducted schemes using different data settings. Finally, we compared our FSL model's performance with that of the traditional FL models.\nWe employed the UCI HAR Dataset for human activity recognition, ensuring a comprehensive evaluation. The dataset includes accelerometer and gyroscope data from 30 subjects, performing six activities: walking, walking upstairs, walking downstairs, sitting, standing, and laying. We used this dataset to evaluate the performance of our FSL framework. We used the LSTM architecture with 100 units and a dropout layer on the client-side network, a dense layer with 100 units, and a softmax output layer on the server-side."}, {"title": "B. Simulation Results", "content": "We examine the performance of our FSL model without DP and using various e values when using DP. Fig. 2a shows the prominent privacy trade-off as the e value decreases. Without DP, our model achieves the highest accuracy, indicating that the absence of noise addition allows for more precise model updates. As the e value decreases, the amount of noise added increases, which degrades our model's accuracy. This is no- ticeably true when \u20ac = 50 which caused about a 22% decrease in accuracy compared to the performance without DP, and as \u20ac = 80 cause a lower decrease of about 12%. In fig. 2b we observe that DP has a similar effect to our loss value.\nWe also examine the accuracy performance of our model under different data settings when \u20ac = 80. Fig. 3a displays the effect, on accuracy, of using only accelerometer or only gyroscope data as compared to both in our FSL model. Specifically, we notice the following trends: a) when using both gyroscope and accelerometer data, our model achieves the highest accuracy which is a 73.39% increase from accuracy using gyroscope data only, and a 15.50% increase from using accelerometer data only. b) As shown in fig. 3b, our model reached a lower loss value as we used both gyroscope and accelerometer data, indicating more precise predictions and better overall performance.\nIn addition, we examine the performance of traditional FL model as compare to our FSL framework. Figs. 4a and 4b showcase that our framework outperforms traditional FL models. specifically, our FSL framework achieves higher ac- curacy and lower loss values across 100 rounds of training, demonstrating improved learning efficiency.\nMoreover, we compare the communication time required to train each round between the proposed FSL and traditional FL methods. As shown in Fig. 5, our FSL framework demonstrates quicker training times per round in more than 95% of the training rounds. This efficiency in communication time highlights the effectiveness of the FSL framework in reducing latency and improving overall training speed compared to traditional FL. For example, at the global round of 100, our proposed FSL scheme only requires around 65 seconds to complete the entire federated model training, while the FL scheme needs 123 seconds, showing around 100% training time savings offered by our algorithm design."}, {"title": "IV. CONCLUSION", "content": "This paper has proposed a novel FSL approach for human activity recognition. We have developed a framework using an LSTM model to accurately detect human activity using real-life sensor data. We also implemented a DP mechanism to further enhance privacy protection for activations shared with the server. Simulation results indicate that our proposed FSL framework has outperformed existing FL approaches with better accuracy and loss. Our model also achieved significant latency reductions, with over 100% lower training time for some rounds compared to traditional FL methods."}]}