{"title": "Towards Trustworthy Knowledge Graph Reasoning: An Uncertainty Aware Perspective", "authors": ["Bo Ni", "Yu Wang", "Lu Cheng", "Erik Blasch", "Tyler Derr"], "abstract": "Recently, Knowledge Graphs (KGs) have been successfully coupled with Large Language Models (LLMs) to mitigate their hallucinations and enhance their reasoning capability, e.g., KG-based retrieval-augmented framework. However, current KG-LLM frameworks lack rigorous uncertainty estimation, limiting their reliable deployment in high-stakes applications Directly incorporating uncertainty quantification into KG-LLM frameworks presents challenges due to their complex architectures and the intricate interactions between the knowledge graph and language model components. To address this crucial gap, we propose a new trustworthy KG-LLM framework, UAG (Uncertainty Aware Knowledge-Graph Reasoning), which incorporates uncertainty quantification into the KG-LLM framework. We design an uncertainty-aware multi-step reasoning framework that leverages conformal prediction to provide a theoretical guarantee on the prediction set. To manage the error rate of the multi-step process, we additionally introduce an error rate control module to adjust the error rate within the individual components. Extensive experiments show that UAG can achieve any pre-defined coverage rate while reducing the prediction set/interval size by 40% on average over the baselines.", "sections": [{"title": "Introduction", "content": "Large Language Models (LLMs) have recently achieved impressive performance in question-answering tasks due to their unprecedented capability of understanding complex linguistic patterns and generating coherent responses (OpenAI et al. 2024; Huang and Chang 2022). However, LLM's frequent hallucination (Huang et al. 2023b; M\u00fcndler et al. 2024) and lack of reasoning capability (Lin, Hilton, and Evans 2021; Fu et al. 2023) still limit their practical usage when facing domain-specific or complex questions.\nTo address the challenges, recently knowledge graphs (KGs) have been coupled with LLMs to provide factual data and contextual grounding, enhancing the reliability and accuracy of their responses. Knowledge graphs, as a form of structural knowledge representation consisting of factual triplets, provide two unique advantages to overcome the aforementioned challenges of LLMs. First, the additional information retrieved from KGs is directly extracted from"}, {"title": "Preliminiaries", "content": "Conformal Prediction (CP) is a distribution-free model-agnostic approach for uncertainty quantification. By calibrating the model prediction on a held-out calibration set, CP produces sets of predicted intervals that contain the ground-truth labels with a user-specified error rate \u03b1 (Angelopoulos and Bates 2021; Shafer and Vovk 2008).\nWithout loss of generality, considering the ith sample (xi, yi) with xi being the input feature and yi being the corresponding ground-truth output, we denote the calibration set as Dcal = {(xi, Yi)}^n_{i=1}. Conformal Prediction (CP) guarantees the error rate of the prediction set with the following steps.\n\u2022 Define non-conformal score: A heuristic-based uncertainty estimation function S:X \u00d7 Y \u2192 R is defined to calculate the non-conformal score si = S(xi, Yi), which measures the uncertainty of the prediction yi given the input xi with larger score indicating worse agreement between xi and Yi.\n\u2022 Compute the quantile: CP then calculates the non-conformal score for every input-output pair in the calibration set to obtain Scal = {$i}^n_{i=1} and further compute the conformal score q^{S, Deal}_{a} as the [(n+1)(1-a) quantile of the calibration scores Scal:\nq^{S,Deal}_{a} = Quant({S(x, y)|(x, y) \u2208 Dcal}, \u300c(n + 1)(1 \u2212 a)])\n(1)"}, {"title": "Learn Then Test (LTT)", "content": "Recently, the Learn Then Test (LTT) framework (Angelopoulos et al. 2021) was introduced that extends conformal prediction to manage the expectation of any loss functions. Specifically, it is achieved by approaching the hyper-parameter selection as a multiple-hypothesis testing problem. Next, we formally introduce the LTT framework.\nFormally, let L\u03bb: Y \u00d7 \u0177 \u2192 R be any loss function with a hyperparameter configuration \u03bb\u2208 A. Notably, A could be multi-dimensional. Let a \u2208 R be the user-defined error rate for Lx (i.e., E(Lx) \u2264 a). Using the calibration set Dcal, LTT then computes a set of valid configurations Avalid \u2208 A that satisfies\nP(sup E[Lx | Dcal] \u2264 \u03b1 | \u2200\u03bb \u2208 Avalid) \u2265 1 \u2212 \u03b4\n(2)\nwhere \u03b4 represents the desired confidence level on the selection of configurations. Intuitively, d is the probability that the valid configurations we identify will truly meet our error guarantee. To calibrate the configurations on Dcal, we define the null hypothesis H\u1ed3 : E[L\u03bb] > a for each \u03bb \u2208 A and calculate a super-uniform p-value px using concentration inequalities. Then we can leverage any family-wise error rate (FWER) controlling algorithms to identify the non-rejected configurations Avalid.\nTheorem 1 (Learn Then Test (Angelopoulos et al. 2021)). Suppose px is super-uniform under H\u2200\u05d2 \u220b A. Let T be any FWER-controlling algorithm at level d. Then Avalid satisfies Eq. (2)."}, {"title": "Problem Definition", "content": "Given a knowledge graph G = (E, R), where E is the set of entities and R is the set of relations. The edges in the knowledge graph are represented as triplets (i.e., (es, r,eo) \u2208 G) with es \u2208 & being the head entity, r \u2208 R being the relation, and e\u2208 E being the tail entity. For the rest of this paper, without further specification, we denote the calligraphic font as sets (such as X, Y) and capital letters as functions (such as S, F, for score functions and loss functions, respectively).\nDefinition 1 (Uncertainty quantification for multi-hop knowledge graph question answering). Given a question q in natural language with the ground-truth answer set being Vtest, assuming the user specified error rates as a and 8, the task here is to derive a algorithm CA hyper-parametrized by \u5165, which takes the input Xtest and predicts the output set test that satisfies:\nP(P (\u00ea\u2208 Vtest, V\u00ea \u2208 Cx(Xtest) | Dcal) \u2265 1 \u2212 a) \u2265 1 \u2212 \u03b4\n(3)\nRemark 1. The error rate & controls the probability that the inner probabilistic guarantee holds. Specifically, it ensures that with at least (1 \u2013 8) confidence, the prediction set"}, {"title": "Method", "content": "UAG is a multi-hop knowledge graph reasoning framework that incorporates uncertainty quantification (UQ) into its reasoning process. It consists of three components: UQ-aware candidate retriever, UQ-aware candidate evaluator, and Global Error Rate Controller, as shown in Figure 2. Given a user-specified query, the UQ-aware Candidate Retriever selectively retrieves neighboring nodes and formulates reasoning paths to ensure a pre-defined error rate. The UQ-aware Candidate Evaluator then reasons over the retrieved candidates and reasoning paths to produce the final answer set. Subsequently, to avoid overly conservative predictions, the Global Error Rate Controller adjusts individual error rates by calibrating them using the LTT framework introduced in the previous section."}, {"title": "UQ-aware Candidate Retriever", "content": "The first component of our UAG framework is the candidate retriever, which retrieves candidate entities from the knowledge graph based on the question or current paths. Previous research shows that multi-hop graph traversal frameworks improve LLM reasoning and answer faithfulness (Wang et al. 2024; Sun et al. 2023). However, these frameworks typically use heuristics like Top-K candidate selection based on textual similarity, which lack a theoretical basis and cannot ensure a consistent error rate, making them unreliable for high-stakes scenarios. To address this, we incorporate uncertainty quantification into graph traversal, replacing heuristic selection with error-bounded selection. Specifically, we apply conform prediction to two steps: retrieving candidate paths and candidate neighbors."}, {"title": "Retrieving Candidate Path", "content": "Formally, for each traversed path currently ending at node v, we update the breadth-first-search tree queue by following:\n{$s|ss\u2208N(v), S1 (Q||(||=ri), j) <q^{S1, Dal}_{\u03b1}}\n(4)\nwhere N(v) is the neighborhood set of v, Q||(||=ri) are the concatenated relations traversed so far in the path with starting passages being Q, rj is the current relation between the entities v and s, and S\u2081 is the uncertainty estimation score for the candidate retriever. In our context, we choose S\u2081 to be the textual similarity between two textual passages."}, {"title": "Retrieving Candidate Neighbor", "content": "While traversing the graph, we also want to determine if the current node should be added into the candidate set. As a result, we add the following set to the prediction set while visiting node v:\n{$s|ss \u2208 N(v), S1 (Q, lori) <q^{S1, Dal}_{\u03b1}}\n(5)\nEq. (4) differs from Eq. (5) in their focus during the traversal process. Eq. (4) focuses on identifying the likely answer paths by assessing the similarity between the traversed path and the current relation. In contrast, Eq. (5) evaluates if the entire path up to the current relation sufficiently answers the query by comparing it to the initial query. This distinction allows for dynamic adjustment of the traversal process and candidate set based on the evolving query context and encountered relations."}, {"title": "UQ-aware Candidate Evaluator", "content": "The second component of UAG is an uncertainty-aware candidate evaluator based on large language models (LLMs). Directly prompting the language model has demonstrated significant advantages in knowledge graph question answering (KGQA) tasks, particularly due to its ability to generate diverse and contextually relevant answers. However, this open-ended generation approach lacks any theoretical guarantees on the correctness of the answers, which can lead to unreliable outputs. Conversely, the retrieved candidates are constrained by a predefined error rate, ensuring the reliability of the prediction set. However, this constraint often results in overestimating the prediction set size, encompassing a broader range of potential answers than necessary.\nThus, to harness the strengths of both approaches, we introduce a calibration process that optimizes the balance between them. By aligning the similarity between the LLM-generated candidates and the retrieved set, we aim to refine the prediction set size while maintaining a bounded error rate. This ensures that the final output is not only theoretically sound but also practically effective.\nTo calculate the final answer set, we define the non-conformal score for the evaluator by taking the similarity between the retrieved answers and the generated answers. Formally, given a set of candidates C and retrieved reasoning paths P, let I be the LLM generation function. Then, the final answer set is defined as follows:\n{a | a \u2208 C | S\u2081 (\u03b1, \u03a6(P)) <q^{S1, Deal}_{\u03b1}}(6)"}, {"title": "Global Error Rate Controller", "content": "Since UAG involves multiple components, directly applying the user-defined error rate a to Eqs. (4)-(6) may not achieve the desired error rate. Errors from the knowledge graph traversal can propagate to the inference stage, potentially exceeding the user-specified tolerance unless errors across components are perfectly correlated.\nTo address this issue, we leverage the LTT framework (Section 2) to find the best error rate for each component by treating their error rates as hyper parameters. Let X = (\u03b11,\u03b12, \u03b13) \u2208 (0, 1]\u00b3 be the individual error rates for each component. The finite search space A can be represented as the Cartesian product of these sets for a1, a2, and 03:\nA = {(a1, a2, a3) | A1, A2, A3 \u2208 {h, 2h, ..., 1}}\nwhere h is the hyper parameter to control the size of the search space, bounded by 0 and 1. For each A\u2208 A, we compute a valid p-value px for the null hypothesis H\u00e0: E[Lx] > a by computing the concentration inequality on the calibration dataset Dcal.\nTheorem 2 (Binomial tail bound p-values (Quach et al. 2023)). Let Binom(n, a) denote a binomial random variable with sample size n and success probability a. Then Px = P(Binom(n, a) \u2264 \nE^{Lx}_{Dcal}) is a valid p-value for\nH\u1ed3 : E[L] > \u03b1.\nIn our context, we define the loss function F as the error rate in the system. Let T be a FWER-controlling algorithm\u00b9 T : (P,R) \u2192 P' where P denotes a family of p-values that we want to control based on a given error rate. Then we can identify a set of configurations Avalid C A that satisfies Eq. (2) by taking T({px | \u03bb \u2208 \u039b}, \u03b4) as Avalid.\nTheorem 3 (Coverage Guarantee of UAG). If \u03bb\u2208 Avalid, then Eq. (3) is satisfied.\nProof. From Eq. (2), \u2200\u00c0 \u2208 Avalid,\nP (E[Lx | Dcal] < \u03b1) \u2265 1 \u2013 \u03b4\nIn the context of KGQA,\nLx = 1{\u2260\u00ea \u2208 Cx(X): \u00ea \u2208 Eans}\nNote that,\nE[Lx | Dcal] = E[1{\u2260\u00ea \u2208 Cx(X): \u00ea \u2208 Eans}|Dcal]\n= P (\u0110\u00ea \u2208 Cx(X): \u00ea \u2208 Eans|Dcal)\nSubstitute E[Lx | Dcal] in eq. 2, then we have\nP (P (\u00ea \u2208 Cx(X): \u00ea \u2208 Eans|Dcal) < a) \u2265 1 \u2013 \u03b4\nThis is equivalent to\nP (P (\u00ea \u2208 Eans, V\u00ea \u2208 Cx(Xtest) | Dcal) \u2265 1 \u2212 a) \u2265 1 \u2013 \u03b4\n(7)\nIn addition, to minimize the returned set size to make the prediction most useful to the users, we use the validation set to select the configuration A\u2208 Avalid with the smallest average set size."}, {"title": "Experiment", "content": "In this section, we conduct extensive experiments on two widely used multi-hop KGQA datasets (Luo et al. 2024; Sun et al. 2023; Lan et al. 2022). Our experiments are designed to rigorously evaluate the uncertainty quantification performance of UAG, employing standard UQ metrics to assess its effectiveness against state-of-the-art baselines. We provide detailed analysis to identify key strength and potential area of improvements. Additional experiments comparing UAG to standard KGQA methods are further detailed in the ablation studies."}, {"title": "Datasets", "content": "We evaluate UAG with two widely used benchmark dataset for KGQA: WebQuestionSP (WebQSP) (Yih et al. 2016) and Complex WebQuestions (CWQ) (Talmor and Berant 2018). WebQSP contains up to 2 hop questions, and CWQ contains up to 4 hop questions. Additionally, Freebase (Bollacker et al. 2008) is used as the underlying knowledge graph for both datasets. The dataset statistics are presented in Table 1. Note that for calibration, we use the training partition."}, {"title": "Evaluation Metrics", "content": "Compared to traditional KGQA tasks that typically rely on evaluation metrics such as hits@1 (Luo et al. 2024), our approach focuses on measuring the uncertainty quantification of the methods. To this end, we use empirical coverage rate and average prediction set size as the key metrics to measure the accuracy and efficiency of the models, respectively (Angelopoulos and Bates 2021). We aim to provide insights into how well the various methods balance accuracy with the efficiency of its predictions. The details of these metrics are the following:\n\u2022 ECR (Empirical Coverage Rate): This measures how well the uncertainty quantification model satisfies the error rate. For knowledge graphs, we consider the accuracy of the prediction set.\n\u2022 APSS (Average Prediction Set Size): This evaluates the effectiveness of the uncertainty quantification model, with smaller average prediction set sizes indicating greater efficiency in selecting the most likely answers."}, {"title": "Baselines", "content": "We compare UAG with the following uncertainty quantification baselines. Because there has been no existing work considering uncertainty quantification in the KG-LLM paradigm, we include the previously proposed existing LLM-based uncertainty quantification methods as baselines.\n\u2022 Top-K: Non-CP method without coverage guarantee. It includes responses with the K highest probabilities for each question in the test set (Huang et al. 2023a).\n\u2022 Standard Split Conformal Prediction (SplitCP). Standard conformal prediction (Shafer and Vovk 2008) where we follow the framework outlined in previous work for its application on language models (Ye et al. 2024).\n\u2022 Conformal Language Modeling (CLM) A logit-based CP method that utilizes the general risk control framework directly on the output of the large language models (Quach et al. 2023)."}, {"title": "Case Study", "content": "We demonstrate the real-life implications and usefulness of UAG through a detailed case study. Specifically, we select an instance among the samples where existing KGQA methods produce mispredicted or incomplete answers and analyze how UAG overcomes these challenges.\nAs shown in Table 5, the ground truth to the question What are the religions practiced in Indonesia? includes four distinct answers, showcasing the diversity of religious practices in the country. However, directly prompting the question to the language models results in only a single answer-Islam-even when using the state-of-the-art KGQA model. This outcome poses a significant threat to fairness and may introduce bias, as it fails to capture the full spectrum of religious diversity in Indonesia. UAG addresses this challenge by incorporating risk level control, which allows for a more comprehensive and balanced prediction.\nThe prediction set is constructed by setting the risk tolerance level to 0.2. While the resulting set includes several additional related answers\u2014The Religion of Java, a reference to a popular book by anthropologist Clifford Geertz focused on the religion of Java (an island of Indonesia), and The Language of the Gods, an alias for Sanskrit, the ancient classical language of Hinduism-it successfully covers all four ground truth answers. This ensures a more accurate and inclusive representation of the answer to the given question, thereby reducing the risk of bias and enhancing the trustworthiness of the predictions."}, {"title": "Ablation Studies", "content": "We conduct ablation studies on UAG to comprehensively evaluate its effectiveness and robustness. Specifically, we first examine how UAG compares to state-of-the-art KGQA methods, as robust performance on standard KGQA tasks is critical in daily uses. Additionally, we investigate the effects of pre-training and different similarity measures on the model performance."}, {"title": "Comparing to KGQA Methods", "content": "Here we compare our method to state of the art KGQA methods (Luo et al. 2024) by selecting the top responses from UAG given a fixed error rate a. We select a = 0.2 for the purpose of testing. Our result is shown in Table 2. Overall, the table highlights that our model attains performance on par with current state-of-the-art for the traditional benchmark KGQA tasks (that utilize Hits@1 for evaluation). This underscores the robust reasoning capabilities of the UAG and the efficiency of the candidate retrieval process."}, {"title": "Effects of LM Pre-Training", "content": "As shown in Figure 4(a), pre-training the sentence transformers (specifically for graph traversal) significantly reduces the size of the prediction set. This improvement is likely because fine-tuning at this stage enhances the quality of the initial traversal on the knowledge graph, leading to more accurate retrieval of answers. This process is analogous to better indexing in the context of Retrieval-Augmented Generation (RAG). However, when we pre-trained the large language model backbone, we did not observe a substantial improvement. This outcome aligns with previous findings suggesting that fine-tuning large language models can increase model uncertainty (Ye et al. 2024)."}, {"title": "Alternative Similarity Measures", "content": "We also experimented with alternative methods for measuring textual similarity, specifically S\u2081 as defined in Eq. 4. As shown in Figure 4(b), we found that using cosine similarity significantly improves prediction efficiency while maintaining the user-defined error rate compared to L1 similarity. This improvement can be attributed to cosine similarity's focus on the angle between vectors, which makes it less sensitive to variations in vector magnitudes. This is particularly helpful in high-dimensional spaces, as it allows cosine similarity to more effectively capture semantic relationships between text representations."}, {"title": "Ablation Studies Discussion", "content": "Overall, UAG demonstrates strong performance compared to existing KGQA methods even though it was not specifically designed for the traditional setting. Through the ablation studies, we observed that while UAG benefits significantly from fine-tuning sentence transformers for graph traversal, the pre-training of large language models does not yield substantial gains, which we leave further investigation on finding improvements with fine-tuning LLMs as one future work in this direction. Lastly, through a case study we were able to more deeply understand the benefits of the proposed trustworthy knowledge graph reasoning framework."}, {"title": "Related Work", "content": "Knowledge Graph Question Answering. Knowledge graph-based question answering (KGQA) has been a pivotal research topic in natural language processing due to its potential to leverage structured information for precise and interpretable answers. Traditional embedding-based methods transform entities and relations into a continuous embedding space and reason over these embeddings to produce answers (He et al. 2021; Xie et al. 2022; Wang et al. 2021). Recently, the advent of large language models (LLMs) has shifted attention towards retrieval-augmented generation, where the reasoning capabilities of LLMs are enhanced by retrieving relevant information from knowledge graphs. By retrieving structured data from the knowledge graph, LLMs can generate more accurate and contextually relevant answers. For instance, Luo et al. jointly fine-tuned a language model to generate both a relation plan and an answer by utilizing the retrieved reasoning paths (Luo et al. 2024). Similarly, Sun et al. and Wang et al. introduced novel LLM-guided graph traversal methods, enabling more efficient and effective navigation during the retrieval process (Sun et al. 2023; Wang et al. 2024).\nLLM Uncertainty Quantification. Uncertainty quantification has emerged as a critical research area for developing trustworthy AI systems, especially in contexts where decision-making involves significant risks. Recently, growing attention has been directed towards modeling uncertainty in large language models (LLMs). Conformal Language Models (CLM) extended the general risk control framework, allowing for the control of error rates in text generation while providing a more fine-grained level of confidence in the generated content (Quach et al. 2023). LofreeCP further extended conformal prediction to black-box language models by approximating the non-conformity score with repeated prompting, thereby improving the reliability of LLM outputs (Su et al. 2024). Additionally, researchers have proposed novel approaches to quantify uncertainty in retrieval-augmented generation by calibrating uncertainty across both the retrieval and generation processes with parameter tuning (Rouzrokh et al. 2024; Li et al. 2024)."}, {"title": "Conclusion", "content": "In this paper, we tackle the challenge of uncertainty quantification in knowledge graph question answering by integrating conformal prediction with KG-LLM models. Our architecture leverages the Learn Then Test (LTT) framework for multi-step calibration, delivering reliable results that meet pre-defined error rates while maintaining practical prediction set sizes. Extensive experiments show our method's effectiveness in balancing accuracy and uncertainty, making it suitable for real-world applications.\nWhile our focus is on knowledge graphs, this approach can be extend to open-domain QA, although challenges remain due to the lack of structured graph properties in such settings. Future work can explore these adaptations and ensure robust uncertainty quantification across various tasks."}, {"title": "Appendix", "content": "This technical appendix provides additional details and insights to complement the main paper. The rest of the appendix is organized as follows: Section 1 presents the notations used throughout the paper. Section 2 presents the pseudocode for UAG. Section 3 includes the hardware specs and the hyper-parameter settings. Section 4 includes the quantitative experiment results of UAG. Finally, Section 5 includes the Python implementation of UAG."}, {"title": "Notations", "content": "We present the commonly used notations throughout the paper and this technical supplementary material in table 4."}, {"title": "Pseudo-code", "content": "We present the pseudo-code of UAG in Algorithm 1. We follow the notation and equations used throughout our paper. The algorithm begins by initializing an empty Candidate Set C to store potential answers and a Search Queue Q for the BFS(breadth-first-search). The BFS process is guided by the calibarated scores which serve as the threshold for adding neighboring nodes to Q.\nOnce all candidate nodes are collected, the algorithm filters them further by comparing the candidates with the llm generated answers (P), ensuring that only those satisfying the condition in Equation (6) are included in the final answer set A. Finally, the algorithm returns the set A as the output."}, {"title": "Implementation Details", "content": "All of our experiments are conducted on a machine running Ubuntu 22.04.4 LTS with one GeForce RTX 4090 (24 GB VRAM) GPU and Intel i9 CPU with 64 GB RAM."}, {"title": "Sentence Transformers", "content": "Model. In Eqs. (4)-(6), UAG's S\u2081 calculation requires first mapping the textual data into the embedding space. To this end, we employ SBERT as the encoder. Specifically, we use all-MiniLM-L6-v2 model as the backbone model for pre-training."}, {"title": "Fine-Tuning.", "content": "We leveraged fine-tuning to adapt the model to the dataset space. To ensure consistency with the traversal process, we fine-tuned the backbone SBERT using the CosineSimilarityLoss\u00b3 , where the input pairs are (Q||||),j)."}, {"title": "Hyper-parameters", "content": "The key hyper-parameters for SBERT fine-tuning are the following:\nbatch_size: 32\nscale: 20.0\nsimilarity_fct: 'cos_sim'\nepochs: 40\nevaluation_steps: 0\nevaluator: NoneType\nmax_grad_norm: 1\noptimizer.class: AdamW\nlr: 2e-05\nscheduler: WarmupLinear\nsteps_per_epoch: null\nwarmup_steps: 79636\nweight_decay: 0.01"}, {"title": "UAG", "content": "Hyper-parameters. For UAG, the main hyper-parameter is h, which controls the search space of the parameters, and \u03b4, which controls the inner probability of the optimization target. In our experiments, we set h to be different for the searc of a1, a2, and a3 to speed up the process. We set h\u2081 = 0.3, h2 = 0.3, and h3 = 0.1. In reality, smaller value would result in more fine-grained optimization. For d, we set the value to be 0.05.\nAnother critical consideration is the choice of Family-Wise Error Rate (FWER) control algorithm. Traditional methods, such as the Bonferroni correction, yield valid but often conservative prediction sets, leading to excessively broad predictions. To mitigate this, we adopted a heuristic approach where larger p-values are associated with better prediction coverage. This strategy allows us to effectively manage the search space frontier without significantly lowering the threshold (e.g.,). Specifically, by selecting the top p-value, we can optimize the size of the prediction set. In our experiments, we opted to select the top p-value, corresponding to setting n = 1."}]}