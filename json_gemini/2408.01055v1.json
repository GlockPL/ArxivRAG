{"title": "LLM as Runtime Error Handler: A Promising Pathway to Adaptive Self-Healing of Software Systems", "authors": ["Zhensu Sun", "Haotian Zhu", "Bowen Xu", "Xiaoning Du", "Li Li", "David Lo"], "abstract": "Unanticipated runtime errors, lacking predefined handlers, can abruptly terminate execution and lead to severe consequences, such as data loss or system crashes. Despite extensive efforts to identify potential errors during the development phase, such unanticipated errors remain a challenge to to be entirely eliminated, making the runtime mitigation measurements still indispensable to minimize their impact. Automated self-healing techniques, such as reusing existing handlers, have been investigated to reduce the loss coming through with the execution termination. However, the usability of existing methods is retained by their predefined heuristic rules and they fail to handle diverse runtime errors adaptively. Recently, the advent of Large Language Models (LLMs) has opened new avenues for addressing this problem. Inspired by their remarkable capabilities in understanding and generating code, we propose to deal with the runtime errors in a real-time manner. The runtime context, such as error messages and program states, can be exploited to produce corresponding exception handling strategies with extended diversity and quality.\nMotivated by our idea, we propose HEALER, the first LLM-assisted self-healing framework for handling runtime errors. When an unexpected, thus unhandled, runtime error occurs, HEALER will be activated to generate a piece of error-handling code with the help of its internal LLM and the code will be executed inside the runtime environment owned by the framework to obtain a rectified program state from which the program should continue its execution. Our exploratory study evaluates the performance of HEALER using four different code benchmarks and three state-of-the-art LLMs, GPT-3.5, GPT-4, and CodeQwen-7B. Results show that, without the need for any fine-tuning, GPT-4 can successfully help programs recover from 72.8% of runtime errors, highlighting the potential of LLMs in handling runtime errors. Moreover, in our experiments, HEALER introduces negligible latency in normal code execution (less than 1 ms per program) and an acceptable overload for error handling (less than 4 seconds for the LLM to generate the handling code), making it a suitable real-time reactor.", "sections": [{"title": "INTRODUCTION", "content": "Runtime error handling [55] is an essential component of software reliability engineering, requiring developers to be able to anticipate possible errors and prepare corresponding error handlers beforehand. Unanticipated runtime errors, being lack of corresponding handlers and naturally uncaught, can lead to program crashes, exposure of sensitive information, or other severe consequences [1]. For example, the infamous Heartbleed bug in OpenSSL [14] was caused by an unanticipated out-of-bound error, which allows attackers to request a server to return a chunk of its own memory.\nTo prevent such errors, substantial efforts have been dedicated to identifying possible errors in the source code through techniques such as software testing and verification [28, 61]. However, identifying all possible runtime errors and offering them corresponding exception handlers remains a challenging and often impractical goal.\nGiven the near inevitability of unanticipated runtime errors, dynamic countermeasures are demanded to minimize their impact when they really happen. This requirement has led to the development of self-healing systems [19, 41], where the one at the program level aims to automatically recover from abnormal program states and restore program functionality as much as possible. Notably, to heal a program execution is not to patch the code against an error but to revise the runtime state, such as variable values and environment configurations, to recover the program execution. A successful healing should not only proceed the execution without termination, but also correct the runtime state so that the rest of the execution can continue meaningfully. The core challenge for a self-healing system is that the specific errors and their locations are unknown in advance, requiring the system to react in real time. Consequently, it relies on predefined heuristic strategies, such as rolling back to a checkpoint [10] and matching existing error handlers [20]. Although self-healing systems have been widely studied for decades, limited by their rule-based nature, these strategies are not adaptive enough to deal with diverse errors that impede their adoption. A large-scale industry practitioner study highlights that one of the main challenges encountered with engineering such systems is the complexity of defining the adaptation rules [56].\nIdeally, a self-healing system might employ human developers to be always on call and manually correct the state according to the error that occurred, which is impractical for real-world applications. Recently, the emergence of Large Language Models (LLMs) has introduced new opportunities to revolutionize this field. LLMs have shown remarkable performance in code-related tasks [21]. For instance, AlphaCode2 [3] has outperformed 85% of human participants in a programming competition, showcasing impressive capabilities in understanding both source code and natural language."}, {"title": "BACKGROUND AND RELATED WORK", "content": "In this section, we first recap the error-handling mechanisms in modern programming languages and then introduce the research on self-healing systems and the use of LLMs for code, respectively."}, {"title": "Error Handling in Modern Programming Languages", "content": "Modern programming languages typically incorporate built-in error-handling mechanisms, with the try-catch block being a core component. This construct consists of a try block, which encloses code that might throw exceptions, and a catch block, which defines the error handler for exceptions thrown within the try block\u00b9. When developers anticipate an exception in a specific code segment, they can encapsulate that segment within a try block and implement an error handler within the catch block. If an exception occurs inside the try block, execution jumps to the catch block where the error handler is executed. Once the error handler completes without terminating the program, the program continues running the code following the try-catch block.\nFor errors occurring in code segments not enclosed by a try-catch block, the runtime environment halts execution and searches for an error handler by traversing up the call stack. This search continues until a suitable exception handler is found or the top of the call stack is reached. If no matching handler is found, the program typically terminates, often generating an error message and stack trace to assist with debugging, which can be seen as the default error handler. When this default error handler is triggered, the program's normal"}, {"title": "Self-healing Systems", "content": "Self-healing systems, as defined by Ghosh et al. [19], are designed to \u201crecover from the abnormal (or \"unhealthy\") state and return to the normative (\u201chealthy\u201d) state, and function as it was prior to disruption\". It is a long-standing research area aimed at enhancing system reliability and availability, often classified as a subclass of fault-tolerant [40] or self-adaptive [34] systems. The self-healing process involves three primary steps: (1) Maintenance of health: ensuring the normal functionality of the system, such as preparing redundant components [23]; (2) Detection of system failure: identifying abnormal states within the system, such as monitoring [17]; and (3) Recovery from failure: transforming a system state containing one or more errors (and possibly faults) into a state without detected errors [6].\nIn this paper, the proposed method is a recovery step at program level. For this step, various methods have been proposed, including restarting [9], rolling back to a checkpoint [10], trying alternative methods [11], modifying input [33], reusing existing error handlers [20], preparing default error handlers [43], or combining multiple strategies [12]. The core idea behind these studies is to heuristically construct a set of fixed recovery strategies and apply them when some specific errors occur, which is typically rule-based. For example, Failure-Oblivious Computing [43] ignores invalid memory writes (such as out-of-bounds writes and null dereferences) and generates default values for invalid memory reads. Gu et al. [20] handle errors by synthesizing handlers in two ways: (1) transforming the type of the error to fit existing error handlers and (2) returning early with a default value. Carzaniga et al. [10] propose restoring the application state to a previously set checkpoint and then selecting and executing an equivalent sequence of operations that might avoid the error. While effective in certain scenarios, their rule-based nature limits their generalization and adaptability. To the best of our knowledge, this is the first work to demonstrate that LLMs can effectively achieve the recovery, creating a new technical pathway for this long-standing research field (widely studied for decades). Compared with these rule-based methods, LLMs can dynamically adapt to a wide range of scenarios by understanding the source code context and natural language error messages, making them more flexible and generalizable."}, {"title": "Large Language Models for Code", "content": "Typically, LLMs are Transformer [51] models pre-trained on large corpora of textual data, including books, research papers, web contents, etc. These models have gained great popularity because of their versatility and effectiveness, and software engineering is no exception. Recent studies [21, 60] have highlighted the capability of LLMs in code recognition, understanding, and generation, etc. Numerous LLMs designed for code have been proposed, such as CodeGen [35], StarCoder [29], and CodeLlama [44]. These models are pre-trained on code corpora to predict the next token, making"}, {"title": "Why not LLM-based APR?", "content": "Recently, LLM has been widely applied in Automate Program Repair (APR) and shows promising performance. For example, Xia and Zhang [58] reveal that the LLM-based APR method is able to achieve the new state-of-the-art in program repair performance. This naturally raises the question: if we can statically fix the root causes of runtime errors using LLMs, why do we still need LLMs to recover from failures?\nFirstly, it's important to clarify that LLM-assisted runtime error handling is not a replacement for LLM-based APR but rather a supplement. APR requires locating the bug first, which has long been a challenge in both the research community and industrial practices. Undetected bugs, even those that are easy to fix if identified, can escape APR tools and lead to dangerous errors during runtime. In contrast, when a runtime error occurs, its location is immediately available, allowing the handler to create a specific context-aware solution. We thus argue that LLM-assisted runtime error handling creates an additional layer of defense in software robustness, serving as a last-resort mechanism to prevent the consequences of unhandled errors.\nTo support this argument, we experimentally investigate this supplementary relationship between LLM-based APR and LLM-based runtime error handling on an APR benchmark, DebugBench [49],"}, {"title": "PROPOSED FRAMEWORK", "content": "In this section, we introduce HEALER, the first error-handling framework that leverages LLMs to handle unanticipated runtime errors. We begin with an overview of the framework, followed by detailed descriptions of its main components, prompt strategy, and a proof-of-conception implementation for Python."}, {"title": "Overview", "content": "HEALER is an error-handling framework designed to handle unanticipated runtime errors during program execution. We first define the problem and then introduce the workflow of HEALER."}, {"title": "Requirements:", "content": "As described in Section 1, unanticipated runtime errors are almost inevitable in practice, necessitating a mechanism to recover the program from such errors when they really occur. A key assumption according to the nature of unanticipated runtime errors is the lack of prior knowledge about their occurrence, such as their location, preventing the pre-implementation of specific error handlers. Under this assumption, an effective error-handling mechanism must recover the program from the faulty state in real time, allowing it to continue executing its intended functionality. Specifically, a successful handling should satisfy the following requirements:"}, {"title": "Proceed the execution:", "content": "The execution session should not terminate due to the error and should continue executing its remaining code. This requirement alone is easy to achieve by simply ignoring the error. However, it leaves the faulty state unchanged, potentially causing unexpected behaviors in the remaining code."}, {"title": "Correct the program state:", "content": "The handling should correct the faulty state that caused the error, enabling the remaining code to execute with a correct initial state. For example, if the type of a variable is invalid and causes a type error, the handling should correct the type of the variable to the expected type. Notably, an incorrect program state could still proceed the execution, but it may lead to unexpected behaviors, such as wrong computing results, or even more severe errors."}, {"title": "Real-time response:", "content": "The handling should be completed within a reasonable time frame to avoid excessively blocking the execution, thus minimizing side effects."}, {"title": "Workflow:", "content": "HEALER acts as a default error handler for the program, which can be seen as a last resort for handling unanticipated runtime errors. It will be activated when a runtime error occurs without an available error handler. The framework handles the errors relying on an internal LLM, which generates a piece of code, named handling code by understanding the error context. The workflow of HEALER is illustrated in Figure 2. To ease the understanding, we assume the framework is applied for an interpreted programming language, such as Python and JavaScript, where the code is executed line by line, and the program state is inherently maintained. We discuss the application of HEALER for compiled languages in Section 6. Formally, consider a program P with n lines as P = {L1, L2, ..., Ln}. If an error E occurs at line Li without an available error handler, HEALER is activated. It first collects the error context, including the error message, the program state S, the entire code snippet, and the erroneous line, to construct a prompt. The internal LLM is then instructed with this prompt to generate a piece of handling code L'. This code L' is executed under the state S of the original program using an executor isolated from the original program environment. If the execution of L' is successful, the resulting program state S' is integrated back to the original program state, allowing the program to continue from line Li+1. Notably, although the state is corrected for the current session, the original program is not fixed and thus still needs to be reproduced and fixed in future development, which is beyond the scope of this paper. If unsuccessful, the program is terminated, and the error is reported, following traditional error handling mechanisms."}, {"title": "Main Components", "content": "HEALER consists of two main components: an LLM and an isolated executor. The former is used for generating the handling code given the error context, while the latter executes the handling code in an isolated environment and updates the program state of the original program."}, {"title": "Large Language Model:", "content": "The LLM inside HEALER needs to be capable of the error-handling task. As introduced in Section 2.3, LLMs trained with instruction tuning can understand and follow complex instructions. Using instruction-based LLMs, such as GPT-4 [2], we can prompt the LLM to generate handling code by providing proper prompts. We present our prompt strategy in Section 3.3. Moreover, the LLM can be further fine-tuned on a task-specific dataset to better align with the intention of the task. However, to the best of our knowledge, a decent dataset specifically for the error-handling task is currently unavailable. Although there are many human-crafted error handlers in open-source codebases, they do not consider the dynamic context of errors, especially the program state, and thus lack the knowledge of properly modifying the program state to recover from the error. To fill this gap, we create an instruction-tuning dataset to fine-tune the LLMs for the runtime error-handling task. We introduce and evaluate our dataset in Section 4.4 and Section 5.3, respectively."}, {"title": "Executor:", "content": "The handling code generated by the LLM needs to be executed to produce a new program state. However, directly executing the code in the original session can be risky, as the code generated by LLMs may contain malicious code or vulnerabilities [39, 59]. To mitigate potential security risks, HEALER adopts an executor that is isolated from the original program. It could be a new session, a sandbox, or a virtual machine, depending on the security level required by the system. The execution is not to re-run the original program from the beginning but to execute the handling code with the program state before the error occurs. Given an error at line Li and handling code L', the executor initializes its state with si\u22121 (the program state before the error) and then executes L'. If the handling code executes successfully, a new state s is produced. HEALER then updates the original program state to s and continues the execution of the original program from line Li+1."}, {"title": "Prompt Construction", "content": "The performance of LLMs heavily relies on the provided prompt [32]. In HEALER, the interaction between the LLM and HEALER is conversational, where HEALER first prompts its LLM with a system prompt and then a user prompt. The system prompt is a predefined instruction guiding the LLM's behavior, tone, or response style, while the user prompt is the input provided by the user during the conversation. The LLM does not respond to the system prompt but follows its instructions when it responds to the user prompt. In HEALER, the system prompt introduces the requirements and constraints of the error handling task, and the user prompt provides the context of the occurred error."}, {"title": "System Prompt.", "content": "The system prompt is structured into four parts: task description, goals, constraints, and examples. These four parts are concatenated to form the system prompt, which will be sent to the LLM as the first prompt in the conversation. In the"}, {"title": "User Prompt.", "content": "In addition to the source code, many runtime details can be collected, such as the error message, error location,"}, {"title": "Implementation", "content": "We implement HEALER for Python as a proof of concept, which is available in our artifacts. The implementation is to demonstrate the feasibility and effectiveness of HEALER, and it is not optimized for performance, security, or scalability, which would require further enhancement for practical use.\nHEALER is implemented as a code executor, accepting source code strings as input and executing them using the HEALER process. Upon receiving the source code, the implementation first instruments the code using Python's ast module, wrapping each statement in a try-except block. Notably, the statements inside loops are not wrapped to avoid the overhead of exception handling in each iteration. In the except block, the implementation uses a customized exception handler to handle the runtime errors. The customized handler follows the steps illustrated in Figure 2. Given a caught exception, the handler collects the error type and message from the exception object and the program state using Python's built-in functions, locals() and globals(), which respectively return a dictionary of all the local and global variables. The collected information is formatted into the user and system prompts based on the templates introduced in Section 3.3. It then interacts with the LLM through RESTful APIs, sending the prompts to the LLM server as HTTP requests and receiving the handling code as the response. Upon receiving the handling code, the handler starts a new Python session and executes the handling code using the exec() function, a built-in Python function for dynamically executing source code. The program state for exec() is initialized with the collected program state. If the handling code executes successfully, the implementation compares the new program state with the original to identify differences and integrates these differences into the original program's state. To prevent infinite loops or other malicious behaviors, the implementation enforces a 60-second timeout limit for the execution of the handling code."}, {"title": "EXPERIMENTAL SETUP", "content": "This section details the setup of our experiments, including benchmarks, large language models, the instruction tuning dataset, evaluation metrics, and implementation details. The rationale behind our set up is driven by answering the following four research questions:"}, {"title": "RQ1:", "content": "How effective is HEALER in handling runtime errors?"}, {"title": "RQ2:", "content": "How does the performance of HEALER vary in handling different types of runtime errors?"}, {"title": "RQ3:", "content": "How much performance of HEALER gained by instruction tuning?"}, {"title": "RQ4:", "content": "What is the overhead introduced by HEALER?"}, {"title": "Benchmarks", "content": "In these experiments, we focus on Python due to its popularity and robust support for dynamic code execution. We evaluate the performance of HEALER against runtime errors in three types of programs: (1) human-written code, (2) LLM-generated code, and (3) code with implanted bugs. To this end, we use four popular benchmarks: CodeNet for human-written code, HumanEval+ and MBPP+ for LLM-generated code, and DebugBench for code with implanted bugs.\nCodeNet [24] includes 4,053 programming challenges for various programming languages from the AIZU Online Judge [26] and AtCoder [4] platforms, each with multiple implementations submitted by distinct programmers. For each challenge, at least one test case is provided. We run the code snippets on our local machine with the provided test cases and keep the (code, test case) pairs that raise runtime errors. This process yields 228 instances.\nHumanEval+ and MBPP+ [31] are enhanced versions of HumanEval [13] and MBPP [5], benchmarks used to evaluate the performance of LLMs in code generation. They contain 164 and 400 Python coding tasks, respectively, each associated with several test cases In the paper of these two benchmarks, multiple LLMs are evaluated, and the code snippets generated during the evaluation are publicly available [15]. We reuse the code snippets generated by"}, {"title": "Large Language Models", "content": "In our experiments, we respectively evaluate the best-performing closed-source and open-source LLMs, GPT-4 [2] and CodeQwen [7], in the code generation task according to the EvalPlus leaderboard [31] (accessed on May 2024). Additionally, we include GPT-3.5 [37], which is the previous version of GPT-4, to compare the performance of the two versions. All models are pre-trained by their creators, and by default, we do not perform further training unless otherwise stated. Notably, as the ground truth, i.e., the handling code for each sample, does not exist in the benchmarks, potential data leakage issues are avoided."}, {"title": "Evaluation Metrics", "content": "In each benchmark, all code snippets raise runtime errors when executed with their associated test cases. The effectiveness of HEALER"}, {"title": "Instruction-tuning Dataset", "content": "We created an instruction-tuning dataset to fine-tune the LLMs for runtime error handling. It consists of 586 (prompt, handling code) pairs, where the prompt is constructed using the strategy described in Section 3.3 and the handling code leads to the CORRECT status. These instances are produced using samples from all benchmarks except the human-written benchmark, CodeNet, which is reserved as the test set for the fine-tuned LLMs. Specifically, we run GPT-3.5 and GPT-4 to handle the runtime errors in each instance from the selected benchmarks and record the handling code. For each CORRECT instance, we pair the prompt and its corresponding handling code as a sample in the dataset. This dataset will be used to answer RQ3 (Section 5.3) and is available in our artifacts to facilitate future research or applications."}, {"title": "Implementation Details", "content": "In our experiments, we use the OpenAI APIs to invoke GPT-3.5 (gpt-3.5-turbo-0125) and GPT-4 (gpt-4-turbo-2024-04-09) and the Huggingface Transformers library with PyTorch to implement CodeQwen (CodeQwen1.5-7B-Chat). The experiments for CodeQwen are conducted on a machine with 20 vCPU, 100GB RAM, and an NVIDIA GeForce RTX L20 GPU (48GB RAM). During inference, we use the default hyper-parameters for all models but set the maximum input length to 4,096 tokens for CodeQwen due to GPU memory limitations. This may result in input text truncation for CodeQwen, and we will discuss the potential impact of this truncation in Section 6.1."}, {"title": "RESULTS", "content": "In this section, we report our experimental results and answer the four research questions."}, {"title": "RQ1: Effectiveness of HEALER", "content": "This experiment assesses the effectiveness of HEALER by analyzing the execution outcomes of the instances in the benchmarks. For each benchmark, we execute each code snippet with its paired test case and respectively handle the runtime errors using the three LLMs, GPT-3.5, GPT-4, and CodeQwen, following the framework"}, {"title": "RQ2: Effects of Error Types", "content": "In RQ2, we investigate the performance of HEALER on different types of runtime errors. To be specific, we merge the instances of all the benchmarks and categorize them based on their error types. There are 12 types of runtime errors in total, but we analyze only those with more than 10 occurrences, combining the rest into the \"Others\" category. This resulted in 7 categories: TypeError, AttributeError, IndexError, ValueError, NameError, FileNotFoundError, and Others. Each category is accompanied by an example error message to facilitate understanding. All of them are common errors in Python programs and are frequently encountered in practice. We calculate the number and proportion of instances with CORRECT and PROCEED for each category across the three LLMs.\nAs revealed in Table 2, LLMs exhibit varying performance across different error types. For example, GPT-4 continues the execution for 88.1% of AttributeError instances and 80.9% of IndexError instances but only 50.0% of FileNotFoundError instances and 62.8% of ValueError instances. This suggests that the effectiveness of LLMs varies by error type, indicating that error type could be an important factor when applying HEALER. This observation implies that the reliability of error handling could be enhanced by applying HEALER selectively based on the error type.\nInterestingly, we find that different LLMs excel at handling different error types. For GPT-3.5, IndexError instances are the easiest to handle, with 55.2% of them free of interruption, while CodeQwen handles AttributeError best, with a 45.2% PROCEED. It suggests that the LLMs may have different capabilities in handling different"}, {"title": "RQ3: Impact of Fine-tuning", "content": "To answer RQ3, we fine-tune the LLMs to find out how much their performance could be improved. Two LLMs, GPT-3.5 and CodeQwen, are fine-tuned in this experiment, while GPT-4 is used as a reference as we do not have access to fine-tune it. The fine-tuning dataset is the instruction-tuning dataset introduced in Section 4.4, which contains 586 training samples. With this dataset, GPT-3.5 is fine-tuned via the commercial API provided by OpenAI, where the hyperparameters are automatically determined [36]. CodeQwen is fine-tuned on our machine using LoRA [22], a parameter-efficient"}, {"title": "RQ4: Overhead of HEALER", "content": "In RQ4, we evaluate the overhead introduced by HEALER when handling runtime errors. The overhead is divided into two parts: the overhead to normal program execution and the overhead during the error-handling process.\nTo determine the impact of HEALER on normal program execution, we test the overhead introduced by the try-catch blocks, the error-handling mechanism to trigger HEALER in our implementation. Specifically, we prepare two pieces of Python code: one containing an assignment statement and the other containing the same statement but wrapped in a try-catch block. The assignment statement will not raise any exceptions, and thus the time difference between the two code snippets can be attributed to the cost for the try-catch to detect exceptions. We execute both code snippets one million times and compute the difference in the consumed time. The results show that the code with a try-catch block costs only 4.5 ms more for one million runs, indicating that the overhead to normal program execution is negligible. It aligns with the claim in the official Python document, i.e., \"A try/except block is extremely efficient if no exceptions are raised\" [16].\nThe primary overhead during the error-handling process arises from the LLMs' inference times. We measured the average time required by CodeQwen (deployed on our local machine using Huggingface Transformers) and GPT-3.5 and GPT-4 (deployed on OpenAI's remote server) to generate the handling code for the benchmarks. On average, CodeQwen, GPT-3.5, and GPT-4 take 1.7 seconds, 1.6 seconds, and 3.1 seconds, respectively, to generate the handling code for the occurred error. These durations are deemed acceptable, compared with the consequences of the execution interruption. Given the rapid advancements in LLMs, we anticipate continued improvements in their efficiency."}, {"title": "DISCUSSION", "content": "In this section, we discuss the threats to validity and the issues with HEALER, including its trustworthiness, operational cost, and extension to other programming languages."}, {"title": "Threats to Validity", "content": "Internal validity: The main threat to internal validity is the difference in hyper-parameters among the LLMs used in this study. We evaluate the performance of HEALER using the commercial LLMs, GPT-3.5 and GPT-4, and the open-source LLM, CodeQwen. In our experiments, we use the default hyper-parameters for these models during inference, except for the CodeQwen's context window. The context window for CodeQwen is set to 4096 tokens, which is significantly smaller than the context windows of GPT-3.5 and GPT-4. This limitation is due to the deployment of CodeQwen on our local machine, where 4096 tokens is the maximum context window supported by the server. This constraint may affect CodeQwen's performance in handling runtime errors, as some prompts exceed this window size and are truncated. This could result in an unfair comparison between CodeQwen and GPT-4. However, we qualitatively analyzed the prompt length distribution, where less than 1% of the prompts are truncated. Therefore, we believe the impact of this truncation is trivial.\nExternal validity: The threats to external validity mainly lie in the selection of benchmarks. The benchmarks used in this paper are limited to four Python benchmarks, which may not encompass all practical scenarios. Although these benchmarks include the most common error types in Python programs, certain error types may still be unrepresented, potentially limiting the generalizability of the conclusions to real-world scenarios.\nConstruct validity: Bias in performance evaluation is a common threat to construct validity. In our experiment, we introduce two metrics, CORRECT and SURVIVED, to measure the effectiveness of HEALER in handling runtime errors. While these metrics are intuitive, they may not be optimal. For instance, even if an error is successfully handled, the resulting program output may still be incorrect due to flaws in the original source code."}, {"title": "Trustworthiness of the Handling Code", "content": "As revealed by various studies [39, 46, 60], the code generated by LLMs is not guaranteed to be secure. It may contain malicious code injected by attackers or vulnerable code, leading to security issues. Moreover, due to the randomness in the generation process, the generated code may exhibit unpredictable behaviors. HEALER, operating without human intervention, directly executes the generated code to handle runtime errors, which could be risky. Currently, popular AI systems, such as ChatGPT, mitigate such security risks by running model-generated code in a sandboxed environment with limited permissions. Similarly, HEALER adopts this strategy."}, {"title": "Operational Cost for Using HEALER", "content": "HEALER involves an LLM for generating handling code, which introduces additional costs associated with the LLM inference. Typically, HEALER can interact with LLMs either deployed on remote servers or on user devices. Remote servers may incur additional costs due to operational expenses or commercial fees. In our experiments, we used the commercial APIs of GPT-3.5 and GPT-4 to generate handling code, with costs around $0.002 and $0.02 per handling code, respectively. On-device inference can significantly reduce costs and enhance the reliability of HEALER by eliminating the dependence on remote servers. Various techniques, such as model compression [47] and quantization [30], have been developed to enable model inference on user devices. For example, LLAMA.cpp [18] can run Llama2-13B [50] on a single M2 Ultra MacBook with fast inference speeds (61.44 ms per token). As the field of LLMs progresses, we anticipate further advancements in reducing the resource requirements for LLMs."}, {"title": "Extension to Other Programming Languages", "content": "As introduced in Section 3.4, we implement HEALER in Python. However, as a general framework for handling runtime errors, HEALER is not limited to Python and can be extended to other programming languages. The applicability of HEALER to a programming language depends on two factors: (1) the availability of LLMs for the language, and (2) the feasibility of executing dynamically generated code during runtime. Currently, most of SOTA LLMs [2, 7, 29] are pre-trained on multiple programming languages. For example, CodeQwen [7] supports 92 programming languages, covering all the mainstream languages. Therefore, the first factor is a minor concern. The second factor depends on the programming language itself. Typically, interpreted languages, such as Python, JavaScript, and Ruby, are more suitable for HEALER, as they natively support the execution of dynamically generated code. Compiled languages, such as Java, C++, and Rust, precompile the source code before execution, introducing extra complexity to dynamic code execution. However, there are usually some workarounds in such languages. For example, Java provides the Java Compiler API to compile the code at runtime. Therefore, technically, HEALER can be applied to a wide range of programming languages."}, {"title": "CONCLUSION AND FUTURE WORK", "content": "In this paper, we introduced HEALER, an innovative framework that uses Large Language Models (LLMs) to handle unanticipated runtime errors dynamically. Our study demonstrated that LLMs, particularly GPT-4, can effectively generate handling code snippets, successfully surviving a significant portion of runtime errors, 72.8% of errors in our experiments. Moreover, fine-tuning further enhanced performance, showing promise for LLM-assisted error recovery. HEALER opens up a new technical pathway towards self-healing systems, where LLMs are employed as error handlers to recover from runtime errors automatically.\nThroughout the study, we identified several avenues for future research. Firstly, the performance of HEALER can be further enhanced through methods like prompt engineering [53] and instruction tuning [45]. Secondly, addressing the trustworthiness of code generated by LLMs is crucial, necessitating mechanisms specifically designed for HEALER. Lastly, integrating HEALER into the runtime environment is an interesting topic, offering more accessible and efficient error-handling mechanisms that benefit the development of self-healing systems."}]}