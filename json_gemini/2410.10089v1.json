{"title": "PromptGCN: Bridging Subgraph Gaps in Lightweight GCNS", "authors": ["Shengwei Ji", "Yujie Tian", "Fei Liu", "Xinlu Li", "Le Wu"], "abstract": "Graph Convolutional Networks (GCNs) are widely used in graph-based applications, such as social networks and recommendation systems. Nevertheless, large-scale graphs or deep aggregation layers in full-batch GCNs consume significant GPU memory, causing out of memory (OOM) errors on mainstream GPUs (e.g., 29GB memory consumption on the Ogbn-products graph with 5 layers). The subgraph sampling methods reduce memory consumption to achieve lightweight GCNs by partitioning the graph into multiple subgraphs and sequentially training GCNs on each subgraph. However, these methods yield gaps among subgraphs, i.e., GCNs can only be trained based on subgraphs instead of global graph information, which reduces the accuracy of GCNs. In this paper, we propose PromptGCN, a novel prompt-based lightweight GCN model to bridge the gaps among subgraphs. First, the learnable prompt embeddings are designed to obtain global information. Then, the prompts are attached into each subgraph to transfer the global information among subgraphs. Extensive experimental results on seven large-scale graphs demonstrate that PromptGCN exhibits superior performance compared to baselines. Notably, PromptGCN improves the accuracy of subgraph sampling methods by up to 5.48% on the Flickr dataset. Overall, PromptGCN can be easily combined with any subgraph sampling method to obtain a lightweight GCN model with higher accuracy.", "sections": [{"title": "I. INTRODUCTION", "content": "Graph Convolutional Networks (GCNs) aggregate the features of the neighboring nodes and efficiently transmit information about the nodes among the layers. This approach have achieved significant performance in various graph tasks, such as link prediction [1] and node classification [2].\nRecent studies indicate that increasing the scale of training batches correlates with higher accuracy in GCNs [3]. For example, the full-batch approaches [4], [5], [6], [7] utilize the global graph information (i.e., the relationships and features among all nodes) to optimize the accuracy of GCNs. Nevertheless, the memory consumption also rises with the scale of batch size and graph increasing. For instance, as illustrated in Fig. 1, training full-batch GCNs on the large-scale Obgn-products graph-comprising over 20 million nodes and 100 million edges-using an NVIDIA 3090 GPU, results in an out of memory (OOM) error when the number of layers exceeds 3 or the dimensions surpass 512.\nTo reduce memory consumption, existing studies train GCNs in smaller batches through various sampling methods. Based on different sampling granularities, existing sampling methods can be categorized into three types, detailed as follows. 1) The node-wise sampling methods [8], [9] sample a fixed or random number of neighbors for each node. Nevertheless, as the number of layers increases, the number of sampled neighboring nodes grows exponentially, leading to the neighbor explosion problem. 2) The layer-wise sampling methods [10], [11], [12], [13] sample a fixed number of nodes at each layer to mitigate the neighbor explosion problem. On the other hand, information loss from unsampled nodes in each layer will result in a reduction in GCN accuracy. 3) The subgraph sampling methods [14], [15], [16], [17], [18], [19] partitions the global graph into multiple subgraphs, then GCN is trained on each subgraph sequentially. For instance, ClusterGCN [14] uses a node clustering algorithm METIS [20] to partition the global graph into subgraphs. GraphSAINT [15] designs the sampling probabilities for nodes and edges and uses these to sample the subgraph in each batch. Compared with the node- and layer-wise sampling methods, the subgraph sampling methods reduces the memory consumption of GCN while ensuring that all nodes are sampled. Fig. 1 illustrates that the subgraph sampling method ClusterGCN [14] has lower memory consumption than full-batch GCN.\nHowever, subgraph sampling methods discard information outside the subgraph during the training process of GCN, resulting in only local receptive fields within the subgraph (i.e., the aggregation range of the target node reduced) [21], [22]. This limitation makes it challenging to capture global graph information, as shown in Fig. 2(a). Moreover, subgraph sampling methods yield gaps among subgraphs, which can lead to reduced connectivity and, consequently, decrease the accuracy of GCN. Fig. 2(b) illustrates that the accuracy of the subgraph sampling method is lower than that of the full-batch method across different GCN layers. Concerning this, few studies optimize subgraph sampling by integrating external information to reduce the gaps among subgraphs. For instance, GAS [23] and LMC [16] include the node outside the subgraph into the training process of GCN to expand the subgraphs' receptive fields. For these methods, as the graph scale and GCN complexity increase, the time and space consumption also increases correspondingly. Therefore, how to bridge the gap among the subgraphs to improve accuracy while maintaining low memory consumption is an essential problem for GCN.\nRecent studies [24], [25], [26], [27] have indicated that prompts are effective in bridging the gap between pre-trained models and downstream tasks. In this paper, the \"prompt\" strategy is introduced and applied for the first time in subgraph sampling methods for large-scale graphs, with these prompts typically consisting of a small number of free parameters and occupying minimal memory. Specifically, prompts are used to transfer global information among subgraphs, bridging the gap among each subgraph, which is shown in Fig. 2(a). Nevertheless, there are two challenges in designing prompts for subgraph sampling: (1) How to design prompt embeddings that effectively capture global information? (2) How to transfer global information to bridge the gaps among subgraphs? To address the two challenges, we propose a prompt-based lightweight GCN (PromptGCN) model. First, PromptGCN incorporates learnable prompt embeddings that capture global information beyond the target subgraph. Second, these prompt embeddings are attached with the target subgraph in various ways, effectively transferring global information to the subgraph. Extensive experimental results indicate that PromptGCN effectively bridges the gaps among subgraphs and enhances the accuracy of GCNs, while maintaining low memory consumption on large-scale graphs. The main contributions of PromptGCN are as follows:\n\u2022 PromptGCN extends the receptive field of subgraph sampling GCN and bridges gaps between subgraphs by utilizing prompts to capture and share global information.\n\u2022 PromptGCN can be easily integrated with any subgraph sampling method to obtain a lightweight GCN model that achieves higher accuracy on multiple downstream tasks.\n\u2022 Extensive experiments on seven large-scale datasets across multiple downstream tasks demonstrate that PromptGCN outperforms baselines in terms of accuracy and memory consumption.\nThe paper is structured as follows: In Section II, we present the problem formulation for PromptGCN. Section III provides a detailed explanation of the proposed PromptGCN model. Section IV describes the experiments conducted to evaluate the performance of PromptGCN. Section V reviews existing GCN sampling and prompt learning methods. Finally, Section VI concludes the paper."}, {"title": "II. PROBLEM FORMULATION", "content": "The global graph is defined as G = (V,E, A), where V = [v1, v2,...,vn] represents the nodes in the global graph, and & represents the edges. An edge from node vi to node vj is denoted as (vi,vj) \u2208 E, and vj: j \u2208 Ni denotes a neighbor of node vi. The adjacency matrix A indicates whether edges exist between nodes, using 1 to signify their presence and 0 to signify their absence. The input features of the nodes are denoted as H = (h1,h2,...,hn) \u2208 Rn\u00d7d, where n is the number of nodes and d is the input feature dimension. For instance, the features of nodes v\u2081 and vj are denoted as hi and hj, respectively.\nTraining GCN models on a global graph significantly increases memory consumption. To alleviate this problem, we introduce a graph vertex partitioning method that partitions the input graph data into local subgraphs by cutting edges. Specifically, the graph partition method partitions the global graph G into c subgraphs (i.e., G\u2081\u2026\u2026\u2026, Gc), and each subgraph is denoted as Gt, where t = (1,...,c). The nodes in the global graph are correspondingly clustered into c clusters V = [V1,...,Vc]. We then have Uf=1 V (Gt) = V and N=1 V (Gt) = \u00d8. In addition, we can partition the feature matrix H and the labels Y into [H1, ..., Hc] and [V1, ..., \u0423c], respectively. Ht = (h1t,h2t,...,hnt) \u2208 Rn\u00d7d consists of the node feature matrix in the t-th subgraph. To enhance the connection between subgraphs, we propose to utilize prompt embedding P = [P1,..., PM] to obtain global graph information, where M is the number of prompt embeddings. The node features of the t-th subgraph Ht, and the shared prompt matrix P are fed into the GCN model, which is trained sequentially from the 1st subgraph to the c-th subgraph. The shared prompt embedding Pis passed from one subgraph to the next to transfer the global graph information among subgraphs."}, {"title": "III. MODEL DESCRIPTION", "content": "Subgraph sampling methods discard information outside the subgraph during GCN training, creating gaps among subgraphs that can reduce connectivity. Therefore, we propose a prompt-based lightweight GCN (PromptGCN) to learn global information and bridge the gaps among subgraphs.\nThe framework of PromptGCN is outlined in Section III-A. Section III-B covers Graph Partition, while Section III-C details Prompt Selection. Prompt Attachment is discussed in Section III-D, and Prompt Sharing in Section III-E. Finally, the application of PromptGCN for Downstream Tasks is presented in Section III-F.\nA. PromptGCN Framework\nThe overall framework of PromptGCN is illustrated in Fig. 3, comprising Graph Partitioning, Prompt Selection, Prompt Attachment, Prompt Sharing, and Prompts for Downstream Tasks. First, the graph partitioning algorithm partitions the global graph G into several subgraphs, each containing the feature matrices of the nodes Ht. The input to PromptGCN consists of the node feature matrix Ht and a small set of shared prompt embedding matrices P (detailed in Section III-B). Second, each node feature adaptively selects the most relevant prompt embedding and attaches the selected prompt embedding to itself (detailed in Section III-C and III-D). Third, the processed node-prompt embedding pairs are then fed into the GCN model, which is trained sequentially across subgraphs, with the shared prompt embeddings being passed from one subgraph to the next (detailed in Section III-E). Finally, PromptGCN is applied to various downstream tasks (e.g., Node Classification and Link Prediction) to guide the model training process (detailed in Section III-F). In summary, the prompt embeddings shared among subgraphs carry crucial global information, which is effectively transmitted to different subgraphs through the interaction between node features and prompt embeddings. The details are in Algorithm 1."}, {"title": "B. Graph Partitioning", "content": "Training a GCN model on a global graph leads to high memory consumption. To address this issue, we employ the graph vertex partitioning approach, which reduces memory consumption by partitioning the global graph into multiple local subgraphs.\nSpecifically, the graph partitioning method partitions the global graph G into c local subgraphs, where the nodes in the graph are allocated into c clusters V = [V1, V2, ..., Vc]. Vt consists of the nodes in the t-th subgraph, where t = 1, 2, ..., c. The details are as follows:\nG = [G1,\u2026, Gc] = [{V1, E1},\u00b7\u00b7\u00b7, {Vc, Ec}], (1)\nwhere V denotes the nodes, and & represents the edges, with each Et consisting solely of edges between nodes in Vt. We then have Uf=1 V (Gt) = V and N=1 V (Gt) = 0.\nFurthermore, we can partition the feature matrix H and the labels y into [H1, . . ., Hc] and [V1, ..., Vc], respectively, based on the partition [V\u2081,..., V.], where Ht and Vt consist of the features and labels of the nodes in Vt."}, {"title": "C. Prompt Selection", "content": "Subgraphs discard information outside their boundaries during training process, making it difficult for nodes within the subgraph to obtain global information representations. To address this, we adopt prompt embedding P to learn global information and enable node features to autonomously select the appropriate global information.\nSpecifically, let the prompt embedding Pconsist of a series of learnable embeddings, P = [P1,...,PM], where M represents the number of prompt embeddings. The input features of the nodes in the t-th subgraph are denoted as Ht = (h1t, h2t,..., hnt) \u2208 Rn\u00d7d, where t = 1, 2, ..., c, n is the number of nodes, and d is the input feature dimension. The embedding dimension of each prompt embedding Pm \u2208 Rd is aligned with the node feature dimension hjt \u2208 Rd, where m = 1, 2, ..., M and j = 1,2,...,n. The similarity between node feature hj and prompt embedding Pm is computed by the dot product, and the Pm with the largest association with the node feature is selected as the prompt message for that node:\nPm = arg max(\u2211(PmTht)), (2)\nwhere Pm is the adaptively chosen prompt embedding for the node feature. After selecting the appropriate prompt embedding, determining how to attach it to the subgraph becomes another key issue to address."}, {"title": "D. Prompt Attachment", "content": "There are two main types of feature fusion methods in deep learning, i.e., concatenate and point-wise operations. Therefore, we use two types of approaches to fuse node features and prompt embeddings, allowing nodes to acquire global information. The specific methods are listed below: (1) The first method directly concatenates node features with prompt embeddings; (2) The second method point-wise additions the node features to the prompt embeddings; (3) The third method point-wise multiplies the node features with the prompt embeddings; (4) The fourth method point-wise additions prompt embeddings to node features with specific weights. In the above scheme, (1) is a concatenate operation, while (2), (3), and (4) are point-wise operations. The corresponding formulas are provided below:\nhjt = Concat(hjt, Pm)\nhjt+Pm\nhjt * Pm\nahjt + (1-a)Pm, (3)\nwhere a is a custom parameter that controls the weight of prompts added to the node feature. Through Experiment IV-D, we found that using the concatenate operation to attach prompt embeddings to node features maximize the delivery of global information. Therefore, in this paper, the concatenate operation is used as the main attachment method."}, {"title": "E. Prompt Sharing", "content": "Based on the local subgraph, GCN is able to capture the structured feature of nodes and their neighbors in the graph. At each layer, GCN employs a message passing and aggregation mechanism, where it collects features from neighboring nodes and efficiently propagates node information across layers using various linear combination functions. The aggregation process for passing node features hjt in GCN at the k-th layer is represented as:\nhkit = f (hk-1it, {hk-1njt: jt \u2208 Nit};\u0398k), (4)\nwhere Nit is the neighbors of node feature hit and Ok is the k-th layer learnable GCN parameter, including node feature matrix Ht and shared prompt embedding P. f denotes the aggregation function, which is used to pass the neighbor node features to the target node feature hit \u2208 Rd, where i = 1, 2, ..., n and t = 1,2,..., c.\nThe GCN is trained sequentially across subgraphs, with the shared prompt embeddings P passed from one subgraph to the next, thereby sharing global information across subgraphs."}, {"title": "F. PromptGCN for Downstream Tasks", "content": "Combining the GCN model with downstream tasks allows for effective training of the prompt parameters and refinement of the global information carried within the prompts. Therefore, we apply the GCN model across different downstream tasks.\nNode classification. The node classification task consists of ||) classes, and ym \u2208 Vt is the ground label of the target node. Specifically, we predict the classification labels for target node feature hit. The optimized classification loss is described as:\nLt =  \u2211(Def (ym, hit) + Lo, (5)\nwhere y is a customized hyper-parameter, and f is the classification loss function. Through Experiment IV-D, we found a correlation between the number of prompts and the classes in the node classification task. Specifically, model performance is optimized when the number of prompts is similar to the number of class. Since the classes are independent of each other, we introduced a regularization term Lo to ensure a larger difference between different P.\nLo = \u2211 ||P * (P) - I2, (6)\nwhere I is the identity matrix. Prompt embeddings P corresponding to different classification labels should be distinct from one another, meaning that these prompt embeddings should exhibit low similarity to each other.\nLink Prediction. The GCN model predicts the score between the head node feature hit \u2208 Rd and the tail node feature hjt \u2208 Rd by defining a scoring function f (hit, hjt). In addition, GCN improves the prediction accuracy by randomly negatively sampling some incorrect samples of tail node feature h'jt \u2208 Rd. The loss function equation is as follows:\nLt =  \u03a3(log (f (hit, hit)) + log (1 \u2013 (f (hit, h'jt)))), (7)\nwhere N represents the number of links."}, {"title": "IV. EXPERIMENTS", "content": "In this section, we introduce the experimental setup (Section IV-A) and proceed to answer the following research questions and validate the model's contribution in Sections IV-B-IV-D:\n\u2022 RQ1: How does the performance of PromptGCN on node classification and link prediction tasks compare to the baselines?\n\u2022 RQ2: How does the memory consumption of PromptGCN compare to that of a full-batch model?\n\u2022 RQ3: How do hyperparameters affect the performance of PromptGCN?\nA. Setup\nDatasets. To verify the generalization ability of the model across different datasets, we evaluate the PromptGCN model on five large-scale public datasets about node classification tasks: AmazonCoBuyPhoto\u00b9, AmazonCoBuyComputer\u00b9, Flickr\u00b2, Reddit\u00b3, and Ogbn-products\u2074. Additionally, we evaluate the PromptGCN model on two large-scale public datasets about link prediction tasks: Ogbl-citation25 and Obgl-collab6. The datasets detail are shown in Table I.\nBaselines. In this paper, we provide a brief description of the full-batch and subgraph sampling models.\n\u2022 GCN (Thomas N et al. 2017) [4] learns the mean representation of neighboring node features, uses the mean as a weight, and aggregates the node features for the target node through multiple convolutions.\n\u2022 GAT (Petar Velickovic et al. 2019) [5] enhances the GCN by introducing an attention mechanism that serves as the weight in the convolution process, with a particular emphasis on aggregating the features of neighboring nodes.\n\u2022 GCNII (Ming Chen et al. 2020) [6] enhances the GCN model by incorporating initial residuals and constant mapping, along with arbitrary weights for multilayer convolution, effectively mitigating the over-smoothing problem.\n\u2022 ClusterGCN (Chiang et al. 2019) [14] uses a Metis strategy to partition the global graph into different subgraph partitions and randomly selects multiple partitioned subgraphs to participate in the training process.\n\u2022 GraphSAINT (Zeng et al. 2020) [15] reduces the problem of estimation bias in the training of traditional subgraph sampling algorithms by using a normalization method based on subgraph sampling.\n\u2022 LMC (Shi et al. 2023) [16] applies the subgraph approach to the node classification task by employing a subgraph approach that retrieves information lost during forward and backward propagation in the neural network. Additionally, it incorporates nodes outside the subgraph into the GCN learning process.\n\u2022 ELPH (Chamberlain et al. 2023) [28] applies the subgraph approach to the link prediction task by implicitly constructing subgraph sketches as message passing.\n\u2022 GCN-Ours, GAT-Ours, and GCNII-Ours methods utilize PromptGCN prompt templates to investigate the role of prompt in full-batch models.\n\u2022 ClusterGCN-Is, GraphSAINT-Is, and LMC-Is methods use the isolated prompt templates within each subgraph to investigate the role of prompts in subgraph sampling models. These methods are variants of PromptGCN, where each subgraph has its own exclusive prompt template, and the templates are independent of one another.\n\u2022 ClusterGCN-Ours, GraphSAINT-Ours, and LMC-Ours methods incorporate PromptGCN to explore the role of prompts in subgraph sampling models. These methods use a shared prompt template between subgraphs to transfer global information.\nEvaluation indicators. This paper evaluates the Prompt-GCN model using several classical evaluation metrics. As"}, {"title": "B. Prediction Performance Comparison (RQ1)", "content": "This section compares the performance of PromptGCN with baselines on seven large-scale datasets. Table II and Table III show that the performance comparison among Prompt-GCN and the baselines on the node classification and link prediction tasks at 3 layers, respectively. The experimental results are statistical results of multiple experiments. We apply PromptGCN to two representative subgraph sampling methods (i.e., ClusterGCN [14] and GraphSAINT [15]) and two latest methods (i.e., LMC [16] and ELPH [28]). From the experimental results, we can draw the following conclusions:\n(1) PromptGCN is applied to node classification and link prediction tasks, respectively. Experiments show that PromptGCN finally resembles full-batch performance on all datasets.\n(2) Table II presents the overall performance of Prompt-GCN on the node classification task. Compared to the three backbone subgraph sampling models, PromptGCN achieves competitive metrics across almost all datasets. For instance, on the Flickr dataset, PromptGCN improves performance by 5.48%. Additionally, we selected the largest dataset, Ogbn-products, for visualization experiments. As shown in Fig. 4, experiments across different layers reveal that PromptGCN achieves the highest test accuracy.\n(3) To evaluate the performance of PromptGCN on different downstream tasks, we applied it to a link prediction task. Table III presents the overall performance of PromptGCN for this task. On the Ogbl-collab dataset, PromptGCN improves the backbone performance by 2.02%. The strong performance of PromptGCN across various tasks demonstrates that our method is adaptable to different backbone models and downstream tasks. Experimental results on two tasks show that Prompt- GCN performs less impressively with the latest backbone models. This suggests that these advanced neural network models are more complex and require more sophisticated and well-designed prompts.\n(4) Additionally, when applied to full-batch models, PromptGCN does not consistently improve metrics across all experiments. For example, on the Ogbn-products dataset, GCNII-Ours improves performance by 1.46% and 13.92% on both metrics, whereas GCN-Ours fails to match the performance of the original model. The reason is that when training a full-batch model on the entire graph, PromptGCN cannot effectively bridge the gaps between subgraphs, a challenge unique to subgraph sampling algorithms. It's important to note that due to the high memory consumption of the full-batch models, using PromptGCN with it can result in an OOM error.\n(5) \"-Is\" denotes the isolated prompt assigned to each subgraph. The isolated prompt fails to achieve the superior performance of PromptGCN. The reason is that isolated prompt assigns independent prompts to each subgraph, disrupting the role of prompts as a bridge between subgraphs, and making it challenging to expand the subgraph receptive field or transfer global information. In contrast, the shared prompt significantly strengthens the connection between subgraphs by capturing global information during training.\nIn summary, PromptGCN can effectively bridge the gap among subgraphs and can be generalized to different subgraph sampling methods as well as different downstream tasks to achieve competitive performance."}, {"title": "V. RELATED WORK", "content": "The section presents related work from two perspectives, including GCN Sampling (V-A), Prompt Learning in Text Pre-train and Fine-tune (V-B), and Prompt Learning in Graph Pre-train and Fine-tune (V-C). The research framework for this section is illustrated in Fig. 9.\nA. GCN Sampling\nGCNs are widely used in graph-based applications, such as social networks and recommender systems to learn the feature representation of target nodes by aggregating information from multiple layers of neighboring nodes during full-batch training. Nevertheless, this approach increases additional memory consumption . To effectively reduce memory consumption, GCN sampling methods use mini-batch training at various granularities, serving as a crucial technique for lightweight GCNs.\nNode-wise Sampling Methods. The node-wise sampling methods sample neighbors for each node, eliminating the need for GCNs to process the entire graph, thereby reducing the memory consumption generated during the training process. GraphSAGE randomly samples a fixed number of its first-order neighbors to reduce the memory consumption. Unlike GraphSAGE, which optimizes the sampling strategy, proves the convergence of its sampling algorithm. The above methods sample nodes with random probability. proposes a learnable sampling method that samples nodes with an unfixed probability. introduce the node-wise sampling method to reduce the number of redundant boundary nodes per partitioned subgraph and reduce GCN communication costs. However, the number of nodes sampled grows exponentially with the number of GCN layers, leading to the node explosion problem.\nLayer-wise Sampling Methods. The layer-wise sampling methods sample a certain number of nodes for each GCN layer to alleviate the node explosion problem. and sample a fixed number of nodes in each layer, but and believe that sampling an incremental number of nodes in each layer produces better results. combines the advantages of layer-wise sampling and node-wise sampling to sample the minimum number of vertices needed for each layer. However, these methods only consider node associations between neighboring GCN layers; information loss from unsampled nodes in each layer will result in a reduction in GCN accuracy.\nSubgraph Sampling Methods. The subgraph sampling methods reduces the memory consumption of GCN while ensuring that all nodes are sampled. ClusterGCN uses a METIS strategy to partition the global graph into different subgraphs and randomly selects multiple partitioned subgraphs to participate in the training process. GraphSAINT reduces the problem of estimation bias in the training of traditional subgraph sampling algorithms by applying a normalization method based on subgraph sampling. accelerates model convergence by retrieving discarded messages in backward passes to compute accurate mini-batch gradients. introduces a centrality-based subgraph generation algorithm to solve the problem of information loss among subgraphs caused by the traditional graph sampling process. effectively mitigates redundancy and load imbalance between subgraph partitions through both redundant embedded graph partitioning and memory-aware partitioning. introduces a GCN training framework for adaptive joint optimization of graph data partitioning and GCN partitioning to bridge the information gap arising from graph-centric partitioning.\nHowever, the current subgraph sampling methods only have a local receptive field on the subgraph, which makes it difficult to capture the global information in the graph. This limitation significantly impacts the accuracy of GCN in downstream tasks. Concerning this, few studies optimize subgraph sampling by integrating external information to reduce the gaps among subgraphs. For instance, GAS incorporates historical node embedding into the training process of GCN to ensure the integrity of the graph information. LMC retrieves the neighbor information of the subgraph to expand the receptive field of the subgraph. These methods represent nodes as free parameters, and different nodes can learn different information during model training. As the number of nodes and the complexity of the neural network increase, the model has better expressiveness while incurring high memory consumption. and have shown that gaps in the model can significantly affect the performance of the model. Therefore, how to bridge the gaps among the subgraphs to improve accuracy while maintaining low memory consumption is an essential problem for GCN.\nB. Prompt Learning in Text Pre-train and Fine-tune\nWith the rise of pre-trained language models in the field of NLP, fine-tuning methods utilizing prompt learning have demonstrated superior performance on tasks such as intent recognition and text classification . Prompt learning effectively bridges the gaps between the model and the downstream task. These prompts usually consist of a small number of free parameters and take up only a small amount of memory. Overall, prompt learning is typically divided into two forms: discrete and continuous prompts.\nDiscrete prompts (i.e., hard prompts) are a method of describing prompts in discrete spaces, typically phrases in natural language that humans can understand. XNLI introduces a prompting strategy for cross-language natural language understanding tasks, using additional sampling templates to attach a question example to each question. PET reconstructs the input data as natural language phrases with masked semantics, reconstructing the downstream task of the model. This approach achieves excellent performance on labeled sparse data.\nContinuous prompts (i.e., soft prompts) are a prompting method that performs in the feature embedding space without restricting the prompts to natural language phrases. That is, continuous prompting learns the prompt itself as a task along with the input information. Li et al. inserted task-relevant prompt embeddings directly into each layer of the pre-trained model to improve the model's performance on downstream tasks by introducing additional prompt parameters. PTCAS proposes a continuous answer search method based on relation extraction and adds TransH as a knowledge constraint module to enable the model to find the best answer representation through the semantic information of relations.\nHowever, due to the differences in data distribution between text and graphs, textual prompt templates cannot be directly transferred to graph data. Therefore, some existing studies transfer prompt to graph data (Section V-C).\nC. Prompt Learning in Graph Pre-train and Fine-tune\nInspired by the application of pre-training models in text area, the use of pre-training models in graph area has become a powerful paradigm. For example, pre-trained GCN's node-level and graph-level representations to capture both local and global information. In addition, some works use contrastive learning to enhance the feature representation of downstream nodes. However, there is a gap between the pre-training content and the downstream target, which will affect their generalizability across tasks. Recent researches have shown that prompt learning techniques also exhibit superior performance on cross-task graphs. Specifically, task-specific prompts are designed to prompt downstream tasks to bridge the gaps between pre-training and downstream tasks.\nGPPT uses prompts to reformulate the link prediction task into a node classification task, effectively bridging the gaps between the pre-trained model and the downstream task. But GPPT cannot handle different downstream tasks. Graphprompt unifies pre-training and downstream tasks in a prompt template that relies on learnable prompts to cope with different downstream tasks. GPF adopts the same prompt template for all pre-trained models to suggest downstream tasks in an adaptive manner. Building on this work, Sun et al. use prompts for node classification, edge classification, and graph classification, achieving superior performance on multi-task graphs.\nGiven that prompts have demonstrated efficacy in bridging the gaps between pre-trained models and downstream tasks, a \"prompt\" strategy is proposed to bridge the gaps among subgraphs."}, {"title": "VI. CONCLUSION", "content": "In this paper, we proposed PromptGCN, a novel prompt-based lightweight GCN model, to bridge the gaps among subgraphs. First, the learnable prompt embeddings were designed to obtain global information. Then, the prompts were attached to each subgraph to transfer the global information among subgraphs. Overall, PromptGCN could be easily combined with any subgraph sampling method to obtain a lightweight GCN model with higher accuracy. In future studies, we plan to further investigate the design of prompt templates and examine how the quality of these templates impacts model performance."}]}