{"title": "BoT-Drive: Hierarchical Behavior and Trajectory Planning for Autonomous Driving using POMDPS", "authors": ["Xuanjin Jin", "Chendong Zeng", "Shengfa Zhu", "Chunxiao Liu", "Panpan Cai"], "abstract": "Uncertainties in dynamic road environments pose significant challenges for behavior and trajectory planning in autonomous driving. This paper introduces BoT-Drive, a planning algorithm that addresses uncertainties at both behavior and trajectory levels within a Partially Observable Markov Decision Process (POMDP) framework. BoT-Drive employs driver models to characterize unknown behavioral intentions and utilizes their model parameters to infer hidden driving styles. By also treating driver models as decision-making actions for the autonomous vehicle, BoT-Drive effectively tackles the exponential complexity inherent in POMDPs. To enhance safety and robustness, the planner further applies importance sampling to refine the driving trajectory conditioned on the planned high-level behavior. Evaluation on real-world data shows that BoT-Drive consistently outperforms both existing planning methods and learning-based methods in regular and complex urban driving scenes, demonstrating significant improvements in driving safety and reliability.", "sections": [{"title": "I. INTRODUCTION", "content": "Autonomous driving (AD) represents a pivotal advancement in transportation technology, aiming to improve road safety, efficiency, and convenience by enabling vehicles to navigate without human input. A crucial aspect of AD systems is behavior and trajectory planning. This involves planning high-level actions like lane keeping, lane changing, and turning, as well as low-level driving trajectories-sequences of positions, speeds, and accelerations. These elements must be carefully planned for the autonomous vehicle (the ego-vehicle) over a future time window, considering the dynamic nature of road environments.\nOne of the greatest challenges in behavior and trajectory planning is handling uncertainties, particularly in complex interactions among many traffic participants. For example, the subtle actions of a nearby vehicle-such as slowly drifting toward the lane boundary-may suggest various possible intentions. These could range from preparing to change lanes or trying to create space for another vehicle, to simply exhibiting erratic driving habits. This uncertainty about the intentions and driving styles of other agents adds a significant layer of complexity to planning.\nAddressing these uncertainties in real-time is often prohibited due to the computational challenge-the computational cost increases exponentially with the number of participants and the planning horizon, known as the \"curse of dimensionality\u201d and the \u201ccurse of history\" [1]. Common strategies to mitigate this challenge involve simplifying the planning process by focusing only on certain aspects of the uncertainty, either at the behavior [2]\u2013[15] or trajectory level [16]\u2013[22], or by employing maximum-likelihood planning approaches [23]\u2013[27]. However, such simplifications may compromise the safety and efficiency of the ego-vehicle in complex interaction scenes.\nThis paper introduces BoT-Drive, a new planning algorithm grounded within a Partially Observable Markov Decision Process (POMDP) framework, addressing uncertainties at both behavior and trajectory levels using hierarchical planning. The algorithm treats behavioral intentions and driving styles of external traffic participants (exo-agents) as hidden states. It represents potential driving behaviors with a set of driver models, leveraging their model parameters to characterize driving styles. This hierarchical representation allows for efficient reasoning about others' uncertain behaviors and trajectories.\nBoT-Drive further employs these driver models as high-level decision-making actions, in order to cut down the POMDP planning horizon, thus addressing the exponential complexity. This enables real-time planning in complex driving scenes, even with limited computational resources. At the low level, it generates driving trajectories by simulating the outcomes of these driver models, evaluating decisions at both levels to determine the optimal driving behavior and trajectory under uncertainty. Subsequently, we employ a trajectory optimization step to further refine the driving trajectory. The refinement step resamples scenarios from an importance sampling distribution that ensures coverage of events with high impact on safety and efficiency, thereby improving the robustness of the driving trajectory.\nOur experiments show that BoT-Drive effectively enables safe and robust long-term planning under uncertainty in diverse urban environments. Evaluations using the interactive setting of nuPlan demonstrate that BoT-Drive achieves state-of-the-art performance compared to learning-based methods trained on the same dataset, without requiring any training data. Further analyses on another real-world dataset emphasizing long-term interactions show that BoT-Drive significantly enhances driving safety and efficiency over existing planning algorithms, attributed to its hierarchical and long-term reasoning and the application of importance sampling."}, {"title": "II. RELATED WORK", "content": "To plan behaviors and trajectories for a robot car, a prerequisite is to predict the behaviors of other agents and characterize the uncertainty in it. This requires motion"}, {"title": "IV. UNCERTAINTY MODELING USING DRIVER MODELS", "content": "In this section, we present details on the driver models and the methodology for multi-model inference, which is essential for effectively tracking the belief over behavioral intentions and driving styles within our POMDP framework."}, {"title": "A. Driver Models", "content": "We define two key driver behaviors for urban driving: lane / lane connector following (LF) and lane changing"}, {"title": "B. Multi-Model Inference", "content": "To effectively track the beliefs over behavioral intentions and driving styles, we construct a dynamic Bayesian network (DBN) (Fig. 3), incorporating the aforementioned driver models and their parameters."}, {"title": "1) DBN Structure", "content": "The DBN framework comprises several key random variables:\n\u2022 x: physical states of all agents, including position, speed, linear acceleration, heading direction, yaw rate, etc.\n\u2022 m: behavioral intention (driver model) of exo-agents, assumed to be static and independent.\n\u2022 \u03b8: driving style (model parameters) of exo-agents, also static and independent.\n\u2022 o: observations reflecting agents' physical states with inherent noise.\nThe DBN also includes critical conditional distributions:\n\u2022 p(x_t|x_{t-1},m, \\theta): the transition model of physical states, following x_t = G(x_{t-1}, m, \\theta) where G denotes forward simulation using the assumed driver models in m and model parameters in \u03b8.\n\u2022 p(O_t|x_t): the observation model assuming Gaussian distribution around actual physical states x_t."}, {"title": "2) Hierarchical Filtering", "content": "For belief tracking, we apply hierarchical filtering in two stages:"}, {"title": "V. HIERARCHICAL BEHAVIOR AND TRAJECTORY PLANNING USING POMDP", "content": "In this section, we present the formulation of our Partially Observable Markov Decision Process (POMDP) and illustrate the BoT-Drive algorithm for hierarchical behavior and trajectory planning, developed upon the POMDP formulation."}, {"title": "A. POMDP Model", "content": "The specifics of the POMDP model are as follows."}, {"title": "1) State and Observation Spaces", "content": "The state representation, x, and observation representation, o, in our POMDP model are consistent with those defined in the Dynamic Bayesian Network (DBN) as discussed in Section IV."}, {"title": "2) Action Space", "content": "The action space, A, for the ego-vehicle contains a set of high-level driving behaviors. They include lane / lane connector following (LF), lane changing to the left (LC-L), and lane changing to the right (LC-R), each underpinned by a specific driver model. Actions are dynamically filtered based on the current physical state of the ego-vehicle to exclude illegal or unreasonable maneuvers. For example, LC-L is deemed illegal if the ego-vehicle is already in the leftmost lane."}, {"title": "3) State Transition and Observation Models", "content": "The state transition and observation models in the POMDP mirror those in Section IV. State transitions are determined by forward simulating the assumed driver models and parameters for all agents, including the ego-vehicle, while the observation model remains consistent with the DBN."}, {"title": "4) Reward Function", "content": "The reward function in the POMDP model is designed to holistically capture the key aspects of autonomous driving performance:\n\u2022 Safety: Measured by a cubic collision penalty that increases with driving speed.\n\u2022 Efficiency: Measured by a linear penalty based on the deviation from the desired speed.\n\u2022 Task Completion: Measured by an exponentially growing penalty as the vehicle deviates from its goal lane.\n\u2022 Smoothness: Measured by a constant penalty assigned to each lane change action."}, {"title": "B. Belief Tree Search Planner", "content": "In this section, we present the belief tree search planner in BoT-Drive for computing the optimal behavior policy (Fig. 2(c)). This planner is developed upon DESPOT [53], a popular POMDP solver, extended to integrate high-level behavior planning with low-level trajectory optimization.\nThe planner begins by sampling a diverse set of driving scenarios. Each scenario captures a unique combination of the physical state x, behavioral intention m, and driving style \u03b8 of all exo-agents interacting with the ego-vehicle, collectively forming the initial belief. Rooted in this belief, the planner constructs a belief tree that recursively branches over all feasible high-level actions available to the ego-vehicle and the potential observations it might encounter. For each action and a given scenario, the planner simulates the corresponding behavior of the ego-vehicle and rolls out the driver models of all relevant agents. These forward simulations are conducted with discrete time steps (0.2 seconds) and over fixed durations (2 seconds for LF and 4 seconds for LC). After action branching, the tree further branches with observations. The planner streamlines the branching process by considering only the final observation from each simulation. The belief tree is iteratively built following the DESPOT heuristics, using a maximum look-ahead horizon of 9 seconds. The planner replans at a fixed rate, e.g., 10Hz."}, {"title": "C. Trajectory Optimization with Importance Sampling", "content": "This trajectory optimization complements the belief tree search planner by performing detailed analysis at the trajectory level. Scenarios are resampled using importance sampling, focusing on key driving events. Candidate trajectories are generated for each scenario and cross-evaluated across all scenarios as follows,\nE[V(\u03c4(\u03c6))] = \\frac{1}{n_{IS}} \\sum_{i=1}^{n_{IS}} \\prod_{j=1}^{N} \\frac{p(m_{i,j})}{q(m_{i,j})} V (\u03c4(\u03c6)),\n\u03c4(\u03c6)^* = arg \\max E[V(\u03c4(\u03c6))],\nwhere n_{is} is the number of sampled scenarios, N is the number of exo-agents, \u03c6 is a sampled scenario, \u03c4(\u03c6) is a candidate trajectory generated under scenario \u03c6. The expected trajectory value V(\u03c4(\u03c6)) is computed using the reward model as detailed in Section V-A.4), with importance weights \\frac{p(m_{i,j})}{q(m_{i,j})} correcting for bias. The trajectory that maximizes the expected value is selected, ensuring safe and efficient maneuvers under uncertainty."}, {"title": "VI. EXPERIMENTS", "content": "Our experiments compare BoT-Drive with both learning-based models and model-based planning using real-world driving data. Results show that BoT-Drive successfully generalizes to diverse urban environments and effectively enhances driving safety in complex scenes and task completion in long-term interactions. While BoT-Drive is completely training-free, it achieves state-of-the-art performance in the interactive setting of nuPlan, compared to learning-based models. On another dataset focused on long-term interactions, BoT-Drive achieves zero collisions and full task completion compared to existing planning algorithms. Ablation"}, {"title": "A. Comparison with Learning-Based Models", "content": "In this section, we compare BoT-Drive with existing learning-based methods, focusing on the driving performance in diverse urban environments. We evaluate methods on nuPlan [45], a large-scale real-world autonomous driving dataset, using the Val14 set selected by [52] with 1,118 regular scenes and the Test14-hard set selected by [51] with 272 complex scenes. Each scene lasts for 15 seconds. Evaluations are conducted in the interactive setting, leveraging closed-loop simulation of the traffic flow. We apply the official metrics from nuPlan, including collision rate (Coll. R), progress towards the goal (Prog.), passenger comfort (Comf.), and drivable area compliance (Area Com.).\nWe compare BoT-Drive with state-of-the-art learning models, including PDM [52], the winner of the 2023 nuPlan planning competition, which integrates IDM [48] for longitudinal control with a learned module for lateral offset adjustment, and baselines highlighted in that paper, such as GC-PGP [50], which encodes observations as graphs to predict probable trajectories; PlanCNN [51], which uses a CNN to encode observations and employs a transformer-based model for future trajectory planning; and IDM [48].\nstudies highlight the crucial roles of hierarchical POMDP planning and importance sampling in trajectory optimization."}, {"title": "B. Comparison with Model-Based Planning", "content": "In this section, we compare BoT-Drive with model-based planning methods. To emphasize the driving performance in long-term interactions, we now use a different dataset containing 100 real-world traffic scenes, each with significantly longer episodes of 40 seconds, collected by autonomous"}, {"title": "C. Ablation Study", "content": "We conduct an ablation study to assess key components of our algorithm by testing three variations: W/O-Unc., which uses only a single maximum-likelihood scenario for planning; W/O-IS, which omits importance sampling and directly samples from the original belief for trajectory optimization; and H=4s, which reduces the planning horizon from 9s to 4s."}, {"title": "D. Visualization of Planning Results", "content": "Our planning results in Fig. 1 illustrate BoT-Drive's ability to handle uncertainty and perform long-term planning for safe and efficient driving. In (a), the ego-vehicle navigates through a complex junction, carefully interacting with surrounding vehicles. In (b), long-term planning enables the ego-vehicle to perceive the orange vehicle from a distance and anticipate a potential collision due to it intruding into the ego-vehicle's lane, thus, the ego-vehicle decelerates in a timely manner. In (c), the belief tracker detects a significant increase in the probability of the risky intrusion, prompting the ego-vehicle to change lane, thus avoiding collision. In (d), while performing the lane change, the ego-vehicle continues to decelerate to ensure a safe following distance. In (e), the ego-vehicle has completed the lane change, and continues to follow the leading vehicle."}, {"title": "VII. CONCLUSION", "content": "In this study, BoT-Drive addresses the challenge of behavior and trajectory planning in complex urban autonomous driving, focusing on tackling uncertainties. We have proposed a hierarchical POMDP planning framework, capable of handling uncertainties in both behavioral intentions and driving styles of other agents. By doing so, it can dynamically track others' uncertain behaviors, and generate the optimal policy and the corresponding trajectory to achieve safe and efficient driving. Evaluations in real-world datasets demonstrate significant improvements in both safety and robustness.\nFuture work aims to increase computational efficiency through parallelization techniques and incorporate advanced deep-learning methods to further enhance the planner's robustness and adaptability in highly unstructured and dynamic environments."}]}