{"title": "PYTHON AGENT IN LUDII", "authors": ["Izaias Saturnino de Lima Neto", "Marco Ant\u00f4nio Athayde De Aguiar Vieira", "Anderson Rocha Tavares"], "abstract": "Ludii is a Java general game system with a considerable number of board games, with an API for developing new agents and a game description language to create new games. To improve versatility and ease development, we provide Python interfaces for agent programming. This allows the use of Python modules to implement general game playing agents.\nAs a means of enabling Python for creating Ludii agents, the interfaces are implemented using different Java libraries: jpy and Py4J. The main goal of this work is to determine which version is faster. To do so, we conducted a performance analysis of two different GGP algorithms, Minimax adapted to GGP and MCTS. The analysis was performed across several combinatorial games with varying depth, branching factor, and ply time. For reproducibility, we provide tutorials and repositories.\nOur analysis includes predictive models using regression, which suggest that jpy is faster than Py4J, however slower than a native Java Ludii agent, as expected.", "sections": [{"title": "Introduction", "content": "Ludii is a comprehensive game platform built to play, evaluate, and create various types of games (Piette et al. [2020]).\nIt is implemented in Java, offering an application programming interface (API) for agent development\u00b9 and a game description language for game creation\u00b2.\nInteroperability between languages is beneficial in Ludii. For example, Python has numerous libraries for data analysis and machine learning. However, the overhead of the Python-Java communication can be considerable. Thus, the main goal of this work is to evaluate two different Python-Java communication methods: jpy\u00b3 and Py4J\u2074.\nThe Python-Java bridges were evaluated by assessing the execution performance of a general game playing (GGP) implementation of the Minimax algorithm with alpha-beta pruning (Knuth and Moore [1975]), along with Upper Confidence Bound for Trees (UCT) (Kocsis and Szepesvari [2006]), a widely used variant of Monte Carlo Tree Search (MCTS). The selected games for this evaluation are combinatorial, defined as deterministic, two-player, zero-sum games with complete information. Different performance metrics were employed for each algorithm: the number of"}, {"title": "Background", "content": "General game playing artificial intelligence refers to a program capable of playing a wide variety of games. As explained by Genesereth et al. [2005] and further emphasized by Vieira et al. [2023], these algorithms cannot be tailored for specific games, since they receive a game description in some representation at runtime and must use this description to play the game effectively. Several algorithms for general game playing AI exist, implementing different approaches to the problem. This report uses common and simple algorithms for the purposes of performance evaluation, which are further discussed in Sections 2.1 and 2.2."}, {"title": "Monte Carlo Tree Search", "content": "As the name suggests, Monte Carlo Tree Search (MCTS) is a tree search algorithm. There are several variants of this algorithm (Browne et al. [2012]). MCTS is an iterative algorithm with four steps in each iteration: selection, expansion, simulation, and backpropagation. The selection step chooses the leaf node on the partially-built game tree with the highest evaluation, where this evaluation is usually a function of the number of node visits and the reward associated with it. The next step is expansion, where a child of the selected leaf node is added to the tree. In the simulation step, a random game is played from the added node and backpropagation uses the result obtained on the simulation to update the number of visits and reward associated with each node traversed in the tree. The intuition is that the selection process directs the search towards more promising tree regions, building an unbalanced tree tending towards stronger moves. Since the algorithm uses statistics, it may return a suboptimal move with finite time. Even so, it tends to choose better moves given more time.\nThis report uses the Upper Confidence bounds for Trees (UCT) variant of MCTS (Kocsis and Szepesvari [2006]), which is simple to implement and understand. During selection, UCT favors nodes with the highest average reward plus its upper confidence bound, related to how frequently the node was visited. Given infinite time, this variant is guaranteed to infer the path that maximizes the reward."}, {"title": "Minimax", "content": "Minimax is another tree search algorithm. It differs significantly from UCT, since it calculates the value of the current state without the use of probability, requiring the construction of the entire subtree from the current state in a depth-first fashion. This allows the discovery of all terminal node values and the propagation of this information upwards. Since the tree grows exponentially, finding the true state value is unfeasible in most cases.\nA variation of this algorithm is the alpha-beta pruning, which reduces the number of evaluated states without losing optimality (Knuth and Moore [1975]). The Minimax algorithm variation used is an anytime variation with alpha-beta pruning and no heuristic. When the time limit is reached, the algorithm assumes that every non-evaluated state is a draw for the purpose of selecting a move."}, {"title": "Ludii", "content": "Ludii is a general game system designed to play, evaluate, and create a wide range of games (Piette et al. [2020]). Ludii provides a game description language for creating games and an API for developing agents.\nA game description language serves as a formalism for specifying the rules, objects, and behavior of a game in a structured format. By using the game description language, a game can be expressed in a concise and formal manner,"}, {"title": "Python-Java inter-process communication", "content": "When creating Python agents for Ludii, communication is necessary between the Java Virtual Machine (JVM) running Ludii and the Python interpreter running the agent. This communication is established using two different Java libraries, jpy and Py4J. In this work, we evaluate Ludii agents implementing anytime Minimax alpha-beta pruning and UCT in Python on both Python-Java bridges. The UCT agents are based on the Ludeme project agents78. The Minimax agents are based on the original alpha-beta pruning variant, with modifications to exclude heuristics and enable them to function as anytime agents.\nWhen implementing an agent with jpy, the jpy library source code was cloned from jpy's Git repository and built. Afterwards, the dependencies for the jpy project were added manually. To demonstrate how to create a working environment, we created a Git repository with the locally working project and a step-by-step guide. Simply cloning the repository may not yield the expected result, as the project was built for a specific environment. In other words, the steps must be followed to ensure the project functions properly in different configurations. The relevant characteristics of the experimental environment include Windows 11, Python 3.10, and Java 21.0.1, along with 16GB of RAM and an AMD Ryzen X Series processor featuring a clock speed of 3.6 GHz, 6 cores, and 12 threads.\nFor the Py4J agent, the Py4J Python module was installed using pip, and the Java library was built automatically. A Git repository with the Py4J project and a step-by-step guide is also provided10.\nPy4J uses a server to exchange data. Consequently, if the JVM starts the server, as in this implementation, the separate Python interpreter process that implements the agent must be executed before the agent is used by Ludii. Another consequence is the overhead caused by the network layer in communication between the JVM and the Python interpreter, which could be avoided by using other communication methods."}, {"title": "Performance Analysis", "content": "To evaluate the different libraries, we implemented each GGP algorithm using both libraries, with the only difference between the implementations being the Java-Python communication (i.e., the library itself). We also created an equiva-lent native Java agent to further improve the experiment and compare performance against a Java-only implementation.\nThe GGP algorithms used were UCT (Section 2.1) and an anytime Minimax with alpha-beta pruning and no heuristic (Section 2.2). In a preliminary analysis, the agents were evaluated in Chess, Go, and Shogi. The respective source codes for the implementations are available in the Git repositories previously mentioned. For the Java implementation, refer to ExampleUCT.java and Minimax.java, and for the Python implementations, refer to uct.py and minimax.py in both repositories.\nDifferent evaluation metrics were used for each algorithm. For the UCT agents, we evaluated the number of playouts in a fixed time. For the Minimax agents, we evaluated the number of expanded game states in 1 second. These metrics are intrinsically related to the nature of these algorithms: for UCT, more playouts provide more accurate estimates of action values, whereas for Minimax, more accurate estimates are obtained as the game tree is explored more deeply. We also conducted an average score evaluation for each agent. This average score was calculated with a win as 1, a draw as 0.5, and a loss as 0.\nThe comparison of the number of playouts used the average and standard deviation of playouts on the first move of a game when the agent was the first player. For each agent, 1000 evaluations were made. In Chess and Go, all agents had 1 second to make their move. For Shogi, only 2 playouts were performed in 1 second. Hence, the time used for evaluation in Shogi was 10 seconds. This difference in Shogi evaluation time arises from the relatively small number of playouts performed in 1 second, which would affect the standard deviation and the analysis results. The resulting average number of playouts in Shogi was subsequently divided by 10."}, {"title": "Performance Prediction", "content": "This section presents a regression analysis aimed at evaluating the influence of game features on the performance of MCTS and Minimax algorithms. Specifically, the following features are considered: game depth (d), which refers to the average number of moves required to complete a game; ply time (t), defined as the average time taken to process a move; and branching factor (b), representing the average number of possible moves at each game state. The objective of"}, {"title": "Conclusion", "content": "This technical report provides a comparative analysis of two Java-Python communication libraries, jpy and Py4J, within the context of Python-based GGP agents for Ludii, a general game system developed in Java. The UCT and Minimax algorithms were implemented using each communication library to evaluate the extent to which the choice of library influences the performance of the algorithms. Furthermore, predictive models were constructed to estimate the performance of these implementations based on game characteristics.\nWe conclude that performance improvements are closely correlated with the frequency of inter-process communication events, as communication between processes varies with the algorithm's design. UCT communicates between processes each time it executes a rollout and performs multiple rollouts, whereas Minimax does so a fixed number of times per node, which results in UCT being significantly impacted by communication overhead. Furthermore, Java implementations exhibit superior performance relative to jpy implementations, which in turn outperform Py4J implementations.\nA potential area for future exploration involves researching methods for communicating the game state to Python in a way that minimizes inter-process communication. This approach would enable the creation of Ludii agents entirely within Python, using jpy."}]}