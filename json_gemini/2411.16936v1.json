{"title": "Harnessing LLMs for Educational Content-Driven Italian Crossword Generation", "authors": ["Kamyar Zeinalipour", "Achille Fusco", "Asya Zanollo", "Marco Maggini", "Marco Gori"], "abstract": "In this work, we unveil a novel tool for generating Italian crossword puzzles from text, utilizing advanced language models such as GPT-40, Mistral-7B-Instruct-v0.3, and Llama3-8b-Instruct. Crafted specifically for educational applications, this cutting-edge generator makes use of the comprehensive Italian-Clue-Instruct dataset, which comprises over 30,000 entries including diverse text, solutions, and types of clues. This carefully assembled dataset is designed to facilitate the creation of contextually relevant clues in various styles associated with specific texts and keywords. The study delves into four distinctive styles of crossword clues: those without format constraints, those formed as definite determiner phrases, copular sentences, and bare noun phrases. Each style introduces unique linguistic structures to diversify clue presentation. Given the lack of sophisticated educational tools tailored to the Italian language, this project seeks to enhance learning experiences and cognitive development through an engaging, interactive platform. By meshing state-of-the-art AI with contemporary educational strategies, our tool can dynamically generate crossword puzzles from Italian educational materials, thereby providing an enjoyable and interactive learning environment. This technological advancement not only redefines educational paradigms but also sets a new benchmark for interactive and cognitive language learning solutions.", "sections": [{"title": "1. Introduction", "content": "While traditionally valued for their challenge and entertainment, crossword puzzles are increasingly recognized for their educational benefits. They provide an interactive learning environment that enhances the retention of both technical terms and general language skills, hence facilitating learning across various disciplines, improving language acquisition, and supporting cognitive development, through critical thinking and memory retention [1, 2, 3, 4, 5, 6, 7, 3, 8, 9, 2, 10, 11].\nThe integration of Natural Language Processing (NLP) and Large Language Models (LLMs) has further enhanced their effectiveness by providing sophisticated, contextually relevant clues for educational crosswords.\nThis paper presents a novel tool that uses LLMs to generate tailored Italian educational crossword puzzles from texts, offering various clue types. By integrating user-provided texts or keywords and applying fine-tuning techniques, the tool produces high-quality clues and answers, offering educators a resource to develop more interactive and effective instructional methods.\nFurthermore, a new dataset called \u00b9 has been compiled and will be released to the scientific community.\nThe layout of this paper is organized in the following manner: Section 2 surveys the relevant literature in detail. Section 3 explains the methods used for dataset collection and curation. In Section 3, we describe the computational techniques employed in our study. Section 4 reports the results derived from our experimental analysis. Finally, Section 5 closes with conclusive insights and the broader implications of our research findings."}, {"title": "2. Related Works", "content": "Among the pioneering efforts in the field of crossword puzzle generation, Ranaivo et al. have formulated a distinctive strategy that merges text analytics with graph theory, allowing for the extraction and refinement of topic-specific clues through NLP [12]. Another notable contribution comes from Rigutini et al., who laid the groundwork by utilizing advanced NLP to automatically generate crossword puzzles from online sources, representing a seminal step in the field [13, 14].\nIn parallel, Esteche and his team have focused on Spanish-speaking audiences by creating puzzles with the aid of electronic dictionaries and news articles to formulate clues [15].\nOn a different front, Arora et al. developed SEEKH, a system that integrates statistical and linguistic analyses to generate crossword puzzles in multiple Indian languages. Their approach emphasizes the identification of keywords to structure the puzzles [16].\nRecent progress in crossword puzzle generation has been notably advanced by the work of Zeinalipour et al. [17, 18, 19, 20], who demonstrated the use of large-scale language models to develop puzzles in languages with limited support, such as English, Italian and Arabic. Their research highlights the vast potential of computational linguistics in crafting puzzles that are both engaging and linguistically rich. Initially, they employed few-shot and zero-shot learning techniques to generate new crossword clues from text [18, 17].\nFurthermore, Zugarini et al. [21] introduced a method for generating educational crossword clues from the provided text in English.\nIn their Italian crossword puzzle generation study [18], Zeinalipour et al. initially used few-shot learning with large language models as-is. However, our current project goes a step further by introducing a specially designed dataset for this task in Italian. Additionally, we have developed open-source models that have been fine-tuned to significantly enhance performance for this specific application.\nThe current research initiates a novel approach by utilizing state-of-the-art language modeling to develop Italian crossword puzzles from given texts. By doing so, it enriches the toolkit for language education, thereby pushing forward the development of Italian crossword puzzles."}, {"title": "3. Methodology", "content": "We have developed an automated system that generates educational Italian crossword puzzles using LLMs, with the Italian-Clue-Instruct dataset at its core. Our approach leverages the adaptability of LLMs, like GPT-40, to create puzzles from text, with human validation for accuracy. Additionally, we fine-tuned models such as Llama3-8b-Instruct and Mistral-7B-Instruct-v0.3 to improve clue accuracy and relevance.\nA more detailed description of our methodology, illustrated in Figure 1, is provided in the following.\nItalian-Clue-Instruct\nData Collection Methodology Initiating the data collection process, we began by extracting the introductory portions of Italian Wikipedia articles. We use Wikipedia API and Beautiful Soup to automatically extract the pages. The prominent focus was placed on the bolded keywords that highlight the primary topic and other significant terms within each article. Beyond keyword identification, we also gathered a variety of essential metadata. This included metrics such as view counts, relevance assessments, brief narrative summaries, central headlines, related terms, categorization, and URLs. The uniform structure of the Italian Wikipedia significantly aids this process. By tapping into the introductory sections, which are particularly information-rich, we could systematically extract and outline the key concepts needed. This approach ensures a comprehensive data repository, capturing critical elements and insights from a diverse array of articles.\nData Enhancement To ensure the reliability and effectiveness of our data, we performed some filtering based on different criteria. The first filter was designed to prioritize the most important pages and those with the highest number of views. Firstly, articles were selected based on their popularity and relevance. To ensure a balanced and manageable dataset, we also discarded articles that were either too lengthy or too brief, specifically those with fewer than 50 words. Additionally, we removed keyword associations longer than two words to maintain the clarity and relevance of the crossword clues. Finally, we imposed restrictions on keywords to ensure they were between 3 and 20 characters in length and free of special characters or numerals. Multi-words expressions were also included as good keywords as they are quite common in crossword puzzles.\nFormulation of Various Prompts Crafting specialized prompts was pivotal for producing Italian crossword clues from a given text using GPT-40. The prompts were created to generate clues that were both informative and engaging, by incorporating crucial details and background context from the articles. Additionally, apart we aimed to elicit three specific types of clue varying in their syntactic structures:\n*   definite determiner phrases: nominal clues headed by a definite article and usually modified by adjectives, prepositional phrases (PPs) or relative clauses (RCs), like <La repubblica asiatica con capitale Tashkent, Uzbekistan> ('The Asian republic with Tashkent as capital', 'Uzbekistan'). Such clues are examples of definite descriptions which have been traditionally analyzed as carrying a uniqueness presupposition ([22]) when singular and a maximality presupposition [23] when plural. In the context of crosswords, clues of this kind refer to their solution as the single entity or the maximal plural entity satisfying the description.\n*   bare noun phrases [24]: the clue consists of a simple noun phrase (NP) with no determiner and typically modified by adjectives, PPs or RCs, for example <Grande centro commerciale di lusso con sede a Londra, Harrods> ('Luxury shopping mall based in London', 'Harrods'). In Italian, NPs are taken to denote a predicate that can be true of one or more individuals [22, 25]. Given the absence of the definite determiner, bare NP clues do not specify whether the referent of the solution uniquely satisfies the description [22], thus more than one solution could in principle be possible.\n*   copular sentences [26]: copular clues are clausal definitions structured as <copula predicate> with an elliptical subject as in <\u00e8 una salsa piccante tipica della Tunisia, Harissa> ('(It) is a spicy sauce typical of Tunisia', 'Harissa'). Copulas, like Italian essere ('to be') connect a subject with a non-verbal predicate, such as an adjectival phrase (AP), a PP or another nominal phrase (NP/DP). In crossword puzzles, the solution targets the precopular position of such sentences, i.e. the elliptical subject.\nTo accomplish this, we created three distinct prompts for each clue structure, and one prompt that does not specify the structure. This step allows us to test the syntactic sensitivity of the models employed and, more importantly it gives us the possibility of manipulating the structure to create variation not just with respect to the subject matter but also in the clue syntactic complexity. Moreover, generating clues with specific structures represents an interesting resource for the educational characterization of puzzles. Indeed, it is well-known from psycholinguistic research that different structures can elicitate different reactions in the processing which can be correlated with factors like age, linguistic disorders etc. and this can be exploited when creating puzzles specific for any solver's needs.\nAs for the prompt engeneering, the structure has been explicitated in one dedicated step of the prompt chain. For what regards the copular structure, which is widespread and widely used with different formulation, we include an example in the prompt (as shown in 9) to ensure that the required structure is given in output. It has been observed during the prompt trials that the validity of precise structures for clues strongly depends on the type of text given in input. The prompts used for clue generation in this study are presented in Figures 6, 7, 8 and 9, located in the Appendix.\nGeneration of Educational Italian Clues. Guided by the SELF-INSTRUCT framework [27], we devised a method to automate the generation of educational crossword clues in Italian, harnessing the power of LLMs. Central to our approach is the sophisticated GPT-40, an enhanced version of LLMs, renowned for its efficiency. A key differentiator of our strategy is the integration of contextual information with the clues produced. To achieve this, we carefully curated the content and keywords from the Wikipedia text extracted in previous sections. We used four distinct types of prompts, each designed to generate different categories of clues: bare noun phrases, definite determiner phrases, and copular sentences. These prompts were crafted to create diverse types of clues, ensuring alignment with our specific objectives for educational content in Italian.\nOverview of the Italian-Clue-Instruct Dataset Our research began with downloading 88,403 articles from the Italian Wikipedia, which we filtered down to 11,413 relevant entries. From this refined set, we selected 5,000 articles for clue generation, spanning 29 thematic categories. To enhance our dataset, we leveraged the capabilities of GPT-40, generating a minimum of three diverse clues per Wikipedia article, depending on the text length. This effort resulted in a compilation of 15,000 unique clues.\nThe dataset's in-depth analysis demonstrates a variability in context length, ranging from 10 to 1512 tokens, with most texts falling between 100 and 600 tokens. Figure 2 showcases the token distribution for contexts and clues, which have been processed using the Llama3 tokenizer. Typically, the clue-generation process results in clues ranging from 4 to 55 tokens in length.\nFigure 3 illustrates the spread of data across different categories. The dataset is notably dominated by the categories of \"Entertainment\", \"Geography\", and \"History\". In contrast, categories such as \"Mathematics\", \"Architecture\", and \"Languages\" are underrepresented.\nEvaluating quality of the Italian-Clue-Instruct Dataset Producing accurate and engaging Italian educational crossword clues is inhibited by the absence of a reference corpus, making it difficult to draw comparisons using standard measures, such as ROUGE scores."}, {"title": "4. Experimental Results", "content": "This section offers a detailed overview of the experiments conducted in the study. It begins with the training setup for the Italian-Clue-Instruct LLMs, including key parameters and computational resources. The performance of the models is then evaluated using automated metrics, such as the ROUGE score, to compare configurations and identify areas for improvement. This is followed by an in-depth analysis of human evaluations, focusing on relevance, coherence, and content quality to provide insights beyond automated metrics. Additionally, an example of a generated crossword puzzle is presented to demonstrate practical usability. The goal is to highlight the robustness and versatility of the proposed approach.\nTraining Setup The models Mistral-7B-Instruct-v0.3 and Llama3-8b-Instruct were fine-tuned using LORA [30], with parameters set to r = 16 and a = 32, across three training epochs, maintaining a total batch size of 64. The full experimental setup was performed on a server equipped with four NVIDIA A6000 GPUs, utilizing DeepSpeed [31] and FlashAttention 2 [32]. For the initial learning rate was configured at 3 \u00d7 10^{-4}. During inference, model distribution sampling was applied to generate clues for both Mistral-7B-Instruct-v0. 3 and Llama3-8b-Instruct, with a temperature parameter set to 0.1. Additionally, the parameters for top-p and top-k sampling were set to 0.95 and 50, respectively. Among the three epoch checkpoints, the one with the minimum loss was selected, which, in our case, turned out to be the second checkpoint.\nEvaluation Results with the Automatic Metrics We evaluated the resemblance between various sets of clues produced by different models (details shown in Table 1) and those generated by the GPT-40 model on a test set of 200 educational contexts. This evaluation was done using ROUGE scores. Our results indicate that the fine-tuned Mistral-7B-Instruct-v0.3 and Llama3-8b-Instruct models exhibit a closer similarity to GPT-40. On the other hand, the base Llama3-8b-Instruct model shows significantly lower similarity with minimal overlap. These outcomes highlight the efficacy of fine-tuning, demonstrating that using the Italian-Clue-Instruct dataset enhances the capability of Mistral-7B-Instruct-v0.3 and Llama3-8b-Instruct models in generating clues from Italian educational texts.\nEvaluation Results with the human evaluator Using a dataset of 100 Italian contexts, each containing 3 clues, a human evaluation was conducted on both the generated and base models. The results of this evaluation are depicted in Figure 5. The evaluation employed the 5-level rating system described in Section 3.\nThe table provided offers a comparative evaluation of the performance of language models in generating Italian clues from a given text. Specifically, the models Mistral-7B-Instruct-v0.3 and Llama3-8b-Instruct are evaluated based on both their base and fine-tuned configurations. Upon fine-tuning, Mistral-7B-Instruct-v0.3 displays a significant improvement, emerging as the top performer in category \"A\", and surpassing Llama3-8b-Instruct in terms of performance enhancement. These findings underscore the impact of fine-tuning on enhancing model capabilities, particularly highlighted by the performances of Mistral-7B-Instruct-v0.3 and Llama3-8b-Instruct, which feature 7 and 8 billion parameters, respectively. Furthermore, fine-tuning with the introduced dataset significantly increased the models' ability to generate Italian clues from the given text, illustrating the quality and effectiveness of the Italian-Clue-Instruct dataset.\nThe methodology for generating Italian crossword clues from educational texts was explored, enabling customized clues. This would allow educators to select suitable clues matching their teaching needs. The selected clues could in turn be used to automatically generate a crossword schema as discussed Zeinalipour et al. [17]. Figure 10 in Appendix shows an example puzzle, demonstrating the system's application."}, {"title": "5. Conclusion", "content": "A novel system for generating crossword clues from Italian text is introduced, leveraging the newly developed Italian-Clue-Instruct dataset. This dataset, which includes text, keywords, categories, and related crossword clues in Italian, is pioneering in this field. By fine-tuning two large language models (LLMs), Mistral-7B-Instruct-v0.3 and Llama3-8b-Instruct, using this dataset, we have achieved significant improvements in the models' ability to generate crossword clues from given text. The results highlight a substantial enhancement in model performance after fine-tuning. Both the Italian-Clue-Instruct dataset and the fine-tuned models are now publicly available, providing valuable tools for students and teachers to create educational crossword puzzles from Italian text."}]}