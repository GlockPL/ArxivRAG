{"title": "MEXA-CTP: Mode Experts Cross-Attention for Clinical Trial Outcome Prediction", "authors": ["Yiqing Zhang", "Xiaozhong Liu", "Fabricio Murai"], "abstract": "Clinical trials are the gold standard for assessing the effectiveness and safety of drugs for treating diseases. Given the vast design space of drug molecules, elevated financial cost, and multi-year timeline of these trials, research on clinical trial outcome prediction has gained immense traction. Accurate predictions must leverage data of diverse modes such as drug molecules, target diseases, and eligibility criteria to infer successes and failures. Previous Deep Learning approaches for this task, such as HINT, often require wet lab data from synthesized molecules and/or rely on prior knowledge to encode interactions as part of the model architecture. To address these limitations, we propose a light-weight attention-based model, MEXA-CTP, to integrate readily-available multi-modal data and generate effective representations via specialized modules dubbed \"mode experts\", while avoiding human biases in model design. We optimize MEXA-CTP with the Cauchy loss to capture relevant interactions across modes. Our experiments on the Trial Outcome Prediction (TOP) benchmark demonstrate that MEXA-CTP improves upon existing approaches by, respectively, up to 11.3% in F1 score, 12.2% in PR-AUC, and 2.5% in ROC-AUC, compared to HINT. Ablation studies are provided to quantify the effectiveness of each component in our proposed method.", "sections": [{"title": "1 Introduction", "content": "Despite the persistent challenges in clinical trial success, the increasing availability of historical data on clinical trials and extensive knowledge about both approved and failed drugs presents a unique opportunity. Leveraging machine learning/deep learning during the design stages of trials could significantly enhance our ability to predict their likelihood of success. This potential comes at a crucial time, as clinical trials, essential for new drug development, face significant challenges including high costs [23], lengthy timelines [18], and a low probability of success, often due to the difficulty of meeting the desired criteria [16, 20]. Accurate clinical trial outcome prediction has the potential to shift resources towards trials with a greater chance of positive outcomes, significantly optimizing the drug development landscape.\nNumerous prior efforts have been made to predict clinical trial outcomes and improve trial results, including using EEG measurements to identify biomarkers of efficacy, monitor treatment effects in real-time [2], predicting drug toxicity from molecular properties [10], and leveraging phase II results to forecast phase III outcomes [21]. In the past years, there has been heightened focus on the broader objective of creating a universal method for predicting trial results across various diseases. A very recent method titled Hierarchical IN-"}, {"title": "Limitations of State-of-the-Art Approaches.", "content": "Some prior works aiming to design models for clinical trial outcome prediction rely on biomedical knowledge graphs (BKGs) [3] representing the relationship between various biomedical entities. However, it is challenging to incorporate BKGs into clinical trial outcome predictions since public repositories cannot keep up with new discoveries in the literature [15], contain uncertain relations and have almost no information on rare diseases. This has severely limited the applications of BKGs to specific diseases, such as COVID-19 [11]. In contrast, more general models do not make use of BKGs. Among those, HINT [6] (Fig. 1 (Left)) achieves state-of-the-art performance on the Trial Outcome Prediction (TOP) benchmark. Nevertheless, it has three key limitations:\n\u2022 Paragraph-level Embedding Limitations. HINT utilizes paragraph-level embeddings to encode trial protocols. However, this approach does not distinguish between inclusion and exclusion criteria (which respectively specify characteristics that subject must and cannot have to be eligible to participate), potentially confusing the model about the trial's requirements. Additionally, HINT relies on the combination of ClinicalBERT [14] and sliding window [9], thus overlooking subtle nuances and interconnections between sentences within a paragraph, potentially missing critical information.\n\u2022 Reliance on hard-to-acquire data. Drug molecules are represented through their estimated pharmacokinetics properties (absorption, distribution, metabolism, excretion and toxicity) using a pre-trained model [5]. However, this approach is hindered by the need for extensive wet lab data to label these pharmacokinetics properties, which is expensive to acquire and unavailable for molecules that have not yet been synthesized. Additionally, when new drugs becomes available over time, the pretrained model requires retraining to incorporate this new knowledge.\n\u2022 Human biases in neural network design. Designing neural networks by connecting their modules based on human intuition regarding what they represent and how they should interact is a widely common approach [6,8,27]. Yet, this practice can limit the"}, {"title": "Our Approach.", "content": "We introduce a pioneering approach titled Mode Experts Cross-Attention for Clinical Trial Outcome Prediction (\u041c\u0415\u0425\u0410-CTP) \u2013 illustrated in Fig. 1 (Right). MEXA-CTP leverages the Cauchy loss [19] during optimization, so that the resulting model can use masked cross-attention to selectively combine rich representations extracted via modality-specific modules (referred as mode experts), thus incorporating data representing drug molecules, disease information, and trial protocols in a holistic way. Additionally, MEXA-CTP employs a normalized temperature-scaled cross-entropy (NT-Xent) [24] loss to further refine the knowledge captured in the learned representations, culminating in a robust model capable of leveraging cross-domain information. The proposed method outperforms the current state-of-the-art results on the Trial Outcome Prediction (TOP) benchmark while circumventing the dependence on hard-to-use or expensive-to-acquire data such as BKGs and wet lab data. Our main contributions are:\n\u2022 We introduce MEXA-CTP, a new method that integrates multi-modal data based on the concept of mode experts, and is optimized with Cauchy and contrastive losses to capture the relevant drug-disease, drug-protocol, and disease-protocol interactions, without resorting to hand-crafted structures.\n\u2022 We evaluate MEXA-CTP against several baselines including the SOTA method, HINT [6], using real world data from phase I, II and III clinical trials. \u041c\u0415\u0425\u0410-CTP yields up to 11.3%, 12.2% and 2.5% of improvement respectively in terms of F1, PR-AUC and ROC-AUC compared with HINT.\n\u2022 We conduct a case study and an ablation study to demonstrate the contribution of key components of MEXA-CTP to its prediction power."}, {"title": "2 Definitions and Notation", "content": "Before introducing MEXA-CTP, we formally define the key components of a (drug-based) clinical trial along with the notation used in this paper.\nDrug Molecule refers to a specific category of pharmaceutical compounds and chemical substances designed to produce pharmacological effects on a target disease."}, {"title": "3 Proposed Method", "content": "To tackle the limitations of the existing techniques, we introduce MEXA-CTP. It consists of the following four stages (see Fig. 2). Stage 1: The encoding module leverages modern, publicly-available encoders to extract raw representations for data from each mode (i.e., drug, disease, and eligibility criteria). Stage 2: The knowledge embedding module learns how to extract deep features from each mode utilizing the multi-head self-attention mechanism. Stage 3: The mode experts module learns how to capture interactions between drug-disease, drug-criteria, and disease-criteria pairs in a self-supervised fashion. Stage 4: The knowledge compensation module fuses all the information provided by the mode experts to predict the outcome of the clinical trial. Below we provide additional details."}, {"title": "3.1 Stage 1: Encoding Module.", "content": "This module processes data from multiple modalities/modes, including drug molecules, disease information and eligibility criteria. Specifically, we utilize DeepChem [22] to transform drug molecules, represented as SMILES strings, into drug molecules embeddings, ICDCODEX2 to map ICD-10 codes to target diseases embeddings, and BioBERT [17] to generate separate embeddings for the statement-level inclusion and exclusion criteria. We denote these initial embeddings respectively by UM(j), UD(j), Uic(j) and UEC(j). This approach enables us to capture the diverse aspects of the input data and extract meaningful representations for downstream tasks in clinical trial outcome prediction."}, {"title": "3.2 Stage 2: Knowledge Embedding Module.", "content": "This module enriches the information within each mode, contributing to more meaningful representations. By leveraging mode-specific knowledge and inter-relationships, this module enhances the overall understanding of drug molecules, disease information, and eligibility criteria. For drug molecules and target diseases, we utilize multi-layer transformer encoders to get enriched drug molecules embeddings U(3) and target diseases embeddings (3) separately. However, for in-"}, {"title": "3.3 Stage 3: Mode Experts Module", "content": "We model interactions between drug-disease, drug-criteria, and disease-criteria pairs using three mode experts. Each mode expert performs two main functions: (i) the token selection function chooses essential output tokens to serve as queries for constructing interactions with other mode experts, and (ii) the cross-attention function generates values and keys from source tokens S to respond to queries based on target tokens T from other mode experts, thereby accounting for interactions."}, {"title": "3.3.1 Token Selection.", "content": "The token selection for these interactions is based on filtering noisy information, which helps the model attend to the most relevant tokens for predicting each trial's outcome. We utilize a projection layer to predict the probability of each token being selected by the mode expert:\n$p(S) = sigmoid(S W_p)$,\nwhere $S \\in \\{U_M^{(3)}, U_D^{(3)}, U_C^{(3)}\\}$. Intuitively, $p_S$ represents the confidence that token S should be used for querying other experts. Note that all tokens S are used for generating keys and values for cross-mode attention.\nWe employ two mechanisms to control the quality of the output tokens T, to be sent to the cross-attention layer. First, we apply a hard margin to mask tokens with confidence levels lower than a specified threshold t; then we apply a soft margin which modulates S with its confidence level p's:\n$p'(S) = I_{p(S)<t} \\odot p(S), T = p'(S) \\odot S$,\nwhere $I_{p(S) < t}$ is an indicator function, $\\odot$ operator denotes element-wise multiplication. The soft margin step allows for a more gradual and continuous masking"}, {"title": "3.3.2 Cross-Attention.", "content": "The cross attention aims to build interactions between two modes. A mode expert from mode D\u2208 {M,D,C} combines information from its own mode (source tokens SD) with information from another mode D' \u2260 D received from the respective expert (target tokens TD) via cross-attention. More precisely, this operation is expressed as\n$I_{D'D} = softmax(\\frac{T_D W (S_D W)^T}{\\sqrt{d_k}}) S_D W$ , where the arrow direction signifies D' forwards target tokens to D. This mechanism is repeated for all mode pairs, allowing the model to capture interactions between different modes and learn meaningful representations. For conciseness, we adopt shorter notations for those pairs: Imd, Idm, Icd, Idc, Imc, Icm."}, {"title": "3.3.3 Self-supervised Learning.", "content": "We leverage the output tokens from mode experts with self-supervised learning to build better semantic-level representations. Unlike general contrastive learning methods in large language models (LLMs), we define anchors at the semantic level. For instance, we obtain pairs representing interactions between molecules and diseases from Imd, and the reciprocal pairs from Idm. We treat these pairs as positive samples and consider other pairs as negative samples by defining our contrastive loss as follows:\n$L_{contrastive} = - \\sum_{pair \\in P^+} log(\\frac{exp(sim(pair)/\\tau)}{\\sum_{pair_{all} \\in P_{all} exp(sim(pair_{all})/\\tau)}})$,\nwhere $P_+ = \\{(I_{md}, I_{dm}), (I_{cm}, I_{mc}), (I_{cd}, I_{dc})\\}, P_{all} = \\{(I_{D'D}, I_{\\delta'\\delta}) \\mid (D', D, \\delta', \\delta) \\in \\{m,d,c\\}^4 \\land (D' \\neq D) \\land (\\delta' \\neq \\delta) \\land (D' \\neq \\delta' \\lor D \\neq \\delta)\\}$, sim(.) is the cosine similarity function, and $\\tau$ is the temperature of the contrastive loss."}, {"title": "3.4 Stage 4: Knowledge Compensation Module.", "content": "The aim of the knowledge compensation module is to enhance interactions between molecules, diseases, and criteria. Following a self-attention encoder, we concatenate the output tokens from each expert and average them across the sequence dimension, and forward them through a projection head with a sigmoid function to predict the probability that the trial is successful:\n$\\hat{y} = \\sigma(f_{pred}(AVERAGE(I_{all})))$, where Iall = CONCATENATE(Imd, Idm, Icd, Idc, Imc, Icm).\nA class-weighted binary cross-entropy (wBCE) loss is used for guiding the model training due to the imbalance of negative/positive pairs:\n$L_{cls} = -w_0 y log\\hat{y} - w_1(1-y)log(1-\\hat{y})$,\nwhere w0 (w1) is the fraction of negative (positive) labels in the training set."}, {"title": "3.5 Loss function", "content": "The final loss is a combination of classification, Cauchy and contrastive losses:\n$L = L_{cls} + \\lambda_1 L_{cauchy} + \\lambda_2 L_{contrastive}$, where \u03bb1 and \u03bb2 are hyperparameters which help balance the Cauchy loss and contrastive loss. We conduct a grid search to tune \u03bb1 and \u03bb2 on the validation set."}, {"title": "4 Experiments", "content": "We carefully follow the same experimental settings as in the Trial Outcome Prediction (TOP) benchmark [6] to evaluate our model. In addition, to demonstrate the way the mode expert works and gain intuition on its importance, we visualize the token selection ratios. Last, to assess the capabilities of the learning components, we conduct ablation studies on different parts of our model."}, {"title": "4.1 Experimental Settings.", "content": "Dataset. To the best of our knowledge, the TOP benchmark includes all available trials and their outcomes from DrugBank\u00b3. To evalute the proposed model, we use the TOP benchmark and follow the same strategy for splitting the train, validation, and test sets. Specifically, for each"}, {"title": "4.3 Token Usage for Token Selection.", "content": "Regarding the analysis of the effectiveness of token selection in Section 3, we conduct an in-depth examination of that process by visualizing the selected rate of tokens by mode experts. In Fig. 3, we visualize the token selection"}, {"title": "4.4 Ablation Studies.", "content": "We conduct ablation studies for assessing (i) the effectiveness of MEXA-CTP's information aggregation method at the statement level, (ii) the contribution of positional embedding at statement level, (iii) the impact of using the Cauchy loss for selecting meaningful tokens, (iv) the influence of using the contrastive loss for cross-mode representation learning, (v) and token selection methods. In these studies we use the best hyperparameters for our model in phase III obtained in Section 4.2, unless stated otherwise."}, {"title": "4.4.1 Information Aggregation at the Statement Level.", "content": "Aiming to obtain the best representation for inclusion/exclusion criteria, we explore three methods for aggregating information at the statement level in Table 3: directly using the [CLS] token, averaging all tokens (except for [CLS] and [SEP] tokens), and summing all tokens (except for [CLS] and [SEP] tokens).\nAs shown in Table 3, using only the embedding of the first token ([CLS]) to represent the statement-level criteria yields the best performance. In addition to showing significant improvements in comparison to the other aggregation methods, it also leads to slightly"}, {"title": "4.4.2 Positional Embedding at Statement level.", "content": "To understand whether the order is an important feature of eligibility criteria, we conduct ablation study by experimenting with and without positional embedding for inclusion and exclusion criteria in Table 3. MEXA-CTP with positional embeddings shows improvements on F1, PR-AUC and ROC-AUC.\nWe introduce the Cauchy loss for token selection and the contrastive loss for cross-mode representation learning. We use \u03bb1 and \u03bb2 to control the magnitude of the loss, respectively. To examine the gains originating from each of these losses and compare them with their combined usage in"}, {"title": "4.5 Complexity Analysis", "content": "As a transformer-based model [12,13], \u041c\u0415\u0425\u0410-CTP's time complexity for training is O (dn\u00b2), where d is the hidden size of the attention model (we set d = 32), and n is the maximum number of tokens considered by the model. Given the maximum number of drug molecules, target diseases, inclusion criteria, and exclusion criteria, n \u2264 2 \u00b7 (5+5+8+5) = 46."}, {"title": "5 Related Work", "content": "Clinical Trial Matching. Many studies have focused on learning patient retrieval and enrollment information for predicting individual patient outcomes within clinical trials, rather than making overall predictions about trial success. Doctor2Vec [1] learns representations for medical providers from EHR data, and for trials from their descriptions and categorical information, in order to address data insufficiency issues such as trial recruitment in less populated countries. DeepEnroll [28] encodes enrollment criteria and patient records into a shared latent space for matching inference. COMPOSE [7] encodes structured patient records into multiple levels based on medical ontology and used the eligibility criteria embedding as queries to enable dynamic patient-trial matching. In contrast, our work focuses on predicting the"}, {"title": "Clinical Trial Outcome Prediction.", "content": "The first works using classic machine learning method for clinical trial outcome prediction focused on one specific trial [26]. More recently, there have been numerous efforts to build more general models. Hong et al. [10] focused on forecasting clinical drug toxicity using features related to drug and target properties, employing an ensemble classifier of weighted least squares support vector regression. RS-RNN [21] predicted phase III outcomes based on phase II results by considering time-invariant and time-variant variables. EBM-Net [15] inferred clinical trial outcomes by unstructured sentences from medical literature that implicitly contain PICOs (Population, Intervention, Comparison and outcome). More recently, HINT [6] incorporated drug molecule features, target diseases, and eligibility criteria to build a hierarchical graph (tree). While these studies optimize representation learning for either engineered features or manual-designed graph, our method MEXA-CTP predicts clinical trial outcome using same input as HINT but with minimal human efforts."}, {"title": "6 Conclusion", "content": "This paper presents MEXA-CTP, a novel lightweight approach for predicting clinical trial outcomes. MEXA-CTP addresses prior limitations by incorporating statement-level embeddings from eligibility criteria, and integrating multi-modal data via mode experts. By guiding the optimization loss through carefully designed loss functions (Cauchy Loss and contrastive loss), our model leverages \"mode expert\" modules to learn inter-"}, {"title": "A Encoding Module.", "content": "We observe that although drug molecules may differ, they often share some SMILES segments. Therefore, we create molecule embeddings by intelligently combining their SMILES segment representations as obtained by DeepChem [22]. To improve efficiency, we build an embedding dictionary DICTemb for each SMILES segment,"}, {"title": "A.1 Drug Molecules Embedding.", "content": "$DICTemb = \\{e_{s1}, e_{s2}, ..., e_{sV} \\}, e_{sk} = DEEPCHEM(s_k)$\nwhere sk; k \u2208 [1..V] is a SMILES segment and esk is the corresponding representation pre-computed by DEEPCHEM. Molecules embeddings are represented as a sequence of tokens from DICTemb, denoted by UM(i)."}, {"title": "A.2 Target Diseases Embedding.", "content": "Each target disease in a trial is represented using the ICD-10 code tree, which expresses how different diseases and related within the disease classification system. We encode the structural information of each code using the ICDCODEX package:"}, {"title": "A.2", "content": "$U_D^{(3)} = \\{e_{d_1^{(j)}}, e_{d_2^{(j)}},...,e_{d_{D_j}^{(j)}}\\}, e_{d_i^{(j)}} = ICDCODEX(d_i^{(j)})$, i \u2208 [1..Dj], where $U_D^{(3)}$ represents a sequence of tokens for target disease embeddings."}, {"title": "A.3 Eligibility Criteria Embedding.", "content": "We split the inclusion and exclusion criteria at the statement level based on the keywords \"inclusion\" and \"exclusion\". If these keywords are not found, we consider the entire paragraph as inclusion criteria, and use zero vectors for the exclusion criteria embedding. We use BioBERT [17] to extract information from each statement, adding [CLS] (classification) and [SEP] (separator) tokens as per the model's convention. The inclusion and exclusion statement-level embeddings are denoted by"}, {"title": "A.3", "content": "$U_{IC(3)} = \\{e_{ic_1^{(j)}}, e_{ic_2^{(j)}},..., e_{ic_{|IC|}^{(j)}}\\}$,\n$U_{EC(3)} =$"}, {"title": "B Knowledge Embedding Module.", "content": "Drug Molecules & Target Diseases. The dimensions of the drug molecules embeddings UM(i) and target disease embeddings UD(5) are intentionally kept low to reduce the complexity of the model and improve computational efficiency. However, to enrich the features in each mode and capture more complex relationships, we utilize a multi-layer transformer encoder. This allows us to effectively process and encode the information from the low-dimensional embeddings, enabling the model to learn more nuanced representations that can better capture the characteristics of the drug molecules and target diseases.\nTherefore, we get enriched drug molecules embeddings UM(3) and target diseases embeddings (3) We use dk = 32 as the dimension size of enriched tokens."}, {"title": "B.1", "content": "$B_2$ Eligibility Criteria. We treat inclusion and exclusion criteria separately. As they originate from highly structured text inputs, the order of statements in eligibility criteria can determine the logical flow and requirements for inclusion or exclusion. As in this case, the order of statements often reflects the order of importance or relevance in the context of eligibility criteria for clinical trials, with key information typically presented first. Understanding the statement order allows the model to capture these relationships and make more accurate predictions. By considering the statement order, the model can better prioritize and interpret the information in the text. To capture the statement order as a key feature, we enhance the model by adding sinusoidal positional embeddings to the statements with its corespondent order. We utilize a multi-layer transformer encoder with siamese design [4] to capture information from both inclusion and exclusion criteria to get U\u2081(3) and Unc(i). Then we merge outputs of the inclusion criteria and exclusion criteria together as the enriched embedding of eligibility criteria U (3) CONCATENATE (UTC(3), UC(3))."}, {"title": "B.2", "content": "C Baselines.\nML-based methods. Implementation. We utilized scikit-learn packages for all machine learning baselines, including Logistic Regression, Random Forest, k-Nearest Neighbor + Random Forest, XGBoost, Adaptive Boosting, a 3-layer Feed-Forward Neural Network.\nData Preprocessing. We utilize the same encoding module outlined in appendix A. For handling missing values, if the method involves k-nearest neighbors, we will generate k clusters using the non-missing values and predict the missing value based on the centroid of the corresponding cluster. For methods that do not incorporate clustering, we will substitute missing values"}]}