{"title": "Accurate Water Level Monitoring in AWD Rice Cultivation Using Convolutional Neural Networks", "authors": ["Ahmed Rafi Hasan", "Niloy Kumar Kundu", "Saad Hasan", "Mohammad Rashedul Hoque", "Swakkhar Shatabda"], "abstract": "The Alternate Wetting and Drying (AWD) method is a rice-growing water management technique promoted as a sustainable alternative to Continuous Flooding (CF). Climate change has placed the agricultural sector in a challenging position, particularly as global water resources become increasingly scarce, affecting rice production on irrigated lowlands. Rice, a staple food for over half of the world's population, demands significantly more water than other major crops. In Bangladesh, Boro rice, in particular, requires considerable water inputs during its cultivation. Traditionally, farmers manually measure water levels, a process that is both time-consuming and prone to errors. While ultrasonic sensors offer improvements in water height measurement, they still face limitations, such as susceptibility to weather conditions and environmental factors. To address these issues, we propose a novel approach that automates water height measurement using computer vision, specifically through a convolutional neural network (CNN). Our attention-based architecture achieved an R2 score of 0.9885 and a Mean Squared Error (MSE) of 0.2766, providing a more accurate and efficient solution for managing AWD systems.", "sections": [{"title": "1 Introduction", "content": "Irrigation is the largest water-demanding sector in Bangladesh, accounting for approximately 86% of the total water use, primarily for crop production [1]. This demand is closely tied to regional climatic conditions. As one of the most vulnerable countries to climate change, Bangladesh faces critical challenges from water-related impacts [2]. Observations and climate projections indicate that freshwater resources will be severely affected by climate change, with far-reaching consequences for human health and agriculture [3]. According to the IPCC, by 2050, about 25% of the global population will live in regions facing water scarcity due to climate change and increasing water demand [4]. In Bangladesh's southwest coastal zone, the total freshwater river area is projected to shrink from 40.8% in 2012 to 17.1% by 2050 [5].\nBangladesh's crop production spans three concurrent seasons, with rice (paddy) covering about 42% of the land during the Boro season. This season accounts for 19.56 million tons of clean rice, around 54% of the country's total rice production [6]. The Bangladesh Agricultural Yearbook 2021 reports that 97.36% of Boro rice was cultivated using irrigation, with 93.67% of that irrigation sourced from groundwater. Groundwater irrigation, particularly for dry-season rice, has expanded significantly in recent decades, playing a crucial role in the country's food security [7]. However, this increased consumption has adversely impacted the water balance, especially in the northwest, where groundwater levels have dropped due to excessive usage [8].\nAs freshwater availability declines across many Asian countries including Bangladesh, the de-mand for rice continues to rise [9]. Approximately 50% of available freshwater is used for rice production [10], but this resource is no longer as abundant as it once was [11]. The growing demand for rice, coupled with increasing water scarcity, necessitates producing more rice with less water [10]. In the face of climate uncertainties and hydrological extremes, adopting efficient water management practices is critical to sustaining food production for about half the global population. Lampayan et al. [12] demonstrated that the water level in experimental fields was manually monitored using a measuring stick on a PVC water tube. Reducing water use in irrigation systems, especially for rice and other economically important crops, is essential.\nOne promising water-saving technique is the Alternate Wetting and Drying (AWD) irrigation method, where the field is allowed to dry until a threshold water level is reached before re-irrigation [12]. AWD has been proven to reduce irrigation water consumption without significantly affecting rice yields [13, 14, 15, 16]. It also reduces methane (CH4) emissions [17, 18, 19, 20, 21, 22, 23, 24], making it a viable option for mitigating global warming potential from rice cultivation. Linquist et al. [18] found that AWD reduced global warming potential by 45-90% compared to continuous flooding. Besides environmental benefits, AWD also lowers labor requirements by reducing the frequency of irrigation [25]. Demonstrations and training programs are key to encouraging its adoption among farmers [14, 26]. Farmers who implemented AWD reduced irrigation frequency by 28% on average and saw a nearly 20% reduction in irrigation costs [27]. In some cases, rice yields increased by 0.4 to 0.5 tons per hectare (around 10%), with farmers reporting healthier crops and improved plant development [27, 28, 26].\nHowever, excessive standing water can reduce transpiration rates [29], and decreased stomatal conductance can lead to reduced photosynthesis and biomass [30]. This presents a challenge in manually monitoring field water levels to ensure they do not fall below the safe threshold. Advances in sensor technology have alleviated this burden by enabling remote monitoring. Recent innovations in real-time field water level monitoring have helped farmers make informed irrigation decisions. Wireless sensors, capable of monitoring field water levels, soil moisture [31], and climatic variables [32, 33], have evolved significantly. Kalyan et al. [34] suggested using soil moisture sen-sors to measure water height in AWD, while Pham et al. [35] demonstrated that IoT-based water level measurements could maximize AWD's water-saving benefits. These technologies offer various sensor types, communication protocols, and system architectures, providing affordable and effective solutions for real-time water monitoring [32].\nDespite these advancements, ultrasonic sensors used in irrigation systems have limitations, es-pecially during harsh weather, which can reduce accuracy and reliability. Therefore, a more reliable and real-time water height estimation system is needed to ensure accurate measurements over large irrigation areas.\nThe primary contributions of this study are as follows:\n1.  We introduce a novel dataset specifically designed for water height estimation in AWD sys-tems. This dataset plays a crucial role in improving the accuracy and efficiency of water level monitoring in lowland crop production systems.\n2.  Our study proposes an innovative solution that integrates camera technology with AI algo-"}, {"title": "2 Proposed Methodology", "content": "In this section, we outline the architecture of the proposed network for identifying water height in the AWD system and provide details of its component modules. We begin by briefly describing the architecture of the pre-trained networks we used, ConvNeXt, followed by a detailed explanation of our proposed architecture and the modules integrated within it. Additionally, we incorporate an attention mechanism to enhance the model's focus on relevant features. Figure 1 illustrates the overall workflow of our proposed work."}, {"title": "2.1 Overview of Our Proposed Architechture", "content": "From Figure 1, we start by preprocessing the images. We resize them to 224 \u00d7 224 dimensions and normalize their pixel values to ensure they are consistent. After preprocessing, we apply image augmentation techniques, which increase the total number of images from 1,275 to 2,250. Finally, we split the dataset into training, testing, and validation sets in a ratio of 80:10:10."}, {"title": "2.2 ConvNeXt as a Base Architecture", "content": "ConvNeXt [37] is a state-of-the-art architecture built upon the original ResNet50 framework and incorporates ideas from hierarchical Vision Transformers, like the Swin Transformer [38]. It has a multistage architecture with different resolutions for feature maps at each stage. Key design aspects of ConvNeXt include the stage compute ratio (SCR) and the structure of the stem cell. The SCR, with a ratio of 3:3:9:3, defines the number of blocks per stage. The stem cell structure is updated with a patchify layer that uses a 4x4 convolutional kernel and a stride of 4, replacing the ResNet-style stem cell [37].\nConvNeXt also includes several advanced design elements. It uses a depthwise convolution layer with a network width of 96, maintaining the same channel configuration as the Swin Transformer, a concept called \u201cResNeXt-ify.\u201d It employs an \"Inverted Bottleneck\" design, similar to transformer architectures, with an expansion ratio of 4, meaning the hidden dimension of the multi-layer per-ceptron block is four times wider than the input dimension [37]. Additionally, ConvNeXt uses 7x7 depth-wise convolutions within each block to capture more comprehensive spatial information. It also integrates various layer-wise micro designs, such as the Gaussian Error Linear Unit (GELU) activation function instead of ReLU, and layer normalization (LN) instead of batch normalization. These enhancements together contribute to ConvNeXt's superior performance in image recognition tasks.\nIn our study, we used ConvNeXt for transfer learning to identify water height in the AWD (Alternate Wetting and Drying) system. This method helps improve water management in agricul-ture by accurately measuring water levels. By using ConvNeXt and transfer learning, we aim to demonstrate the effectiveness and adaptability of deep learning models in practical applications."}, {"title": "2.3 Convolutional Block Attention Module (CBAM)", "content": "Attention Mechanisms is one of the modern techniques used in Neural Networks in the field of Computer Vision. Human vision is the source of inspiration for attention mechanisms. These mechanisms help the model focus on specific regions or features. In AWD system, it is hard to capture the feature from the above by the camera as it is influenced by various factors such as lighting conditions, water reflections and complex background structures.\nTo address these challenges, we incorporated different attention block modules in our pre-trained CNN model to reduce the error of the system. We experimented with Squeeze-and-Excitation block, Channel Attention Module and Spatial attention block. Convolutional Block Attention Module (CBAM) [36] includes both Channel attention block and Spatial attention block."}, {"title": "2.3.1 Channel Attention", "content": "The channel attention mechanism in the CBAM is designed to focus on 'what' is important given an input feature map. This mechanism applies GAP and global max pooling operations across the spatial dimensions of the input feature map independently to generate two different context descriptors which are $F_{avg}$ and $F_{max}$ (See Equation 1 and Equation 2) [36].\nThese descriptors are then passed through a shared network, which is a multi-layer perceptron (MLP) with one hidden layer. The outputs of the MLP for the average-pooled and max-pooled features are combined using element-wise summation, followed by a sigmoid activation function to produce the final channel attention map Mc.\n$F_{avg}^{C}$ = MLP(AvgPool(F))\t\t(1)\n$F_{\u0442\u0430\u0445}^{C}$ = MLP(MaxPool(F))\t\t(2)\n$M_{C}(F) = \u03c3(F_{avg}^{C} + F_{max}^{C})$\t\t\t(3)\nwhere F is the input feature map, o denotes the sigmoid function, AvgPool and MaxPool represent GAP and global max pooling operations, respectively. The resultant channel attention map Mc is then used to recalibrate the input feature map.(See Equation 3) [36]. The Figure 3 shows the channel attention module."}, {"title": "2.3.2 Spatial Attention", "content": "The spatial attention mechanism in CBAM focuses on 'where' is important by exploiting the inter-spatial relationships of features. Unlike the channel attention mechanism, spatial attention operates on the channel-wise aggregated features. To achieve this, the input feature map is first aggregated along the channel axis using GAP and global max pooling, resulting in two 2D maps which are $F_{avg}^{s}$ and $F_{max}^{s}$ [36]. Equation 4 and 5 shows the calculation and Equation 6 shows the spatial feature maps calculation.\n$F_{avg}^{S}$ = AvgPool(F, axis = channel) \t\t\t\t (4)\n$F_{max}^{S}$ = MaxPool(F, axis = channel)\t\t\t\t(5)\n$M_{S}(F) = \u03c3(Conv([F_{avg}^{s}; F_{max}^{s}], kernel size = 7)) \t\t\t(6)\nwhere o denotes the sigmoid function, kernel size 7 denotes 7 \u00d7 7 kernal size and Conv represents the convolution operation. The attention map Ms is used to recalibrate the input feature map spatially [36]. The Figure 4 shows the diagram of spatial attention module."}, {"title": "3 Experimental Analysis", "content": "In this section, we represent the experimental results and rigorous analysis of our experimented models with statistical validation."}, {"title": "3.1 Dataset Description", "content": "The dataset utilized in this study was sourced from the two location. The first location was Lal-monirhat and the second location was Gazipur in Bangladesh. The dataset includes measurements of water height at different time intervals, as well as corresponding environmental factors such as temperature, humidity, and rainfall. It was taken from a ESP-32 camera with the IoT device box which was installed in the rice field. We took both day and night pictures. The dataset was collected over a span of several months to capture the seasonal variations in water height. The height of the AWD pipe was 25 cm with the radius of 10 cm. The camera was installed in a fixed position facing the AWD pipe to capture images of the water level. We took the water height from ultrasonic sensor as ground truth for training and evaluating the water height detection model. We took images and height at the same timestamp to ensure accurate labeling of the water level in the images.\nOur dataset had 1,275 data points. To make the dataset bigger and more varied, we used data augmentation. This is important for improving our model, especially because the dataset is small. We applied three types of augmentation: rotation, flipping, and brightness adjustment. These methods change how the images look, which helps the model perform better in real life. We randomly applied one of these augmentation methods to each image. As a result, the total number of images was increased to 2,550. This approach not only diversifies the training data but also ensures that the model can learn to recognize water height under various conditions and perspectives."}, {"title": "3.2 Preprocessing", "content": "In the preprocessing pipeline, the input image is first loaded and resized to 224 \u00d7 224 to ensure all images have the same size. Resizing images ensures they are uniform, which is important for consistency and helps reduce the workload during training or inference. Followed by Gaussian blurring is applied to reduce noise and smooth out small variations. It smooths the image by averaging pixel values with their neighbors, which helps to suppress noise and minor artifacts that could interfere with subsequent processing steps. The unsharp mask technique is then used to sharpen the image and make edges and details more visible. It subtracts a blurred version of the image from the original image, thereby emphasizing edges and fine details, which can be critical for tasks requiring precise feature extraction. Converting the image to grayscale simplifies the processing. This reduces the image from three color channels to one, making it easier to work with and focusing on light and dark variations instead of colors. Canny edge detection is then used to find prominent edges. This method highlights important edges in the image, which helps in identifying object boundaries and structures. The edge map is then inverted to standardize how edges are represented. Inverting ensures that edges are consistently represented in all images. Finally, normalization is applied to scale the pixel values to a standard range. Normalization, often scaling values between 0 and 1, improves numerical stability and helps the machine learning algorithms work better by ensuring consistent input values."}, {"title": "3.3 Parameters of the experiment", "content": "To train the proposed model, we incorporated an augmented dataset, which was divided into three portions with an 80:10:10 ratio: 80% of the images were used for training, 10% for validation, and 10% for testing. We initialized the ConvNeXt architecture with pre-trained weights. For our dataset, the batch size was set to 8, and the learning rate was 0.0001. We used Mean Square Error (MSE) as the loss function and the Adam optimizer to train the model over a total of 30 epochs. The experi-"}, {"title": "3.4 Evaluation Metrics", "content": "In this study, we use two different metrics to quantify the experimental results: MSE and R-squared score. The expressions of the metrics are described as follows:\nMean Squared Error = $\\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y_i})^2$ \t\t\t\t (7)\nR2 Error = 1- $\\frac{\\sum_{i=1}^{n} (y_i - \\hat{y_i})^2}{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}$ \t\t\t\t\t(8)\nHere, $y_i$ represents the actual value, $\\hat{y_i}$ represents the predicted value, and n denotes the num-ber of observations. In eq. 7 the summation term $\\sum_{i=1}^{n} (y_i - \\hat{y_i})^2$ calculates the squared differences between the actual and predicted values for each observation, and the mean of these squared differ-ences is obtained by dividing by n. This metric effectively penalizes larger errors more than smaller ones, making it a robust measure for evaluating model performance. In eq. 8, the numerator $\\sum_{i=1}^{n} (y_i - \\hat{y_i})^2$ is the sum of the squared errors of the model, and the denominator $\\sum_{i=1}^{n} (y_i - \\bar{y})^2$ is the total sum of squares (TSS), which measures the total variance in the actual data. The R2 score ranges from 0 to 1, with values closer to 1 indicating that a greater proportion of variance is explained by the model, and thus, the model has a better fit."}, {"title": "4 Result Analysis", "content": "In our initial experiments, we focused on baseline CNN models without incorporating attention blocks. We selected several well-known pretrained models for our analysis, including InceptionNetV3 [39], VGG16 [40], ResNet50 [41], EfficientNetB0 [42], and ConvNeXt. These models are widely recognized as benchmark architectures for image classification tasks, providing a solid foundation for evaluating performance in our study.\nWe tested the models with our test set. ConvNext performed better among all the pretrained models with the MSE of 0.2700 cm and R2 score of 0.9884. EfficientNetB0 showed higher MSE score which is 1.1404. The Resnet50 is another model which performs relatively well than Vgg16 and InceptionNetV3. The experimental results are shown in Table 1.\nThe ConvNeXt model was tested with new field data and was decided for deployment but the model was failing to predict images accurately which had noises and cpatured in low light or comparatively blurred.\nTo address the shortcomings of the ConvNeXt model, particularly its difficulty in accurately pre-dicting images with noise, low light, or blur, we incorporated attention mechanisms into the architec-ture. Specifically, we integrated Convolutional Block Attention Module (CBAM) and Squeeze-and-Excitation Networks (SENet) into the pretrained ConvNeXt architecture to enhance its performance on challenging image conditions. CBAM and SENet blocks have shown remarkable capabilities in enhancing feature representation after incorporating with Resnet50 and ConvNeXt architectures. These mechanisms allow the model to dynamically focus on informative regions of the image, thereby improving its ability to handle variations in the input data. Our experimental results demonstrate significant improvements when these attention layers are applied to the ConvNeXt model."}, {"title": "4.1 Ablation study", "content": "To determine the effect of image preprocessing, attention mechanism and source of data, we trained and fine tuned our model. We experimented in various set of combinations to select the best available configurations for the proposed model."}, {"title": "4.2 Discussion", "content": "The results indicate that the proposed attention-based models outperformed the baseline CNN models in the water height estimation task. Prior to implementing attention-based solutions, we tested our hypothesis by collecting indoor data using the experimental setup illustrated in Figure 6.\nWe initially tested our model using indoor data collected in a controlled environment, where factors such as lighting, background conditions, air flow, and temperature were regulated. The indoor test data comprised images with clear water surfaces, free from noise or disturbances. In this controlled setting, the baseline CNN model without attention blocks performed well. However, when applied to outdoor data, the model's performance degraded significantly due to environmental factors and noise. The field setup presented several challenges, including thunderstorms, strong air flow, extreme sunlight fluctuations, water ripples, and reflections, all of which negatively impacted the model's accuracy on field data.\nTo better understand the effects of airflow and temperature, we tested our lab setup outdoors,"}, {"title": "5 Conclusion", "content": "In this paper, we introduced a robust water height estimation system using a CNN enhanced with attention mechanisms. We also proposed a novel dataset specifically designed for AWD systems, offering a reliable solution for water conservation in irrigation.\nOur experimental results show that incorporating attention mechanisms like CBAM and SE-net into the ConvNeXt architecture significantly improves water height estimation, even under challenging environmental conditions. The proposed system, which automates water height mea-surement using camera technology, offers high durability, reliability, and lower maintenance costs compared to traditional ultrasonic sensors. This solution can be deployed in the field to accurately measure water height and automatically adjust irrigation systems, contributing to more efficient water management in agriculture. It also supports deployment on both edge devices and cloud platforms.\nWhile the results are promising, this study has some limitations. The model's performance in extreme weather conditions, which were not extensively tested, could vary. Additionally, although the dataset is comprehensive, it may not cover every environmental scenario in diverse agricultural settings. In future work, we plan to expand the dataset to include a wider variety of conditions and explore additional attention mechanisms to further improve estimation accuracy."}]}