{"title": "A Systematic Literature Review on Deep Learning-based Depth Estimation in\nComputer Vision", "authors": ["Ali Rohana", "Md Junayed Hasan", "Andrei Petrovski"], "abstract": "Depth estimation (DE) provides spatial information about a scene and enables tasks such as 3D recon-\nstruction, object detection, and scene understanding. Recently, there has been an increasing interest\nin using deep learning (DL)-based methods for DE. Traditional techniques rely on handcrafted features\nthat often struggle to generalise to diverse scenes and require extensive manual tuning. However, DL\nmodels for DE can automatically extract relevant features from input data, adapt to various scene con-\nditions, and generalise well to unseen environments. Numerous DL-based methods have been developed,\nmaking it necessary to survey and synthesize the state-of-the-art (SOTA). Previous reviews on DE have\nmainly focused on either monocular or stereo-based techniques, rather than comprehensively reviewing\nDE. Furthermore, to the best of our knowledge, there is no systematic literature review (SLR) that com-\nprehensively focuses on DE. Therefore, this SLR study is being conducted. Initially, electronic databases\nwere searched for relevant publications, resulting in 1284 publications. Using defined exclusion and quality\ncriteria, 128 publications were shortlisted and further filtered to select 59 high-quality primary studies.\nThese studies were analysed to extract data and answer defined research questions. Based on the results,\nDL methods were developed for mainly three different types of DE: monocular, stereo, and multi-view.\n20 publicly available datasets were used to train, test, and evaluate DL models for DE, with KITTI, NYU\nDepth V2, and Make 3D being the most used datasets. 29 evaluation metrics were used to assess the\nperformance of DE. 35 base models were reported in the primary studies, and the top five most-used base\nmodels were ResNet-50, ResNet-18, ResNet-101, U-Net, and VGG-16. Finally, the lack of ground truth\ndata was among the most significant challenges reported by primary studies.\nKeywords: Deep Learning (DL), Artificial Intelligence (AI), Depth Estimation, Monocular depth\nestimation, Stereo Depth Estimation, Multi-view", "sections": [{"title": "1. Introduction", "content": "Depth Estimation (DE) is an essential component of the field of computer vision, enabling machines\nto understand the spatial arrangement of a scene in images or videos. DE calculates the distance to each\nobject in the image, similar to how humans perceive depth. This extra dimension of distance helps to\ncreate a 3-D representation of the environment, enhancing machines' abilities to navigate, interact, and\ncomprehend visual information more efficiently [1]. DE has had a significant impact on the development\nof intelligent systems and human-machine interactions. It is now essential for applications such as au-\ntonomous vehicles [2] [3], robots [4], autonomous navigation [5] [6], obstacle avoidance [7], object detection\n[8], virtual reality, and augmented reality [9].\nThe techniques for DE have evolved rapidly over the past few decades. Early approaches relied\nheavily on depth cues like vanishing points [10] to infer depth and focus-defocus techniques [11] that used\nthe variation in sharpness to estimate depth. However, these methods were not suitable for handling\ncomplex scenes, diverse environments, and non-constrained scenarios where these cues might not be\napplicable. Later, researchers developed several hand-crafted features-based methods like Scale-Invariant\nFeature Transform (SIFT) [12], which detects distinctive features in invariant images to scale variations,\nConditional Random Field (CRF) [13], which uses probabilistic graphical models to capture contextual\ndependencies for structured prediction, Markov Random Field (MRF) [14], which uses stochastic models\nover a set of random variables and models spatial dependencies, and Speeded-up Robust Features (SURF)\n[15], which detects and describes interest points in images that are robust to scale and rotation changes.\nHowever, these methods had several limitations. For instance, SIFT has limited performance in highly\ntextured and repetitive scenes [16], CRF is less efficient for large-scale problems [17], MRF requires careful\nmodelling of pairwise potentials and struggles with large optimisation problems [14], and SURF struggles\nin cases of extreme scale and rotation changes, making it less robust to viewpoint variations [15].\nOn the contrary, researchers developed methods such as Stereo Block Matching (StereoBM) [18] and\nSemi-Global Block Matching (StereoSGBM) [19] to calculate disparities for DE. These methods match\nthe defined area of blocks between two images taken from different perspectives. This breakthrough has\nlaid the foundation for subsequent developments of traditional DE methods, especially in computer vision\nand robotics. Traditional DE methods are primarily based on stereo vision. These methods measure\nthe binocular disparity between two images taken by cameras set at slightly different positions using\nstereo-matching algorithms and triangulation techniques. By adding spatial information, stereo-based\nDE provides accurate depth information, allowing one to understand the 3D structure of the scene and"}, {"title": "2. Methodology", "content": "The details of this study are presented in the following sections. Section 2 provides the details of the\nmethodology used to conduct this review. Section 3 provides the results answering each research question.\nLastly, section 4 presents the conclusions."}, {"title": "2.1. Review Protocol", "content": "This study adheres to the \"Guidelines for Performing Systematic Literature Reviews in Software\nEngineering\" by [28] The process of Systematic Literature Review (SLR) involves three primary steps, as\nillustrated in Figure 1.\nThe initial step involves planning the review, which includes identifying the review's necessity, for-\nmulating research questions, and developing search strategies. These strategies concentrate on selecting\nrelevant databases, creating effective search strings, and defining selection criteria. The second step is ex-\necuting the review, which involves choosing primary studies and extracting and synthesising data. Search\nstrings are utilized to scrutinise titles, abstracts, and keyword fields in selected databases. Publications\nthat meet the selection criteria are shortlisted, and a quality assessment process ensures that only high-\nquality publications are included. This step involves extracting and synthesizing data required to address\nresearch questions. The final step is reporting the findings. Research question answers and outcomes are\npresented through supporting figures and tables, culminating in a comprehensive representation of the\nstudy's results."}, {"title": "2.2. Research Questions", "content": "This study posits five critical research questions aimed at exploring, collecting, and presenting recent\ntrends, challenges, and the importance of the application of deep learning-based methods in DE.\nRQ.1: What are the importance and the critical applications of DE in computer vision?\nRQ.2: What are the recent advancements and developments in monocular and stereo DE approaches?\nRQ.3: What are the available datasets for DE, and what are their type, quantity, and quality?\nRQ.4: What methodologies and metrics are used to assess the outcome of DE?\nRQ.5: What are the main challenges and limitations of DE?"}, {"title": "2.3. Database and Search Strategy", "content": "For this SLR study, seven popular databases were selected to search for related publications. These\ndatabases were Google Scholar, IEEE Xplore, ScienceDirect, SpringerLink, Scopus, Web of Science, and\nWiley. Relevant keywords were combined into search strings, including \"depth estimation\" and \"deep\nlearning\" as initial keywords, and synonymous terms such as \"depth perception\", \"depth mapping\",\n\"monocular\", \"stereo\", and \"multi-view\" related to \"depth estimation\", as well as \"artificial intelligence\"\nand \"machine learning\" related to \"deep learning\". The general search string used was (\"deep learning\"\nOR \"machine learning\" OR \"artificial intelligence\u201d) AND (\"depth mapping\" OR \"depth estimation\u201d OR\n\"depth perception\u201d) AND (\"monocular\" OR \"stereo\" OR \"multi-view\u201d). The general string was then\nmodified based on each database's specific search criteria. For example, the keywords were adjusted to\naccount for character limits for Google Scholar and restrictions on Boolean characters for ScienceDirect.\nEach database's abstract, title, and keyword fields were searched, except for Wiley and SpringerLink,\nwhich only allowed keyword searches within the publications themselves. Filtering was done using selection\nand quality criteria. In total, 1284 publications were found through the search of the selected databases.\nThe specific search strings used for each database are listed below:\nGoogle Scholar: [(\"computer vision\" AND \"depth estimation\")] AND [(\"deep learning\u201d OR \u201cmachine\nlearning\" OR \"artificial intelligence\u201d) AND (\"monocular\" OR \"stereo\" OR \"Multiview\")]\nIEEE Xplore: (\"deep learning\u201d OR \u201cmachine learning\" OR \"artificial intelligence\u201d) AND (\"computer\nvision\" OR \"depth estimation\" OR \"depth perception\" OR \"depth mapping\") AND (\"monocular\"\nOR \"stereo\" OR multiview)"}, {"title": "2.4. Selection Criteria", "content": "During the initial search, numerous publications were discovered; however, a significant number of\nthem were irrelevant to the subject of DE. To address this issue and to improve the quality, specific\ncriteria were established to filter out irrelevant publications. Each publication was evaluated against\nthese criteria, and only those that did not violate any of the exclusion criteria were retained. This\nmethodology was based on the guidelines outlined by [28]. To ensure agreement on the eligibility of each\npublication, the Cohen Kappa statistic [29] was utilized. Finally, out of the 1284 publications, only 128\nwere deemed relevant and included in further study. The exclusion criteria used are given below:\n1. The publication is not related to DE in computer vision.\n2. The publication either contains duplicated content or has been retrieved from another database."}, {"title": "2.5. Collecting and Filtering Publications", "content": "The 128 publications underwent a rigorous evaluation to ensure that only high-quality primary studies\nwere included. To evaluate the publications, we utilized quality assessment criteria derived from the study\nby [30]. Each publication was assessed based on a series of questions, with a score of 1 (yes), 0 (no), or\n0.5 (maybe) assigned to each response. The total score for each publication was then calculated, and any\npublications scoring below three were excluded. Finally, 59 publications were selected as primary studies.\nFigure 2 shows the overall process for the selection of primary studies. The quality criteria employed in\nthis study are given below:\n1. Are the study's aims and objectives clearly stated?\n2. Is the study's scope, methodology, and experimental design clearly defined?\n3. Is the research process documented appropriately?\n4. Have all of the study questions been answered?\n5. Have any negative findings been presented?\n6. Do the study's conclusions align with its goals and purpose?"}, {"title": "2.6. Data Extraction and Synthesis", "content": "A comprehensive review of 59 primary studies was conducted to extract pertinent data for each research\nquestion. The specifics of the selected primary studies for this SLR study can be found in Table 1. Using a\nMicrosoft Excel spreadsheet, the relevant data was organized in rows for each primary study and columns\nfor each research question. The extracted data was focused on addressing the research questions, including\nthe objectives, the significance and practical applications of DE, the current global research trends for DE,\nthe latest advancements and developments in monocular and stereo DE approaches, available datasets\nfor DE, their type, quantity, and quality, performance evaluation methods and metrics, the publication\nyear and journal details, and challenges associated with the application of DL for DE. After synthesising\nthe extracted data, each research question was thoroughly answered. The results of this SLR study are\ndetailed in the following section."}, {"title": "3. Results", "content": "The results of this SLR study are\ndetailed in the following section."}, {"title": "3.1. RQ.1: Importance and the critical applications of DE", "content": "In 59 primary studies, researchers have identified the numerous uses of DE in various applications.\nFigure 3 provides an insightful overview of these applications, ranked from the most to least common.\nThe six most common applications of DE include autonomous vehicles, robotics, 3D scene reconstruction,\nAugmented Reality (AR), scene understanding, and Simultaneous Localisation and Mapping (SLAM).\nThese applications also encompass autonomous navigation, Virtual Reality (VR), and Unmanned Aerial\nVehicles (UAVs), among others.\nIn autonomous vehicles, DE enables accurate measurement of the distance of objects, allowing ve-\nhicles to recognize and navigate around obstacles. This information is used to create a 3D map of the\nenvironment, enabling the vehicle to make real-time decisions and navigate safely in diverse and challeng-\ning conditions. In robotics, DE enhances the versatility and efficiency of robotic systems across various\ndomains. Robots leverage DE for object manipulation, ensuring precise interactions in industrial and man-\nufacturing settings. In surveillance, depth perception enhances object tracking and anomaly detection.\nHuman-robot interaction benefits from DE, enabling robots to understand and respond to human ges-\ntures and movements. Additionally, depth information aids in 3D mapping, crucial for mapping unknown\nenvironments and creating detailed spatial representations for robots to navigate effectively in diverse\nand dynamic surroundings. DE is also instrumental in advancing the fidelity and utility of 3D scene\nreconstruction across diverse disciplines. Medical imaging benefits from precise DE for reconstructing\nanatomical structures in three dimensions, aiding in diagnostics and surgical planning. Archaeology and\ncultural heritage preservation leverage DE for creating detailed 3D models of artefacts and historical sites.\nIn AR, DE enhances realistic virtual object placement within the real world. Accurate depth information\nensures proper occlusion and alignment, creating immersive AR experiences. This technology is integral\nfor applications like virtual try-ons in e-commerce, interactive gaming, and architectural visualization,\nenhancing user engagement and interaction in AR environments. DE is vital for scene understanding"}, {"title": "3.1.1. Primary studies and global research trend for DE", "content": "Figure 4 presents the breakdown of primary studies based on their year of publication and the journal\nthey were published. This SLR study focuses on research studies that were published within the last five\nyears, covering the years from 2018 to 2023. As expected, the number of publications has steadily increased\nfrom 2018 to 2021, with the surge in popularity of deep learning-based methods being the primary driving\nfactor. The year 2021 had the highest number of related publications. These publications were featured\nin a total of 24 different journals, with Computer Vision and Pattern Recognition (CVPR) leading the\nway, followed by IEEE Access and the International Conference on Computer Vision (ICCV), with 15,\n9, and 8 publications respectively, from 2018 to 2023. Figure 5 showcases the current global research\ntrend for DE using DL through a Sankey chart. The chart is segmented into three categories: countries\nwith the highest number of related primary studies, learning paradigms, and depth estimation types.\nBased on the data, China has taken the lead in DL for DE research with 57.19% of the publications,\nfollowed by the USA at 16.84%, Australia at 5.26%, Germany at 4.21%, South Korea at 2.81%, and\nthe UK at 2.81% among others. The deep learning methods involve a variety of ways for algorithms\nto acquire knowledge, including supervised, self-supervised, semi-supervised, and unsupervised learning\nparadigms. Primary studies have reported the use of all four paradigms. Supervised learning entails\ntraining a model on a labelled dataset of input-output pairs. This enables the algorithm to learn how\nto map inputs to corresponding desired outputs, facilitating accurate predictions on new data. Of the\nprimary studies, 41.75% focused on the use of supervised learning. Self-supervised learning involves the\nmodel generating its labels from input data, promoting unsupervised learning through pretext tasks. For\nexample, the model may predict missing parts of an image, leading to improved feature representation.\nOf the primary studies, 34.39% focused on the use of self-supervised learning. It is interesting to note that\nthese studies are more recent, suggesting a shift towards the self-supervised learning paradigm in recent\nyears. Unsupervised learning involves training models on unlabelled data to uncover inherent patterns,\nstructures, or representations. This approach enables tasks like clustering, dimensionality reduction, and\ngenerative modelling without explicit guidance. Of the primary studies, 14.74% focused on unsupervised\nlearning. On the contrary, semi-supervised learning uses both labelled and unlabelled data during training.\nThis approach leverages both types of information to enhance model performance, making it particularly\nuseful when labelled data is scarce or difficult to obtain. Of the primary studies, 9.12% focused on the\nuse of semi-supervised learning.\nAs noted in the manuscript introduction, depth estimation can be divided into two primary types:\nstereo and monocular. Nevertheless, recent research has explored the use of Multiview DE, which involves\na 360\u00b0 perception of the scene geometry. Stereo DE uses two synchronised cameras to capture a scene from\ndifferent perspectives, calculating depth information by using the disparity between corresponding points.\nThis method provides highly accurate 3D perception. Conversely, MDE uses a single camera to estimate\ndepth from a 2D image. Multiview DE combines data from multiple cameras or viewpoints to enhance\ndepth perception by incorporating information from different angles, aiming to improve the accuracy of\ndepth estimates, particularly in complex scenes. Of the primary studies reviewed, 22.11% focused on"}, {"title": "3.2. RQ.2: Recent advancements and developments in monocular and stereo DE approaches", "content": "In recent times, attention mechanisms such as self-attention and channel attention have been incor-\nporated into DL-based MDE and stereo DE to capture contextual information more effectively. These\nmechanisms enable networks to focus on relevant features, which enhances the accuracy of DE [89].\nFurthermore, unsupervised learning strategies are being leveraged in MDE, which eliminates the need\nfor explicit ground-truth depth data. By using unlabelled monocular video sequences, these approaches\nenhance depth predictions through improved pose prediction and attention mechanisms [90]. Contempo-\nrary MDE networks utilize hierarchical feature extraction, combining low-resolution features that capture\nlong-range context with fine-grained features describing local context. This approach has been reported\nto enhance the representation of specific semantics and improve overall feature extraction [91]. Addi-\ntionally, recent models focus on designing efficient frameworks to address computational challenges. This\nincludes leveraging lightweight encoder-decoder structures, introducing novel attention architectures, and\nincorporating factorized convolutions to reduce the number of model parameters and enhance computa-\ntional efficiency [92]. Several novel approaches have been introduced to improve scalability across different\nscenes and scales. This includes adaptive multi-scale convolutions, dynamic cross-attention modules, and\nscale-sensitive features to handle variations in object size and scene complexity [93]. Monocular DE mod-\nels incorporate multi-task learning strategies, simultaneously predicting additional semantic information.\nThis leads to more robust and interpretable depth maps, aiding in scene understanding [94].\nOn the contrary, recent advancements in stereo DE focus on end-to-end learning, where deep neural\nnetworks are trained to predict depth maps directly from stereo image pairs. This approach eliminates\nthe need for handcrafted features and enhances the model's ability to capture intricate depth details [95].\nStereo model refinement has been reported to refine disparity estimations using advanced cost volume\nprocessing. Techniques such as pyramid voting modules and recurrent refinement units are reported to\ncontribute to more accurate and reliable disparity maps, especially in challenging scenarios [75]. Addi-\ntionally, the integration of semantic information into stereo DE has become a prominent trend. Models\nleverage semantic cues to enhance stereo correspondences and optimal transport algorithms are employed\nto suppress attention in non-visible areas, improving disparity estimation [96]. Adaptive fusion techniques,\nsuch as occlusion-aware distillation modules and occlusion-aware fusion modules, have been introduced to\nfuse depth predictions from different sources. These methods improve the reliability of depth estimates,\nespecially in regions with occlusions or challenging lighting conditions [57]. Stereo DE models now explore\nordinal regression techniques, predicting depth maps in an ordinal manner [97]. Context-based encoders,"}, {"title": "3.3. Datasets for DE, their type, quantity, and quality", "content": "The use of data is critical to the advancement of DL, as it lays the foundation for training and eval-\nuating DL models. The accuracy and robustness of these models are directly impacted by the quantity,\nquality and type of datasets used. With comprehensive and diverse datasets, deep learning models can\ngeneralize effectively and perform well across various scenarios. In 59 primary studies, researchers em-\nployed 20 publicly available datasets to train, test, and evaluate deep learning models for DE. These\ndatasets, which were recorded under different environmental settings such as outdoor, indoor, and syn-\nthetic, are available online. Table 2 provides details on the datasets used for DE, including their type,\nquantity, and quality. Of the 20 datasets, five were recorded outdoors, seven were recorded indoors, two\nwere recorded in both indoor and outdoor environments, and six were recorded in synthetic environments.\nThe number of images or videos used to record these datasets varied, and no established guidelines were\nfound in primary studies on the amount of data needed to create tangible DL models. The Make3D\ndataset had the least amount of data, with only 534 RGB images and corresponding depth maps, and\nincluded both indoor and outdoor scenes. The Oxford Robot Car dataset had the most data, with 20\nmillion RGB images with LIDAR scans and included solely outdoor scenes. Most of the datasets were\nrecorded for RGB images with either corresponding depth maps or LIDAR scans as ground truths. For\nquality, the Lightfield dataset had the lowest image resolution of 512 x 512 pixels, while the DDAD dataset\nhad the highest resolution of 4032 x 6048 pixels.\nThe usage rate of public datasets in primary studies was analysed, and Figure 6 depicts the results.\nAmong the available datasets, the KITTI dataset emerged as the most used one with a usage rate of\n45.30%. This dataset provides high-resolution images, lidar point clouds, and radar data, spanning various\nurban and highway environments. The dataset's diversity offers different testing scenarios, making it an\ninvaluable resource for evaluating algorithms. Moreover, it features ground truth annotations making\nit an essential benchmark for autonomous driving technology research. NYU Depth V2 is the second\nmost used dataset with a usage rate of 20.51%. It comprises indoor scenes captured by Microsoft Kinect,\nproviding RGB images and corresponding depth maps. This dataset's diversity in indoor environments"}, {"title": "3.4. RQ.4: \u0395valuation methods and metrics", "content": "The primary studies used 29 evaluation metrics to assess the performance of the DE. Figure 9 shows the\nusage rate of the evaluation metrics reported in the studies. The most consistent and prominent metrics\nwere Root Mean Squared Error (RMSE) (18.18%), Accuracy (17.13%), Absolute Relative Difference (Abs\nRel) (16.78%), Square Relative Difference (Sq Rel) (12.24%), RMSE log (9.09%), and log 10 (7.34%)\namong others.\nRMSE is a metric defined as the square root of the average of squared differences between predicted\n($x_i$) and ground truth ($x_i^*$) depth values for all pixels. Accuracy was reported in three different thresholds\n\u03b4 < 1.25, \u03b4 < 1.252, and d < 1.253, indicating the percentage of pixels for which the absolute relative"}, {"title": null, "content": "error falls within a specified threshold. Abs Rel computes the average absolute relative difference between\npredicted and ground truth depth values for all pixels. Sq Rel measures the average squared relative\ndifference between predicted and ground truth depth values for all pixels. These evaluation metrics are\ngiven below:\n\u2022 RMSE = $\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(x_i - x_i^*)^2}$", "formula": ["$\\sqrt{\\frac{1}{n}\\sum_{i=1}^{n}(x_i - x_i^*)^2}$"]}, {"title": null, "content": "\u2022 Accuracy with threshold (\u03b4) = % of $x_i$ s.t."}, {"title": null, "content": "$max(\\frac{x_i}{x_i^*},\\frac{x_i^*}{x_i}) < 1.25, \u03b4 < 1.25^2, \u03b4 < 1.25^3$", "formula": ["$\\frac{x_i}{x_i^*}$", "$\\frac{x_i^*}{x_i}$"]}, {"title": null, "content": "\u2022 Abs Rel = 1/\u03b7 $\u03a3_i\\frac{x_i - x_i^*}{x_i}$", "formula": ["1/\u03b7 $\u03a3_i\\frac{x_i - x_i^*}{x_i}$"]}, {"title": null, "content": "\u2022 Sq Rel = 1/\u03b7 $\u03a3_i \\frac{x_i - x_i^*}{x_i}$", "formula": ["\u03a3_i \\frac{x_i - x_i^*}{x_i}"]}, {"title": null, "content": "\u2022 RMSE (log) = $\\sqrt{\\frac{1}{n} \u03a3_i (log(x_i) \u2013 log(x_i^*))^2}$\nTo provide a comprehensive analysis, the primary studies showcased their findings across various\ndatasets including KITTI, NYU Depth V2, and Make3D. As such, this SLR study offers a detailed\ncomparison of diverse DE methods across these datasets, as outlined in Tables 6, 7, and 8, utilising the\nperformance metrics mentioned earlier. It is worth noting that the performance metrics that bear the\nsymbol\u2193 indicate that lower values are optimal, while those with the symbol \u2191 suggest that higher values\nare preferable.", "formula": ["$\\sqrt{\\frac{1}{n} \u03a3_i (log(x_i) \u2013 log(x_i^*))^2}$"]}, {"title": "3.5. RQ.5: Challenges and limitations in monocular and stereo DE", "content": "The challenges and limitations of monocular and stereo depth estimation (DE) techniques were thor-\noughly examined through the analysis of data from 59 primary studies. These challenges are crucial as\nthey significantly affect the development and application of DE methods across various computer vision\ntasks. Below, we discuss the key challenges identified in these studies, their underlying causes, and the\nlimitations they impose on DE systems.\nOne of the significant issues reported in DE is the lack of an effective mechanism to preserve cross-\nborder details in depth maps. These details, especially at object edges, are essential for maintaining\nhigh-resolution and sharp depth predictions. Without accurately preserving them, depth maps often\nexhibit blurred or inaccurate boundaries, which degrades performance in applications such as robotics\nand autonomous navigation [31]. Ensuring the preservation of cross-border details is critical for improving\nthe overall accuracy of DE models.\nMonocular depth estimation (MDE) is frequently described as an inherently ill-posed problem, mean-\ning multiple possible 3D configurations can exist for the same 2D image. Unlike stereo methods, which\nrely on disparity cues from multiple views, MDE must infer depth from a single image without explicit\ndepth cues. This results in significant depth ambiguity, where the model infers relationships between\nobjects based on limited information, leading to accumulated errors and a wide semantic gap [32]. This\nill-posed nature of monocular DE remains a persistent challenge requiring innovative solutions.\nIn deep learning-based DE methods, a major challenge arises from data imbalance caused by the\nperspective effect. Objects closer to the camera occupy more space in an image, resulting in an overrepre-\nsentation of small depth values (nearby objects) and fewer samples of large depth values (distant objects).\nThis imbalance skews the learning process, causing models to perform well on nearby objects but poorly\non distant ones. Additionally, rapid depth changes at object boundaries complicate the prediction pro-"}, {"title": null, "content": "cess, as models struggle to accurately capture these variations compared to other dense prediction tasks\nlike segmentation [33].\nAcquiring ground truth data for training supervised DE models presents another significant challenge.\nCollecting paired RGB images and depth maps requires specialized depth-sensing equipment such as\nLiDAR or Kinect, which are both costly and complex to deploy. Even when obtained, ground truth\ndatasets often contain noisy artifacts, particularly in reflective or dark environments, which can degrade\nDE model performance [34]. To address this data scarcity, synthetic datasets are frequently used, but\nthey suffer from poor generalization. Synthetic images, while visually appealing, lack the textures, noise,\nand complexities of real-world environments, causing models trained on synthetic data to perform poorly\nwhen applied to real-world scenarios [33]. Additionally, Depth sensors like radar, LiDAR, sonar, structured\nlight, and stereo cameras are widely used for data collection in industrial applications. However, these\nsensors have inherent limitations, including noise, sparse outputs, low resolution, and matching errors in\nstereo setups [47] [34]. These limitations introduce variability in depth data, reducing model accuracy\nand generalization in real-world settings.\nSupervised DE models also rely heavily on high-level semantic information to link visual cues to depth.\nThis often requires learning relationships between object recognition and DE, which is particularly difficult"}, {"title": null, "content": "in unconstrained environments like outdoor scenes, where lighting, object sizes, and scene layouts vary\nwidely. Learning such semantic information is computationally expensive and requires large, diverse\ndatasets, making it challenging even with advanced loss functions designed to capture depth relationships\n[35].\nAnother critical challenge in DE is scale ambiguity, where objects at different distances may appear\nsimilarly sized in 2D images. To overcome this, DE models must capture long-range context informa-\ntion\u2014the ability to infer relationships between distant parts of an image. Small, localized patches of an\nimage often lack sufficient depth cues, so broader scene context must be incorporated for accurate depth\npredictions. Techniques like atrous spatial pyramid pooling and serialized layers extend the receptive field\nto capture multiscale objects. However, issues like discretized dilation, used to improve receptive fields\nwhile maintaining resolution, can lead to grid artifacts\u2014undesired patterns or distortions in depth maps\n[53].\nWhile stereo methods are often preferred for their ability to estimate depth through disparity be-\ntween two images, monocular DE is appealing due to its simplicity and lack of hardware dependencies.\nMonocular DE leverages prior knowledge, such as monocular cues (texture gradients, occlusion, motion\nparallax), allowing for efficient 2D-to-3D problem-solving, and demonstrates potential in real-world sce-\nnarios. MDE eliminates the need for stereo rigs but still faces persistent challenges, including its ill-posed\nnature and difficulties in handling depth variations in complex environments [34]. Conversely, recent\nstereo-matching methods have improved disparity estimation in active stereo systems while maintaining\naccuracy. However, integrating such techniques into neural network-based stereo-matching systems for\npassive stereo-depth sensing remains an open question [84]. The choice between monocular and stereo\nmethods often depends on the trade-offs between cost, accuracy, and deployment feasibility.\nMonocular DE was found to be useful in medical imaging, particularly in procedures like endoscopy,\nwhere a single image is used to estimate depth. However, even in this domain, monocular DE encounters\nchallenges like image artifacts during depth synthesis, reducing the accuracy and reliability of depth maps\nfor medical diagnoses. These issues must be addressed to make DE systems viable in sensitive medical\napplications, such as anatomical reconstruction [3].\nAlthough good results have been achieved with DE, challenges such as the inability to estimate the\ndepth of certain objects, like windows, and the presence of artifacts persist [46]. Furthermore, the high\nsparsity of data highlights the need for further refinement and optimization in DE methods. Convolutional\nbackbones are essential for extracting features in DE, but downsampling\u2014the process of reducing image"}, {"title": null, "content": "or feature map resolution in the deeper stages of the model\u2014presents challenges for dense prediction\ntasks like depth estimation. Downsampling can result in a loss of fine details that are critical for accurate\ndepth predictions. Therefore, careful consideration of architecture design is crucial to maintaining feature\nresolution throughout the network to improve depth prediction accuracy [83", "42": ".", "44": ".", "86": ".", "43": [54], "36": "."}, {"86": "."}]}