{"title": "Think Twice Before Recognizing: Large Multimodal Models for General Fine-grained Traffic Sign Recognition", "authors": ["Yaozong Gan", "Guang Li", "Ren Togo", "Keisuke Maeda", "Takahiro Ogawa", "Miki Haseyama"], "abstract": "We propose a new strategy called think twice before recognizing to improve fine-grained traffic sign recognition (TSR). Fine-grained TSR in the wild is difficult due to the complex road conditions, and existing approaches particularly struggle with cross-country TSR when data is lacking. Our strategy achieves effective fine-grained TSR by stimulating the multiple-thinking capability of large multimodal models (LMM). We introduce context, characteristic, and differential descriptions to design multiple thinking processes for the LMM. The context descriptions with center coordinate prompt optimization help the LMM to locate the target traffic sign in the original road images containing multiple traffic signs and filter irrelevant answers through the proposed prior traffic sign hypothesis. The characteristic description is based on few-shot in-context learning of template traffic signs, which decreases the cross-domain difference and enhances the fine-grained recognition capability of the LMM. The differential descriptions of similar traffic signs optimize the multimodal thinking capability of the LMM. The proposed method is independent of training data and requires only simple and uniform instructions. We conducted extensive experiments on three benchmark datasets and two real-world datasets from different countries, and the proposed method achieves state-of-the-art TSR results on all five datasets.", "sections": [{"title": "I. INTRODUCTION", "content": "Ensuring traffic safety remains an important issue in the real world [1]. The latest statistics from the World Health Organization show that road traffic injuries are the leading cause of death among children and adolescents aged 5 to 29 years and that approximately 1.19 million people die each year due to road traffic accidents 1. Furthermore, road traffic accidents result in substantial economic losses and impose a significant burden on society [2]. Consequently, there is an urgent need to decrease road traffic accidents.\nTraffic sign recognition (TSR) is a technology that enables vehicles to identify traffic signs on dynamic road scenes. As an important part of the road, it is crucial to effectively recognize traffic signs for traffic safety. Advanced driver assis-tance systems help drivers make safer decisions by evaluating"}, {"title": "II. RELATED WORK", "content": "TSR has become a widely researched field, deriving many approaches to challenge this task. TSR is generally divided into two key steps: traffic sign detection (TSD) and traffic sign classification (TSC). TSD performs localization and de-tection of traffic signs in road images, while TSC performs classification on the detected traffic signs. There have been many studies based on traditional and deep learning methods for TSR."}, {"title": "1) Traditional TSR methods:", "content": "The early TSR studies focus on performing recognition based on hand-crafted features and machine learning algorithms. For example, hand-crafted features were used to extract features from traffic signs and machine learning algorithms recognized the extracted features. Zaklouta et al. [5] introduce a real-time system for detecting and classifying circular and triangular traffic signs. Kus et al. [41] introduced a method for detecting and recognizing traffic signs by improving upon the SIFT [8] algorithm. They enhanced SIFT by integrating features associated with the color of local regions. Huang et al. [7] propose a streamlined method for TSR by using HOG features and a single classifier trained with the extreme learning machine algorithm. The HOG feature strikes a balance between redundancy and local details, improving the representation of distinctive shapes. In this way, the traditional methods rely heavily on hand-crafted features, which are sensitive to variations in lighting, occlusion, and complex backgrounds [42]."}, {"title": "2) Deep learning-based TSR methods:", "content": "The emergence of deep learning has inspired TSR research. Compared with traditional hand-crafted feature-based methods, deep learning-based methods can better learn features of traffic sign im-ages. Zhang et al. [43] introduced two lightweight networks for improving recognition accuracy with fewer parameters. Abudhagir et al. [44] utilized the LeNet model for traffic sign recognition. Their CNN architecture consisted of the first two layers adapted from LeNet, followed by two addi-tional convolutional layers, a dropout layer, and a flattened layer. Zhu et al. [45] proposed a TSR method based on YOLOv5. Besides, transformer-based TSR methods have also been proposed. Zheng et al. [18] used a vision transformer (ViT) [46] to perform a detailed TSR evaluation. Luo et al. [16] proposed a TSR approach comprising a lightweight pre-locator"}, {"title": "B. Large Multimodal Models", "content": "The LLM has received a lot of attention recently [49]. As demonstrated by existing work [29], LLMs can solve a wide variety of tasks, in contrast to previous models that were limited to solving specific tasks. In addition, LMMS have been proposed [28], [31], [32], [50]\u2013[52] to address a wide variety of visual problems that exist in the real world. LMM further extends the capabilities of language models by integrating visual information as part of the input. This integration of visual data enables LMM to efficiently under-stand and generate responses that contain both textual and visual prompts, thus enabling richer context conversations in multimodal environments. In recent months, LMMs have also drawn attention in intelligent transportation fields, such as autonomous driving and mapping systems [53]. LMMs have the potential to revolutionize the traditional human-vehicle interaction paradigm [40]. LMMs can process information from text and image inputs captured by in-vehicle cameras to understand complex traffic situations. In addition, they can significantly enhance personalized human-vehicle interactions through voice communication and user preference analysis. Drivers can use languages, gestures, and even eyes to com-municate their requests while driving, and the LMM pro-vides real-time in-vehicle feedback through integrated visual displays. However, despite the unprecedented capabilities of LMMs, TSR-related studies based on LMMs remain to be explored."}, {"title": "III. METHODOLOGY", "content": "We explain the proposed fine-grained TSR method in this section. As shown in Fig. 2, our method first implements localization and detection on original road images and then the extraction of traffic signs is performed by the designed extraction detector. Next, we implement the proposed think twice before recognizing strategy for stimulating the fine-grained TSR capability of the LMM."}, {"title": "A. Traffic Sign Extraction", "content": "1) Segmentation: In the proposed method, we first perform segmentation of the original road image $I$ containing the traffic signs $i \\in \\{0,1,2,..., N\\}$. $N$ represents the number of traffic signs contained in the original road image. The original road image $I$ is input to the segmentation model. The segmentation model generates segmentation images $I'$ with various object category labels for the original image. As the recognition of traffic signs is performed, the traffic signs need to be distinguished from other objects. Specifically, in the segmentation image $I'$, each particular object category is coded as a different color for identification. We convert $I$ to a mask image $I_m$, thereby separating the traffic sign from the other objects and background in $I$. The segmentation model is not limited to a specific architecture.\n2) Extraction: The extraction of traffic signs is realized by a designed extraction detector. The extraction detector first obtains the coordinates of the traffic signs in the mask image $I_m$ using the contour detection algorithm [54]. Then, the extraction detector uses the original road image $I$ and the coordinates of the traffic signs to extract the image $I_N$ that contains only the real traffic signs. $I'$ removes other objects and backgrounds in the original road image. The extraction detector finally retrieves the traffic sign image $I^i$ from $I^N$ using the corresponding coordinates of the traffic signs. $T_i \\in \\mathbb{R}^{H \\times W \\times 3}$ represents the final extracted traffic sign image. Note that while $I^i$ can also be obtained directly from the original road image $I$ via the coordinates, the extracted traffic sign image contains unnecessary backgrounds. In contrast, the designed extraction detector can remove the backgrounds and avoid potential interference for subsequent recognition."}, {"title": "B. Think Twice Before Recognizing", "content": "After obtaining the traffic sign image $I^i$, we perform the think twice before recognizing strategy to stimulate the perceptual potential of fine-grained TSR with LMM. Our think twice before recognizing strategy consists of two steps: prior knowledge generation and multistep thinking."}, {"title": "1) Prior Knowledge Generation:", "content": "In the proposed method, prior knowledge includes context descriptions of original road images, characteristic descriptions of template traffic signs, and differential descriptions of similar traffic signs. The inputs of LMMs are typically an image $I^i$ and a text query $T^i = [t_1,..., t_{l_i}]$ with length $l_i$, and LMMs generate a sequence of textual output $T_{out} = [t_1,..., t_{l_o}]$ with length $l_o$ as follows:\n$T_{out} = LMM(I^i, T^i)$.\nContext Descriptions: Since original road images contain important contextual information about traffic signs, we trans-form original road images into context descriptions to fully utilize the scene information. Given an original road image $I$, the context descriptions $D_{cont} = [D_{cont}^1, ..., D_{cont}^{C_o}]$ are generated as\n$D_{cont} = LMM(I, T_{cont})$,\nwhere $T_{cont}$ represents the prompt for generating the context descriptions. As shown in Fig. 3, we carefully designed $T_{cont}$ so that the generated contextual descriptions contain the context background information understood by LMM from the original road image. Furthermore, as in the real-world question-answering process, we find that narrowing the range of answers can reduce the recognition difficulty of LMM. To this end, we propose a prior traffic sign hy-pothesis, which allows LMM to filter irrelevant traffic sign types and provide potential candidates. Similar to human cognition, where irrelevant answers are swiftly filtered based on existing knowledge, the potential traffic sign candidates generated by the prior traffic sign hypothesis are obtained from LMM's preliminary understanding of the original road image. This preliminary understanding stimulates subsequent detailed thinking. In addition, when multiple traffic signs"}, {"title": "Characteristic Descriptions:", "content": "Since TSR is a fine-grained task, it is difficult for LMMs to accurately answer the specific types of traffic signs based on the existing knowledge. We consider that template traffic signs are easily accessible in national traffic sign databases, which helps to reduce the dependence on training data. Although previous TSR meth-ods have utilized template traffic signs at the feature level, actual traffic sign images are diverse due to lighting con-ditions, angles, occlusions, etc., and can be different from template traffic sign images. It increases the difficulty of cross-domain recognition at the feature level. We introduce the few-shot in-context learning to generate characteristic descriptions $D_{Char} = [D_{char}^1, ..., D_{char}^{T_t}]$ of each class $c$ of template traffic sign $I_{Temp} = [I_{Temp}^1, ..., I_{Temp}^{T_t}]$ with the prompts $T_{char} = [T_{char}^1, ..., T_{char}^{T_t}]$ as follows:\n$D_{char} = LMM(I_{Temp}^c, T_{char}^c)$,\nwhere $T_{char}$ represents the corresponding prompt for the template traffic sign $I_{Temp}^c$. As shown in Fig. 4, traffic signs in all countries have three key features: shape, color, and composition. When performing in-context learning, the de-signed prompt makes the LMM focus on these three features without introducing any other irrelevant information. The pro-posed in-context learning method only needs to generate the characteristic descriptions once for each template traffic sign. By avoiding computation at the feature level, the generated characteristic descriptions can reduce cross-domain differences between templates and real traffic signs. The prompts we design are uniform and simple for each traffic sign and require no special adjustments. We construct a memory bank to store the generated characteristic descriptions."}, {"title": "Differential Descriptions:", "content": "Since the characteristics of certain types of traffic signs are similar, we generate differential descriptions to emphasize the differences between these traffic signs. Given a template traffic sign $I_{Temp}^u$ and the similar traffic sign $I_{Temp}^v \\in [I_{Temp}^1, ..., I_{Temp}^{T_t}]$, the characteristic descriptions of $I_{Temp}^u$ and $I_{Temp}^v$ can be obtained by Eq. (3), and are respectively expressed as\n$D_{char}^u = LMM(I_{Temp}^u, T_{char}^u)$,\n$D_{char}^v = LMM(I_{Temp}^v, T_{char}^v)$.\nThe differential descriptions $D_{Diff}^{(u,v)}$ are then obtained by inputting $D_{char}^u$ and $D_{char}^v$ into the LMM as follows:\n$D_{Diff}^{(u,v)} = LMM(D_{char}^u, D_{char}^v, T_{Diff}^{(u,v)})$, where $T_{Diff}^{(u,v)}$ represents the prompt for generating the differential descriptions of $I_{Temp}^u$ and $I_{Temp}^v$. Thus, the final differential descriptions $D_{Diff}$ are expressed as\n$D_{Diff} = \\bigcup_{u, v \\in I_{Temp}} D_{Diff}^{(u,v)}$.\nAs shown in Fig. 5, experts perform the judgments of the signs similar to the traffic sign. The characteristic descriptions in the memory bank are imported to help generate differential descriptions of the traffic sign and each similar sign. The dif-ferential descriptions emphasize the subtle differences between similar traffic signs and can further optimize the fine-grained recognition ability of LMMs."}, {"title": "2) Multistep Thinking:", "content": "After obtaining the context descrip-tions $D_{cont}$, characteristic descriptions $D_{Char}$, and differential descriptions $D_{Diff}$, the LMM performs multistep reasoning for a target traffic sign. Step 1: LMM first conducts a preliminary understanding of the target traffic sign image based on existing knowledge. Step 2: LMM understands the scene information around the target traffic sign by referring to the context descriptions. Meanwhile, LMM further narrows the thinking scope by referring to the prior traffic sign hypotheses. Step 3: referring to the characteristic descriptions, LMM understands the basic features of various traffic signs of the shape, color, and composition, and compares the understanding of the target traffic sign image with the characteristic descriptions, thus stimulating the fine-grained TSR. Final: referring to the differential descriptions, LMM gains insight into understanding the differences between the target traffic sign and other similar traffic signs to optimize the recognition results as follows:\n$T = LMM(I^i, D_{cont}, D_{char}, D_{Diff}, T_{Multi})$,\nwhere $T_{Multi}$ represents the designed multistep prompt, and $T'$ is the final TSR results of the LMM. Through multistep thinking, the LMM performs feature inference step by step to finally find out the \"real face\" of the target traffic sign. Multistep thinking can largely stimulate the LMM's ability to recognize traffic signs at a fine-grained level. Therefore, the fine-grained TSR performance in real-world scenarios of LMM is improved."}, {"title": "IV. EXPERIMENTS", "content": "We conducted comprehensive experiments on several datasets, including three benchmark datasets: the German traffic sign recognition benchmark (GTSRB) dataset [55], the Belgium traffic sign dataset [56] and the Tsinghua-Tencent 100K (TT-100K) dataset [57]. TT-100K focuses on complex scenarios in the real world and is therefore a difficult bench-mark to recognize. Besides, to fully evaluate the performance of the proposed method in real-world scenes, we also con-ducted experiments on two real-world datasets in Japan, the Sapporo urban road dataset (Sapporo) and the Yokohama urban road dataset (Yokohama). We perform fine-grained TSR by Gpt-4v and Gpt-40. The proposed method does not require training any model. However, due to the rate limits of LMM's API 2, we followed the experimental setting strategy in [58] and randomly used the subset of GTSRB, BTSD, and TT-100K validation data for our study. Note that we do not reduce the number of categories in the subset, but rather keep it consistent with the categories in the full dataset to fully validate the fine-grained TSR performance of our think twice before recognizing strategy. In addition, since the traffic signs in the GTSRB and BTSD datasets have been extracted, multiple thinking is directly performed on them, and due to the lack of original road images, context descriptions were not generated. For TT-100K, Sapporo, and Yokohama datasets, we utilize the proposed traffic sign extraction framework to locate and extract traffic signs from the original road images. To evaluate the performance of the proposed fine-grained TSR method, we adopted the common evaluation metric of Top-kaccuracy, which performs comprehensive evaluations of the TSR performance. Top-k is defined as follows:\n$Top\\text{-}k = \\frac{\\sum C_k}{T}$"}, {"title": "V. DISSCUSSION", "content": "Since LMMs are trained on large amounts of internet data, there are concerns and speculation that they have memorized public benchmarks [70]. In this paper, we not only tested our method on three public benchmark datasets (GTSRB, BTSD, TT-100K) but also on two private datasets (Sapporo and Yokohama). Our method shows consistent and robust performance on all five datasets. It is impossible that these"}, {"title": "VI. CONCLUSION", "content": "In this paper, we proposed the think twice before recognizing strategy for constructing a general fine-grained TSR method. The proposed framework is simple, effective, and easily ex-tensible. The designed multi-thinking strategy stimulates the fine-grained recognition ability of LMM for traffic signs. Experimental results conducted on three benchmark datasets and two real-world datasets demonstrate the effectiveness of the proposed method."}]}