{"title": "Conditional Diffusion-Flow models for generating 3D cosmic density fields: applications to f (R) cosmologies", "authors": ["Julieth Katherine Riveros", "Paola Saavedra", "H\u00e9ctor J. Hort\u00faa", "Jorge Enrique Garc\u00eda-Farieta", "Ivan Olier"], "abstract": "Next-generation galaxy surveys promise unprecedented precision in testing gravity at cosmological scales. However, realising this potential requires accurately modelling the non-linear cosmic web. We address this challenge by exploring conditional generative modelling to create 3D dark matter density fields via score-based (diffusion) and flow-based methods. Our results demonstrate the power of diffusion models to accurately reproduce the matter power spectra and bispectra, even for unseen configurations. They also offer a significant speed-up with slightly reduced accuracy, when flow-based reconstructing the probability distribution function, but they struggle with higher-order statistics. To improve conditional generation, we introduce a novel multi-output model to develop feature representations of the cosmological parameters. Our findings offer a powerful tool for exploring deviations from standard gravity, combining high precision with reduced computational cost, thus paving the way for more comprehensive and efficient cosmological analyses .", "sections": [{"title": "1 INTRODUCTION", "content": "The advent of precision cosmology marks a new era in our under- standing of the Universe driven by a variety of upcoming missions. Among the key ongoing and forthcoming efforts are the Dark En- ergy Spectroscopic Instrument (DESI) (DESI Collaboration et al. 2016), the Euclid space mission (Laureijs et al. 2011; Amendola et al. 2018), the Legacy Survey of Space and Time (LSST) (Vera C. Rubin Observatory LSST Solar System Science Collaboration et al. 2020), the Wide-Field Infrared Survey Telescope (WFIRST) (Ake- son et al. 2019), and the Square Kilometre Array (SKA) (Square Kilometre Array Cosmology Science Working Group et al. 2020). These experiments aim to provide unprecedented measurements that will constrain cosmological parameters with high precision, with N-body simulations being a crucial component of these efforts. N-body simulations are, in fact, essential for accurately modelling the large-scale structure of the universe, understanding the evolution of cosmic fields, and interpreting the data from these surveys. N-body simulations play a fundamental role in understanding the physics behind galaxy survey data, as they enable the exploration of cos- mic structures across a range of scales. Although the non-linear regime of structure formation can, in principle, be approximated by perturbative-based methods (for different approaches, see e.g. Osato et al. 2019; Blas et al. 2014; Konstandin et al. 2019; Cabass et al. 2023; Bernardeau et al. 2002; Crocce & Scoccimarro 2006; Carl- son et al. 2009; Malik & Wands 2009; Baumann et al. 2012; Car- rasco et al. 2012), there is currently no single, universally adopted framework. Simulations not only offer insights into the small-scale behaviour of galaxy clustering but also provide a reliable means of investigating the clustering in cosmologies beyond the A-Cold Dark Matter (ACDM) model. As a result, simulations have become in- creasingly crucial in exploring modified gravity models, with f(R) models highlighting a minimal but significant modification of Ein- stein's general relativity (GR). Since deviations from GR are likely to manifest in summary statistics, accurately predicting these statistics is crucial for connecting to theoretical models of structure formation. Despite their advantages, simulations can be computationally expen- sive, depending on their complexity, such as the richness of physical phenomena included and the resolution of mass and scale. This has led to the rise of emulators based on deep learning algorithms that are designed to quickly and accurately predict cosmological observ- ables. In particular, generative models have emerged as a promising tool in cosmology, especially for enhancing and accelerating the analysis of simulations. Recent advancements in generative models offer a powerful approach to efficiently approximate and generate maps where their summary statistics closely mirror the ones ob- tained from simulated data. By learning the underlying distribution of the complex, high-dimensional cosmic structures, generative mod- els can potentially provide faster and more scalable solutions while maintaining accuracy, opening new avenues for both theoretical and observational cosmology. Generative models have been widely used in astronomy such as autoencoders (Ullmo et al. 2024; Rothschild et al. 2022; Arcelin et al. 2021; Jamieson et al. 2023a; Saadeh et al. 2025), normalizing flows (Hassan et al. 2022; Kwon & Hahn 2024;"}, {"title": "2 PRELIMINARIES", "content": "This section outlines the basis for conditional diffusion models as emulators for N-body simulations. Additionally, we introduce several strategies developed to implement diffusion model flavours."}, {"title": "2.1 Denoising Diffusion Models", "content": "Diffusion Probabilistic Models (DPMs) have rapidly gained promi- nence as a highly promising generative technique in recent years. Functioning as latent variable models for sequence modelling, DPMs utilise a latent space with the same dimensionality as the input data."}, {"title": "2.2 Denoising diffusion probabilistic model (DDPM)", "content": "Generative models aim to learn and approximate complex, high- dimensional data distributions (Lamb 2021). Among these, proba- bilistic diffusion models have recently emerged as a powerful tech- nique, distinguished by their capacity to transform unstructured noise into highly detailed and structured outputs that closely resemble the training data distribution (Ho et al. 2020). This is achieved through a two-stage process: a forward diffusion process that progressively adds noise to the data, gradually corrupting its structure, and a re- verse diffusion process that learns to reverse this corruption, itera- tively building coherent structures from the noise. This bidirectional approach, involving both forward and reverse diffusion, has proven particularly effective for challenging astrophysical scenarios, most notably in generating high-resolution fields (Schanz et al. 2023),re- construction (Sabti et al. 2024), and as emulators (Mudur et al. 2024; Zhao et al. 2023; Mudur & Finkbeiner 2022), setting new bench- marks for generative modelling performance. The learning aspect of these models involves mastering the reversal of a complex noising process, where progressively more noise is actively added to an ini- tial image xo q(xo) (Schanz et al. 2023). This noise sequence is executed through a Markov chain of T steps and systematically intro- duces Gaussian noise at each stage, generating a sequence of noise samples x1, ..., xt. According to Ho et al. (2020), during the forward diffusion step, noise is introduced to a sample x\u2081 from the preceding one x1\u22121 and step sizes are regulated by a variance {\u1e9e1={(0,1) \u220b\nas\n$$q(x_t|X_{t-1}) = \\mathcal{N} (x_t; \\sqrt{1 \u2013 B_t}x_{t-1}, \u03b2_tI).$$\n(1)\nwhere \u1e9e1 < \u03b22 < < \u03b2\u2081 regulates the reduction in noise between steps. In Eq. (1) the process assumes that xt is conditionally Gaussian with a mean $\\sqrt{1 \u2013 B_t}x_{t-1}$ and variance $\u03b2_tI$, where I is the identity matrix. The mean term controls how much of xt-1 contributes to xt, while the variance introduces isotropic Gaussian noise with a magnitude determined by \u1e9e\u2081 (Weng 2021). Therefore, by repeatedly applying the forward diffusion process, the image at a specific time t, denoted xt, can be expressed as a function of the original field x0. From conditional probabilities, the following joint probability is calculated as\n$$q(x_{1:T} | X_o) = \\prod_{t=1}^Tq(X_t | X_{t-1}).$$\n(2)\nThe term q(x1:7 | x0) represents the overall probability of observing the sequence x1 to xy. Each factor q(xt | Xt-1) denotes the probability of transitioning to state x\u2081 from the previous state xt-1, capturing the Markov property, where the next state is determined solely by the current state (Weng 2021). A notable feature of this process is that sampling at any arbitrary time step can be achieved in closed form by leveraging the reparameterization trick (Ho et al. 2020). This property allows for direct access to any sample x\u2081 eliminating the need to sequentially compute all t \u2013 1 previous noisy image\n$$x_t = \\sqrt{\\bar{a}_t}x_o + \\sqrt{1 \u2013 \\bar{a}_t}\u0454,$$\n(3)\nwhere at = 1-\u00dft, with\u0101\u2081 = \u03a0\u03b1\u2081, and \u0454 ~ N(0, I). The noise added at each step is systematically removed during the reverse diffusion phase (Ho et al. 2020). As a result, the process begins with a distribu- tion that contains only noise (the final state of the forward process). Consequently, the noise is removed from the samples step by step, moving in the reverse direction. As stated in Ho et al. (2020), the inverse diffusion process considers xo, and the events are connected through the conditional probability distribution\n$$P_\u03b8 (x_{0:T}) = P(x_T) \\prod_{t=1}^T P_\u03b8 (x_{t-1} | x_t).$$\n(4)\nbeing the reverse process equals to\n$$P_\u03b8 (x_{t-1} | x_t) = \\mathcal{N}(x_{t\u22121}; \u03bc_\u03b8 (x_t, t), \u03a3_\u03b8 (x, t)).$$\n(5)\nHere, a neural network with parameters @ is used to compute Eq (4). This express the joint probability distribution pe (X0:T) over a se- quence of variables x0, X1, ..., xr parameterized by 0 (Weng 2021). We can divide this joint probability into two parts: the marginal probability of the final state p(x\u012b), and the product of conditional probabilities po(Xt-1 | Xt) over all timesteps t from 1 to T (Weng 2021). This structure reflects a reverse process, where each state xt-1 depends on the subsequent step x\u2081. The variance is usually se- lected as \u03a3\u03b8 (xt, t) = \u03b2\u2081I as Ho et al. (2020) reported to be the best performance in their results, while the mean \u03bc\u03b8 (x, t) is given by\n$$\u03bc_\u03b8 (x,t) = \\frac{1}{\\sqrt{\u03b1_t}}(x_t \u2013 \\frac{\u03b2_t\u0454_\u03b8 (x_t,t)}{\\sqrt{1 \u2013 \u03b1_t}}),$$\n(6)\nwhere \u2208 (xt, t) is the neural network outcome of the noise e present in the sample x\u2081. The loss function used for this optimisation is given by the expectation value (Ho et al. 2020)\n$$L_t = E_{t\\sim[1,T], x_0, \u0454} E \u2013 \\mathcal{E}_\u03b8 (X_t,$$\n(7)\nbeing \u2208 (x, t) the neural network prediction of the noise e present in the sample x\u2081, and t ~ [1,T] the time step drawn from a uniform distribution. By minimising this loss, the model learns to predict and remove the noise at each step, enabling it to reverse the diffusion process during inference and generate realistic data from random noise. The training algorithm is listed in Algorithm 1. Once training is completed, we expect to generate xo ~ p(x0) image from noise. In fact, the model learns to approximate the probability distribution of the training set. Hence, we can sample from this distribution and be able to generate new samples that obey the same features as the training dataset. This can be done by sampling T times Eq. 5 crossing the Markov chain until t = 0 as\n$$x_{t-1} = \\frac{1}{\\sqrt{\u03b1_t}}(x_t \\frac{\u03b2_t}{\\sqrt{1 \u2013 \\bar{\u03b1_t}}}\u0454_\u03b8(x,t) + \\sqrt{\u03b2_t}z,$$\n(8)\nwith z ~ N(0, I). Here, the first term is the mean estimate provided by the neural network Eq. 6 perturbed by the presence of a Gaussian noise \u1e9e\u2081 akin to a Langevin sampling step (Welling & Teh 2011). The inference algorithm is listed in Algorithm 2."}, {"title": "2.3 Denoising diffusion implicit models (DDIM)", "content": "DDIMs are implicit probabilistic models associated with DDPMs, since they are trained using the same loss function (Song et al. 2022). DDIMs present an optimised version of DDPM and offer a more effi- cient and faster solution to the image generation problem. Although it uses the same training objective as DDPM, DDIM introduces non-Markov processes instead of strictly following the Markov approach. This allows DDIM to balance between the quality of the generated samples and processing time. Furthermore, it can create high-quality images faster than DDPM and it performs direct interpolations in latent space and reconstructs observations with minimal error, pro- viding greater flexibility in the generation process (Song et al. 2021). According to Song et al. (2021), the non-Markov inference process is employed in this case, which leads to the same function applied in the DDPM model mentioned above in equation (1). Therefore, the DDIM model generalises the DDPM model and, in turn, allows modifications to the design of the inverse Markov chains. The ex- pression for the non-Markovian conditional probability distribution P(Xt-1 | Xt, xo) is\n$$p(x_{t-1} | x_t, X_0) = \\mathcal{N}(x_{t-1}; \\sqrt{\\bar{a}_{t-1}}x_0 +\n\\frac{\\sqrt{1-\\bar{a}_{t-1} -\u03c3_t^2(\\frac{x_t - \\sqrt{\\bar{a}_t}x_0 }{\\sqrt{1-\\bar{a}_t }}})}{\\sqrt{1-\\bar{a}_t}}}, \u03c3_t^2).$$\n(9)\nAccording to Song et al. (2021), the processes for the implicit DDIM diffusion models are defined in two phases. In the first phase, the for- ward diffusion process defines xo and transforms it into x\u2081. Initially, the inference distribution, the non-Markovian forward process is as follows\n$$P(x_{1:T} | X_0) = P(x_T | X_0) \\prod_{t=2}^T P(x_{t-1} | x_t, X_0),$$\n(10)\nwhere p(x1:T | X0) corresponds to the conditional probability of observing the sequence of variables x1:T evolves from an initial state x0. It shows that the likelihood of a sequence of observations given the initial conditions can be decomposed in terms of a chain of probabilistic dependencies over time (Zhang et al. 2023). Eq. 9 can be expressed as\n$$x_{t-1} = \\sqrt{\\bar{a}_{t-1}} \\frac{x_t - \\sqrt{1 \u2013 \\bar{a}_t}\u0454_\u03b8(x_t,t)}{\\sqrt{\\bar{a}_t}} + \\sqrt{1 \u2013 \\bar{a}_{t-1}} - \u03c3_t\u0454\u0454(x,t) + \u03c3_tz.$$\n(11)\nwith z ~ N(0, 1), \u03b5\u03b8 (xt, t) is the predicted neural network noise Et at time t, and o\u2081 is a parameter learning whose variation determines the difference in the posterior distribution. When \u03c3\u2081 = 0, there is not random sampling and the sample is generated into a deterministic scenario. This is the core of DDIM model. Besides, since it does not need to satisfy the Markov process, a subset {t1, ..,ts} \u2208 {t1, .., tr} with s << T can be created from the original T diffusion time-steps for sampling inference, where s is the number of steps in the new diffusion subset. The inference DDIM algorithm is listed in Algo- rithm 3. DDPM and DDIM primarily differ in their approach to sam- pling. While DDPM relies on a Markov process and requires many diffusion steps to achieve high-quality results, it tends to be compu- tationally expensive (Weng 2021). The DDIM model offers several improvements over DDPM. It can produce higher-quality samples in fewer steps, enhancing efficiency (Weng 2021). Moreover, DDIM maintains a consistency property due to its deterministic generative process, ensuring that samples conditioned on the same latent vari- able share similar high-level features (Weng 2021). This consistency also enables DDIM to perform meaningful semantic interpolation within the latent space, resulting in smoother and more interpretable transitions between samples (Weng 2021)."}, {"title": "2.4 Conditioned Generation: Classifier-Free diffusion guidance", "content": "While training generative models on the simulation, it is important to generate samples conditioned on the cosmological parameters. To ex- plicit incorporate parameter information into the diffusion process, we employ the Classifier-Free Guidance (CFG) in our methodol- ogy (Ho & Salimans 2022). This technique assumes an unconditional denoising diffusion model p(x) parameterized through an estimator \u20ac0(xt,t) = \u20ac0(X1, t, y = 0)\u00b9 and a conditional model po (x|y) param- eterized through eo (xt, t, y). Both models are trained with the same neural network. In fact, the conditional diffusion model is trained on data (x, y), where the conditioning cosmological parameters y are randomly discarded by y < 0.1 (being y a sample drawn from an uniform distribution [0,1]) such that the model knows how to gen- erate images unconditionally as well. Therefore, the score estimator can be written as (Ho & Salimans 2022)\n$$\u0112_\u03b8(x_t, t, y) = \u20ac_\u03b8 (x_t, t, y) + \u03c9(\u03b5_\u0189(x_t, t) \u2013 E_\u03b8 (x_t, t, y)),$$\n(12)\nwhere w is a parameter that controls the strength of the classifier guidance. In our experiments, we found that w = [0,0.5] provides a suitable range of values to obtain good results. The authors (Ho & Salimans 2022) conclude in their studies that the diffusion model needs to have a part dedicated to the unconditional generation task in order to produce classifier-free guided scores effective for sample quality."}, {"title": "2.5 Stochastic Interpolants (SI)", "content": "Although diffusion-based methods have achieved impressive results in areas such as image generation, there is ongoing research into methods that provide exact transport between arbitrary (not just Gaus- sian) probability densities within a finite time frame. Initially, score- based diffusion models achieved the best results using Stochastic Differential Equations (SDEs) (Albergo et al. 2023). However, recent research has shown that methods based on ordinary differential equa- tions (ODE) can achieve comparable or even superior performance if the scoring function is learned effectively. ODE-based methods offer significant advantages, including the availability of an exact and computationally tractable likelihood formula and the straightfor- ward application of established adaptive integration techniques for sampling (Albergo & Vanden-Eijnden 2023). A recent generative model based on stochastic dynamics propose the use of stochastic interpolants (SI) x\u2081 that connect a base density po to the target p1, but allow for bases that are more general than a Gaussian density. The dynamics can be described as (Albergo & Vanden-Eijnden 2023)\n$$x(t) = a(t)x_0 + \u03b2(t)x_1 + \u03c3(t)W(t), t\u2208 [0, 1],$$\n(13)\nwhere by construction, it satisfies x(t = 0) = X0 po, and x (t = 1) = X1 P1. This approach therefore exactly bridge between samples from po at t = 0, and from p\u2081 at t = 1. For a large class of densities, po and p\u2081 supported on Rd, these distributions are absolutely continuous with respect to the Lebesgue measure and p(t) satisfies a family of forward and backward Fokker-Planck equations (Albergo et al. 2023). Therefore, Eq. 13 can be realized by many different processes such as ODEs and SDEs, and whose densities at time t are given by p(t) (Albergo & Vanden-Eijnden 2023). Following the work in (Chen et al. 2024; Sabti et al. 2024) let us write the functions under Eq. 13 as a(t) = (t) = 1 t, \u03b2(t) = t\u00b2, and W = \u221atz with z N(0, I) a Wiener process. The authors in (Chen et al. 2024; Albergo et al. 2023) also demonstrate that the velocity field associated with the interpolant, Eq. (13) takes the form\n$$v(t, x_0,x_1) = &(t)x_0 + \u03b2(t)x_1 + 8(t)W(t),$$\n(14)\nwhere the dot in the variables represents differentiation with respect to time t. The velocity field can be approximately computed with a neural network (t, x(t)) by minimizing the loss function\n$$L[\\Phi] = \\int dt E_{x_0,x_1\\sim q_0,q_1} [(\\Phi(t, x(t)) \u2013 v(t, x_0, x_1))^2] .$$\n(15)\nOnce trained, the velocity field will function as the drift term within the stochastic differential equation (Sabti et al. 2024)\n$$dx(t) = v(t, x(t))dt + (t)dW(t),$$\n(16)\nwhose solutions are such that x(t = 1) ~ p(x1|x0) and W accounts for another Wiener process. This equation expresses the evolution of x(t) in terms of two components, the first term describes the deterministic part of the dynamics, while the second term accounts for the stochastic component of the process. To suit this approach to our work, xo represents a latent representation of the cosmological parameters generated by a neural network while x\u2081 describes the 3D simulation. Once the model is trained, the velocity field is substituted by the UNet in Eq. 16, and the initial volume (x(t = 0)) is given by the feature representation for the cosmological parameters. The time interval t \u2208 [0,1] is divided in 200 steps along which we solve Eq. 16. The Stochastic differential equation was solved using the Euler second-order method. At the end, the emulator should generate distributions of volumes x(t = 1) that resemble the characteristics of the density field conditioned on the cosmological parameters."}, {"title": "3 DATASET: MODIFIED GRAVITY SIMULATIONS", "content": "We used a dataset already generated by (Garc\u00eda-Farieta et al. 2024a). These simulations were created with the COmoving Lagrangian Ac- celeration (COLA) algorithm (Tassev et al. 2013; Koda et al. 2016), in particular, the authors used MG-PICOLA2 (Winther et al. 2017), a modified version of L-PICOLA (Howlett et al. 2015) that has been extensively tested against full N-body simulations and that extends the gravity solvers to a variety of gravity models. The dataset con- sists in 2500 modify gravity simulations varying four cosmological parameters = {\u03a9m, h, \u03c3\u03b5, fro}, where h is the reduced Hubble parameter, 08 the r.m.s. density fluctuation within a top-hat sphere"}, {"title": "4 METHODOLOGY", "content": "4.1 Neural Network Architecture\nWhile DDPM and DDIM employ neural networks to predict noise at each time step during reverse diffusion, stochastic interpolants use them to estimate the velocity field (t, x\u2081). The architecture used in this research for all approaches is the 3D-UNet depicted in Fig. 4. This model starts with 64 x 64 x 64 voxels with 1 channel, which are passed to a calculating schedule across T = 1000 timesteps, ge- ometrically (cosine) interpolating noise levels from a Beta Start of 1 \u00d7 10-4 to a Beta End of 0.02. Several experiments were performed using lineal, polynomial, and sigmoid functions, however, cosine functions provided the best performance. This UNet consists of an encoder, the middle module, and its decoder. The feature maps of the same pixel level are concatenated via shortcut connections be- tween the encoder and decoder. In the encoder, max-pooling is used to down-sampling layer halves the feature maps, enhancing feature extraction and expanding the receptive field. On the other hand, up- sampling3D in the decoder increases the feature maps, progressively restoring the spatial resolution of the original volume. The output of the decoder part is processed with a group normalization layer followed by an swish activation and a final convolutional block. In the middle module, we have different configurations depending on the method used (DDPM or SI). For the SI case, four ResNet blocks are sequently used. The ResNet block shown in Fig. 4-(b) processes both the feature maps and the timesteps. The latter is first projected onto an embedding space of dimension 32 using sinusoidal scaling, and then processed through two dense layers of 32 neurons, each with swish activation functions. In case that DDPM (and DDIM) is employed, the middle module consists in two paired ResNet-Target blocks where the cosmological parameter information is inserted into the architecture. Fig. 4-(c) illustrates the target block schema, where the cosmological parameters are fed into a pre-trained neural network to get a 3D feature representation (explained later in Subsec. 4.2) of these parameters. The resultant parameter voxel is then concatenated to the feature maps coming from the encoder part.\n4.2 Feature Representation for Cosmological Parameters\nWe built a 3D volume feature representation for the cosmological parameters to either aggregate it with the simulation boxes along with the time-steps in DDPM (and DDIM) or define the base density x0 ~ po in the SI approach. We propose to build this parameter volume based on the so-called representation learning, a powerful technique that enable a neural network to automatically discover and learn the most useful representations of raw data (Bengio et al. 2014). First, we developed a multioutput regression model using the neural network displayed in Fig. 5. For this task, we compute the summaries for all train, validation and test volumes such as the power spectra (PS), probability distribution function of the voxels (PDFs), and four different configurations for the bispectra (Bis). Then, we take data pairs ([\u03a9m, h, 08, fr0], [PS, PDFs, Bis1,..., Bis4]) for training the model in a supervised way. The network receives the cosmological parameters as input, which are then processed by two dense layers, each with 64 neurons, followed by a sigmoid activation function and batch normalization. The output features are reshaped into a (64, 64, 64, 1) volume and passed through three 3D convolutional layers, each employing 16 filters, sigmoid activations, and batch normalization. Then, a 3D convolutional layer with one filter along with a sigmoid activation is applied generating a 3D representation of the input parameters with dimensions matching the simulation boxes. This sub-neural network yields the 3D representation used in the diffusion models. Following with the neural network architecture, a 3D global max pooling operation is applied to flatten the volume, resulting in six output branches, each corresponding to one of the pre- defined summaries. The optimized network architecture is shown in Fig. 5. Training is performed using a Huber loss, with weighted losses assigned to the power spectra and PDF to prioritize their accuracy.\n4.3 Training and summary statistics\nSimulation data normalization involved clipping values using the minimum of all maximum values found across the boxes in the training dataset. Subsequently, we applied a logarithmic scale and normalized the data by subtracting the minimum logarithmic value (logmin) and dividing by the range of logarithmic values (logmax - logmin), both calculated from the training data. All models were trained using the Huber loss in Eq. 7 instead of the standard mean squared error. The models were optimized with the Adam optimizer employing a learning rate of 10-4, a batch size of 16, and training for 30 epochs. Callbacks were implemented to mitigate overfitting. The DDPM model, with approximately 15 million parameters, required approximately nine hours of training on a 16GB Nvidia T4 GPU, while the interpolant model required twelve hours on the same GPU.\n4.3.1 A quality metric for generated density fields: n-point statistics\nThe spatial distribution of dark matter is non-Gaussian, and remark- ably little is known about the information encoded in it about cosmo- logical parameters beyond the power spectrum. Therefore, it is crucial that generative models can learn significant information well beyond its power spectrum. Therefore, to illustrate the quality generation of our emulators, we compute some summary statistics that provide information about the Gaussian and non-Gaussian signals. We start using the one-point statistics, commonly known as the probability\ndensity function (PDF). The PDF reveals density variations within the simulated volume, identifying overdense regions like galaxy clus- ters and dark matter halos, as well as underdense regions such as cosmic voids. The values of density contrast 6 are binned using log- arithmically spaced bins. The PDF of the cosmic density field is then defined as the normalized number of cells as:\n$$\u03a1(\u03b4_i) = \\frac{N_i}{N_{total} \u03b4},$$. (17)\nwhere Ni is the number of samples in the i-th bin, Ntotal is the total number of samples, and Ad is the width of each bin. The next statistical moment is the matter power spectrum defined as\n$$\\langle\u03b4 (k) \u03b4 (k\u2019)\\rangle = (2\u03c0)^3\u03b4_p (k + k') P(k),$$. (18)\nwhere angular brackets denote ensemble average, dp is the 3D Dirac delta function, which enforces the homogeneity of the density statis- tics, and k, k' are Fourier modes. The fact that the power spectrum depends only on the magnitude k = |k| is required by isotropy, which allow us to provide information about the Gaussian signal in the data. In addition to the two-point statistics, we also considered the three- point statistics of the density field. These statistics are able to capture any non-Gaussianities in the density field. The matter bispectrum B (k1,k2, k3) is defined as\n$$\\langle\u03b4 (k_1) \u03b4 (k_2) \u03b4 (k_3)\\rangle = (2\u03c0)^3\u03b4_p (k_1 + k_2 + k_3) B (k_1, k_2, k_3) .$$. (19)\nUnlike the power spectrum, which is only sensitive to the magnitude of Fourier modes, the bispectrum is the lowest-order correlator that is sensitive to phases. Because homogeneity constraints the wavenum- bers (k1 + k2 + k3) to form a closed triangle, we can also express the bispectrum as a function of two magnitudes and an angle, i.e. B(k1,k2, 0). It is useful, particularly in analyses of modified theories of gravity to consider the reduced bispectrum\n$$Q (k_1,k_2, k_3) = \\frac{B (k_1,k_2, k_3)}{P (k_1) P (k_2) + P (k_2) P (k_3) + P (k_1) P (k_3)},$$. (20)\nto remove the information that is already contained in the power spectrum. Note that Q(k1,k2, k3) can be written as Q(k1,k2, 0) which define a unique triangle given two out of the three arguments."}, {"title": "5 RESULTS", "content": "Having thoroughly examined the methodologies employed for DDPM (and DDIM) as well as SI models, we now turn our attention to evaluating their performance in generating 3D density fields. To assess the efficacy of the DDPM model, we trained it on the rele- vant dataset and subsequently generated 50 synthetic samples. These samples were then rigorously compared against a test set instance with identical cosmological parameters, focusing on their summary statistics. The outcomes of this analysis for the DDPM model are il- lustrated in Fig. 6. The results demonstrate that the DDPM-generated fields exhibit remarkable consistency with the true field. Not only do they accurately capture the Gaussian signal, but they also success- fully recover a diverse range of bispectra configurations. Specifically, two of the bispectra configurations analysed were directly aligned with those used during the training of the feature representation (as detailed in Sec. 4.2), while the remaining configurations represent interpolations between these key points. This highlights the mod- els ability to generalise and produce physically meaningful outputs, even for configurations not explicitly encountered during training. Notice that for lower wavenumbers(k), the predicted power spectrum deviates significantly from the true one. This discrepancy can be at- tributed to the finite size of the volumes, which inherently imposes a cut-off on large-scale modes. Due to the periodic boundary condi- tions and the limited spatial extent of the simulation boxes, modes with wavelengths exceeding the box size are effectively truncated. As a result, the power spectrum and bispectra, are influenced by the absence of these large-scale fluctuations. For the latter, we can observe slight deviations in their tails. These limitations are particu- larly significant in cosmological simulations with a small resolution size, as large-scale modes play a crucial role in shaping the structure of the density fields. As previously discussed, one of the primary drawbacks of DDPM is the significant computational time required to generate samples. This is due to the iterative nature of the process, where the neural network must denoise the image over T = 1000 sequential steps. To address this limitation, DDIM was introduced as an alternative approach during the inference process after training the DDPM model. DDIM accelerates the generation process by relaxing the Markovian assumption, as detailed in Sec. 2.3. While this modi- fication substantially reduces inference time, it comes at the cost of a slight degradation in the quality of the generated samples. This trade- off is evident in Fig. 7, where the bispectra of the DDIM-generated simulations show a noticeable, though modest, deterioration com- pared to those produced by DDPM. The balance between sample quality and inference time is a critical consideration, particularly in applications requiring the bispectra to constrain cosmological param- eters. During the validation phase, this trade-off must be carefully calibrated to ensure that the reduction in computational cost does not compromise the scientific utility of the generated samples. By fine-tuning this balance, DDIM enables the efficient production of a high number of volume samples in a shorter time, making it a practical choice for large-scale simulations despite its minor quality trade-offs. Note that in the DDIM model, the small Fourier modes exhibit behaviour consistent with the ground truth. However, devi- ations begin to emerge for larger modes, reaching up to 30% error. This discrepancy can be linked to the slight degradation in quality observed in DDIM, as we typically expect precise reconstruction at scales below the Nyquist frequency. Despite this, the power spec- trum can be recovered within tens of percent accuracy across the entire range. Finally, the statistics of a generated sample from the SI approach"}]}